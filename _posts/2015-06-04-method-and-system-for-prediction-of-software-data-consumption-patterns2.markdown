---

title: Method and system for prediction of software data consumption patterns
abstract: A method including downloading a streaming model file and at least one initial execution file from a server via a conventional download protocol without using a specialized streaming protocol. When executed, the initial execution file only partially implements an application. The model file stores information identifying additional portions of the application file to be downloaded from the server. Data is read from the initial execution file, and stored in a local copy of the application file. Then, the application is executed by executing the local copy. Until the entire application file has been downloaded and as the application is executing, the information is read from the model file to identify a next file to download, the next file is downloaded via the conventional download protocol without using a specialized streaming protocol, next data is read from the next file, and the next data is stored in the local copy.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639387&OS=09639387&RS=09639387
owner: CODE SYSTEMS CORPORATION
number: 09639387
owner_city: Seattle
owner_country: US
publication_date: 20150604
---
This application claims the benefit of U.S. Provisional Application No. 61 361 373 filed Jul. 2 2010 which is incorporated herein by reference in its entirety.

The present invention is directed generally to methods and systems for profiling access to a file that implements an application.

A virtual application is a virtual machine image pre configured with all of the files registry data settings components runtimes and other dependencies required for a specific application to execute immediately and without installation on a host computing device. The virtual application is partially isolated from other applications implemented on a host computing device and partially isolated from an underlying host operating system installed and executing on the host computing device. The virtual application is encapsulated from the host operating system by a virtual runtime environment which includes a virtual operating system that receives operations performed by the virtualized application and redirects them to one or more virtualized locations e.g. a virtual filesystem virtual registry and the like .

Thus the virtual application may be conceptualized as including two components a virtualization runtime and a virtual application configuration. The virtualization runtime implements the virtual runtime environment which implements various operating system application programming interfaces APIs in such a way that allows the executing virtual application to access and interact with items that may not be present on the host computer. The virtual application configuration includes data necessary to implement the virtual application within the virtualization runtime.

The virtual application is stored in and implemented by one or more data files and or executable files. Depending upon the implementation details the one or more data files and or executable files storing and implementing the virtual application may include blocks of data corresponding to each application file of a natively installed version of the application. Herein these blocks of data will be referred to as virtual application files. The one or more data files and or executable files storing and implementing the virtual application also include configuration information.

The data files and or executable files are configured to execute within a virtual runtime environment that is provided at least in part by the virtual operating system. When the virtual application is executed within the virtual runtime engine the configuration information is used to configure the virtual operating system to execute the virtual application. For example the configuration information may contain information related to the virtual application files virtual registry entries environment variables services and the like. The virtual operating system is configured to communicate with the host operating system as required to execute the virtual application on the host computing device.

To download and execute a virtual application a user must either use a specialized streaming protocol or download the entire virtualized application file before executing the application. Therefore a need exists for a method and system configured to download and execute a virtualized application file without first downloading the entire file or using a specialized streaming protocol. The virtual application can be executed using less than the entire virtualized application file provided the executing virtual application does not request access to a portion of the file that has not been downloaded. Therefore a need exists for a method or system that determines in which order the virtual application will request access to portions of the virtualized application file. A need also exists for systems and methods for managing the download and execution of a virtual application by a virtual runtime engine. The present application provides these and other advantages as will be apparent from the following detailed description and accompanying figures.

A diagram of hardware and an operating environment in conjunction with which implementations of the server computing device the model building server the client computing device the computing device and the network may be practiced is provided in and described below.

As explained above a virtualized application file is transferred to the client computing device from the server computing device . The virtualized application file is illustrated in dashed lines to indicate that the virtualized application file is stored in the cache during and after the download. However before the download begins the virtualized application file is not stored in the cache . As will be explained below the virtualized application file may be an executable file or a file configured to execute within a virtualized environment provided by a virtual machine or virtual runtime engine .

The system memory A stores one or more files implementing one or more virtual machines or virtual runtime engines . By way of a non limiting example the system memory A may include a plurality of virtual machine executable files that when executed each implement a different virtual machine. For example each of the virtual machine executable files may implement a different version of the same virtual machine. The virtual machine executable files may be executed individually. When executed a virtual machine executable file implements a virtualized environment. Execution of a virtual machine executable file may be initiated by the Sandbox Manager using a command including a parameter e.g. a file path identifying a virtualized application file to execute. In response to receiving the parameter the virtual machine executable file executes the identified virtualized application file inside the virtualized environment implemented by the virtual machine executable file. illustrates a virtual application implemented by the virtualized application file being executed by a virtual runtime engine . The virtual runtime engine may execute within an operating system shell process. Optionally the virtual machine executable files may be stored in the cache .

The Sandbox Manager and the virtual runtime engine may both have read write access to a block of shared memory that may be used to send settings and state information between the Sandbox Manager and the virtual runtime engine .

The virtualized application file includes a version identifier that may be used by the Sandbox Manager to select which of the virtual machine executable files is configured to execute the virtualized application file .

In the embodiment illustrated the system memory B stores web server components configured to implement a web server. The web server components may be configured to provide a web page having one or more links to virtualized application files using standard Hypertext Transfer Protocol HTTP protocol. By way of non limiting examples the web server components may include Internet Information Services IIS provided by Microsoft Corporation Apache and the like. While illustrated as being outside the filesystem B those of ordinary skill in the art appreciate that the virtualized application file and the web server components may be conceptualized as being within the filesystem B.

The virtualized application file may include components necessary to implement a virtual runtime environment including a virtual operating system configured to execute in the operating system A see of the client computing device illustrated in . Alternatively the virtual runtime environment may be implemented by one of the virtual machine executable files see . The virtualized application file includes components necessary to implement the virtual application configured to execute in the virtual runtime environment provided by the virtual runtime engine illustrated in . In particular embodiments a single virtualized application file is used to implement both the virtual operating system and the virtual application . However those of ordinary skill in the art appreciate that more than one virtualized application file may be used to implement the virtual operating system and the virtual application . For example the components implementing the virtual runtime environment may be stored in one of the virtual machine executable files see and the components implementing the virtual application may be stored in the virtualized application file . Further one or more of the files used to implement the virtual application may be other than an executable file having the exe file extension.

The virtual operating system includes a virtual filesystem a virtual registry and a virtual process environment and threading subsystems component . The virtual application interacts with the virtual filesystem virtual registry and virtual process environment and threading subsystems component instead of interacting directly with the host filesystem A the host registry A and the process environment and threading subsystems component A of the host operating system A illustrated in . The virtual operating system is configured to communicate with the host operating system A illustrated in as required to execute the virtual application .

The virtual application executes inside a virtual runtime environment provided at least in part by the virtual operating system . Some virtual applications require one or more additional runtime environments to execute. For example to execute a Flash application the Flash runtime engine must also be installed. Therefore to virtualize a Flash application both the Flash application and Flash runtime engine must be included in the virtualized application file and configured to execute in the portions of the virtual runtime environment provided by the virtual operating system . Collectively all runtime components necessary to execute the virtual application will be referred to as a virtual runtime engine. However those of ordinary skill in the art appreciate that the virtual runtime engine may include only the virtual operating system and components of other additional runtime engines e.g. the Flash runtime engine required to execute the virtual application may be loaded separately by the virtual operating system . When executed the virtual runtime engine generates at least in part the virtual runtime environment in which the virtual application executes.

Referring to a natively installed version of an application is configured to execute within a runtime environment provided at least in part by the host operating system A. Typically to execute within the runtime environment provided at least in part by the host operating system A a natively installed version of an application modifies the configuration and settings of the host operating system A. For example the natively installed version may install dynamic link libraries or change registry settings of the host operating system A. In contrast a virtual version of the same application may be executed on the host operating system A without installation on the host operating system A. Thus the virtual application does not modify the configuration or settings of the host operating system A. For example to execute the virtual application dynamic link libraries dlls data files registry settings environment variables and the like need not be modified on to the host operating system A.

The virtualized application file includes virtualized application files A C corresponding to application files A C of a natively installed version of the same application. The virtualized application files A C are stored as blocks of data inside a configuration data block . During execution the virtualized application files A C are accessed via the virtual filesystem . The virtualized application files A C include one or more startup executables. The virtualized application file identifies one or more startup executables that are executed when the virtual application is first executed. The startup executables may be identified in the configuration data block .

When the virtualized application file is executed the configuration data block is used to configure the virtual operating system to execute the virtual application. For example the configuration data block may contain configuration information related to the files in the virtual filesystem e.g. the virtualized application files A C entries in the virtual registry environment variables services and the like. The configuration data block may also include basic application metadata and settings such as the application name application version and sandbox location. Further the configuration data block may provide isolation information to the virtual operating system . This information indicates which virtualized application files A C virtual registry keys virtual registry values environment variables and services are to be isolated from the host operating system A.

The configuration data block may also include one or more virtual layers. Each virtual layer may identify files registry entries environment variables and services. As the virtual layers are read the corresponding files registry entries environment variables and services are added to appropriate runtime data structures. If the virtualized application file is configured to execute on more than one host operating system the configuration data block may include a virtual layer for each operating system. In such an embodiment each virtual layer includes information necessary to configure the virtual runtime environment to execute on a particular operating system. Further the configuration data block may include a virtual layer that includes configuration information common to the other virtual layers e.g. a default virtual layer .

To execute the virtual application an initialization process is first performed. During this process the virtual operation system is launched and configured by the configuration data block . A component of the virtual runtime engine referred to as a reader not shown reads data stored in the configuration data block and uses that data to configure the virtual runtime environment. For example the reader reads the virtual layer for the host operating system A and any other applicable virtual layers and uses the information read to configure the virtual operation system and in some implementations other components of the virtual runtime environment to execute the virtual application on the host operating system A. The virtual filesystem may be configured to mirror a host filesystem configured to execute a natively installed version of the application. Similarly the virtual registry may be configured to mirror a host registry configured to execute a natively installed version of the application.

After the initialization process has completed the appropriate startup executable s is are launched inside the virtual operating system . The virtual operating system intercepts calls to the host operating system A see and routes them to corresponding components of the virtual operating system . For example when the virtual application requests to access an application file using a path of a natively installed version of the application the virtual operating system intercepts the request and routes the request to one of the virtualized application files A C corresponding to the application file requested. The virtual operating system may also route some requests and actions to the host operating system A see for processing.

The virtualized application file is read only and when executed cannot be modified by the virtual application or components of the virtual runtime engine see . Therefore modifications to the data stored in the configuration data block e.g. modifications to the virtualized application files A C modifications to the registry keys of the virtual registry and the like are written to a readable and writable memory location referred to herein as a sandbox . The sandbox is a location on the host filesystem A a network share a removable storage device and the like whereat files may be created modified and deleted by the virtual application at runtime. For example when the virtual operating system needs to create modify or delete a virtualized application file the virtual operating system does so in the sandbox . Similarly if the virtual application modifies a virtual registry value the virtual registry value is changed in the sandbox . The virtual operating system may also route some requests and actions to the host operating system A for processing.

U.S. patent application Ser. No. 12 188 155 filed on Aug. 7 2008 U.S. patent application Ser. No. 12 188 161 filed on Aug. 7 2008 and U.S. patent application Ser. No. 12 685 576 filed on Jan. 11 2010 all of which are incorporated herein by reference in their entireties disclose systems that may be used to create and configure the virtualized application file . As described in greater detail in U.S. patent application Ser. Nos. 12 188 155 12 188 161 and 12 685 576 the virtualized application file may be created by a virtual application executable constructor or authoring tool using an application template that includes copies of files such as a configuration file application files A C and the like used to configure the virtualized application file . However the template is not a requirement. Instead to build the virtualized application file the authoring tool needs only the configuration file and copies of any applications files A C necessary for a natively installed version of the application to execute. The applications files A C and the configuration file are referred to collectively as an application configuration .

The authoring tool combines the application configuration and the components of the virtual runtime engine e.g. the virtual operating system into the executable virtualized application file . Sometimes multiple virtual applications share a common set of virtual machine configuration settings or virtual runtime engine components. By way of a non limiting example multiple Flash applications may be configured to be executed by the same Flash runtime engine. Further system administrators may want to share a common set of configuration options e.g. browser bookmarks application settings etc. across a department or enterprise. These settings may be stored in a file referred to as an xlayer file and incorporated into one or more virtual application files at runtime by the virtual runtime engine . Depending upon the implementation details the authoring tool may be used to create the xlayer file .

The xlayer file cannot be executed directly from the host operating system A and instead requires the virtual runtime environment supplied at least in part by the virtual operating system . Like the configuration data block the xlayer file may be read by the reader of the virtual runtime engine at runtime. The information stored within the xlayer file may be made available to a virtual application e.g. the virtual application via the virtual filesystem and virtual registry of the virtual operating system at runtime. By way of a non limiting example the configuration data block may specify a location on the host filesystem A whereat the virtual runtime engine is configured to look for xlayer files. If an xlayer file is located in the specified location the xlayer file may be read automatically by the reader of the virtual runtime environment. Alternatively the virtual runtime engine may be configured to look for xlayer files in a particular location each time the virtual application is executed.

The xlayer file may be shared between users and used to supply virtual machine settings to multiple virtual applications. The xlayer file may include all virtual registry and virtual filesystem information associated with a particular software component e.g. a virtual runtime engine component allowing the component to be fully installed in the virtual runtime environment. The xlayer file may include all of the application data required to implement the virtual application when executed by the virtual runtime engine . The xlayer file may be implemented as a binary file. The data in the xlayer file may be organized in one or more virtual layers substantially similar to the virtual layers of the configuration data block described above.

As is apparent to those of ordinary skill in the art the number of files and registry keys needed to implement a virtual application such as the virtual application and or a component encoded in the xlayer file can be very large. For example it is not uncommon for the number of files and registry keys needed to implement a virtual application to total in the tens of thousands. Therefore the performance characteristics of the configuration data block and the xlayer file can affect the performance of the virtual application significantly. In other words the performance characteristics of the configuration data block and or the xlayer file can increase or decrease the startup time for the virtual application .

Further the size of the xlayer file may affect an amount of time required to access data stored by the xlayer file which may affect the performance of the virtual application . The size of the xlayer file also affects an amount of time required to download or otherwise communicate the xlayer file between computing devices e.g. the computing devices and illustrated in and across a network e.g. the network illustrated in .

As is apparent to those of ordinary skill in the art the configuration data block and the xlayer file store similar data and therefore can be formatted in accordance with a common format. U.S. patent application Ser. No. 12 697 029 filed on Mar. 31 2010 entitled Method and System for Improving Startup Performance and Interoperability of a Virtual Application which is incorporated herein by reference in its entirety describes a file format that may be used to configure the configuration data block portion of the executable virtualized application file and or the xlayer file .

Referring to as mentioned above the size of the xlayer file may affect the amount of time required to access data stored by the xlayer file which may affect the performance of the virtual application . The size of the xlayer file also affects an amount of time required to download or otherwise communicate the xlayer file between computing devices e.g. from the server computing device to the client computing device illustrated in and across a network e.g. the network illustrated in .

Applications often store large amounts of data in a single file stored on a hard disk. For example the virtual application may be executed using one or more xlayer files e.g. the xlayer file . Unlike streaming media where a file is used in a linear fashion some applications e.g. the virtual application require random access to chunks of data referred to herein as pages. Thus the pages required by the end user or the application are retrieved from a file in a non sequential fashion. In other words the pages are accessed in non predetermined sequences that may include some randomness and may be difficult to predict. Depending upon the implementation details pages may have a predetermined size e.g. 4 kilobytes 10 kilobytes etc. . Alternatively pages may have non uniform sizes.

If during execution an application suddenly requires access to a page that has not yet been downloaded a delay must be introduced to download the page. Alternatively execution of the application may end. To avoid this problem when the xlayer file is hosted on a web server e.g. a web server implemented by the web server components of the server computing device illustrated in the user may download the entire xlayer file to the client computing device illustrated in before the virtual application can be executed on the client computing device illustrated in . The delay introduced by the download process greatly impacts the user experience. However delays may be avoided by preemptively downloading pages before they are needed but as mentioned above preemptive downloading is difficult because which pages will be accessed by the application and when may be difficult to predict. Thus it is desirable to download the pages in an order that is consistent with an order in which the application when operated by a user will request access to the pages.

If there is a predictable pattern in the order in which the pages are requested by the application the pages can be ordered and encoded into files that model this pattern. In this manner the most commonly accessed pages or page sequences may be downloaded first. This improves access time and transmission efficiency. Depending upon the implementation details this ordering and encoding allows the pages to be distributed using standard Hypertext Transfer Protocol HTTP which is a conventional download technology and does not require the use of specialized streaming protocols. By way of additional non limiting examples the pages to be distributed using other conventional download protocols including File Transfer Protocol FTP Server Message Block Protocol SMB and the like.

For example pages stored in a large single xlayer file e.g. the xlayer file can be reordered and divided into a plurality of smaller files referred to herein as xsequence files encoded using a predetermined file format referred to herein as xsequence file format which is described in detail below . The xsequence file format is configured to store permutations of at least a portion of the pages stored in a larger file e.g. the xlayer file and enables streaming distribution of the larger xlayer file. As mentioned above the smaller xsequence files may be streamed over the Internet using conventional download methods thereby transferring the data of the xlayer file between different computing devices. Thus the virtual application may be launched by the client computing device from the web without first downloading the entire xlayer file . This may greatly decrease startup latency. The remaining portions of the xlayer file may be downloaded subsequently while the user interacts with the executing virtual application .

For ease of illustration the file from which one or more xsequence files are created will be referred to as an original file. While the original file may be an xlayer file e.g. the xlayer file having one or more of the file format s described in U.S. patent application Ser. No. 12 697 029 it is apparent to those of ordinary skill in the art that the original file may have a format other than the file format s described in U.S. patent application Ser. No. 12 697 029. For example the original file may be an alternate encoding of a virtual machine or virtual application a data file an xml file and the like. For ease of illustration the original file is described below as implementing the virtual application . However as is apparent to those of ordinary skill in the art the original file may implement other applications including applications requiring installation on the client computing device see .

Profiling generally refers to a method of analyzing an application e.g. the virtual application to determine usage statistics. A profile or transcript of the application contains information about a single execution of the application such as the order of the page access and the time spent in each transition between pages. The transcript may be stored in a transcript file see . Multiple transcript files may be combined or merged to generate a streaming model illustrated in and described below .

An application e.g. the virtual application may implement one or more processes that are selectively executed as the application executes. As the virtual application executes it implements one or more such processes that each access the original file e.g. the xlayer file to obtain information about the virtual application . This information includes but is not limited to virtual environment settings virtual filesystem information virtual registry information and the like. This information resides in various locations within the original file e.g. the xlayer file . Threads and processes spawned by the virtual application as it executes may be treated as separate instances and merged together in the same transcript file in a manner similar to that used to merge multiple transcript files together discussed below .

A profiling process described below may be used to determine an order in which blocks of data pages stored in a file are accessed by an executing application. For ease of illustration the profiling process will be described as being performed with the virtual application . However as is apparent to those of ordinary skill in the art the profiling process may be performed with other types of applications including applications requiring installation on the client computing device see .

The profiling process profiles usage of the virtual application to generate transcript files such as the transcript file illustrated in that are used to generate a streaming model e.g. the streaming model illustrated in that specifies an order in which pages are downloaded from the server computing device to the client computing device . While the xlayer file may be thought of as generally opaque data is written sequentially within the xlayer file . Furthermore virtual files within a specific virtual directory are generally written sequentially one after the other. The same can be said for virtual registry keys and values. Therefore profiling access to the xlayer file is substantially similar to profiling access to the underlying files and registry entries of a natively installed application.

As mentioned above the Sandbox Manager see may execute the virtual application inside the virtual runtime engine . As will be explained below the Sandbox Manager may implement a directing process see configured to collect profile information that may be used to profile the virtual application s access to the underlying original file e.g. the xlayer file . Such profile information may be used to perform statistical analysis of a software application e.g. the virtual application to create a model of its data consumption. The profile information may also be used to make runtime adjustments in real time to the data delivery schedule described in the Modeling Subsection below . The data delivery schedule being the order in which data or pages are organized in the xsequence files and or the order in which the xsequence files are delivered to the client computing device .

The information stored in the transcript files generated by the profiling process is then used to divide the original file into pages that are loaded onto the server computing device for download to the client computing device . The server computing device streams the xsequence files to the client computing device through the Client Application and the Sandbox Manager that together download and execute the pages.

The profiling process described herein may be used to perform accurate and low overhead profiling of a virtual application s access to an underlying xlayer file. Depending upon the implementation details the profiling process may include the use of per thread data structures and named pipes to communicate to the directing process that by the executing virtual application has requested access to raw block level data stored in the original file e.g. the xlayer file . The term per thread data structure refers to a data structure corresponding to a single thread. Thus a separate per thread data structure may be created for each thread used by an application e.g. the virtual application . A ThreadDiscriminate value is sent to the Sandbox Manager by the virtual runtime engine when a thread is created. The ThreadDiscriminate value is an entry point discriminator for the thread accessing the xlayer file. An example method of generating the ThreadDiscriminate value is described below.

The profiling process is performed using a PseudoPid value and a PseudoTid value. The PseudoPid value and the PseudoTid value are determined by the virtual runtime engine .

The PseudoPid value is a unique process identifier of the application process accessing the original file e.g. the xlayer file . Because operating system allocated process identifiers Pid values can be recycled and reused a unique identifier the PseudoPid value is generated for each process. The PseudoPid value may be generated by performing a hash function using the operating system allocated Pid value and the current system time as input parameters. For example the following pseudo code may be used to generate the PseudoPid value 

The hash function performed may be a 32 bit good hash function. Those of ordinary skill in the art are familiar with good hash functions. Therefore such functions will not be described herein.

Furthermore because operating system allocated thread identifiers Tid values can be recycled and reused a unique identifier the PseudoTid value is generated for each thread. The PseudoTid value may be generated by performing a hash function using the operating system allocated Tid value and the current system time as input parameters. For example the following pseudo code may be used to generate the PseudoTid value 

Thus there may be three different scopes for the profiling process Session Process and Thread. Session scope includes the profiling context of a single execution of the virtual application . As is apparent to those of ordinary skill in the art during execution the virtual application may include multiple processes and multiple threads.

Process scope refers to the lifetime of a single process instance given a unique PseudoPid value described below within a session. If two or more virtualized application files are launched more than once a separate process for each launched file each having a different PseudoPid value and a separate process contexts for each launched file are created or recorded within a transcript. If the same virtualized application file is launched more than once execution statistics recorded for each process can be aggregated using the name of the virtualized application file or other identifier to identify execution statistics associated with the same virtualized application file.

Thread scope refers to the lifetime of a single thread instance given a unique PseudoTid value described below within a process and therefore session . Different threads may be identified in the transcript using the ThreadDiscriminate value described below . If a thread with the same ThreadDiscriminate value is launched more than once execution statistics recorded for the thread having that ThreadDiscriminate value can be aggregated using the ThreadDiscriminate value or other identifier to identify execution statistics associated with the same thread or similar threads. As is apparent to those of ordinary skill in the art because the ThreadDiscriminate value stores an identifier e.g. a file name of an entry point module e.g. a Dynamic Link Library dll file an executable file and the like and a relative offset within the module whereat execution of the thread began different threads may have the same ThreadDiscriminate value.

Each time the virtual application accesses the original file access information including one or more execution statistics is recorded. For example each time the virtual application accesses the original file e.g. the xlayer file the Sandbox Manager may record a PseudoTid value an xlayerId value an AccessOffset value an AccessBytes value a TickCount value and flags. This access is associated with the PseudoPid value of the process that created the thread.

The xlayerId value is an identifier of the xlayer file . The xlayerId value may be a hash e.g. a good hash of the path of the xlayer file . The AccessOffset value is an offset in bytes of the portion of the xlayer file accessed. The AccessBytes value is a size in bytes of the portion of the xlayer file accessed. The TickCount value is a current Operating System OS tick count at the time the xlayer file is accessed. The flags may include a Blocked value implemented as Boolean field. The Blocked value indicates whether the virtual runtime engine and or the virtual application is are blocked from further execution of the page for which access is requested.

During performance of the profiling process data is recorded for each process over its lifetime. Thus each process is tracked over the duration of its lifetime. Optionally shutdown notifications may not be tracked.

During performance of the profiling process data is recorded for each thread over its lifetime. Thus each thread is tracked over the duration of its lifetime. Optionally thread shutdown notifications may not be tracked.

When the profiling process is performed it may be useful to aggregate statistics collected for the same application code path. A thread discriminate the ThreadDiscriminate value is used to identify a code path by its starting point. The ThreadDiscriminate value may be obtained by performing a hash function using the name of the entry point module e.g. a file name and the entry point relative offset within the module as input parameters. Optionally the name of the entry point module may include the file path. The hash function performed may be a 32 bit good hash function. For example if the entry point for the thread was in a file named myapplogic.dll and at an offset of 0x10025 the hash function is performed on the bytes of the string myapplogic.dll using the offset 0x10025 as a seed value. The ThreadDiscriminate value for any xlayer access from this thread is set to the resulting value generated by the hash function. For example the following pseudo code may be used to generate the ThreadDiscriminate value 

The ThreadDiscriminate value may be stored in a per thread data structure. The following is a non limiting example of such a structure 

By way of a non limiting example the ThreadDiscriminate value may be stored in a per thread data structure e.g. the structure CVmTlsData using dynamic thread local storage mechanisms via Win32 TlsGetValue and TlsSetValue APIs. As is apparent to those of ordinary skill in the art thread local storage mechanisms refer to storing data in a thread local storage location that is accessible only by a thread associated with the thread local storage location. The ThreadDiscriminate value and or the PseudoTid value for a particular thread may be stored in the thread local storage location associated with the particular thread. The thread may look up the ThreadDiscriminate value and or the PseudoTid stored in the thread local storage location and provide such information to the virtual runtime engine which may in turn communicate the information to the directing process .

The structure may be initialized at thread creation time. By way of a non limiting example hooking the CreateThread system call may be used to initialize the structure at thread creation time. In other words an instance of the structure CVmTlsData may be created in response to each detection of the CreateThread system call by the hook on the CreateThread system call. Hooking the CreateThread system call is a technique known to those of ordinary skill in the art and will not be described in detail.

When an application thread is created a PseudoTid value and ThreadDiscriminate value are determined as described above. Then memory for the structure CVmTlsData is allocated and the structure CVmTlsData is saved in thread local storage. By way of a non limiting example the structure may be saved in thread local storage via the Win32 TlsSetValue API. By way of another non limiting example the following pseudo code may be used to create a per thread data structure which in this example is the structure CVmTlsData. 

After the PseudoTid value and the ThreadDiscriminate value are stored in the per thread data structure e.g. the structure CVmTlsData each access to the original file e.g. the xlayer file during execution of the virtual application is recorded by the Sandbox Manager in a transcript file see . By way of a non limiting example the transcript file may have a simple binary format and may use the extension xt. The transcript file may include a header followed by a series of tuples that each include a thread identifier e.g. the PseudoTid value a timestamp value and a block identifier or number. Optionally the transcript file may also store the PseudoPid value. In the transcript file the tuples may be organized by process or PseudoPid value in a hierarchical structure.

Named pipe communication may be used to provide communication between the virtual runtime engine and the directing process implemented by the Sandbox Manager . Thus the directing process may listen to the virtual runtime engine over at least one named pipe connection illustrated in . Those of ordinary skill in the art are familiar with the use of named pipes as a means of implementing communication between processes. Therefore named pipes will not be described in further detail.

In first block the virtual runtime engine receives an instruction from the Sandbox Manager to execute the virtual application in profiling mode. As will be described in more detail below the virtual runtime engine may also receive information e.g. the SessionId value and the path to the xlayer file from the Sandbox Manager .

Then in block the virtual runtime engine begins execution of the virtual application in profiling mode.

In block the virtual runtime engine connects to the named pipe of the Sandbox Manager to form the named pipe connection .

In block the virtual runtime engine constructs a message containing the SessionId value received from the Sandbox Manager in block and optionally other information e.g. the Pid value the PseudoPid value a ProcessName value and a Process Name Length value . This message signals the start of a new process. The virtual application is associated with a process that may launch one or more additional processes. Thus the first message received by the Sandbox Manager signals the start of the virtual application . The Pid value in the first message is associated with the virtual application itself. By way of a non limiting example the Pid value may be obtained using a function named GetCurrentProcessId As mentioned above the PseudoPid value may be obtained using a hash function. By way of a non limiting example the ProcessName value may be obtained using a function named GetStartupExecutableName The ProcessName value is a file name of the entry point executable file of the process. For example the ProcessName value may be the filename of the original file e.g. the xlayer file . However this is not always the case. The ProcessName value may not be the filename of the original file e.g. the xlayer file . The ProcessName Value may be used to merge statistics across processes having the same name.

The following structure named SProcessConnectMessage may be used to construct the message containing the new process information.

In the above pseudo code the Name variable stores the ProcessName value. The message constructed in block may inform listeners e.g. the directing process that a new process is starting. The message may be sent by the virtual runtime engine to the Sandbox Manager once for each PseudoPid value.

Then in block the virtual runtime engine sends the message constructed in block to the directing process implemented by the Sandbox Manager . At this point communication between the Sandbox Manager and the virtual runtime engine has been properly initialized and messages including statistics may be sent from the virtual runtime engine to the Sandbox Manager for recordation in a transcript file.

In next block all read operations e.g. IStream Read operations performed by the virtual application with respect to the original file e.g. the xlayer file are monitored. This may be achieved by abstracting access to the original file through the standard IStream interface which is used to read data from the original file. The IStream interface is configured to read from and write data to stream objects. Those of ordinary skill in the art are familiar with reading data from a file such as the xlayer file and this process will not be described in detail.

In decision block the virtual runtime engine determines whether a read operation is being performed on the original file e.g. the xlayer file or execution of the virtual application has terminated. The decision in decision block is ACCESS when a read operation has been detected by the virtual runtime engine . The decision in decision block is TERMINATED when the virtual runtime engine detects execution of the virtual application has terminated.

A method of detecting when execution of the virtual application has terminated is described below. When the decision in decision block is TERMINATED the method terminates.

When the decision in decision block is ACCESS in decision block the virtual runtime engine determines whether this is the first time the thread associated with the PseudoTid has accessed the xlayer file. The data stored in the per thread data structures e.g. the structures CVmTlsData described above may be used to determine whether this is the first time the thread associated with the PseudoTid value has accessed the original file. The decision in decision block is YES when this is the first time the thread associated with the PseudoTid value has accessed the xlayer file. Otherwise the decision in decision block is NO when this is not the first time the thread associated with the PseudoTid value has accessed the xlayer file.

When the decision in decision block is YES in block the virtual runtime engine stores the new thread information e.g. the PseudoTid value and the ThreadDiscriminate value . In block both of the PseudoTid value and the ThreadDiscriminate value may be stored in the per thread data structure e.g. the structure CVmTlsData . By way of a non limiting example these values may be obtained via the Win32 TlsGetValue API.

Then in block the virtual runtime engine constructs a message containing the new thread information e.g. the PseudoTid value and the ThreadDiscriminate value . The message constructed in block is sent by the virtual runtime engine to the Sandbox Manager once for each PseudoTid value. The following structure named SThreadStartedMessage may be used to construct the message containing the new thread information.

The variable named Discriminate in the above pseudo code stores a ThreadDiscriminate value that is sent when a new thread is created. The ThreadDiscriminate value is an entry point discriminator for the thread accessing the original file e.g. the xlayer file .

In block the virtual runtime engine sends the message constructed in block to the Sandbox Manager . Then the virtual runtime engine advances to block .

In block an offset value indicating where in the original file the read operation started and a length value indicating an amount of the original file read are recorded. The offset may be implemented as a 64 bit value. The PseudoTid value is also recorded. Further the current process tick count is recorded as the TickCount value.

In next block a message including the information recorded above e.g. the PseudoTid value the xlayerId value the AccessOffset value the AccessBytes value the TickCount value and flags is constructed. The message also includes an xlayerId value that is an identifier of the original file e.g. the xlayer file . By way of a non limiting example the message may be implemented using the following data structure named SFeedbackStatsMessage 

In summary the Sandbox Manager sends the SessionId value and the path of the original file to the virtual runtime engine . The xlayerId value may be determined by performing a hash function e.g. a good hash function on the path. When a new process accesses the original file the virtual runtime engine sends the SessionId value the Pid value the PseduoPid value the ProcessName value and the Process Name Length value to the Sandbox Manager . The Sandbox Manager may use this information to associate processes with the session identified by the SessionId value. Because two different sessions launched under the directing process see may use the same xlayerId value the Session Id value is send to the Sandbox Manager to inform the Sandbox Manager as to which child session sent the information to the directing process see .

When a new thread accesses the original file the virtual runtime engine sends the PseudoTid value and the ThreadDiscriminate value to the Sandbox Manager . For each read operation performed by the virtual application on the original file the virtual runtime engine sends the PseudoTid value the xlayerId value the AccessOffset value the AccessBytes value the TickCount value and flags to the Sandbox Manager . The Sandbox Manager may use this information to associate each read operation with the original file identified by the xlayerId value and the thread identified by the PseudoTid value. The xlayerId value is used because a single session may include the execution of one or more application file in addition to the original file.

Then in block the virtual runtime engine sends the message SFeedbackStatsMessage to the directing process . Then the virtual runtime engine returns to block .

The following pseudo code provides a non limiting example of an implementation of the blocks and of the profiling process described above.

If the virtual application initiates a child process the virtual runtime engine will perform block using the same SessionId received in block . The named pipe connection created in block is used for child processes.

It may be beneficial if the profiling process has as little affect on the running application as possible. In such implementations communication mechanisms may be very fast and invisible to the running application itself. Using the named pipe of the Sandbox Manager to provide communication between the virtual runtime engine and the directing process may provide such benefits. Thus the messages sent in blocks and may be sent over the named pipe connection s .

On the WINDOWS platform named pipes are implemented with multiple instance support. Thus multiple clients e.g. virtual runtime engines can communicate with a single named pipe server implemented by the Sandbox Manager with each client having an isolated connection to the same named pipe. In other words each process even processes started by the process associated with the virtual application will connect separately to the named pipe server. On the named pipe server implemented by the Sandbox Manager multiple connections are handled via a unique connection handle for each client e.g. virtual runtime engine . Thus each virtual runtime engine running a virtual application can connect to the name pipe of the same Sandbox Manager and send statistics to the single Sandbox Manager.

One named pipe connection per process may be used. In such implementations access to the named pipe from multiple threads may be serialized within a process via a critical section. This may impact performance of the virtual application slightly. However the size of the data being sent is small and named pipe communication is inherently fast. Thus this method may provide satisfactory performance.

In first block the Sandbox Manager obtains information e.g. command line parameters to send to the virtual runtime engine along with a command to execute the virtual application in profiling mode. By way of a non limiting example the SessionId may have been obtained via a XExecutionSession command line parameter.

In block the Sandbox Manager sends the information and a command to execute the virtual application in profiling mode to the virtual runtime engine . The virtual runtime engine knows it was started by a parent process the directing process of the Sandbox Manager . With that information the virtual runtime engine initiates the named pipe communication with the Sandbox Manager to send messages including those with execution statistics to the directing process .

The execute command and the Session Id value are received by the virtual runtime engine in block of the profiling process illustrated in and described above.

As discussed above while the virtual application is executing in profiling mode the Sandbox Manager may receive messages from the virtual runtime engine and generate events in response to those messages.

In decision block the Sandbox Manager determines whether it has received a message from the virtual runtime engine or execution of the virtual application has terminated. If a message is received the decision in decision block is RECEIVED and the Sandbox Manager advances to decision block . Otherwise if the virtual runtime engine stops executing the virtual application before a message is received the decision in decision block is TERMINATED and the method terminates.

When the virtual runtime engine detects that a process is accessing the original file e.g. the xlayer file for the first time the virtual runtime engine sends a message optionally implemented using a structure name SProcessConnectMessage to the directing process . In decision block the Sandbox Manager determines whether the message received in block indicates a process is accessing the original file e.g. the xlayer file for the first time. The decision in decision block is YES when the message received in block indicates a process is accessing the original file e.g. the xlayer file for the first time. For example the decision in decision block is YES when the message received was constructed in block of the profiling process illustrated in . Otherwise the decision in decision block is NO when the message received in block does not indicate the process is accessing the original file e.g. the xlayer file for the first time.

When the decision in decision block is YES in block the Sandbox Manager generates a ProcessStarted event. In block Sandbox Manager records information included in the message e.g. the SessionId PseudoPid and ProcessName values . This information may be recorded in the transcript file see . Then the Sandbox Manager advances to decision block .

When the decision in decision block is NO in decision block the Sandbox Manager determines whether the message received in block includes statistics to be stored in the transcript file see . The decision in decision block is YES when the message received in block indicates the message received in block includes statistics to be stored in the transcript file . For example the decision in decision block is YES when the message received was constructed in block of the profiling process illustrated in . Otherwise the decision in decision block is NO when the message received in block does not indicate that the message received in block includes statistics to be stored in the transcript file .

When the decision in decision block is YES in block the Sandbox Manager generates an ExecutionStatistic event. Then in block the statistics included in the message are stored in the transcript file . Then the Sandbox Manager advances to decision block .

When the decision in decision block is NO in decision block the Sandbox Manager determines whether the message received in block indicates a thread is accessing the original file e.g. the xlayer file for the first time. The decision in decision block is YES when the message received in block indicates a thread is accessing the original file for the first time. Otherwise the decision in decision block is NO. 

When the decision in decision block is YES in block the Sandbox Manager generates a ThreadStarted event. Then in block the PseudoTid and ThreadDiscriminate values are stored in memory. This information may be recorded in the transcript file see . Then the Sandbox Manager advances to decision block .

In decision block the Sandbox Manager determines whether the virtual runtime engine has stopped executing the virtual application and therefore no additional statistics will be generated for the virtual application . The decision in decision block is NO when the virtual runtime engine has stopped executing the virtual application . Otherwise the decision in decision block is YES. 

The information received in the messages constructed in block of the profiling process illustrated in is stored in the transcript file associated with the original file e.g. the xlayer file .

The Sandbox Manager may include a dictionary accessible by the directing process . The directing process may use the dictionary to associate all subsequent messages e.g. implemented using the structures named SThreadStartedMessage and SFeedbackStatsMessage with the correct PseudoPid value. The dictionary may be keyed by a connection handle to a structure storing the PseudoPid value Pid value and Process Name value. The following data structure named SPipeConnection is an example of a data structure that may be used to implement the dictionary 

As described above the information stored in the class defined by the pseudo code above is received by the Sandbox Manager from the virtual runtime engine in the message constructed in block of the profiling process illustrated in .

The dictionary lookup may be hidden by the implementation of the .NET System.IO.Pipes.NamedPipeServerStream class which may have been used to perform the named pipe communication. This class uses IO Completion Ports to schedule asynchronous pipe reads from the pipe clients e.g. the virtual runtime engine in the virtual application processes. An asynchronous named pipe completion routine may be responsible for determining the type of message received reading the message and calling back into the listening code of the directing process with the appropriate callbacks. Possible callbacks are SignalNewProcess which is called when a new process is started in the virtual application SignalNewThread which is called when a new thread is started within a virtual application process and SignalXLayerAccess which is called when access to the original file has been requested by a particular thread within the virtual application process . How this data provided by these callbacks is handled is described below.

The following pseudo code provides a non limiting example of a server side named pipe completion routine. Portions of the routine may be performed in blocks and .

As mentioned above the transcript file generated by the profiling process is used to determine a predictive application access model that is used to determine an order in which to download blocks of data e.g. portions of the xlayer file to the client computing device . When used to stream blocks of data or pages to the client computing device the access model is referred to as a streaming model.

The server computing device provides applications to the client computing device on a self serve basis i.e. a user operating the client computing device may select any of the applications provided by the server computing device for download at anytime . After the user has selected an application for download and execution the server computing device downloads or streams the selected application to the client computing device . Multiple client computing devices e.g. the computing devices and may select applications for download at the same time.

Because training and building streaming models is a computationally intensive process and relies on proprietary technologies it may be preferable to perform this process on a centralized server e.g. the server computing device or another computing device connected thereto . The access model may be generated using machine learning techniques that require training. The training of streaming models requires information about the program s access patterns under realistic and or actual use. Thus generating transcripts via profiling is a task best performed manually by an application publisher or test users.

As described above the Sandbox Manager may be configured to profile an application downloaded from a web page e.g. via the plug in . Transcript files generated by the Sandbox Manager may then be uploaded to the server computing device or another computing device connected thereto which automatically generates and distributes a streaming model e.g. the streaming model illustrated in for the application.

As mentioned above the authoring tool allows application developers and publishers to virtualize an application and publish it to the web. The result of this process is one or more executable files or xlayer files e.g. a file named application p.xlayer residing on the server computing device . As described in U.S. patent application Ser. No. 12 695 107 these files can be downloaded and executed from the web via the plug in and the Sandbox Manager . If the plug in is executing on a computing device e.g. the computing device that is also executing the authoring tool optionally when the layer file is published to the server computing device the xlayer file will also be copied to the local cache see making future downloads unnecessary.

An upper portion of illustrates exemplary communications between the computing device operated by an application publisher or developer the server computing device and the model building server . A lower portion of illustrates exemplary communications between the client computing device operated by a user and the server computing device . In the authoring tool the profiling tool and the Sandbox Manager are installed and operating on the computing device . Another instance of the Sandbox Manager and the Client Application are installed and operating on the client computing device . For ease of illustration the computing device operated by an application publisher will be described as being the computing device . However this is not a requirement.

Returning to in first block the server computing device receives an instruction from an application publisher or developer that a particular application is to be profiled. Arrow A in illustrates a communication from the computing device to the server computing device requesting profiling for an application. The authoring tool may be configured to allow an application publisher or developer to specify that after an application is downloaded the Sandbox Manager is to profile the application and upload transcript files generated by the profiling process illustrated in to the server computing device . For example the authoring tool may have a link to an online management panel configured to display a profiling tool see operable by a user to indicate a particular application is to be profiled following its download. Using the online management panel the user selects a virtual application e.g. by selecting an xlayer file implementing the virtual application . For example the publisher or developer may select a virtual application implemented by an xlayer file named app.xlayer. If an application has been identified as to be profiled streaming is not enabled. Instead to run the application from the web the entire application file e.g. the xlayer file named application p.xlayer must be downloaded before execution can begin. Thus arrow A in illustrates a communication downloading the xlayer file from the server computing device to the computing device .

The profiling tool may be implemented as a Profile link in the online management panel. When the publisher clicks on the Profile link a panel launcher page may be displayed that includes a query string parameter e.g. profile set to a value that indicates the application should be profiled. The page may pass the query string parameter e.g. profile to an iframe that renders the panel launcher page. The panel launcher page renders a javascript call to the xrfw.go method that sets the query string parameter e.g. profile equal to TRUE. 

In block the server computing device receives an instruction to download the virtual application to the client computing device . For example this instruction may be received in response to a user clicking on a launch button on the panel launcher page.

In block the Sandbox Manager downloads and executes the virtual application file in a profile mode. When executing an application in profile mode the Sandbox Manager instructs the virtual machine e.g. the virtual runtime engine to provide execution statistics e.g. via messages implemented using the structure named SFeedbackStatsMessage .

In block the Sandbox Manager receives messages from the virtual runtime engine and handles events generated by the virtual runtime engine executing the application as the application is running. The method described above may be performed in blocks and .

By way of non limiting examples the events may include a ProcessStarted event a ThreadStarted event an ExecutionStatistic event and an ApplicationEnded event. A ProcessStarted event may be identified by the Sandbox Manager when the directing process receives a message from the virtual runtime engine indicating a process has requested access to the xlayer file for the first time. As explained above such a message may be sent by the virtual runtime engine in block of the profiling process illustrated in and implemented using the structure named

 SProcessConnectMessage. A ThreadStarted event may be identified by the Sandbox Manager when the directing process receives a message indicating a thread has requested access to the xlayer file for the first time. As explained above such a message may be sent by the virtual runtime engine in block of the profiling process illustrated in and implemented using the structure named SThreadStartedMessage. The ProcessStarted and ThreadStarted events allow the Sandbox Manager to separately track access requests from different processes and threads.

An ExecutionStatistic event may be identified by the Sandbox Manager when the directing process receives a message including access statistics. As explained above such a message may be sent by the virtual runtime engine in block of the profiling process illustrated in and implemented using the structure named SFeedbackStatsMessage. Every time the virtual application finishes reading a contiguous section of an xlayer file the virtual runtime engine triggers an ExecutionStatistic event and sends a message including access statistics to the directing process. The message which may be implemented using the structure named SFeedbackStatsMessage may include an identifier for the xlayer file e.g. the xlayerId value the thread e.g. the PseudoTid value time e.g. the TickCount value timestamp and the like the location of the block in the xlayer file e.g. the AccessOffset value and the size of the block read e.g. the AccessBytes value . The TickCount value may be used to track the runtime of a process. An identifier for the process e.g. the PseudoPid value may be inferred from the named pipe connection used because the named pipe connection used by each process is unique.

Then in block the Sandbox Manager combines the collected execution statistics into a single combined transcript e.g. the combined transcript CT illustrated in .

In block the Sandbox Manager uploads the combined transcript to the server computing device . Arrow A in illustrates a communication from the computing device to the server computing device uploading the combined transcript. In block the Sandbox Manager may connect to a web service running on the server computing device and transfer a unique application identifier and a byte array containing the binary data of combined transcript to the server computing device . By way of a non limiting example the application identifier may have the following format    p.xlayer.

In block the server computing device receives the uploaded combined transcript and associated application identifier.

In block the server computing device resolves the application identifier to determine which application and version created the transcript. The server computing device includes an application library database illustrated in . In block the application library database may be queried for an application that has a matching version and xlayer revision. If an xlayer file is found the transcript will be associated with this xlayer file.

In block the server computing device saves the combined transcript in a predetermined location on the filesystem. In block the binary data contained in the transcript may be written to a file on the server computing device using a standard .NET BinaryWriter. Each transcript is named using a unique GUID. Files containing the transcripts may be stored at the following location relative to the web root Layers Transcripts  p.xlayer .xt.

In block the server computing device requests a build of a new streaming model for the xlayer file identified in block . Arrow A in illustrates a communication from the server computing device to the model building server requesting a build of a new streaming model for the xlayer file identified in block . If a streaming model has not been created for a particular xlayer file in block the server computing device may automatically add a request for a streaming model to a streaming model build queue. By way of a non limiting example the streaming model build queue may be implemented as a ModelRequest table illustrated in . In implementations including multiple model build servers the ModelRequest table may be stored in a database accessible by all model build servers.

Application publishers can use the profiling tool to request subsequent model builds as needed e.g. by adding a request to the ModelRequest table illustrated in after additional profiling has been performed to generate additional transcripts. This may be achieved by adding a record to the ModelRequest table illustrated in .

In block the request is processed and a streaming model e.g. the streaming model illustrated in is generated for the xlayer file identified in block . The streaming model may be generated by the server computing device or another computing device connected thereto. In the embodiment illustrated in streaming models are generated by the model building server . By way of a non limiting example an application running as a windows service on the model building server may be responsible for building the streaming model based on the transcripts associated with the unique application identifier. The model building server may periodically query the ModelRequest table for any requests that have not yet been started. When one is found the model building server begins a build i.e. starts constructing a streaming model .

Then in block the model building server copies all transcript files associated with the xlayer file identified in block into the same directory in the filesystem of the model building server . For example all files stored in a first directory named LibraryResources Layers Transcripts    p.xlayer may be copied to a second directory named LibraryResources Layers Transcripts    p.xlayer . Arrow A in illustrates a communication from the server computing device to the model building server uploading the transcript files to the model building server .

When the copying is finished in block the model building server tries to delete the original transcript files stored in the first directory .

In decision block the model building server determines whether the transcript files have been successfully deleted. If the attempt to delete a particular transcript file fails the model building server concludes the transcript is still being written and the decision in decision block is NO. Then in block the copy stored in the second directory is deleted. These copy and delete actions may use the standard .NET File class.

In block the model building server then performs a method illustrated in to construct a streaming model based on the transcripts stored in the second directory. The collection of files including the transcripts stored in the second directory and the streaming model may be stored in a third directory named LibraryResources Layers   xstream 0 . 

In block referring to when the streaming model is saved the model building server creates a record in an XStreamModel table as well as corresponding entries in an XFile table and a ServerXFile table . Arrow A in illustrates a communication from the model building server to the server computing device recording information in the XStreamModel table the XFile table and the ServerXFile table . These tables may be stored in the same database used to store the ModelRequest table . This database may be accessible by each of the server computing devices and model building servers.

Referring to a streaming model e.g. the streaming model illustrated in includes a streaming model file and one or more xsequence files .

Returning to the records in the XFile table and ServerXFile table indicate the existence of a new streaming model and identify on which server s the streaming model is stored. The server table stores information about each of the server computing devices e.g. the server computing devices and . The XStreamModel table indicates a particular streaming model exists the XFile table stores data about the streaming model file and the ServerXFile table describes the streaming model file located on a particular server computing device. Arrow A in illustrates a communication from the model building server to the server computing device storing the streaming model file and associated one or more xsequence files on the server computing device . Optionally the model building server may store the streaming model file and associated one or more xsequence files on one or more other server computing devices. The streaming model which includes the streaming model file and associated one or more xsequence files may be stored in a predetermined storage location on the server computing device .

At this point the streaming models may be distributed to other computing devices connected to the model building server and or the network . is a flow diagram of a method of distributing streaming models. Server computing devices e.g. the server computing devices and may poll or query the ServerXFile table to locate files stored on other server computing devices. In first block a querying server computing device e.g. the server computing device polls or queries the ServerXFile table for streaming models stored on other server computing devices e.g. the server computing device . For example in block the server computing device may receive a list of streaming models identified in the ServerXFile table that are stored on all other server computing devices.

In decision block for each streaming model identified in block the querying server computing device determines whether the streaming model is already stored in the filesystem of the querying server computing device. The decision in decision block is NO when the streaming model is already stored in the filesystem of the querying server computing device. Otherwise the decision in decision block is YES when the streaming model is not already stored in the filesystem of the querying server computing device.

When the decision in decision block is YES in block the querying server computing device waits for a period of time and then returns to block . In block the querying server computing device may wait for a predetermined amount of time a randomly selected amount of time or a combination thereof.

When the decision in decision block is YES in block the streaming model is copied from a server computing device on which the streaming model is stored to the querying server computing device. Thus when a record is found in the ServerXFile table that the querying server computing device does not yet have stored in its filesystem according to the ServerXFile table a copy is initiated. In other words the querying server computing device e.g. the server computing device may use the ServerXFile table to locate model files stored on other server computing devices e.g. the server computing device and copy those files to the local filesystem of the querying server computing device. The files located in this manner may be copied from the third directory to a fourth directory named LibraryResources Layers   xstream 0 . In other words each server computing device is responsible for distributing streaming model files by copying those files onto their own filesystem.

In decision block for each streaming model copied in block the querying server computing device determines whether the streaming model was copied to the filesystem of the querying server computing device successfully. The decision in decision block is YES when the streaming model was copied to the filesystem of the querying server computing device successfully. Otherwise the decision in decision block is NO when the streaming model was not copied to the filesystem of the querying server computing device successfully.

When the decision in decision block is NO the querying server computing device may return to block to retry the copy operation.

When the decision in decision block is YES the copy operation has completed successfully in block the querying server computing device e.g. the server computing device adds a new record to the ServerXFile table indicating that the streaming model is now stored on that particular server computing device. Thus after a server computing device e.g. the server computing device copies streaming models onto its filesystem the server computing device records this in the database illustrated in . For example if a server computing device named publicserver1 copies a streaming model named Model1 into its filesystem the publicserver1 computing device creates a record in the ServerXFile table in which a field named Server is set to publicserver1. Then the method terminates.

In optional block the Client Application communicates that the user would like to execute a virtual application to the Sandbox Manager .

In block the Sandbox Manager executing on the client computing device which may be located somewhere across the world from the server computing device requests the virtual application the user indicated he she would like to execute in block .

In block the server computing device that services the request e.g. the server computing device will query the ServerXFile table to determine which server computing device s is are storing the streaming model for the application requested in block . For example in block the Sandbox Manager may request an application named App1.xlayer for which a streaming model named Model1 was created. In this example in block the server computing device may query the ServerXFile table to determine which server computing device s are storing the streaming model named Model1 associated with the application requested in block .

Then in block the server computing device that services the request e.g. the server computing device selects one of the server computing device s storing the streaming model requested in block from which to download the streaming model. Load balancing techniques or a random selection algorithm may be used to select a server computing device in block . For example in block load balancing techniques or a random selection algorithm may be used to select a server computing device e.g. the publicserver1 computing device from which the Model1 model file may be downloaded to the client computing device .

Then in block the method illustrated in is performed to download and execute the virtual application on the client computing device using the streaming model. Then the method terminates.

Among other data each transcript includes information identifying transitions between pages page transitions . To combine the transcripts in block the page transitions are broken down and combined. For example referring to if a first transcript T records a first sequence of page transactions PPPPP indicating a first order in which the pages P P P P and P were accessed by the application and a second transcript T records a second sequence of page transactions PPP PP indicating a second order in which the pages P P P P and P were accessed by the application the transcripts T and T are broken down into individual transitions PP PP PP PP for the first transcript T and PP PP PP PP for the second transcript T. In this example the first sequence in the first transcript T transitioned from page P to page P to page P to page P to page P and the second sequence in the second transcript T transitioned from page P to page P to page P to page P to page P. Because a transition from page P to page P is present in both transcripts T and T in block this transition PP is combined into a single transition and assigned a weight W indicating how many times the transition appears in the transcripts e.g. a weight equal to two in a combined transcript CT. Similarly because a transition from page P to page P is present in both transcripts T and T in block this transition PP is combined into a single transition and assigned a weight W indicating how many times the transition appears in the transcripts e.g. a weight equal to two in a combined transcript CT. The other transitions appear in only one transcript. Therefore in this example in block these transitions are each assigned a weight equal to one. Further a timestamp value may be stored for each page indicating a time at which the page was first accessed. After transitioning to page P the first and second transcripts T and T indicate the user may transition to either page P or page P. Thus the combined transitions include a branch B and no longer follow a linear path.

After the individual transcripts have been combined to form the combined transcript CT in block the combined transcript CT is used to create a directed graph structure SD. The directed graph structure SD includes states and transitions between states. The states are merely end points or nodes for the transitions. Each transition is associated with one or more pages. The directed graph structure SD illustrated in includes five states S to S and five transitions TRANS to TRANS .

In the directed graph structure SD linear sequences of transitions i.e. sequences of transitions without any branches in the combined transcript CT are reduced or simplified into a single transition. For example the linear sequence of transitions that includes the following transitions PPP is simplified into the single transition TRANS or SS that is associated with the pages P P and P. The weight of transition TRANS is the same as the weight of each of the transitions PPP . The transition TRANS or S S is associated with the pages P and P. The transition TRANS or SS is associated with the pages P and P. The transition TRANS or SS is associated with the pages P and P. The transition TRANS or SS is associated with the pages P and P.

When the states and transitions are created by combining the transitions in the combined transcript CT a timestamp delta valued is calculated for each page. The timestamp delta is the difference between the start time of the transcript e.g. a time at which execution of the virtual application began and the timestamp recorded for the page in the transcript. Then an average timestamp delta value is calculated for the pages associated with each of the transitions between states. This average is recorded for each transition between states as a TickDelta member.

The directed graph structure SD describes data access by the application while executing and may be stored in one or more state objects. Referring to each of the states e.g. the states S to S may be stored in a different state object . The state object may include a list of transitions associated with the state. For example the list of transitions for a state object corresponding to the state S would include only the transition TRANS . By way of another example the list of transitions for a state object corresponding to the state S would include the transitions TRANS and TRANS . The state object may include a degree member that indicates a number of transitions associated with the state object . For example the degree member of the state object corresponding to the state S would indicate only a single transition is associated with the state object e.g. degree 1 . By way of another example the degree member of the state object corresponding to the state S would indicate two transitions are associated with the state object e.g. degree 2 . The state object may include a weight member that stores a total of the weights assigned to the transitions. For example the weight member of the state object corresponding to the state S may be set to a weight of two. By way of another example the weight member of the state object corresponding to the state S may be set to a weight of two. The weight members of state objects corresponding to the states S and S may each be set to a weight of one.

Referring to each of the transitions may be stored in a transition data structure that has a weight member indicating how many times the transition occurs in the combined transcript. The transition data structure may include a page sequence member that stores the page identifiers of the pages included in the transition. For example the page sequence member of a transition data structure storing the transition TRANS would store identifiers for pages P P and P. The transition data structure may include a TickDelta member that stores an amount of time e.g. in nanoseconds that the transition required.

The directed graph structure SD stored by the one or more state objects may include loops or cycles. By way of a non limiting example the directed graph structure SD may be a directed acyclic graph DAG . However this is not a requirement. As mentioned above in the directed graph structure SD the transitions or edges are labeled with a set of pages or data blocks. Transition data structures that are too large may be divided into two or more separate transition data structures. For example transition data structures that have a large value stored in the TickDelta member or have a large number of pages stored in the page sequence member may be subdivided into two or more separate transition data structures.

In block the pages identified in the page sequence members of the transition data structures are encoded in one or more xsequence files. The xsequence files each belong to one of three categories initial execution xsequence files sequence xsequence files and rest xsequence files. For example the xsequence files of the streaming model illustrated in include a initial execution xsequence file a sequence xsequence file and a rest xsequence file .

As mentioned above the virtual application may be streamed from the server computing device without using a special streaming protocol by encoding the xlayer file into smaller xsequence files. In particular embodiments the virtual application may be streamed from the server computing device using well known download protocols such as HTTP FTP SMB and the like. Which category a particular page is encoded into is based upon the directed graph structure SD which predicts when the page may be used by a virtual application as it is executing as xsequence files are concurrently being downloaded.

In block the pages included in the initial execution xsequence file may be identified by determining how close in time which may be determined using the time stamp for the page each page is to an origin or first transition data structure listed in the list of transitions in a first state object in the directed graph structure SD. Then only the pages accessed within a predetermined amount of time from the first transition data structure may be selected for inclusion in the initial execution xsequence file s . Alternatively a predetermined number of pages accessed within a least amount of time from the first transition data structure may be selected for inclusion in the initial execution xsequence file s . By way of another non limiting example a predetermined percentage of pages including those that were accessed within the least amount of time from the first transition data structure may be selected for inclusion in the initial execution xsequence file s .

The following pseudo code provides a non limiting example of a method of encoding the pages in the initial execution xsequence file using the directed graph structure SD. 

In the pseudo code above the function named IsChildOf determines whether a second state stored in variable named 5 is reachable from the first state stored in a variable named OriginState . In other words the function named IsChildOf determines whether a path exists in the directed graph structure SD from the first state to the second state. In the state S is considered the first or origin state. If the second state is reachable from the first state and less than a threshold amount of time stored in a constant named BUFFERTIME THRESHOLD elapsed between the first and second states the second state is added to a list of initial execution states. Then while not included in the pseudo code above the pages associated with the transitions between the first and second states are written into the initial execution xsequence file.

In block the model building server writes the pages identified in block to the initial execution xsequence file s .

In block the model building server identifies pages for inclusion in the sequence xsequence files. For example in block the model building server may identify the pages identified in the page sequence members of the transition data structures that were not written to the initial execution xsequence file s in block .

In decision block the model building server decides whether to create a sequence xsequence file for each transition data structure that was not used to populate the initial execution xsequence file or to reduce the number of sequence xsequence files created by combining the transition data structures that were not used to populate the initial execution xsequence file. The decision in decision block is YES when the model building server decides to combine the transition data structures that were not used to populate the initial execution xsequence file. Otherwise the decision in decision block is NO when the model building server decides to create a sequence xsequence file for each transition data structure that was not used to populate the initial execution xsequence file.

When the decision in decision block is YES in block the model building server combines at least a portion of the transition data structures that were not used to populate the initial execution xsequence file. For example in block the model building server may combine similar transitions into a single transition to be stored in a single sequence xsequence file. By way of another example a threshold file size may be used to identify sequence xsequence files having a size less than the threshold file size. The sequence xsequence files identified may be combined into one or more larger sequence xsequence files. The following pseudo code provides a non limiting example of a method of combining transitions into a single transition for storage in a single sequence xsequence file.

Next in block the pages identified in block are stored in sequence xsequence files. As mentioned above a sequence xsequence file may be created for each transition data structure that was not used to populate the initial execution xsequence file and used to store the pages of the transition data structure for which the sequence xsequence file was created. Optionally the number of transition data structures that were not used to populate the initial execution xsequence file may be reduced by combining two or more of them before creating the sequence xsequence files.

The sequence xsequence files store the pages that were accessed by the application as it executed. Thus the sequence xsequence files store all of the pages appearing in all of the transcripts.

In block the model building server identifies pages for inclusion in the rest xsequence files. In block the model building server identifies pages that did not appear in every transcript for inclusion in the rest xsequence files. For example referring to one or more rest xsequence files would store the pages P and P. Further in block the model building server identifies pages that did not appear in any of the transcripts for inclusion in the rest xsequence files.

While a rest xsequence file may store one or more pages also stored in one of the sequence xsequence files this is not a requirement. Optionally in decision block the model building server may decide whether to search the sequence xsequence files for each page and only write pages not found in the sequence xsequence files to the rest xsequence file s . The decision in decision block is YES when the model building server decides to search the sequence xsequence files for each page. Otherwise the decision in decision block is NO when the model building server decides not to search the sequence xsequence files for each page.

When the decision in decision block is NO in block the model building server writes the pages identified in block to the rest xsequence file s . It may be beneficial to include all of the pages that did not appear in every transcript in the rest xsequence file s because as the directed graph structure SD is traversed particular transitions may not be visited.

When the decision in decision block is YES for each page in block the model building server searches the sequence xsequence files to determine whether the page has been written to one or more of the sequence xsequence files.

Then in decision block the model building server determines whether the page has been written to one or more of the sequence xsequence files. The decision in decision block is YES when the page has been written to one or more of the sequence xsequence files. Otherwise the decision in decision block is NO when the page has not been written to one or more of the sequence xsequence files.

When the decision in decision block is NO in block the model building server writes the page to a rest xsequence file. Then the model building server advances to decision block .

When the decision in decision block is YES the page may be omitted from the rest xsequence file and the model building server advances to decision block .

In decision block the model building server determines whether there are any pages for which the sequence xsequence files have not been searched. The decision in decision block is YES when the model building server has not searched the sequence xsequence files for all of the pages. Otherwise the decision in decision block is NO when the model building server has searched the sequence xsequence files for all of the pages.

The pages may be ordered within the rest xsequence files based on the frequencies at which the pages appeared in the transcripts. Rest xsequence files may be downloaded when the download pipeline that is downloading the xsequence files from the server computing device to the client computing device is idle.

The following pseudo code provides a non limiting example of a method of adding pages to the rest xsequence file.

Then in block the model building server creates the streaming model file see . The streaming model file stores information in the directed graph structure SD. By way of a non limiting example the model file may store a number of states in the directed graph structure SD a list of states in the directed graph structure SD a list of transitions for each state a weight associated with each transition and a list of pages associated with each transition. The Sandbox Manager may use this information to predict to which pages the virtual application will request access as the virtual application executes. Based on these predictions the Sandbox Manager may preemptively download pages before the pages are requested by the virtual application .

Referring to the following pseudo code provides a non limiting example of a method of creating the streaming model file and the xsequence files which in the following pseudo code include a single initial execution xsequence file one or more sequence xsequence files and one or more rest xsequence files. The following pseudo code uses data that was stored in data structures by pseudo code portions provided above.

In response to this request the server computing device streams the streaming model file and the initial execution xsequence file s e.g. the initial execution xsequence file to the Sandbox Manager and or the Client Application . Arrow A in illustrates a communication from the server computing device to the client computing device that streams streaming model file and the xsequence files which include the initial execution xsequence file from the server computing device to the client computing device .

In block the Sandbox Manager and or the Client Application receive the model file and the initial execution xsequence file s .

By way of a non limiting example the following code may be used in blocks and to pass a URL to the server computing device and download the model file and the initial execution xsequence files.

Then in block the Sandbox Manager launches the virtual application . Thus the virtual application begins executing even though less then all of the data stored in the xlayer file has been downloaded.

In decision block the Sandbox Manager determines whether it has received a notification from the virtual runtime engine that a page has been requested by the virtual application that has not yet been downloaded or whether there are additional xsequence files to be downloaded for the virtual application .

The decision in decision block is REQUEST when the Sandbox Manager determines it has received a notification from the virtual runtime engine that a page has been requested by the virtual application that has not yet been downloaded.

The decision in decision block is MORE TO DOWNLOAD when the Sandbox Manager determines there are additional xsequence files to be downloaded for the virtual application and the Sandbox Manager determines it has not received a notification from the virtual runtime engine that a page has been requested by the virtual application that has not yet been downloaded.

When the decision in decision block is REQUEST in block the directing process identifies the xsequence file storing the page for which access has been requested. The directing process may use the model file to look up which xsequence file is storing the page for which access has been requested. Optionally the directing process may pause execution of the virtual application .

In block the Sandbox Manager and or the Client Application download the xsequence file identified in block while the virtual application is in use. Then the Sandbox Manager and or the Client Application advance to decision block .

The Sandbox Manager and or the Client Application may download additional xsequence files even without receiving a notification from the virtual runtime engine indicating a page stored by the xsequence file has been requested. For example after the Sandbox Manager and or the Client Application have downloaded the model file and the initial execution xsequence file s the Sandbox Manager and or the Client Application may download the sequence xsequence files.

When the decision in decision block is MORE TO DOWNLOAD in decision block the Sandbox Manager determines whether one or more of the sequence xsequence files have yet to be downloaded. The decision in decision block is YES when one or more of the sequence xsequence files have yet to be downloaded. Otherwise the decision in decision block is NO when all of the sequence xsequence files have been downloaded.

When the decision in decision block is YES in block the Sandbox Manager and or the Client Application download one of the sequence xsequence files. The directing process may use the model file to determine which sequence xsequence file to download. Because the directing process knows which of the sequence xsequence file was the last one downloaded the directing process may use the model file to traverse the directed graph structure SD and locate the next sequence xsequence file to download. By way of a non limiting example the following pseudo code provides an exemplary download loop that may be used to download the sequence xsequence file referred to in the following pseudo code as blocks . The function named GetNextXferBlock reads the model file to identify the next sequence xsequence file to download.

The above download loop continues looping until all of the sequence xsequence files listed in the model file are written to the shared memory block . As mentioned above in the above pseudo code the order in which the sequence xsequence files are downloaded is determined by the function named GetNextXferBlock The following pseudo code provides an exemplary implementation of the function named GetNextXferBlock 

As discussed above the directed graph structure SD may include one or more branches. Therefore when the Sandbox Manager is traversing the directed graph structure SD using the model file and encounters a branch the Sandbox Manager must select one of the transitions of the branch. The Sandbox Manager may perform a weighted depth first traversal of the directed graph structure SD which reflects the order s in which the pages are most commonly accessed as determined by the profiling process and the modeling process. Alternatively other types of traversal such as a breadth first traversal may be used. The weight assigned to a transition to a particular sequence xsequence file which stores the pages of one or more transition data structures may be a percentage that the particular transition occurred out of all of the transitions recorded in the transcripts. illustrates an exemplary traversal of a streaming model containing the sequence xsequence files SXF to SXF. Each transition between two consecutively accessed sequence xsequence file is assigned a weight. For example the weight assigned to the transition between the sequence xsequence file SXF and SXF is 40 . In this example the sequence xsequence files are downloaded in the following order SXF SXF SXF SXF SXF and SXF.

Returning to the rest xsequence files are downloaded after the sequence xsequence files have been downloaded. Thus when the decision in decision block is NO in block the Sandbox Manager and or the Client Application download one or more rest xsequence files. The rest xsequence files are ordered by the frequency in which their pages were accessed during the profiling process . For example a rest file 0 r0.xs may contains pages that are most likely to be accessed and should be downloaded first. Then the Sandbox Manager and or the Client Application advances to decision block .

In decision block the Sandbox Manager determines whether all of the xsequence files have been downloaded. The decision in decision block is YES when all of the xsequence files have been downloaded. Otherwise the decision in decision block is NO when all of the xsequence files have not been downloaded.

When the decision in decision block is YES all of the rest xsequence files have been downloaded. Therefore the application download is complete and the method terminates.

The following pseudo code is a non limiting example of a method of downloading the rest xsequence files and determining when the download is complete.

U.S. patent application Ser. No. 12 695 107 which is incorporated herein by reference describes the Sandbox Manager which is a virtual process manager configured to download and execute a virtualized application file from a server computing device to a client computing device. Each of the streaming model file see the initial execution xsequence files the sequence xsequence files and the rest sequence files may be downloaded using well known conventional download protocols such as HTTP FTP SMB and the like. As discussed above the Sandbox Manager may be used to implement the directing process configured to direct the delivery and execution of the virtual application . The directing process may perform operations on behalf of the virtual application including but not limited to streaming application code and data profiling execution e.g. by performing the method illustrated in managing the sandbox performing shell integration and performing instance management. To support these operations in a cooperative fashion the directing process selectively starts pauses terminates and monitors the virtual application . By way of a non limiting example the directing process may start pause resume terminate the virtual application in response to a command or instruction from a user or another process or application separate from the Sandbox Manager and the virtual runtime engine . The directing process may also dynamically populate the underlying xlayer file during execution of the virtual application .

As mentioned above the directing process may send one or more special command line arguments to the virtual runtime engine . For example settings may be provided to the virtual runtime engine via the special command line arguments . An exemplary command line argument may include XExecutionSession . This SessionId value is used by the directing process and the virtual runtime engine to lookup the shared memory by name.

In the above format managerVersion is one of the special command line arguments like the SessionId value . By way of a non limiting example the SessionId value may be implemented as a 64 bit integer.

Status events are created and used by the directing process to signal changes in the state of the session to the virtual runtime engine . By way of a non limiting example the session may have the following states which may be assigned the exemplary values indicated 

The sentinel object which is a named kernel object is used to indicate the lifetime of the virtual application. For example a named mutex may be used. Once the sentinel object disappears which may be determined by polling in the directing process all processes of the virtual application have terminated. As is appreciated by those of ordinary skill in the art some operating systems such as Microsoft WINDOWS are configured to track or count references by other objects to named kernel objects. Thus when a WINDOWS process has a reference or handle to the sentinel object the host operating system A see will store an indication of this reference. For example the host operating system A may store a reference count indicating how many objects have references to the sentinel object . When the reference count is zero no processes have references to the sentinel object .

In addition to the above fixed sized shared memory structures used to manage execution of the virtual application optionally another named shared memory block containing handles to a shared mapping of the xlayer file e.g. the xlayer file itself may be used along with a shared memory based bit array structure to support dynamic population of the xlayer file e.g. the xlayer file while the virtual application is running. This is done to support streaming delivery of the virtual application using the streaming model .

In first block the directing process allocates the block of shared memory see . In next block the directing process allocates a status event object used for signaling changes in the state of the session. The status event objects may be implemented using the WINDOWS event system that uses kernel handles.

Then in block the directing process sets the values of any specific settings or values stored in the shared memory block. For example the shared memory block may store a SignalEvent value and a State value. The SignalEvent value is set to the handle value of the status event object allocated in block .

Whenever the State value is changed or the xlayer mapping is updated by the directing process e.g. when additional xsequence files have been downloaded the directing process triggers a SignalEvent. In response to detecting the SignalEvent each thread launched by the execution of the virtual application checks the State value to determine if the state of the virtual application is to be changed e.g. paused resumed or terminated . Any threads waiting for the xlayer mapping to indicate a particular portion of the downloading virtualized application file is available or stored in a local copy of the virtualized application file also check the xlayer mapping to determine whether the data has been delivered.

The initial value of the State value depends upon in which state the virtual application is to be launched. If the virtual application is to be launched in a paused state the State value is set to a value indicating the application is paused e.g. the eSessionPaused value . Otherwise the State value is set to a value indicating the application is executing e.g. the eSessionRunning value . If at some point the application is terminated the State value is set to a value indicating the application has shutdown e.g. the eSessionShutdown value .

Once the shared memory block status event object s and command line arguments are prepared in block the directing process launches the virtual application . By way of a non limiting example the virtual application may be launched via standard a Win32 CreateProcess function or ShellExecute APIs. The following pseudo code provides a non limiting example of a method of starting a virtual application.

The first code portion to execute within the virtual application is called bootstrap code. The bootstrap code includes the virtual runtime engine code that when executing sets up the virtual runtime environment reads the configuration information e.g. virtual filesystem information virtual registry settings and the like and other initialization tasks. As explained above the configuration information may be stored in an xlayer file e.g. the xlayer file . When the SessionId value is passed to the bootstrap code the bootstrap code uses the SessionId value to determine a name of the shared memory block having the predetermined format specified above and searches for the shared memory block using that name. The bootstrap code may also create the sentinel object . Once found addition settings can be read as well as the State value. As discussed above in particular implementations the State value may be set to the eSessionPaused value the eSessionRunning value or the eSessionShutdown value.

As mentioned previously once a virtual application has been started in the directed fashion it is able to detect SignalEvents that provide notification of changes in the state of the session. Depending upon the implementation details this may be done via the Win32 WaitForMultipleObjects APIs and by associating the SignalEvent value with the handle of the directing process . After detecting a SignalEvent the virtual application can check the State value of the shared memory block . If the State value indicates the session has been paused e.g. the State value is set to the eSessionPaused value the virtual runtime engine blocks access by the virtual application to the underlying xlayer file which contains the virtual filesystem and registry among other things . The virtual runtime engine could also explicitly suspend application threads. However this may not be necessary.

The following pseudo code provides a non limiting example of a method of pausing a virtual application by setting the value of the State value to the eSessionPaused value and triggering a SignalEvent to indicate a change in the state of the session.

When the State value indicates the session is running e.g. the State value is set to the eSessionRunning value access to the xlayer file is restored. In other words the virtual application resumes. The following pseudo code provides a non limiting example of a method of resuming a virtual application by setting the value of the State value to the eSessionRunning value and triggering a SignalEvent to indicate a change in the state of the session.

The directing process has the ability to tell the virtual application to shutdown. However this shutdown occurs asynchronously. Additionally the virtual application can shut itself down at any time or may be shut down due to user control for example when the user closes the virtual application. As mentioned above the named sentinel object is used to determine when the virtual application is completely shutdown. Each process within the virtual application duplicates the handle of the named sentinel object to the child process during any create process call. For example the name of the named sentinel object may be determined as follows 

Duplicating the handle of the named sentinel object into each child process ensures that the named sentinel object remains alive e.g. has a reference count greater than zero for the lifetime of the virtual application. The directing process may determine the virtual application is executing by polling for the existence of the named sentinel object occasionally e.g. at regular intervals . For example the directing process may poll for the named sentinel object once every second via a Win32 timer thread function. In embodiments in which a reference count is available the polling may simply poll to determine if the reference count is equal to zero meaning no objects have references or handles to the named sentinel object .

The following pseudo code provides a non limiting example of a method of monitoring for virtual application shutdown.

Once shutdown is detected the directing process may perform custom actions such as cleaning up resources marking the end time in usage statistics recording the termination in a transcript file etc.

To begin execution of a virtual application as soon as possible one may try to determine which portions of the xlayer file are necessary for initial execution and deliver those portions to the virtual application first. To actually support dynamic population of the underlying xlayer file while it is being executed requires a system and method for doing so.

The directing process is responsible for preparing the data structures described above and illustrated in . The named shared memory block contains handle values of the xlayer mapping and the bit array page mask . The shared memory block includes a file mapping of the underlying xlayer file e.g. the xlayer file with read write access enabled. The shared memory block includes a block of shared memory used to store the bit array for indicating which pages have been populated within the xlayer being used by the virtual runtime engine to execute the virtual application .

By way of a non limiting example the name of the shared memory block may have the following format  xmgr  mem xlayerinfo . Where managerVersion is an argument passed on the command line from the directing process . The xlayerpathhash may be a hash e.g. a good hash of the normalized path to the xlayer file being populated.

If the shared memory block has been allocated the virtual runtime engine concludes the xlayer file is to be dynamically delivered. If the shared memory block has not been allocated the virtual runtime engine concludes the xlayer file is fully populated.

By way of a non limiting example the shared memory block may be implemented using the following structure 

The following pseudo code provides a non limiting example of a method of preparing dynamic xlayer population data structures.

After this data structure is prepared execution of the application may be started as described above. Note the local copy of the xlayer file need not be fully populated to launch the virtual application. However once started the virtual application will begin to demand access to various parts of the local copy of the xlayer file and will wait until these requests are satisfied. By way of a non limiting example this access may be requested via an IStream interface abstraction of the xlayer file. The blocking is done by way of a check of the pageMap bit array . If a requested page is not yet populated as indicated by this bit array the virtual application waits on the SignalEvent until the PageMap indicates the page has been populated within the local copy of the xlayer file. The following pseudo code provides a non limiting example of a method by which the virtual application may access the xlayer file and check the PageMap.

Simultaneously the directing process may populate any portion of the xlayer file. The following pseudo code provides a non limiting example of a method by which the directing process may populate any portion of the xlayer file.

As the virtual application executes it sends messages e.g. messages using the data structure named SFeedbackStatsMessage to the directing process indicating which page of the local copy of the xlayer file is currently being accessed by the executing virtual application . The directing process uses these messages to determine where in the streaming model file the page currently being accessed by the executing virtual application is located. The directing process then begins reading the streaming model file from that location. This allows the traversal of the directed graph structure stored by the streaming model file to be modified by the user choices occurring during the execution of the virtual application . Thus the directing process traverse the streaming model file in a custom manner dictated by the actions of a user. As discussed above the SFeedbackStatsMessage type message includes the blocked value. The virtual runtime engine may communicate to the directing process that the virtual runtime engine has tried to access a page that has not yet been downloaded e.g. is not indicated as being included in the local copy of the downloaded xlayer file by the xlayer mapping by setting the blocked value to TRUE. 

The signature value is a value used to authenticate the information stored in a file. For example the signature value may be used to validate a particular xsequence file. By way of a non limiting example the signature value of a valid xsequence file may store a predetermined value e.g. the string xsequencedfile . Thus to validate the xsequence file the Sandbox Manager may simply confirm the signature value stores the predetermined value. The signature value may be implemented as a 16 byte array. The value stored in the signature value may be generated using any method and the present teachings are not limited to use with a signature value generated using any particular method.

The version stamp may include a major version identifier and a minor version identifier . The major version identifier is typically modified when a change is made to the xsequence file format that would make the file incompatible with a previous version of the virtual runtime engine . The minor version identifier may be incremented for informational purposes when the xsequence file format is modified such that it requires special handling to enable backwards compatibility. By way of a non limiting example each of the major and minor version identifiers and may be implemented as 32 bit integers.

The flags may include a flag that indicates whether the data stored in the xblocks has been compressed. The flags may include a flag that indicates which type of compression was used to compress the data stored in the xblocks . By way of a non limiting example the flags may be implemented as a 32 bit integer.

The size indicator identifies a location in memory that corresponds to the end of an xsequence file having the xsequence file format . The location in memory to which the size indicator refers is identified in FIG. by a curved arrow A. By way of a non limiting example the size indicator may be implemented as a 64 bit integer.

The indicator of size of the original file indicates the size of the original file e.g. the xlayer file . By way of a non limiting example the indicator of size of the original file may be implemented as a 64 bit integer.

The indicator of size of the xblocks indicates the size of all of the xblocks in the xsequence file combined. By way of a non limiting example the indicator of size of the xblocks may be implemented as a 32 bit integer.

The number of xblocks indicator indicates the number of the xblocks in the xsequence file. By way of a non limiting example the number of xblocks indicator may be implemented as a 32 bit integer.

The number of xblocks per chapter indicator indicates a number of xblocks stored in a particular chapter. Chapters may be used by the directing process of the Sandbox Manager to skip to a particular portion of the xsequence file. By way of a non limiting example the number of xblocks per chapter indicator may be implemented as a 32 bit integer.

As mentioned above the xsequence file format includes one or more xblocks that each contains a portion of the data stored in the original file e.g. the xlayer file . Referring to each of the xblocks has a block structure that may include a signature value one or more flags an xblock index value an xblock identifier an xblock size indicator and a data portion . The data in the block structure is ordered with the signature value being first followed by the flags which is followed by the xblock index value which is followed by the xblock identifier which is followed by the xblock size indicator which is followed by the number of the data portion .

The signature value is a value used to authenticate the information stored in an xblock and contains a unique value assigned to the xblock. The signature value may be implemented as a 6 byte array. The value stored in the signature value may be generated using any method and the present teachings are not limited to use with a signature value generated by any particular method.

The flags may include values for various block options. By way of a non limiting example the flags may include an indicator that a block stores metadata instead of virtual application data. By way of a non limiting example the flags may be implemented as a 16 bit integer.

The xblock index value is a numeric index value assigned to the xblock within the xsequence file. This xblock index value is an index value associated with the block within an xsequence file. For example if an xsequence file has four xblocks the xblocks may be assigned index values of 0 1 2 and 3 in the order in which the xblocks were written to xsequence file. By way of a non limiting example the index value may be implemented as a 32 bit integer.

The xblock identifier identifies the data stored in the xblock within the original file e.g. the xlayer file . The model builder server divides the original xlayer file into pages. For example an xlayer file may be divided into pages P P P P P . . . PN. The xblock identifier stores the location of the page in the original xlayer file. Thus when the xblock is read by the Sandbox Manager the Sandbox Manager knows where to write the xblock in the locally reconstructed copy of the xlayer file. By way of a non limiting example the xblock identifier may be implemented as a 32 bit integer.

The xblock size indicator indicates the size of the xblock. By way of a non limiting example the xblock size indicator may be implemented as a 32 bit integer.

As described above the streaming model is used to create the initial execution xsequence file sequence xsequence files and rest xsequence files in accordance with an order specified in the streaming model. After one or more of these files are downloaded the Sandbox Manager may begin the process of reassembling or reconstructing the original file e.g. the xlayer file .

In next block the Sandbox Manager reads the information stored in the file header portion see of the xsequence file.

In decision block using the information read in block the Sandbox Manager determines whether the xsequence file received in block is valid. An xsequence file must be validated or authenticated before it can be used. As mentioned above the Sandbox Manager may validate an xsequence file by confirming the signature value stores the predetermined value e.g. the unique string xsequencedfile . Further to ensure compatibility the Sandbox Manager may confirm that the major and minor versions match those of the virtual runtime engine .

In the pseudo code above if the signature value read into variable signature does not equal the predetermined value stored in the constant GLOBAL SIGNATURE an exception is generated. Further if the major version identifier read into variable MajorVersion does not match the major version of the virtual runtime engine stored in the constant CURRENT MAJOR VERSION or the minor version identifier read into variable MinorVersion does not match the major version of the virtual runtime engine stored in the constant CURRENT MINOR VERSION an exception is generated. After the xsequence file has been verified in the pseudo code above the remaining data stored in the file header portion is read e.g. the flags the size indicator the indicator of size of the original file the indicator of size of the xblocks the number of xblocks indicator and the number of xblocks per chapter indicator . At this point the Sandbox Manager knows the number of blocks stored in the xsequence file which is provided by the number of xblocks indicator and block sizes which is provided by the indicator of size of the xblocks .

The decision in decision block is YES when Sandbox Manager determines the xsequence file is valid. Otherwise the decision in decision block is NO when Sandbox Manager determines the xsequence file is invalid. By way of a non limiting example the decision in decision block is NO when the pseudo code above generates an exception because the signature value does not equal the predetermined value the major version identifier does not match the major version of the virtual runtime engine and or the minor version identifier does not match the minor version of the virtual runtime engine . Otherwise in this example the decision in decision block is YES. 

As mentioned above the xsequence files are configured to be transferred from one computing device to another e.g. using conventional streaming methods . When the client computing device receives an xsequence file from the server computing device portions of the original file contained in the received xsequence file are used to populate a copy of the original file constructed or assembled on the client computing device .

When the decision in decision block is YES in decision block the Sandbox Manager determines whether the xsequence file received is the first one for the original file. The decision in decision block is YES when the xsequence file received in block is the first one for the original file. Otherwise the decision in decision block is NO when one or more xsequence files have been received previously for the original file.

When the decision in decision block is YES in block the Sandbox Manager allocates the memory mapped file illustrated in . The memory mapped file is not yet populated with data at this point. Alternatively the Sandbox Manager may create the memory mapped file when the Sandbox Manager receives the model file. In such embodiments block is omitted from the method and when the decision in decision block is YES the Sandbox Manager advances directly to block .

In block the Sandbox Manager reads the data portions of the xblocks into the memory mapped file optionally allocated in block . As explained above the block structure includes the xblock identifier that indicates the location in the original file from which the data in the xblock was obtained. The xblock identifier may be used to write the data stored in the xblock in the correct location of the memory mapped file .

The following pseudo code provides a non limiting example of a method of reading a single xblock into memory.

Then in block the Sandbox Manager sends one or notifications that data has been downloaded. In block the Sandbox Manager may send a notification to the virtual runtime engine e.g. that signals an event that the blocks have been downloaded. The following pseudo code provides a non limiting example of a method of writing the data in an xblock into the correct location of the memory mapped file and sending a notification to the virtual runtime engine .

In block the Sandbox Manager may also modify the bit array page mask before sending the notification to the virtual runtime engine .

Then in block the Sandbox Manager instructs the virtual runtime engine to launch the virtualized application file to thereby execute the virtual application . Depending upon the implementation details at this point a initial execution xsequence file may have been downloaded and used to initiate execution of the virtual application . However the data stored in the initial execution xsequence file may be inadequate to support all features of the virtual application . Therefore in decision block the Sandbox Manager determines whether all of the xsequence files have been downloaded. The method illustrated in and described above is used to determine the order in which the xsequence files are downloaded and to request the download of each of the xsequence files in accordance with that order. Then the Sandbox Manager advances to decision block .

When the decision in decision block is NO in block the Sandbox Manager reads the data portions of the xblocks into the memory mapped file optionally allocated in block . Block may be substantially identical to block .

Then in block the Sandbox Manager sends one or more notifications that blocks have been downloaded. Block may be substantially identical to block . Then the Sandbox Manager advances to decision block .

The decision in decision block is YES when all of the xsequence files have been downloaded. The decision in decision block is NO when all of the xsequence files have not been downloaded.

When the decision in decision block is NO the Sandbox Manager returns to block whereat the Sandbox Manager receives another xsequence file.

When the decision in decision block is YES in block in block the copy of the original file which is at least partially populated is written to the local cache illustrated in . The following pseudo code provides a non limiting example of a method of copying the copy of the original file to the local cache .

Thus the Sandbox Manager need not wait until the entire original file has been assembled to instruct the virtual runtime engine to execute the virtual application . In other words a partially assembled version of the original file may be written to the local cache illustrated in .

The copy of the original file is illustrated in as the virtualized application file e.g. a copy of the xlayer file stored in the local cache .

Moreover those skilled in the art will appreciate that implementations may be practiced with other computer system configurations including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers and the like. Implementations may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

The exemplary hardware and operating environment of includes a general purpose computing device in the form of a computing device . Each of the virtual application file the xlayer file the authoring tool the Sandbox Manager the Client Application and or virtual runtime engine may be implemented using one or more computing devices like the computing device . By way of non limiting example the virtual application file the xlayer file the authoring tool the Sandbox Manager the Client Application and or virtual runtime engine may be implemented on the computing device . Further each of the server computing device the model building server the client computing device and the computing device may be implemented by computing devices substantially similar to the computing device .

The computing device includes the system memory a processing unit and a system bus that operatively couples various system components including the system memory to the processing unit . There may be only one or there may be more than one processing unit such that the processor of computing device comprises a single central processing unit CPU or a plurality of processing units commonly referred to as a parallel processing environment. The computing device may be a conventional computer a distributed computer or any other type of computer.

The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory may also be referred to as simply the memory and includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computing device such as during start up is stored in ROM . The computing device further includes a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM DVD or other optical media.

The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical disk drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the computing device . It should be appreciated by those skilled in the art that any type of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards USB drives digital video disks Bernoulli cartridges random access memories RAMs read only memories ROMs and the like may be used in the exemplary operating environment. As is apparent to those of ordinary skill in the art the hard disk drive and other forms of computer readable media e.g. the removable magnetic disk the removable optical disk flash memory cards USB drives and the like accessible by the processing unit may be considered components of the system memory .

A number of program modules may be stored on the hard disk drive magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the computing device through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor computers typically include other peripheral output devices not shown such as speakers and printers.

The computing device may operate in a networked environment using logical connections to one or more remote computers such as remote computer . These logical connections are achieved by a communication device coupled to or a part of the computing device as the local computer . Implementations are not limited to a particular type of communications device. The remote computer may be another computer a server a router a network PC a client a memory storage device a peer device or other common network node and typically includes many or all of the elements described above relative to the computing device . The remote computer may be connected to a memory storage device . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computing device is connected to the local area network through a network interface or adapter which is one type of communications device. When used in a WAN networking environment the computing device typically includes a modem a type of communications device or any other type of communications device for establishing communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computing device or portions thereof may be stored in the remote computer and or the remote memory storage device . It is appreciated that the network connections shown are exemplary and other means of and communications devices for establishing a communications link between the computers may be used.

The computing device and related components have been presented herein by way of particular example and also by abstraction in order to facilitate a high level view of the concepts disclosed. The actual technical design and implementation may vary based on particular implementation while maintaining the overall nature of the concepts disclosed.

Returning to the system memory A and the system memory B may each be substantially similar to the system memory . Thus the host operating system A the host operating system B the virtual application file the xlayer file the authoring tool the Sandbox Manager the Client Application and or virtual runtime engine may be stored as computer executable components on the system memory A and or B. Each of the host operating system A the host operating system B the virtual application file the xlayer file the authoring tool and or virtual runtime engine may be implemented using software components that are executable by the processing unit and when executed perform the functions described above. Further each of the methods and may be implemented as computer executable instructions that are executable by the processing unit .

The foregoing described embodiments depict different components contained within or connected with different other components. It is to be understood that such depicted architectures are merely exemplary and that in fact many other architectures can be implemented which achieve the same functionality. In a conceptual sense any arrangement of components to achieve the same functionality is effectively associated such that the desired functionality is achieved. Hence any two components herein combined to achieve a particular functionality can be seen as associated with each other such that the desired functionality is achieved irrespective of architectures or intermedial components. Likewise any two components so associated can also be viewed as being operably connected or operably coupled to each other to achieve the desired functionality.

While particular embodiments of the present invention have been shown and described it will be obvious to those skilled in the art that based upon the teachings herein changes and modifications may be made without departing from this invention and its broader aspects and therefore the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of this invention. Furthermore it is to be understood that the invention is solely defined by the appended claims. It will be understood by those within the art that in general terms used herein and especially in the appended claims e.g. bodies of the appended claims are generally intended as open terms e.g. the term including should be interpreted as including but not limited to the term having should be interpreted as having at least the term includes should be interpreted as includes but is not limited to etc. . It will be further understood by those within the art that if a specific number of an introduced claim recitation is intended such an intent will be explicitly recited in the claim and in the absence of such recitation no such intent is present. For example as an aid to understanding the following appended claims may contain usage of the introductory phrases at least one and one or more to introduce claim recitations. However the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles a or an limits any particular claim containing such introduced claim recitation to inventions containing only one such recitation even when the same claim includes the introductory phrases one or more or at least one and indefinite articles such as a or an e.g. a and or an should typically be interpreted to mean at least one or one or more the same holds true for the use of definite articles used to introduce claim recitations. In addition even if a specific number of an introduced claim recitation is explicitly recited those skilled in the art will recognize that such recitation should typically be interpreted to mean at least the recited number e.g. the bare recitation of two recitations without other modifiers typically means at least two recitations or two or more recitations .

