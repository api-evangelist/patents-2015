---

title: Computing device with force-triggered non-visual responses
abstract: In one example, a method includes receiving, by a computing device, an indication of a detected force applied to the computing device. The method further comprises determining, by the computing device, that the detected force matches a corresponding input that the computing device associates with a corresponding function that is executable by the computing device. The method further comprises generating, by the computing device and in response to determining that the detected force matches the corresponding input and, a non-visual output based on the corresponding function.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519345&OS=09519345&RS=09519345
owner: Google Inc.
number: 09519345
owner_city: Mountain View
owner_country: US
publication_date: 20150924
---
This application is a continuation of U.S. application Ser. No. 13 732 946 filed Jan. 2 2013 which claims the benefit of U.S. Provisional Application No. 61 718 059 filed Oct. 24 2012 the entire content of each of which is incorporated herein by reference.

Many mobile computing devices such as smartphones and tablet computers have touchscreens that provide graphical outputs and enable users to enter inputs via touch gestures and or virtual or hardware keyboards or buttons. Mobile computing devices may also provide audio outputs and enable user inputs via virtual or hardware keyboards and buttons. Mobile computing devices may provide a variety of functions including telephony email text messaging web browsing etc.

Keyboard and touch gesture inputs and graphical outputs may be the primary modes of a user s interaction with a mobile computing device. A user may typically begin interacting with a computing device such as a smartphone or tablet computer by positioning the computing device where the user can view its display and can enter gesture inputs to virtual icons or keys presented at the display.

In one example a method includes receiving by a computing device an indication of a detected force applied to the computing device. The method further comprises determining by the computing device that the detected force matches a corresponding input that the computing device associates with a corresponding function that is executable by the computing device. The method further comprises generating by the computing device and in response to determining that the detected force matches the corresponding input a non visual output based on the corresponding function.

In another example a computing device includes at least one processor. The at least one processor is configured to receive an indication of a detected force applied to the computing device. The at least one processor is further configured to determine that the detected force matches a corresponding input that the at least one processor associates with a corresponding function that is executable by the at least one processor. The at least one processor is further configured to generate in response to determining that the detected force matches the corresponding input a non visual output based on the corresponding function.

In another example a computer readable storage medium includes instructions that are executable by the at least one processor to receive by the at least one processor an indication of a detected force applied to a computing device. The instructions are further executable by the at least one processor to determine by the at least one processor that the detected force matches a corresponding input that the at least one processor associates with a corresponding function that is executable by the at least one processor. The instructions are further executable by the at least one processor to generate in response to determining that the detected force matches the corresponding input and by the at least one processor a non visual output based on the corresponding function.

The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

The various described features are not drawn to scale and are drawn in a simplified form in which one or more features relevant to the present application are emphasized. Like reference characters denote like elements throughout the figures and text.

Techniques and methods are disclosed herein whereby a computing device can provide force triggered non visual responses to user inputs. In some implementations such responses can be output by the mobile computing device without the user accessing a touchscreen or keyboard and without the user having to look at or handle the computing device. Techniques of this disclosure can also provide new opportunities for wearable computing and for interacting with a device without interfering with personal social interaction. Techniques of this disclosure can also provide device accessibility for users with sensory impairments or within the context of operating a vehicle or other machine.

This disclosure is further directed to a computing device receiving acceleration based or squeeze based inputs and in response the computing device outputting non visual responses such as audio or vibration outputs. These non visual outputs generated in response to receiving acceleration based or squeeze based inputs collectively force based inputs can be referred to generally as force triggered non visual responses. In some examples the computing device can output non visual responses while a presence sensitive screen of the device is off or locked. Generating force triggered non visual responses can enable a user to access functionality of a computing device without having to go through the process of unlocking or turning on the device s screen and without directly handling the computing device. A user can make use of functions of the computing device while the computing device remains in the user s pocket with the user tapping the device through the cloth of the user s pants for example. A user can also tap or squeeze a computing device to activate certain features without having to look at the computing device such as when the user is driving. Force triggered non visual responses can also serve as an accessibility feature for users who have a visual impairment in some examples.

A computing device may use any force based inputs that can be sensed through any type of force sensor such as an accelerometer or a compression squeeze sensor. A computing device may respond to force based inputs in the form of any input detectable by an accelerometer a compression squeeze sensor or other sensors. These force based inputs may include tapping squeezing shaking or rotating the computing device. The computing device can also combine these force based inputs with inputs from a Global Positioning System GPS sensor a cellular WiFi position sensor a touchscreen a light sensor a magnetic field sensor a near field communication NFC tag sensor etc. collectively non force based inputs . A computing device may respond to a combination of force based inputs and non force based inputs to provide additional modes of interaction for responding to force based inputs.

As one example of a non visual output a computing device may generate in response to force based inputs a computing device may respond to a tapping input by using speech synthesis to generate a speech audio output. This force triggered speech audio output may include the current time of day calendar events for the day news headlines a weather forecast selected stock quotes or market indexes or the name and phone number of a caller if the user taps the computing device while it has an incoming phone call for example. The computing device may respond to a phone call conveyed over a traditional telephony network or over a packet based network such as by a web based application over the Internet for example. The computing device may provide different responses to different tap inputs during an incoming phone call. In one example if a call is incoming the computing device may respond to a single tap by answering the call on speaker respond to two taps by generating a speech synthesis output stating the caller s name and phone number or respond to three taps by muting the incoming call e.g. by stopping a ringing or vibrating output.

A computing device may also provide different responses to a tap input or other force based input subsequent to an audio or vibration output indicating arrival of a new email text message or social networking notification. For example a computing device may respond to different tap inputs or other force based inputs by generating a speech synthesis output identifying the sender of the message or reading the message to the user or generating vibration outputs or other outputs identifying whether the caller or message sender is on a list of high value contacts. In other examples a computing device may respond to different tap inputs or other force based inputs by opening an interactive application using speech synthesis audio outputs in response to voice inputs such as for web search map search or road navigation.

In other examples a computing device may generate other types of non visual responses besides audio or vibration outputs in response to force based inputs potentially in combination with audio or vibration outputs. In various examples a computing device may respond to different force based inputs by generating an output to check into a location on a location based app to open a local sharing group to share files or other data with other local computing devices to start or stop a position tracked route with tracking by GPS Wi Fi navigation etc. in a route tracking application to mark a location for a geocaching app to interact with remote control apps such as to lock or unlock the user s car or start the engine or to turn the user s TV on or off or to start an audio recorder with transcription which might include saving to a notepad or word processing app or opening an email app and transcribing into an email message draft.

A computing device may have an initial default set of non visual responses corresponding to different force based inputs. A computing device may also enable the non visual responses it generates corresponding to different force based inputs to be configurable by the user. In one example a computing device may have an initial default setting to respond to a single tap by generating a speech synthesis output stating the current time of day to respond to two taps by generating a speech synthesis output stating remaining events for the day from a calendar application and to respond to three taps by generating a speech synthesis output stating a current local weather forecast. The computing device may provide options for a user to reconfigure the responses generated for these inputs and to set any other corresponding functions for input patterns to the accelerometer compression sensor or other force sensor potentially also conditional on other sensor inputs or states. An example of a computing device implementing features such as those described above is shown in .

For example the tap input may be a sequence that includes both a single tap followed by a double tap. In this example computing device may associate a single tap input with a corresponding function of outputting a current time using data from a clock application while computing device may associate a double tap input with a corresponding function of outputting information from or about recently received emails using data from an email application. In response to determining that the detected forces match the corresponding inputs i.e. the stored input parameters associated with the corresponding functions computing device executes the corresponding functions i.e. outputting the current time and information about recently received emails in this example. Executing the corresponding functions includes the computing device generating non visual outputs based on the corresponding functions such as computing device generating speech synthesis audio output of the current time and with information about recently received emails in this example. In other examples computing device may respond to a single tap or double tap or other force based input by generating a speech synthesis audio output with information from recently received text messages using data from a text message application or from recently received social networking updates using data from a social networking application for example.

In another example computing device may interpret different inputs from subsequent tap inputs within a period of time after an initial tap input or after a response to the first input by computing device . For example the user may tap computing device to enter a first input to prompt computing device to generate an audio output such as the current time then the user may enter another one or more taps within a period of time after the initial audio output such as a subsequent single tap to prompt computing device to generate an audio output with calendar information for upcoming appointments. These input and output responses may be extended such that another single tap input within a certain period of time after the calendar audio output may prompt computing device to generate yet another output such as information on recently received emails or current stock market data. Computing device may also enable the inputs and outputs for these sequences of force based inputs to be user configurable. Computing device may define a period of time for accepting a subsequent tap input so that it doesn t begin too quickly after a prior tap to prevent confusion with a double tap input and so that it doesn t extend for too long to prevent confusion with later unrelated tap inputs or random motions in some examples.

Computing device may include logic to differentiate between distinct tap inputs or other force based user inputs and ordinary motions that are not intended as force based user inputs intended to elicit non visual outputs. Computing device may also use any of various aspects of context as part of differentiating intended force based user inputs from non input motions. For example computing device may refrain from processing detected forces for generating audio outputs when a mute switch on computing device is set to mute. As another example computing device may determine whether the force is applied while a presence sensitive display not depicted in that is operatively connected to the mobile computing device is in an activated state or in a deactivated state e.g. the presence sensitive display is either off or locked or while a pair of headphones or other external audio device are plugged into an audio socket so that computing device has its default audio speakers in a deactivated state.

Computing device may also refrain from processing detected forces for generating audio outputs if computing device determines that a given output component such as the presence sensitive display or the default audio output system is in an activated state. In the example noted above involving a presence sensitive display if computing device determines that the force was applied while presence sensitive display was in a deactivated state computing device may then in response execute the corresponding function and generate the non visual output. Computing device may maintain the presence sensitive display in the deactivated state while generating the non visual output. In the example noted above involving headphones computing device may generate audio outputs only on determining that the force was applied while headphones are plugged into the audio socket. For example computing device may generate audio outputs based on text to speech processing of emails to read emails aloud to the user only if headphones are plugged into computing device at the time the user enters the appropriate tap inputs in this example.

Computing device basing its outputs in part on whether a presence sensitive display is in a deactivated state or whether headphones are plugged into an audio socket are illustrative examples of context sensitive output modes. Computing device may apply a variety of other context sensitive output modes to determine what output channel to use for outputs in response to force based user inputs. For example other context sensitive output modes may include the presence or absence of a selected Bluetooth NFC WiFi or other electromagnetic signal. In various examples computing device may establish a communicative connection with a nearby car stereo system home stereo system or other audio player system via Bluetooth or other communicative link and may send its audio outputs via the communicative link to be output by the connected audio system. As another example of a context sensitive output mode computing device may detect through one or more of an accelerometer WiFi networks a GPS sensor etc. whether it is moving with speeds and motions characteristic of a motor vehicle and may generate audio outputs based in part on detecting that a motor vehicle context or driving mode is applicable.

Various context sensitive output modes may be combined in some examples. For example computing device may be configured to recognize a Bluetooth signal from the user s own car and only begin generating audio outputs in response to either the Bluetooth signal from the user s car or when computing device is in a moving vehicle and headphones are plugged into the audio socket. Computing device may thus avoid generating audio outputs out loud while the user is riding a bus or light rail. Computing device may also prompt the user for confirmation before responding with audio outputs such as by asking Okay to read emails out loud and continuing only if it receives a certain confirmatory force based user input in response such as a double tap for example. Computing device may enable each of these settings to be configured by the user in various examples.

Computing device may therefore accept force based user inputs and respond by generating audio outputs or other non visual outputs. As another example of a non visual output computing device may generate vibration outputs in response to specific force based user inputs such as either one or two vibrations to communicate information. For example computing device may be configured so that when the user enters a specific force based input such as a set of two taps computing device checks whether a certain contact to whom the user has sent a calendar invitation in a calendar application has sent a reply to accept the calendar invitation. Computing device may be configured to respond to this force based input by outputting a single period of vibration if the contact has sent a reply to accept the calendar invitation a set of two periods of vibration if the contact has not yet replied or a set of three periods of vibration if the contact has replied to reject the calendar invitation for example.

Generating vibration outputs as non visual outputs in response to the force based user inputs may enable computing device to provide simple and subtle modes of user interaction that may be more practical and or socially convenient than entering inputs and viewing outputs on a display screen in some contexts. Computing device may provide a capability for the user to configure force based inputs and corresponding non visual outputs to involve any of a wide range of specific information and or for interacting with any type of software application.

Computing device may incorporate or be operatively connected to any of a number of different sensors that may be capable of detecting forces applied to the computing device such as an accelerometer a compression sensor or an acoustic sensor for example and may use inputs from one or multiple sensors in determining whether a detected force is consistent with and matches a force based input. Computing device may evaluate the properties of detected forces over time and may apply different steps of filtering and processing detected forces such as by initially screening sensor inputs for any potentially significant force detection events and performing further processing or analysis on such potentially significant force detection events to determine whether they match a stored profile for a corresponding force based input. Computing device may also compare potentially significant force detection events with other aspects of its operating context such as whether the force was detected during an incoming phone call that hadn t yet been answered or soon after the computing device had generated an alert for an incoming text message or email as is further described below.

Computing device may be implemented in a variety of different forms such as a smartphone a tablet computer a laptop a netbook a wearable computing device or other mobile computing device for example. Computing device may also connect to a wired or wireless network using a network interface. Additional details of example computing devices are described in further detail below with respect to subsequent figures.

Computing device as shown in includes an accelerometer a compression sensor and an acoustic sensor in this example. Other examples of computing devices may include any one or more of these or other sensors capable of sensing acceleration vibration or other indicator of an applied force. Computing device also includes one or more processors memory a network interface one or more data storage devices power source one or more microphones one or more speakers one or more cameras and presence sensitive display which may be a touchscreen or other presence sensitive display. Each of the components and may be interconnected physically communicatively and or operatively in any of a variety of physical and or communicative connection means for inter component communications.

Computing device has operating system stored on one or more storage devices and that may execute on one or more processors . Operating system in various examples may control aspects of the operation of components of computing device and facilitate operation of higher level software applications. Computing device in this example has applications that may include a non visual input output I O application that is executable by computing device . Non visual I O application may include executable instructions to perform or facilitate any or all of detecting forces applied to computing device determining whether the applied forces match stored parameters for force based inputs gathering data or outputs from other sources or applications if necessary to respond to the force based inputs and outputting non visual responses to the force based inputs or any other aspects of this disclosure which may collectively be referred to as non visual I O as an abbreviated term of reference. Operating system in one example facilitates the interaction of non visual I O application with any or all of accelerometer a compression sensor and an acoustic sensor processors memory network interface data storage device power source one or more microphones one or more speakers one or more cameras and presence sensitive display .

As shown in non visual I O application may include an input module and an output module . Input module may include portions of executable code responsible for detecting forces applied to computing device and determining whether the applied forces match corresponding force based inputs and output module may include portions of executable code responsible for performing the corresponding functions and generating non visual outputs based on the corresponding functions for example.

Non visual I O application input module and output module may each include program instructions and or data that are executable by computing device or by at least one of the one or more processors of computing device . For example non visual I O application input module and or output module may include computer executable software instructions that cause computing device to perform any one or more of the operations and actions described in the present disclosure. In various examples operating system and browser application may include code and or data that are stored on one or more data storage devices and that are read and executed or processed by one or more processors and may in the process be stored at least temporarily in memory .

In this illustrative implementation of computing device operating system may include an operating system kernel which may include various device drivers kernel extensions and kernel modules for example. Operating system may also include or interact with a set of libraries which may include various more or less standard specialized open source and or proprietary libraries. These may include a specialized library such as non visual I O framework that may perform or support non visual I O functions in accordance with any of the examples described herein.

In an illustrative implementation of computing device operating system may also include or interact with a runtime which may include various core libraries and or a virtual machine which may be the Dalvik virtual machine in an example implementation. Virtual machine may abstract certain aspects and properties of computing device and allow higher level applications to run on top of virtual machine so that software code in the higher level applications may be compiled into bytecode to be executed by the virtual machine . Computing device may also have an application framework that executes on top of runtime and libraries and that may include resources to facilitate the execution of applications that execute on top of application framework . Other embodiments may include other elements of a software stack between the operating system kernel and the top level applications .

Application framework may for example include a non visual I O manager that itself may include executable instructions to perform or facilitate any or all of detecting forces applied to computing device determining whether the applied forces match stored parameters for force based inputs gathering data or outputs from other sources or applications if necessary to respond to the force based inputs and outputting non visual responses to the force based inputs or any other aspects of this disclosure. Computing device may perform or facilitate any of these or other non visual I O functions with any one or all of the non visual I O application the non visual I O manager in the application framework the non visual I O framework in the libraries or any other element of the software stack included in or operatively accessible to computing device .

In various examples executable instructions for applications or software elements such as non visual I O application may be written in C which may be executable as native code by computing device or may be written in Java then compiled to virtual machine executable bytecode to be executed by virtual machine . As one illustrative example libraries may include the Standard C Library libc which provides native support for C functions. In different implementations the operating system and or the virtual machine may be able to execute code written in various other languages such as Objective C C C Go JavaScript Dart Python Ruby or Clojure for example either natively or compiled into a virtual machine executable bytecode or compiled into an assembly language or machine code native to the CPU of computing device for example. Various examples may not use a virtual machine and use applications that run natively on the computing device C or that use some other technique compiler interpreter or abstraction layer for interpreting a higher level language into code that runs natively on computing device .

GUI framework libraries or other aspect of operating system or the software stack underlying the applications may include code for providing any or all of the functionality for performing non visual I O e.g. detecting force based inputs and generating non visual outputs based on functions that match the corresponding force based inputs in accordance with any of the examples described above and may abstract this functionality at an underlying level for applications . Code for implementing the functionality of any of the aspects of this disclosure may therefore be included in any level or portion of the entire software stack running on computing device or that is operatively accessible to computing device such as in a web application or other program executing on resources outside of computing device but that interact with computing device such as via HTTP over a wireless connection for example.

In various examples computing device may also have various application programming interfaces APIs that are native to operating system and that run on top of operating system and which are intended to provide resources that automate or facilitate higher level applications that access the one or more APIs. These one or more APIs may include object libraries or other libraries toolsets or frameworks and may be associated with a native programming environment for writing applications. Computing device C may also have a different specific organization of APIs libraries frameworks runtime and or virtual machine associated with or built on top of operating system other than the example organization depicted in .

Higher level applications such as non visual I O application may therefore make use of any of various abstractions properties libraries or lower level functions that are provided by any of operating system OS kernel libraries non visual I O framework runtime core libraries virtual machine or other compilers interpreters frameworks APIs or other types of resources or any combination of the above with which computing device is configured to enable functions such as detecting force based inputs and generating non visual outputs based on functions that match the corresponding force based inputs and other functions as described herein.

The one or more processors in various examples may be configured to implement functionality and or process instructions for execution within computing device . For example processors may be capable of processing instructions stored in memory or instructions stored on data storage devices . Computing device may include multiple processors and may divide certain tasks among different processors. For example processors may include a central processing unit CPU which may have one or more processing cores. Processors may also include one or more graphics processing units GPUs and or additional processors. Processors may be configured for multi threaded processing. Processors and or operating system may divide tasks among different processors or processor cores according to certain criteria such as to optimize the user experience. Various tasks or portions of tasks may also be divided among different layers of software and hardware.

Memory in various examples may be configured to store information within computing device during operation. Memory in various examples may be a computer readable storage medium. In various examples memory is a temporary memory and computing device relies more on one or more data storage devices than memory for long term storage. Memory in various examples may be a volatile memory meaning that memory may not maintain stored contents for a long duration of time once it is powered down such as when computing device is turned off. Examples of volatile memories that may characterize memory include random access memories RAM dynamic random access memories DRAM static random access memories SRAM and other forms of volatile memories. In various examples memory may be used to store program instructions for execution by processors . Memory in various examples may be used by software or applications running on computing device to temporarily store data and or software code during execution of an application.

One or more data storage devices in various examples may include a computer readable storage medium or multiple computer readable storage media. Data storage devices may be configured to store larger amounts of information than memory . Data storage devices may further be configured for long term storage of information. In various examples data storage devices include non volatile storage elements. Examples of such non volatile storage elements include magnetic hard discs optical discs floppy discs flash memories or forms of electrically programmable memories EPROM or electrically erasable and programmable EEPROM memories. In other examples memory may also be configured for long term data storage and any of a variety of technologies may blur the lines between memory and data storage and between volatile and non volatile. Memory and data storage devices may also include any of various caches buffers and other temporary memories that may be incorporated at any of various levels of a processing architecture and with various latency and capacity profiles including a dedicated cache exclusive to a processing core or processing chip.

Computing device in various examples may also include a network interface . Computing device C in one example utilizes network interface to communicate with external devices such as servers or data centers via one or more networks which may include one or more wireless networks. Network interface may be or include a network interface card such as an Ethernet card an optical transceiver a radio frequency transceiver or any other type of component that is configured to send and receive information. Other examples of such network interfaces may include Bluetooth 3G 4G LTE and WiFi radios configured for mobile computing devices as well as USB. In various examples computing device may use network interface to communicate wirelessly with an external device such as a server or data center that may provide data to computing device .

Computing device in various examples may also include one or more input and or output devices such as presence sensitive display C. Presence sensitive display C may include a liquid crystal display LCD display screen or display screen that uses another type of graphical output technology. Presence sensitive display C may also be a touchscreen that may include an electrically capacitive layer sensitive to the presence of touch and configured to translate the positions of touch gesture inputs and the motions of touch gesture inputs as they change position over time into signals to provide to a driver for the touchscreen or other feature for receiving the information on the gesture inputs. Presence sensitive display may also be another type of presence sensitive display in other examples.

Computing device may also include or be configured to connect with any of a variety of other input and or output devices such as physical buttons a physical keyboard a mouse a touchpad a trackball a voice user interface system a vibration component a sound card a video graphics adapter card or any other type of device for detecting and or interpreting inputs from a user or for converting a signal into a form of graphical audio tactile or other form of user output that can be sensed by a user.

Computing device C in various examples may include one or more power sources which may be rechargeable and provide power to computing device C. Power source in various examples may be a lithium ion battery a nickel cadmium battery a nickel metal hydride battery or other suitable power source.

Computing device may also include one or more force sensitive sensors such as accelerometer compression sensor acoustic sensor a gyroscope or other types of sensors capable of detecting acceleration compression vibration rotation or other indicator of force applied to computing device . Accelerometer may measure any acceleration of computing device and therefore detect any net force applied to computing device including the net force from a user tapping anywhere on computing device including through a pocket a handbag or other intervening material. Compression sensor may detect a compressive force to computing device or one or more portions of the surface of computing device and could detect an applied force in the form of a compression or a squeezing action applied to computing device . Acoustic sensor could detect an applied force in the form of a mechanical or acoustic vibration which may include vibrations transmitted through intervening materials between a surface a user applies a force to and computing device . For example computing device may be positioned in a user s pocket or in a wristwatch or armband form factor and detect when the user taps another area of the user s body through acoustic vibrations transmitted from the tapped area through the user s body e.g. through the user s skeletal system to the computing device . Computing device may include multiple accelerometers compression sensors and or acoustic sensors and may use one or multiple of one of these types of sensors or one or multiple of multiple types of these sensors any of which may facilitate reliable detection and processing of such force based input signals.

Computing device may have one set of stored parameters for a force based user input of a double tap sequence that corresponds to the applied force signal shown in . The particular corresponding input i.e. the particular corresponding set of stored parameters that match the sensor data of signal may be any input to any application. The particular corresponding input may also have an initial default input that might be determined by the operating system or be pre selected by a vendor of computing device for example and may be freely user configurable to any other input that a user selects. The particular corresponding input may also be selected differently based on the current operating context when the signal is detected so that the signal may be interpreted as one input in a default context or a second input when a new phone call is incoming or a third input when simultaneous data from other sensors show that the user is currently driving a car for example. In particular a default setting in a default context might be to respond to the double tap input of signal by generating an audio output of the current time and information about any recently received emails or text messages for example. If a new phone call is currently incoming while the computing device receives the double tap input of signal the default setting in this context may be to generate an audio output identifying the caller for example. If the computing device receives the double tap input of signal while it detects that the user is currently driving a car such as by communicating with the car or by detecting motion at typical car speeds via position sensors e.g. GPS and or WiFi position sensors and recognizing that the particular car belongs to the user computing device may respond by generating audio outputs for a street navigation voice user interface for example. Any other corresponding functions and outputs may also be used or selected in any of these contexts for responding to the force based user input corresponding to the detected force of signal .

Similarly any default or user configurable function and output may be selected to correspond to other user inputs such as those represented by signal in graph of corresponding to a user s sequence of three taps signal in graph of corresponding to a user shaking the computing device signal in graph of corresponding to a single tap by the user or other signals. As another example computing device may also interpret taps to different portions of itself as different inputs e.g. it may distinguish between a tap to its front or back or to a side edge or a corner and apply different non visual responses based on those different inputs. Computing device may differentiate among these inputs through inputs to accelerometers in different orientations or different positions within the body of computing device for example. The signals shown in are examples but any other type or pattern of signal may also be saved as a user input parameter and may be interpreted as a corresponding user input. Other examples may also incorporate signals from various types of force based sensors such as a signal corresponding to one or more squeezes or compressions of one or more compression sensors. Regarding a detected force corresponding to a single tap as in computing device may in some examples apply default responses to this input only in special operating contexts such as during an incoming phone call e.g. when the phone is ringing but apply no action in a default operating context since a single temporary force may be likely to arise from time to time from ordinary motions so that avoiding a response in ordinary contexts helps prevent interpreting ambient motions as false positives when they are not inputs intended by the user.

User configuration interface may also scroll down to reveal many additional input output assignments under the incoming phone call context or any of various other operating contexts. User configuration interface may also include options for the user to add additional inputs and assign corresponding functions and outputs. The user may be enabled to select additional inputs from a list or to define a new force based input kinematically with the computing device recording whatever pattern of force the user applies to it to generate a new user defined force based input. Computing device may also enable the user to define any non visual output to be generated in response to a selected input and may provide tools to allow a user to integrate functions of any application with the non visual I O system of this disclosure and assign any function of any application as an output with which the non visual I O system integrates and generates in response to a force based user input.

For one or more pre stored or user defined non visual I O selections computing device may store a plurality of force parameters associated with a plurality of force inputs such that determining that the detected force matches the corresponding input comprises comparing the detected force with force signal parameters associated with the plurality of force inputs such as described with reference to .

Computing device may also enable a variety of one or more additional inputs indicating various additional operating contexts to be differentiated and determined in conjunction with the force based input. Computing device may also receive an indication of the one or more additional inputs within a defined interval of time of receiving the indication of the detected force applied to computing device and generate a non visual output based at least in part on the one or more additional inputs. For example computing device may detect if there is an input from a presence sensitive display indicating a large area of contact with the presence sensitive display such as if the user is applying her palm or a large area of her hand to the touchscreen to apply a tap which may for example be a useful additional indicator of the user s intention of entering force based inputs. As another example computing device may detect an input from a light sensor and determine if the light sensor input indicates a level of light below a selected threshold. Computing device may then apply a different operating context for the user being in the dark such as when the user is in bed at night. An example differentiated I O response in this context might be to interpret a selected force based input to mute the computing device or to generate an audio output confirming that an alarm is on and the time for which it is set for example.

As another example of shifting non visual I O responses by operating context computing device may compare input from a magnetic field sensor and apply different non visual outputs based on a direction of travel indicated by the magnetic field sensor such as during a voice user interface navigation function. As another example computing device may detect one or more additional inputs from a near field communication NFC tag sensor and modify the non visual I O responses based on the NFC tag detected.

Additionally any of a wide variety of non visual outputs may be generated in response to a force based user input. Some examples may use a force input to initiate a voice user interface so the user may tap the computing device and then issue a speech input and the computing device may respond with an audio output including for functions involving search and navigation. In this case the computing device may detect the speech input as part of performing the corresponding function in response to detecting the corresponding force based user input that initiates the voice user interface mode. For example computing device may receive a speech input and perform a speech to text function on the speech input to generate a text query based on the speech input. In one example computing device may then enter the text query to a search application wherein generating the non visual output comprises generating a speech synthesis audio output of the results of the web search. As another example computing device may then determine a current location based at least in part on one or more position sensors and perform a location based search based at least in part on the text query and on the current location wherein generating the non visual output comprises generating a speech synthesis audio output of the results of the location based search. As yet another example computing device may then determine a current location based at least in part on one or more position sensors and perform with a navigation application a location based navigational route search based at least in part on the text query and on the current location wherein generating the non visual output comprises generating a speech synthesis audio output of the results of the location based navigational route search.

Computing device may also issue any of a variety of other non visual outputs drawing on any of a variety of applications data sources or other resources. For example computing device may generate a speech synthesis audio output of news using data from a news application or of financial information using data from a financial data application or with identifying information about an incoming phone call using data from a telephone application. Computing device may apply various other forms of receiving a speech input performing a speech to text function on the speech input to generate a text based on the speech input and entering the text to an application to elicit some form of responsive output or data from the application based on the speech input.

Computing device may also apply a variety of location based functions in non visual I O responses. For example computing device may execute a corresponding function in response to detecting a force based user input where the corresponding function includes determining a current location based at least in part on one or more position sensors and performing an additional function or generating an output based in part on the location. This may include starting or stopping a recorded track at the current location in a route tracking application providing local advertising content relevant to the current location providing a user check in to the current location in a location based social networking application or marking the current location in a geocaching application for example.

Computing device may also record and enter speech inputs to any of a variety of applications as part of executing a corresponding function in response to detecting a force based user input. This may include interaction with an email application a text message application or a word processing application for example. The computing device may perform additional functions such as sending an email or a text message comprising the entered text based on the speech input or saving the text in a word processing file for example.

In process a computing device or processor s thereof may execute instructions such as those of non visual I O application . In this example a sensor e.g. accelerometer compression sensor acoustic sensor of computing device or that is operatively connected to computing device detects a force applied to the computing device and conveys a digital signal or other data that indicates that detected force. Computing device or processor s receives this indication of a force applied to computing device . Computing device or one or more processor s of computing device determines that the detected force matches a corresponding input that computing device associates with a corresponding function that is executable by computing device . For example the detected force may be characterized by force parameters that are consistent with a user tapping squeezing or shaking computing device with one or more taps squeezes or shakes and which may be within an interval of time of each other. Computing device may associate different force inputs with different force parameters with different corresponding functions so that each of the corresponding functions may be indicated by a different force input as described above with reference to . Computing device or one or more processor s then generates in response to determining that the detected force matches the corresponding input a non visual output based on the corresponding function . The computing device may further perform any of the functions and processes described above with reference to .

Various techniques described herein may be implemented in software that may be written in any of a variety of languages making use of any of a variety of toolsets frameworks APIs programming environments virtual machines libraries and other computing resources as indicated above. For example software code may be written in Java C Objective C C Go JavaScript Dart Python Ruby Clojure assembly language machine code or any other language. As one specific illustrative example aspects of the disclosure discussed above may be implemented in a software module written in Java that is executable on virtual machine of for example.

Aspects of the disclosure may be equally applicable and implemented in any computing device or any operating system and using any other APIs frameworks or toolsets. Aspects described herein for decoding and processing of data for force based inputs and non visual outputs which may interact with any other data store or application. When implemented in software or firmware various techniques disclosed herein may be realized at least in part by a computer readable data storage medium comprising instructions that when executed cause a processor to perform one or more of the methods described above. For example the computer readable data storage medium may store such instructions for execution by a processor.

A computer readable medium may form part of a computer program product which may include packaging materials. A computer readable medium may comprise a computer data storage medium such as random access memory RAM read only memory ROM non volatile random access memory NVRAM electrically erasable programmable read only memory EEPROM flash memory magnetic or optical data storage media and the like. In various examples an article of manufacture may comprise one or more computer readable storage media.

In various examples the data storage devices and or memory may comprise computer readable storage media that may comprise non transitory media. The term non transitory may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. In certain examples a non transitory storage medium may store data that can over time change e.g. in RAM or cache . Data storage devices may include any of various forms of volatile memory that may require being periodically electrically refreshed to maintain data in memory but those skilled in the art will recognize that this also constitutes an example of a physical tangible non transitory computer readable data storage device. Executable instructions are stored on a non transitory medium when program code is loaded stored relayed buffered or cached on a non transitory physical medium or device including if only for only a short duration or only in a volatile memory format. Machine readable code may be stored on the data storage devices and or memory and may include executable instructions that are executable by at least one processor. Machine readable code and executable instructions may refer to any form of software code including machine code assembly instructions or assembly language bytecode software code in C or software code written in any higher level programming language that may be compiled or interpreted into executable instructions that may be executable by at least one processor including software code written in languages that treat code as data to be processed or that enable code to manipulate or generate code.

The code or instructions may be software and or firmware executed by processing circuitry including one or more processors such as one or more digital signal processors DSPs general purpose microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects functionality described in this disclosure may be provided within software modules or hardware modules.

The various embodiments described above and depicted in as well as additional embodiments are within the scope of one or more of the following claims.

