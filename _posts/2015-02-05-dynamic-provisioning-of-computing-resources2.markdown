---

title: Dynamic provisioning of computing resources
abstract: Dynamic provisioning of computing resources may be implemented to provision computing resources for a data center or other collection of computing resources. Computing resources for provisioning may be detected. A build manifest describing configuration operations to provision the computing resources to perform respective tasks may be identified. The build manifest may be evaluated to direct the computing resources to perform the configuration operations according to the build manifest. In some embodiments, the provisioning of the computing resources may be paused or undone according to the build manifest. Upon completion of the configuration operations, the computing resources may be made available to perform the respective tasks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09535754&OS=09535754&RS=09535754
owner: Amazon Technologies, Inc.
number: 09535754
owner_city: Reno
owner_country: US
publication_date: 20150205
---
Data centers and other collections of computers that undergird many different systems services or applications are growing in number and complexity. In order to keep up with increased demand for these services additional resources may need to be integrated into new or existing infrastructures in order to begin providing extra capacity for performing different tasks. Provisioning computing resources to add capacity to these services has grown increasingly challenging. Large numbers of computers servers and other equipment are networked together creating a complex environment into which new resources are introduced. While some automated provisioning techniques have been achieved to increase the speed at which new resources may be added constant changes to this environment make it increasingly difficult to adapt automated provisioning techniques to new circumstances.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that the embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

The systems and methods described herein may implement dynamic provisioning of computing resources. Provisioning computing resources to operate within new and existing infrastructures is challenging. Multiple different steps may be performed to configure computing resources such as a server to perform particular tasks or functions. Attempts to automate provisioning processes have created provisioning techniques that relay heavily upon decentralized logic which attempts to try to determine the correct way to build a system based on a large number of variables. Such evaluations may be performed multiple times creating the potential for error and wasted resources. Moreover these automation techniques rely upon preconfigured applications such as ram disks to configure different computing resources. In order to differently provision a computing resource one or multiple new ram disks may have to be created.

Dynamic provisioning of computing resources may allow for centralized control for provisioning computing resources. Build manifests may be centrally created stored and managed to provide simple provisioning workflows to provision computing resources for many different configurations. Build manifests may provide descriptions of configuration operations and decision making to perform the configuration operations so that decision making is consistent instead of on the fly. Provisioning computing resources according to a build manifest allows provisioning of computing resources to succeed or fail quickly and reliably.

For example as computing resource s available for provisioning are detected dynamic provisioning engine may identify a build manifest for the computing resource s . Various selection criteria for instance may be evaluated to select a build manifest that is compatible or best suited to the detected computing resources. Dynamic provisioning engine may then evaluate the identified build manifest to direct the performance of configuration operations at the computing resource. In this way configuration decision making may be moved from the computing resource itself to the dynamic provisioning engine . For instance a build agent may be launched on raw computing resources. The build agent may implement a manifest framework that may perform configuration operations as described in the build manifest. Dynamic provisioning engine may programmatically instruct the build agent to perform the configuration operations via the manifest framework in order to direct the performance of the configuration operations to configure the computing resource as described in the build manifest.

Dynamic provisioning engine may direct the provisioning process to provide provisioned computing resource s ready to perform work. Additionally the build agent and dynamic provisioning engine may collect diagnostic information about the performance of the computing resource and the provisioning process which may be later provided to interested parties and for further analysis. Dynamic provisioning engine may be able to implement centralized control of the provisioning of larger numbers of computing resources being provisioned. Moreover as dynamic provisioning engine directs the performance of the configuration operations provisioning operations may be paused or undone in order to handle different failure scenarios that occur within the provisioning process which may be resolved more efficiently by dynamic provisioning engine .

This specification next includes a general description of a provider network which may implement dynamic provisioning of computing resources. Then various examples of a provider network and dynamic provisioning service are discussed including different components modules or arrangements of components module that may be employed as part of implementing a dynamic provisioning service. A number of different methods and techniques to dynamic provisioning of computing resources are then discussed some of which are illustrated in accompanying flowcharts. Finally a description of an example computing system upon which the various components modules systems devices and or nodes may be implemented is provided. Various examples are provided throughout the specification.

In some embodiments provider network may provide computing resources as part of computing service s . For example these computing resources may in some embodiments be offered to clients in units called instances. A virtual compute instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . A number of different types of computing devices may be used singly or in combination to implement the compute instances of provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like. Compute instances may operate or implement a variety of different platforms such as application server instances Java virtual machines JVMs general purpose or special purpose operating systems platforms that support various interpreted or compiled programming languages such as Ruby Perl Python C C and the like or high performance computing platforms suitable for performing client applications without for example requiring the client to access an instance. In some embodiments compute instances have different types or configurations based on expected uptime ratios. The uptime ratio of a particular compute instance may be defined as the ratio of the amount of time the instance is activated to the total amount of time for which the instance is reserved. Uptime ratios may also be referred to as utilizations in some implementations. If a client expects to use a compute instance for a relatively small fraction of the time for which the instance is reserved e.g. 30 35 of a year long reservation the client may decide to reserve the instance as a Low Uptime Ratio instance and pay a discounted hourly usage fee in accordance with the associated pricing policy. If the client expects to have a steady state workload that requires an instance to be up most of the time the client may reserve a High Uptime Ratio instance and potentially pay an even lower hourly usage fee although in some embodiments the hourly fee may be charged for the entire duration of the reservation regardless of the actual number of hours of use in accordance with pricing policy. An option for Medium Uptime Ratio instances with a corresponding pricing policy may be supported in some embodiments as well where the upfront costs and the per hour costs fall between the corresponding High Uptime Ratio and Low Uptime Ratio costs.

Compute instance configurations may also include compute instances with a general or specific purpose such as computational workloads for compute intensive applications e.g. high traffic web applications ad serving batch processing video encoding distributed analytics high energy physics genome analysis and computational fluid dynamics graphics intensive workloads e.g. game streaming D application streaming server side graphics workloads rendering financial modeling and engineering design memory intensive workloads e.g. high performance databases distributed memory caches in memory analytics genome assembly and analysis and storage optimized workloads e.g. data warehousing and cluster file systems . Size of compute instances such as a particular number of virtual CPU cores memory cache storage as well as any other performance characteristic. Configurations of compute instances may also include their location in a particular data center availability zone geographic location etc. . . . and in the case of reserved compute instances reservation term length.

Provider network may implement control plane to manage the operation of provider network and computing service s . Other service s may implement various functionalities such as resource management network management monitoring and customer account management. Control plane may also implement interface which may be a programmatic and or graphical user interface for client s to access computing service s and other features provided by control plane e.g. account control features .

Computing services like computing service s may be implemented utilizing computing resource s that have been provisioned to perform various tasks as part of the respective computing service. For example provisioned computing resource s may host one or more of the variously configured instances described above. In some embodiments in order to increase or add additional capacity to computing service to handle more clients additional computing resources may be needed. Moreover different configurations of the computing resources may be needed. In various embodiments provider network may implement dynamic provisioning service as part of control plane to provision available computing resources which may be newly acquired resources or decommissioned resources to support computing services .

Clients may encompass any type of client configurable to submit requests to provider network . For example a given client may include a suitable version of a web browser or may include a plug in module or other type of code module configured to execute as an extension to or within an execution environment provided by a web browser. Alternatively a client may encompass an application such as a database application or user interface thereof a media application an office application or any other application that may make use of compute instances or other services offered by computing service s to perform various operations. In some embodiments such an application may include sufficient protocol support e.g. for a suitable version of Hypertext Transfer Protocol HTTP for generating and processing network based services requests without necessarily implementing full browser support for all types of network based data. In some embodiments clients may be configured to generate network based services requests according to a Representational State Transfer REST style network based services architecture a document or message based network based services architecture or another suitable network based services architecture. In some embodiments a client e.g. a computational client may be configured to provide access to a compute instance in a manner that is transparent to applications implement on the client utilizing computational resources provided by the compute instance.

Clients may convey network based services requests to provider network via external network . In various embodiments external network may encompass any suitable combination of networking hardware and protocols necessary to establish network based communications between clients and provider network . For example a network may generally encompass the various telecommunications networks and service providers that collectively implement the Internet. A network may also include private networks such as local area networks LANs or wide area networks WANs as well as public or private wireless networks. For example both a given client and provider network may be respectively provisioned within enterprises having their own internal networks. In such an embodiment a network may include the hardware e.g. modems routers switches load balancers proxy servers etc. and software e.g. protocol stacks accounting software firewall security software etc. necessary to establish a networking link between given client and the Internet as well as between the Internet and provider network . It is noted that in some embodiments clients may communicate with provider network using a private network rather than the public Internet.

Dynamic provisioning service may implement interface which may be a programmatic e.g. an application programming interface API and or graphical user interface via which other systems or devices such as provisioning clients computing resources and other control plane services may communicate with dynamic provisioning service. For example provisioning client s which may be like clients and may be internal or external to provider network may upload generate update delete or otherwise interact with build manifests that are used to provision computing resources. Similarly these provisioning clients or other control plane services may be provided with diagnostics and other data about ongoing provisioning operations e.g. live data streams or query previously collected historical data. In some embodiments provisioning client s may be able send requests to provoke dynamic provisioning service to re provision idle or unused computing resources. Interface may provide support for developing operations tooling that may be implemented at provisioning client s . Interface may also be configured to allow components of dynamic provisioning service to interact with other control plane service s according to their respective interfaces e.g. to perform various configuration and or provisioning tasks .

Dynamic provisioning service may implement provisioning execution discussed in detail below with regard to to direct computing resources such as computing resources to perform configuration operations according to build manifests. Dynamic provisioning service may implement build manifest management as discussed in detail below with regard to to create and manage build manifests for provisioning computing resources to perform respective tasks.

Dynamic provisioning service may implement provisioning data collection and reporting . Provisioning data collection and reporting may provide deep support for access to diagnostic artifacts. For example provisioning data store s may maintain diagnostic s collected during the course of provisioning computing resources. Access to these historical diagnostic s may be made available via provisioning data collection and reporting e.g. servicing various data queries and requests . In some embodiments provisioning data collection and reporting may provide access to live diagnostic data streams allowing operators e.g. client s and services e.g. services to consume live telemetric diagnostic information from systems inside the provisioning service . Provisioning data collection and reporting may provide a framework for components of computing resources to report diagnostics during configuration operations. For example operating system components installed or loaded onto computing resources when performing configuration operations may include active logging components which allow logging and diagnostic operations to be exposed into the dynamic provisioning service . For example when an operating system is instrumented with this active logging framework all of the system logs and other relevant information may be automatically published into dynamic provisioning service allowing for deep inspection via queries and other interface requests and also for live consumption during the provisioning act. Provisioning data collection and reporting may also provide metrics from the provisioning pipeline allowing for automated intelligent pipeline optimization and also allowing for full operational alarming.

Dynamic provisioning service may implement provisioning data store s to provide persistent storage for various data including but not limited to build manifests s execution state diagnostic s and other resource data . For example provisioning data store s may implement an extensive inventory management database for maintaining information about provisioned available and or raw computing resources. Various life cycle management schemes for provisioning and decommissioning computing resources may be managed according to such an inventory management database. Provisioning data store s may utilize local storage such as a local database storage cluster or type of data store or may utilize a storage service of provider network in some embodiments.

Dynamic provisioning of computing resources may occur in three phases in some embodiments. Different interactions may occur during the different phases between a computing resource and dynamic provisioning service . is a block diagram illustrating interactions between a computing resource and a dynamic provisioning service according to some embodiments.

Identification phase illustrates that computing resource may send an indication of itself to dynamic provisioning service . For example computing resource may be configured to attempt to boot over a network from dynamic provisioning service e.g. according to a Preboot Execution Environment implemented on a computing resource PXE . In some embodiments multiple interactions such as discussed below with regard to an identification workflow may be performed to identify or detect computing resource . In configuration phase dynamic provisioning service begins directing computing resource to perform configuration operations according to a build manifest that has been identified for computing resource . For example in some embodiments computing resource may be instructed load or launch build agent e.g. by obtaining loading a ram disk or other application over the network onto the computing resource . Build agent may be an application module component or framework which may allow dynamic provisioning service to direct the performance of configuration operations according to data maintained in a build manifest at dynamic provisioning service or other remote dynamic provisioning engine . For example build agent may implement various inversion of control components to obtain the implementation of and or data to perform various configuration operations from dynamic provisioning service e.g. request and consume data obtained from the build manifest . For instance dynamic provisioning service may programmatically instruct build agent to perform certain configuration operations according to the description of the build manifest as discussed in more detail below with regard to via such inversion of control components.

Completion phase illustrates the completion of provisioning computing resource as configured computing resource . In some embodiments dynamic provisioning service may instruct resource to advertise itself as ready to perform respective tasks. However in some embodiments configured computing resource may perform such an action without the instruction from dynamic provisioning service e.g. due to a boot procedure operating system or application installed at configured computing resource as a result of the configuration operations .

As illustrated in provisioning execution may implement build manifest selection to select or identify a build manifest for a computing resource for provisioning. Resource specific information e.g. such as information received from the computing resource or from other systems may be used to identify the build manifest. In some embodiments capacity planning such as input from another control plane service may be used to select a build manifest. Identifying a build manifest may be performed by analyzing one or more selection criteria for the computing resource. Selection criteria may be the information about the computing resource s such as hardware specifications for the computing resources e.g. processor speed memory amount storage capacity etc. resource supplied information e.g. identifying information physical implementation of the computing resource e.g. region data center fault tolerant zone rack or other information regarding the computing resource and or the capacity planning input . In at least some embodiments the selection criteria may be weighted to allow operators or other control plane components the ability to tune the selection of build manifests.

In the event that a build manifest is not identified for a computing resource manifest the computing resource may be placed into a workflow to be provisioned as storage or additional capacity to perform provisioning tasks e.g. task workers . In some embodiments a notification or other message or indication may be sent requesting the manual selection or upload of a build manifest.

Once the build manifest is identified a computing resource may be ready for active provisioning as illustrated in the configuration phase in . In some embodiments a job or other indication may be placed on a queue such that one or more workers nodes processes or other components of provisioning execution may initiate provisioning. As illustrated in build manifest evaluation may be implemented to evaluate and direct the provisioning of a computing resource. In some embodiments individual worker nodes processes or threads may respectively implement build manifest evaluation so that multiple computing resources may be provisioned in parallel. Build manifest evaluation may get the identified build manifest from build manifest store and begin evaluation of the build manifest. For example as discussed below with regard to a configuration operation in the build manifest may be selected. Execution state may be retrieved from execution state store and build agent may be directed to perform the configuration operation based on the execution state retrieved.

As illustrated in build agent and build manifest evaluation may collect and report diagnostics which may be stored in build diagnostics store . Provisioning execution may implement provisioning error recognition and response which may access and evaluate the diagnostics for errors and responsive actions to be performed such as discussed below with regard to . For example provisioning error recognition and response may request a responsive action by other control plane service s e.g. to correct a failure or problem in a system on which the provisioning of a computing resource may depend . Provisioning error recognition and response may also request that build manifest evaluation take a responsive action e.g. by pausing or undoing provisioning for a computing resource which may or may not be a resource with a detected build error .

In various embodiments build manifests such as build manifest may represent a description of configuration operations that produce the same capacity in the same way each time the build manifest is executed. In other words the manifest may be a point in time snapshot of a provisioning operation which may be concrete and repeatable. Build manifests may describe a particular order or sequence for performing configuration operations. Advancing through each configuration operation may allow a provisioning engine to provision for performing respective tasks. However build manifests may also include undo operations or version of configuration operations which may allow the different configuration operations to be partially or fully undone. For example retreating back through configuration operations undoing each configuration operation in reverse order may be performed to decommission a computing resource. Build manifests may also include retry policies and other information for handling unsuccessful attempts to perform a configuration operation in some embodiments.

Configuration operations may be idempotent and orthogonal. However as illustrated in configuration operations may be informed by provisioning execution state maintained for a computing resource. For example a database or other persistent store may be used in some embodiments to maintain state information parameters variables and other data that informs the performance of a configuration operation. Configuration operations may result in access to provisioning execution state reading and writing new information which have been generated as a result of performing the configuration operation . Configuration operations may be transactional in some embodiments such that the tasks actions or changes to data or computing resource contained in a configuration operation can succeed or fail as a unit.

In at least some embodiments build manifest management may implement build manifest generator . Build manifest generator may take one or more build manifest artifacts which may be settings configurations identifiers or other information describing the desired resultant configuration of a computing resource and generate a build manifest including the configuration operations to achieve the desired configuration. For large distributed systems such as provider networks offering multiple network based services many stakeholders may be involved in the generation of build manifests. As illustrated in provisioning client s operated by the different stakeholders may submit build artifact s or inputs requests which lead to the creation of build artifact s via interface to build manifest generator . Once generated build manifest generator may store the generated build manifest in a data store for build manifests .

Build manifest management may implement build manifest version control in some embodiments to manage stored build manifests. For instance in addition generating build manifests requests to update build manifests may be sent from clients via interface . For example a request may be sent to update one or more configuration operations of a build manifest. As a result of this request build manifest version control may generate or instigate the generation of a new version of the build manifest including the updated configuration operations. Build manifest version control may update build manifest s store to include the new version of the manifest. Build manifest version control may also receive requests to delete manifests via interface . Correspondingly build manifest version control may delete the identified build manifests from build manifest s store or mark them as unavailable for subsequent use for provisioning .

The examples of implementing dynamic provisioning of computing resources discussed above with regard to have been given in regard to virtual computing resources offered by a provider network. Various other types or configurations of systems or services may implement these techniques. For example in some embodiments a provisioning engine and or service may be implemented in a single computing device to provision computing resources. Moreover the tasks location or environment for which computing resources are provisioned e.g. rack room data center fault tolerance zone may vary. is high level flowchart illustrating various methods and techniques for dynamic provisioning of computing resources according to some embodiments. These techniques may be implemented using various components or nodes of a system as described above or other systems or devices.

As indicated at computing resource s for provisioning may be detected in some embodiments. For example when a new computing resource is added to a network in a data center or other collection of network computing devices the computing resources may send an indication identifying itself to a provisioning engine or service which may detect the computing resource based on the indication. In another example as new computing resources are added information indicating the new computing resources may be entered into a database or other system that maintains information about computing resources in a data center or collection of computing resources. The database may be periodically queried or scanned for new entries to detect new computing resources for provisioning.

As indicated at a build manifest may be identified to provision the computing resource s for performing respective task s . A default build manifest may be selected in some embodiments. In some embodiments a specific build manifest may identified or indicated in information provided to a provisioning engine. However as discussed above multiple build manifests may be maintained for provisioning a system to perform different respective tasks in some embodiments. For example the computing resources may be provisioned to add additional capacity to serve more clients of a network based service such as the computing services discussed above with regard to . In another example the computing resources may be provisioned to perform tasks or functions for a system that is not yet online or operational. In some embodiments identifying the build manifest may be based on identifying which tasks the computing resource s should perform. For instance in a system where the computing resource s may be provisioned to do different tasks e.g. for different services or different components of a system or service a selection may be made from among the multiple different build manifests.

In at least some embodiments identifying a build manifest may be performed by analyzing one or more selection criteria for the computing resource s . As discussed above with regard to selection criteria may be information about the computing resource s such as hardware specifications for the computing resources e.g. processor speed memory amount storage capacity etc. resource supplied information e.g. identifying information physical implementation of the computing resource e.g. region data center fault tolerant zone rack or other information regarding the computing resource. Other input or data such as need for particular resources to perform tasks e.g. input from a capacity planning system . In at least some embodiments the selection criteria may be weighted. Requests to modify weightings of scores may be received to increase the selection of particular build manifests in some embodiments. For example if a capacity planning system identifies that resources of a certain configuration are needed to meet the demand of a particular function of a network based service then the capacity planning system may request that criteria which determine whether a build manifest that provisions resources to perform the particular function be increased in weight so that computing resources which may be configurable to perform the needed function are provisioned according to the build manifest which results in the desired configuration.

As indicated at and the build manifest may be evaluated and performance of the configuration operations of the identified build manifest at the computing resource s may be directed in some embodiments. As discussed in more detail below with regard to a build manifest framework or other component such as build agent discussed above with regard to implemented at the computing resources may be utilized to allow a provisioning engine system or service which is remote from the computing resources to programmatically control the performance of configuration operations at the computing resources. Once the configuration is complete as indicated by the positive exit from the configured computing resources may be made available for performing the respective task s . For example the configured computing resources may be identified to a control plane system as available to begin receiving workload.

Build manifests may allow a provisioning engine or other system or device implementing the above techniques to drive the provisioning of computing resources for particular tasks systems or services removing the responsibility for decision making and other provisioning tasks from a computing resource itself. The operations described in a build manifest to configure computing resources may be used to allow provisioning to be consistently and repeatable performed for multiple computing resources to be provisioned to perform the same tasks. is a high level flowchart illustrating various methods and techniques for directing the performance of configuration operations to provision computing resources according to a build manifest according to some embodiments.

As indicated at when evaluating a build manifest a next configuration operation to perform may be determined in some embodiments. For example as described above with regard to a build manifest may describe an ordering or sequence in which configuration operations may be performed. The next configuration operation may be determined according to the ordering or sequence in the build manifest. As indicated at execution state for the provisioning may be accessed in some embodiments. Execution state as described above with regard to may describe common data parameters variables or other information which may be used to perform a determined configuration operation. For example the results of a previously performed configuration operation e.g. a particular resource configuration or information obtained may be used as input to perform the next configuration operation.

As indicated at a build agent at a computing resource may be programmatically instructed to perform the next configuration operation based at least in part on the execution state in some embodiments. For example as discussed above with regard to the manifest frame execution platform or other implementation located at a computing resource being provisioned such as a build agent may be able to receive data that indicates the action s to be taken to perform the configuration operation. Inversion of control components or techniques may be implemented at the computing resource allowing the configuration operation to be programmatically injected into the computing resource e.g. into a ram disk or other set of instructions performed at the computing resource . As noted above the execution state may provide input variables or other information for performing the next configuration operation which may be provided or included in the instructions to the build agent.

As indicated at the execution state may be updated to reflect the performance of the next configuration operation. For example results and or other information may be obtained at the build agent after performing the configuration may be recorded or written to the execution state. Additionally state information describing completed configuration operations for the provisioning of the computing resource may be updated to indicate the completed next configuration operation. In at least some embodiments elements and may be performed as a single transaction which either completes or does not complete. Though a configuration operation may include multiple different tasks or steps to be performed completed steps or tasks may be rolled back or undone if one of the tasks or steps fails to complete.

Directing the performance of configuration operations in a build manifest may be performed iteratively as indicated at . The next configuration operation may be performed as illustrated by the negative exit from until all of the configuration operations for a build manifest are performed and configuration is complete as indicated by the positive exit from . Since the performance of provisioning may be driven by a provisioning engine or other system or device that is remote from the computing resource being provisioned the provisioning itself may be paused or fully or partially undone as discussed above with regard to . In this way a provisioning engine may manage the state of any resource undergoing provisioning controlling when a computing resource advances or retreats to a prior state achieved by the performance or undoing of a configuration operation.

For example as indicated at an undo event for a provisioning may be detected during the iterative performance of configuration operations illustrated in . The undo event may be triggered to partially or fully remove the effects of provisioning a computing resource e.g. returning the resource to a different configuration . As indicated at select configuration operations may be undone. For example as discussed above with regard to a build manifest may describe an undo operations for each configuration operation in a build manifest to reverse the effects of the performance of the configuration operation e.g. return a storage device to a prior format relinquish an assigned network address etc. . The corresponding undo operations may be performed for identified configuration operations in some embodiments in a manner similar to that illustrated at elements through by programmatically instructing a build agent to perform the undo operations. In this way provisioning of a computing resource may move forward or backward along a sequence of configuration operations e.g. in order to troubleshoot at what point a particular problem occurs . In at least some embodiments a decommissioning event may detected similar to an undo event which may be similarly handled to perform the undo operations described in a build manifest used to provision a computing resource to return the resource to a raw or decommissioned state available for provisioning for other tasks or removal .

A pause event may be detected as indicated at in at least some embodiments. For instance the number of provisioning operations ongoing may need to be throttled so as not to overwhelm other control plane systems or dependencies on which the provisioning relies. In some embodiments as discussed below an error condition or failure scenario for another computing resource in provisioning may trigger a pause event for other computing resources to prevent those resources from having the same error occur. A resume event as indicated at may be detected which allows provisioning to continue. In some embodiments an undo event may follow a resume event not illustrated . Please note that is provided for illustrative purposes and is not intended to be limiting as to the particular ordering of elements depicted.

Diagnostic information provisioning performance metrics and other information as noted earlier may be collected during the performance of provisioning for various computing resources. In addition to providing the diagnostic information to provisioning clients or other systems or devices the diagnostics may be stored and evaluated using machine learning or other data analysis techniques to identify problems that occur during provisioning and appropriate corrective responses or other improvements that may be performed or implemented. For example in some embodiments responsive actions such as repairing certain failure conditions may be automatically or dynamically detected and performed. is a high level flowchart illustrating various methods and techniques for performing responsive actions to build errors detected in provisioning computing resources according to some embodiments.

As indicated at a build error for a computing resource in provisioning may be detected. For instance a configuration operation performed at a host may be unable to complete due to some failing dependency. Consider the example of a network address allocation system which may be separate from a provisioning engine or other entity implementing the aforementioned techniques may have no more network addresses allocated to assign to computing resources currently being provisioned. The configuration operation performed as described in a build manifest may programmatically instruct a build agent at a computing resource to obtain a network address from the network address allocation system. The configuration operation may return a build error as no more network addresses are available.

Provisioning diagnostics may be evaluated to determine a responsive action for the detected build error as indicated at in some embodiments. For example diagnostics information for previous instances of provisioning may be analyzed to identify particular error codes behaviors or other signifiers that may determinatively point to what the detected error is. In the example given above it may be that all failures that occur at a common configuration operation in the particular build manifest being used to provision the computing resources occur as a result of a lack of network addresses available to allocate to a computing resource. The diagnostic information may also describe responsive actions taken to correct or alleviate the detected build error. For example particular API calls requests or other actions taken to initiate the allocation of additional network addresses at the network address allocation system may be performed. In some embodiments the responsive action for the detected build error may be to flag or identify the computing resource for manual evaluation by a technician or engineer e.g. by sending a notification or posting to a maintenance reporting system . Many different machine learning data mining or other analysis techniques may be implemented to determine the build error and responsive action and thus the previous examples is not intended to be limiting.

In at least some embodiments as indicated at the performance of provisioning other computing resource s may be modified as part of the responsive action for the detected build error. As in the given example other computing resources being provisioned using the same build manifest or another build manifest that includes a configuration operation with a similar dependency on the network address allocation system may be identified. A pause event such as discussed above with regard to may be triggered to pause the performance of the provisioning until more network addresses have been allocated. In another example undo operations may be performed at other computing resources to return the computing resources to a prior configuration. As noted above other responsive actions whether performing other automated responses or fixes or notifying technicians or engineers of the affected computing resources may be performed. In at least some embodiments the configuration operations of a common or similar build manifest that would result in the build error may be undone such as described above with regard to and a different build manifest which may have configuration operations that do not result in the build error may be used to provision the computing resources. In this way build errors may be dynamically handled or predicated without each computing resource affected by a common dependency having to trigger the same build error and initiate the same responsive actions.

The methods described herein may in various embodiments be implemented by any combination of hardware and software. For example in one embodiment the methods may be implemented by a computer system e.g. a computer system as in that includes one or more processors executing program instructions stored on a computer readable storage medium coupled to the processors. The program instructions may be configured to implement the functionality described herein e.g. the functionality of various servers and other components that implement the distributed systems described herein . The various methods as illustrated in the figures and described herein represent example embodiments of methods. The order of any method may be changed and various elements may be added reordered combined omitted modified etc.

Embodiments of dynamic provisioning of computing resources as described herein may be executed on one or more computer systems which may interact with various other devices. is a block diagram illustrating an example computer system according to various embodiments. For example computer system may be configured to implement one or more nodes of a compute cluster that implements the provisioning engine or service described above the network based services such as a computing service or storage service and or clients or other systems or devices described above in different embodiments. Computer system may be any of various types of devices including but not limited to a personal computer system desktop computer laptop or notebook computer mainframe computer system handheld computer workstation network computer a consumer device application server storage device telephone mobile telephone or in general any type of computing device.

Computer system includes one or more processors any of which may include multiple cores which may be single or multi threaded coupled to a system memory via an input output I O interface . Computer system further includes a network interface coupled to I O interface . In various embodiments computer system may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA. The computer system also includes one or more network communication devices e.g. network interface for communicating with other systems and or components over a communications network e.g. Internet LAN etc. . For example a client application executing on system may use network interface to communicate with a server application executing on a single server or on a cluster of servers that implement one or more of the components of the data warehouse system described herein. In another example an instance of a server application executing on computer system may use network interface to communicate with other instances of the server application or another server application that may be implemented on other computer systems e.g. computer systems .

In the illustrated embodiment computer system also includes one or more persistent storage devices and or one or more I O devices . In various embodiments persistent storage devices may correspond to disk drives tape drives solid state memory other mass storage devices or any other persistent storage device. Computer system or a distributed application or operating system operating thereon may store instructions and or data in persistent storage devices as desired and may retrieve the stored instruction and or data as needed. For example in some embodiments computer system may host a storage system server node and persistent storage may include the SSDs attached to that server node.

Computer system includes one or more system memories that are configured to store instructions and data accessible by processor s . In various embodiments system memories may be implemented using any suitable memory technology e.g. one or more of cache static random access memory SRAM DRAM RDRAM EDO RAM DDR 10 RAM synchronous dynamic RAM SDRAM Rambus RAM EEPROM non volatile Flash type memory or any other type of memory . System memory may contain program instructions that are executable by processor s to implement the methods and techniques described herein. In various embodiments program instructions may be encoded in platform native binary any interpreted language such as Java byte code or in any other language such as C C Java etc. or in any combination thereof. For example in the illustrated embodiment program instructions include program instructions executable to implement the functionality of a virtual computing resource provider network in different embodiments. In some embodiments program instructions may implement multiple separate clients server nodes and or other components.

In some embodiments program instructions may include instructions executable to implement an operating system not shown which may be any of various operating systems such as UNIX LINUX Solaris MacOS Windows etc. Any or all of program instructions may be provided as a computer program product or software that may include a non transitory computer readable storage medium having stored thereon instructions which may be used to program a computer system or other electronic devices to perform a process according to various embodiments. A non transitory computer readable storage medium may include any mechanism for storing information in a form e.g. software processing application readable by a machine e.g. a computer . Generally speaking a non transitory computer accessible medium may include computer readable storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM coupled to computer system via I O interface . A non transitory computer readable storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc. that may be included in some embodiments of computer system as system memory or another type of memory. In other embodiments program instructions may be communicated using optical acoustical or other form of propagated signal e.g. carrier waves infrared signals digital signals etc. conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface .

In some embodiments system memory may include data store which may be configured as described herein. In general system memory e.g. data store within system memory persistent storage and or remote storage may store data blocks replicas of data blocks metadata associated with data blocks and or their state configuration information and or any other information usable in implementing the methods and techniques described herein.

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the system including through network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computer system and other devices attached to a network such as other computer systems which may implement one or more storage system server nodes database engine head nodes and or clients of the database systems described herein for example. In addition network interface may be configured to allow communication between computer system and various I O devices and or remote storage . Input output devices may in some embodiments include one or more display terminals keyboards keypads touchpads scanning devices voice or optical recognition devices or any other devices suitable for entering or retrieving data by one or more computer systems . Multiple input output devices may be present in computer system or may be distributed on various nodes of a distributed system that includes computer system . In some embodiments similar input output devices may be separate from computer system and may interact with one or more nodes of a distributed system that includes computer system through a wired or wireless connection such as over network interface . Network interface may commonly support one or more wireless networking protocols e.g. Wi Fi IEEE 802.11 or another wireless networking standard . However in various embodiments network interface may support communication via any suitable wired or wireless general data networks such as other types of Ethernet networks for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol. In various embodiments computer system may include more fewer or different components than those illustrated in e.g. displays video cards audio cards peripheral devices other network interfaces such as an ATM interface an Ethernet interface a Frame Relay interface etc. 

It is noted that any of the distributed system embodiments described herein or any of their components may be implemented as one or more network based services. For example a compute cluster within a computing service may present computing services and or other types of services that employ the distributed computing systems described herein to clients as network based services. In some embodiments a network based service may be implemented by a software and or hardware system designed to support interoperable machine to machine interaction over a network. A network based service may have an interface described in a machine processable format such as the Web Services Description Language WSDL . Other systems may interact with the network based service in a manner prescribed by the description of the network based service s interface. For example the network based service may define various operations that other systems may invoke and may define a particular application programming interface API to which other systems may be expected to conform when requesting the various operations. though

In various embodiments a network based service may be requested or invoked through the use of a message that includes parameters and or data associated with the network based services request. Such a message may be formatted according to a particular markup language such as Extensible Markup Language XML and or may be encapsulated using a protocol such as Simple Object Access Protocol SOAP . To perform a network based services request a network based services client may assemble a message including the request and convey the message to an addressable endpoint e.g. a Uniform Resource Locator URL corresponding to the network based service using an Internet based application layer transfer protocol such as Hypertext Transfer Protocol HTTP .

In some embodiments network based services may be implemented using Representational State Transfer RESTful techniques rather than message based techniques. For example a network based service implemented according to a RESTful technique may be invoked through parameters included within an HTTP method such as PUT GET or DELETE rather than encapsulated within a SOAP message.

Although the embodiments above have been described in considerable detail numerous variations and modifications may be made as would become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such modifications and changes and accordingly the above description to be regarded in an illustrative rather than a restrictive sense.

