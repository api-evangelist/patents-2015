---

title: Predicting video start times for maximizing user engagement
abstract: Implementations disclose predicting video start times for maximizing user engagement. A method includes applying a machine-learned model to audio-visual content features of segments of a target content item, the machine-learned model trained based on user interaction signals and audio-visual content features of a training set of content item segments, calculating, based on applying the machine-learned model, a salience score for each of the segments of the target content item, and selecting, based on the calculated salience scores, one of the segments of the target content item as a starting point for playback of the target content item.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09659218&OS=09659218&RS=09659218
owner: Google Inc.
number: 09659218
owner_city: Mountain View
owner_country: US
publication_date: 20150429
---
This disclosure relates to the field of content sharing platforms and in particular to predicting video start times for maximizing user engagement.

On the Internet social networks allow users to connect to and share information with each other. Many social networks include a content sharing aspect that allows users to upload view and share content such as video content image content audio content text content and so on which may be collectively referred to as media items or content items . Such viewable and shareable media items may include audio clips movie clips TV clips and music videos as well as amateur content such as video blogging short original videos pictures photos other multimedia content etc. Users may use computing devices such as smart phones cellular phones laptop computers desktop computers netbooks tablet computers network connected televisions to use play and or consume media items e.g. watch digital videos and or listen to digital music .

The following is a simplified summary of the disclosure in order to provide a basic understanding of some aspects of the disclosure. This summary is not an extensive overview of the disclosure. It is intended to neither identify key or critical elements of the disclosure nor delineate any scope of the particular implementations of the disclosure or any scope of the claims. Its sole purpose is to present some concepts of the disclosure in a simplified form as a prelude to the more detailed description that is presented later.

In an aspect of the disclosure a method includes applying a machine learned model to audio visual content features of segments of a target content item the machine learned model trained based on user interaction signals and audio visual content features of a training set of content item segments calculating based on applying the machine learned model a salience score for each of the segments of the target content item and selecting based on the calculated salience scores one of the segments of the target content item as a starting point for playback of the target content item.

In one implementation the user interaction signals include at least one of scrubbing in the content item segments seeking to the content item segments sharing at a timestamp of the content item segments or quitting at a timestamp of the content item segments. In another implementation the audio visual content features include at least one of low level color features low level texture features semantic embedding features audio volume levels or annotations from classifiers training on audio visual vocabularies.

Furthermore each content item segment of the training set may be assigned an assumed salience score based on the user interaction signals corresponding to the content item segment. In addition the machine learned model may be trained by generating a function that predicts the assumed salience score for the content item segment using the audio visual content features of the content item segment as inputs to the function. In some implementations the machine learned model is a pairwise ranking model.

In a further implementation the playback of the target content item includes auto play of the target content item via starting the playback of the target content item at the selected one of the segments without any user intervention. In addition the target content item may be a video. Furthermore selecting the one of the segments in the method may further be based on one or more logic rules limiting where the playback of the target content item is to begin. In another implementation additional user interaction signals corresponding to the playback of the target content item may be used as feedback to training the machine learned model.

In an additional implementation calculating the salience score for each of the segments of the target content item in the method further includes receiving the target content item for the playback dividing the target content item into the segments extracting values corresponding to audio visual content features from each of the segments inputting for each of the segments the extracted values corresponding to the audio visual content features from the segment to a function of the machine learned model and receiving from the function for each of the segments a calculated salience score for the segment.

Computing devices for performing the operations of the above described method and the various implementations described herein are disclosed. Computer readable media that store instructions for performing operations associated with the above described method and the various implementations described herein are also disclosed.

Aspects and implementations of the disclosure are directed to predicting video start times for maximizing user engagement. Implementations are described for enabling automatic identification of salient segments of a video by using a combination of user interaction analytics and video content analysis. A salient segment e.g. clip portion point may refer to a noticeable important relevant and or interesting segment of the video. These identified salient segments may then be used as starting points from which to auto play the video. Auto play refers to starting playback of a video without any user interaction.

In order to identify a salient segment of a video implementations of the disclosure may use a combination of analysis of previous user interactions with the video and computational analysis of audio video content features of the video. In one implementation a machine learned model is built i.e. trained and utilized to identify the salient segments of videos.

Auto play is a popular means for consuming videos on mobile interfaces. Most auto play experiences start from the beginning of the video where there is often non salient content e.g. title screen setup whereas most of the salient portions of the video may be further into playback of the video. Users often have very limited time in which they decide whether to consume a video. Spending this time in the non salient portions of the video is not optimal. Prior solutions typically do not offer a preview of what is salient e.g. exciting relevant and or interesting in a video as part of an auto play experience.

Implementations of the disclosure overcome the limitations of the prior solutions for predicting video start times for maximizing user engagement by providing automatic identification of salient segments of a video by using a combination of user interaction analytics and video content analysis. These identified interesting segments may then be used as starting points from which to auto play the video in order to persuade a user to watch the whole video. This significantly improves the user s experience with auto play and also improves overall engagement with videos on the content sharing platform. In addition implementations of the disclosure lower the work a user has to do when deciding whether to watch a video. The user is saved time spent on a video which could mean allowing the user to explore a larger part of the video corpus of the content sharing platform improving the user s engagement with content of the content sharing platform and improving overall experience and perception of the content sharing platform.

Implementations of the disclosure often reference videos for simplicity and brevity. However the teachings of the disclosure are applied to media items generally and can be applied to various types of content or media items including for example video audio text images program instructions etc.

The client devices A through Z may each include computing devices such as personal computers PCs laptops mobile phones smart phones tablet computers netbook computers network connected televisions etc. In some implementations client device A through Z may also be referred to as user devices. Each client device includes a media viewer . In one implementation the media viewers may be applications that allow users to view content such as images videos web pages documents etc. For example the media viewer may be a web browser that can access retrieve present and or navigate content e.g. web pages such as Hyper Text Markup Language HTML pages digital media items etc. served by a web server. The media viewer may render display and or present the content e.g. a web page a media viewer to a user. The media viewer may also display an embedded media player e.g. a Flash player or an HTML5 player that is embedded in a web page e.g. a web page that may provide information about a product sold by an online merchant . In another example the media viewer may be a standalone application that allows users to view digital media items e.g. digital videos digital images electronic books etc. .

The media viewers may be provided to the client devices A through Z by the server and or content sharing platform . For example the media viewers may be embedded media players that are embedded in web pages provided by the content sharing platform . In another example the media viewers may be applications that are downloaded from the server .

In general functions described in one implementation as being performed by the content sharing platform can also be performed on the client devices A through Z in other implementations if appropriate. In addition the functionality attributed to a particular component can be performed by different or multiple components operating together. The content sharing platform can also be accessed as a service provided to other systems or devices through appropriate application programming interfaces and thus is not limited to use in websites.

In one implementation the content sharing platform may be one or more computing devices such as a rackmount server a router computer a server computer a personal computer a mainframe computer a laptop computer a tablet computer a desktop computer etc. data stores e.g. hard disks memories databases networks software components and or hardware components that may be used to provide a user with access to media items and or provide the media items to the user. For example the content sharing platform may allow a user to consume upload search for approve of like dislike and or comment on media items. The content sharing platform may also include a website e.g. a webpage or application back end software that may be used to provide a user with access to the media items.

In implementations of the disclosure a user may be represented as a single individual. However other implementations of the disclosure encompass a user being an entity controlled by a set of users and or an automated source. For example a set of individual users federated as a community in a social network may be considered a user . In another example an automated consumer may be an automated ingestion pipeline such as a topic channel of the content sharing platform .

The content sharing platform may include multiple channels e.g. channels A through Z . A channel can be data content available from a common source or data content having a common topic theme or substance. The data content can be digital content chosen by a user digital content made available by a user digital content uploaded by a user digital content chosen by a content provider digital content chosen by a broadcaster etc. For example a channel X can include videos Y and Z. A channel can be associated with an owner who is a user that can perform actions on the channel. Different activities can be associated with the channel based on the owner s actions such as the owner making digital content available on the channel the owner selecting e.g. liking digital content associated with another channel the owner commenting on digital content associated with another channel etc. The activities associated with the channel can be collected into an activity feed for the channel. Users other than the owner of the channel can subscribe to one or more channels in which they are interested. The concept of subscribing may also be referred to as liking following friending and so on.

Once a user subscribes to a channel the user can be presented with information from the channel s activity feed. If a user subscribes to multiple channels the activity feed for each channel to which the user is subscribed can be combined into a syndicated activity feed. Information from the syndicated activity feed can be presented to the user. Channels may have their own feeds. For example when navigating to a home page of a channel on the content sharing platform feed items produced by that channel may be shown on the channel home page. Users may have a syndicated feed which is a feed comprised of at least a subset of the content items from all of the channels to which the user is subscribed to. Syndicated feeds may also include content items from channels that the user is not subscribed to. For example the content sharing platform or other social networks may insert recommended content items into the user s syndicated feed or may insert content items associated with a related connection of the user in the syndicated feed.

Each channel may include one or more media items . Examples of a media item can include and are not limited to digital video digital movies digital photos digital music website content social media updates electronic books ebooks electronic magazines digital newspapers digital audio books electronic journals web blogs real simple syndication RSS feeds electronic comic books software applications etc. In some implementations media item is also referred to as a content item.

A media item may be consumed via the Internet and or via a mobile device application. For brevity and simplicity an online video also hereinafter referred to as a video is used as an example of a media item throughout this document. As used herein media media item online media item digital media digital media item content and content item can include an electronic file that can be executed or loaded using software firmware or hardware configured to present the digital media item to an entity. In one implementation the content sharing platform may store the media items using the data store .

In one implementation the server may be one or more computing devices e.g. a rackmount server a server computer etc. . In one implementation the server may be included in the content sharing platform . The server may include a start time prediction system . In one implementation the start time prediction system enables automatic identification of salient segments of a video by using a combination of user interaction analytics and video content analysis. A salient segment e.g. clip portion point may refer to a noticeable important relevant and or interesting segment of the video based on general user interactions on the content sharing platform with the video. These identified salient segments may then be used as starting points from which to auto play the video. Auto play refers to the act of starting playback of a video without any user interaction. Auto playing a video from a salient segment can significantly improve a user s experience with auto play and also improve overall engagement with videos on the content sharing platform. Implementations of the disclosure are not limited to the auto play context and may encompass utilizing predicted salient segments of videos for start times in other contexts than auto play.

In order to identify a salient segment of a video implementations of the disclosure may use a combination of analysis of previous user interactions with the video and computational analysis of audio video content features of the video. In one implementation a machine learned model is built i.e. trained and utilized to identify the salient segments of videos.

In some implementations start time prediction system of server may interact with content sharing platform and or with other third party social network servers to provide implementations of the disclosure. Further description of the start time prediction system and its specific functions is described in more detail below with respect to .

Although implementations of the disclosure are discussed in terms of content sharing platforms and promoting social network sharing of a content item on the content sharing platform implementations may also be generally applied to any type of social network providing connections between users. Implementations of the disclosure are not limited to content sharing platforms that provide channel subscriptions to users.

In situations in which the systems discussed here collect personal information about users or may make use of personal information the users may be provided with an opportunity to control whether the content sharing platform collects user information e.g. information about a user s social network social actions or activities profession a user s preferences or a user s current location or to control whether and or how to receive content from the content server that may be more relevant to the user. In addition certain data may be treated in one or more ways before it is stored or used so that personally identifiable information is removed. For example a user s identity may be treated so that no personally identifiable information can be determined for the user or a user s geographic location may be generalized where location information is obtained such as to a city ZIP code or state level so that a particular location of a user cannot be determined. Thus the user may have control over how information is collected about the user and used by the content sharing platform .

The start time prediction system is communicatively coupled to the data store . For example the start time prediction system may be coupled to the data store via a network e.g. via network as illustrated in . In another example the start time prediction system may be coupled directly to a server where the start time prediction system resides e.g. may be directly coupled to server . The data store may be a memory e.g. random access memory a cache a drive e.g. a hard drive a flash drive a database system or another type of component or device capable of storing data. The data store may also include multiple storage components e.g. multiple drives or multiple databases that may also span multiple computing devices e.g. multiple server computers . The data store includes content item data training data salience model data and auto play data .

As discussed above the start time prediction system enables automatic identification of salient segments of a video by using a combination of user interaction analytics and video content analysis. A salient segment e.g. clip portion point may refer to a noticeable important relevant and or interesting segment of the video. These identified salient segments may then be used as starting points from which to auto play the video. Auto play refers to the act of starting playback of a video without any user interaction. Auto playing a video from a salient segment can significantly improve a user s experience with auto play and also improve overall engagement with videos on the content sharing platform.

In order to identify a salient segment of video the start time prediction module may use a combination of analysis of how users have previously interacted with the video and computational analysis of audio video content features of the video. In one implementation the training module builds a machine learned model to identify salient segments of videos.

To build the machine learned model the training module first identifies a training set of video segments segments may also be referred to as clips portions or snippets herein . In one implementation the length of the video segments may vary from one segment to another and may be based on natural segmentation with the video such as scene changes narration changes and so on. In other implementations the video segments are each of a uniform duration. Video segments may be obtained from content item data stored in data store .

The training module may utilize user interaction signals for the training set and attach assumed salience values to the video segments from the training set . User interaction signals may include both active and passive user interaction signals. Active user interaction signals may include but are not limited to scrubbing e.g. manually moving forward or backward through the video via interaction with a scrollbar in a segment seeking to the segment and sharing at a particular timestamp that is in a segment. Passive user interaction signals may include but are not limited to quitting at a particular timestamp that is in a segment also referred to as audience retention statistic .

The user interaction signals corresponding to each video segment may be used by the training module to associate a salience value or salience score to the video segment. For example the user interaction signal of the audience retention statistic may be used to assign to each video segment of the training set a salience score corresponding to the retention of audience relative to other similar videos. If the score is high it is indicative of a salient segment of a video. The training set and associated salience scores may be stored as training data in data store .

In some implementations data other than user interaction signals is relied upon to predict a salience of a video segment for the training set . For example a frequency of upload of a segment of a movie can be used to infer that this portion of the movie is a more interesting i.e. more salient segment of the movie. In other implementations creation of Graphics Interchange Format images GIFs or other images from a segment of video can indicate that the segment is an interesting e.g. salient portion of the video. In some implementations more than one user interaction signal or other signal data is used for the training set corresponding salience scores of video segments from the training set .

Once a training set is identified a ranking module is trained using audio visual content features extracted from the video segments along with the salience scores corresponding to the segments. The audio visual content features may include but are not limited to low level color and texture features semantic embedding features audio volume levels and annotations from classifiers training on audio visual vocabularies. In one implementation the ranking module is a pairwise ranking model. In the pairwise ranking model it is assumed that the saliency clip A saliency clip B . Then a salience score function is learned so that when a feature vector of audio visual content features from clip A is used as input to the salience score function a salience score is generated that is higher than a salience score generated from the function with the feature vector from clip B used as input.

The end result of the training by training module is to create a function that can predict a salience score for any segment of a content item that is inputted into the function. The function of the trained model may be stored as salience model data of data store .

The salient segment prediction module of start time prediction system may apply the function learned from training module to determine one or more salient segments of a target video also referred to herein as a target content item . In one implementation the target video is the result of a search query or a browsing session. In another implementation the target video is part of a playlist or other set of content items presented to a user of the content sharing platform. The salient segment prediction module may temporally segment a target video into clips or segments. As discussed above the segments may correspond to natural breaks within the video and may vary in length. In other implementations the segments may be of a uniform length.

The salient segment prediction module may then apply the function of the trained model to each of the generated segments of the video to obtain a predicted salience score for each segment. In one implementation an audio visual feature vector is extracted from each segment and used as the input to the function to generate the salience score for the segment.

In some implementations a relevance score indicating relevance of a segment to user context e.g. query can also be incorporated into the predicted salience scoring performed by salient segment prediction module . For example if a user searches for a particular term such as giraffe the salient segment prediction module may use metadata associated with each segment to identify those segments corresponding to giraffes as candidates for selection as opposed to selecting the highest overall salience score clip which may have some other animals in it .

The auto play module may then utilize the salience scores predicted for each segment of the target video by the salient segment prediction module in order to select a segment from which to automatically start playback of the target video. The UI generation module may then provide data to a client device in order to render a UI that auto plays the target video from the selected segment.

In one implementation the auto play module may select the segment with the highest salience score to start auto playback of the target video. In other implementations the auto play module may identify the top X number or top X percentage of the target video segments in terms of predicted salience score and then select one of these segments e.g. randomly or otherwise to start auto playback of the target video. In some implementations other selection logic may be applied by the auto play module such as not skipping more than X of the video. For example if the most salient segment occurs at the 60 mark and the additional selection logic indicates that more than 50 of the video should not be skipped then the selection logic of the auto play module dictates that the most salient segment starting at 

The segment selected for auto playback of the target video as well as feedback e.g. did users quit during segment did users scrub in segment did users share during the segment etc. associated with auto playing the target video from the selected segment may be stored in auto play data of data store . In one implementation the feedback from user interactions with an auto played segment selected based on predicted salience score can be used to inform training of the machine learned model by training module .

By selecting a high scoring salience video segment to auto start playback of a target video a user may be more likely to enjoy the segment of the video and continue watching the target video for longer than if the user had started watching the target video from the beginning. In some implementations the user is also offered an option to start playback of the target video from the beginning of the video in the event that the user anticipates that he or she may enjoy watching the entire video.

For simplicity of explanation the methods of this disclosure are depicted and described as a series of acts. However acts in accordance with this disclosure can occur in various orders and or concurrently and with other acts not presented and described herein. Furthermore not all illustrated acts may be required to implement the methods in accordance with the disclosed subject matter. In addition those skilled in the art will understand and appreciate that the methods could alternatively be represented as a series of interrelated states via a state diagram or events. Additionally it should be appreciated that the methods disclosed in this specification are capable of being stored on an article of manufacture to facilitate transporting and transferring such methods to computing devices. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device or storage media. In one implementation method may be performed by start time prediction system as shown in .

Method begins at block when a set of segments from one or more videos of a content sharing platform are extracted. Then at block user interaction signals associated with each segment are analyzed. At block a salience score is assigned to each segment based on the analysis of the user interaction signals. In one implementation a higher salience score corresponds to a higher salience of the segment.

Subsequently at block audio visual content feature values are extracted from each of the segments. Then at block a ranking model is trained using the audio visual content features in order to generate a function that predicts that assigned salience score corresponding to each segment. Lastly at block a function of the trained ranking model is returned. The function can be subsequently used to assign ranking scores to segments of other videos. In particular the function can use the audio visual content feature values of a video segment as input to generate a predicted salience score for the segment.

Method begins at block when a function of a trained ranking model is received for predicting salience scores for a video segment. At block a target video is received for auto play. Then at block the target video is divided into segments. At block audio visual content feature values are extracted from each video segment.

Subsequently at block the received function is applied to each video segment using the extracted audio visual content feature values as input for the function. At block a salience score is calculated for each video segment based on the application of the received function to the video segment. At block one of the video segments is selected based on the calculated salience scores for the video segments. In one implementation the video segment with a predicted salience score that indicates high saliency of the video segment is selected for auto play. Lastly at block the target video is auto played using the selected video segment as the starting point for the auto play of the target video.

The user interface includes a main region e.g. for displaying content and a header region for displaying device information etc. . The main region includes a search box for entering a search string and a search button that causes a search request for text entered into the search box to be transmitted to a search engine. Content items and may be returned as search results. In some implementations the search aspect is omitted and the user interface may present content to a user e.g. content items and others not shown for example based on user preferences and user specific content recommendations without requiring a user to request or select the content.

In one implementation the content item corresponds to a current content item that is being played by a client device implementing the user interface . The content item may be a video. In some implementations a playback bar with a corresponding playback indicator may be displayed e.g. overlaid on the content item adjacent to the content item etc. . A full screen option may also be displayed which when selected causes the content item to fitted to the dimensions of the user interface . The content item may correspond to a content item that was previously played by the client device partially played by the client device or scheduled for playback but skipped e.g. in response to the user advancing forward through a list of scheduled content items . The content item may correspond to a next content item to be played.

In some implementations if the user interface is implementing a continuous content stream each content item is auto played in a sequential fashion. For example once the content item ends e.g. as a result of reaching an end of the content playback in response to receiving a user input to advance skip the content etc. the content item then becomes the current content item being played by the client device without any user interaction. In one implementation each content item begins its auto play from a video segment in the video selected based on a predicted salience score of the segment. For example the start time for the auto play of a content item may be selected according to method described with respect to .

The content items and may appear to scroll up and the content item may be cropped depending on the dimensions of the user interface such that the content item appears at or near the center of the main region . The content item may also appear in the main region e.g. and may be cropped as a result of the scrolling up of the content items and . In some implementations the user of the client device may control the playback of content items. For example scrolling up or down may occur in response to a user input e.g. scrolling using a mouse a finger swipe if the client device has touch screen capabilities a voice command etc. .

Prior to commencement of playback of the content item the content item may have been represented as a static image e.g. a representative frame from video of the content item a title screen of the content item etc. . In some implementations the content item may have been presented as a video. For example the video may be muted e.g. so as to not interfere with audio from the current content item and may correspond to playback of highlights of the content e.g. one or more designated interesting portions of the content item based on for example annotation data associated with the content item or a live feed of the content item e.g. if the content item is a live content item .

Once playback of the content item has commenced the content item may be displayed as a static image or as a video e.g. as described above with respect to the content item . Similarly the content item the next content item may be displayed in a similar fashion. Once playback of the content item the current content item ends the content items and may scroll up within the main region .

The exemplary computer system includes a processing device a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM or Rambus DRAM RDRAM etc. a static memory e.g. flash memory static random access memory SRAM etc. and a data storage device which communicate with each other via a bus . Any of the signals provided over various buses described herein may be time multiplexed with other signals and provided over one or more common buses. Additionally the interconnection between circuit components or blocks may be shown as buses or as single signal lines. Each of the buses may alternatively be one or more single signal lines and each of the single signal lines may alternatively be buses.

Processing device represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processing device may be complex instruction set computing CISC microprocessor reduced instruction set computer RISC microprocessor very long instruction word VLIW microprocessor or processor implementing other instruction sets or processors implementing a combination of instruction sets. Processing device may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a digital signal processor DSP network processor or the like. The processing device is configured to execute processing logic for performing the operations and steps discussed herein.

The computer system may further include a network interface device . The computer system also may include a video display unit e.g. a liquid crystal display LCD or a cathode ray tube CRT an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. a speaker .

The data storage device may include a computer readable storage medium also referred to as a machine readable storage medium on which is stored one or more set of instructions e.g. software embodying any one or more of the methodologies of functions described herein. The instructions may also reside completely or at least partially within the main memory and or within the processing device during execution thereof by the computer system the main memory and the processing device also constituting machine readable storage media. The instructions may further be transmitted or received over a network via the network interface device .

The computer readable storage medium may also be used to store instructions to perform a method for predicting video start times for maximizing user engagement as described herein. While the computer readable storage medium is shown in an exemplary implementation to be a single medium the term machine readable storage medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more sets of instructions. A machine readable medium includes any mechanism for storing information in a form e.g. software processing application readable by a machine e.g. a computer . The machine readable medium may include but is not limited to magnetic storage medium e.g. floppy diskette optical storage medium e.g. CD ROM magneto optical storage medium read only memory ROM random access memory RAM erasable programmable memory e.g. EPROM and EEPROM flash memory or another type of medium suitable for storing electronic instructions.

The preceding description sets forth numerous specific details such as examples of specific systems components methods and so forth in order to provide a good understanding of several implementations of the present disclosure. It will be apparent to one skilled in the art however that at least some implementations of the present disclosure may be practiced without these specific details. In other instances well known components or methods are not described in detail or are presented in simple block diagram format in order to avoid unnecessarily obscuring the present disclosure. Thus the specific details set forth are merely exemplary. Particular implementations may vary from these exemplary details and still be contemplated to be within the scope of the present disclosure.

Reference throughout this specification to one implementation or an implementation means that a particular feature structure or characteristic described in connection with the implementation is included in at least one implementation. Thus the appearances of the phrase in one implementation or in an implementation in various places throughout this specification are not necessarily all referring to the same implementation. In addition the term or is intended to mean an inclusive or rather than an exclusive or. 

Although the operations of the methods herein are shown and described in a particular order the order of the operations of each method may be altered so that certain operations may be performed in an inverse order or so that certain operation may be performed at least in part concurrently with other operations. In another implementation instructions or sub operations of distinct operations may be in an intermittent and or alternating manner.

