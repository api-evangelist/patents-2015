---

title: Accelerated panning user interface interaction
abstract: A computer-implemented user interface method includes displaying on a touch screen a portion of a large scale graphical space that is at least multiples larger than the device display, receiving from a user of the device an input to pan within the graphical space, automatically generating a pop up graphical panning control in response to receiving the user input, and receiving a user input to the panning control and providing panning in the graphical space, wherein movement of the panning control in a single selection is able to pan the display across a substantial portion of the large scale graphical space.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09256355&OS=09256355&RS=09256355
owner: Google Inc.
number: 09256355
owner_city: Mountain View
owner_country: US
publication_date: 20150316
---
This application is a continuation of U.S. patent application Ser. No. 14 076 841 filed Nov. 11 2013 which is a continuation of and claims the benefit of priority to U.S. patent application Ser. No. 13 613 766 filed Sep. 13 2012 which is a continuation of and claims the benefit of priority to U.S. patent application Ser. No. 12 473 927 filed May 28 2009 which claims priority under 35 U.S.C. 119 e to U.S. Patent Application Ser. No. 61 056 823 filed on May 28 2008 the entire contents of which are hereby incorporated by reference.

This document relates to systems and techniques for generating graphical display elements and controls.

People spend hours at a time with their electronic devices computers telephones music players and the like. They like best those devices that are intuitive to use and whose interactions best meet their expectations regarding how machines should work. They interact with electronics through inputs and outputs from the devices where the outputs generally are provided audibly and or on a flat graphical display screen and the inputs may occur via touch screens joysticks mice 4 directional keypads and other such input mechanisms.

As mobile devices become more powerful users interact with them more by using graphical objects such as lists of items maps images and the like. The information represented by such objects may be enormous and very large e.g. a detailed map of the United States would be miles wide while the displays on mobile devices are very small. As a result it can be a challenge to provide graphical information in sufficient detail for a user e.g. by zooming in on one area of an object while still giving the user a sense of space and permitting the user to move intuitively throughout the space.

This document describes systems and techniques that may be employed to interact with a user of a computing device like a mobile telephone having a touch screen user interface. In general the techniques may react in particular ways to inputs for moving around a multi dimensional space in two or more directions. In particular when a user indicates an intent to pan in a space such as by scrolling in a list or panning in a map or image the techniques may determine whether the space is a large space e.g. several times larger than the device display and may present a noticeable but unobtrusive graphical control element that permits accelerated panning in the space. The control element may be for example a scroll bar that is automatically generated along an edge of the display whenever the user begins panning in a large space using touch screen inputs.

In certain implementations such systems and technique may provide one or more advantages. For example a user of a device may be saved time in navigating around a large space which could otherwise require dragging their finger repeatedly across the surface of a touch screen because they can use the accelerated panning control to move across an entire space with a single finger input. Also the user may be provided with a contextual indication that shows them where they are currently located within the larger space. For example the scrolling control may be located along an edge of the display at a location that reflects the user s current location within the space i.e. the control can be near the top of the screen if the user is near the top of the space . In this manner the user s interactions with their device may be more efficient and enjoyable and the user may use the particular applications on their device more often and also be more likely to purchase the particular device.

In one implementation a computer implemented visual navigation method is disclosed. The method comprises displaying on a touch screen a portion of a large scale graphical space that is at least multiples larger than the device display. The method also comprises receiving from a user of the device an input to pan within the graphical space automatically generating a pop up graphical panning control in response to receiving the user input and receiving a user input to the panning control and providing panning in the graphical space wherein movement of the panning control in a single selection is able to pan the display across a substantial portion of the large scale graphical space. The pop up control can comprise a slider button located along an edge of the touch screen. Also the method can further comprise increasing the graphical panning control in size if the user provides multiple panning inputs without selecting the control.

In certain aspects the graphical space comprises a list of items and the graphical panning control causes accelerated scrolling through the list. Also the graphical space can comprise a map or image and the graphical panning control can cause accelerated panning across the map or image. The method can also include automatically removing the graphical panning control a determined time after a user selects the graphical panning control. In addition the method can include displaying on the touch screen during user selection of the panning control a miniature representation of the graphical space and an indicator of the user s current location within the graphical space.

In certain other aspects the method further comprises displaying on the touch screen during user selection of the panning control an indicator of a segment from within a group of discrete segments in the graphical space that is currently being displayed on the touch screen. Also the pop up graphical panning control can be generated in response to a long press by the user on the touch screen or in response to a quick flick input on the touch screen. The control can also be sized relatively proportionately to the size of the touch screen in comparison to the size of the graphical space. In addition the method can comprise receiving a long press input from the user on the touch screen and generating a zoom control on the touch screen in response to the long press input.

In another implementation an article comprising a computer readable data storage medium storing program code is disclosed. The code is operable to cause one or more machines to perform certain operations where the operations comprising displaying on a touch screen a portion of a large scale graphical space that is at least several multiples larger than the device display receiving from a user of the device an input to pan within the graphical space automatically generating a pop up graphical panning control in response to receiving the user input and receiving a user input to the panning control and providing panning in the graphical space wherein movement of the panning control in a single selection is able to panning the display across a substantial portion of the large scale graphical space.

In yet another implementation a computer implemented user interface system is disclosed. The system comprises a graphical display to present portions of large scale graphical areas a touch screen user input mechanism to receive user selections in coordination with the display of the portions of the large scale graphical areas and means for generating an accelerated panning control in response to a user panning selection on portions of the large scale graphical areas. The system can also include a mapping application and wherein the pop up control comprises a panning control for controlling the mapping application.

The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description and drawings and from the claims.

This document describes systems and techniques by which mobile devices may interact with a user of such devices. For example a user may be shown graphical objects such as in the form of icons that indicate to the user where they are located within a large virtual space and may provide controls that a user may select in order to move visually within that space. For example when the space is a long list of items such as titles of sings in a playlist on a digital media player a proportional scroll bar may appear on the edge of a screen when a user starts to scroll. If the user scrolls a sufficient amount or at a sufficient speed a large letter may appear on the screen to indicate the letter in the alphabet at which they are currently located in their scrolling of the list. Thus while the list may be blurred the user may have an indication of where they are in any event. The location of the letter vertically on the display may be comparable to its position within the alphabet so that the letter A will appear at the top of the display and the letter Z will appear at the bottom. The scroll bar can also change appearance as a user scrolls getting large or otherwise more prominent as a user scrolls more.

In another example where it is desirable to show a large portion of the visual space but a user cannot fully see the items in the visual space at a zoom level that permits seeing a large portion of the space a object in the form of a virtual magnifying glass may be provided. Such an object may be an area on the screen within which a portion of the space is substantially enlarged. Such an object may be used for example during web browsing so that a user can see an overall layout of a web page and can then quickly read or otherwise more closely review a portion of the page.

In yet another example the visual space may be a 360 degree panorama at a point in the real world like that provided by the well known GOOGLE STREETVIEW service. Such a panorama may be generated by taking digital images simultaneously or nearly simultaneously by a plurality of cameras mounted near a common point and aimed radially outward. Such images may normally be navigated on a desktop personal computer such as via the GOOGLE MAPS service. In the example here the images may be navigated inherently by using position detecting components on a mobile device itself such as a compass in a compass module provided on the device. Thus a user can select a geographic location which may be their current location or a different location and may then see on their device a view from that location is aligned with the direction that they are currently facing e.g. as determined by a compass in their mobile device . As they turn the images on their mobile device will change to match the view from the selected location in the direction that they are currently facing if they are holding their device in front of themselves.

Referring now to the example in there is shown a graphical system that comprises a list of items stored on a mobile device. The items may include things such as personal contacts associated with a user songs or records in a user s music collection various files stored on a device video files that may be played conveniently on the device or other appropriate groups of items that are displayable in a list format. An individual item 110 may be displayed to the user with a variety of information indicative of the item. For example where the item is a contact the displayed information may include a name of the contact and a telephone number for the contact. Where the item 110 is a musical group the system may display an image of the musical group or an album cover for the musical group a name of the group and the name of a song albums or other appropriate information regarding the group. Where the item 110 is a file in a list of files the system may display the file name a size of the file and a last saved date for the file.

A display is shown superimposed near the middle of the list . The display in this example represents a typical portrait formatted video display from a mobile device and may be approximately 3 to 4 inches measured diagonally. The display is shown as a window in effect over the list to represent that a user may scroll through the list to see various different portions of the list at one time by way of the display .

Conceptually then the list moves up and down beneath the display and the display serves as a window onto the list. In an implementation the manner in which the list is sorted and the manner in which the display fetches and formats items from the list for presentation to a user may occur according to standard mechanisms. The top and bottom of the display are shown as being shaded to indicate that items in the list may fade to black near the top and bottom of the display so as to provide a user with the impression that the items are effectively on a dimensional reel that the user is spinning as they navigate up and down the list.

The display may be integrated as part of a touch screen structure so that a user may drag the list up and down by sliding their finger up or down respectively on top of the list in an intuitive manner. However where the list is very long sliding a finger on display or flicking on display to provide momentum in panning up and down the list may be a slow method for providing such panning because the user will have to repeat their motion many times. As a result a visual control is displayed on display to assist in such panning across the long list . The control may take the form of a slider button that will be familiar to users from various applications that involve the use of scrolling bars such as desktop productivity software e.g. spreadsheets and word processors . The control may be displayed in a scrolling bar to the side of the list or as an element that visually floats over the elements in the list .

The control may take a proportional form as is well known in the art in that the control may be shorter if list is longer. In such a situation then the control may take the user to the top or bottom of the list by the user dragging the control to the top or bottom of its predetermined positions within display . In particular a shorter control may represent the relative smaller area being displayed by display where list is a very long list. As a result each movement of control through a span equal to the height of control may approximate the movement across one display of list . In other words equal movement by a user of control may result in much more corresponding movement of items across display when control is small than when control is larger and list is thus shorter.

The control may take a variety of other forms also. For example the control may be placed elsewhere on the area of display such as being overlaid over the middle of display . In certain implementations however it may be preferred to locate control as far out of the way of the display as possible so as to avoid obscuring the content of display by a user s finger or other pointer.

The movement of a control in a particular direction may drive the movement of list across display in the same or an opposite direction depending on the implementation. For example the dragging of control downward may visually drag list downward and thus make it appear that display is climbing the list and that control is attached directly to the list though perhaps in a form of accelerating linkage. Alternatively movement of control down may cause list to move upwards through display leaving an impression that control is connected to display perhaps by way of an accelerating linkage.

A first display represents a user of a mobile device viewing a zone in the Southwest metropolitan area. Display shows the generation of a four headed arrow over the surface of the map in display . A user may drag the arrow up or down or sideways to indicate an intent to pan around the map . In one example panning by a user before the arrow is displayed e.g. dragging a finger across the map may cause display to move only several miles in one direction across the metropolitan area. In contrast after the four headed arrow is displayed the user may drag the arrow into the upper right hand corner of the display to thereby cause display to move to the upper right corner of the map in the Northeast zone on the metropolitan area. Other such exaggerated or accelerated motions may also occur via manipulation of the arrow

The display also includes a small overview map of the entire map area. Map is provided in a familiar manner and shows a large box that represents the entire mapped area available to a user in a current zoom level and a smaller box that represents the current display of the user so that the user may readily identify their location relative to other locations in the larger map. Major features from the map may also be displayed inside map though all features likely will not be displayed because map is much smaller than map .

Display shows slider controls that operate in a manner similar to slider control in . In particular a user presented with display may initially be shown only the map information filling up their entire display . If they begin to pan in their display across map or flick to pan so as to indicate that they want to pan a long distance controls may be generated and shown to the user. The user may then pan all the way to the left or right of map by sliding control all the way to the left or right of display . In a similar manner display may be moved all the way to the top or bottom of map by sliding control all the way to the top or bottom of display . In this manner the user may quickly move about map using the controls to accelerate their motion across the map so that a single swipe on display may move the display much farther then would a normal panning motion directly on the map in display and not using the controls 

Display provides for navigation similar to that shown in display but with an annular ring displayed over the map . The location of the ring on display indicates the relative position of the display on map . In particular here the display is near the top of map and slightly to the left and likewise the ring is near the top and slightly to the left on display . The user may then drag their finger in the area of display but not on ring to pan slowly across the map or may place their finger on ring to pan quickly across the map .

Thus the mechanisms of show various mechanisms for allowing a user to navigate within a large virtual space whether the space is along a single dimension or in two dimensions. These mechanisms may provide the user a sense of their current location within the large space as well as a selectable control or controls to let the user control their computing device so as to pan around the space. The mechanisms shown here may be particular useful for touch screen devices and more particularly mobile devices having touch screens.

Referring now again to a display of a long list of items shows sequential displays that may be generated for a user who is navigating a long list on a mobile device having a touch screen. In this example the list is a list of music groups or singers that could be shown conceptually like the list in .

Display shows seven different groups with the group name the number of albums stored on the user s device for that group and the total number of songs on those albums. In addition a graphical icon is shown for each group where the icon indicates whether a single album or multiple albums are available for that group. Where available album cover art may be downloaded manually or automatically or other images may be inserted for the icons.

A slider control is shown along the right hand edge of display in this example. The slider control may be shown whenever the display is showing a list that is larger than the display or may be shown only in particular contextual circumstances e.g. only after particular actions by a user that indicate an intent by the user to pan a long way across a representation of data as described more fully above and below.

Display shows the action of a user flick across the screen upward from a pictured small dot to a pictured larger dot and ring. The particular graphic shown here would typically not be shown on display but instead is provided here to show a typical user input on the display . The flick may result in the generation of slider control on the display in situations where the slider control was not previously displayed. In this example the user is at the top of the alphabet in the list so the slider control is shown at the top of display . The size of the slider control may be generally proportional or inversely proportional to the length of the list shown on display . For example here slider control is about 1 10 the height of display . As a result one may conclude that the list includes approximately 60 artists. The size of control may also be related to the length of the list but not necessarily proportionately sized against display . For example a minimum size for slider control may be specified so that even if the list includes thousands of entries the slider control will be large enough for a user to see it adequately and select it without frequent errors.

Display results from the flick . In particular the list of artists has scrolled upward and has rested two letters further down the alphabet. Notice that the movement involves momentum because the flick spanned only the distance of two artists but the display has scrolled down through several dozen artists. The particular speed of the flick may determine the distance that is scrolled so as to approximate the action of a physical spinning wheel or similar physical object that a user might flick in what is a familiar manner to a skilled artisan.

Additionally the control has changed in two relevant manners to become control . First because control is a scrolling control its position has moved down slightly from its position as control to reflect that the user is further down the list in display in comparison to display . In addition the control is more prominent than control to bring it to the user s attention more readily. For example the control has begun to thicken and bulge slightly at its center to signify to the user that it may be selected for particular contextual functions.

In this example the control may be used to conduct accelerated panning up and down the list of artists. For example the control may be dragged all the way down the side of display and although such motion will span only five artists as they are currently shown on the display it can result in motion of the list all the way down to the letter Z perhaps across hundreds of artists.

The control may be made more prominent in other ways also. For example the control may be made brighter as an alternative to or in addition to increasing the size of control . The control may also be rendered so as to appear to stretch and to look under pressure as the user conducts repeated flicks like flick . In this manner the user may see more urgency in employing control to conduct accelerated panning since multiple flicks on the list itself should indicate that the user truly would benefit from accelerated panning rather than having to perform so many manual flicks. In addition the color of the control may change both as a user performs one or more flicks across the surface of a list and also as the control moves up and down the edge of a display so as to bring the control more to the user s attention as they provide inputs that indicate that they may have a need for the control .

Display represents a change resulting from a user selection of control as shown by the dot at the bottom of control in the arrow leading to display . The dot on control indicates that a user has maintained pressure on the control and is about to scroll down through the list on display . Such a selection may cause the control to change shape again from that shown by control to that shown by control . In addition an index letter for the items in the list is shown in a familiar manner to provide additional guidance for a user. The index letter represents a discrete grouping of the elements in the list here a letter of the alphabet to represent the starting letter of the artist that is shown at the top of display . The index letter may take other forms also such as a numeral representing a size of a file stored on a device or any other indicator by which a list of items may be classified into discrete groups.

The index letter may be displayed in a variety of manners. In this example the index letter is located near the edge of the display so as to minimize the manner in which it may cover the artist names but may also be made partially or wholly transparent to permit viewing of the names even when they are positioned under the index letter . In addition the index letter may move up and down on the display along with the movement of control . For example the index letter may be anchored just to the left of control a sufficient distance so that the index letter may be seen by a user even while their finger is on control . However the index letter may move up and down the side of display along with the control . In such a manner the user may more readily focus on the letter being displayed and be able to navigate more closely to the artist in which they are interested because they may watch and move their eyes along with the fingers that they are moving.

The index letter may change as the letters in the list in display change so that for example if there were many artists in the list that started with the letter A but few that started with the letter C very little motion of control would be required to pass through the letter C as an index letter as compared to passing through the letter A. Alternatively each index letter here A to Z and perhaps 0 to 9 may have an equal division in comparison to the movement of control so that movement down one 26th of display will always result in the changing of one letter in index letter for example.

In some implementations the index letter may change as the user slides the control up and down but the items in the list may stop moving when such control is occurring. Thus there may be two modes of control normal panning where the items in the list scroll up and down as the user pans and accelerated panning where the items no longer move and an index letter is cycled through in an accelerated manner as the user moves the control.

Using the techniques described herein a user may readily navigate in small movements by dragging their finger across a display of a list. The user may navigate in larger movements by flicking across the display with their finger so as to give it virtual momentum and thereby move more than one display at a time in the list. The user may also be provided a convenient option for scrolling in an accelerated manner through the list without having to take up unnecessary interaction via the presentation of a control that is hidden until the user indicates an intent to pan or scroll through the list.

Referring now to the examples shown in a mobile device is shown being held by a user in different orientations or directions. The user is shown with particular headings according to the North arrow . That is the same user is shown with different headings according to a compass included in the mobile device . In general the mobile device may include a web browser or other software application s that allows the user of the mobile device to access a map of a particular area. In some implementations the map also includes images of the area that are captured from a street side vantage point. One such example is STREETVIEW from GOOGLE Mountain View Calif. . The user can provide an address to the web browser or other software application s to generate a view in the form of a map satellite image or combination of the two of the area surrounding the provided address. In some implementations the mobile device may automatically provide the address as the current address where the user is located using a global position system GPS or other systems designed to locate the mobile device automatically.

The user may initially provide address information here the address of the Hubert H. Humphrey Metrodome and may be provided with map tiles and other map data in a familiar manner for the area around The Dome. The user may then further select to be presented with a street view in an area around The Dome. While the user may be located for example in their home they may be displayed images from the outside of The Dome that were taken by a car that passed the dome at an earlier time. The user may obtain the view alternatively via a search such as by the query MetroDome which may return an address as a Onebox result that includes a link to the map of the area around the structure and they may then choose to see images from a point on the map.

The direction in which the person is looking in a virtual manner via STREETVIEW may be coordinated with the compass direction the person is facing in their own frame of reference. For example as the user moves the mobile device generates displays of a particular region according to the map data the location of the mobile device the heading of the mobile device and or other information that can be detected by the mobile device e.g. acceleration exerted on the mobile device . For example user is looking generally SSE and is thus shown the view in the area near the Dome that is oriented in a similar direction.

If the user turns to their left e.g. in a heading illustrated as user the mobile device can detect the motion or direction of the user e.g. the change in heading and automatically pan the view to match heading of the user which is illustrated as display . That is the mobile device now displays in display a different portion of the Metrodome according to new heading detected by the mobile device . If the user turns to their right e.g. in a heading illustrated by user the mobile device can detect the motion of the user e.g. the change in heading and automatically pan the view to match the current heading of the user which is illustrated as display

The heading of the device may be matched easily to relevant heading data that identifies portions of the image or images that make up the particular street view. Where there are multiple images they can be made to appear seamless to a user by serving them in succession and blending them at their edges. In this manner the user can be provided with the effect of viewing on their mobile device the area around the point at which the images were captured even though the user may be far away from such a location.

In some implementations an accelerometer can be used instead of or in addition to a compass on the mobile device . For example as the user walks the accelerometer can detect the motion e.g. shaking walking change in elevation orientation or other motion and update the displays accordingly. For example the mobile device can detect that user is moving based on detected accelerations and can pan the displays as if the user were walking down the street. The user may also simply shake the device in space to cause forward motion to occur in the displayed space much like selection of a travel arrow in GOOGLE STREETVIEW causes the user to move virtually down a street. As another example the mobile device can detect a change in the orientation of the mobile device e.g. according to acceleration detected by the accelerometer and can pan the displays up or down as if the user were looking up or down where the graphical images provided by a remote server to the device include such panoramic photographs.

The direction shown by the device may also be relative rather than absolute and particularly where an accelerometer is used and a compass is not. In particular the initial orientation of a view that is provided to a user may initially be selected by a rule rather than a particular direction that the user is facing. Then relative motion by the user rotating to the left or right may be sensed by an accelerometer on a device and the images of the geographic locality that the viewer is reviewing may be panned relative to such motion though perhaps not in a manner perfectly proportional to the user s motion. For example the user may rotate 90 degrees while the display may be made to rotate only 60 degrees in the same direction because of limitations in the ability of the user s device to sense absolute motion.

At shot b the user is shown moving their finger toward the zoom box and the user may press on the box and drag it around until it lies over the area the user would like to review more closely. To provide a contrast between the content inside the zoom box and the content outside the content inside may be increased in size slightly as the box is moved around as shown in shots b d . The zoom box may also trail the user s finger slightly when the motion starts see trailing box in shot d where the user s finger is moving toward the lower left corner . The box may then catch up in a springy fashion once the finger stops moving. This may provide the user with a better sense that they are dragging the box and may also keep the finger from fully covering the zoom box while it is being moved around.

When the user has moved the zoom box over the content they would like to see more closely they may lift their finger thus leaving the zoom box in the location where they lifted. Such an action may also cause a display manager to automatically zoom in on the area in the zoom box until the area inside the zoom box fills the entire display. a user may then pan on the page by dragging their finger on the touch screen or by rolling a trackball and may choose to zoom back out by again double tapping on the screen.

One such component is a display manager which may be responsible for rendering content for presentation on display . The display manager may receive graphic related content from a number of sources and may determine how the content is to be provided to a user. For example a number of different windows for various applications on the device may need to be displayed and the display manager may determine which to display which to hide and what to display or hide when there is overlap between various graphical objects.

The display manager can include various components to provide the device with particular functionality for interacting with displayed components which may be shared across multiple applications and may be supplied for example by an operating system of device . Such functionality may be provided for example by interface navigation module which may be responsible for receiving input from a user wanting to move between and among elements on display . In this example a control is shown on display and may be similar to control on display in . In particular the positioning of control on display may represent to the user that they are looking at a portion of their map that is in the Southeast corner of the entire map.

If the user drags on the map interface navigation module may initially cause control to be displayed and may cause the map to pan an amount related to the dragging motion. Subsequent dragging on the map but away from the control may cause more panning of the map and the control may in certain circumstances move a small amount if the location of the control on the map corresponds to the location of the map sub section shown on the display relative to the overall map. Interface navigation module can likewise provide for other changes in the display in response to user input such as those described above and below.

Individual applications can register themselves with the display manager in accordance with an API so as to indicate the sort of display elements they might require. For example an application may identify a group of data elements as corresponding to a list and the interface navigation module may then treat such elements as a list visually e.g. it may show an accelerated scrolling control when the list is sufficiently long and a user input indicates a user intent to scroll up or down within the list.

An input manager may be responsible for translating commands provided by a user of device . For example such commands may come from a keyboard from touch screen display from trackball or from other such sources including dedicated buttons or soft buttons e.g. buttons whose functions may change over time and whose functions may be displayed on areas of display that are adjacent to the particular buttons . The input may also occur more inferentially such as from signals provided by an on board compass or accelerometer. The input manager may determine for example in what area of the display commands are being received and thus in what application being shown on the display the commands are intended for. In addition it may interpret input motions on the touch screen into a common format and pass those interpreted motions e.g. short press long press flicks and straight line drags to the appropriate application. The input manager may also report such inputs to an event manager not shown that in turn reports them to the appropriate modules or applications.

A variety of applications may operate generally on a common microprocessor on the device . The applications may take a variety of forms such as mapping applications e mail and other messaging applications web browser applications music and video players and various applications running within a web browser or running extensions of a web browser.

One application that may run independently or as part of a browser is GOOGLE MAPS and GOOGLE STREETVIEW. Such an application may accept readings from a compass module on the device which may include an electronic compass and related circuitry and software for interpreting compass readings and an accelerometer . The compass module and accelerometer may be used such as described above with respect to to sense user motion or orientation in changing the device s views of a geographic area that has previously been photographed panoramically and whose digital images are available from a server to the device .

A wireless interface manages communication with a wireless network which may be a data network that also carries voice communications. The wireless interface may operate in a familiar manner such as according to the examples discussed below and may provide for communication by the device with messaging services such as text messaging e mail and telephone voice mail messaging. In addition the wireless interface may support downloads and uploads of content and computer code over a wireless network. One example of data that may be obtained via the wireless network is images provided by an application such as GOOGLE STREETVIEW where an application running on the device such as an JavaScript application running on a web page displayed on the device may have access to compass data on the device and may request new image data around a certain geographical point automatically in response to a user s movement of the device .

Various forms of persistent storage may be provided such as using fixed disk drives and or solid state memory devices. Two examples are shown here. First maps lists etc storage includes all sorts of data to be used by applications and can include lists of data elements graphical components like map tiles and a variety of other well known data structures so that a user can interact with applications on device .

Other storage includes user defaults which may be profile information for a user stored on the same media as maps links etc. storage . The user defaults include various parameters about a user of the device . In the example relevant here the user profile may include data defining the manner in which the user prefers to have panning controls presented on the display e.g. what the controls should look like whether a list should scroll with the control or in the opposite direction of the control the actions by the user that will bring up the control etc. .

Using the pictured components and others that are omitted here for clarity the device may provide particular actions in response to user inputs. Specifically the device may respond to panning inputs within large areas in particular ways including by displaying a control that permits accelerated panning in the areas i.e. panning that is substantially faster than dragging across a panned object and typically permits navigation from one side of the area to another using a single swipe on the controls .

The process begins in this example at box where a request to display large area data is received. Large area data may include various forms of data whose display extends well beyond the edges of a single screen on a device. Such data may include for example long lists of information and large images or maps or similar presentations of information. The request to display the large area information may take a number of forms such as a search request provided to a device where the search results include the large area information such as in the form of a list of files on a computer on the Internet or a map generated in response to a search result.

At box the process selects a subset of the large area data and displays that subset. For example where the large area data is a map the displayed subset may be a portion of that map surrounding an address that is a result for a search query that was entered by a user. The process then receives a panning input from a user at box . Such an input may generally be received by a user moving their finger or a stylus across the surface of a touch screen display.

The process reacts to the user input at box by showing a panning control on the display after determining the relative size of the display in comparison to the size of the entire area of data. The prior determination of the relative size of the display before displaying the control may ensure that a control is not shown if the area of data is the size of the display or only slightly larger than the display. In such situations panning either does not operate or can be completed easily right on the data without the need for a special control that can be used to provide accelerated panning.

The display of the control may also be dependent on the speed and manner of the user input. For example if the user drags slowly across the display the process may assume that the user is not interested in navigating to far flung corners of the data and may decline to display the control. Similarly if the user leaves their finger on the display at the end of their action such input may be taken as an indication that the user is not interested in panning very far and thus not in need of an accelerated panning control. In contrast if the user moves quickly and lifts their finger at the end so as to create a fling input such an input may be taken as a sign that the user intends to pan a long way so that the control may be generated in such a situation.

At box the process reacts to the user input such as a fling panning input or by the input of subsequent panning inputs by increasing the prominence of the input control. Such an action may involve increasing the size or brightness of the control or for example pulsing the control. The prominence of the control may be increased only once such as when a second panning input is received or may proceed through multiple increasing phases up to a maximum point. The intent of increasing the prominence of the control is to bring to the user s attention the option of using an accelerated panning control where the more the user tries to pan on the subject matter itself the more the user is likely to pan and the more they need help from the control.

At box the user notices the control and selects it so as to provide accelerated panning of their display. the process responds by quick panning the data in accordance with the user s manipulation of the control. For example if the user slides the control downward the display may move downward across a map or list of items at an exaggerated rate as the user watches. After a time of inaction either of the user not selecting the control and or the user not making a panning motion on the display that would normally bring up the control the control may disappear as shown at box . The control may for example be faded out so that the user may see any data that may have been located beneath the control.

If the user later repeats a flicking action the control may be brought back and the steps repeated. However the control will generally be located in a position that reflects the user s current view of the data area. For example if the user is currently looking at the middle of a list of videos stored on her device the control may be generated on the side of the display midway between the top and bottom of the display.

The process starts at box where the process receives from a user a flick input i.e. a fast movement followed by lifting of the finger or stylus on a long list. The process may then check the length of the list boxes and if the list is not long i.e. is not longer than the device display or is not substantially longer than the device display such as many times as long as the display the process may continue receiving input form the user box .

If the list is long a thin panning control may be displayed on a display of the device box such as in the form of a scrolling handle along one edge of the display generally the right edge to avoid covering left justified text in the list . In addition the list may be scrolled in response to the flick and the speed and distance of the scrolling may represent the movement of a physical object so that the list continues to scroll after the flick and slows gradually as if it were being dragged down by friction. Also the control will move along the side of the display so that it reflects by its location between the top and bottom of the display the user s location i.e. the display s location between the top and bottom of the list.

At box the process receives a second flick input from the user and the list may scroll again as it did after the first flick input. In addition the fact that the user has flicked twice indicates that he or she may want to go very far down or up the list. As a result the process at box thickens the display of the control so that the control will be more visually prominent to the user. The system also checks at box whether the user has selected the control though it would generally be checking for such input anytime after the control is initially displayed and the control fades away if the user does not select it or perform a flick of the subject matter for a determined period box . If the user does select the control the process thickens the control further so as to make it even easier for the user to manipulate and then pans the display according to the user s manipulation of the control such as in the various manners discussed above.

In reference to the process starts at box when a map application is launched. In some implementations the map application may be launched automatically when the mobile device is booted. For example the map application may be bootstrapped to the mobile device s initialization routines. In some implementations the map application may be launched by a user. For example the user can select an application icon on the display of the mobile device to launch the map application. In some implementations another process or application may launch the map application. For example a social networking application may launch the map application when the social networking application presents locations of particular friends to the user.

Once the map application is launched in box an address is received by the map application. This can be accomplished in any number of ways. For example the user can input the address manually. As another example a GPS device located on the mobile device may automatically provide an address.

In box the map application can fetch and display map tiles around the received address. For example the map application can display one or more tiles that show buildings parks streets or other locations on the mobile device.

In box the map application can fetch and display StreetView images. In general a StreetView image is an image taken from the vantage point of a person vehicle and the like at street level. As such in some implementations the user of the map application may need to specify the street for which the map application fetches and displays the StreetView images. A first image may be displayed that represents the digital image taken by the camera at the relevant point facing at a radial angle the corresponds to the present direction that the mobile device is facing.

In box the map application can sense motion of the mobile device. In general the sensing of motion is accomplished by communicating with one or more systems or modules included on the mobile device that are capable of detecting motion. For example the map application can communicate with an accelerometer a compass or other modules to sense motion of the mobile device.

In box the map application pans the StreetView images to match the orientation of the user i.e. the orientation of the mobile device . For example in reference to StreetView images are presented on the displays of mobile device according to the orientation of user 

Thus by this process a user of a mobile device can quickly get a view of an area such as a shopping district that they are planning to visit or a neighborhood of a friend where they expect to travel. They can obtain a more immersive experience of the location by holding their mobile device in front of them and turning in a circle while the images on the device pan to match their motion. As a result the user can quickly see what an area will look like and can decide whether to go there or not or can more readily recognize the area when they arrive at it.

In reference to the process starts at box when the mobile device launches a maps search box. In general search boxes are types of input controls that give a user of a process the ability to provide some information in the form of a query. For example a search box may be an editable text box or other user interface component.

In box the mobile device receives an address input from the search box. In some implementations a user may input an address into the search box e.g. HHH Metrodome or 123 Main Street Anytown CA . In other implementations an automated process may automatically provide the address. For example the map application may be configured with certain predefined addresses e.g. the user s work the user s home or other addresses which the map application can automatically provide to the mobile device upon request. As another example a GPS module may determine the address of the mobile device according to a GPS calculation.

In box the mobile device submits a formatted maps query. In general the maps query can be formatted for any number of application program interfaces API . Example formatting includes but is not limited to any number of database query formats common gateway interface CGI request formats hypertext markup language HTML formats or any other conventional formats for submitting queries.

In box the maps server receives the query and generates one or more results. For example in some situations the address may not be able to be resolved. That is there may be more than one location with an address substantially similar to the one received from the mobile device. As such in some implementations the maps server may generate multiple results one for each result and may provide feedback to the mobile device and the user to help disambiguate the result s . In other implementations the maps server may first disambiguate the address before generating a result.

Once the maps server has determined a particular result in box the maps server transmits the relevant map tiles and other data to the mobile device. For example the maps server may transmit map tiles and data associated with the HHH Metrodome e.g. images advertisements or other data .

In box the mobile device displays the map around the submitted address. For example the mobile device can display buildings streets parks or other aspects of the geography around the HHH Metrodome.

Once the map is displayed in box the mobile device may receive user input of a StreetView location and transmit location data. For example the user can select a particular street displayed on the mobile device as the StreetView location. As another example a GPS module may automatically provide the mobile device s current street as the StreetView location. The location data can be transmitted as a query. For example the mobile device can format a query for one or more images associated with the StreetView location.

In box the StreetView server receives the query and generates the results. In general the StreetView server can access one or more image repositories and generate data that includes one or more images associated with the received query.

In box the StreetView server transmits relevant real word camera images perhaps with annotations . For example in reference to the StreetView server transmits real world camera images of the HHH Metrodome with annotations for the particular street e.g. Kirby Puckett PI and the direction the street runs e.g. represented by the NE and SW arrows . In some implementations the image is comprised of multiple joined image files.

In box the mobile device senses motion and updates the display to reflect that motion. For example in response to a user shaking of the mobile device the mobile device can move forward in the image space according to the amount of shaking detecting. As another example in accordance with compass readings sensed by the mobile device the image can be panned laterally around the geographic location. Other updates according to the reflected motion are also possible some of which have been described above. In some implementations the mobile device may request additional images if for example the mobile device does not contain any images that correspond to the sensed motion. For example if the mobile device is panned laterally beyond a certain point the mobile device may need to communicate with the StreetView server to receive additional images.

In box the StreetView server generates and transmits additional image data as requested by the mobile device. In some implementations the StreetView server may use previous queries to pre fetch certain images from the image repositories in anticipation of additional motion sensed by the mobile device. That is the StreetView server may determine additional images that may be used by the mobile device sometime in the future according to the current motion of the mobile device and transmit the additional image data with the current request. In general boxes and and their respective communications may occur any number of times.

Referring now to the exterior appearance of an exemplary device that implements the user interface features described here is illustrated. Briefly and among other things the device includes a processor configured to display notifications regarding events on the device and to permit a user to conveniently pull down detail about the events relating to the notifications into an extended view of the events.

In more detail the hardware environment of the device includes a display for displaying text images and video to a user a keyboard for entering text data and user commands into the device a pointing device for pointing selecting and adjusting objects displayed on the display an antenna a network connection a camera a microphone and a speaker . Although the device shows an external antenna the device can include an internal antenna which is not visible to the user.

The display can display video graphics images and text that make up the user interface for the software applications used by the device and the operating system programs used to operate the device . Among the possible elements that may be displayed on the display are a new mail indicator that alerts a user to the presence of a new message an active call indicator that indicates that a telephone call is being received placed or is occurring a data standard indicator that indicates the data standard currently being used by the device to transmit and receive data a signal strength indicator that indicates a measurement of the strength of a signal received by via the antenna such as by using signal strength bars a battery life indicator that indicates a measurement of the remaining battery life or a clock that outputs the current time.

The display may also show application icons representing various applications available to the user such as a web browser application icon a phone application icon a search application icon a contacts application icon a mapping application icon an email application icon or other application icons. In one example implementation the display is a quarter video graphics array QVGA thin film transistor TFT liquid crystal display LCD capable of 16 bit or better color.

A user uses the keyboard or keypad to enter commands and data to operate and control the operating system and applications that provide for responding to notification of alerts and responding to messages and the like and also to a touch screen . The keyboard includes standard keyboard buttons or keys associated with alphanumeric characters such as keys and that are associated with the alphanumeric characters Q and W when selected alone or are associated with the characters and 1 when pressed in combination with key . A single key may also be associated with special characters or functions including unlabeled functions based upon the state of the operating system or applications invoked by the operating system. For example when an application calls for the input of a numeric character a selection of the key alone may cause a 1 to be input.

In addition to keys traditionally associated with an alphanumeric keypad the keyboard also includes other special function keys such as an establish call key that causes a received call to be answered or a new call to be originated a terminate call key that causes the termination of an active call a drop down menu key that causes a menu to appear within the display a backward navigation key that causes a previously accessed network address to be accessed again a favorites key that causes an active web page to be placed in a bookmarks folder of favorite sites or causes a bookmarks folder to appear a home page key that causes an application invoked on the device to navigate to a predetermined network address or other keys that provide for multiple way navigation application selection and power and volume control.

The user uses the pointing device to select and adjust graphics and text objects displayed on the display as part of the interaction with and control of the device and the applications invoked on the device . The pointing device is any appropriate type of pointing device and may be a joystick a trackball a touch pad a camera a voice input device a touch screen device implemented in combination with the display or any other input device.

The antenna which can be an external antenna or an internal antenna is a directional or omni directional antenna used for the transmission and reception of radiofrequency RF signals that implement point to point radio communication wireless local area network LAN communication or location determination. The antenna may facilitate point to point radio communication using the Specialized Mobile Radio SMR cellular or Personal Communication Service PCS frequency bands and may implement the transmission of data using any number or data standards. For example the antenna may allow data to be transmitted between the device and a base station using technologies such as Wireless Broadband WiBro Worldwide Interoperability for Microwave ACCess WiMAX 5GPP Long Term Evolution LTE Ultra Mobile Broadband UMB High Performance Radio Metropolitan Network HIPERMAN iBurst or High Capacity Spatial Division Multiple Access HC SDMA High Speed OFDM Packet Access HSOPA High Speed Packet Access HSPA HSPA Evolution HSPA High Speed Upload Packet Access HSUPA High Speed Downlink Packet Access HSDPA Generic Access Network GAN Time Division Synchronous Code Division Multiple Access TD SCDMA Evolution Data Optimized or Evolution Data Only EVDO Time Division Code Division Multiple Access TD CDMA Freedom Of Mobile Multimedia Access FOMA Universal Mobile Telecommunications System UMTS Wideband Code Division Multiple Access W CDMA Enhanced Data rates for GSM Evolution EDGE Enhanced GPRS EGPRS Code Division Multiple Access 2000 CDMA2000 Wideband Integrated Dispatch Enhanced Network WiDEN High Speed Circuit Switched Data HSCSD General Packet Radio Service GPRS Personal Handy Phone System PHS Circuit Switched Data CSD Personal Digital Cellular PDC CDMAone Digital Advanced Mobile Phone System D AMPS Integrated Digital Enhanced Network IDEN Global System for Mobile communications GSM DataTAC Mobitex Cellular Digital Packet Data CDPD Hicap Advanced Mobile Phone System AMPS Nordic Mobile Phone NMP Autoradiopuhelin ARP Autotel or Public Automated Land Mobile PALM Mobiltelefonisystem D MTD Offentlig Landmobil Telefoni OLT Advanced Mobile Telephone System AMTS Improved Mobile Telephone Service IMTS Mobile Telephone System MTS Push To Talk PTT or other technologies. Communication via W CDMA HSUPA GSM GPRS and EDGE networks may occur for example using a QUALCOMM MSM7200A chipset with an QUALCOMM RTR6285 transceiver and PM7540power management circuit.

The wireless or wired computer network connection may be a modem connection a local area network LAN connection including the Ethernet or a broadband wide area network WAN connection such as a digital subscriber line DSL cable high speed internet connection dial up connection T 1 line T 3 line fiber optic connection or satellite connection. The network connection may connect to a LAN network a corporate or government WAN network the Internet a telephone network or other network. The network connection uses a wired or wireless connector. Example wireless connectors include for example an INFRARED DATA ASSOCIATION IrDA wireless connector a Wi Fi wireless connector an optical wireless connector an INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS IEEE Standard 802.11 wireless connector a BLUETOOTH wireless connector such as a BLUETOOTH version 1.2 or 5.0 connector a near field communications NFC connector an orthogonal frequency division multiplexing OFDM ultra wide band UWB wireless connector a time modulated ultra wide band TM UWB wireless connector or other wireless connector. Example wired connectors include for example a IEEE 1394 FIREWIRE connector a Universal Serial Bus USB connector including a mini B USB interface connector a serial port connector a parallel port connector or other wired connector. In another implementation the functions of the network connection and the antenna are integrated into a single component.

The camera allows the device to capture digital images and may be a scanner a digital still camera a digital video camera other digital input device. In one example implementation the camera is a 5 mega pixel MP camera that utilizes a complementary metal oxide semiconductor CMOS .

The microphone allows the device to capture sound and may be an omni directional microphone a unidirectional microphone a bi directional microphone a shotgun microphone or other type of apparatus that converts sound to an electrical signal. The microphone may be used to capture sound generated by a user for example when the user is speaking to another user during a telephone call via the device . Conversely the speaker allows the device to convert an electrical signal into sound such as a voice from another user generated by a telephone application program or a ring tone generated from a ring tone application program. Furthermore although the device is illustrated in as a handheld device in further implementations the device may be a laptop a workstation a midrange computer a mainframe an embedded system telephone desktop PC a tablet computer a PDA or other type of computing device.

The CPU can be one of a number of computer processors. In one arrangement the computer CPU is more than one processing unit. The RAM interfaces with the computer bus so as to provide quick RAM storage to the CPU during the execution of software programs such as the operating system application programs and device drivers. More specifically the CPU loads computer executable process steps from the storage medium or other media into a field of the RAM in order to execute software programs. Data is stored in the RAM where the data is accessed by the computer CPU during execution. In one example configuration the device includes at least 128 MB of RAM and 256 MB of flash memory.

The storage medium itself may include a number of physical drive units such as a redundant array of independent disks RAID a floppy disk drive a flash memory a USB flash drive an external hard disk drive thumb drive pen drive key drive a High Density Digital Versatile Disc HD DVD optical disc drive an internal hard disk drive a Blu Ray optical disc drive or a Holographic Digital Data Storage HDDS optical disc drive an external mini dual in line memory module DIMM synchronous dynamic random access memory SDRAM or an external micro DIMM SDRAM. Such computer readable storage media allow the device to access computer executable process steps application programs and the like stored on removable and non removable memory media to off load data from the device or to upload data onto the device .

A computer program product is tangibly embodied in storage medium a machine readable storage medium. The computer program product includes instructions that when read by a machine operate to cause a data processing apparatus to store image data in the mobile device. In some embodiments the computer program product includes instructions that generate notifications about alerts such as newly arriving messages on the device.

The operating system may be a LINUX based operating system such as the GOOGLE mobile device platform APPLE MAC OS X MICROSOFT WINDOWS NT WINDOWS 2000 WINDOWS XP WINDOWS MOBILE a variety of UNIX flavored operating systems or a proprietary operating system for computers or embedded systems. The application development platform or framework for the operating system may be BINARY RUNTIME ENVIRONMENT FOR WIRELESS BREW JAVA Platform Micro Edition JAVA ME or JAVA 2 Platform Micro Edition J2ME using the SUN MICROSYSTEMS JAVASCRIPT programming language PYTHON FLASH LITE or MICROSOFT .NET Compact or another appropriate environment.

The device stores computer executable code for the operating system and the application programs such as an email instant messaging a video service application a mapping application word processing spreadsheet presentation gaming mapping web browsing JAVASCRIPT engine or other applications. For example one implementation may allow a user to access the GOOGLE GMAIL email application the GOOGLE TALK instant messaging application a YOUTUBE video service application a GOOGLE MAPS or GOOGLE EARTH mapping application or a GOOGLE PICASA imaging editing and presentation application. The application programs may also include a widget or gadget engine such as a TAFRI widget engine a MICROSOFT gadget engine such as the WINDOWS SIDEBAR gadget engine or the KAPSULES gadget engine a YAHOO widget engine such as the KONFABULTOR widget engine the APPLE DASHBOARD widget engine the GOOGLE gadget engine the KLIPFOLIO widget engine an OPERA widget engine the WIDSETS widget engine a proprietary widget or gadget engine or other widget or gadget engine the provides host system software for a physically inspired applet on a desktop.

Although it is possible to provide for notifications and interactions with messages and other events using the above described implementation it is also possible to implement the functions according to the present disclosure as a dynamic link library DLL or as a plug in to other application programs such as an Internet web browser such as the FOXFIRE web browser the APPLE SAFARI web browser or the MICROSOFT INTERNET EXPLORER web browser.

The navigation module may determine an absolute or relative position of the device such as by using the Global Positioning System GPS signals the GLObal NAvigation Satellite System GLONASS the Galileo positioning system the Beidou Satellite Navigation and Positioning System an inertial navigation system a dead reckoning system or by accessing address internet protocol IP address or location information in a database. The navigation module may also be used to measure angular displacement orientation or velocity of the device such as by using one or more accelerometers.

The operating system can generally be organized into six components a kernel libraries an operating system runtime application libraries system services and applications . The kernel includes a display driver that allows software such as the operating system and the application programs to interact with the display via the display interface a camera driver that allows the software to interact with the camera a BLUETOOTH driver a M Systems driver a binder IPC driver a USB driver a keypad driver that allows the software to interact with the keyboard via the keyboard interface a WiFi driver audio drivers that allow the software to interact with the microphone and the speaker via the sound interface and a power management component that allows the software to interact with and manage the power source .

The BLUETOOTH driver which in one implementation is based on the BlueZ BLUETOOTH stack for LINUX based operating systems provides profile support for headsets and hands free devices dial up networking personal area networking PAN or audio streaming such as by Advance Audio Distribution Profile A2DP or Audio Video Remote Control Profile AVRCP . The BLUETOOTH driver provides JAVA bindings for scanning pairing and unpairing and service queries.

The libraries include a media framework that supports standard video audio and still frame formats such as Moving Picture Experts Group MPEG 4 H.264 MPEG 1 Audio Layer 3 MP3 Advanced Audio Coding AAC Adaptive Multi Rate AMR Joint Photographic Experts Group JPEG and others using an efficient JAVA Application Programming Interface API layer a surface manager a simple graphics library SGL for two dimensional application drawing an Open Graphics Library for Embedded Systems OpenGL ES for gaming and dimensional rendering a C standard library LIBC a LIBWEBCORE library a FreeType library an SSL and an SQLite library .

The operating system runtime includes core JAVA libraries and a Dalvik virtual machine . The Dalvik virtual machine is a custom virtual machine that runs a customized file format .DEX .

The operating system can also include Mobile Information Device Profile MIDP components such as the MIDP JAVA Specification Requests JSRs components MIDP runtime and MIDP applications as shown in . The MIDP components can support MIDP applications running on the device .

With regard to graphics rendering a system wide composer manages surfaces and a frame buffer and handles window transitions using the OpenGL ES and two dimensional hardware accelerators for its compositions.

The Dalvik virtual machine may be used with an embedded environment since it uses runtime memory very efficiently implements a CPU optimized bytecode interpreter and supports multiple virtual machine processes per device. The custom file format DEX is designed for runtime efficiency using a shared constant pool to reduce memory read only structures to improve cross process sharing concise and fixed width instructions to reduce parse time thereby allowing installed applications to be translated into the custom file formal at build time. The associated bytecodes are designed for quick interpretation since register based instead of stack based instructions reduce memory and dispatch overhead since using fixed width instructions simplifies parsing and since the 16 bit code units minimize reads.

The application libraries include a view system a resource manager and content providers . The system services includes a status bar an application launcher a package manager that maintains information for all installed applications a telephony manager that provides an application level JAVA interface to the telephony subsystem a notification manager that allows all applications access to the status bar and on screen notifications a window manager that allows multiple applications with multiple windows to share the display and an activity manager that runs each application in a separate process manages an application life cycle and maintains a cross application history.

The applications include a home application a dialer application a contacts application and a browser application . Each of the applications may generate graphical elements that either do or do not have long press interactions. As described above those that do not have long press interactions may provide no immediate visual feedback when they are first pressed while those that do have such interactions may be highlighted between the time they are first pressed and the expiration of the long press period. Also the highlighting may not occur exactly upon a press so that mere tapping of an item does not cause it to be highlighted instead the highlighting may occur upon the expiration of a short press period that is slightly more than the time period for a tap but appreciably shorter than a long press period.

The telephony manager provides event notifications such as phone state network state Subscriber Identity Module SIM status or voicemail status allows access to state information such as network information SIM information or voicemail presence initiates calls and queries and controls the call state. The browser application renders web pages in a full desktop like manager including navigation functions. Furthermore the browser application allows single column small screen rendering and provides for the embedding of HTML views into other applications.

Some processes can be persistent. For example processes associated with core system components such as the surface manager the window manager or the activity manager can be continuously executed while the device is powered. Additionally some application specific process can also be persistent. For example processes associated with the dialer application may also be persistent.

The processes implemented by the operating system kernel may generally be categorized as system services processes dialer processes browser processes and maps processes . The system services processes include status bar processes associated with the status bar application launcher processes associated with the application launcher package manager processes associated with the package manager activity manager processes associated with the activity manager resource manager processes associated with a resource manager that provides access to graphics localized strings and XML layout descriptions notification manger processes associated with the notification manager window manager processes associated with the window manager core JAVA libraries processes associated with the core JAVA libraries surface manager processes associated with the surface manager Dalvik virtual machine processes associated with the Dalvik virtual machine and LIBC processes associated with the LIBC library .

The dialer processes include dialer application processes associated with the dialer application telephony manager processes associated with the telephony manager core JAVA libraries processes associated with the core JAVA libraries Dalvik virtual machine processes associated with the Dalvik Virtual machine and LIBC processes associated with the LIBC library . The browser processes include browser application processes associated with the browser application core JAVA libraries processes associated with the core JAVA libraries Dalvik virtual machine processes associated with the Dalvik virtual machine LIBWEBCORE processes associated with the LIBWEBCORE library and LIBC processes associated with the LIBC library .

The maps processes include maps application processes core JAVA libraries processes Dalvik virtual machine processes and LIBC processes . Notably some processes such as the Dalvik virtual machine processes may exist within one or more of the systems services processes the dialer processes the browser processes and the maps processes .

Computing device includes a processor memory a storage device a high speed interface connecting to memory and high speed expansion ports and a low speed interface connecting to low speed bus and storage device . Each of the components and are interconnected using various busses and may be mounted on a common motherboard or in other manners as appropriate. The processor can process instructions for execution within the computing device including instructions stored in the memory or on the storage device to display graphical information for a GUI on an external input output device such as display coupled to high speed interface . In other implementations multiple processors and or multiple buses may be used as appropriate along with multiple memories and types of memory. Also multiple computing devices may be connected with each device providing portions of the necessary operations e.g. as a server bank a group of blade servers or a multi processor system .

The memory stores information within the computing device . In one implementation the memory is a volatile memory unit or units. In another implementation the memory is a non volatile memory unit or units. The memory may also be another form of computer readable medium such as a magnetic or optical disk.

The storage device is capable of providing mass storage for the computing device . In one implementation the storage device may be or contain a computer readable medium such as a floppy disk device a hard disk device an optical disk device or a tape device a flash memory or other similar solid state memory device or an array of devices including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that when executed perform one or more methods such as those described above. The information carrier is a computer or machine readable medium such as the memory the storage device memory on processor or a propagated signal.

The high speed controller manages bandwidth intensive operations for the computing device while the low speed controller manages lower bandwidth intensive operations. Such allocation of functions is exemplary only. In one implementation the high speed controller is coupled to memory display e.g. through a graphics processor or accelerator and to high speed expansion ports which may accept various expansion cards not shown . In the implementation low speed controller is coupled to storage device and low speed expansion port . The low speed expansion port which may include various communication ports e.g. USB Bluetooth Ethernet wireless Ethernet may be coupled to one or more input output devices such as a keyboard a pointing device a scanner or a networking device such as a switch or router e.g. through a network adapter.

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a standard server or multiple times in a group of such servers. It may also be implemented as part of a rack server system . In addition it may be implemented in a personal computer such as a laptop computer . Alternatively components from computing device may be combined with other components in a mobile device not shown such as device . Each of such devices may contain one or more of computing device and an entire system may be made up of multiple computing devices communicating with each other.

Computing device includes a processor memory an input output device such as a display a communication interface and a transceiver among other components. The device may also be provided with a storage device such as a microdrive or other device to provide additional storage. Each of the components and are interconnected using various buses and several of the components may be mounted on a common motherboard or in other manners as appropriate.

The processor can execute instructions within the computing device including instructions stored in the memory . The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide for example for coordination of the other components of the device such as control of user interfaces applications run by device and wireless communication by device .

Processor may communicate with a user through control interface and display interface coupled to a display . The display may be for example a TFT LCD Thin Film Transistor Liquid Crystal Display or an OLED Organic Light Emitting Diode display or other appropriate display technology. The display interface may comprise appropriate circuitry for driving the display to present graphical and other information to a user. The control interface may receive commands from a user and convert them for submission to the processor . In addition an external interface may be provide in communication with processor so as to enable near area communication of device with other devices. External interface may provide for example for wired communication in some implementations or for wireless communication in other implementations and multiple interfaces may also be used.

The memory stores information within the computing device . The memory can be implemented as one or more of a computer readable medium or media a volatile memory unit or units or a non volatile memory unit or units. Expansion memory may also be provided and connected to device through expansion interface which may include for example a SIMM Single In Line Memory Module card interface. Such expansion memory may provide extra storage space for device or may also store applications or other information for device . Specifically expansion memory may include instructions to carry out or supplement the processes described above and may include secure information also. Thus for example expansion memory may be provide as a security module for device and may be programmed with instructions that permit secure use of device . In addition secure applications may be provided via the SIMM cards along with additional information such as placing identifying information on the SIMM card in a non hackable manner.

The memory may include for example flash memory and or NVRAM memory as discussed below. In one implementation a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that when executed perform one or more methods such as those described above. The information carrier is a computer or machine readable medium such as the memory expansion memory memory on processor or a propagated signal that may be received for example over transceiver or external interface .

Device may communicate wirelessly through communication interface which may include digital signal processing circuitry where necessary. Communication interface may provide for communications under various modes or protocols such as GSM voice calls SMS EMS or MMS messaging CDMA TDMA PDC WCDMA CDMA2000 or GPRS among others. Such communication may occur for example through radio frequency transceiver . In addition short range communication may occur such as using a Bluetooth WiFi or other such transceiver not shown . In addition GPS Global Positioning System receiver module may provide additional navigation and location related wireless data to device which may be used as appropriate by applications running on device .

Device may also communicate audibly using audio codec which may receive spoken information from a user and convert it to usable digital information. Audio codec may likewise generate audible sound for a user such as through a speaker e.g. in a handset of device . Such sound may include sound from voice telephone calls may include recorded sound e.g. voice messages music files etc. and may also include sound generated by applications operating on device .

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a cellular telephone . It may also be implemented as part of a smartphone personal digital assistant or other similar mobile device.

Device may also include one or more different devices that are capable of sensing motion. Examples include but are not limited to accelerometers and compasses. Accelerometers and compasses or other devices that are capable of detecting motion or position are available from any number of vendors and can sense motion in a variety of ways. For example accelerometers can detect changes in acceleration while compasses can detect changes in orientation respective to the magnetic North or South Pole. These changes in motion can be detected by the device and used to update the display of the respective devices according to processes and techniques described herein.

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium computer readable medium refers to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

To provide for interaction with a user the systems and techniques described here can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

The systems and techniques described here can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here or any combination of such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network . Examples of communication networks include a local area network LAN a wide area network WAN and the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

A number of embodiments have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the invention. For example much of this document has been described with respect to messaging and mapping applications but other forms of graphical applications may also be addressed such as interactive program guides web page navigation and zooming and other such applications.

In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other embodiments are within the scope of the following claims.

