---

title: Real-time distributed tree
abstract: Some embodiments provide a real-time distributed tree (RDT) comprising scalability, protocol, and data layers for dynamically and in real-time defining and implementing customer applications over cloud operator resources. The RDT is a tree structure with customer branches comprising nodes hierarchically organizing domains, domain applications, and application rooms. Service layer service nodes can be linked to any customer branch node. Linking service nodes to the customer node reserves services represented by the service nodes for allocation to or scaling of any customer application or room under that customer branch. Linking service nodes to an application node or room node allocates the corresponding services to the application or room. The RDT moves linkages to maximize service usage and minimize wasted allocation. Protocol layer nodes modify signaling or messaging of the services implementing a customer application. Data layer nodes provide customizable four-dimensional storage of activity occurring anywhere in the customer branch.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09584440&OS=09584440&RS=09584440
owner: XIRSYS LLC
number: 09584440
owner_city: Valencia
owner_country: US
publication_date: 20151012
---
Much of today s digital content and services are consumed and delivered from the cloud . Generally the cloud refers to a distributed platform whose architecture and resources are operated and managed by one entity. Different customers leverage and rely on these resources to execute and deliver their applications to end users located throughout the world. By leveraging the cloud application providing customers can direct their focus to content and application creation rather than building and managing the infrastructure to serve the content and applications to end users.

Cloud operators include content delivery networks CDNs hosting providers or any operator operating multiple servers at different geographic locations for purposes of serving content and services of others. Akamai and Amazon Web Services are examples of some cloud operators. Together the cloud operators create a virtually unlimited resource pool from which application providers can reach end users.

The problem with cloud usage is the manual or human administrative and configuration overhead required to deploy applications thereon. This problem is evident in applications that are active for short periods of time and that can experience widely fluctuating demand. For example web real time communication WebRTC applications include live streaming events chat and other communication sessions online meetings and other online collaborations. These applications are relatively brief in length and can experience unexpected or large spikes in demand over that brief interval. These applications require rapid allocation and deallocation of resources service configuration and customization and attention to scaling. Such operations are normally beyond the automated functions of current cloud operators whereby cloud operators primarily deploy machines for customers to use and leave much of the configuration and customization of the machines up to the customers. As a result these applications can reintroduce much of the infrastructural overhead that the cloud was intended to remove and free application providers from.

Accordingly there is a need to simplify the deployment of WebRTC and other applications on the cloud. To this end there is need to obfuscate the allocation and scaling of the underlying services and resources on which the applications are implemented. There is further a need to automate the allocation and scaling of such services and resources with the automation occurring dynamically and in real time.

Some embodiments provide a real time distributed tree RDT offering different services that can be used to implement different customer applications over cloud operator resources managed by the RDT. The RDT automatically dynamically and in real time deploys allocates and scales the services and resources needed to implement the different customer applications on behalf of the RDT customers thereby freeing the customers from manually managing the infrastructure needed for the distribution of their applications. Furthermore the RDT greatly simplifies the deployment of those applications by providing the means with which customers can rapidly and easily configure customize and scale the services that execute the features and functionality of the applications on the cloud operator resources.

In some embodiments the RDT coalesces resources of one or more cloud operators. This provides the RDT with a virtually unlimited pool of resources onto which the RDT seamlessly transparently and automatically deploys services for the implementation of different customer applications. This coalescing of resources also allows the RDT to optimize customer applications by providing a geographically targeted deployment of the services.

The RDT is a tree structure comprising first tier identifiers hierarchically organizing different customers or customer domains second tier identifiers hierarchically organizing different customer applications and third tier identifiers hierarchically organizing different application instances also referred to as application rooms. Different scalability protocol and data layers are then linked to the tree and relinked about the various nodes at the first second and third hierarchically tiers to dynamically define the allocation of services protocols storage and other configurations and customizations.

The RDT scalability layer is comprised of different services nodes representing different services that can be used in implementing customer applications. Linking a service node to an RDT node allocates the service represented by the service node and the resources needed to execute the service to the corresponding customer domain customer application or application room identified by the RDT node. The linkages between the RDT and the scalability layer provide simply and efficient means by which the RDT can deallocate reallocate or scale a service as demand changes and services are onboarded and offboarded.

In some embodiments the protocol layers define the signaling and messaging that occurs between the services used to implement a common customer application. The protocol layers establish inter service dependencies and facilitate the scaling of a particular service used to implement a specific customer application. In some embodiments the protocol layers link users of a customer application directly or indirectly to various services implementing the customer application. Here the protocol layers define the signaling and messaging with which services and users of the customer application communicate and can thereby define the means by which customers access or engage with a service used in implementing a customer application. In some embodiments the protocol layers link the customer application and or the services implementing the application to the data layer. Here the protocol layers are used to track service activity occurring anywhere within the RDT.

In some embodiments the data layers provide four dimensional storage to compliment the RDT and more specifically to any node thereof. By leveraging the data storage capabilities customers can track any application or service related activity throughout the service duration. The storage is non destructive. In some embodiments the four dimensional storage tracks and organizes activity across path key layer and time dimensions. This provides for an organized hierarchical storage of the activity as well as efficient and simple retrieval of the activity when needed.

The first tier nodes represent application provider or customer domains. Applications that are reachable through the identified domains and defined by the second tier nodes rely on the RDT for automatic deployment allocation and scaling using RDT services and cloud operator resources managed by the RDT. It should be noted that a particular application provider or customer can place multiple domains under RDT control with each domain creating a new first tier node in the RDT.

The second tier nodes identify applications that are defined by the application providers or customers under each domain. The second tier nodes represent the applications that the RDT is tasked with implementing via automated service and resource allocation and scaling.

The third tier identify the application rooms. Each room represents a different instance of an application. For example a customer can define a chat application at the second tier of the RDT and the chat application can have different rooms representing different running instances of the application with each room having a different set of users participating in a different chat session.

The service layer nodes linked to a first tier node represent the various services that the RDT has dedicated for implementing any of the applications defined under the corresponding customer domain. These services can be reallocated to different applications or application rooms defined under the customer domain as they are needed.

The service layer nodes linked to a second tier node identify the services that the RDT has allocated and are in use in implementing a particular customer application represented by the corresponding second tier node . Should demand or usage of the allocated services exceed the allocated set of services the RDT automatically scales the service set by allocating additional services from the reserved set of services identified at the parent first tier node wherein the allocation of additional services is in response to the RDT linking additional service layer nodes to the second tier node of the corresponding particular customer application.

The protocol layer nodes define signaling and messaging for the customer applications and services implementing those applications. The protocol layer nodes can also establish communication between a service identified by a service node and the storage layer such that some or specific activity resulting from the service execution is tracked and recorded to storage. The data layer nodes track and record various service and application activity across the different dimensions according to a four dimensional storage of some embodiments.

The RDT service layer manages service allocation to different domains customer applications and application rooms. The allocated services are identified by service nodes that have been linked to the corresponding RDT first tier second tier and third tier nodes.

The RDT has an ever changing and dynamic form as customers add or modify tree branches and as the RDT links and relinks service nodes about the nodes of the tree branches. With each such linking the RDT reallocates and scales services and the corresponding resources between applications of the same or different domains in real time and in a geographically targeted manner as the services are needed. To determine where services are needed and where they are no longer needed the RDT monitors usage of each linked service node. In doing so the RDT manages service scaling and reallocation with little to no manual effort on the part of the customers.

Before a customer can request services from the RDT the customer creates its own branch in the RDT. The initial tier or first node in the customer branch provides some unique identifier. In some embodiments the unique identifier is a customer domain. The domain identifies the application provider or customer controlling the domain. In the second tier the customer creates application nodes identifying applications the customer implements using one or more of the RDT services executing over cloud operator resources. These applications are accessible from the domain identified as the first tier node from which the corresponding application second tier node branches off of. In the third tier and branching from any particular application node the customer creates application rooms. As noted above each room represents a different instance of an application. In some embodiments a customer can create different rooms to restrict which users can participate or access specific instances of an application.

The discussion above relating the first tier nodes to domains the second tier nodes to customer applications and the third tier nodes to application rooms is provided as preferred embodiments of the RDT. However the nodes need not be restricted only to such uses and implementations. The nodes can be containers of any kind to which different RDT services protocols and data storage from the different layers can be linked. In other words the RDT services protocols data storage and resources of different cloud operators under RDT control can be used to dynamically implement and scale any solution feature or functionality for a customer.

In this figure the customer branch first tier specifies example.com . The customer branch second tier specifies two applications entitled events and chat . The customer branch third tier specifies rooms Paris Singapore and Los Angeles for the events application. The events application can be representative of a live stream that is broadcast to users in three different regions or can alternatively represent three different live streams while the chat application can be representative of a chat room in which users can communicate with one another.

Once a customer creates a branch the customer requests services from the RDT in order to implement the various applications and application rooms defined therein. illustrates a first manner in accordance with some embodiments for requesting services under the RDT customer branch of . illustrates a second manner in accordance with some embodiments for requesting services under the RDT customer branch. In both figures an online interface or other dashboard is used in requesting services.

Using the interface or dashboard the customer requests services individually for each created room and . For each of the application rooms and the customer request granularly identifies different services for instantiating the overall customer application instance for that room. Specifically the customer requests a separate file system service a TURN server service and a web server service for implementing the application instance for each room and . The customer can then build or customize its application atop these RDT services using its own code scripts APIs or interface as some examples. These are examples of some granular services that a customer can request from the RDT. The customer also requests an all encompassing service such as a chat session service for implementing application . Requesting such an all encompassing service automatically instantiates different underlying services that are linked to and needed to implement the chat session service. For example the chat session service may require a STUN server and signaling server for its implementation with the RDT automatically including these sub services as part of the all encompassing chat session service. Here again the customer could customize the application i.e. chat session service by configuring the service or by deploying its own code scripts APIs or interfaces to run atop the RDT service.

In requesting RDT services the customer further identifies an expected usage. In some embodiments the expected usage is defined for the application or room for which services are requested. In some such embodiments the customer identified expected usage applies to all services requested for the application or room. In some other embodiments the customer defines the expected usage for each requested service individually. In the customer defines expected usage for rooms and but defines expected usage for each service of room individually. The expected usage is defined in terms of a number of users that are expected to access or otherwise participate. More sophisticated users could define expected usage in terms of expected load or resource utilization.

The RDT uses the customer identified expected usage in order to determine the quantity of the requested services to allocate to each room or application. A set of heuristics convert the expected usage to a quantity of the requested services for handling the anticipated load in each room. For each allocated service instance that is allocated to an application room the RDT links a corresponding service node representing the allocated service instance to the room node identifying the application room.

Each service node linkage then triggers the instantiation of an actual TURN server. Instantiating the TURN server services for room involves the RDT deploying the container packaging the TURN server software image to three different sets of resources in order to instantiate three TURN servers that are dedicated and customized for implementing the specific instance of the application in room . In terms of a live event the three allocated TURN servers assist different users in accessing the live stream presented in the corresponding application room.

Once the RDT allocates and instantiates a requested service for a particular customer application or application room the customer can then customize the service. Service customization is achieved by way of controlling or configuring the service. Service control and configuration is explained in greater detail below.

In some embodiments the service instantiation is time driven irrespective of when the customer defines and customizes the services for an application. As part of the expected usage definition the customer may specify when an event starts and ends. In such cases the RDT delays instantiating the services and resources for the event until just before the event start time. This ensures that services and resources are not unnecessarily allocated and do not remain unused. Similarly at the specified event end time the RDT may deallocate the event services and resources and reallocate them elsewhere if needed. Thus for live streaming events and other time specified applications customers can define the application and the services needed for the application in advance and the RDT will queue the instantiation of the services until the designated start time.

To further reduce customer effort in deploying their applications through the RDT provides an alternative means with which customers can request RDT services for implementing various customer applications and application rooms. In the customer requests services for the entire domain rather than each individual application or application room created under the domain. Additionally the customer identifies the aggregate expected usage for all applications created under the customer domain as well as all rooms for all applications under the customer domain .

Based on these parameters and as shown at the RDT links the appropriate quantity of requested service nodes under the first tier of the customer branch. The linkages trigger the actual instantiation of the services on cloud operator resources and allocation of the services to the corresponding domain for implementing any of the customer applications or application rooms defined thereunder. Continuing with the TURN server service example the RDT dedicates and customizes multiple TURN servers for the customer domain. However unlike in where different subsets of the TURN servers were dedicated to different rooms in all TURN servers are reserved under the customer domain without specific assignment to any application or room. The services can then be reallocated to different customer applications or application rooms as they are needed by shifting the corresponding service node down from the first tier node to the second tier node of the application or the third tier node o the application room where the service identified by the service node is needed. The RDT then configures the service for implementing the application or application room where it is allocated. In other words the RDT can use any of the services allocated at the first tier for scaling customer applications defined in the second tier and application rooms defined in the third tier dynamically and in real time as the services are needed and demand for the applications increases.

In either service requesting scenario of the customer is charged for the services that have been allocated to any tier in the customer branch. These services remain dedicated for the customer but can be reallocated and reconfigured for use in implementing any customer application or application room at no additional cost. Thus the allocated services are not statically linked to any particular application or application room. Instead the RDT deallocates services from applications or application rooms where they are no longer needed as a result of a decline in user usage as a result of the ending or closing of an application or application room or when a specified end time for an application or application room has been reached. The RDT then reallocates the services to other applications or application rooms of the customers that need additional such services either as a result of increasing demand or new applications or application rooms being instantiated by the customer or reaching a designated start time. In this manner the RDT frees the customer from having to manage the infrastructure connecting users to its applications. Instead the customer can focus on how to improve the user experience and better its offerings while the RDT goes about maximizing service usage and minimizing unnecessary service allocation on behalf of the RDT customers. Moreover the dynamic allocation of services provides cost savings to the customer. By removing extraneous or unused services from applications or application rooms where they are not needed the RDT eliminates fees associated with services that are allocated but that are unused.

In either service allocation of and to ensure service usage is maximized the RDT monitors actual demand at each tier of the various customer branches. In some embodiments each of the deployed services signals back usage statistics to the RDT. Alternatively the usage statistics can be obtained directly from the customer application rooms applications or domains. In some embodiments demand in a room is determined from the number of users that have accessed or joined that specific room. In some embodiments demand at the application level is determined from the total number of users that have accessed or joined any of the rooms defined from the application. In some embodiments demand at the customer level is determined from the total number of users accessing or joining the various applications offered by the customer. Usage of a service or application by users can be derived from a number of active HyperText Transfer Protocol HTTP connections or sessions to the service or application number of unique Internet Protocol IP addresses that access the service or application number of packets or aggregate byte count passing through the various instantiated services for an application or application room or by the number of user requests received by the service or application. The RDT has a holistic and granular view of demand at all times. Based on these views the RDT dynamically and in real time reallocates and scales the services where they are needed.

The RDT begins monitoring user access and usage of the various applications and application rooms under the first tier domain of the customer branch. The RDT determines that 50 users have accessed room 35 users have accessed room and 20 users have accessed room . In this example each service represented by one of the allocated service nodes handles up to 25 users.

To ensure that sufficient services have been allocated to each room and the RDT first checks to see if any service nodes have already been linked to rooms and . In this case no services have been linked to any of the rooms . Accordingly the RDT moves up one tier in the customer branch to the application second tier to seek out free service nodes. At the application second tier there are also no available service nodes. Once again the RDT moves up another tier to the first tier in search of free service nodes. As noted above the initial allocation based on expected usage has six service nodes allocated at the first tier. At the RDT shows the relinking of services from the service nodes of the first tier to the different application rooms and based on actual demand. Specifically the RDT links two service instances to room two service instances to room and one service instance to room with one unused service instance remaining linked at the first tier in case additional services have to be allocated to any of the rooms. In some embodiments linking a service instance involves reallocating and customizing the service and the resources that implement the service to the application instance represented by the application room node where the service is needed.

As can be seen the RDT takes a hierarchical approach to service scaling. When services in a particular room or third tier are exceeded the RDT queries the next higher tier i.e. application tier for unused services that can be used to scale the service in the lower level. If no services are available at the application tier the RDT then queries the domain tier in the customer branch for unused services that can be used to scale the services of lower tiers. When there are no available services at the domain level the RDT may allocate additional service nodes from the RDT root to the domain and then link the corresponding services of the allocated service nodes down the customer branch to where they are needed. Doing so however may come at additional cost to the customer as these services have been allocated in addition to services that had already been requested by the customer.

Service linking can also operate in reverse. Services that go unused or are extraneous for demand in a particular application room are deallocated from that particular application room and relinked to nodes at either the application or domain tiers. This makes the services available for other applications or rooms under the same domain where demand exceeds the services that have been allocated for those other applications or rooms. Service deallocation occurs whenever an application ends is offboarded or a designated stop time is reached. Such applications have no users or have ceased to function. Service deallocation also occurs when a usage threshold for a particular service is no longer exceeded by demand for a particular application or application room. For example a room may at some time be allocated with two instances of the same service. Demand in the room for the services gradually declines to a point in which only one instance of the service is sufficient to meet the demand. The RDT then deallocates one instance of the service and moves the corresponding service node representing the deallocated service up one or more tiers in the customer branch so that the service instance may be reassigned where needed.

The dynamic reallocation is extremely beneficial for streaming or live events. Usage of these events ramps up quickly therefore requiring service and resource scaling and allocation of several instances of the same service. However as soon as the event ends or is about to end most users if not all users leave the event leaving the services and corresponding resources unused and available for allocation to the next event. The RDT identifies the unused services that are available for reassignment by linking them back to the domain tier.

At the figure illustrates that user demand for services of room has declined to a point in which one of the allocated services is now superfluous. Accordingly the RDT deallocates service node from application room . In deallocating the service from room the RDT relinks the corresponding service node from the room tier to the domain tier although the service node could also be moved to the application tier.

At the figure shows usage in room has increased to the point that it exceeds a usage threshold for the services allocated to that room . Accordingly the RDT relinks the service represented by the freed service node originally allocated to room over from the domain tier to room thereby dedicating the corresponding service for implementing the application instance associated with the second room .

To ensure service availability and scalability the RDT compiles available and unallocated resources from multiple different cloud operators. This provides the RDT a pool of virtually unlimited resources over which a virtually unlimited number of services can execute. In some embodiments the RDT requests cloud operator resources on demand as each new service is deployed for a customer customer application or application room. In some other embodiments the RDT reserves a set of cloud operator resources. The RDT then repurposes the cloud operator resources for execution of different services as those services are deployed and allocated for the implementation of different customers customer applications and application rooms.

Due to cost reliability and performance variations on the cloud operator resources some embodiments qualify the services using one or more of these metrics. The metrics help differentiate services that may otherwise appear homogenous. For example TURN server services offered by the RDT may be deployed and executed on resources of two different cloud operators. Although the two TURN servers provide similar functionality executing the TURN server service on resources of the first cloud operator can be cheaper than executing the TURN server service on resources of the second cloud operator. Similarly the TURN server service may have better performance when executing on resources of the first cloud operator than when executing on resources of the second cloud operator. The qualifications provide the RDT as well as the RDT customers with greater control over cost reliability and performance parameters and in turn provide differentiation for the same service.

Performance variations can be due to the strength of the underlying resource e.g. a faster processor or greater bandwidth . Performance variations are also due largely in part to the geographic location of those resources. When a service executes over a first set of resources that are more proximally located to users using the service than a second set of resources the users are able to more quickly access the service as a result of the fewer network hops that are traversed in reaching the first set of resources executing the service. This translates to reduced service latency as each additional network hop traversed typically increases latency for a user receiving the service. Fewer network hops also means that there are fewer potential points of service failure thereby increasing reliability while reducing packet loss. Lastly fewer network hops means there are fewer potential network obstructions such as firewalls and misconfigurations that could block users from accessing the service.

Accordingly some embodiments further qualify services on the basis of geographic location when the services are tied to and execute using resources located in specific regions. In some embodiments services qualified to a particular geographic region are clustered together. This makes it easier for a customer to request services that are geographically optimized.

In service node cluster represents services running on resources located in North America i.e. a first region such that the services in cluster are optimized for users accessing and interacting with the services from within North America. Service node cluster represents services running on resources located in Europe i.e. a second region such that the services in cluster are optimized for users accessing and interacting with the services from within Europe. It should be apparent that the clusters can be defined more granularly to qualify services on the basis of Autonomous System AS number IP address block nation zip code or geographic coordinate identifiers as some examples.

This clustering allows a customer to request an RDT service and also identify the geographic region from which a majority of users are expected to access the service. In response the RDT allocates the service from the cluster optimally serving that geographic region.

In some embodiments the different RDT services are packaged in containers. The containers are stored in an RDT service store. The RDT service store is a repository from which service images stored in the containers can easily and rapidly be deployed to cloud operator resources in order to instantiate working instances of the services on the resources.

In some embodiments a container includes the code runtime system tools and system libraries of a given service. Each container need not include an operating system image. Instead the container software can be deployed to run over a host operating system that is already installed and running on resources used to execute the service. In some embodiments the services run as isolated processes in userspace on the host operating system. This greatly simplifies service deployment and allows multiple services to run on the same set of resources. In some embodiments the container images are not tied to any specific infrastructure such that the service software images can run on infrastructure of any cloud operator.

Each container may include metadata. The metadata can be used to define a minimum set of resources over which the container service executes. For example a given service may require a minimum amount of allocated memory processor and network bandwidth to function properly. The metadata assists the RDT in allocating the correct resources for the given service.

In some embodiments the containers include or are derived from containers of the Docker containerization technology. This is merely one example of a container that can be used in deploying RDT services. The RDT can seamlessly adapt to use other container technologies for the deployment of services and service software images for execution over resources of different cloud operators.

When a service node is linked to any of a first tier node second tier node or third tier node of the RDT the RDT allocates some set of resources from the available pool of cloud operator resources to execute the service represented by the linked service node. In some embodiments the amount of allocated resources can be set for a service i.e. minimum resource set or can be dynamically allocated based on an expected usage of the service. Once resources have been allocated the RDT deploys the container packaging the service software to the allocated resources. Deployment involves installing the service software on the allocated resources and beginning execution of the services with the allocated resources. In some embodiments service deployment also involves customizing the service for implementation of part or all of a particular customer application function or application room function.

In some embodiments the customer deploys its own software e.g. code scripts interfaces etc. atop the service. The RDT provides various interfaces or APIs that allow the customer software to be added atop any services deployed by the RDT on the customer behalf. The customer software can interact with the underlying service via function or API calls. In fact the customer software can control the service operation through the function or API calls. Service documentation provided by the RDT to the customer exposes the various calls commands and variables allowing communication between the RDT services and customer software.

In some embodiments services can also be customized by configuring various exposed parameters of the services. The parameters can be configured prior to installing the software on the resources or after installation thereon. A customer can directly configure the service parameter using RDT interfaces or APIs. In some embodiments the customer enters configuration parameters for one or more requested services in a configuration file. The customer uploads the configuration file to the RDT where it is stored under the customer branch. Thereafter when the RDT deploys a service to a particular customer application the RDT scans the configuration file to identify customer specified configuration parameters for the service implementing the particular customer application. The RDT then automatically configures the service according to the customer specified configuration parameters.

In some embodiments the customer specified configuration file or configuration parameters can be stored to the RDT data layer. In some such embodiments a data layer node storing customer provided configuration parameters is linked to an application node or application room node of the RDT.

The protocol layer can be used to scale and adapt signaling and messaging of RDT services and customer applications. By adapting the signaling and messaging the protocol layer can be used to control inter service dependencies and the manner with which users access or engage with the services that implement various customer applications. In some embodiments the protocol layer links customer applications and or the services implementing the applications to the data layer. Here the protocol layer is used to track service activity occurring anywhere within the RDT.

The protocol layer can adapt service or application signaling and messaging in different ways. The adaptation occurs whenever one or more protocol layer nodes are linked to a customer application node or directly to a service node implementing a customer application.

One adaptation involves changing service messaging and connection formats. In some embodiments the protocol layer can adapt messaging of a particular service for either connectionless passage or connection oriented passage. In so doing any RDT service can be optimized via different protocol layer nodes for implementation of a time sensitive customer application or for implementation of a customer application where reliability is paramount. For instance a first protocol layer node linked to a particular service node encapsulates messaging produced from the corresponding service as User Datagram Protocol UDP packets that are then sent to the intended destination using UDP. A different second protocol layer node linked to the particular service node can instead encapsulate the service messaging as Transmission Control Protocol TCP packets that are then sent to the intended destination using TCP. The protocol layer nodes could also be linked to the particular application node. This linkage adapts all messaging from the particular application for either connection oriented or connectionless transmission as determined by the protocol layer node that is linked to the particular application node.

In some embodiments the protocol layer changes service messaging and connection format by adding encryption support to service communications. In some such embodiments a protocol layer node linked to a particular service node causes all communications between the service identified by the particular service node and other services and users to be encrypted.

The protocol layer can also adapt service or application messaging and connection formats for security reasons. The protocol layer can be used to restrict the kinds of messages that a service accepts as input or the content of the messages. For example the protocol layer can define various filters or signatures to detect and block malicious traffic.

As noted above the protocol layer can also be used to establish inter service dependencies. The protocol layer nodes can be linked to different service nodes to establish the manner with which the output from one service is fed as input to another service or to a user. In this manner the protocol layer nodes can define service execution ordering for a customer application. The protocol layer nodes also define the permitted service to service communication and service to user communication.

The protocol layer nodes can also be used in some embodiments to expand service reach. In some such embodiments the protocol layer nodes when linked to the service nodes enable the corresponding services to communicate with different devices. For example the RDT may link multiple protocol layer nodes to a particular service node in order to enable the corresponding service identified by the service node to accept messaging from mobile devices personal computers and Internet of Things IoT devices. In such cases the protocol layer nodes can be used to define the messaging format for input to and output from a particular service. The protocol layer nodes can also be used to expand the ports or websockets over which a service listens and communicates.

In some embodiments the protocol layer nodes link the service layer to the data layer. These links define the service activity the RDT tracks and stores to the data layer. The protocol layer nodes could also establish links between nodes of a customer branch and the data layer. These links define the domain application or application room activity that the RDT tracks and stores to the data layer. In this manner the protocol layer links determine what information is stored to the data layer.

In accordance with some embodiments illustrates defining a link between a customer application room and the data layer. In this figure a customer has defined an RDT branch with an application node representing a chat application created by the customer. The application node has multiple application room nodes connected to it. Each room node represents a chat room with different sets of users. A protocol layer node links the third room node to the data layer. This link causes the RDT to record all chat activity occurring in the third room to a specific data layer node representing storage that is specifically dedicated to that chat room .

The RDT data layer can be used to track activity occurring at any node within the tree structure. Accordingly the data layer can track and store activity in conjunction with any customer domain customer application or customer application. The data layer can also track and store activity in conjunction with any service that is deployed on behalf of a customer. As noted above the protocol layer can be used to define what activity is to be recorded by linking various nodes of the customer branch or service nodes to the data layer.

In some embodiments the data layer tracks designated activity across four dimensions. The four dimensions provide an efficient storage and retrieval mechanism as well as non destructive storage of the activity. All historic activity can be tracked without being overwritten even as values for the same tracked variables change over time or change throughout the duration of a service. In some embodiments the data layer via the four dimensional storage can be used to record chat sessions meetings and other such user interactions or communications.

The four dimensional storage expands on traditional key value stores by adding two additional dimensions by which activity is tracked. In some embodiments the four dimensional storage records activity across path key layer and time dimensions.

The first dimension identifies a tree path. The path identifies the domain or customer service or application and room where the activity occurs. The path also identifies the location where the activity should be stored or retrieved from.

The second dimension is the key for the storage key value pair. The key represents a data instance or variable. The second dimension allows customers to target and record specific activity generated from a service.

The third dimension introduces layers. The layers allow the targeted activity to be indexed. In other words the layers can be used to assign different values to the same data instance or variable. By default all activity is stored to a default layer. However an arbitrary number of layers can be specified in order to track additional activity or values to the same key value pair. For example a first layer can be used to record a first value that a first service produces for a particular data variable and a second layer can be used to record a second value that a different second service produces for the same particular data variable. The layers also allow targeted activity to be indexed. In other words the layers can be used to assign different values to the same data instance or variable. By default all activity is stored to a default layer. However an arbitrary number of layers can be specified in order to track additional activity or values to the same key value pair.

The fourth dimension introduces time as part of storage. The time element allows a specific data instance or variable to have multiple different values at different points of time. Therefore as data changes the previous history for that data is preserved such that it is still accessible. For example a command such as node.time series path key layer mylayer returns a list of values that the identified key at the path had at different recorded times. Each value is presented with a timestamp to indicate when the key had the identified value. Such four dimensional storage is useful to track chat history between users in a given room as one example.

These four dimensions provide full customizability in what data is tracked and stored and how it is retained. Such storage can be added to any node of the RDT. When added to a particular node storage can be configured for all activity at that particular node and optionally any sub nodes branching from the particular node.

Many of the above described processes and components are implemented as software processes that are specified as a set of instructions recorded on a non transitory computer readable storage medium also referred to as computer readable medium . When these instructions are executed by one or more computational element s such as processors or other computational elements like ASICs and FPGAs they cause the computational element s to perform the actions indicated in the instructions. Server computer and computing machine are meant in their broadest sense and can include any electronic device with a processor including cellular telephones smartphones portable digital assistants tablet devices laptops notebooks and desktop computers. Examples of computer readable media include but are not limited to CD ROMs flash drives RAM chips hard drives EPROMs etc.

The bus collectively represents all system peripheral and chipset buses that communicatively connect the numerous internal devices of the computer system . For instance the bus communicatively connects the processor with the read only memory the system memory and the permanent storage device . From these various memory units the processor retrieves instructions to execute and data to process in order to execute the processes of the invention. The processor is a processing device such as a central processing unit integrated circuit graphical processing unit etc.

The read only memory ROM stores static data and instructions that are needed by the processor and other modules of the computer system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the computer system is off. Some embodiments of the invention use a mass storage device such as a magnetic or optical disk and its corresponding disk drive as the permanent storage device .

Other embodiments use a removable storage device such as a flash drive as the permanent storage device Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such as random access memory RAM . The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments the processes are stored in the system memory the permanent storage device and or the read only memory .

The bus also connects to the input and output devices and . The input devices enable the user to communicate information and select commands to the computer system. The input devices include alphanumeric keypads including physical keyboards and touchscreen keyboards pointing devices. The input devices also include audio input devices e.g. microphones MIDI musical instruments etc. . The output devices display images generated by the computer system. The output devices include printers and display devices such as cathode ray tubes CRT or liquid crystal displays LCD .

Finally as shown in bus also couples computer to a network through a network adapter not shown . In this manner the computer can be a part of a network of computers such as a local area network LAN a wide area network WAN or an Intranet or a network of networks such as the Internet .

As mentioned above the computer system may include one or more of a variety of different computer readable media. Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. SD cards mini SD cards micro SD cards etc. magnetic and or solid state hard drives ZIP disks read only and recordable blu ray discs any other optical or magnetic media and floppy disks.

In the preceding specification various preferred embodiments have been described with reference to the accompanying drawings. It will however be evident that various modifications and changes may be made thereto and additional embodiments may be implemented without departing from the broader scope of the invention as set forth in the claims that follow. The specification and drawings are accordingly to be regarded in an illustrative rather than restrictive sense.

