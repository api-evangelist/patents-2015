---

title: System and method for static and moving object detection
abstract: A method for static and moving object detection employing a motion computation method based on spatio-temporal tensor formulation, a foreground and background modeling method, and a multi-cue appearance comparison method. The invention operates in the presence of shadows, illumination changes, dynamic background, and both stopped and removed objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09454819&OS=09454819&RS=09454819
owner: The United States of America as represented by the Secretary of the Air Force
number: 09454819
owner_city: Washington
owner_country: US
publication_date: 20150710
---
The invention described herein may be manufactured and used by or for the Government for governmental purposes without the payment of any royalty thereon.

In real world monitoring applications moving object detection remains to be a challenging task due to factors such as background complexity illumination variations noise and occlusions. As a fundamental first step in many computer vision applications such as object tracking behavior understanding object or event recognition and automated video surveillance various motion detection algorithms have been developed ranging from simple approaches to more sophisticated ones 11 .

The present invention comprises a novel hybrid moving object detection system and method that uses motion change and appearance information for more reliable detections over the prior art. The main features of the invention are i A motion computation method based on spatio temporal tensor formulation named flux tensor ii A novel split Gaussian method to separately model foreground and background iii A robust multi cue appearance comparison module to remove false detections due to illumination changes shadows etc. and to differentiate stopped objects from revealed background by removed objects. The invention can handle shadow illumination changes ghosts stopped or removed objects some dynamic background and camera jitter while still maintaining a fast boot strapping. The invention outperforms most well known prior art techniques on moving object detection.

Previous methods employing flux tensor models alone work well if there is motion in the video. So if a person or object is moving then the flux tensor will work. But if the person or object stops or moves very slowly then the flux tensor will not be able to detect the object. 10 

The present invention FTSG Flux Tensor with Split Gaussian models is able to detect moving objects that become stationary and stop. Other patented and published methods would also fail in this situation as after some time period depending on an update or learning parameter the stopped object would be considered as part of the background and not be detected any further i.e. it would disappear into the background as it is no longer moving. This is a similar situation to a person who walks into a room and sits down in a couch. Initially the person would be detected by flux and other methods. But after varying time periods ranging from a few tenths of a second to a few seconds or longer depending on the update parameter the flux and other competitive methods would then classify the sitting person as background and no longer be able to detect the person until they start to move again.

The present invention FTSG however is able to detect the person when they walk into the room and during the entire period that they are sitting in the chair stationary they are still detected accurately using the change detection model. This makes the present invention very robust. Additionally when a stationary object moves the background behind the object is often misclassified as foreground or an object of interest in prior art methods. In the present invention the FTSG classifies this scenario by labeling these pixels in each video frame as a revealed background . This gives more accurate information for providing alerts to an operator or for providing detections for a tracking algorithm that labels changed pixels as one of multiple categories including revealed background shadow and so forth instead of only background and foreground.

The present invention is also able to properly handle dynamic backgrounds such as a fountain waves sun glint illumination change weather like rain snow and dust by filtering out this spurious motion. Most other prior art methods including those relying on the flux tensor methods alone would respond to these environmental changes as foreground motion and falsely identify many pixels as being important. In reality if we are tracking a person walking in rain or skating in snow we only want the output of the method to indicate the pixels where the person is located. The present invention is capable of distinguishing between background environmental changes that induce false motion from the true motion of foreground objects targets of interest.

The present invention uses a split Gaussian representation to model the foreground and background that is based on two separate probability models one for the object appearance and a separate probability model for the changing background. The split Gaussian is different from the commonly used approach of a single Mixture of Gaussians MOG or Gaussian Mixture Model GMM to model both the foreground and background used by other static and moving object detection methods. Although a single mixture of Gaussians can be used for the foreground background model the split Gaussian is more flexible and provides better overall video change detection performance.

The present invention incorporates a method for automatic learning of parameters for each pixel or region in the image that is not hard coded or predetermined but adaptive to the specific video being analyzed and the spatiotemporal context of the object being tracked. This significantly reduces the number of parameters that needs to be manually specified and increases detection accuracy due to automatic parameter adaptation. For example the number of Gaussians. K for any given pixel in the split Gaussian background model is not fixed a priori but is updated on every frame as new information about the scene is observed and measured in the video.

The present invention associates a semantic label with each pixel that is identified as having changed in the scene using a combination of processing algorithms including information provided by the flux tensor model split gaussian model appearance agreement with foreground model blob size and object based analysis. The semantic label processing enables categorizing changed pixels as being associated with six or more categories including a true moving object stopped object shadows and illumination change static background a revealed background when a stationary object moves a dynamic background arising from constant motion such as a water fountain or sun glint from the waves off a water surface.

The invention fuses two or more types of motion information at the pixel level by combining the flux tensor response jointly with the Gaussian mixture response to facilitate detection of both moving objects and those moving objects which have stopped or whose velocity has become very low. The invention can be extended to fuse other sources of information such as optical flow texture information shape information or depth information.

The present invention can be applied to video taken by a moving camera such as a camera mounted on an airplane or drone after the sequence of video frames is registered and stabilized with respect to an internal or external reference system. A possible internal reference system is one or more base image frames from the video to which other nearby frames are registered or with respect to an external reference system including a physical geospatial map of the indoor or outdoor scene.

It is therefore an object of the present invention to provide moving and stationary object detection with improved performance and accuracy over the prior art.

It is a further object of the present invention to provide a method for moving and stationary object detection that can discriminate between stationary objects and stationary background.

It is still a further object of the present invention is to provide a method for moving and stationary object detection that reduces false detections due to shadowing illumination changes background dynamics and camera jitter.

Briefly stated the present invention achieves these and other objects through a method for static and moving object detection employing a motion computation method based on spatio temporal tensor formulation a foreground and background modeling method and a multi cue appearance comparison method. The invention operates in the presence of shadows illumination changes dynamic background and both stopped and removed objects.

According to an embodiment of the invention a method for static and moving object detection from a source of video images pixel level motion from said video images is detected where the detection comprises performing motion segmentation and performing background subtraction where background subtraction further comprises modeling image background and modeling image foreground separately from each other and where background modeling comprises an adaptive plurality of Gaussians fusing the results of motion segmentation background modeling and foreground modeling so as to identify moving foreground objects and static foreground objects and discriminating among static foreground objects so as to classify them as either stopped objects or background.

The above and other objects features and advantages of the present invention will become apparent from the following description read in conjunction with the accompanying drawings in which like reference numerals designate the same elements.

Referring to depicts the present invention s system flow diagram. Flux Tensor with Split Gaussian models FTSG consists of three main modules described below 

a Pixel level motion detection module two complementary methods flux tensor based motion detection and split Gaussian models based background subtraction run separately on input images and produce foreground detection results.

b Fusion module flux tensor based and split Gaussian based detection results are fused using a rule based system to produce improved results that reduce errors due to noise illumination changes and halo effects.

c Object level classification module removed and stopped objects are handled. Edges of the static objects in foreground detection mask are compared to the edges of the corresponding object in current image and background model using chamfer matching . Detailed descriptions of each component are given in the following sections.

Motion blob detection is performed using multichannel version of flux tensor method 3 which is an extension to 3D grayscale structure tensor. Using flux tensor motion information can be directly computed without expensive eigenvalue decompositions. Flux tensor represents the temporal variation of the optical flow field within the local 3D spatiotemporal volume. In expanded matrix form flux tensor is written as 

Gaussian models have been widely used in background subtraction methods. Mixture of Gaussians can efficiently represent multimodal signals which makes them suitable for background modeling and subtraction. We adopt mixture of Gaussians as our background model. However unlike MoG in 12 where background and foreground are blended together into a single model with fixed number of Gaussians we model foreground and background separately and use adaptively changing number of Gaussians for the background model . This simplifies the background foreground classification step prevents background model from being corrupted by foreground pixels and also provides better adaptation for different background types static vs. dynamic backgrounds . This approach has fast boot strapping adaptive updating and complex background environment modeling capabilities. Background model We use a mixture of K Gaussians to model the background where K is a spatially and temporally adaptive variable. Every new pixel value I x y is checked against the existing K Gaussian distributions. A match to a Gaussian is defined as pixel values within Tb standard deviations of the mean 

Referring to static foreground regions Fare identified within ambiguous detections Fusing foreground model 

The goal of this decision fusion module is to exploit complementary information from two inherently different approaches to boost overall detection accuracy. Referring to flux tensor based motion segmentation produces spatially coherent results due to spatio temporal integration. These results are also robust to illumination changes and soft shadows due to use of gradient based information. But since the method relies on motion it fails to detect stopped foreground objects and tends to produce masks larger than the objects. Background subtraction on the other hand can detect stopped objects but is sensitive to noise illumination changes and shadows. Here the present invention extends flux tensor based motion segmentation with split Gaussian foreground and background models to generate a more complete and accurate foreground object detection method.

Referring to shows fusion flow chart and some examples of flux tensor and split Gaussian model fusion results. Pixels that are detected as foreground by both flux tensor and split Gaussian background subtraction are classified as moving foreground objects . Pixels that are detected as foreground by background subtraction only and have a match in foreground model correspond to static foreground objects .

Still referring to the present invention classifies both stopped objects true positives and revealed background by removed objects false positives as static foreground see . Distinguishing these two types of static foreground can effectively reduce the false positive rate and tackle deadlock problem. The present invention s method used for removed and stopped objects classification see is based on 6 which basically has three steps 1. Identify pixels corresponding to static regions 2. Perform edge detection on static regions in current image background generated by background subtraction and foreground detection mask and 3. Perform classification based on edge matching .

Referring to and show classification examples for stopped object an abandoned bag and revealed background by removed object ghost effect due to background model initialization respectively. Stopped object has higher edge similarity between current image and foreground mask while revealed background by removed object has higher edge similarity between background model and foreground mask.

The proposed flux tensor with split Gaussian models system is evaluated using the dataset and evaluation metrics in CVPR 2014 Change Detection challenge 7 . One fixed set of parameters is used for all the sequences. The learning rate a is 0.004 for background model and 0.5 for foreground model. The matching threshold Tin Eq. 3 is 3 and the similarity matching threshold Tin Eq. 5 is 20. The threshold for flux tensor to segment moving foreground object from non moving background is dynamically changing according to the number of Gaussians distributions at each pixel location. This avoids the use of a fixed global threshold unlike most other temporal differencing methods.

Referring to shows the comparison result of present invention s FTSG methodology with other state of the art change detection methods. Evaluation scores of those methods are obtained from http www.changedetection.net. The best result of each metric is highlighted and in all the measures listed in . It can be seen that the present invention s FTSG methodology outperforms all the listed methods in five out of seven measures and has the second best score in the remaining two measures specificity and FPR.

Referring to shows results of the proposed approach on all eleven scenarios. On seven out of eleven scenarios and on the overall evaluation the present invention s FTSG methodology outperforms not only the listed state of the art methods but also the new change detection challenge submissions in terms of average ranking.

Referring to shows moving object detection results for various algorithms including proposed Flux Tensor with Split Gaussian models FTSG on CVPR 2014 Change Detection dataset 7 with some typical frames selected from the 11 categories. The proposed FTSG is robust to illumination changes col 1 it can detect long term static objects col 3 and it also handles dynamic background col 2 . Image in col 4 demonstrates that FTSG can correctly identify revealed background by removed object and image in col 5 shows that the present invention s FTSG methodology can adapt to scene changes quickly sudden change of camera focus .

A simulation prototype of the present invention implemented in Matlab runs at 10 fps for a 320 240 video. Matlab implementation of flux tensor only detection runs at 50 fps. flux tensor computation can be easily parallelized for different architectures as in 10 because of the fine grain parallelism of the filter operations.

Having described preferred embodiments of the invention with reference to the accompanying drawings it is to be understood that the invention is not limited to those precise embodiments and that various changes and modifications may be effected therein by one skilled in the art without departing from the scope or spirit of the invention as defined in the appended claims.

