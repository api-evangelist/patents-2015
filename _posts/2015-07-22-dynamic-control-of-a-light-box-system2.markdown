---

title: Dynamic control of a light box system
abstract: This disclosure relates to systems and methods for controlling a light box system. The light box system can be used to create lighting for a virtual environment. The light box system, also referred to as a light box, can be formed from a plurality of walls that form a room-like structure. Each wall of the light box can include a plurality of light projection elements. The light projection elements can be light emitting diodes (LED) that can project light within the interior of the light box. The light projection elements can output light towards the interior of the light box in order to generate calculated light output for a virtual environment. The lighting characteristics of the virtual environment can be modified to change the calculated lighting output for a virtual environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619931&OS=09619931&RS=09619931
owner: Electronic Arts Inc.
number: 09619931
owner_city: Redwood City
owner_country: US
publication_date: 20150722
---
During film production motion capture or other video capture having proper lighting on an actor or object can be an important factor during the filming of a scene. Physical lighting devices can be used to create the desired lighting effects on set. However when filming a scene in a virtual environment such as in space it can be a difficult process to determine the correct lighting during a scene. For example a film can be created using a green screen and during post production lighting effects can be introduced using post processing techniques. This can be a time consuming and expensive process. Some film productions have used large screens such as light emitting diode LED screens to produce the light for a virtual environment. However this can be a difficult process as the entire sequence of lighting events for a scene needs to be created and prerendered prior to filming. During filming if changes to the scene need to be made production must stop until the changes to the scene can be made the environment is rendered again. This can be difficult time consuming and costly process.

The systems methods and devices of this disclosure each have several innovative aspects no single one of which is solely responsible for the all of the desirable attributes disclosed herein.

One embodiment discloses a computer implemented method for dynamically controlling the operation of a light box system the method comprising by a hardware processor executing a light box control application loading a virtual environment from an environment data store the virtual environment comprising a plurality of environment elements loading light box configuration information from a light box system the light box configuration information identifying a plurality of light projection elements disposed within the light box system determining a location of the light box within a portion of the virtual environment determining lighting parameters associated with environment elements within the portion of the virtual environment rendering the portion of the virtual environment based at least in part on the lighting parameters associated with the environment elements and the location of the light box within the virtual environment and generating instructions controlling the output of at least a subset of the plurality of the light projection elements within the light box wherein the output of the light projection elements is based at least in part on the rendering of the portion of the virtual environment.

Another embodiment discloses a light box control system comprising a data store configured to store environment data a hardware processor in communication with the data store and a light box interface the light box system interface configured to communicate with a light box system the hardware processor configured to execute a light box control application the light box control application configured to load a virtual environment based at least in part on environment data stored in the data store the virtual environment comprising a plurality of environment elements load light box configuration information associated with the light box system the light box configuration information identifying a plurality of light projection elements disposed within the light box system determine a location of the light box system within a portion of the virtual environment render the portion of the virtual environment based at least in part on lighting parameters associated with the environment elements and the location of the light box within the virtual environment calculate light output data for at least a subset of the plurality of light projection elements based at least in part on the rendered virtual environment and generate instructions configured to control the output of at least the subset of the plurality of the light projection elements within the light box system comprising the light output data.

Another embodiment discloses a non transitory computer readable medium comprising computer executable instructions for dynamically controlling the operation of a light box system that when executed by a computer cause the computer to perform a method comprising loading a virtual environment from an environment data store the virtual environment comprising a plurality of environment elements loading light box configuration information from a light box system the light box configuration information identifying a plurality of light projection elements disposed within the light box system determining a location of a representation of the light box within a portion of the virtual environment rendering the portion of the virtual environment based at least in part on the lighting parameters associated with the environment elements and the location of the light box within the virtual environment and generating instructions controlling the output of at least a subset of the plurality of the light projection elements within the light box wherein the output of the light projection elements is based at least in part on the rendering of the portion of the virtual environment.

Although certain embodiments and examples are disclosed herein inventive subject matter extends beyond the examples in the specifically disclosed embodiments to other alternative embodiments and or uses and to modifications and equivalents thereof.

This disclosure relates to systems and methods for controlling a light box system. The light box system can be used to create lighting for a virtual environment for a film segment. The light box system also referred to as a light box can be formed from a plurality of walls that form a room like structure. For example the light box may include bottom top and side walls. In some embodiments each wall of the light box can include a plurality of light projection elements. The light projection elements can be light emitting diodes LED that can project light within the interior of the light box. In some embodiments the light projection elements substantially cover the entire light box including the bottom top and side walls of the light box. The light projection elements are configured to output light towards the interior of the light box in order to generate calculated light output for a virtual environment. For example the light box can be used to recreate a virtual environment such as space a stadium a house or any virtual environment. The lighting characteristics of the virtual environment can be modified to change the calculated lighting output for a virtual environment. For example a position of the sun can be changed the type of light source can be changed for example replacing the sun with the moon or other types of changes to the virtual environment can be made in order to change the calculated light output for the light projection elements.

The light projection elements and the virtual environment can be controlled by a virtual environment control application. The virtual environment control application can load a virtual environment into an environment engine. The virtual environment can be stored in an environment data store. The environment engine can control and manipulate the virtual environment in order to position the virtual environment within the light box structure. For example the virtual environment may be a castle a city a building a cave or other type of three dimensional environment. The virtual environment can be any type of three dimensional environment that is loaded into the environment engine. The virtual environment includes virtual environment elements that are used to form the virtual environment. For example the environment elements can include terrain such as for example mountains valleys streets water snow grass and the like objects such as for example trees bushes rocks buildings walls and the like and other elements within the environment.

The environment engine can be used to navigate through the virtual environment and can output any location of the virtual environment within the light box structure. The light box can function like a large inward facing television screen that may substantially cover the entire light box. From the interior of the light box it may appear as if an actor was located within the selected location of the virtual environment. The environment engine can emulate and calculate the lighting based on the environment element parameters of the virtual environment. The interior of the light box can be used as focal point for the environment engine to calculate and generate the light output values for the light projection elements.

The calculated light output values can be based on the environment element characteristics within the virtual environment. For example the virtual environment can include a light source such as the sun the light box can calculate output values for the light projection element based on the light source and the other environment elements within the virtual environment. In some embodiments the calculated output values may include color hue saturation light intensity and other characteristics that can be used to control the output of a light projection element. The light box can provide lighting for an actor within the light box structure that emulates the virtual environment lighting. The lighting calculated for the virtual environment can be output and projected onto the actor within the light box in order to recreate the light corresponding to a determined location and setting within the virtual environment. In some embodiments the light box can produce lifelike lighting during a filming segment. For example the light box can create the proper shadows on a character at a specified time of day create reflections on a football player s helmet within a stadium generate lighting for an imaginary world with a green sun or generate lighting associated with another virtual environment. The calculated lighting can be rendered and output during the capture of a film segment. In some embodiments this can save significant time and reduce the post production costs of generating lighting effects after the film segment has been captured. The environment engine can also communicate with the camera control application in order to control the operation of the motion control camera system.

In some embodiments the environment engine can dynamically modify the virtual environment at any time. The environment engine can render and calculate the output for the light box dynamically. In some embodiments the virtual environment can be continuously rendered rendered at a defined frequency or aperiodically rendered in order to output the calculated light values to the light box for visualization of the virtual environment within the light box. The parameters of the environment elements can be modified by the environment engine. The environment engine can dynamically modify the light output associated with a location within a virtual environment by modifying the parameters of the environment elements. For example the environment engine can change lighting parameters of a light source such as brightening or dimming the light source change the type of a light source such as replacing the sun with the moon change the position of a light source such as moving the position of a light within a bedroom change position of an environment element within the virtual environment such as opening or closing a window or door and or perform other modifications to the virtual environment. In some embodiments a virtual environment may have defined constraints that determine the type of modifications that can be performed on environment elements within the virtual environment. For example the position of the sun may only move through a defined arc. In some embodiments the environment engine can output the instructions to the light projection element using high dynamic range HDR lighting. HDR lighting can be used to output a more diverse lighting range.

In some embodiments the environment engine can generate movement of the virtual environment within the light box. The virtual environment can be moved along a defined path within the virtual environment. With reference to a virtual environment of a city a determined film segment may entail an actor driving down a city street and making a left turn down a road. The actor may be sitting in a car located within the light box to simulate driving through the city. The environment engine can move the virtual environment along a defined path relative to the light box at a speed in accordance with the parameters of the film segment. The movement of the virtual environment within the light box can provide the appearance that the actor is moving along the defined path. The light box can generate the lighting associated with driving through the city such as street lights reflecting off the surface of the vehicle and other lighting effects. The environment engine can modify the film segment dynamically according to any changes that may want to be made to the film segment. For example the environment engine can change the characteristics associated with movement of the vehicle within the virtual environment such as the speed the driving path of the vehicle such as turn right instead of left lighting characteristics within the virtual environment such as changing the time of day adding additional light sources and the like or any other modification to the virtual environment and or film segment. The camera control application can also modify the operation of the motion control camera system during the filming.

In some embodiments the output generated by the light projection elements can be more coarse than a desired appearance of the virtual environment. For example the light box may be used to create correct lighting on the actors and not necessarily create the final environment for the film segment. In some embodiments it can be beneficial to utilize a masking procedure in order to remove the light box structure from the captured video segment. For example the light projection elements can pulse at an imperceptible rate. The system can then use the data to differentiate between the light box and the actors and or other physical objects within the light box. A system such as the virtual environment control application or another post processing system can be configured to automatically remove the light box from a filmed sequence.

In some embodiments the dynamic control of the virtual environment by the environment engine can greatly enhance video production by creating real time lighting effects in virtual environments. Additionally as opposed to green screen the actor can visualize the actual virtual environment. The systems and methods can create dynamic lighting for recording film segments within virtual environments which in some embodiments can more lifelike lighting and greatly reduce the amount of post processing.

Although this disclosure focuses on generating light for video production it should be understood that embodiments described herein can be used with other types of applications that utilize dynamic lighting. For example an application for taking photographs in virtual environments may use one or more embodiments of the present disclosure.

The light box system can be described with additional reference to the embodiment of a light box system disclosed in . The light box system can comprise a plurality of walls to form a box like structure. Each wall within the structure can include a plurality of light projection elements . In some embodiments the light box can be constructed to resemble a hollow cube or rectangular prism such as illustrated in . The size and shape of the light box structure can vary dependent upon the specific configuration or application. For example in one embodiment the light box can have a height and width greater than 20 feet whereas in other embodiments the light box may be considerably smaller or larger. Additionally the light box is not limited to a box or rectangular structure. For example in some embodiments the light box may be configured as a circular structure.

In some embodiments the interior walls of the light box can be constructed of a plurality of panels with each panel comprising a plurality of light projection elements . For example as illustrated in a plurality of light projection elements are disposed on a side wall within the light box . In the embodiment illustrated in all of the illustrated walls of the light box structure include light projection elements. In the embodiment illustrated in only a single wall of the light box structure is illustrated as including light projection elements . In some embodiments a plurality of walls can include light projection elements . For example in some embodiments such as in the embodiments illustrated in the top bottom and side walls can include light projection elements . As illustrated the plurality of light projection elements can be configured in an array covering substantially the entire wall . In some embodiments the light projection elements can be in different configurations be located on less than all of the panels and or walls within the light box . The size and density of the light projection elements within the array of may be dependent upon the physical and electrical characteristics of the light projection elements . In some embodiments the light box may include multiple different types sizes and or shapes of light projection elements within the light box. In some embodiments the light projection elements can be an array of LEDs. In some embodiments the spacing of the light projection elements may be different such that the spacing is not perfectly aligned in rows and columns.

The light projecting array can function similar to a large screen such as a large television screen configured to illuminate the interior of the light box . A light box can include millions of individual light projection elements each of which can be individually controlled or controlled in groups. In some embodiments each pixel rendered within a virtual environment can correspond to an individual light projection element that can be controlled by the light box control system . The light projection elements can project light in accordance with the specifications of the make and manufacture of the light projection element . For example the light projection element can project a full range of colors of different hues saturations and other color parameters. Each light projection element can be controlled in accordance within defined lighting specifications based on instructions generated by the light box control system . The light projection elements can act together as a giant screen to display moving sequences of light and color such as a movie screen displaying a movie. The light projection elements can be configured to output light towards the interior of the light box in order to generate calculated light output for a virtual environment. For example the light box can be used to recreate a virtual environment such as space a stadium a house or any virtual environment. The lighting within the light box can be changed by the light box control system by manipulating the virtual environment which can change the lighting within the light box wall without moving any physically lighting. In some embodiments the light box can be configured to output calculated illumination inside the light box based on a defined space within the light box .

In some embodiments the light box system can include a light box movement control system . The movement control system can be coupled to light box structure as illustrated in the embodiment in . The movement control system can be configured to move and manipulate the physical position of the light box. In some embodiments the movement control system can translate the light box along vertical and horizontal axes rotate the light box around an axis and or otherwise manipulate the position of the light box structure. The movement control system can include mechanical mechanisms such as a lift or robotic arms which can be controlled by the light box control system the virtual environment control application the camera control application and or another control system such as a dedicated control system. In some embodiments the movement control system can manipulate portions of the light box structure such as individual panels individual walls and or a combination of components of the light box structure to modify the size and shape of the light box structure.

The light box control system can include one or more processors such as central processing units CPUs graphics processing units GPUs and data storage combined or in separate elements. The light box control system may include user input devices such as the controllers illustrated in or other input devices such as for example a mouse a keyboard and the like. The light box control system may include output devices such as the display illustrated in and or other types of output devices. The light box control system can be configured to execute software code for the operation of the virtual environment control application and the camera control application . In some embodiments the light box control system can be a specialized computing device created for the dedicated purpose of controlling the light box system and or the motion control camera system . The light box control system can be configured to communicate with the light box system and or the motion control camera system using a particular application programming interface API and or a particular hardware interface. In some embodiments the light box control system can communicate with light box system and or the motion control camera system via a physical hardware interface such as a wired connection a wireless interface such as a wireless network or a combination thereof.

In some embodiments the virtual environment control application and the camera control application can be executed on separate computing devices. For example the virtual environment control application may operate on a specialized computing device dedicated to the operation and control of the light box system and the camera control application may operate on a separate specialized computing device dedicated to the operation and control of the motion control camera system . In some embodiments the light box control system may be a general purpose computing device capable of executing the virtual environment application and the camera control system such as illustrated in . For example the computing device may be a desktop computer a workstation a laptop or another computing device. Components of an example embodiment of a computing device are described in more detail with respect to .

In general the word application as used herein refers to logic embodied in hardware or firmware or to a collection of software instructions stored on a non transitory tangible computer readable medium possibly having entry and exit points written in a programming language such as for example C C C or Java. A software application may be compiled and linked into an executable program installed in a dynamic link library or may be written in an interpreted programming language such as for example BASIC Perl or Python. It will be appreciated that software application may be callable from other applications or from themselves and or may be invoked in response to detected events or interrupts. Software applications may be stored in any type of computer readable medium such as a memory device for example random access flash memory and the like an optical medium for example a CD DVD Blu ray and the like firmware for example an EPROM or any other storage medium. The software applications may be configured for execution by one or more CPUs in order to cause light box control system to perform particular operations. Generally the applications described herein refer to logical modules that may be combined with other modules or divided into sub modules despite their physical organization or storage.

A virtual environment application can be configured to be executed on the light box control system . The virtual environment application should be understood to include software code that the light box control system or another computing device can execute to controlling operation of the light box system . A virtual environment control application may comprise software code that informs the light box control system of processor instructions to execute but may also include data used during execution of the application. For example in the illustrated embodiment the virtual environment control application includes an environment engine and environment data .

The environment engine can be configured to execute manipulate and control a virtual environment. The environment engine can generate instructions that can be output to the light box system for controlling the operation of the light projection elements . The virtual environment engine can be configured to control the light box system based at least in part on information provided by the environment data store . The environment engine can receive inputs from a user that enable the user to control and manipulate a virtual environment. The environment engine can load a virtual environment from the environment data store . The environment engine can control the output and display of the virtual environment on a local display such as display and of the light box system . The control of the display within the light box system can be generated at the same time as the display on a local display such as display illustrated in . For example the environment engine may render and generate instructions for control of the light box system multiple times per second such that the output to the light box system is generated at substantially the same time as the manipulation of the virtual environment within the virtual environment control application .

In some embodiments the environment engine can receive configuration information associated with the light box system such as the size of the light box system the number of light projection elements the type of light projection elements the specifications of light projection elements light projection element identifiers and or other information that can be used by the environment engine to configure and position the virtual environment within the light box system . In some embodiments this configuration information can be input manually and in some embodiments it can be automatically determined and provided to the environment engine .

In some embodiments the environment engine can provide controls for a user to manipulate the virtual environment and control the positioning of the virtual environment for outputting within the light box system . The environment engine can receive user inputs to control and manipulate the virtual environment according to constraints and parameters associated with the virtual environment. The virtual environment can be any type of three dimensional environment that is loaded into the environment engine . For example the virtual environment may be a castle a city a building a cave or other type of three dimensional environment. The virtual environment includes virtual environment elements that are used to form the virtual environment in virtual space. For example the environment element can include terrain such as for example mountains valleys streets and the like objects such as for example trees bushes rocks buildings walls clouds and the like active entities such as for example animals people robots vehicles and the like and or other elements within the environment. In some embodiments each environment element can be defined by a set of parameters specific to the environment element. The environment engine can manipulate environment element parameters within the virtual environment.

In some embodiments the environment engine may be limited by constraints of the virtual environment for example in some embodiments only defined parameters of the virtual environment may be manipulated and controlled by the environment engine . The environment engine can generate instructions for outputting the virtual environment within the light box system . During operation the environment engine can emulate and calculate the outputs for the light box system at a location within the virtual environment based at least in part on a portion of the environment element parameters within the virtual environment. In some embodiments a point or portion of the interior of the light box can be used as focal point for the environment engine to calculate and generate the light output values for the light projection elements. The environment engine can utilize the configuration information of the light box system to determine output commands for the virtual environment. For example in one embodiment the environment engine can use the size of the light box to determine the spatial location of the light projection elements within the light box to calculate instructions for control of the light projection elements.

In some embodiments the environment engine can be a game engine that can be used to control the operation of the virtual environment. The virtual environment can be a game environment from a video game application. The virtual environment may include virtual characters and or other active virtual environment elements which can be controlled manually or by game engine rules associated with the game environment. For example a car racing game application may include other race cars that are moving within the environment. In a fantasy game environment the virtual environment may include a dragon that is breathing fire. The environment engine can be used to control the game environment within the light box. The environment engine can be configured to execute a specific level within a game application and control the execution of environment from the perspective of a character within the game application. For example in a racing game the environment engine could play through a specific racing level or course as a racer such that the light box is displaying the level within the game application relative to the racer within the environment.

In some embodiments the environment engine can be controlled by a controller and or other system that could be used by an actor within the light box. The controller such as a steering wheel controller may be used to by an actor to play through the virtual environment within the light box. For example the actor within the light box could drive through the environment participate in a race between other racers and or interact with the environment in other ways.

The environment data store can store environment data associated with the virtual environment. The virtual environment can include environment elements. Examples of environment elements can include terrain such as for example mountains valleys streets water snow grass and the like objects such as for example trees bushes rocks buildings walls and the like active entities such as for example animals people characters robots vehicles and the like and other elements within a three dimensional environment. In some embodiments each environment element can have a set of parameters also referred to as environment element parameters that define the behavior of the object within the virtual environment. For example the parameters can include physical parameters such as spatial information for example size shape height width location within the environment and other characteristics associated with spatial location appearance information for example color texture skins and other characteristics associated with the appearance of the object and other information that can be used to define physical characteristics of the environment elements within the virtual environment. Some environment elements such as active entities can include behavior parameters that can define how the entity behaves and interacts with the environment. For example the behavior parameters may include artificial intelligence AI for controlling the behavior of the entity within the environment a defined behavior such as for example moving along a defined movement path performing a defined set of actions and the like and or other parameters that can be used define behavior of an entity within the virtual environment.

In some embodiments the environment elements can include lighting parameters which can define both passive and active lighting characteristics of an environment element. Passive light characteristics can define how light interacts with environment elements. The passive light characteristics can be based in part on the physical characteristics of the environment elements for example the type of material associated with the environment element . Active light characteristics can be used for environment elements that produce light such as for example the sun a light bulb a fire and or other light producing environment elements. Environment elements with active light characteristics can be referred to as light sources. For example the active characteristics can define characteristics of the light source such as for example directionality of the light the type of light saturation hue intensity and or other information and other information associated with an environment element. Some environment elements can be configured to include dynamic light characteristics that can change active and passive light characteristics of environment elements within the environment. Some examples may include a pulsing light an explosion a dragon breathing fire a gun firing headlights turning on off and other changes that can dynamically change the lighting characteristics of environment elements within the virtual environment. The light parameters can be used by the environment engine to calculate lighting values at for each light projection element within the light box system. The environment elements may include some or all of the various parameters described above. For example the lighting parameters of some environment elements can include passive and active lighting characteristics such as for example a lamp with a shade headlights on a vehicle or a dragon breathing fire.

The camera control application can be in communication with the motion control camera control system . This camera control application can be executed on the light box control system . One or more motion control camera systems can be used to record video during a film segment. In some embodiments multiple cameras can be used simultaneously. In some embodiments the specific characteristic and functionality of the motion control camera systems can be dependent on the specific hardware of the motion control camera system . The camera control application can be used to control or provide instructions for the operation of the motion control camera system . For example the camera control application can output instructions to control the movement and capture functionalities of a camera during a film segment. With multiple cameras the sequence can be recorded from multiple different angles. The camera control application may communicate with the motion control camera system via a camera interface or a specific API that the camera control application can use to provide instructions to the camera. In some embodiments the virtual environment control application provides instructions for operation of the camera to the camera control application and the camera control application can generate the appropriate output for control of the motion control camera system. In some embodiments the virtual environment control application can provide instructions directly to the motion control camera system. The operation of the motion control camera system can be synchronized with the operation of the light box system .

The movement of the virtual environment relative to the light box can be dynamically controlled by the environment engine . In some embodiments the physical object may include a controller that can be used by the actor to control the movement of the virtual environment relative to the light box. For example the actor could drive through the environment participate in a race between other racers and or interact with the environment in other ways. The movement sequence as illustrated in can be configured to create the appearance that the actor is driving the vehicle . Movement of the vehicle within the virtual environment is illustrated as the vehicle moving from to wherein FIG. A is at a first point in time and FIG. B is at a second point in time. The environment engine manipulate the light box within virtual environment such that it gives the appearance that the character is moving. For example the light posts A and B the street lines and the building move toward the right side with light post B disappearing and C appearing. The fence continues to be displayed. Each environment element can defined lighting parameters that can affect the output of the light projection elements. Even though not shown in the illustrated embodiment the environment element parameters of the light post B can still be used to calculate the output of the light projection elements. As the virtual environment moves relative to the actor and the vehicle the lighting within the light box can create reflections and different lighting characteristics can be displayed on the vehicle as if it is moving. The virtual environment can move at a set rate such as the vehicle is moving at a rate of 50 miles per hour. The environment engine can be configured to render the virtual environment and output instructions to the light projection element to generate the correct output during the operation of the movement sequence. The environment engine is not limited to a defined or prerendered output of movement within the virtual environment. The environment engine can dynamically change aspects the virtual environment such as the speed of movement the movement path and or other characteristics during the execution and output of the virtual environment to the light box.

The environment engine can modify parameters of the virtual environment in real time so that it can be changed dynamically at any time. The environment engine can change parameters associated with the movement sequence for example the speed of the vehicle can change the movement path can be modified or other parameters associated with the movement sequence. For example the vehicle was originally scripted to drive down a road and then make a right turn the environment engine could modify the movement make to make a left turn instead. The environment engine could also change the location within the virtual environment to any other place within the virtual environment. The environment engine can process any changes and output the changed output instructions to the light projection elements during the movement sequence. The movement sequence can be captured by the motion control camera system based on instructions received from the camera control application .

At block a virtual environment is loaded into the light box environment application. The virtual environment can be loaded from an environment data store. At block the light box configuration information is loaded into the environment engine .

At block a user can select a portion of the environment for display within the light box. In some embodiments the virtual environment can be moved relative to the light box. In some embodiments based on the light box configuration information the system can determine a representation of the light box that can be displayed for manipulation within the environment engine . The system can determine the location of the light box within the virtual environment. This information can be used to establish the location information of each of the light projection elements relative to the virtual environment. The relative location of the light projection elements can be determined based at least in part on the environment data and the light box configuration information.

At block the lighting characteristics associated with that environment can be determined. The environment element parameters associated with the virtual environment can be modified for the specific video sequence. In some embodiments the environment can load default parameters for each of the environment elements with the virtual environment. In some embodiments a configuration or video segment file may be used to determine establish initial parameters. The environment element parameters can be modified to account for desired changes to the virtual environment. For example light parameter information for one or more light source elements can be modified to change the lighting output within the light box. The user can control the environment engine and see the effects of changes to the environment element parameters.

At block the system can determine the positions of cameras for capturing video segment within the light box. The cameras can be automatically controlled to capture identified segments locations angles and the like of the video segment.

At block the system can render and output the instructions to the light box during a video segment. The rendering of the segment can be performed multiple times per second. The generated output instructions can be executed by the individual light projection elements within the light box. The rendering of the segment can be performed continuously such that the environment engine is continually updating instructions and can output the instructions. In some embodiments the environment engine may only update instructions that change from one update to the next. In environments where the location within the virtual environment is static the lighting effects may still change. For example a fire can be constantly shifting or a lamp can be flickering. At block the camera data can be output to the camera system to capture the video segment.

In some embodiments it can be beneficial to utilize a masking procedure in order to remove the light box structure from the captured video segment. For example the light projection elements can pulse at an imperceptible rate. The system can then use the data to differentiate between the light box and the actors and or other physical objects within the light box. A system such as the virtual environment control application or another post processing system can automatically remove the light box from a filmed sequence.

Computing device may include a separate graphics processor . In some cases the graphics processor may be built into the processing unit . In some such cases the graphics processor may share Random Access Memory RAM with the processing unit . Alternatively or in addition the computing device may include a discrete graphics processor that is separate from the processing unit . In some such cases the graphics processor may have separate RAM from the processing unit . Computing device might be a handheld video game device a dedicated game console computing system a general purpose laptop or desktop computer a smart phone a tablet a car console or other suitable system.

Computing device also includes various components for enabling input output such as an I O a user I O a display I O and a network I O . I O interacts with storage element and through a device removable storage media in order to provide storage for computing device . Processing unit can communicate through I O to store data such as game state data and any shared data files. In addition to storage and removable storage media computing device is also shown including ROM Read Only Memory and RAM . RAM may be used for data that is accessed frequently such as when a game is being played.

User I O is used to send and receive commands between processing unit and user devices such as game controllers. In some embodiments the user I O can include a touchscreen inputs. The touchscreen can be capacitive touchscreen a resistive touchscreen or other type of touchscreen technology that is configured to receive user input through tactile inputs from the user. Display I O provides input output functions that are used to display images from the game being played. Network I O is used for input output functions for a network. Network I O may be used during execution of a game such as when a game is being played online or being accessed online.

Display output signals produced by display I O comprising signals for displaying visual content produced by computing device on a display device such as graphics user interfaces video and or other visual content. Computing device may comprise one or more integrated displays configured to receive display output signals produced by display I O . According to some embodiments display output signals produced by display I O may also be output to one or more display devices external to computing device such a display .

The computing device can also include other features that may be used with a game such as a clock flash memory and other components. An audio video player might also be used to play a video sequence such as a movie. It should be understood that other components may be provided in computing device and that a person skilled in the art will appreciate other variations of computing device .

Program code can be stored in ROM RAM or storage which might comprise hard disk other magnetic storage optical storage other non volatile storage or a combination or variation of these . Part of the program code can be stored in ROM that is programmable ROM PROM EPROM EEPROM and so forth part of the program code can be stored in storage and or on removable media such as game media which can be a CD ROM cartridge memory chip or the like or obtained over a network or other electronic channel as needed . In general program code can be found embodied in a tangible non transitory signal bearing medium.

Random access memory RAM and possibly other storage is usable to store variables and other game and processor data as needed. RAM is used and holds data that is generated during the execution of an application and portions thereof might also be reserved for frame buffers application state information and or other data needed or usable for interpreting user input and generating display outputs. Generally RAM is volatile storage and data stored within RAM may be lost when the computing device is turned off or loses power.

As computing device reads media and provides an application information may be read from game media and stored in a memory device such as RAM . Additionally data from storage ROM servers accessed via a network not shown or removable storage media may be read and loaded into RAM . Although data is described as being found in RAM it will be understood that data does not have to be stored in RAM and may be stored in other memory accessible to processing unit or distributed among several media such as media and storage .

It is to be understood that not necessarily all objects or advantages may be achieved in accordance with any particular embodiment described herein. Thus for example those skilled in the art will recognize that certain embodiments may be configured to operate in a manner that achieves or optimizes one advantage or group of advantages as taught herein without necessarily achieving other objects or advantages as may be taught or suggested herein.

All of the processes described herein may be embodied in and fully automated via software code modules executed by a computing system that includes one or more computers or processors. The code modules may be stored in any type of non transitory computer readable medium or other computer storage device. Some or all the methods may be embodied in specialized computer hardware.

Many other variations than those described herein will be apparent from this disclosure. For example depending on the embodiment certain acts events or functions of any of the algorithms described herein can be performed in a different sequence can be added merged or left out altogether for example not all described acts or events are necessary for the practice of the algorithms . Moreover in certain embodiments acts or events can be performed concurrently for example through multi threaded processing interrupt processing or multiple processors or processor cores or on other parallel architectures rather than sequentially. In addition different tasks or processes can be performed by different machines and or computing systems that can function together.

The various illustrative logical blocks and modules described in connection with the embodiments disclosed herein can be implemented or performed by a machine such as a processing unit or processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A processor can be a microprocessor but in the alternative the processor can be a controller microcontroller or state machine combinations of the same or the like. A processor can include electrical circuitry configured to process computer executable instructions. In another embodiment a processor includes an FPGA or other programmable device that performs logic operations without processing computer executable instructions. A processor can also be implemented as a combination of computing devices for example a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration. Although described herein primarily with respect to digital technology a processor may also include primarily analog components. For example some or all of the signal processing algorithms described herein may be implemented in analog circuitry or mixed analog and digital circuitry. A computing environment can include any type of computer system including but not limited to a computer system based on a microprocessor a mainframe computer a digital signal processor a portable computing device a device controller or a computational engine within an appliance to name a few.

Conditional language such as among others can could might or may unless specifically stated otherwise are otherwise understood within the context as used in general to convey that certain embodiments include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without user input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment.

Disjunctive language such as the phrase at least one of X Y or Z unless specifically stated otherwise is otherwise understood with the context as used in general to present that an item term etc. may be either X Y or Z or any combination thereof for example X Y and or Z . Thus such disjunctive language is not generally intended to and should not imply that certain embodiments require at least one of X at least one of Y or at least one of Z to each be present.

Any process descriptions elements or blocks in the flow diagrams described herein and or depicted in the attached figures should be understood as potentially representing modules segments or portions of code which include one or more executable instructions for implementing specific logical functions or elements in the process. Alternate implementations are included within the scope of the embodiments described herein in which elements or functions may be deleted executed out of order from that shown or discussed including substantially concurrently or in reverse order depending on the functionality involved as would be understood by those skilled in the art.

Unless otherwise explicitly stated articles such as a or an should generally be interpreted to include one or more described items. Accordingly phrases such as a device configured to are intended to include one or more recited devices. Such one or more recited devices can also be collectively configured to carry out the stated recitations. For example a processor configured to carry out recitations A B and C can include a first processor configured to carry out recitation A working in conjunction with a second processor configured to carry out recitations B and C.

It should be emphasized that many variations and modifications may be made to the above described embodiments the elements of which are to be understood as being among other acceptable examples. All such modifications and variations are intended to be included herein within the scope of this disclosure.

