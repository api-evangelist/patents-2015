---

title: Determining quality of a summary of multimedia content
abstract: A quality metric of a multimedia summary of a multimedia content item is determined based, in part, on semantic similarities of the summary and content item, rather than just on word frequencies. This is accomplished in some embodiments by identifying a semantic meaning of the summary and multimedia content item using vector analysis. The vectors of the summary and the vectors of the multimedia content item are compared to determine semantic similarity. In other examples, the quality metric of the multimedia summary is determined based on, in part, a coherence between an image portion of a summary and a text portion of the summary for determining a quality metric of a multimedia summary.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09454524&OS=09454524&RS=09454524
owner: Adobe Systems Incorporated
number: 09454524
owner_city: San Jose
owner_country: US
publication_date: 20151204
---
The present disclosure relates generally to the characterization of multimedia content. Specifically the present disclosure relates to determining quality of a summary of multimedia content in which both the summary and the multimedia content include text and images.

Multimedia content generally refers to digital content that includes some combination of different content forms including text and images video animation graphics etc . Such multimedia content is so ubiquitous and inexpensive that users are often overwhelmed with the process of selecting a multimedia content item to consume. Because of this users of multimedia content often rely on summaries of multimedia content items. These summaries can be used either as a substitution for consuming a multimedia content item or used to facilitate selection of a multimedia content item to be consumed. Thus the quality of a multimedia summary can have a significant impact on a prospective reader s decision to consume a given content item. Currently however there are no suitable methods to evaluate the quality of multimedia summaries.

The figures depict various embodiments of the present disclosure for purposes of illustration only. Numerous variations configurations and other embodiments will be apparent from the following detailed discussion.

As previously noted there are no techniques for evaluating the quality of a given multimedia summary. Such summaries however may have a substantial impact on a prospective user including a user s decision on whether or not to consume a full version of the digital content item that is summarized. Thus from marketing perspective techniques for evaluating the quality of summary of a multimedia content item are desirable. For instance consider a digital article having both image and text portions. As will be appreciated in light of this disclosure a summary of that article having a high degree of coherence between the image portions and the text portion might help one to have a better understanding of the article more quickly than say a summary lacking coherence between the image portions and text portions. In a more general sense the degree to which a summary is representative of a corresponding multimedia content item can be quantified as a quality metric. A quality metric of a summary can then be used for example to gauge the likelihood that the summary will be effective in causing consumption of the content item itself. While some available algorithms might be usable to evaluate the text portions of a given multimedia summary or simply summary herein for brevity of a multimedia content item such algorithms would fail to consider the non text portions e.g. images of that summary. Specifically algorithms for evaluating content would likely operate by comparing a frequency of words in a text portion of the multimedia content to the frequency of words in the corresponding summary. The more similar the word frequencies of the summary are to word frequencies in the multimedia content item the higher the quality score. Examples of this type of algorithm include retention rate which could operate for instance by dividing the number of unique words in the summary by the number of unique words in the multimedia content item KL divergence which could operate for instance by measuring the distribution of word frequencies in the content and corresponding summary Bilingual Evaluation Understudy BLEU which determines the quality of machine translated text from one language into another and Recall Oriented Understudy for Gisting Evaluation ROUGE which determines the quality of a summary using human generated summaries as a reference .

As will be appreciated in light of this disclosure however the above algorithms and similar algorithms are inadequate if used to determine quality of a summary of a multimedia content item. One reason is that because these algorithms rely primarily on word frequency the semantic meaning of the summary is not compared to the semantic meaning of the multimedia non text content item. This word frequency approach can therefore problematically generate a high value of a quality metric even for a summary that has a very different semantic meaning from a corresponding multimedia content item. For example consider a simplistic example of a text portion of a multimedia content item that states this girl does not like cheese. A corresponding summary that has a text portion stating this girl does like cheese would score well using a word frequency algorithm but would not be accurate given the absence of not in the summary. In another example scenario a multimedia content item that includes a text portion that refers to an accompanying image portion using a pronoun could have a high scoring summary that is not informative. For example consider a multimedia content item that includes a picture of a shirt accompanied by a text caption this is nice. Absent an analysis of the image portion of the shirt a summary stating this is nice may be given a high value of a quality metric because it conforms exactly to the text portion of the multimedia content item i.e. there is a high degree of correlation between the text of the summary and the text of the full article . However if the image was actually considered the summary might have been this shirt is nice which is a relatively much more accurate summary and therefore should score higher than a mere text based score. Thus using currently available algorithms a summary can be determined to misleadingly have a high quality score but not accurately reflect the semantic meaning of the multimedia content item.

To this end techniques are provided herein for determining a quality metric of a multimedia summary of a multimedia content item by considering both textual and non textual components of that summary. In some embodiments the quality metric is based in part on semantic similarities of the summary and content item rather than just on word frequencies. This is accomplished in some embodiments by identifying a semantic meaning of the summary and multimedia content item using vector analysis. The vectors of the summary and the vectors of the multimedia content item are compared to determine semantic similarity. Note that both text and non text items can readily be represented by vectors thereby facilitating the vector based comparison.

In addition to assessing similarity of semantic meaning between the given multimedia content item and its multimedia summary the techniques may further include determining a degree of correlation between the text and non text portions of the summary itself. As will be appreciated in light of this disclosure high degree of correlation or coherence between the text and non text portions of the summary tends to indicate a higher quality summary. So some embodiments of the present disclosure provide methods for determining a quality metric of a multimedia summary of a multimedia content item based in part on determining coherence between an image portion of a summary and a text portion of the summary for determining a quality metric of a multimedia summary. Coherence refers to a similarity in semantic meaning between a text portion of a multimedia summary and an image portion of the multimedia summary and is determined according to methods described below. At a high level determining coherence is accomplished by generating vectors from both segments of a text portion and from segments of an image portion and projecting the vectors onto a common unit space. The projected vectors are then compared. Vectors that are proximate to one another in the common unit space correspond to semantically similar information across both text portions and image portions of the summary and thus a high degree of coherence between those portions. Note that if the given multimedia summary includes a video rather than or in addition to static images the video can be treated as a collection of static images or frames where each image is evaluated separately against the text portion of the summary in the same way as a static image. Then an average or other suitable statistical representation of the individual comparisons can be computed so as to provide an overall degree of coherence between the text portion and the video. To this end reference to image herein is intended to include frames of video content.

One benefit of some embodiments of the present disclosure is the improved accuracy of the quality metric. There are several reasons for the improved accuracy. One reason is that some embodiments of the present disclosure analyze both a text portion and an image portion of a multimedia content item and a corresponding summary. This improves the accuracy of the quality metric because the quality metric thus reflects the semantic meaning communicated in both the text portions and image portions of the multimedia content item and the corresponding summary. Another reason for the improved accuracy is that some embodiments analyze and incorporate the coherence between the text portion of the summary and the image portion of the summary. This improves the accuracy because summaries having a text portion and an image portion that are semantically similar will produce a high quality metric when using embodiments of the present disclosure.

Another benefit of some embodiments of the present disclosure is the ability to tailor the weights of three different contributions to the multimedia quality metric. In particular through user selectable coefficients the individual contributions of 1 information content of the text portion of the summary relative to the text portion of the multimedia content text coverage 2 information content of the image portion of the summary relative to the image portion of the multimedia content item image coverage and 3 coherence between text and image of the summary can be weighted according to user preference according to some embodiments. Some embodiments are tailored to make an evaluation of a summary consistent with a set of topics or consistent with user selected topics and interests. Some embodiments can be tailored to improve the accuracy of comparison between semantic meanings of image portions text portions or both.

As used herein the term multimedia content item refers to a content item that includes a text portion and an image portion. The image portion can be a still image of any format in any type of digital resource e.g. an electronic book a web page a mobile application a digital photograph or a frame of a video as previously explained. Each of the text portion and the image portion comprise text segments and image segments respectively. A text segment is a sentence clause of a sentence a word in a sentence or a character i.e. a number a symbol a letter . An image segment is a frame or portion of a frame of an image or an object within a frame of an image. Information content of a text portion or of a text segment refers to the number of words in a text portion or text segment that can convey meaning e.g. nouns verbs and adjectives in contrast to words that generally do not convey meaning by themselves e.g. conjunctions and articles . Information content of an image portion or an image segment refers to frames portions of a frame or objects within a frame that can convey a meaning e.g. an image of a face compared to unfocused background . As indicated above coherence refers to a similarity in semantic meaning between a text portion of a summary and an image portion of summary. The term quality as used herein refers to the degree of similarity between a semantic meaning of a summary compared to the semantic meaning of a corresponding multimedia content item. The higher the value of a quality metric the closer the summary and the corresponding multimedia content item are in semantic meaning.

Some embodiments of the present disclosure then analyze both of the multimedia content item and the multimedia summary. The analysis is described below in more detail in the context of . Based on the analysis a quality metric of the multimedia summary is determined . The quality metric and its determination are described below in more detail also in the context of .

Metastep of method illustrates operations for analyzing similarity between sentences or sentence segments of a text portion of a multimedia content item and sentences or sentence segments of a text portion of a summary. The function and benefit of this analyzing operation is determining a degree to which the semantic meanings between text portions of a multimedia content item and a text portion of a corresponding summary are comparable. This analyzing is accomplished by first generating vectors for sentences in the text portions each of the multimedia content item and the summary to determine whether the text portion of the summary conveys a same or similar semantic meaning as that conveyed by the text portion of the multimedia content item. The more similar the semantic meanings conveyed the higher the contribution to the quality metric of the text portion of the summary.

The vectors are generated by first processing the text portions of both the multimedia content item and the summary using a recursive auto encoder. First an encoding matrix Wis trained. W once trained is used to analyze sentences of the multimedia content item and the corresponding summary to extract the respective semantic meanings and compare them in a common unit space described below in more detail .

To train the encoding matrix W the recursive auto encoder first generates a syntactic parse tree for at least one training sentence. A semantic vector for each word and clause within each training sentence is generated. Each non terminal i.e. non leaf node of the parse tree is generated according to equation 1 which follows. Equation 1

In equation 1 s represents the non leaf node Wis the trained encoding matrix and cand c more generally c are word to vector representations. Specifically cincludes sentence segments that are elements of the parse tree. These sentence segments are subsets of one or more of the training sentences. The term b in equation 1 is a constant. The function is in one example a sigmoid function that produces a result between 0 and 1 when it operates on the arguments of the function.

The training of matrix Wcontinues with the recursive auto encoder reconstructing elements under each node in the parse tree for each sentence of the multimedia content item and the corresponding summary according to equation 2 which follows. Equation 2

Equation 2 describes an output of a plurality of vectors from vector x to vector y based on the operation of matrix Won sentence y which is subsequently processed with the sigmoid function .

When training of the matrix Wis completed a vector representation of the root of the parse tree is then generated and used as a representative vector of a sentence using trained matrix W. The vectors generated for each sentence are then used for computing a cosine similarity between a sentence of the multimedia content item and corresponding sentences of a summary. The similarity S u v between the sentences of the text portions of the multimedia content item and the text portions of the summary is determined based on cosine similarity indicated by the Sim function according to equation 3 which follows. Sim Equation 3

In equation 3 and are vector representations of the text segments of the text portion of a summary u and the text portion of the multimedia content item v respectively. The cosine similarity quantifies the similarity in semantic meaning between text portions of sentences of the multimedia content item and the summary which is then later used as a contribution to the multimedia summary quality metric as described in more detail below.

Metastep of method illustrates operations for analyzing similarity between sentences of a text portion of a summary and an accompanying image portion of the summary. The function and benefit of this analyzing operation is determining a degree to which the semantic meanings between a text portion of a summary and an accompanying image portion of a summary correspond to one another. The more semantic similarity there is between the text and an accompanying image the higher the quality of the multimedia summary.

In an analogous process to the one described above vectors are generated corresponding to image content and text content of the summary in a method similar to the one described by Karpathy et al. Deep Fragment Embeddings for Bidirectional Image Sentence Mapping 2014 pp. 1889 1897. which is incorporated by reference herein in its entirety. The process for generating vectors of an image portion of a summary is described first.

The process for generating vectors corresponding to an image portion of a summary includes first identifying segments of the image portion likely to be relevant to the summary. The segments are identified by training a deep neural network auto encoder which is then applied to the image to extract relevant image portions. At a high level this process is accomplished by extracting pixel values from an image and using the pixel values either individually or in associated groups to identify higher levels of organization within the image that correspond to objects in the image.

Once the image segments are identified a regional convolutional neural network RCNN is used to generate vectors corresponding to each of the identified image segments. In one embodiment the RCNN generates 4096 dimensional vectors corresponding to each identified segments as described by Girshick et al. See Rich Feature Hierarchies for Accurate Object Detection and Semantic segmentation 2014. which is incorporated by reference herein in its entirety. The 4096 dimensional space represents a convenient compromise between consumption of computational resources and quality of output. Because 4096 is equal to 2 it is therefore is conveniently applied to binary data bits. Lower dimensional spaces can be used but with less discrimination between features. Higher dimensional spaces can also be used but with increased consumption of computing resources.

Intersections between any two vectors are identified. A subset of the segments for which vectors are generated are selected based on a likelihood of one of the image segments corresponding to a portion of an image semantically relevant to the summary. In some embodiments the segments identified are further restricted based on a classification determined using the vectors to reduce the risk of overrepresentation of any image segments in subsequent steps of the analysis.

Vectors corresponding to text portions of a summary are generated using the processes described above in the content of element of metastep .

The image vectors and the sentence vectors are then projected onto a common unit space by a matrix transformation. The matrices used to transform the vectors onto a common unit space have been trained so that semantically similar elements whether in the image portion or the text portion are correspondingly projected on areas of the common unit space reflecting the semantic similarity.

One benefit of projecting vectors onto a common unit space is reducing the influence of irrelevant information for the determination of semantic similarity. For example vectors as generated may include extraneous information e.g. color texture shape that is not relevant to the semantic meaning of either the image or the text portions. By mapping the vectors to a common unit space the effect of this extraneous information is reduced.

The cosine similarity of the vectors corresponding to image and text portions of a summary are then determined according to equation 4 which follows. Sim Equation 4

In this equation and tilde over p are the vector representations of the text segments of a text portion u of a summary and image segments of an image portion p of a summary obtained using the methods described above.

Metastep of method illustrates operations for analyzing similarity between an image portion of a summary and an image portion of a multimedia content item in an embodiment. As explained above in the context of metastep vectors are determined for the images and are projected onto a common unit space. A cosine similarity between the images based on the generated vectors is determined according equation 5 which follows. Sim Equation 5

In equation 5 tilde over p and tilde over q are the vector representations of the image segments p and q of image portions of a summary and multimedia content item respectively.

Having generated similarity scores for the various elements of a multimedia content item and a corresponding summary as described above in the method a multimedia quality metric is determined as shown in and as described below in more detail.

Referring once again to the process for determining a quality metric quantifying a degree of similarity between a semantic meaning of a summary to a multimedia content item using the information determined in the analysis and corresponding method is described below.

The multimedia summary quality metric is determined according to equation 6 which follows. Equation 6

Where MuSQ is the multimedia quality summary metric ICis a metric describing a proportional amount of information in a text portion of a summary relative to a text portion of a multimedia content item ICis a proportional amount of information in an image portion of a summary relative to an image portion of a multimedia content item. The term f in equation 6 and as used elsewhere in the present disclosure represents a generic function and not a specific function. Cohis the coherence between a text portion of a summary and an image portion of the summary. Coherence reflects the degree of semantic similarity between a text portion of a summary and an image portion of the summary with a higher number reflecting more semantic similarity between the text and image of the summary. In one embodiment equation 6 is a non decreasing sum of its arguments as shown below in equation 7. Equation 7

In equation 7 A B and C are positive constants used to change the relative contribution of each argument to MuSQ.

In equation 8 Sis defined above in equation 3 and Ris a number of terms or words possibly contributing to the semantic meaning of a text portion of the multimedia content item referred to above as information content . That is Ris the word count of nouns verbs adjective adverbs and pronouns in the text segments of text portion. Articles conjunctions and the like are omitted from the determination of R.

The max function is taken over the text segments u present in a text portion of the summary for a given text segment v of the multimedia content item. The result of the max function is maximal representation of a text segment v present in the summary S. The max function also prevents redundant sentences in a summary increasing a quality metric score because only a summary sentence or segment that is most relevant to the multimedia content item contributes to the metric. In other words using this function facilitates selection of a sentence with the most information content from among multiple sentences in the multimedia content item regarding a particular semantic. This improves the score of a summary that includes a more diverse coverage of multimedia content because duplicative sentences do not contribute or contribute less to a score where sentences and images representing diverse topics are scored as contributing more information content.

The result of the max function is multiplied by the information content of the sentence R. Including the information content Rin equation 8 aids selection of segments conveying more information in terms of the number of nouns adjectives etc. compared to less informative sentences having a lower count of the identified types of informative words. A summation of this quantity over all the text segments v present in a multimedia content item is an indicator of quality of a text portion of the summary relative to the multimedia content item as a whole.

S p q as defined above in equation 5 denotes the information content of an image segment p in the summary about the image q in the multimedia content item . In one embodiment Squantifies a similarity between an image segment in a summary p compared to a corresponding image segment in a multimedia content item q. The quantification of Sis determined based on representations of the image segments as analyzed by a Recurrent Convolutional Neural Network RCNN optionally projected onto a common unit space as described above. The term circumflex over R is the information content of the image q of the multimedia content item. In one embodiment circumflex over R is determined by converting the image segment q into text as described above in the context of metastep and specifically vector generated and then measuring the information content of that text using the methods described above. The function of circumflex over R is similar to that of the Rterm described above.

In equation 9 the max function is taken over image segments p present in the image part of the summary for a given image segment q of the multimedia content item. The result is a maximum representation of the image segment q present in the image part of the summary S. Summing this quantity over all the image segments q present in the multimedia content item provides an indication of how representative the image portion of the summary is of the multimedia content item.

In equation 10 C u p denotes the coherence between a sentence or text segment u from a text portion of a summary S and an image segment p of an image portion I a summary. As described above in the context of equation 4 Cmay be projected onto common unit space to compare the vectors of the extracted text portion and image portions of the summary. Rand circumflex over R are the information contents of the text portions and image portions as defined above.

The user device is a computing device capable of receiving user input as well as transmitting and or receiving data via the network . In one embodiment the user device is a computer system such as a desktop or laptop computer. In another embodiment the user device may be a device having computer functionality such as a personal digital assistant PDA mobile telephone tablet computer smartphone or similar device. In some embodiments the user device is a mobile computing device used for consuming multimedia content items summaries corresponding to multimedia content items and the methods described herein for determining a summary quality metric of a summary corresponding to a multimedia content item. The user device is configured to communicate with the summary quality determination system via the network . In one embodiment the user device executes an application allowing a user of the user device to interact with the summary quality determination system thus becoming a specialized computing machine. For example the user device executes a browser application to enable interaction between the user device and the summary quality determination system via the network . In another embodiment a user device interacts with the summary quality determination system through an application programming interface API that runs on the native operating system of the user device such as IOS or ANDROID .

The user device is configured to communicate via the network which may comprise any combination of local area and or wide area networks using both wired and wireless communication systems. In one embodiment the network uses standard communications technologies and or protocols. Thus the network may include links using technologies such as Ethernet 802.11 worldwide interoperability for microwave access WiMAX 3G 4G CDMA digital subscriber line DSL etc. Similarly the networking protocols used on the network may include multiprotocol label switching MPLS transmission control protocol Internet protocol TCP IP User Datagram Protocol UDP hypertext transport protocol HTTP simple mail transfer protocol SMTP and file transfer protocol FTP . Data exchanged over the network may be represented using technologies and or formats including hypertext markup language HTML or extensible markup language XML . In addition all or some of links can be encrypted using encryption technologies such as secure sockets layer SSL transport layer security TLS and Internet Protocol security IPsec .

The non transitory memory is depicted as including two distinct memory elements a multimedia content item store and a summary store . The multimedia content item store stores multimedia content items and optionally content items that include only one of a text portion or an image portion for analysis and optionally for display or transmission. The summary store stores summaries that correspond to a multimedia content item. As with the multimedia content item store the summary store can store any one or more of text summaries image summaries and multimedia summaries that include both text portions and image portions. Regardless of the nature of the content and summary stored the multimedia content item store and the summary store are in communication with the quality metric determination module .

The non transitory memory may include a computer system memory or random access memory such as a durable disk storage which may include any suitable optical or magnetic durable storage device e.g. RAM ROM Flash USB drive or other semiconductor based storage medium a hard drive CD ROM or other computer readable media for storing data and computer readable instructions and or software that implement various embodiments as taught in this disclosure. The non transitory memory may include other types of memory as well or combinations thereof. The non transitory memory may be provided as a physical element of the system or provided separately or remotely from the system . The non transitory memory of the system may store computer readable and computer executable instructions or software for implementing various embodiments including the multimedia content item store and the summary store .

When engaged the quality metric determination module communicates with the non transitory memory including the multimedia content item store and the summary store in order to receive and subsequently analyze a multimedia content item and corresponding summary. The quality metric determination module includes a sentence to sentence analyzer a sentence to image analyzer and an image to image analyzer . The sentence to sentence analyzer analyzes the quality of sentences or sentence segments in a text portion of a summary with respect to sentences in a text portion of a multimedia content item as described above in the content of . The sentence to image analyzer analyzes the quality of sentences in a text portion of a summary with respect to an accompanying image portion of the summary as described above in the context of . The image to image analyzer analyzes the quality of image portions of an image portion of a summary with respect to an image portion of a corresponding multimedia content item as described above in the context of . Once each of these analyzers and complete analysis the quality metric determination module receives the output of the respective analyses to determine a summary quality metric as described above.

The web server links the summary quality determination system to the user device via the network . The web server serves web pages as well as other web related content such as JAVA FLASH XML and so forth. The web server may provide the functionality of receiving or transmitting content items and summaries from and to a user device receiving and transmitting summary quality metrics from and to a user device and otherwise facilitating the consumption of content items. Additionally the web server may provide application programming interface API functionality to send data directly to native client device operating systems such as IOS ANDROID WEBOS or RIM. The web server also provides API functionality for exchanging data with the user device .

The summary quality determination system also includes at least one processor for executing computer readable and computer executable instructions or software stored in the non transitory memory and other programs for controlling system hardware. Virtualization may be employed so that infrastructure and resources in summary quality determination system may be shared dynamically. For example a virtual machine may be provided to handle a process running on multiple processors so that the process appears to be using only one computing resource rather than multiple computing resources. Multiple virtual machines may also be used with one processor.

The following two examples qualitatively describe applications of embodiments described herein. In the first example a multimedia content item contains two unique sentences. A first sentence Strincludes a set of unique words w. Stris repeated in the multimedia content item ntimes. A second sentence Strcontains a set of unique words w. Stris repeated in the multimedia content item ntimes. For convenience of explanation it is assumed that wand wdo not have any words in common. This last assumption is expressed mathematically as w w . Also for this example it is assumed that the word counts w 5 w 6. The number of times Stris repeated in the multimedia content item is n 10 and the number of times Stris repeated in the multimedia content item is n 2.

If summary of only a single sentence is requested two options are possible either a summary Sthat contains only Stror a summary Sthat contains only Str. Because Stris repeated 10 times five times more frequently than Str the summary Sis preferable because it captures the information which is dominant in the original multimedia content item. Because wand wdo not have any words in common the total number of unique words is the multimedia content item is w w. The retention rate of words in each of the summaries Sand Scompared to the multimedia content item follows in equations 11 and 12.

A retention rate algorithm such as the one presented above would preferentially select Sbecause it has a highest number of unique words of the summaries analyzed. The retention rate algorithm bases this selection criterion on the assumption that a summary that includes more unique words describes more of the content in the multimedia content item. However because these methods look at only word counts significant semantic differences are overlooked. In this example retention rate would select the summary Swhich has more unique words even though it is less representative of the overall content of the multimedia content item.

According to the embodiments of the present disclosure a summary having a higher information content and broader coverage of the multimedia content item as a whole i.e. reflecting different topics throughout the multimedia content item is preferred. In contrast to the above retention rate examples consider embodiments of the present disclosure applied to select between summary 1 S and summary 2 S . Equations 13 and 14 apply embodiments of the present disclosure to the above scenario. 1 1 10 5 50 Equation 13 2 2 2 6 12 Equation 14 In the above examples equation 7 is reduced to the form of equations 13 and 14 because the example includes only text portions therefore reducing the arguments of equation 7 that analyze image portions i.e. ICand Coh to zero. Therefore the only term remaining from equation 7 is that of IC. In this case ICreduces to the number of words in the sentence contributing to semantic meaning R because the max term is 1. Based on the above embodiments of the present disclosure would select Sbecause it is more representative of the multimedia content item i.e. selecting Sthat includes sentence Str which is repeated five times more frequently than Str .

In another example consider the advantages of embodiments of the present disclosure over KL Divergence. Adapting the preceding example summaries Sand Sare defined as S Str Str and S Str Str and w 5 w1 6 and w w . Because Sincludes more information i.e. both of Strand Str in contrast to Swhich includes only Strrepeated twice Sis the preferred summary.

In equation 13 qis the probability of occurrence of iword in the summary and p is the probability of occurrence of iword in the original document. Summary Swill be selected by KL Divergence if KL S 4.3 

In this example n 10 and n 2 so n 4.3 n. For this reason Swill be selected as the preferred summary by KL Divergence in this case even though S has less information than S.

In contrast applying embodiments of the present disclosure MuSQ S n w n w 10 5 2 6 62 and MuSQ S n w 10 5 50. Applying this model Sis properly selected as the preferred summary because of the diversity of information.

As will be appreciated in light of this disclosure the various modules and components of the system shown in such as the sentence to sentence analyzer sentence to image analyzer and image to image analyzer can be implemented in software such as a set of instructions e.g. HTML XML C C object oriented C JavaScript Java BASIC etc. encoded on any computer readable medium or computer program product e.g. hard drive server disc or other suitable non transient memory or set of memories that when executed by one or more processors cause the various methodologies provided in this disclosure to be carried out. It will be appreciated that in some embodiments various functions performed by the user computing system as described in this disclosure can be performed by similar processors and or databases in different configurations and arrangements and that the depicted embodiments are not intended to be limiting. Various components of this example embodiment including the computing device can be integrated into for example one or more desktop or laptop computers workstations tablets smart phones game consoles set top boxes or other such computing devices. Other componentry and modules typical of a computing system such as processors e.g. central processing unit and co processor graphics processor etc. input devices e.g. keyboard mouse touch pad touch screen etc. and operating system are not shown but will be readily apparent.

The foregoing description of the embodiments of the disclosure has been presented for the purpose of illustration it is not intended to be exhaustive or to limit the claims to the precise forms disclosed. Persons skilled in the relevant art can appreciate that many modifications and variations are possible in light of the above disclosure.

Some portions of this description describe the embodiments in terms of algorithms and symbolic representations of operations on information. These algorithmic descriptions and representations are commonly used by those skilled in the data processing arts to convey the substance of their work effectively to others skilled in the art. These operations while described functionally computationally or logically are understood to be implemented by computer programs or equivalent electrical circuits microcode or the like. The described operations may be embodied in software firmware hardware or any combinations thereof.

Any of the steps operations or processes described herein may be performed or implemented with one or more hardware or software modules alone or in combination with other devices. In one embodiment a software module is implemented with a computer program product comprising a non transitory computer readable medium containing computer program code which can be executed by a computer processor for performing any or all of the steps operations or processes described.

In one example a computer implemented method for evaluating a summary of a digital multimedia content item includes receiving the multimedia content item comprising a text portion and an image portion receiving the summary of the multimedia content the summary including a text portion and an image portion and determining a quality metric of the summary relative to the multimedia content item. The determining includes determining at least two of a first content metric quantifying an amount of information content in the text portion of the summary that is common to the text portion of the multimedia content item determining a second content metric quantifying an amount of information content in the image portion of the summary common to the image portion of the multimedia content item and determining a third content metric quantifying an information coherence between the text portion of the summary and the image portion of the summary. The quality metric is based at least in part on the at least two determined content metrics. In one embodiment of this example determining the quality metric further includes determining a product of the first content metric the second content metric and the third content metric. In one embodiment of this example determining the first content metric includes determining a cosine similarity between vector representations of at least one text segment of the text portion of the multimedia summary and at least one text segment of the multimedia content item. A max function can be applied to the cosine similarity determination. In one embodiment of this example determining the second content metric includes generating a first image vector from the image portion of the summary and a second image vector from the image portion of the multimedia content item. In one embodiment of this example determining the third content metric includes projecting a first text content vector from the text portion of the summary and a second text content vector from the image portion of the summary onto a common unit space. In one embodiment of this example determining the third content metric includes determining a product of a first content of the text portion of the summary and a second content of the image portion of the summary.

In another example a computer program product is stored on at least one non transitory computer readable medium that includes instructions that when executed by one or more processors cause the above computer implemented method to be carried out.

In another example a system for evaluating a summary of a digital multimedia content item includes various modules at least one processor and at least one non transitory storage media for determining a quality metric according to the example method described above.

