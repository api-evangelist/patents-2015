---

title: Deployment of database objects
abstract: A system, a method, and a computer program product for deploying of objects are disclosed. At least one file containing a plurality of artifacts for deploying during runtime of an application is defined. Each artifact in the plurality of artifacts includes at least one object in the plurality of objects required to be deployed during runtime of the application. At least one dependency for at least one artifact in the plurality of artifacts is determined. An execution order for deployment of the plurality of artifacts is generated. The plurality of artifacts is deployed in accordance with the generated execution order.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09600269&OS=09600269&RS=09600269
owner: SAP SE
number: 09600269
owner_city: Walldorf
owner_country: DE
publication_date: 20151123
---
This disclosure relates generally to data processing and in particular to deployment of database objects.

Businesses use a plurality of business process applications and or services in their business operations. Applications and or services can be programs that an end user runs to accomplish certain tasks and can work in conjunction with one or more back end systems which can store the data to be worked on such as for example business objects and other business data as well as logic for manipulating the data such as for example transactions or other business logic. Examples of back end systems may include database systems enterprise resource planning ERP systems and customer relationship management CRM systems. A user interface UI can be designed to work in concert with application programs and facilitates interaction between humans and computers by inviting and responding to user input. In order to accomplish various tasks a user can initiate various applications tasks agents etc. that may manipulate data in different ways to achieve results desired by the user.

Users can design and or create various business process objects such as sales orders invoices etc. A business object can be created using any known computing systems and languages e.g. one such exemplary language includes advanced business application programming ABAP high level programming language which is available from SAP SE Walldorf Germany . Such created objects can be stored in memory such as in a database. An example of such database includes a High Performance Analytic Appliance HANA which is a column oriented in memory database appliance available from SAP SE Walldorf Germany. Objects can be created at design time for execution at runtime of an application. To accommodate design time creation and runtime execution objects need to be deployed at the database. Deployment of objects can be a complicated process and conventionally can involve a multitude of aspects such as version control lifecycle management special programs application layer artifacts and others. This can significantly hinder efficient implementation of database systems dependency management among objects etc. Thus there is a need for a transactional all or nothing deployment model that can simplify deployment of database systems.

In some implementations the current subject matter relates to a method for deploying of objects. The method can include defining at least one file containing a plurality of artifacts for deploying during runtime of an application. Each artifact in the plurality of artifacts can include at least one object in the plurality of objects required to be deployed during runtime of the application. The method can also include determining based on the defining at least one dependency for at least one artifact in the plurality of artifacts generating based on the determining an execution order for deployment of the plurality of artifacts and deploying the plurality of artifacts in accordance with the generated execution order. At least one of the defining the determining the generating and the deploying can be performed by at least one processor of at least one computing system.

In some implementations the current subject matter can include one or more of the following optional features. In some implementations the deployment can include at least one of the following undeploying the artifact deploying a modified version of the artifact and re deploying the artifact.

In some implementations the method can also include determining whether the artifact is cyclically dependent on another artifact in the plurality of artifacts prohibiting deployment of the artifact and another artifact based on a determination that the artifact and another artifact do not belong to the same build plugin where the plugin is used to deploy the artifact at runtime of the application and permitting deployment of the artifact and another artifact based on a determination that the artifact and another artifact belong to the same plugin.

In some implementations the method can include generating a dependency graph for the plurality of the artifacts based on the plurality of required objects where the execution order is generated based on the generated dependency graph.

In some implementations the deployment can include initially deploying based on the generated execution order the plurality of artifacts modifying an artifact in the plurality of artifacts generating a modified execution order where the modified execution order specifies deployment of the modified artifact and deploying the plurality of artifacts including the modified artifact based on the modified execution order. The method can also include determining another artifact in the plurality of artifacts being dependent on the artifact and redeploying another artifact as a result of the modification of the artifact. The method can further include determining another artifact in the plurality of artifacts being dependent on the artifact and undeploying another artifact prior to deploying the modified artifact deploying the modified artifact and redeploying another artifact after deploying the modified artifact.

In some implementations the dependency can include at least one of the following the artifact being dependent on at least another artifact in the plurality of artifacts and the artifact being independent of any artifact in the plurality of artifacts.

Non transitory computer program products i.e. physically embodied computer program products are also described that store instructions which when executed by one or more data processors of one or more computing systems causes at least one data processor to perform operations herein. Similarly computer systems are also described that may include one or more data processors and memory coupled to the one or more data processors. The memory may temporarily or permanently store instructions that cause at least one processor to perform one or more of the operations described herein. In addition methods can be implemented by one or more data processors either within a single computing system or distributed among two or more computing systems. Such computing systems can be connected and can exchange data and or commands or other instructions or the like via one or more connections including but not limited to a connection over a network e.g. the Internet a wireless wide area network a local area network a wide area network a wired network or the like via a direct connection between one or more of the multiple computing systems etc.

The details of one or more variations of the subject matter described herein are set forth in the accompanying drawings and the description below. Other features and advantages of the subject matter described herein will be apparent from the description and drawings and from the claims.

In some implementations the current subject matter relates to a deployment infrastructure for a High Performance Analytic Appliance HANA as developed by SAP SE Walldorf Germany . The deployment infrastructure can be a service layer of the HANA database that can simplify deployment of HANA database artifacts i.e. design time objects e.g. tables views etc. . This can be accomplished by providing declarations that define database objects and by ensuring consistent deployment into the database. In some implementations the deployment can be based on a transactional all or nothing deployment model as well as an implicit dependency management. The deployment infrastructure can implement use of containers that can allow multiple deployments and sandboxing. The deployment infrastructure can be used to deploy design time objects of applications databases etc.

In some implementations the deployment infrastructure can focus on deployment aspects and address development and or modeling scenarios as part of the HANA database and or extended application services XS as developed by SAP SE Walldorf Germany . Further the deployment infrastructure can provide artifacts for HANA database objects e.g. tables views calculation views procedures core data services CDS as developed by SAP SE Walldorf Germany etc.

In some implementations the deployment infrastructure can use containers and or container models for the purposes of deploying database objects. A container can correspond to a database schema. Containers can be used for multiple deployments of the same database artifacts for development sandboxes etc. Containers can be isolated from each other by various database mechanisms e.g. each database schema with its deployed database objects can be owned by a per schema technical database user. In some implementations a cross container access at the database level can be permitted via database privileges and or prohibited.

In some implementations database objects can be written in a schema free way e.g. no explicit schema references to allow deployment of the same database objects into different containers. References to schema external objects can be created using synonyms or table links in case of zero downtime maintenance ZDM which can be bound during deployment. The synonyms or table links can provide schema local names for the schema external objects. Privileges on these schema external objects can be explicitly granted to the container s technical user e.g. SELECT WITH GRANT OPTION privileges on schema external ERP tables .

As stated above the deployment infrastructure can be a layer on top of the HANA database. For the purposes of creating modifying and or deleting objects inside the database the deployment infrastructure can use structured query language SQL commands.

In some implementations the deployment infrastructure can allow modeling of a networked set of persistence objects e.g. tables sequences etc. views procedures functions data flows etc. that can be later deployed. These objects can be converted into file based artifacts which can simplify dependency based deployment re deployment and or undeployment of objects. It can also facilitate lifecycle management aspects such as transport of objects. File based artifacts can also allow separation of uploading of the artifacts into deployment infrastructure i.e. staging and deployment of the artifacts. Additionally the artifacts can simplify incremental deployment scenarios where only modified files can be uploaded. The file artifacts can represent the target state of the database objects e.g. they specify a view definition in a declarative way for example instead of imperative CREATE ALTER DROP statements .

In some implementations the deployment infrastructure can perform dependency management by extracting a set of provided and or required database i.e. runtime objects from the file artifacts and can use this information for dependency management during deployment e.g. to calculate the order in which the database objects need to be created and or to detect missing required objects . Additionally dependencies can be used to re deploy database objects that are affected by newly deployed or modified objects.

In some implementations the deployment infrastructure can use database mechanisms to ensure a transactional all or nothing deployment. Modifications of database objects operations as well as re deployments of affected artifacts can be performed inside a single database transaction. In some implementations a single deployment can operate on a single container with the container boundary being a deployment boundary. For example affected database objects inside other database schemata are not re deployed and deployment does not fail if database objects inside other schemata break.

Further in addition to the schema based containers the deployment infrastructure also can use database schemata to isolate its metadata e.g. to separate storage of file artifacts from the deployed database objects.

In some implementations the deployment infrastructure can implement build plugins to provide the infrastructure for all deployment aspects. The interpretation of artifacts including the extraction of dependencies and the steps to implement a target state based deployment of the artifacts can be performed by such build plugins which can include for example a plugin for a table artifact type a plugin for a view artifact type etc. Build plugins can have access to the deployment container for example via a SQL based application programming interface API . In some exemplary implementations SQL commands that the build plugins need for creating altering dropping a database object can be available at the SQL layer of HANA. In addition these SQL commands can further account for database security constraint and support the deployment infrastructure s transactional deployment where statements are run inside a single database transaction in non auto commit mode.

In some implementations the deployment infrastructure can be constrained by at least one of the following deployment architectural boundaries database services application programming interfaces and technical users. In some exemplary implementations the database service instances can be created via a database specific service broker e.g. a HANA database service broker. Additionally a database service instance can correspond to a single database schema and an assigned technical database user. The HANA database service broker can delegate schema creation to the deployment infrastructure such that the deployment infrastructure can also create its required metadata database users and or database roles inside the database. On deletion of a database service instance the deployment infrastructure can be called implicitly by the broker in order to delete the container schema its metadata etc.

In some implementations an SQL based application programming interface can be a lowest common denominator for the deployment infrastructure s API. It can be an API which is accessible via a standard HANA SQL connection.

A technical user can be a technical deployment user for a specific schema based container. Deployment related activities e.g. staging of files triggering of real deployment into a single container etc. can be performed by a dedicated technical deployment user. The technical deployment user of the container schema can be different from the technical runtime user of the container schema to allow separation of privileges for deployment and or runtime access to the deployed database objects.

The database cluster can include various database processes e.g. HANA database processes each having a design time and runtime persistence components not shown in . As shown in the database process can include a database processor e.g. a HANA SQL processor that can be communicatively coupled to a deployment infrastructure proxy component . The deployment infrastructure proxy component can be communicatively coupled to a deployment infrastructure process . The deployment infrastructure process can include a deployment infrastructure kernel e.g. a HANA deployment infrastructure kernel and at least one design time build plugin component .

In some implementations the technical users can access the deployment infrastructure proxy component via the database processor . The proxy component then communicates with the kernel via a network protocol connection. The kernel accesses design time build plugin s to generate create modify various objects which are then supplied by the kernel to the database processor and can thereafter be persisted by the database processor .

In some implementations the system can provide an SQL based API for the deployment infrastructure that can be accessed via a standard SQL connection where the API can be exposed at the SQL layer. As shown in system can represent the system s target architecture for the deployment infrastructure in order to provide the API at the SQL layer and keep the deployment infrastructure kernel and the deployment infrastructure design time build plugin s isolated in its own operation system process.

For the purposes of decoupling the deployment infrastructure can provide database procedures for its APIs. Communication from the database process also referred to as hdbindexserver towards the deployment infrastructure process also referred to as hdbdiserver can be provided via a deployment infrastructure proxy library which can be loaded into the database process . This proxy can implement database procedures and or client side of a deployment infrastructure network protocol. All incoming requests can be routed to the deployment infrastructure process using this network protocol. In some implementations the components and can also be inside the database process .

The deployment infrastructure process can communicate to the database process via an internal application programming interface e.g. HANA s internal EAPI Thin Layer SQL client on a new database transaction. This new transaction is not related to the database transaction in which the deployment infrastructure command is sent to the database process . The SQL communication from deployment infrastructure towards the database process can be a trusted communication which can allow deployment infrastructure to execute SQL statements on behalf of different technical users inside a single database transaction in order to implement different security features at the database layer.

In some implementations the deployment infrastructure can use schema based containers which can be database service instances which can correspond to a database schema and a set of technical users. The database broker can call the deployment infrastructure to create the application s container schema and its required metadata e.g. companion schemata technical users etc. via deployment infrastructure s container management API.

A single deployment via the deployment infrastructure can operate on one schema based container. If multiple schemata are involved then multiple deployments via the deployment infrastructure can be implemented i.e. one for each schema. In case of ZDM each data schema and each access schema can be considered a separate schema which can be deployed using its own deployment.

Referring back to the view can be associated with a view plugin that can transform a design time view resource into a SQL view database object. In some exemplary implementations the file format can use a data definition language DDL style syntax which can be equivalent for example to the corresponding CREATE VIEW SQL syntax without the CREATE . This can include support for column views of TYPE HIERARCHY if the query is provided as a SQL query. If the view selects from a synonym which points to an object inside another schema or different container or to an object inside the same container which is owned by a different user then the container s object owner i.e. COO S can be granted the required privileges on the target object e.g. SELECT UPDATE INSERT in order to access the object. For views the object owner can also have WITH GRANT OPTION privileges if the views are exposed to other users . If a view has to be secured via analytic privileges structured privileges then the view defined needs to contain the WITH STRUCTURED PRIVILEGE CHECK clause.

In some implementations the deployment infrastructure can have at least one view plugin which can include at least one of the following a calculation view plugin a projection view plugin and or any other view plugins. The calculation view plugin can transform a design time calculation view description into a set of view database objects.

The projection view plugin can transform a design time projection view resource into a projection view database object. A projection view configuration resource can contain a binding from the projection view to a target database a target schema and or a target object similar to synonyms as discussed below . The definition of a projection view can include two design time files a projection view file with an optional default configuration and an explicit configuration of the projection view s target. The explicit configuration can be provided at deployment time overriding an optional default configuration. An administrator can map object references according to the deployment context. In some exemplary implementations the format of the projection view file can use a DDL style syntax which can be equivalent to the corresponding CREATE PROJECTION VIEW SQL syntax without the CREATE . The FROM clause of the PROJECTION VIEW definition can define the default configuration. A projection view configuration file can contain multiple configurations. If the schema of a target description is left out then the projection view can point to a container local object. In this case the referenced object can be considered as a deployment dependency. If the projection view points to an object inside another schema or different container or to an object inside the same container which is owned by a different user then the container s object owner e.g. COO S shown in can be granted the required privileges on the target object e.g. SELECT UPDATE INSERT in order to access the object.

The deployment infrastructure can also include a table plugin that can transform a design time table resource into a table database object. The file format can use a DDL style syntax which in some exemplary implementations can be equivalent to the corresponding CREATE TABLE SQL syntax without the CREATE . Tables can have at least two types ROW and COLUMN. A table can be self contained. In some implementations a table cannot reference another table.

The deployment infrastructure can include a virtual table plugin that can transform a design time virtual table resource into a virtual table database object. The target database where the virtual table points to needs to be available via a database remote source. A definition of a virtual table can include two design time files a virtual table file with an optional default configuration and an explicit virtual table configuration that contains the binding from virtual table to remote source target database target schema and or target object. The explicit configuration can be provided at latest at deployment time overriding the optional default configuration. An administrator can map object references according to the deployment context. In some exemplary implementations the file format can use a DDL style syntax which is equivalent to the corresponding CREATE VIRTUAL TABLE SQL syntax without the CREATE . The container s object owner e.g. COO S as shown in can be granted the CREATE VIRTUAL TABLE ON REMOTE SOURCE privilege on the remote source in order to access the remote source.

The synonym objects or table links can allow referencing of schema external objects. A typical example can include accessing database objects that are not brought into the system via HANA deployment infrastructure e.g. database objects from an enterprise resource planning ERP system and or replicated objects. These objects can be easily accessed by defining synonyms. In most cases fully qualified names of referenced database objects are not known during development but can depend on deployment decisions. Thus the synonym can include two design time files a declaration with an optional default configuration and an explicit configuration of the synonym s target. The explicit configuration can be provided at deployment time and can override an optional default configuration. Hence an administrator can map object references according to the deployment context.

The following code illustrates an exemplary synonym definition and configuration. Here the synonym definitions use the content of the associated target objects as a default configuration 

In some implementations a synonym definition configuration file can contain multiple definitions configurations. If the schema and or the database of a target description is are left out then the synonym can point to a container local object. In this case the referenced object can be considered as a deployment dependency. If the schema database of a target description is defined then the referenced target object can be considered as a non development infrastructure managed runtime object and it is not considered during dependency management. If the synonym points to an object inside another schema or different container or to an object inside the same container which is owned by a different user then the container s object owner i.e. COO S as shown in can be granted the required privileges on this target object e.g. SELECT UPDATE INSERT in order to access the object. If views or definer mode procedures are built on top of synonyms then the object owner can be granted privileges WITH GRANT OPTION if the views are exposed to other users .

To perform container management and deployment the deployment infrastructure can use two kinds of APIs. One of the APIs can include a higher level privileged container management API that can allow creation and or deletion of schema based containers. The other API can include a container level deployment API that can allow applications and or tools to deploy undeploy artifacts within a container.

An exemplary grant of privileges on the container schema S can include a call  SYS DI.GRANT CONTAINER SCHEMA PRIVILEGE S SELECT RUNTIME USER S . An exemplary grant of a role on the container schema S can include a call of  SYS DI.GRANT CONTAINER SCHEMA ROLE S A ROLE XYZ SOME USER . An exemplary grant of a privilege e.g. WRITE READ MAKE on the container S deployment API can include calls  SYS DI.GRANT CONTAINER API PRIVILEGE S WRITE EXECUTE DEPLOY USER S  SYS DI.GRANT CONTAINER API PRIVILEGE S READ EXECUTE DEPLOY USER S and  SYS DI.GRANT CONTAINER API PRIVILEGE S MAKE EXECUTE DEPLOY USER S respectively.

In some implementations at installation time of the deployment infrastructure together with underlying database appliance e.g. HANA the management schema  SYS DI its content and all internal deployment infrastructure system users can be created. Additionally for bootstrapping of privileges execute rights on these procedures and or select privileges on additional monitoring views etc. can be granted to the default administration user of the database with GRANT OPTION.

Referring to the system can include a database appliance e.g. HANA communicatively coupled with extended services which can be accessed by an extended services operator . The appliance can include a container deployment infrastructure a processor a deployment infrastructure management component and a management API . The container e.g. container S deployment infrastructure can include deployment infrastructure plugin metadata for container S CP S along with an associated container S plugin metadata owner s CPO S a deployment infrastructure metadata and deployment API for container S including API procedure s along with an associated container S metadata owner CMO S and a deployment schema container S along with container S schema owner CSO S and container S object owner COO S which can have CREATE ANY privileges on the schema S . The container S can include one or more artifacts objects etc. as discussed above. The users are technical users. The deployment infrastructure management can also be communicatively coupled with a deployment infrastructure transaction owner  SYS DI TO and deployment infrastructure super user  STS DI SU which has all privileges . The database appliance can also include a deployment infrastructure management API having API procedure s and a deployment infrastructure database object owner that can be communicatively coupled with the management API the API procedure s as well as the API procedure s .

In some implementations an administrator can create a deployment infrastructure technical management user TMU HDI and grant execute rights on the above procedures e.g. create container drop container grant privilege etc. to the management user . The database service broker of the extended services can use the management user to create alter drop containers and or grant revoke privileges to from users. More than one management user can exist in the system and the privileges can be assigned to various roles and or various roles can be assigned to users. Further grant revoke database procedures can be provided which can support user privileges on the  SYS DI schema and or a container s metadata schemata.

In some implementations when creating a container the system can implement the following procedures. On creation of a container schema S the deployment infrastructure can create the technical container schema owner CSO S the container schema S the container object owner COO S the metadata and deployment API companion schema CM S and a set of plugin metadata companion schemata CP S with corresponding owner users CPO S s . The metadata schema CM S can be used for storing file artifacts and or keeping track of active files. The container specific plugin metadata schemata CPO S s can be used for build plugin specific metadata that can be used during deployment.

In some implementations technical container users i.e. users can only be used internally by the deployment infrastructure and can be created as restricted database users without an ability to log on to the database. The users also own their corresponding objects in the deployment infrastructure.

In some implementations the container object owner COO S can be used for creating database objects inside the container schema S . For example the user can have CREATE ANY privileges on the container schema S and the  SYS DI OO DEFAULTS role. This way the database objects are owned by a system internal technical user and are not bound to the lifetime of externally owned users which trigger the deployment of artifacts. Additionally the deployed database objects do not inherit database privileges from the deploying users. The  SYS DI OO DEFAULTS role can give privileges on standard database objects e.g. objects in SYS like SYS.DUMMY. The  SYS DI OO DEFAULTS role can be a deployment infrastructure specific variant of the PUBLIC role which can have a plurality of privileges with a minimal set of object privileges that every container object owner can have.

In some implementations the objects are not created via the container schema owner CSO S in order to avoid accidental deletion of objects inside the schema which were created by other users e.g. by applications at runtime . The container object owner COO S does not have execute rights on the container s deployment API procedures. Thus it might be not possible to deploy definer mode procedures which expose and or use the deployment API without explicitly granting these privileges to the container object owner COO S . The container object owner COO S does not have any access to the metadata schemata.

Further database privileges on external objects e.g. SELECT privileges on ERP tables which the container object owner COO S needs when creating database objects on top of these external objects e.g. when deploying a view can be granted to the object owner by the privilege owner e.g. an administrator . If a view should be created by the container object owner COO S then the privileges on the external objects can be granted with GRANT OPTION.

The container schema owner CSO S can be used for dropping the container schema S when the container is deleted. The container schema owner can drop the schema including all contained database objects although database objects from other users might exist inside the schema. The container schema owner CSO S can be used internally by deployment infrastructure for granting revoking schema level privileges to from users.

In some implementations once containers are created they can be provided with a particular name in accordance with a container naming scheme. For example container names can have a maximum size of 64 characters and can contain characters A to Z numbers 0 to 9 and an underscore character   and or any other characters.

The name of the container schema S the name of the deployment API and metadata schema CM S and the name of the container object owner COO S can be visible to administrators and or end users. Thus as shown in they can be named S S DI and S OO . All other internal users and internal schemata can use a prefix  DI S to allow to group and or hide them in tools queries etc.

The database can include a processor e.g. a HANA SQL processor container deployment infrastructure in addition to deployment infrastructure for deployment of a container e.g. container S a pseudo catalog metadata e.g.  SYS DI BIMC and various other schema e.g. other application schema ERP schema etc. . The container e.g. container S deployment infrastructure can include deployment infrastructure plugin metadata for container S CP S along with an associated container S plugin metadata owner s CPO S a deployment infrastructure metadata and deployment API for container S including API procedure s along with an associated container S metadata owner CMO S and a deployment schema container S along with container S schema owner CSO S and container S object owner COO S which can have CREATE ANY privileges on the schema S . In some implementations the container object owner can also receive access rights e.g. explicitly granted by a third party to other application schema component . The users can be technical users in accordance with the discussion above.

In some implementations the application deployment component can be associated with a container S deploy user DU S which can generate various calls e.g. CALL DA S.WRITE . . . CALL DA SMAKE . . . etc. to the processor . Similarly the application runtime component can be associated with a container S runtime user RU S which execute various procedures e.g. SELECT INSERT etc. during runtime of an application where the execution calls can be sent to the processor for processing.

During deployment calls issued by the application deployment component can be passed on to the API procedure component in the deployment infrastructure s metadata and deployment API component . The CM S component can further pass the call to the deployment infrastructure s deployment component . The deployment component can exchange metadata updates and perform file staging updates using metadata object owner MOO S and or container metadata schema owner MSO S which can be other technical users in the system . The metadata can be container specific metadata e.g. design time container DTC and can include information concerning design time artifacts data dependencies and or build plugin metadata as well as any other information. The deployment component can also communicate with the deployment schema container component to perform deployment undeployment of schema container using COO S . The component can further be controlled by the transaction owner component another technical user . In some implementations the component can also exchange pseudo catalog metadata updates with the pseudo catalog metadata component using catalog metadata user e.g. using  SYS DI  CATALOG .

In some implementations APIs for working with a specific container S can be created as database procedures inside the container deployment API schema CM S i.e. S DI . The procedures can include at least one of the following file system operations make operations grant revoke operations. The file system operation can include at least one of the following CM S.WRITE CM S.READ CM S.READ DEPLOYED CM S.LIST CM S.LIST DEPLOYED CM S.STATUS and others. The make operations can include CM S.MAKE and other procedures. The grant revoke operations can include at least one of the following CM S.GRANT API PRIVILEGE CM S.REVOKE API PRIVILEGE CM S.GRANTSCHEMA PRIVILEGE CM S.REVOKE SCHEMA PRIVILEGE CM S.GRANT SCHEMA ROLE CM S.REVOKE SCHEMA ROLE and others.

The above database procedures can be created as definer mode procedures and can be owned by the deployment infrastructure database object owner  SYS DI. Their definition can include a delegation to a corresponding procedure in the central management schema  SYS DI while binding the deployment schema. For example 

Execution rights for the container level deployment APIs for schema S can be explicitly granted after container creation using  SYS DI.GRANT CONTAINER API PRIVILEGE and or with GRANT OPTION.

After creation of container S the operator can create at least the following users the deploy user DU S and the runtime user RU S . Then the operator can grant privileges on the container s deployment API to the deploy user DU S and privileges on the container schema S to the runtime user RU S . Additional users and privileges can also be created. In some implementations the deploy user and the runtime user can be a single entity however having separate deploy user DU S and runtime user RU S can simplify zero downtime maintenance ZDM upgrades. For example during a ZDM upgrade ZDM can set the runtime user RU S into a read only mode by revoking privileges which can modify the data in the container schema S from the runtime user RU S while allowing the deploy user DU S to create delete database objects as part of the upgrade.

In some implementations a deployment user can be allowed to deploy everything in the given schema based container. This can avoid a situation where the deployment user is limited to deploying a certain kind of artifact type and or database objects that have a certain kind of name.

In some implementations the current subject matter s deployment infrastructure can also provide various deployment privilege workarounds. This can be applicable in situation where not all database rights which are required during deployment into a container schema S currently exist as a database privilege are grantable and or restrictable on a schema level e.g. they exist only as a global privilege and or are contained in the schema level CREATE ANY privilege. In order to work around these limitations without granting permanent system wide privileges to the container object owner COO S the deployment infrastructure can implement a special deployment infrastructure internal super user  SYS DI SU user e.g. super as shown in which can be created at installation time and who has all the required privileges e.g. creation of users creation of roles etc. . When the deployment transaction begins the super user can temporarily grant one or more privileges to the container object owner COO S and when a transaction is going to be committed these privileges can be revoked by the super user . This approach can be used whenever the container object owner must be the owner of the created database objects and can ensure that the container object owner COO S has the required privileges at the point in time when the container object owner issues the CREATE statements towards the database. In some implementations a catalog read access and or dropping of database objects where only a system wide privilege is available can be performed directly via the super user . Further insertion deletion of data into from catalog like metadata tables which do not have schema level privileges can be performed via dedicated catalog users e.g. catalog metadata user as shown in and can be hidden behind corresponding APIs.

Exemplary container management APIs and container level APIs can be found in the Appendix A. The container management APIs can be available via the central database schema  SYS DI and the APIs for a specific container S inside the container s API schema S DI. The APIs can include a set of database procedures table types and or monitoring views.

As shown in the system can include one or more technical users that can perform various functions associated with the deployment infrastructure. A user SYS DI BI CATALOG can be used for the BI metadata catalog read write access to  SYS BI.BIMC  where DB RTC API can be used. A user  SYS DI CDS CATALOG can be used for the CDS metadata catalog read write access to  SYS RT.CDS  where DB RTC API can be used. A user  SYS DI SEARCH CATALOG can be used for the search metadata catalog  SYS RT.SEARCH  and  SYS RT.ESH  where DB RTC API can be used. The search metadata catalog can be used to store metadata for database level search features. A user  SYS DI CATALOG can be used for generic catalog queries where DB RTC API can be used. The database catalog user  SYS DI CATALOG can be used for unfiltered generic queries on the database catalog e.g. to retrieve metadata of tables e.g. field names field types field sizes etc.

In some implementations the container object owner COO S can have extended privileges during the deployment process and thus it should not be possible for build plugins to call arbitrary database procedures during deployment. Access to required database internal database procedures can be provided via dedicated methods of the deployment infrastructure s database interface.

In some implementations a common naming approach can be implemented by the deployment infrastructure. For example .hdinamespace can contain a pattern that describes the naming scheme e.g. a scheme dot and double colon casesensitive for name.space object a underscore sql style for name space object or a none scheme for you get what you write . This pattern can be checked by the build plugins to ensure that the created database objects follow the rule of the pattern. The .hdinamespace files can be created on a folder level so it is possible to have a mixture of naming schemes inside a single container.

In some implementations build plugins can be handled as pluggable components e.g. each build plugin can live inside its own shared library and plugins can be loaded by the deployment infrastructure dynamically.

In some implementations the deployment infrastructure can be used to deploy artifacts and or objects in a particular order. The deployment of objects can be based on dependencies between objects in the target model. The order of deployment of artifacts can be based on information about database runtime objects which can be provided by an artifact and or which can be required by an artifact. Using this information a dependency graph can be created which can connect object providers to corresponding object consumers.

In some implementations the artifacts can have various types. In some cases the three artifacts can have the same artifact type A B C or three different types A B C and A C or two different types A B C A B C or A C B . In some implementations a single build plugin can handle all artifact types. Alternatively different build plugins can handle different artifact types.

In some implementations the deployment process of artifacts can be modified by receiving a modified version of an artifact or undeploying an old artifact and receiving a modified artifact. Using the first or the DEPLOY strategy the build plugin can receive a modified new version of the artifact and thus can react accordingly. For example the build plugin can issue ALTER statements to the database. Using the second or UNDEPLOY DEPLOY strategy the old artifact can be undeployed and the build plugin receives the modified new version of the artifact for deployment. In some implementations modification strategies can be combined. Similar process can be applicable to revalidation of artifacts which can occur when artifacts that provide required objects are modified or revalidated .

The deployment infrastructure can also prevent occurrences of various cyclic dependencies. For example if artifact C depends on artifact B and artifact B depends on artifact C then no execution order for the deployment of B and C can be determined as shown by the execution graph in . This is because both artifacts require that the other artifact is deployed before the other one is deployed as well.

However in some cases cyclic dependencies can be allowed. illustrates an execution graph that allows cyclic dependencies between artifacts. In this case artifacts B and C can have the same artifact type and thus can be handled by the same build plugin which allows cycles for its artifacts. Hence the cycle between artifacts B and C is an intra type cycle and is not considered as a cycle for the purposes of execution graph creation. Artifacts A and B can be passed together to the build plugin and the intra type cycle between artifacts B and C can be handled by the build plugin which can determine whether the cycle cannot be permitted.

In some implementations the current subject matter can be implemented in various in memory database systems such as a High Performance Analytic Appliance HANA system as developed by SAP SE Walldorf Germany. Various systems such as enterprise resource planning ERP system supply chain management system SCM system supplier relationship management SRM system customer relationship management CRM system and or others can interact with the in memory system for the purposes of accessing data for example. Other systems and or combinations of systems can be used for implementations of the current subject matter. The following is a discussion of an exemplary in memory system.

The one or more modules software components or the like can be accessible to local users of the computing system as well as to remote users accessing the computing system from one or more client machines over a network connection . One or more user interface screens produced by the one or more first modules can be displayed to a user either via a local display or via a display associated with one of the client machines . Data units of the data storage application can be transiently stored in a persistence layer e.g. a page buffer or other type of temporary persistency layer which can write the data in the form of storage pages to one or more storages for example via an input output component . The one or more storages can include one or more physical storage media or devices e.g. hard disk drives persistent flash memory random access memory optical media magnetic media and the like configured for writing data for longer term storage. It should be noted that the storage and the input output component can be included in the computing system despite their being shown as external to the computing system in .

Data retained at the longer term storage can be organized in pages each of which has allocated to it a defined amount of storage space. In some implementations the amount of storage space allocated to each page can be constant and fixed. However other implementations in which the amount of storage space allocated to each page can vary are also within the scope of the current subject matter.

In some implementations the data storage application can include or be otherwise in communication with a page manager and or a savepoint manager . The page manager can communicate with a page management module at the persistence layer that can include a free block manager that monitors page status information for example the status of physical pages within the storage and logical pages in the persistence layer and optionally in the page buffer . The savepoint manager can communicate with a savepoint coordinator at the persistence layer to handle savepoints which are used to create a consistent persistent state of the database for restart after a possible crash.

In some implementations of a data storage application the page management module of the persistence layer can implement shadow paging. The free block manager within the page management module can maintain the status of physical pages. The page buffer can include a fixed page status buffer that operates as discussed herein. A converter component which can be part of or in communication with the page management module can be responsible for mapping between logical and physical pages written to the storage . The converter can maintain the current mapping of logical pages to the corresponding physical pages in a converter table . The converter can maintain a current mapping of logical pages to the corresponding physical pages in one or more converter tables . When a logical page is read from storage the storage page to be loaded can be looked up from the one or more converter tables using the converter . When a logical page is written to storage the first time after a savepoint a new free physical page is assigned to the logical page. The free block manager marks the new physical page as used and the new mapping is stored in the one or more converter tables .

The persistence layer can ensure that changes made in the data storage application are durable and that the data storage application can be restored to a most recent committed state after a restart. Writing data to the storage need not be synchronized with the end of the writing transaction. As such uncommitted changes can be written to disk and committed changes may not yet be written to disk when a writing transaction is finished. After a system crash changes made by transactions that were not finished can be rolled back. Changes occurring by already committed transactions should not be lost in this process. A logger component can also be included to store the changes made to the data of the data storage application in a linear log. The logger component can be used during recovery to replay operations since a last savepoint to ensure that all operations are applied to the data and that transactions with a logged commit record are committed before rolling back still open transactions at the end of a recovery process.

To ensure that committed changes are not lost redo log information can be written by the logger component whenever a change is made. This information can be written to disk at latest when the transaction ends. The log entries can be persisted in separate log volumes while normal data is written to data volumes. With a redo log committed changes can be restored even if the corresponding data pages were not written to disk. For undoing uncommitted changes the persistence layer can use a combination of undo log entries from one or more logs and shadow paging.

The persistence interface can handle read and write requests of stores e.g. in memory stores etc. . The persistence interface can also provide write methods for writing data both with logging and without logging. If the logged write operations are used the persistence interface invokes the logger . In addition the logger provides an interface that allows stores e.g. in memory stores etc. to directly add log entries into a log queue. The logger interface also provides methods to request that log entries in the in memory log queue are flushed to disk.

Log entries contain a log sequence number the type of the log entry and the identifier of the transaction. Depending on the operation type additional information is logged by the logger . For an entry of type update for example this would be the identification of the affected record and the after image of the modified data.

When the data application is restarted the log entries need to be processed. To speed up this process the redo log is not always processed from the beginning Instead as stated above savepoints can be periodically performed that write all changes to disk that were made e.g. in memory etc. since the last savepoint. When starting up the system only the logs created after the last savepoint need to be processed. After the next backup operation the old log entries before the savepoint position can be removed.

When the logger is invoked for writing log entries it does not immediately write to disk. Instead it can put the log entries into a log queue in memory. The entries in the log queue can be written to disk at the latest when the corresponding transaction is finished committed or aborted . To guarantee that the committed changes are not lost the commit operation is not successfully finished before the corresponding log entries are flushed to disk. Writing log queue entries to disk can also be triggered by other events for example when log queue pages are full or when a savepoint is performed.

With the current subject matter the logger can write a database log or simply referred to herein as a log sequentially into a memory buffer in natural order e.g. sequential order etc. . If several physical hard disks storage devices are used to store log data several log partitions can be defined. Thereafter the logger which as stated above acts to generate and organize log data can load balance writing to log buffers over all available log partitions. In some cases the load balancing is according to a round robin distributions scheme in which various writing operations are directed to log buffers in a sequential and continuous manner. With this arrangement log buffers written to a single log segment of a particular partition of a multi partition log are not consecutive. However the log buffers can be reordered from log segments of all partitions during recovery to the proper order.

As stated above the data storage application can use shadow paging so that the savepoint manager can write a transactionally consistent savepoint. With such an arrangement a data backup comprises a copy of all data pages contained in a particular savepoint which was done as the first step of the data backup process. The current subject matter can be also applied to other types of data page storage.

In some implementations the current subject matter can be configured to be implemented in a system as shown in . The system can include a processor a memory a storage device and an input output device . Each of the components and can be interconnected using a system bus . The processor can be configured to process instructions for execution within the system . In some implementations the processor can be a single threaded processor. In alternate implementations the processor can be a multi threaded processor. The processor can be further configured to process instructions stored in the memory or on the storage device including receiving or sending information through the input output device . The memory can store information within the system . In some implementations the memory can be a computer readable medium. In alternate implementations the memory can be a volatile memory unit. In yet some implementations the memory can be a non volatile memory unit. The storage device can be capable of providing mass storage for the system . In some implementations the storage device can be a computer readable medium. In alternate implementations the storage device can be a floppy disk device a hard disk device an optical disk device a tape device non volatile solid state memory or any other type of storage device. The input output device can be configured to provide input output operations for the system . In some implementations the input output device can include a keyboard and or pointing device. In alternate implementations the input output device can include a display unit for displaying graphical user interfaces.

In some implementations the current subject matter can include one or more of the following optional features. In some implementations the deployment can include at least one of the following undeploying the artifact deploying a modified version of the artifact and re deploying the artifact.

In some implementations the method can also include determining whether the artifact is cyclically dependent on another artifact in the plurality of artifacts prohibiting deployment of the artifact and another artifact based on a determination that the artifact and another artifact do not belong to the same build plugin where the plugin is used to deploy the artifact at runtime of the application and permitting deployment of the artifact and another artifact based on a determination that the artifact and another artifact belong to the same plugin.

In some implementations the method can include generating a dependency graph for the plurality of the artifacts based on the plurality of required objects where the execution order is generated based on the generated dependency graph.

In some implementations the deployment can include initially deploying based on the generated execution order the plurality of artifacts modifying an artifact in the plurality of artifacts generating a modified execution order where the modified execution order specifies deployment of the modified artifact and deploying the plurality of artifacts including the modified artifact based on the modified execution order. The method can also include determining another artifact in the plurality of artifacts being dependent on the artifact and redeploying another artifact as a result of the modification of the artifact. The method can further include determining another artifact in the plurality of artifacts being dependent on the artifact and undeploying another artifact prior to deploying the modified artifact deploying the modified artifact and redeploying another artifact after deploying the modified artifact.

In some implementations the dependency can include at least one of the following the artifact being dependent on at least another artifact in the plurality of artifacts and the artifact being independent of any artifact in the plurality of artifacts.

The systems and methods disclosed herein can be embodied in various forms including for example a data processor such as a computer that also includes a database digital electronic circuitry firmware software or in combinations of them. Moreover the above noted features and other aspects and principles of the present disclosed implementations can be implemented in various environments. Such environments and related applications can be specially constructed for performing the various processes and operations according to the disclosed implementations or they can include a general purpose computer or computing platform selectively activated or reconfigured by code to provide the necessary functionality. The processes disclosed herein are not inherently related to any particular computer network architecture environment or other apparatus and can be implemented by a suitable combination of hardware software and or firmware. For example various general purpose machines can be used with programs written in accordance with teachings of the disclosed implementations or it can be more convenient to construct a specialized apparatus or system to perform the required methods and techniques.

The systems and methods disclosed herein can be implemented as a computer program product i.e. a computer program tangibly embodied in an information carrier e.g. in a machine readable storage device or in a propagated signal for execution by or to control the operation of data processing apparatus e.g. a programmable processor a computer or multiple computers. A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.

Although ordinal numbers such as first second and the like can in some situations relate to an order as used in this document ordinal numbers do not necessarily imply an order. For example ordinal numbers can be merely used to distinguish one item from another. For example to distinguish a first event from a second event but need not imply any chronological ordering or a fixed reference system such that a first event in one paragraph of the description can be different from a first event in another paragraph of the description .

The foregoing description is intended to illustrate but not to limit the scope of the invention which is defined by the scope of the appended claims. Other implementations are within the scope of the following claims.

These computer programs which can also be referred to programs software software applications applications components or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the term machine readable medium refers to any computer program product apparatus and or device such as for example magnetic discs optical disks memory and Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor. The machine readable medium can store such machine instructions non transitorily such as for example as would a non transient solid state memory or a magnetic hard drive or any equivalent storage medium. The machine readable medium can alternatively or additionally store such machine instructions in a transient manner such as for example as would a processor cache or other random access memory associated with one or more physical processor cores.

To provide for interaction with a user the subject matter described herein can be implemented on a computer having a display device such as for example a cathode ray tube CRT or a liquid crystal display LCD monitor for displaying information to the user and a keyboard and a pointing device such as for example a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well. For example feedback provided to the user can be any form of sensory feedback such as for example visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including but not limited to acoustic speech or tactile input.

The subject matter described herein can be implemented in a computing system that includes a back end component such as for example one or more data servers or that includes a middleware component such as for example one or more application servers or that includes a front end component such as for example one or more client computers having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described herein or any combination of such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication such as for example a communication network. Examples of communication networks include but are not limited to a local area network LAN a wide area network WAN and the Internet.

The computing system can include clients and servers. A client and server are generally but not exclusively remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

The implementations set forth in the foregoing description do not represent all implementations consistent with the subject matter described herein. Instead they are merely some examples consistent with aspects related to the described subject matter. Although a few variations have been described in detail above other modifications or additions are possible. In particular further features and or variations can be provided in addition to those set forth herein. For example the implementations described above can be directed to various combinations and sub combinations of the disclosed features and or combinations and sub combinations of several further features disclosed above. In addition the logic flows depicted in the accompanying figures and or described herein do not necessarily require the particular order shown or sequential order to achieve desirable results. Other implementations can be within the scope of the following claims.

