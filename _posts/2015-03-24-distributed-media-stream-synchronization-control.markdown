---

title: Distributed media stream synchronization control
abstract: One or more system, apparatus, method, and computer readable media is described below for wireless display synchronization of audio and video data streams received through a direct wireless link between a content source and sink. In some embodiments, the presentation time stamp (PTS) associated with the encoding of a digital audio and digital video data stream into a compressed packetized data stream at the source is utilized as a control point for synchronization of the digital audio and video stream payloads presented at the sink. In some embodiments, one or more wireless display-synchronized PTS values are determined based on a feedback signal indicative of display synchronization error. A source including an optical camera may generate audio/video (A/V) streams that encoded and packetized by a multiplexer with wireless display-synchronized PTS values. In further embodiments, a media sync user input interface is provided at one or more of the source and sink.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09532099&OS=09532099&RS=09532099
owner: Intel Corporation
number: 09532099
owner_city: Santa Clara
owner_country: US
publication_date: 20150324
---
With the increase in mobile devices and the prevalence of wireless networking wireless display capability is experiencing rapid growth. In wireless display technology a wireless link between a source device and sink display device replaces the typical data cable between computer and monitor. Wireless display protocols are typically peer to peer or direct and most usage models have a mobile device transmitting media content to be received and displayed by one or more external monitors. In a typical screencasting application for example a smartphone may be wirelessly coupled to one or more external monitors display panels televisions projectors etc.

Wireless display specifications e.g. WiDi v3.5 by Intel Corporation and Wi Fi Display v1.0 or WFD from the Miracast program of the Wi Fi Alliance have been developed for the transmission of compressed video data and audio data streams over wireless local area networks of sufficient bandwidth. For example current wireless display technologies utilizing WiFi technology e.g. 2.4 GHz and 5 GHz radio bands are capable of streaming encoded full HD video data as well as high fidelity audio data e.g. 5.1 surround .

For both wireless and wired transmission of media content the timing of the rendered video signal may deviate from the timing of the rendered audio signal as the video and audio data are decoded and rendered by a receiving display sink device. This timing difference or mismatch is commonly known as lip sync error because the error is most readily apparent to the wireless display user when the content represents a person speaking. Lip sync error may be quantified as amount of time audio departs from perfect synchronization with the video where a positive time number indicates the audio leads the video and a negative number indicates the audio lags the video. Lip sync error may vary over time occurring for example when an A V stream is corrupted during transmission. Lip sync error of between 50 millisecond and a few seconds are not uncommon.

Certain wired media content receivers for example complying with a High Definition Media Interface HDMI standard e.g. 2.0 released on Sep. 4 2013 include a Lip Sync function by which audio processing time may be adjusted automatically to remove errors in audio video timing. To date however wireless display technology lacks the capability to sufficiently address lip sync issues.

One or more embodiments are described with reference to the enclosed figures. While specific configurations and arrangements are depicted and discussed in detail it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements are possible without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may be employed in a variety of other systems and applications beyond what is described in detail herein.

Reference is made in the following detailed description to the accompanying drawings which form a part hereof and illustrate exemplary embodiments. Further it is to be understood that other embodiments may be utilized and structural and or logical changes may be made without departing from the scope of claimed subject matter. Therefore the following detailed description is not to be taken in a limiting sense and the scope of claimed subject matter is defined solely by the appended claims and their equivalents.

In the following description numerous details are set forth however it will be apparent to one skilled in the art that embodiments may be practiced without these specific details. Well known methods and devices are shown in block diagram form rather than in detail to avoid obscuring more significant aspects. References throughout this specification to an embodiment or one embodiment mean that a particular feature structure function or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrase in an embodiment or in one embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures functions or characteristics described in the context of an embodiment may be combined in any suitable manner in one or more embodiments. For example a first embodiment may be combined with a second embodiment anywhere the particular features structures functions or characteristics associated with the two embodiments are not mutually exclusive.

As used in the description of the exemplary embodiments and in the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items.

As used throughout the description and in the claims a list of items joined by the term at least one of or one or more of can mean any combination of the listed terms. For example the phrase at least one of A B or C can mean A B C A and B A and C B and C or A B and C.

The terms coupled and connected along with their derivatives may be used herein to describe functional or structural relationships between components. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical optical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical optical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause an effect relationship .

Some portions of the detailed descriptions provide herein are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as calculating computing determining estimating storing collecting displaying receiving consolidating generating updating or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s circuitry including registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

While the following description sets forth embodiments that may be manifested in architectures such system on a chip SoC architectures for example implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. Various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smartphones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. Furthermore some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

Certain portions of the material disclosed herein may be implemented in hardware for example as logic circuitry in an image processor. Certain other portions may be implemented in hardware firmware software or any combination thereof. At least some of the material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors graphics processors and or central processors . A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other similarly non transitory tangible media.

Exemplary systems methods and computer readable media are described below for wireless display synchronization sync of audio and video data streams received through a direct wireless link between a content source and sink. In some embodiments the presentation time stamp PTS associated with the encoding of a digital audio and digital video data stream into a compressed packetized data stream at the source is utilized as a control point for synchronization of the digital audio and video stream payloads presented at the sink. With the presentation time synchronization control effort exerted at the source device a receiving device need only be compliant with standardized codecs enabling a display to be dumb with respect to presentation synchronization adjustment algorithms.

In some embodiments one or more feedback signals indicative of display sync error are received and mapped to one or more PTS adjustment values which are applied to one or more reference PTS values to arrive at one or more wireless display synchronized PTS values. In some embodiments a source including an optical camera generates audio video A V streams that are input to an encoder that compresses the A V streams. A multiplexer packetizes the compressed A V streams into a container including wireless display synchronized PTS values. In further embodiments a media synchronization user input interface is provided at one or more of the source and sink through which a feedback signal indicative of display sync error for a given transmission may be received.

A V source device further includes multiplexer to multiplex the coded elementary streams into a higher level packetized stream that further includes a metadata field specifying a presentation synchronization of the elementary stream packets. In some embodiments multiplexer codes the packetized elementary streams into an MPEG program stream MPS or more advantageously into an MPEG transport stream MTS . A presentation timestamp PTS may be assigned in the PES packet layer and utilized by a receiving device to set the presentation time of a given video slice and audio slice. In further embodiments the MTS is encapsulated following one or more of Real Time Protocol RTP user datagram Protocol UDP and Internet Protocol IP as embodiments are not limited in this context. In some RTP embodiments for example a Network Abstraction Layer NAL encoder not depicted receives the MTS and generates Network Abstraction Layer Units NAL units that are suitable for wireless transmission. While exemplary embodiments described in detail herein make reference to PTS metadata fields of a different name but nonetheless utilized to set the presentation time may be similarly utilized. For example where an RTP payload is a PES rather than a MTS the RTP timestamp may serve to set the presentation time of a given video frame.

In the exemplary embodiments an A V source device further includes a wireless transmitter Tx coupled to receive the coded stream data and output a wireless signal representative of the coded stream data directly to a sink device. In the exemplary embodiment illustrated in A V source device includes a wireless transceiver Tx Rx coupled to an output of multiplexer . Wireless transceiver may utilize any band known to be suitable for the purpose of directly conveying e.g. peer to peer the stream data for real time presentation on a sink device. In some embodiments wireless transceiver is operable in the 2.4 GHz and or 5 GHz band e.g. Wi Fi 802.11n . In some embodiments wireless transceiver is operable in the 60 GHz band. Wireless transceiver may further support and or comply with one or more High Definition Media Interface HDMI protocol such as but not limited to Wireless Home Digital Interface WHDI Wireless Display WiDi Wi Fi Direct Miracast WirelessHD or Wireless Gigabit Alliance WiGig certification programs.

As further illustrated in A V display device is communicatively coupled to A V source device through wireless transceiver during a wireless streaming session. Wireless transceiver may utilize any frequency band and wireless communication protocol compatible with that of transceiver . An output from wireless transceiver is coupled to an input of de multiplexer which is to process the encapsulated packetized streams into compressed data inputs passed to audio decoder and video decoder . De multiplexer includes logic to unencapsulate and extract audio and video payloads from the packetized A V stream. In exemplary embodiments de multiplexer includes logic to de multiplex the packet payloads based at least in part on the metadata field specifying the presentation synchronization of the elementary stream packets e.g. PTS . Decoders may utilize any codec compatible with that of encoders to generate representations of digital audio data and digital video data that are input to audio rendering pipeline and video rendering pipeline respectively. Audio rendering pipeline terminates at one or more audio speaker while video rendering pipeline terminates at one or more display screen . Any known audio and image processing may be employed within pipelines as embodiments are not limited in this context.

End to end synchronization for system occurs when presentation timestamps at the output of encoders propagate to decoders and when decoders use those time stamps to schedule presentations by A V display device . A V source device includes a control point for synchronization of the digital audio and video streams presented at display device . In some embodiments control point utilizes the metadata field specifying presentation synchronization e.g. PTS . This field is to be modified from a native or reference value determined in the absence of any control effort applied at control point . The PTS is to be determined or adjusted at A V source device as a function of a wireless display synchronization control signal indicative of an A V presentation synchronization error perceived or determined based on output of A V display device . The PTS assigned to packets in accordance with some embodiments herein may be referred to as presentation feedback synchronized or display synchronized because the relative presentation time at the source device is adjusted to counter a PTS sync offset value perceived in real time at the display device. As described further below the wireless display synchronization control signal may originate from any of a user interaction with A V source device a user interaction with A V display device that is relayed back to A V source device or an automated A V synchronization error determination at A V display device .

System may be implemented with various network topologies and use models. In some embodiments for example a source includes a video camera e.g. a camera communication or CamCom platform . Packetization of the audio and video streams output by a camera module are based at least in part on the feedback signal indicative of an A V presentation synchronization error perceived on a directly coupled A V display device. is a schematic depicting a wireless CamCom display system which could be deployed in surveillance or virtual video conferencing applications for example. In system video capture platform records video of a subject e.g. the user of the video capture platform . Recorded video is wirelessly transmitted to video display which may be located in a conference room proximal to an office of the user of video capture platform for example. In other embodiments a wireless display source device transcodes an A V stream received from an upstream content source. With this topology the source device is to packetize the re coded audio and video streams based at least in part on a feedback signal indicative of an A V presentation synchronization error perceived or determined at a paired A V display device. is a schematic depicting one example where a wireless relayed video display system is deployed in a content mirroring application. In system video relay platform transcodes received video content into a format compatible with wireless transmission to video display such as a large format display within the field of view of a user of platform .

Referring further to video capture platform includes wireless display synchronization control in accordance with some embodiments. In video capture platform the presentation time for audio and or video packets is adjusted based on a known A V sync loss. An audio capture pipeline including for example a microphone is coupled to an input of audio encoder . An input of video encoder A is coupled to an output of video capture pipeline which may include any known image sensor outputting time sequential frames of image data at some predetermined frame rate. Encoders output coded bit streams for packetization. A native presentation time stamp value is determined at a packetization level using any known techniques. A presentation timestamp adjustment module receives an A V synchronization signal indicative of a presentation time synchronization error perceived or determined at A V display .

As further illustrated in in some embodiments a PTS adjustment module is to receive a native PTS value and a PTS synchronization offset value as inputs. A feedback synchronized PTS value is output. In some embodiments a PTS adjustment module may for example add PTS sync offset to a native PTS value associated with one or more payload of a packetized elementary stream. In some embodiments a wireless display synchronized PTS value is associated with packets of at least one of an encoded video elementary stream and an encoded audio elementary stream. is a schematic illustrating a digital audio and video content packet structure in accordance with some embodiments. In the illustrated embodiment native PTS value is associated with one or more packets of H.264 encoded video data stream representing one video frame while the wireless display synchronized PTS value is associated with one or more packets of LPCM audio stream corresponding to the video frame encoded into stream . Payloads of the packetized elementary streams are combined into payloads associated with one or more program clock reference PCR to encode the timing of the transport stream . The transport stream packets are further encapsulated in one or more packets of RTP stream as payloads associated with corresponding RTP timestamps . In alternative embodiments native PTS value is instead associated with one or more packets of LPCM audio stream while the wireless display synchronized PTS value is associated with one or more packets of H.264 encoded video data stream representing one video frame. In further embodiments the encoded video or audio packets are to be delayed by PTS sync offset as a function of perceived audio lag or lead respectively in the audio presentation relative to the video presentation. For example encoded video packets may be delayed by PTS sync offset in response to a sync error signal indicative of audio lag at a display device while encoded audio packets may be delayed by PTS sync offset in response to a sync error signal indicative of audio lead at a display device.

In some embodiments an A V sync offset value is determined with user input received through a user interface UI . The user interface is to receive user input in real time during presentation of content received from the source device. A PTS offset value is derived from the user input map for example by a mapping table or function. The UI for an A V sync adjustment may take any number of forms such as but not limited to an increment decrement button control. is schematic illustrating a mapping between an exemplary synchronization user input and presentation time stamp offset in accordance with some embodiments. The A V sync UI includes an audio sync control and an audio sync control . A sync mapping database maps levels audio lead and audio lag to a PTS modification that may be associated with either the video or data presentation. Entries in the sync mapping database may be traversed as a function of user activation of controls . In some embodiments each entry in the sync mapping database associates an audio lag level with a predetermined PTS sync offset e.g. 0.25 msec 50 msec etc. . Upon an initialization of a content transmission session e.g. a WFD session the PTS sync offset is set to a default value of 0 resulting in an operative state in which there is no PTS modification. Upon receiving a user input indicative of a perceived audio lag the session continues in an operative state where the mapped PTS sync offset is applied to delay the video presentation. Upon receiving a user input indicative of a perceived audio lead the session continues in an operative state where the mapped PTS sync offset is applied to delay the audio presentation.

In some embodiments the source device and or the display device implements an A V sync UI. Returning for example video capture platform may include an A V sync UI . In A V sync UI is denoted with dashed lines to emphasize an A V sync signal may alternatively be generated as a function of user input through A V sync UI implemented by display . In first embodiments A V sync UI is coupled to PTS adjust module . PTS sync offsets determined in response to user inputs received in real time with content transmission are output to PTS adjust module . In alternative embodiments where a user input is received through A V sync UI a PTS sync offset or any signal indicative thereof is transmitted back to video capture platform . In one such embodiment a back channel maintained during the content streaming session is employed to communicate the PTS sync offset from display to video capture platform . In one WiD compatible embodiment a PTS sync offset is communicated over the User Input Back Channel UIBC maintained between video capture platform functioning as a WFD Source and the video display functioning as the WFD Sink . Under the WiD specification 1.0 the UIBC is available to send control and data information originating with user input at the WFD sink.

In alternative embodiments an A V sync offset value is determined automatically at video display based on inputs received from audio render pipeline and or video render pipeline . For such embodiments automated A V sync module may implement any known algorithm for detecting and or quantifying an A V sync error as embodiments are not limited in this respect.

Raw data output by CM and or pre processed video data output by ISP may be further processed into a compressed form by A V encoder . In some embodiments A V encoder further includes audio encoder and video encoder described elsewhere herein. In embodiments A V encoder includes logic to perform the encoding and packetization operations and algorithms described elsewhere herein. In further embodiments PTS adjustment module includes logic to perform one or more modification to presentation timestamps assigned to packets of encoded audio or video. In some embodiments A V encoder and PTS adjustment module may be configured through software instruction s .

PTS modifications based on a feedback signal indicative of a sync error perceived at a wireless display may be implemented through either software or hardware or with a combination of both software and hardware. For pure hardware implementations A V encoder and or PTS adjustment module may be implemented by fixed function logic for example provided in ISP . For software implementations any known programmable processor such as a core of processor or an execution unit of a graphics processor may be utilized to implement the logic of A V encoder and or PTS adjustment module . In the illustrated embodiment A V encoder PTS adjustment module and multiplexer are implemented in software instantiated in a user or kernel space of processor . Alternatively an ISP having fixed or semi programmable logic circuitry may implement one or more of the A V encoder PTS adjustment module or multiplexer .

In some embodiments processor includes one or more programmable logic circuits to perform one or more stages of a method for modifying a presentation time of audio and or video streamed over a real time wireless protocol such as but not limited to WFD or WiDi. For example processor may perform method in accordance with some embodiments described above. In some embodiments processor is to access PTS sync error database stored in main memory and is to determine a PTS modification e.g. PTS offset value based on a presentation time synchronization error signal. Processor may be solely responsible for modifying PTS values to synchronize input image data collected by CM or output from ISP . In one exemplary embodiment A V encoder and or PTS adjustment module and or MUX and or A V sync UI are invoked through the user space of a software stack instantiated by processor . In some embodiments processor executes one or more video encoding and or packetization algorithm in a kernel space of the instantiated software stack. In some embodiments processor employs a graphics processor driver included in subsystem drivers to cause one or more video encoding algorithm to be executed by a graphic processor not depicted . In some embodiments processor is programmed with instructions stored on a computer readable media to cause the processor to perform one or more modification to a presentation time of audio and or video streamed over a real time wireless protocol.

As further illustrated in output A V data streams may be output a wireless transceiver pipeline . In one exemplary embodiment output A V stream data is buffered by writing the stream data to electronic memory e.g. DDR etc. . Memory may be separate or a part of a main memory . Wireless transmission pipeline includes a wireless transceiver for example substantially as described elsewhere herein to convey e.g. with a real time protocol the output A V data stream to receiving display .

An embodiment of data processing system can include or be incorporated within a server based gaming platform a game console including a game and media console a mobile gaming console a handheld game console or an online game console. In some embodiments data processing system is a mobile phone smart phone tablet computing device or mobile Internet device. Data processing system can also include couple with or be integrated within a wearable device such as a smart watch wearable device smart eyewear device augmented reality device or virtual reality device. In some embodiments data processing system is a television or set top box device having one or more processors and a graphical interface generated by one or more graphics processors .

In some embodiments the one or more processors each include one or more processor cores to process instructions which when executed perform operations for system and user software. In some embodiments each of the one or more processor cores is configured to process a specific instruction set . In some embodiments instruction set may facilitate Complex Instruction Set Computing CISC Reduced Instruction Set Computing RISC or computing via a Very Long Instruction Word VLIW . Multiple processor cores may each process a different instruction set which may include instructions to facilitate the emulation of other instruction sets. Processor core may also include other processing devices such a Digital Signal Processor DSP .

In some embodiments the processor includes cache memory . Depending on the architecture the processor can have a single internal cache or multiple levels of internal cache. In some embodiments the cache memory is shared among various components of the processor . In some embodiments the processor also uses an external cache e.g. a Level 3 L3 cache or Last Level Cache LLC not shown which may be shared among processor cores using known cache coherency techniques. A register file is additionally included in processor which may include different types of registers for storing different types of data e.g. integer registers floating point registers status registers and an instruction pointer register . Some registers may be general purpose registers while other registers may be specific to the design of the processor .

In some embodiments processor is coupled to a processor bus to transmit data signals between processor and other components in system . System has a hub system architecture including a memory controller hub and an input output I O controller hub . Memory controller hub facilitates communication between a memory device and other components of system while I O Controller Hub ICH provides connections to I O devices via a local I O bus.

Memory device can be a dynamic random access memory DRAM device a static random access memory SRAM device flash memory device or some other memory device having suitable performance to serve as process memory. Memory can store data and instructions for use when processor executes a process. Memory controller hub also couples with an optional external graphics processor which may communicate with the one or more graphics processors in processors to perform graphics and media operations.

In some embodiments ICH enables peripherals to connect to memory and processor via a high speed I O bus. The I O peripherals include an audio controller a firmware interface a wireless transceiver e.g. Wi Fi Bluetooth a data storage device e.g. hard disk drive flash memory etc. and a legacy I O controller for coupling legacy e.g. Personal System 2 PS 2 devices to the system. One or more Universal Serial Bus USB controllers connect input devices such as keyboard and mouse combinations. A network controller may also couple to ICH . In some embodiments a high performance network controller not shown couples to processor bus .

System includes a device platform that may implement all or a subset of the recoded video encoding packetization and wireless transmission methods described above in the context of . In various exemplary embodiments processor executes PTS adjustments for example as described elsewhere herein. Processor includes logic circuitry implementing PTS adjustment module for example as described elsewhere herein. In some embodiments one or more computer readable media may store instructions which when executed by CPU and or video processor cause the processor s to execute one or more of the image data encoding and or presentation timestamp modification operations described elsewhere herein. One or more image data frames output by CM may then be transmitted by radio in association with a wireless display synchronized PTS.

In embodiments device platform is coupled to a human interface device HID that may further include a user interface . Platform may collect raw image data with CM which is processed and output to HID . A navigation controller including one or more navigation features may be used to interact with for example device platform and or HID . In embodiments HID may include any monitor or display coupled to platform via radio and or network . HID may include for example a computer display screen touch screen display video monitor television like device and or a television.

In embodiments device platform may include any combination of CM chipset processors memory storage applications and or radio . Chipset may provide intercommunication among processors memory video processor applications or radio .

One or more of processors may be implemented as one or more Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU .

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM . Memory may also be implemented as a non volatile storage device such as but not limited to flash memory battery backed up SDRAM synchronous DRAM magnetic memory phase change memory and the like.

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card MC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

As described above system may be embodied in varying physical styles or form factors. further illustrates embodiments of a mobile handset device in which platform and or system may be embodied. In embodiments for example device may be implemented as a mobile computing handset device having wireless capabilities. As shown in mobile handset device may include a housing with a front and back . Device includes a display an input output I O device and an integrated antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown or may be digitized by a voice recognition device. Embodiments are not limited in this context. Integrated into at least the back is a camera module e.g. including one or more lens aperture and imaging sensor through which image data is sampled and output to a hidden image data decoder for example as described elsewhere herein.

As exemplified above embodiments described herein may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements or modules include processors microprocessors circuitry circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software elements or modules include applications computer programs application programs system programs machine programs operating system software middleware firmware routines subroutines functions methods procedures software interfaces application programming interfaces API instruction sets computing code computer code code segments computer code segments data words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors considered for the choice of design such as but not limited to desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

The wireless display synchronization control and PTS modification methods comporting with exemplary embodiments described herein may be implemented in various hardware architectures cell designs or IP cores. 

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable storage medium. Such instructions may reside completely or at least partially within a main memory and or within a processor during execution thereof by the machine the main memory and the processor portions storing the instructions then also constituting a machine readable storage media. Programmable logic circuitry may have registers state machines etc. configured by the processor implementing the computer readable media. Such logic circuitry as programmed may then be understood as physically transformed into a system falling within the scope of at least some embodiments described herein. Instructions representing various logic within the processor which when read by a machine may also cause the machine to fabricate logic adhering to the architectures described herein and or to perform the techniques described herein. Such representations known as cell designs or IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to embodiments this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to be within the spirit and scope of the present disclosure.

In first embodiments a video source apparatus comprises a stream multiplexer to assign a presentation timestamp PTS to one or more first packets of encoded video data and to one or more first packets of encoded audio data. The source apparatus further comprises a wireless transmitter coupled to an output of the multiplexer to wirelessly stream the first packets to a paired display device. The source apparatus further comprises a PTS adjustment module coupled to an input of the multiplexer to trigger a PTS modification for one or more second packets of the encoded video and audio data that is responsive to an audio video A V presentation synchronization error perceived or determined based on an A V output of the display device rendered from the first packets.

In furtherance of the first embodiments the PTS adjustment module is to receive a synchronization error signal indicative of the A V presentation synchronization error and is further to determine based on the sync error signal the PTS modification that counters the A V presentation synchronization error.

In furtherance of the embodiment immediately above the PTS adjustment module is to map the synchronization error signal to a predetermined PTS offset value is to generate a modified PTS value by adding the predetermined PTS offset value to a reference PTS value. The multiplexer is to assign the modified PTS value to one or more of the second packets of the encoded video and audio data.

In furtherance of the first embodiments the multiplexer is to assign a modified PTS including a PTS offset value to delay presentation of second packets of the encoded video in response to an A V presentation synchronization error indicative of a lag in audio output relative to video output rendered based on the first packets.

In furtherance of the first embodiments the apparatus further comprises a sync error user interface to receive a user input indicative of the A V presentation synchronization error. The PTS adjustment module is to map the user input to a predetermined PTS offset value and is to generate a modified PTS value by adding the predetermined PTS offset value to a reference PTS value. The multiplexer is to assign a modified PTS including a PTS offset value that is to delay presentation of second packets of the encoded video in response to an A V presentation synchronization error indicative of a lag in audio output relative to video output rendered based on the first packets. The multiplexer is to assign a modified PTS including a PTS offset value that is to delay presentation of second packets of the encoded audio in response to an A V presentation synchronization error indicative of a lead in audio output relative to video output rendered based on the first packets.

In furtherance of the first embodiments the apparatus further comprises a camera module to generate digital video and audio data as well as a video encoder and audio encoder coupled between an output of the camera module and an input of the multiplexer the encoders to generate the encoded video and audio data.

In furtherance of the first embodiments the apparatus further comprises a video encoder and audio encoder coupled to an input of the multiplexer the encoders to generate the encoded video and audio data. The apparatus further comprises an A V decoder coupled to an input of the video and audio encoders wherein the A V decoder video encoder and audio encoder comprise a transcoder to receive a first encoded A V stream and output second encoded audio and video bit streams.

In one or more second embodiments a wireless display system includes the video source apparatus of the first embodiments and a display device to communicate the A V presentation synchronization error over a back channel maintained between the A V source device and the display device.

In furtherance of the second embodiments immediately above the display apparatus further comprises a synchronization error user interface to receive a user input indicative of the A V presentation synchronization error.

In one or more third embodiments a wireless video display comprises a wireless receiver to receive a stream of first packets from a paired source device. The display further comprises a de multiplexer coupled to an output of the wireless receiver and to de multiplex a compressed audio data payload from a compressed video data payload based at least in part on one or more presentation timestamp PTS associated with the first packets. The display further comprises an audio decoder and video decoder coupled to an output of the de multiplexer the decoders to generate digital audio and video data. The display further comprises an audio rendering pipeline and video rendering pipeline coupled to the decoders to output an A V representation of the digital audio and video data. The display further comprises a sync error user interface to receive a user input indicative of a synchronization error in the A V presentation. The display further comprises a wireless transmitter to communicate an indication of the A V presentation synchronization error to the paired source device.

In furtherance of the third embodiments the wireless transmitter is to send the indication of the A V presentation error over a back channel maintained with the paired source device.

In one or more fourth embodiments a method for controlling synchronization of audio video A V presentation by a wireless display comprises assigning a presentation timestamp PTS to one or more first packets of encoded video data and to one or more first packets of encoded audio data. The method further comprises wirelessly streaming the first packets to a paired display device. The method further comprises assigning a display synchronized PTS to one or more second packets of the encoded video and audio data that is responsive to an audio video A V presentation synchronization error perceived or determined based on an A V output of the display device rendered from the first packets. The method further comprises wirelessly streaming the second packets to the paired display device.

In furtherance of the fourth embodiments the method further comprises receiving a sync error signal indicative of the A V presentation synchronization error. The method further comprises determining based on the sync error signal the display synchronized PTS that counters the A V presentation synchronization error.

In furtherance of the embodiments immediately above determining the display synchronized PTS further comprises mapping the sync error signal to a predetermined PTS offset value generating a modified PTS value by adding the predetermined PTS offset value to a reference PTS value and assigning the modified PTS value to one or more of the second packets of the encoded video and audio data.

In furtherance of the fourth embodiment the method further comprises assigning a display synchronized PTS further comprises assigning a modified PTS including a PTS offset value that delays presentation of second packets of the encoded video in response to an A V presentation synchronization error indicative of a lag in audio output relative to video output rendered based on the first packets. In the alternative or additionally the method further comprises assigning a modified PTS including a PTS offset value that delays presentation of second packets of the encoded audio in response to an A V presentation synchronization error indicative of a lead in audio output relative to video output rendered based on the first packets.

In furtherance of the fourth embodiment the method further comprises presenting a synchronization error user interface. The method further comprises receiving through the synchronization error user interface a user input indicative of the A V presentation synchronization error. The method further comprises mapping the user input to a predetermined PTS offset value generating a modified PTS by adding the predetermined PTS offset value to a reference PTS and assigning the modified PTS to delay presentation of second packets of the encoded video in response to an A V presentation synchronization error indicative of a lag in audio output relative to video output rendered based on the first packets or to delay presentation of second packets of the encoded audio in response to an A V presentation synchronization error indicative of a lead in audio output relative to video output rendered based on the first packets.

In furtherance of the fourth embodiment the method further comprises generating the digital video and digital audio data with a camera module including an image sensor and encoding the digital video and digital audio data into a compressed format.

In furtherance of the fourth embodiment the method further comprises communicating the A V presentation synchronization error over a back channel maintained between the A V source device and the display device.

In one or more fifth embodiments an apparatus comprises a means to perform any one of the fourth embodiments.

In one or more sixth embodiments one or more computer readable media includes instruction stored thereon which when executed by a processing system cause the system to perform any one of the fourth embodiments.

In one or more seventh embodiments one or more computer readable media including instruction stored thereon which when executed by a processing system cause the system to perform a method comprising assigning a presentation timestamp PTS to one or more first packets of encoded video data and to one or more first packets of encoded audio data wirelessly streaming the first packets to a paired display device assigning a display synchronized PTS to one or more second packets of the encoded video and audio data that is responsive to an audio video A V presentation synchronization error perceived or determined based on an A V output of the display device rendered from the first packets and wirelessly streaming the second packets to the paired display device.

In furtherance of the seventh embodiments the one or more media further includes instructions stored thereon which when executed by the processing system cause the system to perform a method comprising assigning a modified PTS including a PTS offset value that delays presentation of second packets of the encoded video in response to an audio video A V presentation synchronization error indicative of a lag in audio output relative to video output rendered based on the first packets and assigning a modified PTS including a PTS offset value that delays presentation of second packets of the encoded audio in response to an audio video A V presentation synchronization error indicative of a lead in audio output relative to video output rendered based on the first packets.

In one or more eighth embodiment a method for controlling synchronization of audio video A V presentation by a wireless display comprises assigning a presentation timestamp PTS to one or more first packets of encoded video data and to one or more first packets of encoded audio data. The method further comprises wirelessly streaming the first packets to a paired display device. The method further comprises assigning a display synchronized PTS to one or more second packets of the encoded video and audio data that is responsive to an audio video A V presentation synchronization error perceived or determined based on an A V output of the display device rendered from the first packets. The method further comprises wirelessly streaming the second packets to the paired display device.

In one or more ninth embodiment a method for controlling synchronization of audio video A V presentation by a wireless display comprises wirelessly receiving a stream of first packets from a paired source device. The method further comprises de multiplexing a compressed audio data payload from a compressed video data payload based at least in part on one or more presentation timestamp PTS associated the first packets. The method further comprises decoding the compressed audio and video data payloads in digital audio and video data. The method further comprises rendering an A V representation of the digital audio and video data. The method further comprises receiving a user input indicative of a synchronization error in the A V presentation. The method further comprises wirelessly transmitting an indication of the A V presentation synchronization error to the paired source device.

In furtherance of the ninth embodiments immediately above wirelessly transmitting the indication further comprises sending the indication of the A V presentation error over a back channel maintained with the paired source device.

In one or more tenth embodiment one or more computer readable media including instruction stored thereon which when executed by a processing system cause the system to perform any one of the ninth embodiments.

In one or more eleventh embodiment an apparatus includes a means to perform any one of the ninth embodiments.

It will be recognized that the embodiments are not limited to the exemplary embodiments so described but can be practiced with modification and alteration without departing from the scope of the appended claims. For example the above embodiments may include specific combination of features. However the above embodiments are not limited in this regard and in embodiments the above embodiments may include undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. Scope should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

