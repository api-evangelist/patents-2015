---

title: 2D animation from a 3D mesh
abstract: Two-dimensional (2D) animation may be generated from a three-dimensional (3D) mesh by a machine or device that flattens, textures, and modifies the 3D mesh, which results in distorting the texture of the 3D mesh. The machine or device is configured to access and flatten a 3D mesh of 3D vertices. At least some of the 3D vertices of the flattened 3D mesh are texture mapped with a 2D image. The machine or device generates a first 2D frame of animation by rendering the 3D mesh (e.g., with graphics acceleration hardware), modifies the 3D mesh by repositioning one or more of the 3D vertices, and generates a second 2D frame of animation by rendering the modified 3D mesh (e.g., with graphics acceleration hardware). Accordingly, 2D animation may be generated by distorting the 2D image that is mapped onto at least part of the 3D mesh.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09652880&OS=09652880&RS=09652880
owner: Zynga Inc.
number: 09652880
owner_city: San Francisco
owner_country: US
publication_date: 20150213
---
This application is a continuation of U.S. patent application Ser. No. 13 399 520 filed on Feb. 17 2012 which claims the priority benefit of U.S. Provisional Patent Application No. 61 544 420 filed Oct. 7 2011 the benefit of priority of each of which is claimed hereby and each of which are incorporated by reference herein in its entirety.

The subject matter disclosed herein generally relates to the processing of data. Specifically the present disclosure addresses systems and methods that generate two dimensional 2D animation from a three dimensional 3D mesh.

Contemporary machines and devices may be configured to present graphics on a display e.g. a screen . To facilitate presentation of graphics one or more graphics accelerators may be included in a machine or device. A graphics accelerator may be implemented in hardware that is permanently or temporarily configured e.g. by circuitry firmware software or any suitable combination thereof to render graphical data for presentation on the display. For example graphics acceleration hardware may take the form of a dedicated graphics accelerator card a graphics accelerator board a graphics accelerator chip or other graphics acceleration circuitry. As another example graphics acceleration hardware may take the form of a multi purpose processor that is temporarily or permanently configured to function as a graphics accelerator. Graphics acceleration hardware may support a graphics library e.g. OpenGL that provides an application programming interface API for using one or more features of the graphics acceleration hardware.

As used herein 2D means two dimensional and 3D means three dimensional. For example a 2D vector has two dimensions e.g. a length dimension and a width dimension and a 3D vector has three dimensions e.g. a length dimension a width dimension and a depth dimension . A graphics accelerator may support 2D graphics 3D graphics or both.

Example methods and systems are directed to generating 2D animation from a 3D mesh. Examples merely typify possible variations. Unless explicitly stated otherwise components and functions are optional and may be combined or subdivided and operations may vary in sequence or be combined or subdivided. In the following description for purposes of explanation numerous specific details are set forth to provide a thorough understanding of example embodiments. It will be evident to one skilled in the art however that the present subject matter may be practiced without these specific details.

Generation of 2D animation may be less computationally intensive than generation of 3D animation. At the same time it may be helpful to utilize a graphics accelerator e.g. graphics acceleration hardware present in a machine or device in generating 2D animation. In some situations however the graphics accelerator of a machine or device is configured e.g. optimized to support 3D graphics e.g. rendering 3D objects defined by 3D meshes . Example systems and methodologies described herein may facilitate generation of 2D animation from a 3D mesh and such generation of 2D animation may be performed using a 3D graphics accelerator.

According to various example embodiments the 3D mesh models a 3D object e.g. an airplane an animal or a house . In some example embodiments the 3D mesh models a portion of a 3D object e.g. a wing of an airplane a leg of an animal or a front door of a house .

As shown the flattened 3D mesh is a mesh of 3D vertices e.g. 3D vertices and . In some example embodiments each of the 3D vertices as generated had individual depth values e.g. z values and these individual depth values were ignored assigned to a single e.g. uniform depth value or both during a flattening operation. In other words the 3D vertices and may have been generated with the depth values that varied from one 3D vertex e.g. 3D vertex to another e.g. 3D vertex . However after the flattening of the 3D mesh all of its 3D vertices e.g. 3D vertices have the same depth value e.g. 100 110 or null . Similarly after flattening of the 3D mesh all of its 3D vertices have the same depth value e.g. 107 110 or null .

According to various example embodiments the 2D image may depict all or part of a 3D object. For example as generated the 3D mesh may model a 3D object e.g. an airplane an animal or a house and the 2D image may depict at least a portion of the 3D object e.g. at least a portion of the airplane the animal or the house . As another example as generated the 3D mesh may model a portion of the 3D object e.g. a wing of an airplane a leg of an animal or a front door of a house and the 2D image may depict the portion of the 3D object.

In the example shown in the 2D image is mapped to at least the 3D vertices and . Since the 2D image is mapped to the 3D vertex e.g. in the center of the hexagonal area shown the modifying of the 3D mesh by the repositioning of the 3D vertex distorts the 2D image by repositioning e.g. moving at least a portion of the 2D image e.g. the center of the 2D image . In other words the modifying of the 3D mesh deforms the 2D image . Accordingly movement of the 3D mesh causes a corresponding movement e.g. distortion or deformation in the 2D image mapped to the 3D mesh . This may have the effect of animating of the 2D image in two dimensions e.g. the x y plane . However this effect may be achieved by manipulating the 3D mesh in its flattened and textured state and such manipulation may be performed using one or more 3D graphics accelerators. In this manner texture deformation may be used as a means of animation. According to various example embodiments animation of one or more 3D vertices e.g. 3D vertex is constrained to 2D movement and thus provides an authoring technique e.g. animation format for 2D animation of a texture e.g. 2D image that is mapped thereto. Moreover such an authoring technique may facilitate efficient 2D animation that is implementable on 3D graphics acceleration hardware.

The animation machine the database or both may form all or part of a game system that utilizes one or more of the methodologies described herein to facilitate generation of 2D animations from 3D meshes e.g. 3D mesh . For example the animation machine may generate the 3D mesh and store the 3D mesh in the database for subsequent use by the animation machine the user device the user device or any suitable combination thereof. As another example the animation machine may generate the 3D mesh and store the 3D mesh itself for subsequent use by the animation machine the user device the user device or any suitable combination thereof. With access to the generated 3D mesh the animation machine the user device the user device or any suitable combination thereof may generate a 2D animation from the 3D mesh .

The database is a data repository e.g. a storage device that stores information maintained by the animation machine and accessible by the animation machine the user device the user device or any suitable combination thereof. This information may include one or more generated 3D meshes e.g. 3D mesh and 3D mesh one or more 2D images e.g. 2D image one or more animations e.g. generated based on 2D frames rendered from the 3D mesh or any suitable combination thereof.

Also shown in are users and . One or both of the users and may be a human user e.g. a human being a machine user e.g. a computer configured by a software program to interact with the user device or any suitable combination thereof e.g. a human assisted by a machine or a machine supervised by a human . The user is not part of the network environment but is associated with the user device and may be a user of the user device . For example the user device may be a personal computer a tablet computer or a smart phone belonging to the user . Likewise the user is not part of the network environment but is associated with the user device . As an example the user device may be a personal computer a tablet computer or a smart phone belonging to the user .

Any of the machines databases or devices shown in may be implemented in a general purpose computer modified e.g. configured or programmed by software to be a special purpose computer to perform the functions described herein for that machine database or device. For example a computer system able to implement any one or more of the methodologies described herein is discussed below with respect to . As used herein a database is a data storage resource and may store data structured as a text file a table a spreadsheet a relational database a triple store or any suitable combination thereof. Moreover any two or more of the machines illustrated in may be combined into a single machine and the functions described herein for any single machine may be subdivided among multiple machines.

The network may be any network that enables communication between machines e.g. animation machine and the user device . Accordingly the network may be a wired network a wireless network e.g. a mobile network or any suitable combination thereof. The network may include one or more portions that constitute a private network a public network e.g. the Internet or any suitable combination thereof.

Operations performable by the various modules of the animation machine are described below with respect to . In some example embodiments one or more modules of the animation machine e.g. generation module perform a portion of the methods discussed herein and one or more modules of the user device perform other portions of the methods discussed herein.

Operations performable by the various modules of the user device are described below with respect to . In some example embodiments one or more modules of the animation machine e.g. generation module perform a portion of the methods discussed herein and one or more modules e.g. render module of the user device perform other portions of the methods discussed herein.

In operation the access module accesses the 3D mesh e.g. from the database . The 3D mesh includes 3D vertices that are each represented in three dimensions where one of the three dimensions is a depth dimension e.g. z dimension that is normal to a viewing plane e.g. a display screen and where two of the three dimensions e.g. x dimension and y dimension are each normal to the depth dimension.

In operation the flattener module flattens the 3D mesh by assigning a single value of the depth dimension e.g. a single z value to each of the 3D vertices in the 3D mesh e.g. 3D vertices . The flattened 3D mesh remains three dimensional since its 3D vertices all have depth values e.g. z values . As noted above the single value of the depth dimension may correspond to the flattened 3D mesh and may identify the flattened 3D mesh as being distinct from a further flattened 3D mesh e.g. 3D mesh .

In operation the texture module textures the flattened 3D mesh by mapping the 2D image to at least some of the 3D vertices e.g. 3D vertices of the 3D mesh . As noted above the flattened 3D mesh remains three dimensional and its 3D vertices e.g. 3D vertices remain assigned to the single value of the depth dimension.

In operation the render module generates a 2D frame of an animation e.g. a first 2D frame by rendering the flattened and textured 3D mesh to which the 2D image is mapped. That is the render module may generate the 2D frame based on the unmodified 3D mesh on the undistorted 2D image or both. In some example embodiments the render module may use the graphics accelerator in performing operation .

In operation the motion module modifies the flattened and textured 3D mesh by repositioning the 3D vertex e.g. with respect to the 3D vertices and within the flattened and textured 3D mesh . Operation also includes maintaining the single value of the depth dimension assigned in operation to each of the 3D vertices in the 3D mesh . In particular the repositioning of the 3D vertex may be performed while maintaining the single value of the depth dimension e.g. the single z value . As noted above the modifying of the flattened and textured 3D mesh distorts e.g. deforms the 2D image that is mapped to at least some of the 3D vertices e.g. 3D vertex of the flattened and textured 3D mesh . The flattened textured and modified 3D mesh remains three dimensional and its 3D vertices e.g. 3D vertices remain assigned to the single value of the depth dimension as discussed above with respect to operation .

In operation the render module generates another 2D frame of the animation e.g. a second 2D frame by rendering the flattened textured and modified 3D mesh to which the distorted e.g. deformed 2D image remains mapped e.g. texture mapped . That is the render module may generate this other 2D frame based on the modified 3D mesh on the distorted 2D image or both. In some example embodiments the render module may use the graphics accelerator in performing operation .

According to various example embodiments the method may iteratively perform multiple instances of operations and to generate multiple 2D frames of the animation. By looping through operations and any number of 2D frames may be generated by modifying and rendering the 3D mesh and 2D image which is mapped thereto.

As shown in the method may include one or more of operations and . For clarity operations are described as being performed by modules of the animation machine . In certain example embodiments however one or more of the operations may be performed by the analogous modules of the user device .

In operation the generation module generates the 3D mesh and stores the 3D mesh e.g. in the database at the animation machine or both . Generation of the 3D mesh may be based on geometric data describing a 3D object e.g. an airplane the animal or a house or a portion thereof. Operation may include generating one or more of the 3D vertices e.g. 3D vertices of the 3D mesh and may include representing each of the 3D vertices in three dimensions e.g. x y z space . The generation module may use e.g. control launch or initiate 3D modeling software e.g. a 3D modeling application in the performance of operation .

Operation may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the render module generates a 2D frame e.g. a first 2D frame of animation based on the flattened textured and unmodified 3D mesh . In operation the render module renders the undistorted 2D image that is mapped to at least a portion of the flattened textured and unmodified 3D mesh . This may have the effect of rendering the 2D image in a state prior to the repositioning of the 3D vertex in operation .

Operation may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the render module generates another 2D frame e.g. a second 2D frame of animation based on the flattened textured and modified 3D mesh . In operation the render module renders the distorted 2D image that is mapped to at least a portion of the flattened textured and modified 3D mesh . This may have the effect of rendering the 2D image in an updated state subsequent to the repositioning of the 3D vertex in operation .

In operation the render module generates an animation e.g. 2D animation based on the 2D frames generated in operations and e.g. the first and second 2D frames . In the generated animation the 2D frames may be sequential 2D frames. For example within the animation the 2D frame generated in operation may precede the 2D frame generated in operation .

One or more of operations may be performed as part e.g. a precursor task a subroutine or a portion of operation . In operation the render module stores the generated 2D frames from operations and e.g. the first 2D frame and the second 2D frame as sequential frames in the animation. The render module may store the animation in the database e.g. as a single data file provide the animation to one or more user devices e.g. user device for presentation or both.

In operation the render module stores the undistorted 2D image e.g. as rendered in operation and the distorted 2D image e.g. as rendered in operation as sequential frames in the animation. As noted above the render module may store the animation in the database provide the animation to one or more user devices for presentation or both.

In operation the render module composites e.g. mixes combines or concatenates the 2D frame generated in operation e.g. the first 2D frame with one or more 2D frames generated in corresponding operations performed on another 3D mesh . For example the render module may composite a set e.g. a first set of 2D frames generated from unmodified 3D meshes and undistorted 2D images that are texture mapped thereon.

In operation the render module composites the 2D frame generated in operation e.g. the second 2D frame with one or more 2D frames generated in corresponding operations performed on the other 3D mesh . For example the render module may composite another set e.g. a second set of 2D frames generated from modified 3D meshes and distorted 2D images that are texture mapped thereon.

The combination of operations and may have the effect of enabling complex animations to be generated e.g. depicting multiple moving portions of a 3D object . For example an animation of a walking animal with four legs may be generated by separately animating a 3D mesh for each of the four legs e.g. in addition to animating separate 3D meshes for the animal s face ears and tail . As noted above each portion of the animal e.g. each leg may be modeled by a separate 3D mesh which may be identified by its depth value e.g. z value assigned to each of its 3D vertices. Accordingly the depth dimension may be used to identify and distinguish different flattened 3D meshes where the 3D meshes respectively correspond to portions of a single 3D model e.g. the animal being animated.

In operation the render module presents the animation generated in operation . For example the render module may provide the animation to a user device e.g. user device for presentation on a display screen of that user device. As another example the render module may directly cause the animation to be displayed on a display screen of the animation machine or connected thereto.

Operation may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the render module presents the animation. In operation the render module presents the 2D frame generated in operation e.g. generated from the flattened textured and unmodified 3D mesh to which the undistorted 2D image is mapped prior to presenting the 2D frame generated in operation e.g. generated from the flattened textured and modified 3D mesh to which the distorted 2D image is mapped . In some example embodiments the render module performs operation by presenting the undistorted 2D image e.g. as rendered in operation prior to presenting the distorted 2D image e.g. as rendered in operation .

As shown in the method may include one or more of operations and . For clarity operations are described as being performed by modules of the animation machine . In certain example embodiments however one or more of the operations may be performed by the analogous modules of the user device .

One or more of operations and may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the texture module textures the flattened 3D mesh . In operation the texture module maps e.g. texture maps the undistorted 2D image to a portion of the 3D vertices that comprise the flattened 3D mesh e.g. 3D vertices . For example the mapping of the undistorted 2D image may include associating one or more portions or edges of the undistorted 2D image with a subset of the 3D vertices in the 3D mesh . In example embodiments that include operation the repositioning of the 3D vertex in operation may distort the 2D image that is mapped to the portion of the 3D vertices. Moreover the portion of the 3D vertices may include the 3D vertex which is repositioned in operation .

In operation the texture module maps at least a portion of the undistorted 2D image to the 3D vertex in the flattened 3D mesh . For example the center or centroid of the 2D image may be mapped e.g. associated with the 3D vertex . As noted above the 3D vertex is subject to repositioning in operation . Accordingly operation involves mapping at least a portion of the undistorted 2D image to the 3D vertex that will be repositioned in operation . In example embodiments that include operation the repositioning of the 3D vertex in operation may deform the 2D image that is mapped to the 3D vertex .

Operation may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the render module generates the 2D frame of animation e.g. the first 2D frame based on the flattened textured and unmodified 3D mesh . In operation the render module generates the 2D frame by rendering the flattened textured and unmodified 3D mesh using the graphics accelerator . As noted above the graphics accelerator may be or include graphics acceleration hardware e.g. graphics acceleration hardware that is local to the animation machine .

One or more of operations and may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the motion module modifies the flattened and textured 3D mesh e.g. by repositioning the 3D vertex in the 3D mesh . As noted above with respect to operation the undistorted 2D image may be mapped to a portion of the 3D vertices of the 3D mesh . In operation the motion module distorts the 2D image that is mapped to this portion of the 3D vertices.

As noted above with respect to operation the undistorted 2D image may be mapped to the 3D vertex which is subject to repositioning in operation . In operation the motion module deforms the 2D image that is mapped to this 3D vertex .

In operation the motion module moves the 3D vertex e.g. with respect to other 3D vertices in the 3D mesh in a direction orthogonal to the depth dimension e.g. z dimension in x y z space . Operation may be performed as part of the repositioning of the 3D vertex while maintaining the single value e.g. a single z value of the depth dimension of the 3D vertex discussed above with respect to operation . The 3D vertex is still three dimensional after being moved and the 3D vertex continues to have the single value of the depth dimension that is assigned to the 3D vertices e.g. 3D vertices of the flattened 3D mesh .

According to some example embodiments the movement of the 3D vertex in operation is described by a 3D vector but the maintaining of a single z value for the depth dimension of the 3D vertex constrains the movement to a two dimensional plane that is orthogonal to the depth dimension. Hence one or more of operations and may be performed as part e.g. a precursor task a subroutine or a portion of operation in which the motion module moves the 3D vertex . In operation the motion module determines a 3D vector of movement for the 3D vertex . The 3D vector of movement may have an x component a y component and a z component. In operation the motion module ignores a component of the 3D vector in the depth dimension. For example the motion module may ignore the z component of the 3D vector of movement. This may have the effect of constraining the movement of the 3D vertex to one or both of the dimensions that are orthogonal to the depth dimension.

Operation may be performed as part e.g. a precursor task a subroutine or a part of operation in which the render module generates the further 2D frame of animation e.g. the second 2D frame based on the flattened textured and modified 3D mesh . In operation the render module generates the 2D frame by rendering the flattened textured and modified 3D mesh using the graphics accelerator . As noted above the graphics accelerator may be or include graphics acceleration hardware e.g. graphics acceleration hardware that is local to the animation machine .

According to various example embodiments one or more of the methodologies described herein may facilitate generation of a 2D animation from one or more 3D meshes. Moreover one or more of the methodologies described herein may facilitate efficient rendering of a 2D animation using 3D graphics acceleration hardware. Hence one or more the methodologies described herein may facilitate efficient production of 2D animations in the context of game applications educational applications presentation applications or other communication applications in which movement of a 3D object is depicted.

When these effects are considered in aggregate one or more of the methodologies described herein may obviate a need for certain efforts or resources that otherwise would be involved in generating 2D or 3D animations. Efforts expended by an animator in generating sprite based 2D animation or complex movements of a 3D object in 3D space may be reduced by one or more of the methodologies described herein. Computing resources used by one or more machines databases or devices e.g. within the network environment may similarly be reduced. Examples of such computing resources include processor cycles network traffic memory usage data storage capacity power consumption and cooling capacity.

The machine includes a processor e.g. a central processing unit CPU a graphics processing unit GPU a digital signal processor DSP an application specific integrated circuit ASIC a radio frequency integrated circuit RFIC or any suitable combination thereof a main memory and a static memory which are configured to communicate with each other via a bus . The machine may further include a graphics display e.g. a plasma display panel PDP a light emitting diode LED display a liquid crystal display LCD a projector or a cathode ray tube CRT . The machine may also include an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse a touchpad a trackball a joystick a motion sensor or other pointing instrument a storage unit a signal generation device e.g. a speaker and a network interface device .

The storage unit includes a machine readable medium on which is stored the instructions e.g. software embodying any one or more of the methodologies or functions described herein. The instructions may also reside completely or at least partially within the main memory within the processor e.g. within the processor s cache memory or both during execution thereof by the machine . Accordingly the main memory and the processor may be considered as machine readable media. The instructions may be transmitted or received over a network e.g. network via the network interface device .

As used herein the term memory refers to a machine readable medium able to store data temporarily or permanently and may be taken to include but not be limited to random access memory RAM read only memory ROM buffer memory flash memory and cache memory. While the machine readable medium is shown in an example embodiment to be a single medium the term machine readable medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database or associated caches and servers able to store instructions. The term machine readable medium shall also be taken to include any medium that is capable of storing instructions e.g. software for execution by a machine e.g. machine such that the instructions when executed by one or more processors of the machine e.g. processor cause the machine to perform any one or more of the methodologies described herein. The term machine readable medium shall accordingly be taken to include but not be limited to a data repository in the form of a solid state memory an optical medium a magnetic medium or any suitable combination thereof.

Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter herein.

Certain embodiments are described herein as including logic or a number of components modules or mechanisms. Modules may constitute either software modules e.g. code embodied on a machine readable medium or in a transmission signal or hardware modules. A hardware module is a tangible unit capable of performing certain operations and may be configured or arranged in a certain physical manner. In various example embodiments one or more computer systems e.g. a standalone computer system a client computer system or a server computer system or one or more hardware modules of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a hardware module that operates to perform certain operations as described herein.

In some embodiments a hardware module may be implemented mechanically electronically or any suitable combination thereof. For example a hardware module may include dedicated circuitry or logic that is permanently configured to perform certain operations. For example a hardware module may be a special purpose processor such as a field programmable gate array FPGA or an ASIC. A hardware module may also include programmable logic or circuitry that is temporarily configured by software to perform certain operations. For example a hardware module may include software encompassed within a general purpose processor or other programmable processor. It will be appreciated that the decision to implement a hardware module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

Accordingly the phrase hardware module should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily configured e.g. programmed to operate in a certain manner or to perform certain operations described herein. As used herein hardware implemented module refers to a hardware module. Considering embodiments in which hardware modules are temporarily configured e.g. programmed each of the hardware modules need not be configured or instantiated at any one instance in time. For example where a hardware module comprises a general purpose processor configured by software to become a special purpose processor the general purpose processor may be configured as respectively different special purpose processors e.g. comprising different hardware modules at different times. Software may accordingly configure a processor for example to constitute a particular hardware module at one instance of time and to constitute a different hardware module at a different instance of time.

Hardware modules can provide information to and receive information from other hardware modules. Accordingly the described hardware modules may be regarded as being communicatively coupled. Where multiple hardware modules exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses between or among two or more of the hardware modules. In embodiments in which multiple hardware modules are configured or instantiated at different times communications between such hardware modules may be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware modules have access. For example one hardware module may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware module may then at a later time access the memory device to retrieve and process the stored output. Hardware modules may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The various operations of example methods described herein may be performed at least partially by one or more processors that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processors may constitute processor implemented modules that operate to perform one or more operations or functions described herein. As used herein processor implemented module refers to a hardware module implemented using one or more processors.

Similarly the methods described herein may be at least partially processor implemented a processor being an example of hardware. For example at least some of the operations of a method may be performed by one or more processors or processor implemented modules. Moreover the one or more processors may also operate to support performance of the relevant operations in a cloud computing environment or as a software as a service SaaS . For example at least some of the operations may be performed by a group of computers as examples of machines including processors with these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. an API .

The performance of certain operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the one or more processors or processor implemented modules may be located in a single geographic location e.g. within a home environment an office environment or a server farm . In other example embodiments the one or more processors or processor implemented modules may be distributed across a number of geographic locations.

Some portions of this specification are presented in terms of algorithms or symbolic representations of operations on data stored as bits or binary digital signals within a machine memory e.g. a computer memory . These algorithms or symbolic representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. As used herein an algorithm is a self consistent sequence of operations or similar processing leading to a desired result. In this context algorithms and operations involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions herein using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or any suitable combination thereof registers or other machine components that receive store transmit or display information. Furthermore unless specifically stated otherwise the terms a or an are herein used as is common in patent documents to include one or more than one instance. Finally as used herein the conjunction or refers to a non exclusive or unless specifically stated otherwise.

The following descriptions define various example embodiments of methods and systems e.g. apparatus discussed herein 

accessing a 3D mesh of 3D vertices each represented in three dimensions one of the three dimensions being a depth dimension that is normal to a viewing plane two of the three dimensions each being normal to the depth dimension 

flattening the 3D mesh by assigning a single value of the depth dimension to each of the 3D vertices in the 3D mesh 

texturing the flattened 3D mesh by mapping a 2D image to at least some of the 3D vertices each represented in the three dimensions and each assigned the single value of the depth dimension that is normal to the viewing plane 

generating a first 2D frame of an animation by rendering the flattened and textured 3D mesh to which the 2D image is mapped 

modifying the flattened and textured 3D mesh by repositioning a 3D vertex among the 3D vertices while maintaining the single value of the depth dimension assigned to each of the 3D vertices the modifying of the flattened and textured 3D mesh distorting the 2D image that is mapped to at least some of the 3D vertices of the flattened and textured 3D mesh the modifying being performed by a processor of a machine and generating a second 2D frame of the animation by rendering the flattened textured and modified 3D mesh to which the distorted 2D image is mapped.

the single value of the depth dimension identifies the flattened 3D mesh as being distinct from a further flattened 3D mesh that is identified by a further value of the depth dimension.

the rendering of the textured flattened and modified 3D mesh includes rendering the distorted 2D image that is mapped to the textured flattened and modified 3D mesh.

generating the animation by storing the first 2D frame and the second 2D frame as sequential frames in the animation 

the second 2D frame being generated from the flattened textured and modified 3D mesh with the repositioned 3D vertex among the 3D vertices.

generating the animation by storing the undistorted 2D image and the distorted 2D image as frames in the animation 

the undistorted 2D image being mapped to the flattened and textured 3D mesh prior to the repositioning of the 3D vertex among the 3D vertices 

the distorted 2D image being mapped to the flattened textured and modified 3D mesh with the repositioned 3D vertex among the 3D vertices.

compositing the first 2D frame with another 2D frame generated from a further 3D mesh that is flattened and textured and

compositing the second 2D frame with a further 2D frame generated from the further 3D mesh that is flattened textured and modified by a repositioning of a 3D vertex included in the further 3D mesh.

the first 2D frame being generated by rendering the flattened textured and unmodified 3D mesh to which the undistorted 2D image is mapped 

the second 2D frame being generated by rendering the flattened textured and modified 3D mesh to which the distorted 2D image is mapped.

the texturing of the flattened 3D mesh includes mapping the 2D image to a portion of the 3D vertices that includes the 3D vertex and

the repositioning of the 3D vertex distorts the 2D image mapped to the portion of the 3D vertices that includes the 3D vertex.

the texturing of the flattened 3D mesh includes mapping the undistorted 2D image to the 3D vertex and

the repositioning of the 3D vertex while maintaining the single value of the depth dimension of the 3D vertex includes moving the 3D vertex in a direction orthogonal to the depth dimension.

the repositioning of the 3D vertex while maintaining the single value of the depth dimension of the 3D vertex includes 

determining a 3D vector of movement for the 3D vertex and ignoring a component of the 3D vector in the depth dimension.

the generating of the first 2D frame of the animation includes rendering the flattened and textured 3D mesh by using 3D graphics acceleration hardware.

the generating of the second 2D frame of the animation includes rendering the flattened textured and modified 3D mesh by using 3D graphics acceleration hardware.

17. A non transitory machine readable storage medium comprising instructions that when executed by one or more processors of a machine cause the machine to perform operations comprising 

accessing a 3D mesh of 3D vertices each represented in three dimensions one of the three dimensions being a depth dimension that is normal to a viewing plane two of the three dimensions each being normal to the depth dimension 

flattening the 3D mesh by assigning a single value of the depth dimension to each of the 3D vertices in the 3D mesh 

texturing the flattened 3D mesh by mapping a 2D image to at least some of the 3D vertices each represented in the three dimensions and each assigned the single value of the depth dimension that is normal to the viewing plane 

generating a first 2D frame of an animation by rendering the flattened and textured 3D mesh to which the 2D image is mapped 

modifying the flattened and textured 3D mesh by repositioning a 3D vertex among the 3D vertices while maintaining the single value of the depth dimension assigned to each of the 3D vertices the modifying of the flattened and textured 3D mesh distorting the 2D image that is mapped to at least some of the 3D vertices of the flattened and textured 3D mesh the modifying being performed by the one or more processors of the machine and generating a second 2D frame of the animation by rendering the flattened textured and modified 3D mesh to which the distorted 2D image is mapped.

the texturing of the flattened 3D mesh includes mapping the 2D image to a portion of the 3D vertices that includes the 3D vertex and

the repositioning of the 3D vertex distorts the 2D image mapped to the portion of the 3D vertices that includes the 3D vertex.

an access module configured to access a 3D mesh of 3D vertices each represented in three dimensions one of the three dimensions being a depth dimension that is normal to a viewing plane two of the three dimensions each being normal to the depth dimension a flattener module configured to flatten the 3D mesh by assigning a single value of the depth dimension to each of the 3D vertices in the 3D mesh a texture module configured to texture the flattened 3D mesh by mapping a 2D image to at least some of the 3D vertices each represented in the three dimensions and each assigned the single value of the depth dimension that is normal to the viewing plane a render module configured to render a first 2D frame of an animation by rendering the flattened and textured 3D mesh to which the 2D image is mapped and a processor configured by a motion module that configures the processor to modify the flattened and textured 3D mesh by repositioning a 3D vertex among the 3D vertices while maintaining the single value of the depth dimension assigned to each of the 3D vertices the modifying of the flattened and textured 3D mesh distorting the 2D image that is mapped to at least some of the 3D vertices of the flattened and textured 3D mesh the render module being configured to generate a second 2D frame of the animation by rendering the flattened textured and modified 3D mesh to which the distorted 2D image is mapped.

the texture module is configured to texture the flattened 3D mesh by mapping the 2D image to a portion of the 3D vertices that includes the 3D vertex and

the motion module configures the processor to distort the 2D image mapped to the portion of the 3D vertices that includes the 3D vertex by repositioning the 3D vertex.

