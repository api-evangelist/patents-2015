---

title: Computer program product for fetching from a first physical memory between an execution of a plurality of threads associated with a second physical memory
abstract: A computer program product, apparatus and associated method/processing unit are provided for utilizing a physical memory system including a first physical memory of a first physical memory class, and a second physical memory of a second physical memory class communicatively coupled to the first physical memory. In operation, one or more pages are fetched from the first physical memory using a time between an execution of a plurality of threads associated with the second physical memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09158546&OS=09158546&RS=09158546
owner: P4TENTS1, LLC
number: 09158546
owner_city: Wilmington
owner_country: US
publication_date: 20150105
---
The present application is a continuation in part of and claims priority to U.S. patent application Ser. No. 13 441 332 filed Apr. 6 2012 entitled MULTIPLE CLASS MEMORY SYSTEMS which claims priority to U.S. Prov. App. No. 61 472 558 that was filed Apr. 6 2011 and entitled MULTIPLE CLASS MEMORY SYSTEM and U.S. Prov. App. No. 61 502 100 that was filed Jun. 28 2011 and entitled SYSTEM METHOD AND COMPUTER PROGRAM PRODUCT FOR IMPROVING MEMORY SYSTEMS all of which are incorporated herein by reference in their entirety for all purposes. If any definitions e.g. figure reference signs specialized terms examples data information etc. from any related material e.g. parent application other related application material incorporated by reference material cited extrinsic reference etc. conflict with this application e.g. abstract description summary claims etc. for any purpose e.g. prosecution claim support claim interpretation claim construction etc. then the definitions in this application shall apply to the description that follows the same.

Embodiments of the present invention generally relate to memory systems and more specifically to memory systems that include different memory technologies.

A computer program product apparatus and associated method processing unit are provided for utilizing a physical memory system including a first physical memory of a first physical memory class and a second physical memory of a second physical memory class communicatively coupled to the first physical memory. In operation one or more pages are fetched from the first physical memory using a time between an execution of a plurality of threads associated with the second physical memory.

While the invention is susceptible to various modifications combinations and alternative forms various embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood however that the accompanying drawings and detailed description are not intended to limit the invention to the particular form disclosed but on the contrary the intention is to cover all modifications combinations equivalents and alternatives falling within the spirit and scope of the present invention as defined by the relevant claims.

A physical memory PM is memory including physical objects e.g. chips packages multi chip packages etc. or memory components e.g. semiconductor memory cells . PM may in exemplary embodiments include various forms of solid state e.g. semiconductor magnetic etc. memory e.g. NAND flash MRAM PRAM etc. solid state disk SSD or other disk magnetic media etc. For example in one embodiment the physical memory may include semiconductor memory cells. Furthermore in various embodiments the physical memory may include but is not limited to flash memory e.g. NOR flash NAND flash etc. random access memory e.g. RAM SRAM DRAM MRAM PRAM etc. a solid state disk SSD or other disk magnetic media and or any other physical memory that meets the above definition.

A virtual memory VM is a memory address space independent of how the underlying PM is constructed if such PM exists . Note that while VM is the normal abbreviation for virtual memory VMy will be used as an abbreviation to avoid confusion with the abbreviation VM which is used for virtual machine.

A memory system is a system using one or more classes of physical memory. In various embodiments the memory system may or may not use one or more VMys. In different embodiments a memory system may comprise one or more VMys may comprise one or more PMs or may comprise one or more VMys and one or more PMs. A VMy may comprise one more classes of PM. A PM may comprise one more VMy structures again structures are used and the use of a term such as VMy types is avoided to avoid possible confusion .

A storage system includes a memory system that comprises magnetic media or other storage devices e.g. a hard disk drive HDD or solid state disk SSD or just disk . If the storage devices include SSDs that include NAND flash that may also be used as memory for example definitions of storage versus memory may become ambiguous. If there is the possibility of ambiguity or confusion it may be noted when for example an SSD is being used for memory e.g. log file or cache etc or when for example memory is being used for disk e.g. RAM disk etc. .

In various embodiments the storage system may or may not comprise one or more physical volumes PVs . A PV may comprise one or more HDDs HDD partitions or logical unit numbers LUNs of a storage device.

A partition is a logical part of a storage device. For example an HDD partition is a logical part of an HDD. A LUN is a number used to identify a logical unit LU which is that part of storage device addressed by a storage protocol. Examples of storage protocols include SCSI SATA Fibre Channel FC iSCSI etc.

Volume management treats PVs as sequences of chunks called physical extents PEs . Volume managers may have PEs of a uniform size or of variable size PEs that can be split and merged.

Normally PEs map one to one to logical extents LEs . With mirroring of storage devices multiple copies of data e.g. on different storage devices multiple PEs map to each LE. PEs are part of a physical volume group PVG a set of same sized PVs that act similarly to hard disks in a RAID1 array. PVGs are usually stored on different disks and may also be on separate data buses to increase redundancy.

A system may pool LEs into a volume group VG . The pooled LEs may then be joined or concatenated together in a logical volume LV . An LV is a virtual partition. Systems may use an LV as a raw block device also known as raw device or block device as though it was a physical partition. For example a storage system may create a mountable file system on an LV or use an LV as swap storage etc.

In this description where the boundary and differences between a memory system and a storage system may be blurred an LV may comprise one or more PMs and a PM may comprise one or more LVs. If there is the possibility of ambiguity or confusion it may be noted when for example an LV comprises one or more PMs and when for example a PM may comprise one or more LVs.

Communicatively coupled means coupled in a way that functions to allow a signal e.g. a data signal a control signal a bus a group of signals or other electric signal to be communicated between the communicatively coupled items.

As used herein memory devices are generally defined as integrated circuits that are composed primarily of memory storage cells such as DRAMs Dynamic Random Access Memories SRAMs Static Random Access Memories FeRAMs Ferro Electric RAMs MRAMs Magnetic Random Access Memories Flash Memory and other forms of random access and related memories that store information in the form of electrical optical magnetic chemical biological or other means. Dynamic memory device types may include FPM DRAMs Fast Page Mode Dynamic Random Access Memories EDO Extended Data Out DRAMs BEDO Burst EDO DRAMs SDR Single Data Rate Synchronous DRAMs DDR Double Data Rate Synchronous DRAMs DDR2 DDR3 DDR4 or any of the expected follow on devices and related technologies such as Graphics RAMs Video RAMs LP RAM Low Power DRAMs which are often based on the fundamental functions features and or interfaces found on related DRAMs.

Memory devices may include chips die and or single or multi chip or multi die packages of various types assemblies forms and configurations. In multi chip packages the memory devices may be packaged with other device types e.g. other memory devices logic chips CPUs hubs buffers intermediate devices analog devices programmable devices etc. and may also include passive devices e.g. resistors capacitors inductors etc. . These multi chip packages may include cooling enhancements e.g. an integrated heat sink heat slug fluids gases micromachined structures micropipes capillaries combinations of these etc. that may be further attached to the carrier or another nearby carrier or other heat removal or cooling system.

Although not necessarily shown in all the Figures memory module support devices e.g. buffer s buffer circuit s buffer chip s register s intermediate circuit s power supply regulation hub s re driver s PLL s DLL s non volatile memory SRAM DRAM logic circuits analog circuits digital circuits diodes switches LEDs crystals active components passive components combinations of these and other circuits etc. may be comprised of multiple separate chips e.g. die dice integrated circuits etc. and or components may be combined as multiple separate chips onto one or more substrates may be combined into a single package e.g. using die stacking multi chip packaging etc. or even integrated onto a single device based on tradeoffs such as technology power space weight cost etc.

One or more of the various passive devices e.g. resistors capacitors inductors etc. may be integrated into the support chip packages or into the substrate board PCB or raw card itself based on tradeoffs such as technology power space cost weight etc. These packages may include an integrated heat sink or other cooling enhancements e.g. such as those described above etc. that may be further attached to the carrier or another nearby carrier or other heat removal or cooling system.

Memory devices intermediate devices and circuits hubs buffers registers clock devices passives and other memory support devices etc. and or other components may be attached e.g. coupled connected etc. to the memory subsystem and or other component s via various methods including solder interconnects conductive adhesives socket structures pressure contacts electrical mechanical optical and or other methods that enable communication between two or more devices e.g. via electrical optical or alternate means etc. .

The one or more memory modules or memory subsystems and or other components devices may be electrically optically connected to the memory system CPU complex computer system or other system environment via one or more methods such as soldered interconnects connectors pressure contacts conductive adhesives optical interconnects and other communication and power delivery methods. Connector systems may include mating connectors male female conductive contacts and or pins on one carrier mating with a male or female connector optical connections pressure contacts often in conjunction with a retaining and or closure mechanism and or one or more of various other communication and power delivery methods. The interconnection s may be disposed along one or more edges of the memory assembly and or placed a distance from an edge of the memory subsystem depending on such application requirements as ease of upgrade ease of repair available space and or volume heat transfer constraints component size and shape and other related physical electrical optical visual physical access requirements and constraints etc. Electrical interconnections on a memory module are often referred to as contacts pins connection pins tabs etc. Electrical interconnections on a connector are often referred to as contacts or pins.

As used herein the term memory subsystem refers to but is not limited to one or more memory devices one or more memory devices and associated interface and or timing control circuitry and or one or more memory devices in conjunction with memory buffer s register s hub device s other intermediate device s or circuit s and or switch es . The term memory subsystem may also refer to one or more memory devices in addition to any associated interface and or timing control circuitry and or memory buffer s register s hub device s or switch es assembled into substrate s package s carrier s card s module s or related assembly which may also include connector s or similar means of electrically attaching the memory subsystem with other circuitry. The memory modules described herein may also be referred to as memory subsystems because they include one or more memory device s register s hub s or similar devices.

The integrity reliability availability serviceability performance etc. of the communication path the data storage contents and all functional operations associated with each element of a memory system or memory subsystem may be improved by using one or more fault detection and or correction methods. Any or all of the various elements of a memory system or memory subsystem may include error detection and or correction methods such as CRC cyclic redundancy code or cyclic redundancy check ECC error correcting code EDC error detecting code or error detection and correction LDPC low density parity check parity checksum or other encoding decoding methods suited for this purpose. Further reliability enhancements may include operation re try e.g. repeat re send etc. to overcome intermittent or other faults such as those associated with the transfer of information the use of one or more alternate stand by or replacement communication paths to replace failing paths and or lines complement and or re complement techniques or alternate methods used in computer communication and related systems.

The use of bus termination is common in order to meet performance requirements on buses that form transmission lines such as point to point links multi drop buses etc. Bus termination methods include the use of one or more devices e.g. resistors capacitors inductors transistors other active devices etc. or any combinations and connections thereof serial and or parallel etc. with these devices connected e.g. directly coupled capacitive coupled AC connection DC connection etc. between the signal line and one or more termination lines or points e.g. a power supply voltage ground a termination voltage another signal combinations of these etc. . The bus termination device s may be part of one or more passive or active bus termination structure s may be static and or dynamic may include forward and or reverse termination and bus termination may reside e.g. placed located attached etc. in one or more positions e.g. at either or both ends of a transmission line at fixed locations at junctions distributed etc. electrically and or physically along one or more of the signal lines and or as part of the transmitting and or receiving device s . More than one termination device may be used for example if the signal line comprises a number of series connected signal or transmission lines e.g. in daisy chain and or cascade configuration s etc. with different characteristic impedances.

The bus termination s may be configured e.g. selected adjusted altered set etc. in a fixed or variable relationship to the impedance of the transmission line s often but not necessarily equal to the transmission line s characteristic impedance or configured via one or more alternate approach es to maximize performance e.g. the useable frequency operating margins error rates reliability or related attributes metrics combinations of these etc. within design constraints e.g. cost space power weight performance reliability other constraints combinations of these etc. .

Additional functions that may reside local to the memory subsystem and or hub device include write and or read buffers one or more levels of memory cache local pre fetch logic data encryption and or decryption compression and or decompression protocol translation command prioritization logic voltage and or level translation error detection and or correction circuitry data scrubbing local power management circuitry and or reporting operational and or status registers initialization circuitry performance monitoring and or control one or more co processors search engine s and other functions that may have previously resided in other memory subsystems. By placing a function local to the memory subsystem added performance may be obtained as related to the specific function often while making use of unused circuits within the subsystem.

Memory subsystem support device s may be directly attached to the same assembly e.g. substrate base board package structure etc. onto which the memory device s are attached e.g. mounted connected etc. to a separate substrate e.g. interposer spacer layer etc. also produced using one or more of various materials e.g. plastic silicon ceramic etc. that include communication paths e.g. electrical optical etc. to functionally interconnect the support device s to the memory device s and or to other elements of the memory or computer system.

Transfer of information e.g. using packets bus signals wires etc. along a bus e.g. channel link cable etc. may be completed using one or more of many signaling options. These signaling options may include such methods as single ended differential time multiplexed encoded optical or other approaches with electrical signaling further including such methods as voltage or current signaling using either single or multi level approaches. Signals may also be modulated using such methods as time or frequency multiplexing non return to zero NRZ phase shift keying PSK amplitude modulation combinations of these and others. Voltage levels are expected to continue to decrease with 1.8V 1.5V 1.35V 1.2V 1V and lower power and or signal voltages of the integrated circuits.

One or more clocking methods may be used within the memory system including global clocking source synchronous clocking encoded clocking or combinations of these and or other methods. The clock signaling may be identical to that of the signal lines or may use one of the listed or alternate techniques that are more conducive to the planned clock frequency or frequencies and the number of clocks planned within the various systems and subsystems. A single clock may be associated with all communication to and from the memory as well as all clocked functions within the memory subsystem or multiple clocks may be sourced using one or more methods such as those described earlier. When multiple clocks are used the functions within the memory subsystem may be associated with a clock that is uniquely sourced to the memory subsystem or may be based on a clock that is derived from the clock related to the signal s being transferred to and from the memory subsystem such as that associated with an encoded clock . Alternately a unique clock may be used for the signal s transferred to the memory subsystem and a separate clock for signal s sourced from one or more of the memory subsystems. The clocks themselves may operate at the same or frequency multiple of the communication or functional frequency and may be edge aligned center aligned or placed in an alternate timing position relative to the signal s .

Signals coupled to the memory subsystem s include address command control and data coding e.g. parity ECC etc. as well as other signals associated with requesting or reporting status e.g. retry etc. and or error conditions e.g. parity error etc. resetting the memory completing memory or logic initialization and other functional configuration or related information etc. Signals coupled from the memory subsystem s may include any or all of the signals coupled to the memory subsystem s as well as additional status error control etc. signals however generally will not include address and command signals.

Signals may be coupled using methods that may be consistent with normal memory device interface specifications generally parallel in nature e.g. DDR2 DDR3 etc. or the signals may be encoded into a packet structure generally serial in nature e.g. FB DIMM etc. for example to increase communication bandwidth and or enable the memory subsystem to operate independently of the memory technology by converting the received signals to from the format required by the receiving memory device s .

Memory devices e.g. memory modules memory circuits memory integrated circuits etc. are used in many applications e.g. computer systems calculators cellular phones etc. . The packaging e.g. grouping mounting assembly etc. of memory devices varies between these different applications. A memory module is a common packaging method that uses a small circuit board e.g. PCB raw card card etc. often comprised of random access memory RAM circuits on one or both sides of the memory module with signal and or power pins on one or both sides of the circuit board. A dual in line memory module DIMM comprises one or more memory packages e.g. memory circuits etc. . DIMMs have electrical contacts e.g. signal pins power pins connection pins etc. on each side e.g. edge etc. of the module. DIMMs are mounted e.g. coupled etc. to a printed circuit board PCB e.g. motherboard mainboard baseboard chassis planar etc. . DIMMs are designed for use in computer system applications e.g. cell phones portable devices hand held devices consumer electronics TVs automotive electronics embedded electronics lap tops personal computers workstations servers storage devices networking devices network switches network routers etc. . In other embodiments different and various form factors may be used e.g. cartridge card cassette etc. .

The number of connection pins on a DIMM varies. For example a 240 connector pin DIMM is used for DDR2 SDRAM DDR3 SDRAM and FB DIMM DRAM a 184 connector pin DIMM is used for DDR SDRAM.

Example embodiments described in this disclosure include computer system s with one or more central processor units CPU and possibly one or more I O unit s coupled to one or more memory systems that contain one or more memory controllers and memory devices. In example embodiments the memory system s includes one or more memory controllers e.g. portion s of chipset s portion s of CPU s etc. . In example embodiments the memory system s include one or more physical memory array s with a plurality of memory circuits for storing information e.g. data instructions etc. .

The plurality of memory circuits in memory system s may be connected directly to the memory controller s and or indirectly coupled to the memory controller s through one or more other intermediate circuits or intermediate devices e.g. hub devices switches buffer chips buffers register chips registers receivers designated receivers transmitters drivers designated drivers re drive circuits etc. .

Intermediate circuits may be connected to the memory controller s through one or more bus structures e.g. a multi drop bus point to point bus etc. and which may further include cascade connection s to one or more additional intermediate circuits and or bus es . Memory access requests are transmitted by the memory controller s through the bus structure s . In response to receiving the memory access requests the memory devices may store write data or provide read data. Read data is transmitted through the bus structure s back to the memory controller s .

In various embodiments the memory controller s may be integrated together with one or more CPU s e.g. processor chips multi core die CPU complex etc. and supporting logic packaged in a discrete chip e.g. chipset controller memory controller memory fanout device memory switch hub memory matrix chip northbridge etc. included in a multi chip carrier with the one or more CPU s and or supporting logic or packaged in various alternative forms that match the system the application and or the environment. Any of these solutions may or may not employ one or more bus structures e.g. multidrop multiplexed point to point serial parallel narrow high speed links etc. to connect to one or more CPU s memory controller s intermediate circuits other circuits and or devices memory devices etc.

A memory bus may be constructed using multi drop connections and or using point to point connections e.g. to intermediate circuits to receivers etc. on the memory modules. The downstream portion of the memory controller interface and or memory bus the downstream memory bus may include command address write data control and or other e.g. operational initialization status error reset clocking strobe enable termination etc. signals being sent to the memory modules e.g. the intermediate circuits memory circuits receiver circuits etc. . Any intermediate circuit may forward the signals to the subsequent circuit s or process the signals e.g. receive interpret alter modify perform logical operations merge signals combine signals transform store re drive etc. if it is determined to target a downstream circuit re drive some or all of the signals without first modifying the signals to determine the intended receiver or perform a subset or combination of these options etc.

The upstream portion of the memory bus the upstream memory bus returns signals from the memory modules e.g. requested read data error status other operational information etc. and these signals may be forwarded to any subsequent intermediate circuit via bypass or switch circuitry or be processed e.g. received interpreted and re driven if it is determined to target an upstream or downstream hub device and or memory controller in the CPU or CPU complex be re driven in part or in total without first interpreting the information to determine the intended recipient or perform a subset or combination of these options etc. .

In different memory technologies portions of the upstream and downstream bus may be separate combined or multiplexed and any buses may be unidirectional one direction only or bidirectional e.g. switched between upstream and downstream use bidirectional signaling etc. . Thus for example in JEDEC standard DDR e.g. DDR DDR2 DDR3 DDR4 etc. SDRAM memory technologies part of the address and part of the command bus are combined or may be considered to be combined row address and column address are time multiplexed on the address bus and read write data uses a bidirectional bus.

In alternate embodiments a point to point bus may include one or more switches or other bypass mechanism that results in the bus information being directed to one of two or more possible intermediate circuits during downstream communication communication passing from the memory controller to a intermediate circuit on a memory module as well as directing upstream information communication from an intermediate circuit on a memory module to the memory controller possibly by way of one or more upstream intermediate circuits.

In some embodiments the memory system may include one or more intermediate circuits e.g. on one or more memory modules etc. connected to the memory controller via a cascade interconnect memory bus however other memory structures may be implemented e.g. point to point bus a multi drop memory bus shared bus etc. . Depending on the constraints e.g. signaling methods used the intended operating frequencies space power cost and other constraints etc. various alternate bus structures may be used. A point to point bus may provide the optimal performance in systems requiring high speed interconnections due to the reduced signal degradation compared to bus structures having branched signal lines switch devices or stubs. However when used in systems requiring communication with multiple devices or subsystems a point to point or other similar bus will often result in significant added cost e.g. component cost board area increased system power etc. and may reduce the potential memory density due to the need for intermediate devices e.g. buffers re drive circuits etc. . Functions and performance similar to that of a point to point bus can be obtained by using switch devices. Switch devices and other similar solutions offer advantages e.g. increased memory packaging density lower power etc. while retaining many of the characteristics of a point to point bus. Multi drop bus solutions provide an alternate solution and though often limited to a lower operating frequency can offer a cost performance advantage for many applications. Optical bus solutions permit significantly increased frequency and bandwidth potential either in point to point or multi drop applications but may incur cost and space impacts.

Although not necessarily shown in all the Figures the memory modules or intermediate devices may also include one or more separate control e.g. command distribution information retrieval data gathering reporting mechanism signaling mechanism register read write configuration etc. buses e.g. a presence detect bus an I2C bus an SMBus combinations of these and other buses or signals etc. that may be used for one or more purposes including the determination of the device and or memory module attributes generally after power up the reporting of fault or other status information to part s of the system calibration temperature monitoring the configuration of device s and or memory subsystem s after power up or during normal operation or for other purposes. Depending on the control bus characteristics the control bus es might also provide a means by which the valid completion of operations could be reported by devices and or memory module s to the memory controller s or the identification of failures occurring during the execution of the main memory controller requests etc.

As used herein the term buffer e.g. buffer device buffer circuit buffer chip etc. refers to an electronic circuit that includes temporary storage and logic In some embodiments a buffer may receive signals at one rate e.g. frequency and deliver signals at another rate. In some embodiments a buffer is a device that may also provide compatibility between two signals e.g. changing voltage levels or current capability changing logic function etc. .

As used herein hub is a device containing multiple ports that may be capable of being connected to several other devices. The term hub is sometimes used interchangeably with the term buffer. A port is a portion of an interface that serves an I O function e.g. a port may be used for sending and receiving data address and control information over one of the point to point links or buses . A hub may be a central device that connects several systems subsystems or networks together. A passive hub may simply forward messages while an active hub e.g. repeater amplifier etc. may also modify the stream of data which otherwise would deteriorate over a distance. The term hub as used herein refers to a hub that may include logic hardware and or software for performing logic functions.

As used herein the term bus refers to one of the sets of conductors e.g. signals wires traces and printed circuit board traces or connections in an integrated circuit connecting two or more functional units in a computer. The data bus address bus and control signals may also be referred to together as constituting a single bus. A bus may include a plurality of signal lines or signals each signal line having two or more connection points that form a main transmission line that electrically connects two or more transceivers transmitters and or receivers. The term bus is contrasted with the term channel that may include one or more buses or sets of buses.

As used herein the term channel e.g. memory channel etc. refers to an interface between a memory controller e.g. a portion of processor CPU etc. and one of one or more memory subsystem s . A channel may thus include one or more buses of any form in any topology and one or more intermediate circuits.

As used herein the term daisy chain e.g. daisy chain bus etc. refers to a bus wiring structure in which for example device e.g. unit structure circuit block etc. A is wired to device B device B is wired to device C etc. In some embodiments the last device may be wired to a resistor terminator or other termination circuit etc. In alternative embodiments any or all of the devices may be wired to a resistor terminator or other termination circuit etc. In a daisy chain bus all devices may receive identical signals or in contrast to a simple bus each device may modify e.g. change alter transform etc. one or more signals before passing them on.

A cascade e.g. cascade interconnect etc. as used herein refers to a succession of devices e.g. stages units or a collection of interconnected networking devices typically hubs or intermediate circuits etc. in which the hubs or intermediate circuits operate as logical repeater s permitting for example data to be merged and or concentrated into an existing data stream or flow on one or more buses.

As used herein the term point to point bus and or link refers to one or a plurality of signal lines that may each include one or more termination circuits. In a point to point bus and or link each signal line has two transceiver connection points with each transceiver connection point coupled to transmitter circuits receiver circuits or transceiver circuits.

As used herein a signal or line signal line etc. refers to one or more electrical conductors or optical carriers generally configured as a single carrier or as two or more carriers in a twisted parallel or concentric arrangement used to transport at least one logical signal. A logical signal may be multiplexed with one or more other logical signals generally using a single physical signal but logical signal s may also be multiplexed using more than one physical signal.

Terms that are special to the field of the invention or specific to this description may in some circumstances be defined in this description. Further the first use of such terms which may include the definition of that term may be highlighted in italics just for the convenience of the reader. Similarly some terms may be capitalized again just for the convenience of the reader. It should be noted that such use of italics and or capitalization by itself should not be construed as somehow limiting such terms beyond any given definition and or to any specific embodiments disclosed herein etc.

In this description there may be multiple figures that depict similar structures with similar parts or components. Thus as an example to avoid confusion an Object in may be labeled Object and a similar but not identical Object in is labeled Object etc. Again it should be noted that use of such protocol by itself should not be construed as somehow limiting such terms beyond any given definition and or to any specific embodiments disclosed herein etc.

In the following detailed description and in the accompanying drawings specific terminology and images are used in order to provide a thorough understanding. In some instances the terminology and images may imply specific details that are not required to practice all embodiments. Similarly the embodiments described and illustrated are representative and should not be construed as precise representations as there are prospective variations on what is disclosed that may be obvious to someone with skill in the art. Thus this disclosure is not limited to the specific embodiments described and shown but embraces all prospective variations that fall within its scope. For brevity not all steps may be detailed where such details will be known to someone with skill in the art having benefit of this disclosure.

This description focuses on improvements to memory systems and in particular to memory systems that include different memory technologies.

Electronic systems and computing platforms may use several different memory technologies faster local memory based on semiconductor memory e.g. SDRAM with access times measured in first units e.g. nanoseconds flash memory e.g. NAND flash with access times measured in second units e.g. microseconds and magnetic media disk drives with access times measured in third units e.g. milliseconds . In some embodiments systems may use higher speed memory e.g. SDRAM etc. on a dedicated high speed memory bus e.g. DDR4 etc. and lower speed memory e.g. NAND flash etc. and or disk storage e.g. disk drive etc. on a separate slower I O bus e.g. PCI E etc. .

In this description several implementations of memory systems are presented that use different memory technologies in combination e.g. SDRAM with NAND flash SRAM with SDRAM etc. . In this description each different memory technology is referred to as a different class of memory in order to avoid any confusion with other terms. For example the term class is used in this context instead of the term memory type or type of memory since memory type is used in some contexts as a term related to caching.

The use of multiple memory classes may in some embodiments allow different trade offs to be made in system design. For example in the 2011 timeframe the cost per bit of DRAM is greater than the cost per bit of NAND flash which is greater than the cost per bit of disk storage. For this reason system designers often design systems that use a hierarchical system of memory and storage. However even though a CPU may be connected to one or more classes of memory e.g. SDRAM NAND flash disk storage systems may use a dedicated memory bus for the fastest memory technology and only one class of memory may be connected to that memory bus. The memory connected to a dedicated memory bus is called main memory. The term main memory will be used which in this description may actually be comprised of multiple classes of memory to distinguish main memory from other memory located on a different bus e.g. USB key etc. or other memory e.g. storage disk drive etc. that is not used as main memory memory that is not main memory may be secondary storage tertiary storage or offline storage for example . The term main memory is used in this context instead of the term primary storage to avoid confusion with the general term storage that is used in several other terms and many other contexts.

In order to build a system with a large amount of memory systems may use a collection of different memory classes that may behave as one large memory. In some embodiments the collection of different memory classes may involve a hierarchy that includes some or all of the following each using different classes of memory main memory or primary storage which may be closest to the CPU followed by secondary storage tertiary storage and possibly offline storage. One possible feature of this approach is that different buses are sometimes used for the different classes of memory. Only the fastest memory class can use the fast dedicated memory bus and be used as main memory for example. When the system needs to access the slower memory classes using a slower I O bus for example this slower memory access can slow system performance and may do so drastically which is very much governed by memory bandwidth and speed.

There may be other reasons that system designers wish to use multiple memory classes. For example multiple memory classes may be used to achieve the fastest possible access speed for a small amount of fast local to the CPU cache to achieve the highest bandwidth per pin since pin packages drive the cost of a system or to achieve a certain overall system price performance cost power etc.

For these and or other reasons it may be advantageous for a system designer to design a system that uses more than one memory class for main memory on a memory bus. Of course it is contemplated that in some embodiments such use of multiple memory classes may not necessarily exhibit one or more of the aforementioned advantages and may even possibly exhibit one or more of the aforementioned disadvantages.

Additionally in various embodiments the physical memory sub system A may include a monolithic memory circuit a semiconductor die a chip a packaged memory circuit or any other type of tangible memory circuit. In one embodiment the physical memory sub system A may take the form of a dynamic random access memory DRAM circuit. Such DRAM may take any form including but not limited to synchronous DRAM SDRAM double data rate synchronous DRAM DDR SDRAM DDR2 SDRAM DDR3 SDRAM etc. graphics double data rate DRAM GDDR GDDR2 GDDR3 etc. quad data rate DRAM QDR DRAM RAMBUS XDR DRAM XDR DRAM fast page mode DRAM FPM DRAM video DRAM VDRAM extended data out DRAM EDO DRAM burst EDO RAM BEDO DRAM multibank DRAM MDRAM synchronous graphics RAM SGRAM and or any other DRAM or similar memory technology.

As shown the physical memory sub system A includes a first memory A of a first memory class and a second memory A of a second memory class. In the context of the present description as set forth earlier a memory class may refer to any memory classification of a memory technology. For example in various embodiments the memory class may include but is not limited to a flash memory class a RAM memory class an SSD memory class a magnetic media class and or any other class of memory in which a type of memory may be classified.

In the one embodiment the first memory class may include non volatile memory e.g. FeRAM MRAM and PRAM etc. and the second memory class may include volatile memory e.g. SRAM DRAM T RAM Z RAM and TTRAM etc. . In another embodiment one of the first memory A or the second memory A may include RAM e.g. DRAM SRAM embedded RAM etc. and the other one of the first memory A or the second memory A may include NAND flash or other nonvolatile memory other memory etc. . In another embodiment one of the first memory A or the second memory A may include RAM e.g. DRAM SRAM etc. and the other one of the first memory A or the second memory A may include NOR flash or other nonvolatile memory other memory etc. . Of course in various embodiments any number e.g. 2 3 4 5 6 7 8 9 or more etc. of combinations of memory classes may be utilized.

The second memory A is communicatively coupled to the first memory A . In the context of the present description being communicatively coupled refers to being coupled in any way that functions to allow any type of signal e.g. a data signal a control signal a bus a group of signals other electric signal etc. to be communicated between the communicatively coupled items. In one embodiment the second memory A may be communicatively coupled to the first memory A via direct contact e.g. a direct connection link etc. between the two memories. Of course being communicatively coupled may also refer to indirect connections connections with intermediate connections therebetween etc. In another embodiment the second memory A may be communicatively coupled to the first memory A via a bus. In yet another embodiment the second memory A may be communicatively coupled to the first memory A utilizing a through silicon via TSV .

As another option the communicative coupling may include a connection via a buffer device logic chip buffer chip FPGA programmable device ASIC etc. . In one embodiment the buffer device may be part of the physical memory sub system A . In another embodiment the buffer device may be separate from the physical memory sub system A .

In one embodiment the first memory A and the second memory A may be physically separate memories that are communicatively coupled utilizing through silicon via technology. In another embodiment the first memory A and the second memory A may be physically separate memories that are communicatively coupled utilizing wire bonds. Of course any type of coupling e.g. electrical optical etc. may be implemented that functions to allow the second memory A to communicate with the first memory A .

The apparatus A is configured such that the first memory A and the second memory A are capable of receiving instructions via a single memory bus A . The memory bus A may include any type of memory bus. Additionally the memory bus may be associated with a variety of protocols e.g. memory protocols such as JEDEC DDR2 JEDEC DDR3 JEDEC DDR4 SLDRAM RDRAM LPDRAM LPDDR etc I O protocols such as PCI PCI E HyperTransport InfiniBand QPI etc networking protocols such as Ethernet TCP IP iSCSI etc storage protocols such as NFS SAMBA SAS SATA FC etc and other protocols e.g. wireless optical etc. etc. .

In one embodiment the physical memory sub system A may include a three dimensional integrated circuit. In the context of the present description a three dimensional integrated circuit refers to any integrated circuit comprised of stacked wafers and or dies e.g. silicon wafers and or dies etc. which are interconnected vertically e.g. stacked compounded joined integrated etc. and are capable of behaving as a single device.

For example in one embodiment the physical memory sub system A may include a three dimensional integrated circuit that is a wafer on wafer device. In this case a first wafer of the wafer on wafer device may include the first memory A of the first memory class and a second wafer of the wafer on wafer device may include the second memory A of the second memory class.

In the context of the present description a wafer on wafer device refers to any device including two or more semiconductor wafers or die dice or any portion or portions of a wafer etc. that are communicatively coupled in a wafer on wafer configuration. In one embodiment the wafer on wafer device may include a device that is constructed utilizing two or more semiconductor wafers which are aligned bonded and possibly cut in to at least one three dimensional integrated circuit. In this case vertical connections e.g. TSVs etc. may be built into the wafers before bonding created in the stack after bonding or built by other means etc.

In another embodiment the physical memory sub system A may include a three dimensional integrated circuit that is a monolithic device. In the context of the present description a monolithic device refers to any device that includes at least one layer built on a single semiconductor wafer communicatively coupled and in the form of a three dimensional integrated circuit.

In another embodiment the physical memory sub system A may include a three dimensional integrated circuit that is a die on wafer device. In the context of the present description a die on wafer device refers to any device including one or more dies positioned on a wafer. In one embodiment the die on wafer device may be formed by dicing a first wafer into singular dies then aligning and bonding the dies onto die sites of a second wafer.

In yet another embodiment the physical memory sub system A may include a three dimensional integrated circuit that is a die on die device. In the context of the present description a die on die device refers to a device including two or more aligned dies in a die on die configuration. Additionally in one embodiment the physical memory sub system A may include a three dimensional package. For example the three dimensional package may include a system in package SiP or chip stack MCM.

In operation the apparatus A may be configured such that the first memory A and the second memory A are capable of receiving instructions from a device A via the single memory bus A . In one embodiment the device A may include one or more components from the following list but not limited to the following list a central processing unit CPU a memory controller a chipset a memory management unit MMU a virtual memory manager VMM a page table a table lookaside buffer TLB one or more levels of cache e.g. L L L etc. a core unit an uncore unit e.g. logic outside or excluding one or more cores etc. etc. . In this case the apparatus A may be configured such that the first memory A and the second memory A are be capable of receiving instructions from the CPU via the single memory bus A .

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing techniques discussed in the context of any of the figure s may or may not be implemented per the desires of the user. For instance various optional examples and or options associated with the configuration operation of the physical memory sub system A the configuration operation of the first and second memories A and A the configuration operation of the memory bus A and or other optional features have been and will be set forth in the context of a variety of possible embodiments. It should be strongly noted that such information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of such features may be optionally incorporated with or without the inclusion of other features described.

In System B comprises a CPU B connected e.g. coupled etc. to Memory B using a single Memory Bus B and connected e.g. coupled etc. to Chipset B using I O Bus B . In Chipset B is coupled to Disk B using I O Bus B . In Memory B comprises memory class B and memory class B . In Memory B may also be the main memory for System B . In memory class B and memory class B may comprise different memory technologies. In Disk B may be secondary storage for System B .

In various different embodiments with reference to and other figures referenced below and other embodiments described below different system components e.g. system blocks chips packages etc. may be constructed e.g. physically logically arranged etc. in different ways the coupling e.g. logical and or physical connection via buses signals wires etc. may be arranged in different ways and the architectures may be arranged in different ways e.g. operations performed in different ways different split e.g. partitioning sectioning assignment etc. of functions between hardware and or software and or firmware etc. but these various differences may not affect the basic descriptions e.g. functions operations theory of operations advantages etc. provided below for each embodiment.

Where appropriate for each embodiment examples of alternative implementations options variations etc. may be described for example where new concepts elements etc. may be introduced in an embodiment. However these alternative implementations are not necessarily repeated for each and every embodiment though application of alternative implementations may be equally possible to multiple embodiments. For example it may be initially explained that a memory component may be constructed from a package that may contain one die or one or more stacked die. These alternative memory component implementations may not be repeatedly explained for each and every embodiment that uses memory components. Therefore the description of each embodiment described here may optionally be viewed as cumulative with respect to the various implementation options alternatives other variations etc. in that each new or different etc. alternative implementation that may be applied to other embodiments should be viewed as having being described as such.

For example in various embodiments memory class and memory class may each be physically constructed e.g. assembled constructed processed manufactured packaged etc. in several ways from one or more memory components from multi chip packages from stacked memory devices etc. In various embodiments memory class and memory class may be integrated on the same die s packaged separately or together in single die package s or multi chip package s stacked separately or together in multi chip packages stacked separately or together in multi chip packages with one or more other chip s as discrete memory components etc.

In different embodiments Memory B may be physically constructed e.g. assembled manufactured packaged etc. in many different ways as DIMM s as component s on a motherboard or other PCB as part of the CPU or other system component s etc.

In one embodiment Memory B may comprise more than two memory classes which may also be physically constructed in the various ways just described.

In one embodiment there may be more than one CPU B . Additionally in one embodiment there may or may not be a Disk B . In another embodiment CPU B may be connected directly to Disk B e.g. there may or may not be a separate Chipset B the function of Chipset B may be integrated with the CPU B etc. . In yet another embodiment one or more CPU s may connect e.g. couple etc. to more than one Memory B .

In various embodiments Memory Bus B may be a standard memory bus e.g. DDR3 DDR4 etc. other standard bus e.g. QPI ARM ONFi etc. a proprietary bus e.g. ARM packet switched parallel multidrop point to point serial etc. or even an I O bus used for memory e.g. PCI E any variant of PCI E Light Peak etc. .

Additionally in different embodiments I O Bus B that couples CPU B to Chipset B may be a standard I O bus e.g. PCI PCI E ARM Light Peak USB etc. a proprietary bus e.g. ARM packet switched parallel multidrop point to point serial etc. or even a memory bus used modified altered re purposed etc. for I O e.g. I O chipset coupling North Bridge to South Bridge coupling etc. purposes e.g. low power DDR etc. . Of course Chipset B or the functions protocol conversion etc. of Chipset B may be integrated with e.g. combined with part of performed by etc. CPU B etc.

Further in various embodiments I O Bus B that couples Chipset B with Disk B may be a standard I O or storage bus e.g. SATA SAS PCI PCI E ARM Light Peak USB InfiniBand etc. a bus used to interface directly with solid state storage e.g. NAND flash SSD etc. such as ONFi 1.0 ONFi 2.0 ONFi 3.0 OneNAND etc a proprietary bus e.g. ARM packet switched parallel multidrop point to point serial etc. a modified bus and or bus protocol e.g. lightweight version of a storage protocol bus for use with NAND flash etc. a networking bus and or networking protocol e.g. Ethernet Internet LAN WAN TCP IP iSCSI FCoE etc. a networked storage protocol e.g. NAS SAN SAMBA CIFS etc. a wireless connection or coupling e.g. 802.11 Bluetooth ZigBee LTE etc. a connection or coupling to offline storage e.g. cloud storage Amazon EC3 Mozy etc. a combination of buses and protocols e.g. PCI E over Ethernet etc. or even a memory bus used modified altered re purposed etc. for I O purposes e.g. low power DDR DDR2 etc. .

In different embodiments for systems similar to based on or using that shown in any of the buses protocols standards etc. operable for I O Bus B may be used for I O Bus B and any of the buses protocols standards etc. operable for I O Bus B may be used for I O Bus B .

Further in various embodiments Memory Bus B and or I O Bus B and or I O Bus B may comprise one or more buses connected in serial one or more buses connected in parallel one or more buses connected in combinations of serial and or parallel one or more buses in series or parallel plus control signals one or more different buses in series plus control signals and many other series parallel data address control etc. bus combinations with various series parallel control signal combinations etc.

In different embodiments Memory Bus B and or I O Bus B and or I O Bus B may comprise one or more buses using different protocols different bus standards different proprietary bus and or protocol formats combinations of these etc.

In different embodiments Memory Bus B and or I O Bus B and or I O Bus B may comprise a point to point bus a multidrop bus a parallel bus a serial bus a split transaction bus one or more high speed serial links combinations of these etc.

For example in one embodiment Memory Bus may be a standard JEDEC e.g. DDR2 DDR3 DDR4 etc. memory bus that comprises a parallel combination of a data bus e.g. 64 bits of data 72 bits e.g. data plus ECC etc. etc. an address bus and control signals.

In another embodiment Memory Bus B may be a standard JEDEC e.g. DDR2 DDR3 DDR4 etc. memory bus or other memory bus that comprises a parallel combination of a data bus e.g. 64 bits of data 72 bits e.g. data plus ECC etc. etc. an address bus and non standard control signals e.g. either in addition to and or instead of standard control signals etc. . In one embodiment control signals may time multiplexed with existing standard control signals. In another embodiment control signals may re use existing control signals or may re purpose existing control signals etc. Of course in various embodiments control signals may also be viewed as data address etc. signals. Equally in one embodiment address data etc. signals that may be part of a bus may also be used as control signals etc. In addition in one embodiment data signals may be used for control signals or address signals etc. For example in some embodiments a Bank Address signal or signals in a DDR protocol may be viewed and or used as a control signal as well as an address signal. In other embodiments one or more Chip Select signals in a DDR protocol may be used as one or more control signals and adapted to be used as one or more address signals etc.

In another embodiment I O Bus B may comprise a wireless connection to offline storage via a combination e.g. series series parallel parallel combination of series and parallel etc. of different buses e.g. I O bus storage bus etc protocols e.g. SATA 802.11 etc. adapters wireless controllers storage controllers network interface cards etc. and different standards and combinations of these etc. For example in some embodiments I O Bus B may be a wireless 802.11 connection that may be coupled to e.g. chained with in series with connected to etc. a cell phone connection that is in turn coupled e.g. in series with coupled to etc. an Ethernet WAN connection etc. Of course in various embodiments these connections may be in any order or of any type.

In different embodiments two or more of Memory Bus B and or I O Bus B and or I O Bus B may share e.g. through time multiplexing through switching through multiplexing e.g. other than time etc. through packet switching etc. some or all of the same connections e.g. wires signals control signals data buses address buses unidirectional signals bidirectional signals PCB traces package pins socket pins bus traces connections logical connections physical connections electrical connections optical connections etc. .

In different embodiments one or more of the bus es that comprise Memory Bus and or I O Bus B and or I O Bus B may be wireless e.g. LTE 802.11 Wi Max etc. . Thus for example in a system that includes a mobile phone e.g. a cellular phone etc. the mobile phone may have some memory e.g. solid state memory disk storage etc. located remotely using a wireless connection in which case one system may be viewed as being the cell phone and another system as being the cell phone plus remote storage .

In different embodiments one or more of the bus es that comprise Memory Bus B and or I O Bus B and or I O Bus B may be optical e.g. Fibre Channel Light Peak use optical components etc. . Thus for example in a system that comprises a server with a requirement for large amounts of high speed memory and having a large power budget etc the CPU may have memory connected via optical cable e.g. optical fiber fibre channel optical coupling etc. .

Of course any technique of coupling e.g. connecting logically and or physically using networks using switches using MUX and deMUX functions encoding multiple functions on one bus etc. may be used for any or all of the buses and to connect any or all of the components that may be coupled.

In different embodiments the multiple memory classes in Memory B and Memory Bus B may be connected e.g. coupled etc. to each other in several different ways depending on the architecture of Memory B . Various embodiments of the architecture of Memory B and the rest of the system are described in detail in exemplary embodiments that follow. It should be noted now however that in order to allow Memory B to contain multiple memory classes and connect e.g. couple etc. to CPU B other components e.g. chips passive components active components etc. may be part of Memory B or otherwise connected e.g. coupled joined integrated etc. with the multiple memory classes . Some other components their functions and their interconnection s which in various embodiments may be part of Memory B are described in detail below. It should be noted that these other components their functions and their interconnection s which may be part of Memory B may not necessarily be included or be shown in all figures.

A VMy may contain pages that may be either located e.g. resident stored etc in main memory or in a page file also called a swap file . In a System includes a CPU coupled to Memory using Memory Bus and coupled to Disk using I O Bus . The system of is similar to except that the Disk is coupled directly to CPU in .

In some high end CPUs the function of chipset South Bridge disk controller etc. may be integrated but in some low end systems and consumer devices for example it may not be integrated. It should be noted that in any of the embodiments shown or described herein a chipset South Bridge disk controller I O controller SATA controller ONFi controller PCI E controller etc. may or may not be connected to the CPU and or may or may not be integrated with the CPU.

In memory class memory class and memory class located on Disk may together form VMy . In memory class and memory class may form the Main Memory . In memory class located on Disk may contain the Page File. In memory class is not part of main memory but in other embodiments it may be . In the Data of Disk may be used for data storage and is not part of VMy but in other embodiments it may be .

In one embodiment memory class memory class and memory class may be composed of e.g. logically comprise etc. multiple different classes of PM e.g. selected from SRAM SDRAM NAND flash embedded DRAM PCRAM MRAM combinations of these and or other memory types etc. .

In all of Memory which included multiple memory classes may be main memory for System . In regions of memory are labeled as memory main memory and virtual memory. In the regions labeled memory and main memory are the same but this is not always so in other embodiments and thus may stretch the precision of the current terminology. Therefore in system components are labeled using a taxonomy that will help explain embodiments that contain novel aspects for which current terminology may be inadequate. In this case elements of CPU cache terminology are borrowed. Thus in the CPU Core is shown as coupled to L Cache and indirectly hierarchically to L Cache . The L Cache and L Cache form a hierarchical cache with L Cache being logically closest to the CPU. Using a similar style of labeling in for the VMy components memory class is labeled as M Memory memory class as M Memory and memory class as M Memory M M M may generally be used but it should be understood that this is a short abbreviation L Cache as just will be referred to L . M may also be referred to as primary memory M as secondary memory M as tertiary memory etc.

The logical labels for CPU cache L and L etc say nothing about the physical technology e.g. DRAM embedded DRAM SRAM etc. used to implement each CPU cache. In the context of the present description there is a need to distinguish between memory technologies used for VMy components M M etc. because the technology used affects such things as system architecture buses protocols packaging etc. Thus following a similar style of labeling to the VMy components in memory class is labeled as C memory class as C and memory class as C. Note that number assigned to memory class and the number assigned to the logical position of the class are not necessarily the same. Thus both M and M may be built from memory class e.g. where memory class might be SDRAM etc. . For example a component of memory may be referred to as M.C which refers to M composed of memory class .

In buses are also labeled as B for Memory Bus and B for I O Bus . Memory bus technologies and I O bus technologies are deliberately not distinguished because the embodiments described herein may blur merge and combine etc. those bus technologies and to a great extent various embodiments remove the distinctions between I O bus technologies and memory bus technologies . The concept of hierarchy in bus technologies may be maintained. Thus when it is convenient B and B may be used to point out that B may be closer to the CPU than B. It should be noted that in many situations e.g. architectures implementations embodiments etc. it is sometimes hard to define what closer to the CPU means with a bus technology. Nevertheless in for example B is regarded as being closer e.g. lower latency in this case to the CPU than bus B. Thus B may be referred to as the primary bus B as the secondary bus etc. The Page File in may be referred to as being memory B.M.C e.g. tertiary memory M is constructed of memory class technology and is located on secondary bus B.

In general though not necessarily always M may be logically closest to the CPU M next and so on. If there is a situation in which for example M and M are not in that logical position and there is possible confusion this may be pointed out. It may not be obvious why the distinction between M and M might not be clear thus some embodiments may be described where the distinction between M and M or M and M M and M etc. is not always clear.

In one embodiment for example memory may be composed of M and M with two different technologies e.g. C and C but both connected to the same bus e.g. at the same logical distance from the CPU in that case it may be the case that both technologies are M and thus there may be M. C and M.C for example or it may be the case that if one technology has lower latency for example C than that faster technology is M because it is closer to the CPU in the sense of lower latency and thus there is M.C with the other slower technology C being M and thus M.C .

In another embodiment a technology C used for M may be capable of operating in different modes and is used in a memory system together with technology C used as M. Suppose for example mode 1 of C is faster than C but mode 2 of C is slower than M. In that case the roles of C and C used as M and M for example may be reversed in different modes of operation of C. In this case where the fastest memory is defined as being closer to the CPU terminology may be used to express that memory is composed of M.C and M.C when C is in mode 1 and memory is composed of M.C and M.C when C is in mode 2.

In that portion of Disk and Secondary Storage that is used for Data as labeled as D. This notation may be helpful in certain embodiments where the distinction between for example page file regions of a disk or memory and data regions of a disk or memory needs to be clear. Although not labeled in if the data region uses memory class disk technology in the data region of the disk may be labeled as B.C.D in for example and the page file labeled memory class in may be more accurately referred to as B.C.M .

In some embodiments different memory technologies e.g. solid state RAM DRAM SDRAM SRAM NAND flash MRAM etc. as well as storage technologies e.g. disk SSD etc. all have individual and different physical logical electrical and other characteristics and thus each technology may for example have its own interface signaling scheme protocol etc. For example DRAM memory systems may use extremely fast e.g. 1 GHz clock frequency or higher etc. and reliable e.g. ECC protected parity protected etc. memory bus protocols that may be industry standards e.g. JEDEC standard DDR2 DDR3 DDR4 protocols etc. Disks e.g. mechanical SSD etc. may use fast reliable and easily expandable storage device protocols that may be industry standards e.g. ANSI INCITS T10 T11 and T13 standards such as SCSI SATA SAS protocols etc. and may be attached e.g. coupled connected etc. via a controller storage controller adapter host bus adapter HBA etc. to I O bus protocols that may also be industry standards e.g. PCI SIG standards such as PCI Express PCI etc.

The following definitions and the following explanation of the operation of a VMy are useful in the detailed description of different and various embodiments of the memory system below.

To create the illusion of a large memory using a small number of expensive memory components together with other cheaper disk components a system may employ VMy. The information e.g. data code etc. stored in memory is a memory image. The system e.g. OS CPU combination of the OS and CPU etc. may divide e.g. partition split etc. a memory image into pages or virtual pages and a page of a memory image can at any moment in time exist in fast but expensive main memory or on slower but much cheaper secondary storage e.g. disk SSD NAND flash etc. or both e.g. main memory and secondary storage . A page may be a continuous region of VMy in length a standard length or size is 4 096 byte 4 kB the page size . A page may be page aligned that is the region e.g. portion etc. of a page starts at a virtual address VA evenly e.g. completely exactly etc. divisible by the page size. Thus for example a 32 bit VA may be divided into a 20 bit page number and a 12 bit page offset or just offset .

System may contain an operating system OS . For an OS that uses VMy every process may work with a memory image that may appear to use large and contiguous sections of PM. The VMy may actually be divided between different parts of PM or may be stored as one or more pages on a secondary storage device e.g. a disk . When a process requests access to a memory image the OS may map or translate the VA provided by the process to the physical address PA or real address . The OS may store the map of VA to PA in a page table.

A memory management unit MMU in the CPU may manage memory and may contain a cache of recently used VA to PA maps from the page table. This cache may be the translation lookaside buffer TLB . When a VA in VMy needs to be translated to a PA the TLB may be searched a TLB lookup for the VA. If the VA is found a TLB hit the corresponding PA may be returned and memory access may continue. If the VA is not found a TLB miss a handler may look up the address map in the page table to see whether the map exists by performing page table lookup or page walk. If the map exists in the page table the map may be written to the TLB. The instruction that caused the TLB miss may then be restarted. The subsequent VA to PA translation may result in a TLB hit and the memory access may continue.

A page table lookup may fail a page miss for two reasons. The first reason for a page miss is if there is no map available for the VA and the memory access to that VA may thus be invalid e.g. illegal erroneous etc. . An invalid access should be a rare event and may occur because of a programming error etc and the operating system may then send a segmentation fault to the process and this may be a fatal event. The second and normal reason for a page miss is if the requested page is not resident e.g. present stored etc. in PM. Such a page miss may happen when the requested page e.g. page has been moved out of PM and written to the page file e.g. disk normally in order to make room for another page e.g. page . The usual term for this process is swapping hence the term swap file and it may be said that the pages e.g. page and page have been swapped. When this page miss happens the requested page needs to be read often referred to as fetched from the page file on disk and written back into PM. This action is referred to a page being swapped out from main memory to disk and the page file and or swapped in from the disk and page file to main memory .

There are two situations to consider on a page miss the PM is not full and PM full. When the PM is not full the requested page may be fetched from the page file written back into PM the page table and TLB may be updated and the instruction may be restarted. When the PM is full one or more pages in the PM may be swapped out to make room for the requested page. A page replacement algorithm may then choose the page s to swap out or evict to the page file. These evicted page s may then be written to the page file. The page table may then be updated to mark the evicted page s that were previously in PM as now in the page file. The requested page may then be fetched from the page file and written to the PM. The page table and TLB may then be updated to mark the requested page that was in the page file as now in the PM. The TLB may then be updated by removing reference s to the evicted page s . The instruction may then be restarted.

In a System includes a CPU coupled to Memory using Memory Bus and coupled to Disk using I O Bus . In memory class M memory class M and memory class M located on Disk together form VMy . In memory class and memory class form the Main Memory . In memory class located on Disk contains the page file. In memory class is not part of Main Memory but in other embodiments it may be .

In a page of memory for example Page X is located in memory class but is not immediately needed by the CPU . In some embodiments memory class may be small and fast but expensive memory e.g. SDRAM SRAM etc. . In this case Page X may be fetched from memory class and copied to a location on larger slower but cheaper secondary storage e.g. Page X . In order to complete the transfer of Page X from memory class to Disk the data comprising Page X may be copied e.g. transferred moved. etc. as Copy over Memory Bus through CPU through I O Bus to the location of Page X on Disk . This process of Copy may in some embodiments free up precious resources in memory class . However one possible result is that the process of Copy may consume time and may also consume various other resources including bandwidth e.g. time delay etc. on Memory Bus bandwidth e.g. time delay etc. on I O Bus bandwidth e.g. time delay etc. and write latency e.g. delay cycles etc. of Disk and possibly also resources e.g. cycles etc. from the CPU . In addition another possible result may be that power is consumed in all these operations.

In different embodiments the Copy may be part of a page swap a page move a write to disk etc. If Copy is part of a page swap then the next operation may be to copy Page Y to memory class in order to replace Page X .

In some embodiments the system designer may accept the trade offs just described and design a system having the memory architecture shown in . In other embodiments that are described below some of these trade offs just described may be changed improved or otherwise altered etc. by changing the architecture of the memory system.

In other embodiments based on that shown in and or based on other similar embodiments described elsewhere Disk may be remote storage using e.g. SAN NAS using a network such as Ethernet etc. and a protocol such as iSCSI FCoE SAMBA CIFS PCI E over Ethernet InfiniBand USB over Ethernet etc cloud storage using wired or wireless connection s RAID storage JBOD SSD combinations of these etc. and where the storage may be disk s SSD NAND flash SDRAM RAID system s combinations of these etc.

In a System includes a CPU coupled to Memory using Memory Bus and coupled to Disk using I O Bus . In memory class M memory class M and memory class M located on Disk together form VMy . In memory class and memory class form the Main Memory . In memory class located on Disk contains the page file. In memory class is not part of Main Memory but in other embodiments it may be .

In a page of memory e.g. Page Y etc. is located on Disk but is immediately needed by the CPU In some embodiments memory class may be small and fast but expensive memory e.g. SDRAM SRAM etc. . In this case Page Y located on larger slower but cheaper secondary storage e.g. Page Y may be fetched from and copied to a location in memory class . In order to complete the transfer of Page Y from Disk to memory class the data comprising Page Y is copied e.g. transferred moved. etc. as Copy through I O Bus through CPU over Memory Bus to the location of Page X to memory class . This process of Copy may in some embodiments allow for providing CPU faster access to Page Y. However the process of Copy may in some embodiments allow for consuming time and may also consume various other resources including bandwidth e.g. time delay etc. on Memory Bus bandwidth e.g. time delay etc. on I O Bus bandwidth e.g. time delay etc. and write latency e.g. delay cycles etc. of Disk and possibly also resources e.g. cycles etc. from the CPU . In addition power is consumed in all these operations.

The operations in the systems of and are described separately above but it should be noted that that if the operations e.g. steps actions etc. shown in are performed e.g. Copy copying Page X from main memory to the swap file etc. followed by the operations shown in e.g. Copy copying Page Y from the swap file to main memory etc. in a system Page X shown as Page X in and Page Y are swapped in main memory with the final result being as shown in . These page swapping operations are a sequence of operations that may be performed via a virtual memory manager VMM or in virtual memory management. The time power and efficiency of these VMM operations including page swapping are an element of system design and architecture.

In some embodiments memory class in and memory class in may be small and fast but expensive memory e.g. SDRAM SRAM etc. as described above. In certain embodiments memory class in and memory class in may be faster than memory class in and memory class in . In these embodiments the page eviction and page fetch are from for eviction and to for fetch the faster part of main memory.

In other embodiments it may be desirous e.g. for reasons of cost power performance etc. for memory class in and memory class in to be slower than memory class in and memory class in . In these embodiments the page eviction and page fetch are from and to the slower part of main memory.

Of course there may be possible trade offs in the design of systems similar to those shown in and e.g. portable consumer devices servers laptops cell phones tablet PCs etc. . For example in some embodiments it may be desirous to perform swapping to and from a memory class that has one or more of the following properties relative to other memory classes in main memory consumes less power e.g. LPDDR rather than DDR low voltage memory etc. is more reliable e.g. uses ECC protection LDPC protection parity protection etc. is removable e.g. USB key ReadyBoost etc. can be remotely connected more easily e.g. SAN NAS etc. is more compact e.g. embedded DRAM rather than SRAM flash rather than SRAM etc. is cheaper e.g. flash rather than SDRAM disk rather than SDRAM etc. can be more easily integrated with other component s e.g. uses the same protocol uses compatible process technology etc. has a more suitable protocol e.g. ONFi DDR etc. is easier to test e.g. standard DDR SDRAM with built in test BIST etc. etc. is faster e.g. SRAM rather than flash etc. has higher bandwidth e.g. DDR3 rather than DDR2 higher bus widths etc. can be stacked more easily e.g. appropriate relative die sizes for stacking for TSV stacking wirebond etc. using TSVs with compatible process technologies etc can be packaged more easily e.g. NAND flash with relatively low clock speeds may be wirebonded etc. can be cooled more easily e.g. lower power NAND flash low power SDRAM LPDDR etc. and or any combinations of these etc.

In other embodiments the decision to swap pages to from a certain memory class may be changed e.g. by configuration by the system CPU OS etc under program control etc. . For example a system may have main memory comprising memory class and memory class and suppose memory class is faster than memory class but memory class consumes more power than memory class . In one embodiment the system may have a maximum performance mode for which the system e.g. CPU OS etc. may use memory class to swap to from. The system may then have a maximum battery life mode in which the system may use memory class to swap to from.

In the process of page eviction in a VMy system is described but the process of page eviction may be similar to a data write from main memory to disk. In the process of page fetch in a VMy system is described but the process of page fetch may be similar to a data read from disk to main memory. Thus the same issues trade offs alternative embodiments system architectures etc. that was described with regard to the systems in and and systems similar to those systems are relevant and may be used in systems that do not use a VMy architecture but that may still benefit from the use of main memory with multiple memory classes. Thus the descriptions and concepts may be broadened and therefore implement a variety of embodiments described to the physical memory sub system general I O and data movement rather than just the page operations involved in VMM. Of course general I O and data movement may involve copying moving shifting replicating etc. different sizes of data other than a page.

In some embodiments the system e.g. OS CPU etc. may track e.g. with modified page table s etc. which pages are located in which memory class in main memory. Descriptions of various embodiments that follow describe how the system e.g. OS CPU etc. may communicate e.g. signal command send control information receive status etc. with the memory to for example transfer e.g. copy move DMA etc. data e.g. pages cache lines blocks contiguous or non contiguous data structures words bytes any portion of memory or storage etc. between multiple memory classes.

In other embodiments the main memory system may autonomously e.g. without knowledge of the CPU OS etc. decide which pages are located in which memory class in main memory. For example data may be moved from one memory class to another due to constraints such as power performance reliability e.g. NAND flash wear out etc. available memory space etc. Such an embodiment may be opted for because since the CPU and or OS are oblivious that anything has changed an implementation may require minimal changes to CPU and or OS etc. For example suppose a system has main memory comprising memory class and memory class . Suppose that a page or any other form portion group etc. of data a page will be used for simplicity of explanation here and subsequently is moved from memory class to memory class . There may be a need for some way to hide this page move from the CPU. One reason that the use of a VMy system in and the process of page swapping in and is described is that in some embodiments the memory management systems e.g. VMM in CPU MMU in CPU software in OS combinations of these possibly with new hardware and or software etc. may be used to allow the main memory to hide either partially or completely from the CPU and or OS the fact that there are multiple memory classes present.

In some embodiments the system designer may accept the trade offs just described and design a system with or similar to the architecture shown in and in that may include some form of secondary storage for paging. In other embodiments the slower speeds of disk I O and secondary storage may lead to the functions of disk and secondary storage being moved to one or more of the memory classes in main memory. Such optional embodiments are described in more detail below.

In various embodiments the page swap functions and memory reads writes may still involve some form of secondary storage but be more complex than that described already. For example page eviction to make room for another page may occur using a copy from one memory class in main memory the eviction class to another memory class but still in main memory rather than secondary storage possibly followed by a copy to secondary storage e.g. disk etc. . In another embodiment page fetch may be a copy from secondary storage to one memory class in main memory the fetch class not necessarily the same as the eviction class and then another copy to a second memory class in main memory.

In different embodiments page files or any other data page files are used for simplicity of explanation may exist just in secondary storage just in main memory in more than one memory class in main memory or using combinations of these approaches and such combinations may change in time . Copies of page files or any other data page files are used for simplicity of explanation may be kept in various memory classes in main memory under configuration and or system control etc. Further and more detailed explanations of such optional embodiments are described below.

In different embodiments the fetch class the eviction class the class or classes assigned to each of the fetch class and the eviction class may be changed in various ways dynamically at start up at boot time via configuration etc.

Of course as already discussed a page fetch operation may be analogous to a disk or other I O read and a page eviction may be analogous to a disk or other I O write thus the preceding description of alternative architectures and logical structures for a system that does use VMy with main memory using multiple memory classes and page swapping applies equally to systems that do not use VMy but still perform disk or other I O.

The systems in and have been described in terms of a VMy system but the concept of swapping regions of the memory image in and out of main memory is a more general one. For example machines without dedicated VMy support in the CPU may use overlays in order to expand main memory in still other possible embodiments.

In general using overlays or overlaying may involve replacement of a block e.g. region portion page etc. of information stored in a memory image e.g. instructions code data etc. with a different block. The term blocks is used for overlays to avoid confusion with pages for a VMy but they may be viewed as similar e.g. though page size s and block size s etc. may be different there may be variable overlay block sizes software and hardware used to manipulate pages and blocks may be different etc. . Overlaying blocks allows programs to be larger than the CPU main memory. Systems such as embedded systems cell phones etc. may use overlays because of the very limited size of PM e.g. due to cost space etc. . Other factors that may make the use of overlays in systems such as those shown in and more attractive than VMy may include one or more of the following the PM may be integrated or packaged with die stacked etc. a system on chip e.g. SoC CPU FPGA etc. further limiting the PM size any CPU if used may not have a VMy MMU any OS if used may be a real time OS RTOS and the swapping of overlay blocks may be more deterministic than page swapping in VMy any OS used may not support VMy etc. For the same reasons that one may opt for use of main memory with multiple memory classes for a VMy system one may also opt to use main memory with multiple memory classes for an overlay system or any other system that may require more main memory than PM available . Thus even though the use of VMy may be described in a particular embodiment any embodiment may equally use overlays or other techniques.

In some embodiments one may opt to use overlays even if the system supports e.g. is capable of using uses etc. VMy. For example in some systems using VMy overlays may be used for some components e.g. software programs code data database bit files other information etc. that may then be loaded as needed. For example overlays may be kept in memory class and swapped in and out of memory class as needed.

Of the time consuming e.g. high delay high latency etc. operations mentioned above the most time consuming highest latency operations may be those operations involving access to the disk s e.g. with rotating magnetic media etc. . Disk access times in 2011 may be 10 s of milliseconds ms 10 3 seconds or 10 million times slower compared to the access times for DRAM of a few nanoseconds ns 10 9 seconds or faster. Though caching may be employed in systems where faster access times are required there is a performance penalty for using disk or other secondary storage separate from main memory etc. in a system with VMy overlays etc. Thus in mobile consumer devices for example one embodiment may eliminate the use of a disk or other secondary storage separate from main memory etc. for paging etc. A potential replacement technology for disk is NAND flash. A simple approach would be to replace the rotating disk used as secondary storage on the I O bus with a faster SSD based on NAND flash technology. For reasons explained in the embodiments described below one may opt to integrate technologies such as NAND flash or other similar memory types etc. into main memory. The next several embodiments describe how the integration of different memory technologies into main memory may be achieved.

In explaining the copy operations corresponding to memory reads in the context of optional features that may be achieved using multiple classes in main memory will be described. In a System includes a CPU coupled to Memory using Bus coupled to Storage using Bus and coupled to Storage using Bus . In Storage contains Data . In Storage contains Data . In memory class memory class with memory class and memory class both located on Storage together form VMy . In memory class and memory class form the Main Memory . In memory class forms a cache for Storage and Disk . In memory class located on Storage contains the page file. In memory class and memory class are not part of Main Memory but in other embodiments they may be .

In various alternative copy operations Copy Copy Copy Copy Copy Copy Copy have been diagrammed. These copy operations perform on various pages Page Page Page Page Page Page Page .

It should be noted that the term copy should be broadly construed in that each copy may in various embodiments be a a true copy e.g. element in location before a copy operation and two elements after a copy operation element in location and element in location with element being an exact copy of element b a move e.g. element in location before the copy operation and element in location after the copy operation c copy or move using pointers or other indirection d copy with re location element in location before the copy operation and two elements after the copy operation element in location and element in location with element being an exact copy of element but locations and being different e combinations of these and or other move and or copy operations etc.

In some embodiments a copy of types a e may result for example from software or other algorithm etc. involved that may not be described in each and every embodiment and that in general may or may not be implemented in any particular embodiment.

Copy shows a copy from memory class to memory class . This copy may be part of a page eviction or a write for example. Copy uses Bus and Bus as well as CPU resources. The lines of Copy in have been drawn as straight lines next to parallel with the bus es that is are being used during the copy but the lines have not necessarily been drawn representing the other copies in a similar fashion.

Copy may follow Copy . For example suppose that memory class may act as a cache for Storage then Copy shows a next action following Copy . In the case of Copy the write completes to memory class . Supposing that memory class located on Storage contains the page file then Copy and Copy together represent a page eviction.

Copy may be an alternative to Copy . For various reasons one may opt to perform Copy instead of Copy . For example Copy may take longer than the time currently available Copy may consume CPU resources that are not currently available Copy may require too much power at the present time etc. Copy copies from memory class to memory class within Main Memory . For example in the case of page eviction a page is evicted to memory class instead of to the page file on Storage . In some embodiments two page files may be maintained one on Storage and one in memory class for example memory class may contain more frequently used pages etc. . In other embodiments Copy may be treated as a temporary page eviction and complete the page eviction or data write in the case of a data write to Storage at a later time. Note that in contrast to Copy and depending on how the Main Memory is constructed Copy may not require Bus or CPU resources or may at least greatly decrease demands on these resources and alternative embodiments and architectures will be described for Main Memory that have such resource saving features below. These features may accompany using main memory with multiple memory classes. In different embodiments the page eviction or data write may be completed in different ways two examples of which are described next.

Copy shows the first part of the case e.g. represents an action performed in which for example a temporary page eviction is reversed or page eviction completed etc. . Suppose for example that Copy has been performed and Copy is treated as a temporary eviction and following Copy possibly after a controlled delay etc. it is desired to complete a page eviction or write in the case of a data write to Storage . Depending on how the system is capable of writing to Storage Copy may be performed next that may reverse the page eviction from memory class . In some cases actions such as Copy followed by Copy may not necessarily not copy a page back to its original source memory location but to a newly released and different target location as shown in and thus the temporary eviction may not be necessarily exactly reversed even though it may help to think of the action as a reversal . In the case that the system always writes pages to memory class and thus Storage from memory class e.g. due to main memory bus architecture DMA architecture etc. Copy should be performed before a copy such as Copy is performed to complete the page eviction similarly for a data write . Note that Copy as was the case for Copy may in certain embodiments not require Bus and CPU resources.

Copy shows the second part of the case e.g. represents an action performed in which for example a temporary page eviction is reversed or page eviction completed etc. . Copy completes a page eviction or data write using a copy of an evicted page from memory class to memory Class and thus to Storage . In other embodiments copies directly from memory class to memory class and thus to Storage may be performed and in that case Copy and Copy may be combined into one operation and avoid the need to request or consume etc. any space in memory class .

Copy is the equivalent to Copy but corresponds to or performs a data write to Storage rather than a page eviction. In the case of the page eviction the write Copy completes to memory class which is part of VMy and contains the page file on Storage . In the case of a data write Copy the write completes to Storage in a region that is outside the VMy.

Copy shows the copy of a page to Storage . Copy may correspond to a data write since in Storage is not part of the VMy though in other embodiments it may be . In the same way that Copy etc. was used to delay postpone etc. Copy applied to a page eviction the same technique s may be used to delay a data write. Thus for example instead of performing Copy immediately the following actions e.g. under program control direction of the CPU direction of the OS direction of the main memory in a configurable or dynamic fashion etc. may be performed first perform a Copy second perform a Copy third perform a Copy .

Such a delay or other similar write manipulation etc. might be opted for in many situations. For example in the case described above where Storage is remote possibly on a wireless connection that may be unreliable e.g. intermittent etc. or consumes more power than presently available etc one may in some embodiments opt to temporarily store writes that may then be completed at a later time etc.

In one embodiment such delayed data writes may be used with techniques such as performing the writes to log files etc. to allow interruptions of connectivity avoid data corruption etc.

In another embodiment data writes may be aggregated e.g. multiple writes combined into a single write etc. . Write aggregation may exhibit various optional features including but not limited to improved bandwidth reduced power reduced wear in NAND flash etc.

In another embodiment data writes may be combined e.g. multiple writes to the same location are collapsed together resulting in many fewer writes . Write combining offers several possible features including but not limited to reduced NAND flash write amplification e.g. the tendency of a single data write to an SSD which may use NAND flash for example to generate multiple writes internally to the SSD leading to rapid wear out of the NAND flash etc. reduced power improved bandwidth and performance etc.

In explaining the copy operations corresponding to memory writes in the context of optional features will be described that may be achieved using multiple classes in main memory. In a System includes a CPU coupled to Memory using Bus coupled to Storage using Bus and coupled to Storage using Bus . In Storage contains Data . In Storage contains Data . In memory class memory class with memory class and memory class both located on Storage together form VMy . In memory class and memory class form the Main Memory . In memory class forms a cache for Storage and Disk . In memory class located on Storage contains the page file. In memory class and memory class are not part of Main Memory but in other embodiments they may be .

In general the copy operations shown in correspond to operations that generally write to e.g. in the direction towards or complete at etc. memory class and are thus opposite in their direction to those similar copy operations shown in .

In various alternative copy operations Copy Copy Copy Copy Copy Copy Copy have been diagrammed. These copy operations perform on various pages Page Page Page Page Page Page Page .

It should be noted that as in the description of each copy may be a a true copy e.g. element in location before a copy operation and two elements after a copy operation element in location and element in location with element being an exact copy of element b a move e.g. element in location before the copy operation and element in location after the copy operation c copy or move using pointers or other indirection d copy with re location element in location before the copy operation and two elements after the copy operation element in location and element in location with element being an exact copy of element but locations and being different .

In some embodiments a copy of types a d may result for example from software or other algorithm etc. involved that may not be described in each and every embodiment and that in general may not be relevant to the embodiment description.

Copy shows a copy from memory class to memory class . This copy could be part of a page fetch or a read for example. Copy uses Bus and Bus as well as CPU resources.

Copy normally precedes Copy but may not always do so. For example suppose that memory class may act as a cache for Storage then Copy may not be required if the page requested is in cache. In the case of Copy the read is from memory class . Supposing that memory class located on Storage contains the page file then Copy and Copy together represent a page fetch. In one embodiment all pages or most frequently used pages etc. may be kept in memory class .

Copy copies from memory class to memory class within Main Memory . In some embodiments two page files may be maintained one on Storage and one in memory class for example memory class may contain more frequently used pages etc. . In this case Copy may represent a page fetch from memory class . Note that in contrast to Copy and depending on how the Main Memory is constructed Copy may not require Bus or CPU resources or may at least greatly decrease demands on these resources and alternative embodiments and architectures will be described for Main Memory that have such resource saving features below.

Copy shows the second part of the case e.g. represents an action performed in which for example a page is fetched. Depending on how the system is capable of reading from Storage Copy may be performed before Copy is performed. Thus in the case that the system always reads pages from memory class and thus Storage to memory class e.g. due to main memory bus architecture DMA architecture etc. then Copy is performed before a copy such as Copy is performed to complete the page fetch similarly for a data read . Note that Copy as was the case for Copy exhibits an optional feature that in certain embodiments the copy may not require Bus and CPU resources.

Copy shows the first part of the case e.g. represents an action performed in which for example a page is fetched. Copy performs a page fetch using a copy of a requested page from memory class to memory Class and thus from Storage . In other embodiments a copy may be performed directly to memory class from memory class and thus from Storage and in that case Copy and Copy may be combined into one operation and the need to request or consume etc. any space in memory class may be avoided.

Copy is the equivalent to Copy but corresponds to or performs a data read from Storage rather than a page fetch. In the case of the page fetch the read Copy reads from memory class which is part of VMy and contains the page file . In the case of a data read Copy the read is from Storage in a region that is outside the VMy.

Copy shows the copy of a page from Storage . Copy may correspond to a data read since in Storage is not part of the VMy though in other embodiments it may be . In the case described above where Storage is remote possibly on a wireless connection that may be unreliable e.g. intermittent etc. or consumes more power than presently available etc one may in some embodiments opt to temporarily or permanently for a certain period of time etc. store data in memory class that would otherwise need to be read over an unreliable link. In one embodiment such caching may be used with techniques such as monitoring data use etc. to allow interruptions of connectivity avoid data corruption etc. For example suppose a user fetches maps on a cell phone via a wireless connection. This would involve operations such as Copy . The map data may then be stored using copy operations already described in for example in memory class . If the wireless connection is interrupted map data may then be read from memory class using operations such as Copy for example . In other embodiments data may also be stored or instead be stored in a configurable manner be stored dynamically be stored under program control be stored etc. in Storage .

As shown a first instruction is received the first instruction being associated with a copy operation. See operation . The first instruction may include any instruction or instructions associated with a copy command or being capable of initiating a copy command or operation. For example in various embodiments the first instruction may include one or more copy operations one or more read instructions associated with at least one copy command one or more write commands associated with at least one copy operation various other instructions and or any combination thereof.

In response to receiving the first instruction a first page of memory is copied to a second page of memory where at least one aspect of the copying of the first page of memory to the second page of memory is independent of at least one aspect of a CPU operation of a CPU. See operation . In the context of the present description a page of memory refers to any fixed length block of memory that is contiguous in virtual memory.

In operation an apparatus including a physical memory sub system may be configured to receive the first instruction and copy the first page of memory to the second page of memory. In one embodiment the first page of memory may be copied to the second page of memory while the CPU is communicatively isolated from the physical memory sub system. In the context of the present description being communicatively isolated refers to the absence of a signal e.g. an electrical signal a control and or data signal etc. at a given time. In one embodiment the apparatus may be configured such that the communicative isolation includes electrical isolation e.g. disconnect switched out etc. .

In another embodiment the physical memory sub system may include logic for executing the copying of the first page of memory to the second page of memory independent of at least one aspect of the CPU operation. For example the first page of memory may be copied to the second page of memory independent of one or more CPU copy operations. As another example the first page of memory may be copied to the second page of memory independent of one or more CPU write operations. In still another embodiment the first page of memory may be independently copied to the second page of memory by accomplishing the same without being initiated controlled and or completed with CPU instructions.

In still another embodiment the physical memory sub system may include at least two classes of memory. As an option the first page of memory may be resident on a first memory of a first memory class and the second page of memory may be resident on a second memory of a second memory class. In this case the logic may be resident on the first memory of the first memory class and or on the second memory of the second memory class. In another embodiment the logic may be resident on a buffer device separate from the first memory and the second memory.

As noted in one embodiment a first page of memory may be copied to a second page of memory where at least one aspect of the copying of the first page of memory to the second page of memory being independent of at least one aspect of a central processing unit CPU operation of a CPU. In various embodiments different aspects of the copying may be independent from the CPU operation. For example in one embodiment reading of the first page of memory may be independent of a CPU operation. In another embodiment a writing of the second page of memory may be independent of a CPU operation. In either case as an option the at least one aspect of the CPU operation may include any operation subsequent to an initiating instruction of the CPU that initiates the copying.

The copying may be facilitated in different ways. For example in one embodiment a buffer device e.g. logic chip buffer chip etc. may be configured to participate with the copying. The buffer device may be part of the physical memory sub system or separate from the physical memory sub system.

In one embodiment the first instruction may be received via a single memory bus. For example the physical memory sub system A of may include the first page of memory and the second page of memory. In this case the first instruction may be received via the single memory bus A .

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing techniques discussed in the context of any of the present or previous figure s may or may not be implemented per the desires of the user. For instance various optional examples and or options associated with the operation the operation and or other optional features have been and will be set forth in the context of a variety of possible embodiments. It should be strongly noted that such information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of such features may be optionally incorporated with or without the inclusion of other features described.

In a System includes a CPU coupled to Memory and coupled to Storage using Bus . In memory class memory class with memory class and memory class both located on Storage together form VMy . In memory class forms a cache for Storage . In memory class located on Storage contains the page file.

In one embodiment the copy operations shown in may in one embodiment correspond to operations shown in and in . Note that the copy operations in use double headed arrows to simplify the diagram but any single copy operation may perform its operation in one direction.

In there is just one single bus Bus for the CPU to access the entire VMy. In there may be other changes to memory and main memory.

In and in main memory and memory were equivalent. In they may not necessarily be equivalent. In Memory includes Main Memory as a subset. In Memory includes VMy as a subset.

In one embodiment main memory e.g. primary memory primary storage internal memory etc. may include memory that is directly accessible to the CPU. In for example memory class and memory class which may be part of secondary storage in various alternative embodiments may now be considered part of main memory and thus not as drawn in . In the context of the present description this may be refer to as Embodiment A of main memory. In in Embodiment A main memory would then comprise memory class memory class memory class and memory class . In in the context of Embodiment A VMy would then be the same as main memory.

In an alternative Embodiment B of main memory the role of memory class in may be considered as cache and memory class in as storage and thus not part of Main Memory . In Embodiment B Main Memory comprises memory class and memory class .

In an alternative Embodiment C of main memory one could take into consideration the fact that main memory is equivalent to primary storage and thus reason that anything equivalent to secondary storage is not main memory. With this thinking main memory may in one embodiment include M only and M is equivalent to secondary storage. In Embodiment C only memory class in would be main memory.

In Embodiment B is adopted. has been used to point out the difficulty of using the term main memory in systems such as that shown in . In embodiments where there is the possibility of confusion use of the term main memory has been avoided.

In one embodiment memory may include the PM coupled to the CPU. In such embodiment of Memory is the memory coupled to the CPU . Note that in some embodiments not all memory classes that make up Memory may be equally coupled to the CPU e.g. directly connected on the same bus etc. but they may be. Thus Memory in comprises memory class M memory class M memory class M memory class M and Data D .

In one embodiment VMy may include the memory space available to the CPU. In such embodiment in the context of VMy may be the memory space available to the CPU .

Note that in some embodiments CPU may be coupled to Storage using Bus as shown in . In Storage contains Data . In Storage may now be the only Secondary Storage since now Storage is part of Memory .

In one embodiment Storage may be used to store various Data e.g. overlays code software database etc. . In some embodiments System may be a consumer device Bus may include a wireless connection Storage may be cloud storage used to store data e.g. overlays code software database etc. . For example information e.g. data program code overlay blocks data database updates other software components security updates patches OS updates etc. may be fetched remotely from Storage e.g. as an application e.g. from an application store operating in demo mode purchased but accessed remotely rented monitored etc. as a transparent download via a push model via a push model etc. .

If Storage if present is detached then all CPU I O may then performed over Bus . The basic model of VMy with storage and data has not changed and thus may require little change to software e.g. OS applications etc. and or CPU and or CPU components e.g. MMU page tables TLB etc. . This is one possible feature of the system architecture when implemented as that shown and described in the embodiment of . There are other possible features as well. One example is that the elimination of one or more CPU I O or other buses may provide cost savings in a system e.g. through reducing pins per package and thus cost reducing package size and thus package cost reduced PCB area and thus cost reduced PCB density and thus cost etc. power e.g. through reduced numbers of high power bus drivers and receivers etc. and space savings e.g. through smaller packages smaller PCB less wiring etc. . Yet another possible feature is that System now may only need to handle read write data traffic between CPU and Main Memory on Bus . All other data traffic e.g. paging overlay caching and other data transfer functions in VMy etc. may be handled independently thus freeing resources required by Bus and CPU . As shown in none of the arrows representing data traffic e.g. move copy etc. involve I O Bus . This offers further savings in cost by potentially decreasing demands on a critical part of the system e.g. Bus and CPU etc. . It should be noted now that in a system where the memory components may be specially designed and packaged etc. e.g. for consumer electronics cell phones media devices etc. it may be cheaper and easier to perform these functions in the memory system e.g. design in integrate co locate etc. than to use expensive CPU resources increase CPU die area add extra CPU pins create larger CPU packages etc.

In Bus is drawn to diagrammatically suggest and logically represent embodiments that include but are not limited to the following alternatives a Bus may be a JEDEC standard memory bus large arrow with possibly modified control signals drawn separately as Bus Control small arrow . The control signals in Bus Control may be JEDEC standard signals modified JEDEC standard signals multiplexed signals additional signals e.g. new signals extra signals multiplexed signals etc. re used or re purposed signals signals logically derived from JEDEC standard signals etc b Bus may be wider than a standard JEDEC memory bus e.g. 128 256 or 512 bits etc. of data wider address bus etc. . This type of embodiment with high pin count data buses makes sense because one or more I O buses may not be present for example in systems that package main memory with CPU c Bus may be a combination of I O bus and memory bus and may share data and or address signals between buses and may use shared separate or new control signals including JEDEC standard signals signals derived from JEDEC standard signals or non standard signals etc. for different memory classes. In the context of the present description this bus may be referred to as a hybrid bus d Bus may be a new standard or proprietary bus that may be customized for an application e.g. stacked CPU and memory die in a cell phone etc. . For example a packet switched bus a split transaction bus etc e combinations of these.

Note that though in Bus is shown separately from Bus Control various terms such as the bus or the memory bus or Bus etc. may refer to Bus although all elements of Bus may be included including the control signals Bus Control for example. In some embodiments components of the bus may be called out individually such as when one component of the bus e.g. data address etc. may be standard e.g. JEDEC etc. but another component of the bus e.g. control etc. may be modified e.g. non standard etc. .

In a System includes a CPU coupled to Memory and coupled to Storage using Bus and Bus Control . In memory class M memory class M with memory class M located on Storage together form VMy . In Storage contains Data . Note that there is just one bus Bus for the CPU to access the entire VMy. In memory class located on Storage contains the page file. In one embodiment the copy operations shown in may correspond to copy operations shown in and described with regard to and and that were also shown in . In the embodiment of there is no secondary storage shown though in different embodiments there may be secondary storage.

In a System includes a CPU coupled to Memory using Bus and Bus Control . In the embodiment of there may not be secondary storage though in different embodiments there may be secondary storage.

There are some differences in the block diagram of the embodiment shown in from previous embodiments even though the functions of previous embodiments are still present a there is no distinction in memory class C between cache storage etc. b In both M and M are shown present in the same class of memory. The term levels of memory will be used to describe the functionality. For example it may be said that level M and level M are both present in the same class c The VMy is not explicitly shown in . Instead the boundary of VMy is capable of changing. For example at one point in time VMy may be equal to VMy at another point in time VMy may be equal to VMy etc.

In VMy comprises memory level B.M.C in memory class C plus memory level B.M.C in memory class C plus memory level B.M.C in memory class C .

In other embodiments the VMy may be extended between classes. Thus for example although M is shown as being in C for simplicity and perhaps no real difference between M and M as far as technology is concerned in it can be seen that in other embodiments M may be in another memory class C for example not shown in .

In other embodiments VMy may be moved between classes. For example in VMy is shown as being VMy which is M plus M plus an additional portion of C or plus an additional portion of C as just described etc. . Similarly VMy may be M plus M. Thus changing between VMy and VMy moves a portion of VMy from M to M. If M is a different memory class from M the change from VMy to VMy is equivalent to moving a portion of VMy between memory classes.

In a portion of memory class C contains Data where that portion is B.D.C . Of course in other embodiments different levels of data e.g. D D etc. may be present in a similar fashion to the different levels of memory e.g. M M M etc. . However in the current embodiment the distinction between memory and data is just that of the difference between format that data is normally stored in a memory system and the format that data is normally stored in a storage system e.g. on disk using a filesystem etc. .

In memory class C may contain the page file. In one embodiment the copy operations shown in may correspond to copy operations shown in and described with regard to and and that were also shown in and . In the embodiment there may be no secondary storage although in different embodiments there may be secondary storage.

One aspect of embodiments such as that shown in is the reduction of the number of wasted I O accesses requiring the memory bus. In those embodiments where memory may perform many most or all system I O functions performance is greatly enhanced. Thus in the embodiment of System moves more I O functions into memory. In this way traffic over the high speed memory bus is reduced e.g. reduced to just the essential traffic between CPU and memory etc.

Another aspect of embodiments such as that shown in is that all VMy functions are now contained in a single memory.

In system contains a CPU . In CPU is coupled to Memory in using Bus in . In CPU is optionally coupled to Disk in using Bus in . In the Memory comprises memory class in and memory class in . In memory class comprises memory level M in memory level M in used as a Page File Cache in memory level M in used as a Page File RAM Disk in memory level D in used as a Data RAM Disk in .

In one embodiment a RAM disk may include software e.g. a software driver Microsoft Windows .dll file etc. used to perform the functions of a small disk in memory e.g. emulate a disk etc. . A RAM disk may be used e.g. in an embedded system for data recovery at boot time etc. to implement small but high speed disks etc. A RAM Disk may be implemented using any combination of memory software etc. and does not have to include RAM and does not have to perform conventional disk functions.

The use of one or more RAM disks in System is purely for convenience of existing software hardware and OS design. For example most OS use a disk for the page file. If a portion of memory is used to emulate a disk it may be easier for the OS to use that portion of memory for a page file and swap space without modification of the OS.

For example systems using an OS e.g. Microsoft Windows Linux other well as other OS etc. may require a C drive in or equivalent in Linux etc. to hold the OS files e.g. boot loader etc. and other files required at boot time. In one embodiment memory class or a portion of it may be non volatile memory to provide a C drive. In another embodiment memory class may be a volatile memory technology but backed e.g. by battery supercapacitor etc. . In other embodiments memory class may be a volatile memory technology but contents copied to a different memory class that is non volatile on system shut down and restored before boot for example.

In the Data RAM disk is assigned drive letter C the Page File RAM disk is assigned drive letter D in the Page File Cache is assigned letter E in and the optional Disk is assigned drive letter F in .

In the use of a separate Page File Cache in memory may be compatible with existing cache systems e.g. ReadyBoost in Microsoft Windows etc. .

As shown the disks C D and E are accessible independently over I O Bus . In the disk D is dedicated as a page file and contains the page file and is used as swap space. In other embodiments the CPU may use data disk C as well as or instead of D for page files e.g. swap space etc. .

In the context of the present description Microsoft Windows drive letters e.g. volume labels etc. have been utilized such as C and D etc. for illustrative purposes to simplify the description and to more easily and clearly refer to memory regions used for data memory regions used for swap space etc. For example these regions e.g. portions of memory etc. may equally be labeled as data and swap in Linux etc. Of course other similar functions for different regions of memory etc. may be used in a similar fashion in many other different types and versions of operating systems.

It should be noted that the number location and use of the memory regions e.g. C D etc. may be different from that shown in or in any other embodiment without altering the essential functions. In some embodiments one may separate the page file and swap space from data space as this may improve VMy performance. In other embodiments swap space and data space may be combined e.g. to reduce cost to simplify software reduce changes required to an OS to work with existing hardware etc. .

The internal architecture of the Memory will be described in detail below but it should be noted that in various embodiments of the system shown in a C and D may be on the same bus internal to the Memory with E on a separate bus b D and E may be on the same bus with C on a separate bus c other similar permutations and or combinations etc.

In other alternative embodiments e.g. for a cell phone etc. some data e.g. additional VMY database etc. may be stored remotely and accessed over a wired or wireless link Such a link e.g. to remote storage etc. is indicated by the optional as indicated by dotted line s in Bus and optional Disk in .

It should be noted that not all of C D and E have to be in memory class . For example any one more combination or all of C D and E may be in memory class or other memory class not shown in but that may be present in other embodiments etc. etc.

It should be noted that C D and E functions may move e.g. migrate switch etc. between memory class and memory class or any other memory class not shown in but that may be present in other embodiments etc. .

In some embodiments Data RAM Disk C may be included as well as optional Disk F e.g. HDD SSD cloud storage etc. because Disk F may be larger and cheaper than a RAM disk.

In some embodiments the OS may be stored on a disk F e.g. permanent media etc. rather than a volatile RAM disk for example.

In memory M.C e.g. level M memory of memory class C e.g. DRAM in some embodiments SRAM in some embodiments etc. may have a capacity of N pages e.g. Page Page etc. Page N as shown in . M. may be a few gigabytes in size.

In memory M.C e.g. level M memory of memory class C e.g. DRAM in some embodiments if M is SRAM NAND flash in some embodiments if M is DRAM etc. may have a larger capacity than M of M pages e.g. Page Page etc. Page M as shown in . In some embodiments M.C may be several terabytes or larger in size.

In one embodiment a page size may be 4 kB. A 4 GB memory system could then hold up to 1M pages. In the 2011 timeframe a disk that is part of secondary storage and normally used to hold a page file as part of VMy may hold up to 2 TB. Thus the disk may hold up to 2 TB 4 kB or 500M pages. It may be desirable to at least match that capability in a system such as using multiple memory classes. Such a large memory capacity may be useful for example to hold very large in memory databases or multiple virtual machines VMs .

One potential issue is how to address such a large memory. A standard JEDEC DDR memory address bus may not have enough address bits to address all available memory e.g. a standard memory address bus is not wide enough .

The potential addressing issue is similar to an office building having four incoming phone lines or circuits but eight office phones. Suppose are four incoming phone numbers. This potential issue may be solved by giving each office phone an extension number. Four phone numbers may address eight phone extension numbers but with the limitation that only four extensions can be used at any one time. The four incoming phone numbers provide a continuously changing window to the eight extension numbers.

In different embodiments a the CPU and VMM including page tables etc. may be used to handle the address mapping b logic in the memory system may be used c or both may be used.

In the current embodiment the page memory page virtual page may include a fixed length or fixed size block of main memory that is contiguous in both PM addressing and VMy addressing. A system with a smaller page size uses more pages requiring a page table that occupies more space. For example if a 2 32 virtual address space is mapped to 4 kB 2 12 bytes pages the number of virtual pages is 2 20 2 32 2 12 . However if the page size is increased to 32 KB 2 15 bytes only 2 17 pages are required. The current trend is towards larger page sizes. Some instruction set architectures can support multiple page sizes including pages significantly larger than the standard page size of 4 kB.

Starting with the Pentium Pro processor the IA 32 x86 architecture supports an extension of the physical address space to 64 GBytes with a maximum physical address of FFFFFFFFFH. This extension is invoked in either of two ways 1 using the physical address extension PAE flag using the 36 bit page size extension PSE 36 feature starting with the Pentium III processors . Starting with the Intel Pentium Pro x86 processors support 4 MB pages using Page Size Extension PSE in addition to standard 4 kB pages. Processors using Physical Address Extension PAE and a 36 bit address can use 2 MB pages in addition to standard 4 kB pages. Newer 64 bit IA 64 Intel 64 x86 64 processors including AMD s newer AMD64 processors and Intel s Westmere processors support 1 GB pages.

Intel provides a software development kit SDK PSE36 that allows the system to use memory above 4 GB as a RAM disk for a paging file. Some Windows OS versions use an application programming interface API called Address Windowing Extensions AWE to extend memory space above 4 GB.

AWE is a set of Microsoft APIs to the memory manager functions that enables programs to address more memory than the 4 GB that is available through standard 32 bit addressing. AWE enables programs to reserve physical memory as non paged memory and then to dynamically map portions of the non paged memory to the program s working set of memory. This process enables memory intensive programs such as large database systems to reserve large amounts of physical memory for data without necessarily having to be paged in and out of a paging file for usage. Instead the data is swapped in and out of the working set and reserved memory is in excess of the 4 GB range. Additionally the range of memory in excess of 4 GB is exposed to the memory manager and the AWE functions by PAE. Without PAE AWE cannot necessarily reserve memory in excess of 4 GB.

OS support may in some embodiment also required for different page sizes. Linux has supported huge pages since release 2.6 using the hugetlbfs filesystem. Windows Server 2003 SP1 and newer Windows Vista and Windows Server 2008 support large pages. Windows 2000 and Windows XP support large pages internally but are not exposed to applications. Solaris beginning with version 9 supports large pages on SPARC and the x86. FreeBSD 7.2 RELEASE supports superpages.

As costs and performance of the memory technologies vary e.g. DRAM flash disk then the capacities allocated to different memory levels M M etc may change.

In the embodiment shown in it may be desirable to allow a the CPU to address and read write from to memory M.C and from to memory M.C b to perform copy operations between M and M and between M and M c perform table updates etc d send and receive status information etc. In the embodiment of three simple commands are shown that may be sent from CPU to Memory RD CMD WR .

In at time t command RD from the CPU performs a read from Page a . If Page a is already in M.C the read completes at t. If not then Page d is fetched via an operation shown as Read from Page d and the read completes at t. The embodiments described below will describe how the memory bus may handle read completions that may occur at variable times e.g. either at t or at t etc. . It should be noted now that several embodiments are possible such as a one embodiment may use a split transaction bus e.g. PCI E etc. b another embodiment may use a retry signal c another embodiment may exchange status messages with the CPU d a combinations of these etc.

In at time t command CMD from the CPU initiates an operation etc. Suppose that CMD is a Swap operation. Then Page b in M.C and Page e in M.C are swapped as shown in . The embodiments described below describe how logic in Memory may perform such operations e.g. swap operation s command s etc. . It should be noted that such commands may include updating tables in M.C updating tables in M.C updating tables in logic of Memory operations to swap move transfer copy etc operations to retrieve status from Memory etc.

In at time t command WR from the CPU performs a write to Page c . Depending on how addressing is handled in one embodiment for example a table such as Table may then be read by logic in Memory . As a result of the mapping between addresses in M and addresses in M a further operation Write from page c in M.C to Page f in M.C .

In memory M.C e.g. level M memory of memory class C e.g. SRAM in some embodiments embedded DRAM in some embodiments etc. may have a capacity of N pages e.g. Page Page etc. to Page N as shown in . In one embodiment M. may be a few megabytes in size.

In memory M.C e.g. level M memory of memory class C e.g. DRAM in some embodiments if M is embedded DRAM NAND flash in some embodiments if M is DRAM etc. may have a larger capacity than M of M pages e.g. Page Page etc. to Page M as shown in . In some embodiments M.C may be a few gigabytes or larger in size.

In memory M.C e.g. level M memory of memory class C e.g. NAND flash in some embodiments if M is SRAM M is DRAM etc. may have a much larger capacity than M of P pages e.g. Page Page . . . to Page P as shown in . In some embodiments M.C may be many gigabytes in size or even much larger e.g. terabytes etc. in size.

In operations that may be performed in one embodiment are shown Operation Operation Operation Operation Operation Operation Operation Operation .

In Operation corresponds to a read R from the CPU. If M is acting as a DRAM cache e.g. M may be SRAM and M DRAM etc. for example then Page a may be read from M if already present. If not then Page b is fetched from M.

In Operation corresponds to a write W from the CPU. Page c may be written to M and then copied to Page d in M.

In Operation corresponds to a read R from the CPU of Page e from M where Page e is already present in M.

Depending on the embodiment Page f may be copied to Page g in M so that it may be read faster in future Page f may also be copied and or moved to Page h in M.

In Operation corresponds to a command C from the CPU to copy or move etc. Page i in M to Page j in M. In one embodiment this may be a CPU command that prepares M for a later read of Page j.

In Operation corresponds to a command C from the CPU to copy Page k in M to Page m in M. This may in some embodiments be a CPU command that prepares M for a later read of Page m.

In Operation corresponds to a swap of Page n and Page o in M initiated without CPU command. In certain embodiments that use NAND flash technology etc. for M this may be to provide wear leveling etc.

In Operation corresponds to a swap of Page p and Page q in M initiated by CPU command C. In certain embodiments that use NAND flash technology etc. for M this may be to provide wear leveling under CPU or OS etc. control etc.

In memory M.C e.g. level M memory of memory class C e.g. SRAM in some embodiments embedded DRAM in some embodiments etc. may have a capacity of N pages. M. may be a few megabytes in size.

In memory M.C e.g. level M memory of memory class C e.g. DRAM in some embodiments if M is embedded DRAM NAND flash in some embodiments if M is DRAM etc. may have a larger capacity than M of M pages.

In memory C e.g. memory class C e.g. NAND flash in some embodiments if M is SRAM M is DRAM etc. may have a much larger capacity than M of P pages. In some embodiments M.C may be a many gigabytes or even much larger terabytes in size. In the embodiment of memory C is partitioned into M.C and D.C . The structure of M.C is memory pages managed by the VMM. The structure of D.C may also be pages but managed by the filesystem e.g. of the OS. etc. . Thus D may be thought of as a disk in memory or RAM disk.

The Inset shows the contents of a single table at two points in time Table and Table . At time t Table is a list e.g. inventory pointers etc. of pages in M and pages in D. For simplicity in Table only a few pages are shown for M though there are P pages in M and for D though there are F pages in D . At time t there are four pages in M and four pages in D . . . etc. Suppose the Memory receives a command CX that would result in a page being copied or moved from M to D. An example of such a command would be a write from memory M to the RAM disk D. In order to perform that operation Table may be updated. Suppose Memory receives a command or commands CY that would result in a page being copied or moved from M to D and a page being moved or copied from D to M. Again examples would be a read write to from M from to D. Again in one embodiment these operations may be performed by updating Table . Table shows the results. At time t there are three pages in M and five pages in D . etc. In one embodiment these operations may be performed without necessarily moving data. In this case the boundaries that define M and D may be re organized

As shown a physical memory sub system is provided. In various embodiments the physical memory sub system may include a monolithic memory circuit a semiconductor die a chip a packaged memory circuit or any other type of tangible memory circuit. In one embodiment the physical memory sub system may take the form of a DRAM circuit.

As shown the physical memory sub system includes a first memory of a first memory class and a second memory of a second memory class. In the one embodiment the first memory class may include non volatile memory e.g. FeRAM MRAM and PRAM etc. and the second memory class may include volatile memory e.g. SRAM DRAM T RAM Z RAM and TTRAM etc. . In another embodiment one of the first memory or the second memory may include RAM e.g. DRAM SRAM etc. and the other one of the first memory or the second memory may include NAND flash. In another embodiment one of the first memory or the second memory may include RAM e.g. DRAM SRAM etc. and the other one of the first memory or the second memory may include NOR flash. Of course in various embodiments any number of combinations of memory classes may be utilized.

The second memory is communicatively coupled to the first memory . In one embodiment the second memory may be communicatively coupled to the first memory via direct contact e.g. a direct connection etc. between the two memories. In another embodiment the second memory may be communicatively coupled to the first memory via a bus. In yet another embodiment the second memory may be communicatively coupled to the first memory utilizing a through silicon via.

As another option the communicative coupling may include a connection via a buffer device. In one embodiment the buffer device may be part of the physical memory sub system . In another embodiment the buffer device may be separate from the physical memory sub system .

In one embodiment the first memory and the second memory may be physically separate memories that are communicatively coupled utilizing through silicon via technology. In another embodiment the first memory and the second memory may be physically separate memories that are communicatively coupled utilizing wire bonds. Of course any type of coupling may be implemented that functions to allow the second memory to be communicatively coupled to the first memory .

The physical memory sub system is configured to dynamically allocate one or more memory functions from the first memory of the first memory class to the second memory of the second memory class. The memory functions may include any number of memory functions and may include any function associated with memory.

For example in one embodiment the one or more memory functions may include a cache function. In another embodiment the memory functions may include a page related function. A page related function refers to any function associated with a page of memory. In various embodiments page related functions may include one or more of the following operations and or functions but are not limited to the following a memory page copy simulating e.g. replacing performing emulating etc. for example a software bcopy function page allocation page deallocation page swap simulated I O via page flipping e.g. setting or modifying status or other bits in page tables etc. etc.

In another embodiment the memory functions may include a file related function. A file related function refers to any function associated with a file of memory. In various embodiments file related functions may include one or more of the following operations and or functions but are not limited to the following file allocation and deallocation data deduplication file compression and decompression virus scanning file and filesystem repair file and application caching file inspection watermarking security operations defragmentation RAID and other storage functions data scrubbing formatting partition management filesystem management disk quota management encryption and decryption ACL parsing checking setting etc simulated file or buffer I O via page flipping e.g. setting or modifying status or other bits in page tables etc. combinations of these etc. In yet another embodiment the memory functions may include a copy operation or a write operation. Still yet in one embodiment the memory functions may involve a reclassification of at least one portion of the first memory of the first memory class.

In one embodiment the dynamic allocation of the one or more memory functions from the first memory to the second memory may be carried out in response to a CPU instruction. For example in one embodiment a CPU instruction from a CPU may be received via a single memory bus . In another embodiment the dynamic allocation may be carried out independent of at least one aspect of the CPU operation.

As an option the dynamic allocation of the one or more memory functions may be carried out utilizing logic. In one embodiment the logic may side on the first memory and or the second memory . In another embodiment the logic may reside on a buffer device separate from the first memory and the second memory .

Furthermore in one embodiment the apparatus may be configured such that the dynamic allocation of the one or more memory functions includes allocation of the one or more memory functions to the second memory during a first time period and allocation of the one or more memory functions back to the first memory during a second time period. In another embodiment the apparatus may be configured such that the dynamic allocation of the one or more memory functions includes allocation of the one or more memory functions to the second memory during a first time period and allocation of the one or more memory functions to a third memory of a third memory class during a second time period.

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing techniques discussed in the context of any of the present or previous figure s may or may not be implemented per the desires of the user. For instance various optional examples and or options associated with the configuration operation of the physical memory sub system the configuration operation of the first and second memories and the configuration operation of the memory bus and or other optional features have been and will be set forth in the context of a variety of possible embodiments. It should be strongly noted that such information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of such features may be optionally incorporated with or without the inclusion of other features described.

As shown a reclassification instruction is received by a physical memory sub system. See operation . In the context of the present description a reclassification instruction refers to any instruction capable of being utilized to initiate the reclassification of memory a portion of memory or data stored in memory. For example in various embodiments the reclassification instruction may include one or more copy instructions one or more write instructions and or any other instruction capable of being utilized to initiate a reclassification.

As shown further a portion of the physical memory sub system is identified. See operation . Further the identified portion of the physical memory sub system is reclassified in response to receiving the reclassification instruction in order to simulate an operation. See operation .

The simulated operation may include any operation associated with memory. For example in one embodiment the identified portion of the physical memory sub system may be reclassified in order to simulate a copy operation. In various embodiments the copy operation may be simulated without necessarily reading the portion of the physical memory sub system and or without necessarily writing to another portion of the physical memory sub system.

Furthermore various reclassifications may occur in response to the reclassification instruction. For example in one embodiment the identified portion of the physical memory sub system may be reclassified from a page in memory to a file in the memory. In another embodiment the identified portion of the physical memory sub system may be reclassified from a file in memory to a page in the memory.

In one embodiment the identified portion of the physical memory sub system may be reclassified by editing metadata associated with the identified portion of the physical memory sub system. The metadata may include any data associated with the identified portion of the physical memory sub system. For example in one embodiment the metadata may include a bit. As an option the metadata may be stored in a table.

In one embodiment the identified portion of the physical memory sub system may be reclassified independent of at least one aspect of a CPU operation. In another embodiment the identified portion of the physical memory sub system may be reclassified in response to a CPU instruction. As an option the CPU instruction may be received via a single memory bus.

For example in one embodiment the method may be implemented utilizing the apparatus A or . In this case the identified portion of the physical memory sub system may be reclassified utilizing logic residing on the first memory and or on the second memory. Of course in another embodiment the logic may be resident on a buffer device separate from the first memory and the second memory or on any other device.

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing techniques discussed in the context of any of the present or previous figure s may or may not be implemented per the desires of the user. For instance various optional examples and or options associated with the operation the operation the operation and or other optional features have been and will be set forth in the context of a variety of possible embodiments. It should be strongly noted that such information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of such features may be optionally incorporated with or without the inclusion of other features described.

In DIMM comprises one or more of Component e.g. integrated circuit chip package etc. comprising memory level M e.g. DRAM in one embodiment etc. one or more of Component e.g. integrated circuit chip package etc. comprising memory level M e.g. NAND flash in one embodiment if M is DRAM etc. one or more of Component e.g. integrated circuit chip package etc. comprising memory logic e.g. buffer chip etc. .

The memory system includes DRAM and NAND flash comprising a Page File Cache a PageFile RAM Disk and a Data RAM Disk. Other embodiments may use other configurations of multiple memory classes combined into a single component and coupled to a CPU using a single bus.

In memory class is partitioned into six portions e.g. block region part set partition slice rank bank etc. that include a Page File RAM Disk a Page File Cache a Page File Cache RAM Disk a Data RAM Disk a Page File Memory a Data Cache RAM Disk . Different embodiments may use different combination of these portions. Also in various embodiments different applications may use different combinations of these portions.

In Application uses a first portion of memory class portions a Page File RAM Disk a Page File Cache a Page File Cache RAM Disk a Data RAM Disk . In Application uses a second different portion of memory class portions a Page File Cache RAM Disk a Data RAM Disk a Page File Memory a Data Cache RAM Disk .

In different embodiments the portions of memory class corresponding to applications e.g. Application Application etc. may be separately manipulated e.g. by the CPU by the OS by the Component memory logic etc. .

In one embodiment the portions of memory class corresponding to applications e.g. Application Application etc. may correspond to virtual machines VMs and the VMs may then easily be swapped in and out of Memory e.g. to secondary storage other device laptop desktop docking station etc cloud storage etc.

In other embodiments groups of portions e.g. Application and Application together etc. may be manipulated as bundles of memory.

In System comprises a CPU and Memory . In CPU is coupled to a buffer chip e.g. memory buffer interface circuit etc. . In the CPU is coupled to Memory using a Memory Bus . The Memory comprises a buffer chip coupled with a component of a memory class and a second component of memory class . Note that in such a configuration a page in a component of memory class could be copied into a component of memory class by the buffer chip without necessarily using bandwidth of the Memory Bus or resources of CPU . In one embodiment some or all of the VMy operations may be performed by the buffer chip without necessarily using bandwidth of the Memory Bus .

In Memory Bus may be of a different width or may have other different properties etc. than the Memory Internal Bus that couples CPU to the buffer chip .

In Bus may be the same width as Bus outside the buffer chip but different widths inside the buffer chip.

In multiple buffer chips may be used so that when they are all connected in parallel the sum of the all the Bus widths is equal to the Bus width. Similar alternative embodiments are possible with .

In System comprises CPU in and Memory in . Memory uses multiple different memory classes with only a single Memory Bus. CPU is coupled to a buffer chip. buffer chip is coupled to multiple different memory components of different memory classes over a single Internal Memory Bus .

In other embodiments there may be one or more Internal Memory Bus . That is not all Memory Classes may be on the same bus in some embodiments.

In one embodiment memory class in and memory class in may be on the same bus and memory class in may be on a separate bus.

In another embodiment memory class and memory class may be on the same bus and memory class may be on a separate bus.

In some embodiments there may be connections communication coupling etc. control signals address bus data bus between memory classes. In one embodiment there may be three possible bi directional some may be unidirectional connections memory class to memory class memory class to memory class memory class to memory class .

In System comprises CPU and Memory . Memory uses multiple different memory classes CPU is coupled to a buffer chip. buffer chip is coupled to multiple different memory components of different memory classes using Internal Memory Bus Internal Memory Bus Internal Memory Bus .

In one embodiment embedded DRAM in on the buffer chip may be used for memory class in . In another embodiment four or more classes of memory may be utilized.

In some embodiments there may be connections communication coupling etc. control signals address bus data bus between memory classes. There are three possible bi directional some may be unidirectional connections memory class to memory class in memory class to memory class in memory class to memory class .

In one embodiment the motherboard may be organized into several partitions including one or more processor sections consisting of one or more processors and one or more memory controllers and one or more memory sections . In one embodiment the notion of any of the aforementioned sections is purely a logical partitioning and the physical devices corresponding to any logical function or group of logical functions might be implemented fully within a single logical boundary or one or more physical devices for implementing a particular logical function might span one or more logical partitions. For example the function of the memory controller may be implemented in one or more of the physical devices associated with the processor section or it may be implemented in one or more of the physical devices associated with the memory section .

Although the memory may be labeled variously in and other figures e.g. memory memory components DRAM etc the memory may take any form including but not limited to DRAM synchronous DRAM SDRAM double data rate synchronous DRAM DDR SDRAM DDR2 SDRAM DDR3 SDRAM etc. graphics double data rate synchronous DRAM GDDR SDRAM GDDR2 SDRAM GDDR3 SDRAM etc. quad data rate DRAM QDR DRAM RAMBUS XDR DRAM XDR DRAM fast page mode DRAM FPM DRAM video DRAM VDRAM extended data out DRAM EDO DRAM burst EDO RAM BEDO DRAM multibank DRAM MDRAM synchronous graphics RAM SGRAM phase change memory PCM flash memory and or any other class of volatile or non volatile memory either separately or in combination.

As an option the exemplary systems of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary system of may be implemented in the context of any desired environment.

It should be noted that in various embodiments other possible placements of buffer chips are possible e.g. on motherboard on DIMM on CPU packaged with CPU packaged with DRAM or other memory etc. .

In one embodiment additional signals may be added to the Memory Bus. The additional signals may be control status error signaling etc. signals that are in addition to standard e.g. JEDEC standard DDR2 DDR23 DDR3 etc. signals.

In one embodiment there may be additional buses and or signals e.g. for control status polling command coding error correction power etc. .

As an option the exemplary system of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary system of may be implemented in the context of any desired environment.

In a Read Command in is placed on the Memory Bus at time t. The Read Command may comprise address information on the Address Bus in together with control information on the Control Bus in . At time t the memory places data the Data Result in on the Data Bus in . The read latency of the memory is the difference in time t t.

Note that the timing diagram shown in may vary in detail depending on the exact memory technology and standard used if any but in various embodiments the general relationship between signals and their timing may be similar to that shown in .

In a first Memory Bus in is used to couple the CPU in and the memory system. In a second Memory Bus is used to couple memory class in and memory class in . The second Memory Bus comprises Address Bus A in Control Bus C in and bidirectional Data Bus D in .

Note that does not show details of the coupling between the Memory Bus the memory system memory class and memory class . The coupling may include for example one or more buffer chips or other circuits that are described in detail below.

In memory class and memory class are shown containing Page X in . In one embodiment memory class may serve as a cache e.g. temporary store de staging mechanism etc. memory for memory class . In one embodiment a page may be written first to memory class and then subsequently written to memory class . In one embodiment after a page is copied e.g. moved transferred etc. from memory class to memory class the page may be kept in memory class or may be removed. In different embodiments the CPU may only be able to read from memory Class or may be able to read from both memory class and memory class . In one embodiment the CPU may request that a page be copied from memory class to memory class before being read from memory class etc. Of course these embodiments as well as other similar embodiments as well as different combinations of these and other similar embodiments may be used.

It should thus be noted that the exemplary system of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s with or without the use of buffer chips e.g. interface chips interface circuits etc. .

In a normal e.g. JEDEC standard other standard etc. read READ in is placed on the Address Bus A and Control Bus C at time t. In one embodiment a normal read command may correspond to a request for data that is present in memory class . At time t if the requested data is present in memory class the requested data from memory class is placed on Data Bus D. At time t a second read command READ in is placed on Address Bus A and Control Bus C. In one embodiment this read command requests data that is not present in memory class and may result for example in a read command for e.g. addressed to etc. memory class being placed on bus A and C at time t labeled as a Cache Miss and Delayed Read in . At time t the requested data from memory class is placed on bus D. At time t the requested data is placed on bus D.

In one embodiment the protocol on Memory Bus may be changed to allow the timing to break e.g. violate exceed non conform to deviate from etc. a JEDEC standard e.g. DDR2 DDR3 DDR4 etc. or other standard etc.

In another embodiment the Memory Bus may use a JEDEC standard e.g. DDR2 DDR3 DDR4 etc. or other standard.

In other embodiments the operation of the memory system may be changed from a standard e.g. JEDEC etc. examples of which will be described below.

In other embodiments the memory address translation and page table logic corresponding to that shown in may be more complex e.g. more detailed more complicated more levels of addressing etc. than shown in and may include other features e.g. multiple CPUs multiple cores nested page tables hierarchical addresses hierarchical page tables multiple page tables some features implemented in hardware some features implemented in hardware intermediate caches multiple modes of addressing etc. but the basic principles may remain as shown in .

In the standard memory bus comprises Address Bus A Data Bus D and Control Bus C. In a second memory bus comprises Address Bus A Data Bus D and Control Bus C. In the Page Miss Logic in is used to instruct the Memory Controller in that a page miss has occurred. The Memory Controller places a command on the Memory Bus to instruct the PM to copy Page X in from memory class to memory class .

In one embodiment the CPU in uses multiple threads. In one embodiment the system uses time between executions of threads to fetch e.g. command retrieve move transfer etc. pages e.g. Page X as necessary from memory class .

In one embodiment the fetching of page s may be performed in software using hypervisor s and virtual machine s . In other embodiments the fetching of pages may be performed in hardware. In other embodiments the fetching of pages may be performed in hardware and or software.

In one embodiment memory class may be faster than memory class e.g. 1 memory class DRAM memory class NAND flash 2 memory class SRAM memory class NAND flash 3 etc.

In a normal e.g. JEDEC standard etc. read READ in is placed on the Address Bus A and Control Bus C at time t. At time t the data from memory class is placed on Data Bus D. At time t a second special e.g. containing special data e.g. control command status etc. non standard etc. read command READ in is placed on bus A and C as a result of a page miss in the CPU. This special read command READ may result in a read command for memory class being placed on bus A and C at time t labeled Cache Miss in . At time t labeled as Page X copied from memory class to memory Class in the requested data copied from memory class is placed on bus D. At time t labeled as READ in the CPU issues another read command READ . This read command is a normal read command and results in the requested data from memory class e.g. copied from memory class transferred from memory class etc. being placed on bus D at time t labeled as CPU reads Page X from memory class in .

In one embodiment the CPU and memory hardware may be standard e.g. unaltered from that which would be used with a memory system comprising a single memory class and the memory bus may also be standard e.g. JEDEC standard etc. .

In other embodiments the read command READ may be a different special command e.g. write command etc. . Examples of such embodiments are described below.

In other embodiments the read command READ may be one or more commands e.g. combinations of one or more standard special write commands and or one or more standard special read commands etc. . Examples of such embodiments are described below.

As an option the exemplary system of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary system of may be implemented in the context of any desired environment.

In the memory bus A C and D may use a standard bus protocol e.g. DDR2 DDR3 DDR4 etc. . In the buffer chip may be coupled to memory class and memory class using standard e.g. JEDEC standard etc. buses A C D and A C D .

In other embodiments bus A C D and or A C D and or bus A C D or components e.g. parts signals etc. of these buses e.g. A C D etc. may be non standard buses e.g. modified standard proprietary different timing etc. .

In other embodiments the buffer chip may comprise one or more buffer chips connected in series parallel series parallel etc.

As an option the exemplary design of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary design of may be implemented in the context of any desired environment.

In a first memory class is packaged in individual chips on a first side of the DIMM. In a second memory class is packaged in individual chips on the second side of the DIMM. In a memory buffer is packaged in an individual chip on the first side of the DIMM.

In one embodiment the DIMM may be a standard design e.g. standard JEDEC raw card etc. . In such an embodiment the space constraints may dictate the number and placement e.g. orientation location etc. of the memory packages. In such an embodiment the space constraints may also dictate the number and placement of the memory buffer s .

In other embodiments the one or more memory buffer s may be packaged together e.g. stacked etc. with the one or more memory classes.

In the Page Table contains the mappings from VA to PA. As shown in VA 00 maps to PA 01 and Page in the Page Table. As shown in PA 01 and Page contains data   in the DRAM in . As shown in the Page Table is 8 bits in total size has 4 entries each entry being 2 bits. As shown in the DRAM is 32 bits in size. As shown in the VA is 2 bits and the PA is 2 bits.

In one embodiment of a CPU architecture the PA and VA may be different than that shown in e.g. 32 bits 64 bits different lengths etc. . In a one embodiment of a memory system architecture the DRAM may be different e.g. much larger than that shown in e.g. 1 GB 256 GB 8 Gbit 2 Tbit etc. . In one embodiment of a CPU architecture the page table s and surrounding logic etc. may be more complex than that shown in e.g. larger nested multi level combination of hardware software including caches multiple tables multiple modes of use hierarchical additional e.g. status dirty modified protection process etc. bits etc. and may be a page table system rather than a simple page table.

In some embodiments the page table system s may maintain a frame table and a page table. A frame sometimes called a physical frame or a page frame is a continuous region of physical memory. Like pages frames are be page size and page aligned. The frame table holds information about which frames are mapped. In some embodiments the frame table may also hold information about which address space a page belongs to statistics information or other background information.

The page table holds the mapping between a virtual address of a page and the address of a physical frame. In some embodiments auxiliary information may also be kept e.g. in the page table etc. about a page such as a present bit a dirty bit address space or process ID information amongst others e.g. status process protection etc. .

In some system embodiments secondary storage e.g. disk SSD NAND flash etc. may be used to augment PM. Pages may be swapped in and out of PM and secondary storage. In some embodiments a present bit may indicate the pages that are currently present in PM or are on secondary storage the swap file and may indicate how to access the pages e.g. whether to load a page from secondary storage whether to swap another page in PM out etc. .

In some system embodiments a dirty bit or modified bit may allow for performance optimization. A page on secondary storage that is swapped in to PM then read and subsequently paged out again does not need to be written back to secondary storage since the page has not changed. In this case the dirty bit is not set. If the page was written to the dirty bit is set. In some embodiments the swap file retains a copy of the page after it is swapped in to PM thus the page swap operation is a copy operation . When a dirty bit is not used the swap file need only be as large as the instantaneous total size of all swapped out pages at any moment. When a dirty bit is used at all times some pages may exist in both physical memory and the swap file.

In some system embodiments address space information e.g. process ID etc. is kept so the virtual memory management VMM system may associate a pages to a process. In the case for example that two processes use the same VA the page table contains different mappings for each process. In some system embodiments processes are assigned unique IDs e.g. address map identifiers address space identifiers process identifiers PIDs etc. . In some system embodiments the association of PIDs with pages may be used in the selection algorithm for pages to swap out e.g. candidate pages etc. . For example pages associated with inactive processes may be candidate pages because these pages are less likely to be needed immediately than pages associated with active processes.

In some system embodiments there may be a page table for each process that may occupy a different virtual memory page for each process. In such embodiments the process page table may be swapped out whenever the process is no longer resident in memory.

Thus it may be seen that as an option the exemplary design of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary design of may be implemented in the context of any desired environment.

In there are two memory classes 1 memory class DRAM in 2 memory class NAND flash in . In a system corresponding to the diagram of that contains more than one memory class it is possible that there are insufficient resources e.g. address space is too small address bus is too small software and or hardware limitations etc. to allow the CPU to address all of the memory in the system.

In one embodiment the method of may have two distinct characteristics 1 the memory class address space e.g. NAND flash size etc. may be greater than the address space of the memory bus 2 data is copied from NAND flash to DRAM before it may be read by the CPU.

In a first memory class e.g. DRAM etc. may be used as a movable e.g. controllable adjustable etc. window into a larger second memory class e.g. NAND flash etc. . The address space of the window is small enough that it may be addressed by the CPU. The window may be controlled e.g. moved through the larger address space of the second memory class etc. using the page table in the CPU.

Thus in order to obtain data at VA e.g. data corresponding to VA 110 the following steps are performed 1 a page in DRAM is selected e.g. Page 01 that may be used e.g. replaced ejected etc. 2 the data e.g.   at address corresponding to VA 110 is copied from NAND flash to DRAM e.g. Page 01 in DRAM 3 the Page Table is updated e.g. so that VA 110 maps to Page 01 4 the old Page Table entry e.g. VA 000 is invalidated 5 the CPU performs a read to VA e.g. VA 110 6 the Page Table maps VA to PA e.g. from VA 110 to PA 01 and Page 01 in the DRAM 6 the data is read from PA e.g.   from DRAM .

In the DRAM forms a 32 bit window into the 64 bit NAND flash. In one embodiment the 32 bit window is divided into 4 sets. Each set may hold a word of 8 bits. Each set may hold one word from the NAND flash. In one embodiment a table e.g. TLB in hardware in the CPU or software e.g. in the OS in a hypervisor etc. keeps the mapping from VA to PA as a list of VAs. In one embodiment the list of VAs may be a rolling list. For example 8 VAs may map to 4 PAs as in . In such an embodiment as PAs in the DRAM are used up a new map is added and the old one invalidated thus forming the rolling list. Once all 8 spaces have been used the list is emptied e.g. TLB flushed etc. and the list started again.

In one embodiment A the CPU and or OS and or software e.g. hypervisor etc. may keep track of which pages are in DRAM. In such an embodiment A a hypervisor may perform the VA to PA translation determine the location of the PA and may issue a command to copy pages from NAND flash to DRAM if needed.

In another embodiment B a region of NAND flash may be copied to DRAM. For example in if an access is required to data that is in the upper 32 bits of the 64 bit NAND flash a region of 32 bits may be copied from NAND flash to the 32 bit DRAM.

In a one embodiment of a CPU architecture the PA and VA may be different than that shown in e.g. 32 bits 64 bits different lengths etc. . In a one embodiment of a memory system architecture the DRAM may be different e.g. much larger than that shown in e.g. 1 GB 256 GB 8 Gbit 2 Tbit etc. . In a one embodiment of a CPU architecture the page table s and surrounding logic etc. may be more complex than that shown in .

Thus for example in embodiments using multiple memory classes together with an existing CPU and or OS architecture the architecture may be more complex than that shown in both in order to accommodate the existing architecture and because the architecture is inherently more complex than that shown in .

In other embodiments the page table s may be more complex than shown in e.g. larger nested multi level combination of hardware software include caches use table lookaside buffer s e.g. TLB etc. use multiple tables have multiple modes of use be hierarchical use additional e.g. status dirty modified protection process etc. bits or use combinations of any these etc. . In some embodiments the page table may be a page table system e.g. multiple tables nested tables combinations of tables etc. rather than a simple page table.

In for the purposes of addressing the DRAM may also be viewed as a cache for the NAND flash. As such any addressing and caching scheme may be used in various alternative embodiments. For example in some embodiments the addressing scheme may use tags sets and offsets. In some embodiments the address mapping scheme may use direct mapping associative mapping n way set associative mapping etc. In some embodiments the write policy for the memory classes may be write back write through etc.

Thus it may be seen that as an option the exemplary design of may be implemented in the context of the architecture and environment of the previous Figure s or any subsequent Figure s . Of course however the exemplary design of may be implemented in the context of any desired environment.

In some embodiments memory class may be SRAM memory class may be DRAM etc. In some embodiments memory may be of any technology e.g. SDRAM DDR DDR2 DDR3 DDR4 GDDR PRAM MRAM FeRAM embedded DRAM eDRAM SRAM etc. .

In other embodiments 1 Step may be performed by the CPU by software e.g. hypervisor etc. or by the memory system 2 Step may be a READ command that may trigger the memory system to copy from memory class MC to memory class MC if required 3 Step may be a WRITE command to a special location in PM that may trigger the memory system to copy from memory class MC to memory class MC if required 4 Step may be a retry mechanism either part of a standard e.g. JEDEC etc. or non standard 5 Step may be a READ command to which the PM may respond e.g. with a special code status retry etc. 6 Step may be a poll e.g. continuous periodic repeating etc. from the CPU to determine if data has been copied to MC and is ready 7 the PM may respond in various ways in step e.g. retry special data with status expected time to complete etc. .

In the Hypervisor in may be a software module and may allow the CPU in to run multiple VMs. In the Hypervisor contains two VMs VM in and VM in . In VM may make a request for VA. The Address Translation in block in the Hypervisor translates this address to VA. Using a custom address translation block may allow the Hypervisor to determine if VA is held in memory class MC in or in memory class MC in . If the data is held in MC then one of the mechanisms or methods already described may be used to copy or transfer move etc. the requested data from MC to MC.

In some embodiments the Address Translation block may be in hardware. In other embodiments the Address Translation block may be in software. In some embodiments the Address Translation block may be a combination of hardware and software.

As an option the exemplary methods of may be implemented in the context e.g. in combination with as part of together with etc. of the architecture and environment of the previous Figure s or any subsequent Figure s .

In a memory system with multiple memory classes copies between two or more memory classes may be performed using several methods or combinations of methods etc. .

A first method is shown in and uses two steps Copy and Copy . In this method Copy copies Page X in from memory class in to Page X in in the CPU in using the Memory Bus in . In one embodiment the CPU may perform Copy . Other methods of performing Copy include but are not limited to 1 use of direct cache injection 2 use of a DMA engine 3 other hardware or software copy methods 4 combinations of the above. Copy then copies Page X to Page X in using the Memory Bus. The CPU may also perform Copy although other methods of performing Copy are possible. Copy and Copy do not have to use the same methods but they may.

A second method in uses a single step Copy and does not necessarily require the use of the Memory Bus. In one embodiment the Memory Bus may be a high bandwidth and constrained resource. In some embodiments use of the Memory Bus for CPU traffic may be maximized while use for other purposes may be minimized. For example some embodiments may avoid using the Memory Bus for copies between memory classes.

In the step labeled Copy copies Page X in memory class directly to Page X in memory class in . The step Copy may be initiated by the CPU using a command over the Memory Bus. The step Copy may also be initiated by a memory controller not shown in in the memory system. The memory controller or memory controllers may be located anywhere in the system as shown in several previous embodiments 1 e.g. in a buffer chip located on a DIMM motherboard etc 2 embedded on one or more of the chips packages etc. that contain one or more of the memory classes shown in 3 part of the CPU 4 a combination of the above.

In one or more triggers e.g. commands signals etc. for the memory controller to initiate a copy may include 1 wear leveling of one of the memory classes 2 maintenance of free space in one of the memory classes 3 keeping redundant copies in multiple memory classes for reliability 4 de staging of cached data from one memory class to another 5 retrieval of data on a CPU command 5 other triggers internal to the memory system 6 other external triggers e.g. from the CPU OS etc 7 other external triggers from other system components or software 8 combinations of any of the above.

In during the step Copy in some embodiments the memory controller may also perform an operation on the Memory Bus during some or all of the period of step Copy . In one embodiment the following sequence of steps may be performed for example 1 disconnect the Memory Bus from the CPU 2 raise a busy flag e.g. assert a control signal set a status bit etc. 3 issue a command to the CPU 4 alter the normal response protocol or other behavior 5 any combination of the above.

In in some embodiments the memory controller may also interact with the CPU before during or after the step Copy using a control signal e.g. sideband signal etc. separate from the main Memory Bus or part of the Memory Bus. The control signal not shown in may use 1 a separate wire 2 separate channel 3 multiplexed signal on the Memory Bus 4 alternate signaling scheme 5 a combination of these etc.

In some embodiments one copy method may be preferred over another. For example in a system where performance is important an embodiment may use a single copy that avoids using the Memory Bus. In a system where power is important an embodiment may use a slow copy using the Memory Bus that may use less energy.

The choice of embodiments and copy method s may depend on the relative power consumption of the copy method s and other factors. It is also possible for example that a single copy without the use of the Memory Bus consumes less power than a copy that does require the use of the Memory Bus. Such factors may change with time user and or system preferences or other factors etc. For example in various embodiments the choice of copy method s may depend on 1 whether the system is in sleep power down or other special power saving mode e.g. system failure battery low etc. or other performance mode etc 2 the length e.g. file size number of pages etc. type e.g. contiguous sequential random etc. etc. of the copy 3 any special requirements from the user CPU OS system etc. e.g. low latency required for real time transactions e.g. embedded system machine control business stock trading etc. games audio video or other multi media content etc. . In some embodiments the system may modify e.g. switch select choose change etc. the copy method either under user and or system control in a manual and or automatic fashion. In some embodiments the system may modify copy methods during a copy.

As shown in the buffer chip in may be connected between the CPU in and multiple memory classes. In the buffer chip is shown connected to memory class in using Bus in and connected to memory class in using Bus in .

In one embodiment memory class in may be used as a cache for the rest of the memory system comprising memory class and memory class . In such an embodiment the PA from the CPU etc. may be divided into tag block and offset to determine if requested data is present in the cache. In various embodiments the type of cache mapping e.g. direct mapping fully associative k way associative etc. and the cache policy e.g. write back write through etc. may be implemented in any desired manner.

Other embodiments may include but are not limited to the following variations 1 more than two memory classes may be connected to the buffer chip 2 less than two memory classes may be connected to the buffer chip 3 the memory classes may be any memory technology e.g. DRAM NAND flash etc 4 Bus and Bus may be combined or separate as shown 5 alternative bus arrangements may be used e.g. a common bus multi drop bus multiplexed bus bus matrix switched bus split transaction bus PCI bus PCI Express bus HyperTransport bus front side bus FSB DDR2 DDR3 DDR4 bus LPDDR bus etc 6 memory class and memory class may be combined on the same chip or in the same package 7 memory class may be embedded contained or part of memory class 8 memory class may be located in a different part of the system physically while still logically connected to the buffer chip 9 any combination of the above. In the buffer chip is shown as containing memory class . memory class may be a special class of memory e.g. fast memory such as SRAM or embedded DRAM for example used as a cache scratchpad or other working memory etc. that the buffer chip may use to hold data that needs to be fetched quickly by the CPU for example. Other examples of use for memory class or any of the other memory classes separately or in combination with memory class may include 1 test repair re mapping look aside etc. tables listing for example bad memory locations in one or more of the memory classes 2 page tables 3 other memory address mapping functions 4 cache memory holding data that later be de staged to one or more of the other memory classes 5 timing parameters used by the system and CPU 6 code and data that may be used by the buffer chip 7 power management e.g. the buffer chip OS CPU etc. may turn off other parts of the system while using memory class to keep energy use low etc. 8 log files for memory mapped storage in one or more of the memory classes 9 combinations of the above.

In buffer chip in interfaces the CPU in and memory class in and buffer chip in interfaces memory class and memory class in . For example in one embodiment Bus in may be a standard memory bus such as DDR4. memory class may be a fast memory such as SRAM. In such an embodiment Bus in may be different e.g. use a different protocol timing etc. than Bus . In buffer chip may perform a conversion of timing protocol etc. In memory class is shown as separate from buffer chip and memory class .

In alternative embodiments memory class may be 1 part of buffer chip 2 part of buffer chip 3 embedded with one or more other parts of the system 4 packaged with one or more other parts of the system e.g. in the same integrated circuit package .

In memory class is shown as using more than one bus e.g. Bus and Bus in . In one embodiment memory class is an embedded DRAM or SRAM that is part of one or more of the buffer chips. In alternative embodiments memory class may not use a shared bus.

In other embodiments 1 memory class may use a single bus shared between buffer chip and buffer chip for example 2 buffer chip and buffer chip may be combined and share a single bus to interface to memory class 3 buffer chip may interface directly to buffer chip instead of or in addition to memory Class 4 any combinations of the above.

In one embodiment memory class may be a fast small memory such as SRAM embedded DRAM SDRAM etc. and able to quickly satisfy requests from the CPU. In such an embodiment memory class may be a larger and cheaper but slower memory such as NAND flash SDRAM etc. .

The various optional features of the architectures based on that shown in and other similar architectures presented in other Figure s here include but are not limited to 1 low power e.g. using the ability to shut down memory class in low power modes etc. 2 systems design flexibility e.g. while still using an existing standard memory bus for Bus with new technology for remaining parts of the system or using a new standard for Bus and or other system components while using existing standards for the rest of the system etc. 3 low cost e.g. mixing high performance but high cost memory class with lower performance but lower cost memory class etc. 4 upgrade capability flexibility with planned or unplanned obsolescence e.g. using an old new CPU with new old memory otherwise incompatible memory and CPU etc. 5 combinations of the above.

In alternative embodiments Bus and Bus or any combination Bus X and Bus Y of the bus connections shown in such as Bus and Bus in Bus and Bus or other combinations of 2 3 or 4 buses etc. may use 1 the same protocol 2 the same protocol but different timing versions e.g. DDR2 DDR3 DDR4 but with a different timing etc. 3 different data widths e.g. Bus X may use 64 bits of data and Bus Y may use 512 bits etc. 4 different physical versions of the same protocol e.g. Bus X may be a JEDEC standard DDR3 bus with a 72 bit wide bus with ECC protection intended for registered DIMMs Bus Y may be the same JEDEC standard DDR3 bus but with a 64 bit wide data bus with no ECC protection intended for unbuffered DIMMs etc. 5 other logical or physical differences such as type multi drop multiplexed parallel split transaction packet based PCI PCI Express etc. 6 combinations of the above.

In the buffer chip in is shown as embedded in memory class in . In alternative embodiments 1 the buffer chip or multiple buffer chips may be packaged with one or more chips die etc. comprising one or more components of memory class 2 one or more buffer chips may be connected to one or more of memory class chips die components etc. using through silicon vias TSV or other advanced high density interconnect HDI techniques e.g. chip on board stacked wire bond etc. 3 combinations of the above.

In Bus in the memory bus is shown as connected to memory class but in various embodiments may be connected to the buffer chip or may be connected to both the buffer chip and memory class . In Bus in is shown as connecting the buffer chip and memory Class in but in various embodiments may connect memory class to memory class or may connect memory class to both memory Class and the buffer chip. In other embodiments there may be more than two memory classes or a single memory class omitting memory class or memory class .

Some embodiments may emulate the appearance that only a single memory class is present. For example in one embodiment there may be system modes that require certain features e.g. low power operation etc. and such an embodiment may modify Bus e.g. disconnect shut off power down modify mode modify behavior modify speed modify protocol modify bus width etc. and memory class shut off change mode power down etc. . In other embodiments memory class may be remote or appear to be remote e.g. Bus may be wireless memory class may be in a different system Bus may involve a storage protocol Bus may be WAN etc. .

In some embodiments the system configuration e.g. number and type of buses number and technology of memory classes logical connections etc. may for example be functionally changed from a two class memory system to a conventional single class memory system.

In some embodiments based on in which there may be more than two memory classes for example the system configuration may be changed from n class to m class e.g. from 3 memory classes to 1 3 classes to 2 2 classes to 3 etc. depending on different factors e.g. power speed performance etc. . Such factors may vary with time and in some embodiments changes to configuration may be made on the fly in response for example to the cost of an operation e.g. length of time energy cost battery life tariffs on cell phone data rate costs based on data transferred rates based on time fees based on copies performed remotely etc. and or the type of operation or operations being performed e.g. watching a movie long file copy long computation low battery performing a backup or combination of these .

In one embodiment one operation O may be started at time t on a consumer electronics device tablet laptop cell phone that requires low performance with high memory capacity but for a short time. The memory configuration may be configured at t to use two classes of memory a C system . Then a second operation O is started at time t before the first operation O has finished and would ideally use a single class memory system C system . The system OS CPU or buffer chip etc. may then decide at t to change e.g. switch modify etc. to a C system.

In other embodiments given certain factors e.g. speed required CPU load battery life remaining video replay quality etc. the system may remain as C as configured at t. At time t the first operation O completes. Again at t the system may make a decision to change configuration. In this case the system may decide at t to switch from C to C.

In the buffer chip in is shown separate from memory class in and memory class in . In the CPU in is connected to the buffer chip using Bus in the memory system bus the buffer chip is connected to memory Class using Bus in and the buffer chip is connected to memory class using Bus in . In memory class is shown as DRAM and memory class is shown as flash.

In other embodiments 1 memory class may be any other form of memory technology e.g. SDRAM DDR DDR2 DDR3 DDR4 GDDR PRAM MRAM FeRAM embedded DRAM eDRAM SRAM etc. 2 memory class may also be any form of memory technology 3 memory class and memory class may be the same memory technology but different in 1 die size or overall capacity e.g. memory class may be 1 GB and memory class may be 16 GB 2 speed e.g. memory class may be faster than memory class 3 bus width or other bus technology 4 other aspect 5 a combination of these.

In other embodiments Bus Bus and Bus may use one or more different bus technologies depending on the memory technology of memory class and memory class . Although two memory classes are shown in in some embodiments the buffer chip may have the capability to connect to more than two memory class technologies. In memory class and memory class are shown as single blocks in the system diagram.

In some embodiments both memory class and memory class may each be composed of several packages components or die. In both Bus and Bus are shown as a single bus. Depending on how many packages components or die are used for memory class and memory class in some embodiments both Bus and Bus may be composed of several buses. For example Bus may be composed of several buses to several components in memory class . In an embodiment for example that memory class is composed of four 1 Gb DRAM die there may be four buses connecting the buffer chip to memory class . In such an embodiment these four buses may share some signals for example 1 buses may share some all or none of the data signals e.g. DQ etc. 2 buses may share some all or none of the control signals and command signals e.g. CS ODT CKE CLK DQS DM etc. 3 buses may share some all or none of the address signals e.g. bank address column address row address etc. . Sharing of the bus or other signals may be determined by various factors including but not limited to 1 routing area and complexity e.g. on a DIMM on a motherboard in a package etc. 2 protocol violations e.g. data collision on a shared bus timing violations between ranks determined by CS etc. 3 signal integrity e.g. of multiple adjacent lines caused by crosstalk on a bus etc. 4 any combination of these.

As an option the exemplary methods of may be implemented in the context e.g. in combination with as part of together with etc. of the architecture and environment of the previous Figure s or any subsequent Figure s .

In several examples of methods to copy pages are shown. Not all possible copying options copying methods or copying techniques are shown in but those that are shown are representative of the options methods techniques etc. that may be employed in various embodiments.

In memory class in contains pages marked to N. In in one embodiment memory class in contains pages marked N 1 N 2 etc. as well as pages that are marked MFT F F etc. In one embodiment Page MFT represents a Master File Table or equivalent table that is part of an OS file system. In such an embodiment the MFT may and in some embodiment may span more than one page but has been represented as a single page in for simplicity. In Page F Page F etc. represent files that may be in memory class for one or more purposes e.g. part of a memory mapped filesystem for demand paging part of a filesystem cache etc. . In Page F or Page F Page F etc. may be a single file part of a file or contain multiple files. Although only memory class is shown in as containing files and related tables one or more files and related tables could also be present in memory class but that has not been shown in for simplicity.

In step Copy shows a page being copied from memory class to memory class . In step Copy shows a page being copied moved or duplicated in memory class . In step Copy shows a page being copied from memory class to memory class . In step Copy shows a copy from a page in memory class to a file in memory class . In step Copy shows a file being copied moved or duplicated in memory class .

In different embodiments the copy operations described may be triggered by various mechanisms including but not limited to 1 using commands from the CPU or OS etc. 2 using commands from one or more buffer chips 3 combinations of these.

In the memory controller in the CPU not shown may be configured to operate with DDR2 SDRAM. In the relationship between read latency of a DDR2 SDRAM RL or CL for CAS latency and the write latency WL or CWL is fixed as follows WL RL 1. In this equation 1 represents one clock cycle and the units of RL and WL are clock cycles. The read latency of the DDR2 SDRAM is represented by d2 RL. Then the read latency as seen by the CPU RLD can be written in terms of RL and the delays of the buffer chip as follows RLD RL d1 d3. In this equation d1 represents the delay of the buffer chip for the address bus for reads. The write latency as of the DDR2 SDRAM WL can be written in terms of the write latency as seen by the CPU WLD and delays of the buffer chip WL WLD d3 d4. In this equation d4 represents the delay of the buffer chip for the address bus for writes. The CPU enforces the same relationship between WLD and RLD as is true for the SDRAM values WL and RL WLD RLD 1. Thus the following equation is true for the protocol between the buffer chip and DDR2 SDRAM d4 2d3 d1.

This equation implies that the delay of the address bus and control bus depends on the type of command e.g. read write etc. . Without this command dependent delay the interface between buffer chip and SDRAM may violate standard e.g. JEDEC standard etc. timing parameters of the DDR2 SDRAM.

In various embodiments logic that introduces a delay may be included in any of the buffer chips present in any designs that are described in other Figure s and that interface e.g. connect couple etc. the CPU to DDR2 SDRAM. In one embodiment the memory controller and or CPU may be designed to account for any timing issue caused by the presence of the buffer chip and thus the equation relating WLD to RLD may no longer be a restriction . In such an embodiment using a potentially non standard design of CPU and or memory controller the design of the buffer chip may be simplified.

In other embodiments the logic in the buffer chip may be used to alter the delay s of the bus es in order to adhere e.g. obey meet timing etc. to standard e.g. JEDEC standard etc. timing parameters of the DDR2 SDRAM.

In the relationship between write latency and read latency is more complex than DDR2 and is as follows WL RL K where K is an integer number of clock cycles . The relationship governing the buffer chip delays is then d4 2d3 d1 K 1 . In various embodiments the memory controller and or CPU may follow the JEDEC DDR3 protocol and in such embodiments the buffer chip may insert a command dependent delay in the bus es e.g. address bus control bus etc. to avoid timing issues.

In other embodiments one or more buffer chips may be used. Such buffer chips may be the same or different. In such embodiments for example delays may be introduced by more than one buffer chip or by combinations of delays in different buffer chips.

In other embodiments the delays may be inserted in one or more buses as relative delays e.g. delay inserting a delay da in all buses but one with that one bus being delayed instead by a delay of da db may be equivalent to e.g. viewed as logically equivalent to etc. a relative delay of db etc. .

In the memory system comprises two memory classes. In Page X in is being copied to Page X in . In the CPU in contains a Page Table in . The Page Table contains a map from Virtual Address VA in to Physical Address PA in . In the CPU contains an RMAP Table in . In Linux a reverse mapping RMAP is kept in a table an RMAP table that maintains a linked list containing pointers to the page table entries PTEs of every process currently mapping a given physical page. The Microsoft Windows OS versions contain a similar structure. The RMAP table essentially maintains the reverse mapping of a page to a page table entry PTE in and virtual address. In an OS the RMAP table is used by the OS to speed up the page unmap path without necessarily requiring a scan of the process virtual address space. Using the RMAP table improves the unmapping of shared pages because of the availability of the PTE mappings for shared pages reduces page faults because PTE entries are unmapped only when required reduces searching required during page replacement as only inactive pages are touched and there is only a low overhead involved in adding this reverse mapping during fork page fault mmap and exit paths. This RMAP table may be used if desired to find a PTE from a physical page number or PA. In the CPU contains a Memory Allocator in . The Memory Allocator may be used if desired to allocate a new page in the memory system.

In the copy is triggered by a request from the memory system to the CPU to perform a copy. This is just one example of a copy. Other copy operations may be 1 triggered by the CPU and passed to the memory system as a command with the copy being executed autonomously by the memory system 2 triggered by the memory system and executed autonomously by the memory system 3 triggered by the CPU and executed by the CPU 4 combinations of these. shows the following steps 1 Step is the entry to a method to swap two pages in the memory system the same process may be used for other operations e.g. move copy transfer etc. 2 Step uses the memory allocator in the CPU to allocate a new page in the memory system with address VA. The new page could be in any of the memory classes in the memory system 3 Step maps the physical address e.g. page number etc. of the page to be swapped e.g. copied moved etc. to the PTE using the RMAP table and determines address VA 4 Step swaps e.g. moves copies transfers etc. Page to Page using VA and VA 5 Step updates the Page Table 6 Step updates the Page Table cache or TLB 7 Step releases Page for move swap etc. operations where the old page is no longer required.

In in one embodiment the Page Table and RMAP Table may be integrated into the memory system. In these components have been shown as separate from the buffer chip memory class in and memory class in . In one embodiment the Page Table RMAP Table and Cache are integrated with the buffer chip. In other embodiments these components may be integrated with or separate from one or more of the following components shown in 1 memory class 2 memory class 3 buffer chip.

In some embodiments the Cache may be used to hold information contained in the Page Table and or RMAP Table.

In the presence of the Page Table allows the memory system to autonomously e.g. without help from the CPU OS etc. perform a mapping of VA in to PA in . In the presence of the RMAP Table allows the memory system to autonomously perform a mapping of PA to VA. These mapping functions are useful in page operations e.g. move copy swap transfer etc. that may be performed for example by the buffer chip.

In patterns of access to certain memory locations in a memory system are diagrammed. In the X axis represents page number within the memory system with a page size of 4 kBytes . In the X axis represents the cache line number within a page with a cache line size of 64 Bytes there are 64 cache lines in a 4 kByte page . By running memory traces it is often found there are certain hot spots in memory marked in by hot spots H H H and H. Each of these hot spots represent a sequence of cache lines that are repeatedly accessed e.g. frequently executed code routines frequently accessed data etc. more frequently than other areas of memory.

In the 32 bit Address in in a 32 bit system e.g. machine physical or virtual CPU OS etc. is shown divided into a 12 bit Offset and 30 bit Physical Page Number.

In one embodiment of an address mapping uses Map in shows how the Address may be mapped to the memory system. In Map the bits are as follows 1 bits correspond e.g. map or are used as etc. to the Byte Address in of the memory system 2 bits correspond to the Column Address in of the memory system 3 bits correspond to the Row Address in of the memory system 4 bits correspond to the Bank in of the memory system and bits correspond to the Rank in of the memory system.

In Map shows an embodiment that uses an alternative system address mapping to the memory system e.g. the Bank address has moved in position from that shown in Map in . Depending on several factors e.g. type of memory access type of program being executed data patterns etc. the memory access patterns may favor one address mapping over another address mapping. For example in some programs e.g. modes of operation etc. Map of combined with the access pattern shown in may result in better performance of the memory system e.g. lower power higher speed etc. . This may be especially true when the memory system comprises multiple memory classes and for example it may be desired that the hot spots as described in for example should remain in one class of memory.

In various embodiments the address mapping function may thus be controlled as described especially for memory systems with multiple memory classes.

In the buffer chip in contains logic that may receive an address from the CPU in e.g. from memory controller etc. and is capable of changing e.g. swizzling re mapping altering etc. the address mapping. In one embodiment the address from the CPU may use Map in . In another embodiment the buffer chip may change Map to Map in .

The ability to change address mapping may be used in several ways. For example if memory class in is a small but fast class of memory relative to the larger but slower memory class in then in one embodiment for example one type of map may keep hot spots as described in and marked H to H in in memory class .

In alternative embodiments 1 the CPU e.g. machine virtual or physical OS etc. may instruct e.g. based on operating mode by monitoring memory use by determining memory hot spots by pre configured statistics for certain programs etc. the buffer chip to alter from Map x to Map y where Map x and Map y are arbitrary address mappings 2 the buffer chip may configure the address mapping to Map x where Map x is an arbitrary address map based on memory use and or other factors e.g. power wear leveling of any or all memory classes etc. 3 different address maps may be used for any or all of the memory classes 4 the memory classes may be identical but may use different memory maps 5 and or any combination of these.

The system may also include a secondary storage . The secondary storage includes for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive a compact disk drive etc. The removable storage drive reads from and or writes to a removable storage unit in any desired manner.

Computer programs or computer control logic algorithms may be stored in the main memory and or the secondary storage . Such computer programs when executed enable the system to perform various functions. Memory storage and or any other storage are possible examples of computer readable media.

In one embodiment the architecture and or functionality of the various previous figures may be implemented in the context of the host processor graphics processor a chipset e.g. a group of integrated circuits designed to work and sold as a unit for performing related functions etc. and or any other integrated circuit for that matter.

Still yet the architecture and or functionality of the various previous figures may be implemented in the context of a general computer system a circuit board system a game console system dedicated for entertainment purposes an application specific system and or any other desired system. For example the system may take the form of a desktop computer lap top computer and or any other type of logic. Still yet the system may take the form of various other devices including but not limited to a personal digital assistant PDA device a mobile phone device a television etc.

Further while not shown the system may be coupled to a network e.g. a telecommunications network local area network LAN wireless network wide area network WAN such as the Internet peer to peer network cable network etc. for communication purposes.

As used herein the singular forms e.g. a an the etc. are intended to include the plural forms as well unless the context clearly indicates otherwise.

The terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

In the following description and claims the terms include and comprise along with their derivatives may be used and are intended to be treated as synonyms for each other.

In the following description and claims the terms coupled and connected may be used along with their derivatives. It should be understood that these terms are not necessarily intended as synonyms for each other. For example connected may be used to indicate that two or more elements are in direct physical or electrical contact with each other. Further coupled may be used to indicate that that two or more elements are in direct or indirect physical or electrical contact. For example coupled may be used to indicate that that two or more elements are not in direct contact with each other but the two or more elements still cooperate or interact with each other.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit component module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

In different embodiments emphasis and or de emphasis may be performed at the designated driver s in a multiple die stack e.g. the transmitter driver re driver on a buffer etc. both for the upstream memory bus es or downstream memory bus es etc. . Additionally in different embodiments emphasis and or de emphasis may be performed at the designated receivers s in a multiple die stack e.g. the receiver s both for the upstream memory bus es or downstream memory bus es etc. . Further in different embodiments emphasis and or de emphasis may be performed at the designated receivers s in a multiple die stack e.g. the receiver s for the downstream memory bus es etc. and or at the designated driver s in a multiple die stack e.g. the transmitter driver re driver on a buffer etc. both for the upstream memory bus es etc. .

In various embodiments e.g. including any of those embodiments mentioned previously or combinations of these embodiments etc. the emphasis and or de emphasis may be adjustable. In various embodiments the emphasis and or de emphasis may be adjusted e.g. tuned varied altered in function e.g. by using more than one designated receiver and or designated driver used for emphasis and or de emphasis etc. moved in position through receiver or driver configuration etc. based on various metrics e.g. characterization of the memory channel calculation BER signal integrity etc. .

The capabilities of the present invention can be implemented in software firmware hardware or some combination thereof.

As one example one or more aspects of the present invention can be included in an article of manufacture e.g. one or more computer program products having for instance computer usable media. The media has embodied therein for instance computer readable program code means for providing and facilitating the capabilities of the present invention. The article of manufacture can be included as a part of a computer system or sold separately.

Additionally at least one program storage device readable by a machine tangibly embodying at least one program of instructions executable by the machine to perform the capabilities of the present invention can be provided.

The diagrams depicted herein are just examples. There may be many variations to these diagrams or the steps or operations described therein without departing from the spirit of the invention. For instance the steps may be performed in a differing order or steps may be added deleted or modified. All of these variations are considered a part of the claimed invention.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

