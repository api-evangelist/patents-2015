---

title: Indefinite texture filter size for graphics processing
abstract: An example method of filtering in a graphics processing unit (GPU) may include storing, by a texture engine of the GPU, filter coefficients of a filter as a texture memory object (TMO) in a texture cache of the GPU in response to a first instruction. The method may include retrieving, by the texture engine, filter coefficients from the texture cache in response to a second instruction. The method may include storing, by the texture engine, pixel data in the texture cache of the GPU in response to the second instruction. The pixel data may include one or more pixel values. The method may include filtering, by the texture engine, the pixel data stored in the texture cache using the retrieved filter coefficients.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09646359&OS=09646359&RS=09646359
owner: QUALCOMM Incorporated
number: 09646359
owner_city: San Diego
owner_country: US
publication_date: 20150206
---
This application claims priority to U.S. Provisional Patent Application No. 62 096 115 filed Dec. 23 2014 the entirety of which is incorporated by reference herein.

This disclosure relates to techniques for graphics processing and more specifically to techniques for filtering textures.

Visual content for display such as content for graphical user interfaces and video games may be generated by a graphics processing unit GPU . A GPU may convert two dimensional or three dimensional 3D objects into a two dimensional 2D pixel representation that may be displayed. Converting information about 3D objects into a bit map that can be displayed is known as pixel rendering and requires considerable memory and processing power. In the past 3D graphics capability was available only on powerful workstations. However now 3D graphics accelerators are commonly found in personal computers PC as well as in embedded devices such as smart phones tablet computers portable media players portable video gaming consoles and the like. Typically embedded device have less computational power and memory capacity as compared to conventional PCs. As such increased complexity in 3D graphics rendering techniques presents difficulties when implementing such techniques on an embedded system. Other tasks performed by GPUs include filtering tasks for image processing.

This disclosure describes techniques for performing filtering in a graphics processing unit GPU . In examples of the disclosure a GPU may be configured to store and fetch filter coefficients also called filter weights to and from a texture memory using a modified texture engine of the GPU. The modified texture engine may be configured to fetch the filter coefficients from the memory and to store the filter coefficients into a cache. In this way filter coefficients for a filter of an indefinite size may be stored in the texture memory for use in various filtering operations that may be performed on the GPU. In one example the texture engine itself may be configured to perform filtering operations on pixels or texels using the filter coefficients stored in the texture memory. In other examples other hardware units of a GPU may be configured to fetch the filter weights from texture memory and perform a filtering operation.

In one example of the disclosure a method for storing filter coefficients in a GPU comprises storing by a texture engine of the GPU filter coefficients of a filter as a texture memory object TMO in a texture memory accessible to the texture engine in response to a first instruction wherein the texture memory is configured to store pixels and filter coefficients. The method further comprises retrieving by the texture engine filter coefficients from the texture memory in response to a second instruction storing by the texture engine pixels from the texture memory in a texture cache of the texture engine in response to the second instruction and filtering by the texture engine the pixels using the retrieved filter coefficients.

In another example of the disclosure a device comprises a graphics processing unit GPU the GPU comprising a texture engine a texture memory configured to store pixels and filter coefficients wherein the texture memory is accessible to the texture engine and wherein the texture engine further comprises a texture cache and at least one processor. The at least one processor is configured to store with the texture engine filter coefficients of a filter as a texture memory object TMO in the texture memory in response to a first instruction retrieve with the texture engine filter coefficients from the texture memory in response to a second instruction store with the texture engine pixels from the texture memory in the texture cache of the texture engine in response to the second instruction and filter with the texture engine the pixels using the retrieved filter coefficients.

In another example of this disclosure a device comprises means for storing by a texture engine filter coefficients of a filter as a texture memory object TMO in a texture memory accessible to the texture engine in response to a first instruction wherein the texture memory is configured to store pixels and filter coefficients means for retrieving by the texture engine filter coefficients from the texture memory in response to a second instruction means for storing by the texture engine pixels from the texture memory in a means for caching in response to the second instruction and means for filtering by the texture engine the pixels using the retrieved filter.

In another example of this disclosure a non transitory computer readable storage medium that includes instructions stored thereon that when executed cause at least one processor to store by a texture engine of a GPU filter coefficients as a texture memory object TMO in a texture memory accessible to the texture engine in response to a first instruction wherein the texture memory is configured to store pixels and filter coefficients retrieve by the texture engine the filter coefficients from the texture memory in response to a second instruction store by the texture engine pixels from the texture memory in a texture cache of the texture engine in response to the second instruction and filter by the texture engine the pixels using the retrieved filter coefficients.

The details of one or more examples of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages of the disclosure will be apparent from the description and drawings and from the claims.

The demand for high quality and high resolution digital images continues to increase. Since high quality and high resolution digital images typically have large data sizes hardware efficiency for performing image processing tasks becomes more important. One such image processing task is image filtering.

GPUs may render three dimensional scenes made of polygons and or process two dimensional arrays of pixels. A GPU may apply and render one or more textures to each of the polygons. As part of rendering the scene the GPU may be configured to filter the textures before converting a three dimensional representation of the scene to a two dimensional grid of pixels a process referred to as rasterization. GPUs may also be configured to filter two dimensional image data e.g. arrays of pixels.

During the process of image filtering a GPU may be configured to adjust an image based on one or more filter coefficients also called filter weights . More particularly the processing unit may apply a filter mask to pixel values to adjust the pixels. The filter mask comprises a 2D matrix of filter weights and the processing unit applies each filter weight in the filter mask to a corresponding pixel. Typically filter masks are square in shape but may take any size or shape. The size of a filter mask is called a kernel size.

For many filters the processing unit multiplies each filter weight by the corresponding pixel color value. The processing unit then adds the result of each of these multiplications together as the filtered value for the current pixel. In some examples the filtered value may be divided and or have a bias value added to it. Different types of filtering may be achieved by varying the values of the filter weights in the filter mask. Example types of filtering include sharpening interpolation edge finding blurring and embossing as some non limiting examples.

Filtering is often performed using a pointer to an image or group of pixels stored in a memory and a fixed filter stored in dedicated local register space. The fixed filter has a fixed number of filter coefficients and the largest size of the fixed filter is limited by the size of the available dedicated local register space. If more filter sizes are desired more dedicated register space would need to be designed into the GPU. As another drawback switching from one filter to another may require a reload of the entire register space to load new filter coefficients. Some approaches for limiting the amount of hardware needed to store filter coefficients leverage particular features typical of filters e.g. separability and symmetry so that less than the total number of filter coefficients need to be stored. However in general conventional techniques for storing filter coefficients particularly filter coefficients for a plurality of large kernel sizes are inflexible and expensive in terms of hardware cost.

This disclosure proposes techniques for storing filter coefficients for a filter of indefinite size using a GPU. A GPU configured in accordance with the techniques of this disclosure stores filter coefficients in a texture memory of a texture engine of the GPU. The advantages of storing filter coefficients in texture memory include increased filter kernel size as well as increased flexibility in terms of the binary representations and precisions that may be used to represent the filter coefficients as will be discussed in greater detail below.

As illustrated in the example of computing device may include user input interface central processing unit CPU memory controller system memory GPU graphics memory display interface display and buses and . Note that in some examples graphics memory may be on chip with GPU . In some cases CPU memory controller GPU and graphics memory and possibly display interface shown in may be on chip for example in a system on a chip SoC design. User input interface CPU memory controller GPU and display interface may communicate with each other using bus . Memory controller and system memory may also communicate with each other using bus . Buses may be any of a variety of bus structures such as a third generation bus e.g. a HyperTransport bus or an InfiniBand bus a second generation bus e.g. an Advanced Graphics Port bus a Peripheral Component Interconnect PCI Express bus or an Advanced eXentisible Interface AXI bus or another type of bus or device interconnect. It should be noted that the specific configuration of buses and communication interfaces between the different components shown in is merely exemplary and other configurations of computing devices and or other graphics processing systems with the same or different components may be used to implement the techniques of this disclosure.

CPU may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause CPU to execute one or more software applications. The software applications that execute on CPU may include for example an operating system a word processor application an email application a spread sheet application a media player application a video game application a graphical user interface application or another program. Additionally CPU may execute GPU driver for controlling the operation of GPU . The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad or another input device that is coupled to computing device via user input interface .

The software applications that execute on CPU may include one or more graphics rendering instructions that instruct CPU to cause the rendering of graphics data to display . In some examples the software instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API a Direct3D API an X3D API a RenderMan API a WebGL API or any other public or proprietary standard graphics API. In order to process the graphics rendering instructions CPU may issue one or more graphics rendering commands to GPU e.g. through GPU driver to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

In other examples the software instructions that execute on CPU may cause GPU to execute a general purpose shader for performing more general computations applicable to be executed by the highly parallel nature of GPU hardware. Such general purpose applications may be a so called general purpose graphics processing unit GPGPU and may conform to a general purpose API such as OpenCL

Memory controller facilitates the transfer of data going into and out of system memory . For example memory controller may receive memory read and write commands and service such commands with respect to system memory in order to provide memory services for the components in computing device . Memory controller is communicatively coupled to system memory via memory bits . Although memory controller is illustrated in as being a processing module that is separate from both CPU and system memory in other examples some or all of the functionality of memory controller may be implemented on one or both of CPU and system memory .

System memory may store program modules and or instractions that are accessible for execution by CPU and or data for use by the programs executing on CPU . For example system memory may store a window manager application that is used by CPU to present a graphical user interface GUI on display . In addition system memory may store user applications and application surface data associated with the applications. System memory may additionally store information for use by and or generated by other components of computing device . For example system memory may act as a device memory for GPU and may store data to be operated on by GPU as well as data resulting from operations performed by GPU . For example system memory may store any combination of texture buffers depth buffers stencil buffers vertex buffers frame buffers or the like. System memory may include one or more volatile or non volatile memories or storage devices such as for example random access memory RAM static RAM SRAM dynamic RAM DRAM read only memory ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

GPU may be configured to perform graphics operations to render one or more graphics primitives to display . Thus when one of the software applications executing on CPU requires graphics processing CPU may provide graphics commands and graphics data to GPU for rendering to display . The graphics data may include e.g. drawing commands state information primitive information texture information etc. GPU may in some instances be built with a highly parallel structure that provides more efficient processing of complex graphic related operations than CPU . For example GPU may include a plurality of processing elements that are configured to operate on multiple vertices or pixels in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to draw graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than drawing the scenes directly to display using CPU .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry.

GPU may be directly coupled to graphics memory . Thus GPU may read data from and write data to graphics memory without using bus . In other words GPU may process data locally using a local storage instead of off chip memory. This allows GPU to operate in a more efficient manner by eliminating the need of GPU to read and write data via bus which may experience heavy bus traffic. In some instances however GPU may not include a separate memory but instead utilize system memory via bus . Graphics memory may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

CPU and or GPU may store rendered image data in a frame buffer . Frame buffer may be an independent memory or may be allocated within system memory . Display interface may retrieve the data from frame buffer and configure display to display the image represented by the rendered image data. In some examples display interface may include a digital to analog converter DAC that is configured to convert the digital values retrieved from the frame buffer into an analog signal consumable by display . In other examples display interface may pass the digital values directly to display for processing. Display may include a monitor a television a projection device a liquid crystal display LCD a plasma display panel a light emitting diode LED array such as an organic LED OLED display a cathode ray tube CRT display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit. Display may be integrated within computing device . For instance display may be a screen of a mobile telephone. Alternatively display may be a stand alone device coupled to computing device via a wired or wireless communications link. For instance display may be a computer monitor or flat panel display connected to a personal computer via a cable or wireless link.

According to one example of the disclosure and as will be explained in more detail below GPU may be configured to store with a texture engine of GPU filter coefficients as a texture memory object TMO in a texture memory accessible to the texture engine in response to a first instruction. For example GPU may be configured to store the filter coefficients in system memory or graphics memory in response to the first instruction. The texture memory may be configured to store pixels and filter coefficients. GPU may be further configured to retrieve with the texture engine the filter coefficients from the texture memory in response to a second instruction store with the texture engine the pixels from the texture memory in a texture cache of the texture engine in response to the second instruction and filter the pixels using the retrieved filter coefficients.

Software application may be any application that utilizes the functionality of GPU . For example software application may be a GUI application an operating system a portable mapping application a computer aided design program for engineering or artistic applications a video game application or another type of software application that may utilize a GPU.

Software application may include one or more drawing instructions that instruct GPU to render a graphical user interface GUI and or a graphics scene. For example the drawing instructions may include instructions that define a set of one or more graphics primitives to be rendered by GPU . In some examples the drawing instructions may collectively define all or part of a plurality of windowing surfaces used in a GUI. In additional examples the drawing instructions may collectively define all or part of a graphics scene that includes one or more graphics objects within a model space or world space defined by the application.

Software application may invoke GPU driver via graphics API to issue one or more commands to GPU for rendering one or more graphics primitives into displayable graphics images. For example software application may invoke GPU driver via graphics API to provide primitive definitions to GPU . In some instances the primitive definitions may be provided to GPU in the form of a list of drawing primitives e.g. triangles rectangles triangle fans triangle strips etc. The primitive definitions may include vertex specifications that specify one or more vertices associated with the primitives to be rendered. The vertex specifications may include positional coordinates for each vertex and in some instances other attributes associated with the vertex such as e.g. color coordinates normal vectors and texture coordinates.

The primitive definitions may also include primitive type information e.g. triangle rectangle triangle fan triangle strip etc. scaling information rotation information and the like. Based on the instructions issued by software application to GPU driver GPU driver may formulate one or more commands that specify one or more operations for GPU to perform in order to render the primitive. When GPU receives a command from CPU graphics processing pipeline decodes the command and configures one or more processing elements within graphics processing pipeline to perform the operation specified in the command. After performing the specified operations graphics processing pipeline outputs the rendered data to frame buffer associated with a display device. Graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode.

GPU driver may be further configured to compile one or more shader programs and to download the compiled shader programs onto one or more programmable shader units contained within GPU . The shader programs may be written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language etc. The compiled shader programs may include one or more instractions that control the operation of a programmable shader unit within GPU . For example the shader programs may include vertex shader programs and or pixel shader programs. A vertex shader program may control the execution of a programmable vertex shader unit or a unified shader unit and include instructions that specify one or more per vertex operations. A pixel shader program may include pixel shader programs that control the execution of a programmable pixel shader unit or a unified shader unit and include instructions that specify one or more per pixel operations.

Graphics processing pipeline may be configured to receive one or more graphics processing commands from CPU via graphics driver and to execute the graphics processing commands to generate displayable graphics images. As discussed above graphics processing pipeline includes a plurality of stages that operate together to execute graphics processing commands. It should be noted however that such stages need not necessarily be implemented in separate hardware blocks. For example portions of geometry processing stage and pixel processing pipeline may be implemented as part of a unified shader unit. Again graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode.

Command engine may receive graphics processing commands and configure the remaining processing stages within graphics processing pipeline to perform various operations for carrying out the graphics processing commands. The graphics processing commands may include for example drawing commands and graphics state commands. The drawing commands may include vertex specification commands that specify positional coordinates for one or more vertices and in some instances other attribute values associated with each of the vertices such as e.g. color coordinates normal vectors texture coordinates and fog coordinates. The graphics state commands may include primitive type commands transformation commands lighting commands etc. The primitive type commands may specify the type of primitive to be rendered and or how the vertices are combined to form a primitive. The transformation commands may specify the types of transformations to perform on the vertices. The lighting commands may specify the type direction and or placement of different lights within a graphics scene. Command engine may cause geometry processing stage to perform geometry processing with respect to vertices and or primitives associated with one or more received commands.

Geometry processing stage may perform per vertex operations and or primitive setup operations on one or more vertices in order to generate primitive data for rasterization stage . Each vertex may be associated with a set of attributes such as e.g. positional coordinates color values a normal vector and texture coordinates. Geometry processing stage modifies one or more of these attributes according to various per vertex operations. For example geometry processing stage may perform one or more transformations on vertex positional coordinates to produce modified vertex positional coordinates. Geometry processing stage may for example apply one or more of a modeling transformation a viewing transformation a projection transformation a ModelView transformation a ModelViewProjection transformation a viewport transformation and a depth range scaling transformation to the vertex positional coordinates to generate the modified vertex positional coordinates. In some instances the vertex positional coordinates may be model space coordinates and the modified vertex positional coordinates may be screen space coordinates. The screen space coordinates may be obtained after the application of the modeling viewing projection and viewport transformations. In some instances geometry processing stage may also perform per vertex lighting operations on the vertices to generate modified color coordinates for the vertices. Geometry processing stage may also perform other operations including e.g. normal transformations normal normalization operations view volume clipping homogenous division and or backface culling operations. In various examples geometry processing stage may perform filtering.

Geometry processing stage may produce primitive data that includes a set of one or more modified vertices that define a primitive to be rasterized as well as data that specifies how the vertices combine to form a primitive. Each of the modified vertices may include for example modified vertex positional coordinates and processed vertex attribute values associated with the vertex. The primitive data may collectively correspond to a primitive to be rasterized by further stages of graphics processing pipeline . Conceptually each vertex may correspond to a corner of a primitive where two edges of the primitive meet. Geometry processing stage may provide the primitive data to rasterization stage for further processing.

In some examples all or part of geometry processing stage may be implemented by one or more shader programs executing on one or more shader units. For example geometry processing stage may be implemented in such examples by a vertex shader a geometry shader or any combination thereof. In other examples geometry processing stage may be implemented as a fixed function hardware processing pipeline or as a combination of fixed function hardware and one or more shader programs executing on one or more shader units.

Rasterization stage is configured to receive from geometry processing stage primitive data that represents a primitive to be rasterized and to rasterize the primitive to generate a plurality of source pixels that correspond to the rasterized primitive. In some examples rasterization stage may determine which screen pixel locations are covered by the primitive to be rasterized and generate a source pixel for each screen pixel location determined to be covered by the primitive. Rasterization stage may determine which screen pixel locations are covered by a primitive by using techniques known to those of skill in the art such as e.g. an edge walking technique evaluating edge equations etc. Rasterization stage may provide the resulting source pixels to pixel processing pipeline for further processing.

The source pixels generated by rasterization stage may correspond to a screen pixel location e.g. a destination pixel and be associated with one or more color attributes. All of the source pixels generated for a specific rasterized primitive may be said to be associated with the rasterized primitive. The pixels that are determined by rasterization stage to be covered by a primitive may conceptually include pixels that represent the vertices of the primitive pixels that represent the edges of the primitive and pixels that represent the interior of the primitive.

Pixel processing pipeline is configured to receive a source pixel associated with a rasterized primitive and to perform one or more per pixel operations on the source pixel. Per pixel operations that may be performed by pixel processing pipeline include e.g. alpha test texture mapping color computation pixel shading per pixel lighting fog processing blending a pixel ownership test a source alpha test a stencil test a depth test a scissors test and or stippling operations. In addition pixel processing pipeline may execute one or more pixel shader programs to perform one or more per pixel operations. The resulting data produced by pixel processing pipeline may be referred to herein as destination pixel data and stored in frame buffer . The destination pixel data may be associated with a destination pixel in frame buffer that has the same display location as the source pixel that was processed. The destination pixel data may include data such as e.g. color values destination alpha values depth values etc.

Texture engine may included as part of pixel processing pipeline . Texture engine may include both programmable and fixed function hardware designed to apply textures texels to pixels. Texture engine may include dedicated hardware for performing texture filtering whereby one or more texel or pixel values are multiplied by one or more filter coefficient values. Texture engine may store filtering results in an accumulator and add the filtering results to produce a final filtered texel or pixel. As will be explained in more detail below this disclosure proposes modifications to texture engine so that a texture memory and or a texture cache of texture engine may be used to store filter coefficients. It should be noted that the techniques of this disclosure are not limited to texture filtering. Any part of graphics pipeline may perform the filtering techniques of this disclosure of storing filter coefficients in texture memory.

Frame buffer stores destination pixels for GPU . Each destination pixel may be associated with a unique screen pixel location. In some examples frame buffer may store color components and a destination alpha value for each destination pixel. For example frame buffer may store Red Green Blue Alpha RGBA components for each pixel where the RGB components correspond to color values and the A component corresponds to a destination alpha value. Although frame buffer and system memory are illustrated as being separate memory units in other examples frame buffer may be part of system memory .

In an example in accordance with the techniques of this disclosure GPU may be configured to store with texture engine filter coefficients of a filter as a texture memory object TMO in a texture memory e.g. graphics memory or system memory accessible to texture engine in response to a first instruction wherein the texture memory is configured to store pixels and filter coefficients. GPU may be further configured to retrieve with texture engine filter coefficients from the texture memory in response to a second instruction and store with texture engine pixels from the texture memory in a texture cache of the texture engine in response to the second instruction and filter with texture engine the pixels using the retrieved filter coefficients.

The following describes filter coefficient storage techniques of the current disclosure implemented by GPU of . In one example this disclosure proposes storing filter coefficients in a texture memory in response to a filter coefficient store instruction.

As described above previous image filtering hardware required every filter coefficient to be stored in dedicated local register space e.g. filter registers . Previous GPU s included a limited number e.g. 4 or 9 of these dedicated filter registers. The small number of filter registers limited the number of filter coefficients i.e. the kernel size that a GPU could apply to a texture during a single pass through the GPU pipeline. To apply filters having kernel sizes greater than the number of registers a program executing would have to configure the GPU to swap filter coefficients in and out of the dedicated filter registers from memory. Configuring the GPU to swap filter coefficients may require time consuming and difficult GPU programming.

If a program executing on the GPU the kernel size is larger than the number of filter registers as may be the case when performing trilinear filtering as one example the GPU may have to perform an additional pass through the graphics rendering pipeline to load all the filter coefficients into the dedicated filter registers and multiply each of the filter coefficients with corresponding texels.

The dedicated filter registers of previous GPUs were also inflexible in that each filter register may allow only one binary representation and could only use a particular number of bits e.g. 8 16 or 32 bits to represent each filter coefficient. Thus programmers of GPUs could not convert between different binary representations and could not easily switch between precisions of filter coefficients.

The techniques of this disclosure allow a GPU such as GPU to store a potentially unlimited number of filter coefficients in a texture memory bounded only by available texture memory e.g. graphics memory . Texture engine may store filter coefficients in graphics memory and cache both of which are configured to store texture data pixel data and filter coefficients. For hardware GPU applications the storage of texture data can be accomplished using a TMO texture memory object . A TMO is typically used to define fields associated with textures used in graphics applications.

GPUs contain native support to cache texels from textures e.g. using cache . The techniques of this disclosure propose treating filter weights in a similar manner to texels i.e. using TMOs to store filter coefficients. Some examples in accordance with the techniques of this disclosure allow a standard TMO to be used in defining a weight texture and allows pre existing hardware used to manage texel fetching and caching to also manage fetching and caching of weights. In addition to avoiding dedicated storage elements e.g. filter registers this approach also allows for multiple filter operations using filters with different weights to be loaded and in flight at the same time.

Some previous filtering hardware used shader processing elements SPEs of a shader such as a geometry shader to perform filtering. The SPEs included single instruction multiple data SIMD floating point but lacked integer units. Thus using SPEs to perform texture filtering did not allow filtering when using integer filter coefficients. This disclosure describes in some examples that GPU may use processing units of texture engine to perform filtering. Texture engine may include processing elements capable of processing filter coefficients in a variety of different binary number representations. For example texture engine may be configured to perform filtering with integer filter coefficients or floating point coefficients. Additionally texture engine may include texture conversion hardware which enables texture engine to convert pixels or texels from a first binary representation to a second different binary representation as described in greater detail below.

Texture engine may load the filter coefficients from graphics memory and into cache . Texture engine may store the filter coefficients as TMOs. A TMO is a descriptor that is included as part of a graphics API such as OpenGL DirectX etc. which may describe properties about a texture. API specific examples of a TMO include DirectX11 and OpenGL texture objects. A TMO may include a pointer to an address of a texture within a memory such as system memory or graphics memory . The TMO may also include fields related to information about the texture such as a texture size and a texture format. The texture format may indicate a binary representation used for the texels of the texture.

This disclosure extends the concept of a TMO to refer to and describe filter coefficients. The TMO may include a size which may be the size of the filter kernel as well as a filter coefficient format which may indicate a binary representation of each of the filter coefficients. Examples of binary representations for filter coefficients may include floating point representations such as 16 bit 32 bit and 64 bit floating point representations integer representations such as signed and unsigned integer representations of different precisions as well as unsigned normalized representations.

Cache may be configured to store texture data pixel data and or filter coefficient data as TMOs e.g. TMOs and TMOs and may include any combination of filter coefficients pixel data or texels. In some examples TMOs and may be different filter coefficients of two different filter kernels. Also the filter coefficients of TMOs and may be of different sizes. Texture engine may determine the format of the filter kernels based on size fields of TMOs and . The sizes of TMOs and are flexible and may be defined in any manner. Texture engine may then load filter coefficients from cache into filtering unit . Filtering unit may be configured to multiply the texels or pixels by the loaded filter coefficients and store the product of the multiplication in accumulator . Texture engine may iteratively repeat the process of multiplying filter coefficients with texels until GPU has processed all the filter coefficients and or texels specified by a GPU kernel. Texture engine may generally be configured to transform a flat texture onto the correct angle and perspective for a three dimensional space. Texture engine may also be configured to filter texels and or pixels.

In examples of the disclosure that will be described in more detail below GPU may be configured to store with texture engine of GPU filter coefficients of a filter as a texture memory object TMO in a texture memory e.g. graphics memory or system memory accessible to texture engine in response to a first instruction. The texture memory is configured to store pixels and filter coefficients. GPU may be further configured to retrieve with texture engine filter coefficients from the texture memory in response to a second instruction and store with the texture engine pixels from the texture memory in cache of texture engine in response to the second instruction and filter with texture engine the pixels using the retrieved filter coefficients.

As shown in GPU may receive a filter coefficient store instruction that instructs GPU to store one or more filter coefficients in a memory such as graphics memory and or system memory . Graphics memory may be configured to store texture data pixel data and filter coefficients. CPU may generate the coefficient store shader instruction in as part of compiling code from a graphics API. For example an OpenGL or DirectX compiler executing on CPU may generate coefficient store instruction in response to an OpenGL or DirectX function call. The function call may specify one or more filter coefficients to be stored for example in a TMO and may include an indicator e.g. an address or a pointer to the location at which the filter coefficients are stored e.g. in graphics memory .

GPU may receive filter coefficient load instruction that instructs GPU to retrieve filter coefficients from graphics memory . Filter coefficient load instruction may cause GPU to load filter coefficients from a location specified by an indicator in the instruction such as a pointer or a memory address. Filter coefficient load instruction may also instruct texture engine or another unit of graphics pipeline to multiply the filter coefficients by the texels or pixels. Filter coefficient load instruction may also include an indicator e.g. a virtual address or other indicator of a pixel value e.g. source pixel value that is to be filtered. It should be noted that this disclosure will generally describe a pixel value to be filtered. The pixel value to be filtered may be one or more color components that represent the color of the pixel or texel that may be displayed. Any color format may be used to represent the color value.

In one example a pixel value may be represented by an RGBA color format where R represents the red value of the pixel color G represents the green value of the pixel color B represents the blue value of the pixel color and A represents the alpha value i.e. the depth value of the pixel. In other examples the pixel color value may be represented by a luma value Y and two chrominance values e.g. U and V or Cr and Cb . In some applications it may desirable to filter each of the color values e.g. each of RGBA . In other applications it may be desirable to only filter one of the color values e.g. only the luminance value Y in YUV or YCrCb color formats .

Once GPU receives coefficient load instruction a shader processor of GPU may pass the address of the current pixel e.g. source pixel to be filtered and an address of one or more filter coefficients associated with the filter to loop control and addressing unit . Loop control and addressing unit may be configured to load one or more filter coefficients from graphics memory into cache based on the address of the filter coefficients.

Loop control and addressing unit be further configured to load the source pixel and surrounding pixels into cache based on an address specified in coefficient load instruction . Loop control and addressing unit may fetch any surrounding pixel values to be filtered based the source pixel from graphics memory and to store the surrounding pixels in cache .

Filtering unit is configured to multiply a pixel within a filter kernel i.e. the source pixel and any surrounding pixels by a corresponding filter weight. Filtering unit loads the pixels and the filter coefficients from cache e.g. based on the indication in filter load instruction .

Texture engine stores the result of the multiplication at accumulator . Texture engine adds subsequent results of multiplying a pixel value with a corresponding filter to the result currently being stored in accumulator until all pixels designated for filtering have been filtered and each of the specified filter coefficients have been multiplied. Texture engine may store the final accumulated result in accumulator e.g. in graphics memory as the filtered value for the source pixel.

As described above the techniques of this disclosure enable the utilization of a potentially unlimited number of filter coefficients. Rather than having to execute additional passes through the graphics pipeline when a large number of filter coefficients are used loop control and addressing unit iteratively loads filter coefficients from cache and filtering unit multiplies the loaded coefficients from cache until each of the filter coefficients from the kernel have been multiplied against corresponding pixels to produce filtered texels.

Additionally because texture engine is not required to use dedicated filter registers texture engine may apply filters having asymmetrical dimensions. For example filter coefficient load instruction may include a width and a height for the filter kernel. The width and the height may have different values. Loop control and addressing unit may load the array of coefficients indicated by the width and height into cache and cause filtering unit to iteratively multiply each of the coefficients by their corresponding pixel values.

Texture engine may also change a filter coefficient from a first binary representation to a second binary representation. For example texture engine may convert a filter coefficient from an integer binary representation to a floating point representation or from a floating point representation to an integer representation. Texture engine may include dedicated hardware for converting the binary representation of texels pixels and or filter coefficients. Converting filter coefficients from a first binary representation to a second binary representation may be useful for applications such as convolutional filtering. Texture engine or a shader unit may also change the representation of a filter coefficient from a signed representation to an unsigned representation or vice versa. Texture engine may also change the representation of filter coefficients from a normalized representation to an un normalized representation or vice versa.

Texture engine or other pipeline stages may also be configured to increase or decrease the number of bits used to represent a coefficient. For example texture engine may increase the number of bits used to represent a filter coefficient from 8 bits to 16 bits or vice versa. As another example texture engine may increase or decrease the number of bits of a filtering coefficient to match the chroma or luma components of the pixels being filtered. For instance some video processing applications may utilize pixels with a 10 bit luma component rather than a standard 8 bit luma component. Texture engine may adjust a filter coefficient to use 10 bits when filtering pixels with 10 bit luma representations.

Texture engine may be further configured to retrieve the filter coefficients from the texture memory in response to a second instruction . Texture engine may then store pixels from the texture memory in cache of texture engine in response to the second instruction and filter the pixels using the retrieved filter coefficients .

In one example to retrieve the filter coefficients GPU may be configured to store the filter coefficients in texture cache . To filter the pixels GPU may be further configured to load the pixels and the filter coefficients from texture cache and filter with filtering unit of texture engine the pixels the and the filter coefficients loaded from cache to produce filtered pixels.

In another example to filter the pixels GPU is further configured to multiply the retrieved filter coefficients with the cached pixels using an integer multiplication unit of texture engine . In another example GPU may be further configured to store a product of the multiplication of the retrieved filter coefficients and the cached pixels in accumulator of texture engine .

In another example GPU may be configured to covert with texture engine a first numerical representation of the filter coefficients to a second different numerical representation wherein the first numerical representation and the second numerical representation comprise one of a signed integer an unsigned integer a 16 bit floating point a 32 bit floating point an unsigned normalized UNORM representation or a 64 bit floating point representation. In some examples the filter coefficients stored in the texture memory have different vertical and horizontal dimensions. The filter may have a size greater than 4 by 4 coefficients in some examples.

In some examples to filter the pixels the GPU may be further configured to perform trilinear filtering of the pixels in a single cycle using the retrieved filter coefficients. In yet some other example GPU may be configured to generate at least one of the first instruction and the second instruction in response to a graphics application programming interface API call.

In another example the filter coefficients may comprise a first set of filter coefficients and GPU may be further configured to store with texture engine a second set of filter coefficients in the texture memory wherein the first set of coefficients has a first size and the second set of filter coefficients has a second size wherein the first size is different than the second size.

In one or more examples the functions described above may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored as one or more instructions or code on an article of manufacture comprising a non transitory computer readable medium. Computer readable media may include computer data storage media. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices flash memory or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and Blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more DSPs general purpose microprocessors ASICs FPGAs or other equivalent integrated or discrete logic circuitry. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs e.g. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various examples have been described. These and other examples are within the scope of the following claims.

