---

title: Restoring virtualized GCU state information
abstract: Method and apparatus for managing a memory, such as but not limited to a flash memory. In accordance with some embodiments, initial state information is stored which identifies an actual state of a garbage collection unit (GCU) of a memory during a normal operational mode. During a restoration mode after a memory power cycle event, a virtualized state of the GCU is determined responsive to the initial state information and to data read from the GCU. The memory is transitioned from the restoration mode to the normal operational mode once the virtualized state for the GCU is determined.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09122593&OS=09122593&RS=09122593
owner: Seagate Technology LLC
number: 09122593
owner_city: Cupertino
owner_country: US
publication_date: 20150119
---
The present application is a continuation of U.S. patent application Ser. No. 13 658 673 filed Oct. 23 2012 and which will issue on Jan. 20 2015 as U.S. Pat. No. 8 938 597.

Various embodiments of the present disclosure are generally directed to a method and apparatus for managing data in a memory such as but not limited to a flash memory.

In accordance with some embodiments initial state information is stored which identifies an actual state of a garbage collection unit GCU of a memory during a normal operational mode. During a restoration mode after a memory power cycle event a virtualized state of the GCU is determined responsive to the initial state information and to data read from the GCU. The memory is transitioned from the restoration mode to the normal operational mode once the virtualized state for the GCU is determined.

These and other features which may characterize various embodiments can be understood in view of the following detailed discussion and the accompanying drawings.

The present disclosure generally relates to the management of data in a memory such as but not limited to a flash memory of a data storage device.

Data storage devices generally operate to store blocks of data in memory. Some memories employ data management systems to track the physical locations of the blocks so that the blocks can be subsequently retrieved responsive to a read request for the stored data.

Some forms of data storage devices such as solid state drives SSDs can be arranged to write data to a new available location each time a block is presented for writing. Over time multiple versions of the same block may persist in memory with one of the versions being the most current data and the remaining versions being older stale data. Metadata can be generated and used to track the locations and status of the stored data. The metadata may track the relationship between logical and physical addresses of the blocks.

Data management systems often expend considerable effort in maintaining the metadata in an up to date and accurate condition. Metadata failures can occur from time to time due to a variety of factors including loss or corruption of the stored metadata failures in the circuitry used to access the metadata incomplete updates of the metadata during a power interruption etc. In some cases a metadata failure may result in an older version of data being returned to the host. In other cases a metadata failure may render the entire device inoperable.

In some storage systems certain types of metadata relating to the state of the system may be updated on a highly frequent basis. For example a staleness count indicative of the total number of stale blocks in a GCU may be incremented during each write operation to that GCU. In high performance environments this may result in several tens of thousands or hundreds of thousands or more of state changes per second. Other types of state information may be similarly updated at a high rate such as aging e.g. data retention values associated with the GCUs.

It can be prohibitively expensive to directly update fast changing state information in non volatile memory for a variety of reasons including the overhead processing requirements and system bandwidth needed to carry out the updates to the memory as well as the possibility of wearing out the memory due to the sheer number of repetitive writes. It is thus common to accumulate updates to state information in local volatile memory and then periodically transfer snapshots of the state information to the non volatile memory array.

While this latter approach can address the overhead processing and wear concerns of writing directly to the array it also raises the possibility that the state information may be lost due to a power interruption or other disturbance event. Inaccuracies in state information can impact system performance in a variety of ways such as by causing the system to make non optimal selections of GCUs for garbage collection operations and to increase the incidence of write amplification writing duplicate sets of the same data blocks .

Accordingly various embodiments disclosed herein are generally directed to restoring virtualized GCU state information in a data storage device memory such as a flash memory after a power cycle event. As explained below initial state information indicating the actual state of a GCU of a memory is identified during a normal operational mode of the device. The device is subjected to a power cycling event and a virtualized state of the GCU is obtained after the power cycling event. The virtualized state of the GCU is based on the actual state of the GCU prior to the event and on data read from the GCU after the event. The device is thereafter transitioned to the normal operational mode after the virtualized state for the GCU is determined.

In some embodiments the initial state is a staleness count for the GCU which indicates the total number of stale blocks of data in the GCU. The estimated state is an estimated staleness count that is incremented by comparing a forward pointer sequence and a reverse directory sequence associated with the GCU. In other embodiments the actual state is an aging of the GCU in terms of elapsed time of operation and the estimated state is an estimated age determined responsive to a timestamp recorded prior to the power cycling event and an operational parameter measurement of the GCU after the power cycling event.

In some embodiments a storage device enters an operationally ready mode upon initialization during which the device can service access commands e.g. reads and writes from a host. During the operationally ready stage a number of restoration routines are carried out to obtain estimated state information for the various active GCUs. At the conclusion of the virtualization routines the device transitions to a normal operational mode.

These and other features of various embodiments can be understood beginning with a review of which provides a functional block diagram of a data storage device . The device includes a controller and a memory module .

The controller provides top level control for the device and may be realized as a hardware based or programmable processor. The memory module provides a main data store for the device and may be a solid state memory array disc based memory etc. While not limiting for purposes of providing a concrete example the device will be contemplated as a non volatile data storage device that utilizes flash memory in the memory to provide a main memory for a host device. The configuration may be a stand alone environment such as the case of a personal computer or portable electronic device a larger data management system such as a mass storage RAID system etc.

The memory takes the form of one or more dies . Each die may be realized as an encapsulated integrated circuit IC having at least one physical self contained semiconductor wafer. The dies may be affixed to a printed circuit board PCB to provide the requisite interconnections. Each die incorporates a number of arrays which may be realized as a physical layout of the cells arranged into rows and columns along with the associated driver decoder and sense circuitry to carry out access operations e.g. read write erase upon the arrayed cells.

The arrays are divided into planes which are configured such that a given access operation can be carried out concurrently to the cells in each plane. For example an array with eight planes can support eight concurrent read operations one to each plane.

The cells in each plane are arranged into individual erasure blocks which represent the smallest number of memory cells that can be erased at a given time. Each erasure block may in turn be formed from a number of pages rows of memory cells. Generally an entire page worth of data is written or read at a time.

Data are stored to the cell in relation to the amount of accumulated charge on the floating gate . A write operation biases the respective doped regions and the control gate to migrate charge from a channel region CH across the lower barrier to the floating gate . The presence of the accumulated charge on the floating gate tends to place the channel in a non conductive state from source to drain. Data are stored in relation to the amount of accumulated charge.

A greater amount of accumulated charge will generally require a larger control gate voltage to render the cell conductive from source to drain. Hence a read operation applies a sequence of voltages to the control gate to identify a voltage magnitude required to place the channel in a conductive state and the programmed state is determined in relation to the read voltage magnitude. An erasure operation reverses the polarities of the source and drain regions and the control gate to migrate the accumulated charge from the floating gate back to the channel.

The cell can be configured as a single level cell SLC or a multi level cell MLC . An SLC stores a single bit a normal convention is to assign the logical bit value of 1 to an erased cell substantially no accumulated charge and a logical bit value of 0 to a programmed cell presence of accumulated charge . An MLC stores multiple bits such as two bits. Generally n bits can be stored using 2storage states.

An exemplary format for a selected erasure block is depicted in . The block includes N pages with each page corresponding to a row in . The erasure blocks are combined into multi block garbage collection units GCUs as represented in at and . It will be noted that the various erasure blocks shown in may not be necessarily physically adjacent one another.

The GCU is formed of eight 8 erasure blocks and a second GCU is formed of four 4 erasure blocks . The GCUs in a given memory may all be the same size or may have different sizes. All of the erasure blocks may be initially grouped into GCUs or the GCUs may be formed and allocated placed into service to store data as needed during the operational life of the device.

Over time the GCUs in the active stage will become filled with data. The data will become increasingly stale as newer versions of the data are stored in other GCUs. Eventually the active GCUs will be scheduled for garbage collection and transferred to stage . A garbage collection operation generally entails identifying currently valid data within the associated GCU migrating the valid data to another location e.g. a different GCU and performing an erasure on each of the erasure blocks in the GCU. Once the garbage collection operation is completed the GCU is returned to the reallocation pool pending subsequent allocation.

The decision to subject an active GCU to garbage collection can be based on a variety of factors including system utilization requirements aging staleness parametric performance history information associated with the GCU etc. Various types of state information can be maintained for each of the GCUs to aid in the garbage collection determination.

An exemplary format a GCU is shown in . The GCU includes metadata useful by the device in performing write read erasures and garbage collection operations thereon. While the metadata is shown to be physically stored within the GCU it will be appreciated that the metadata may be stored elsewhere in non volatile memory such as in specially configured metadata locations. It will be appreciated that all of locations where the user data and metadata stored in the non volatile memory associated with a particular GCU are considered as included within the GCU and these locations need not be necessarily contiguous.

A sample format for the metadata is shown in to include GCU sequence data forward pointers a reverse directory a staleness count one or more aging values and history information . Other formats can be used as desired so the exemplary formats of are provided merely for purposes of providing an illustrative example and are not limiting.

The forward pointer data from is shown in to include a page identifier field an LBA logical block address field a physical address field a sequence number field and a validity staleness flag . In some embodiments forward pointer data as set forth in is provided for each block of data stored in the GCU. The data may be set forth in a table form at the end of the GCU in the form of headers at the beginning of each erasure block as headers at the beginning of each page in the GCU etc.

The page identifier identifies the page within the GCU at which the associated data block is stored. The LBA field identifies the logical address for the block and the physical address field provides a corresponding physical address within the GCU for the block. The physical address may be a physical block address PBA or other bit address data such as length offset etc. The sequence number can be a forward pointer pointing to a next location such as a different GCU in which a newer version of the data block is stored. The validity flag can provide a staleness flag bit e.g. flag 1 means current data flag 0 means stale data .

The reverse directory is organized so that the location of each block e.g. sector or map unit of data listed in the directory represents a physical address within the GCU. These locations can be expressed as offsets from a starting physical address or using some other convention.

The reverse directory is updated during each write operation to the GCU to identify the most recently written block to the GCU. The reverse directory table is written to the GCU as part of each data write operation so that no additional separate writing operations are required to build and maintain the reverse directory table apart from the writing operations used to write the user data.

Referring again to the staleness count is an accumulated count of blocks in the GCU that are stale. As used herein stale generally refers to blocks that are no longer the most currently active version of those blocks such as older versions of particular LBAs or blocks that are in a discarded state such as those that make up files or data sets that have been deleted by the user. Maintaining a separate staleness count reduces the need for the system to evaluate the forward pointer data and evaluate each block in turn to determine how many blocks are stale within a given GCU.

The aging value can take a variety of forms such as a time date stamp value associated with the allocation of the GCU into the active stage. By subtracting the current time date an elapsed time interval can be determined. The aging value may reflect total elapsed time since allocation or total operational time during that interval. Other formats for the aging value can be used as well including elapsed time since the oldest access operation upon the GCU etc.

The history information generally relates to performance and use metrics associated with the GCU. The history information may be global information such as information that has been accumulated for the entire service life of the GCU. The history information may additionally or alternatively be session based such as accumulated information for the service life of the GCU since it was most recently allocated.

Parameters can take a variety of forms and may include total writes erasure cycles total read operations parametric drift measurements e.g. read disturb voltage drift etc. temperature data associated with the GCU etc. The data may be combined into a combined weighted measurement that indicates the state of the GCU using a bloom filter or other measurement algorithm.

During normal operation of the device the metadata is retrieved and stored in a local volatile memory for access by a controller. The forward pointer data is arranged into a forward map used to service access operations from a host device.

The forward pointer data for GCU A is examined to determine whether any entries existed for LBA A within the GCU. The sequence of shows that GCU A includes an entry for LBA A having a forward pointer to GCU B. The system proceeds to load and examine the forward pointer data for GCU B which provides an entry with a forward pointer to GCU C. The forward pointer data for GCU C provides an entry with a forward pointer to GCU D. The forward pointer data for GCU D has a current entry indicating the physical address of the most current version of LBA A within GCU D e.g. page bits offset etc. . The system proceeds with a read operation upon this location and the requested LBA is output and returned to the host.

If the oldest active GCU does not provide an entry for the requested LBA the system proceeds to search the next oldest active GCU and so on until either a forward pointer is located the most current version of the LBA is located or the data block is not found.

The forward search methodology of is performed during a write operation to write a block of data LBA B by locating the oldest active GCU GCU A and searching the forward pointer data for entries listing LBA B and following the pointers to each new GCU which in this case is from GCU A to GCU B and then from GCU B to GCU C. For simplicity of illustration the same GCU sequence is followed for both the read operation for LBA A and the write operation for LBA B although it will be appreciated that each access operation may follow its own GCU sequence along the forward search. It will also be appreciated that the forward pointers may point to other locations within the same GCU and do not necessarily point to a different GCU.

In the forward search finds the then existing current version of LBA B to be stored in GCU C. The system proceeds to write the new version of data to GCU D provide associated forward pointer data for this new entry change the status of the metadata entry for LBA B in GCU C from current to stale and add a forward pointer to GCU C to point to the new location for the written data in GCU D.

Various state information updates are carried out in conjunction with the foregoing read and write operations. These state information updates may include updating write and read counters are updated updates to the reverse directory table with a new entry for the newly written LBA A block temperature measurements date code entries staleness count updates etc.

The metadata necessary to service these access operations may be transferred from non volatile memory e.g. from the GCUs A D to a local volatile memory and the updated metadata may be transferred back to the flash memory array at a suitable time. While this system is operable during normal operation of the device to maintain an accurate assessment of the state of the system the system is further configured to restore these and other types of state information upon device initialization.

A power cycle event is depicted at step . This represents a disturbance event that interrupts normal processing of the device. The power cycle event can take a variety of forms such as the power being turned off and then back on by a user of the device. An unscheduled or inadvertent power loss may also be represented by the event as well as a soft reset of the controller device. In the case of a USB style thumb drive the power cycle event may involve removal of the device by the user from a connection port with or without safely ejecting the device. Corruption or loss of data in volatile memory is contemplated but not necessarily required. The time during which the device is in a non powered state may be of short or long duration. It is presumed although not necessarily required that the device successfully transferred all pending metadata to non volatile memory prior to the disturbance event.

Upon reinitialization of the device after the power cycle event the controller places the system into an operationally ready state as indicated by step . This may involve a number of self tests and the loading of various programs and data. It is contemplated that the operationally ready state indicates that the device is on line and in a position to begin normal data transactions servicing access commands with a host.

The controller next enters a restoration mode of operation in which several operations are carried out in the background to place the device in a normal operational state. The restoration mode may involve steps that are carried out concurrently or sequentially on each of the currently active GCUs until all are restored with updated state information. These steps can include a staleness count restoration routine as depicted at step a write command servicing routine at step and an aging state restoration routine at step .

Once these respective operations are successfully concluded the controller exits the restoration mode and enters normal operational mode at step . The normal mode of operation continues until the next power cycling event is encountered step . From a host standpoint there may be no change detected as the system transitions from the operational ready state to the normal operational state. However as desired a communication can be provided by the device to the host that the background restoration processing is completed.

Once all the blocks from the reverse directory for the first GCU have been compared to the forward map the GCU is identified as being restored and the next reverse directory for the next active GCU is read and compared. Once all of the reverse directories for all of the GCUs have been read the system transitions to the normal mode of operation.

At step the reverse directory data e.g. and current staleness count data e.g. are initially retrieved for a first selected GCU. At step each block in the reverse directory is compared to the forward map to determine whether the physical address for the block in the reverse directory represents the most current version of that block. The forward map can be searched as discussed above in .

Decision step determines whether the physical addresses match if not the retrieved staleness count for the selected GCU is incremented step . The routine continues at decision step to determine whether additional entries blocks require comparison. If so the routine returns to step where the next block from the reverse directory table is evaluated.

Once all of the entries in the reverse directory table have been compared a final accumulated estimated staleness count for the restored GCU is stored at step . In some embodiments this count value is overwritten or otherwise replaces the previous count value retrieved in step . Decision step determines whether additional GCUs require evaluation and if so the next GCU is selected at step and the foregoing steps are repeated.

At the conclusion of the routine step all of the GCUs will have been restored with regard to the staleness information and the system is ready to enter normal operation pending the completion of other steps carried out by the system during the restoration mode. It will be noted that the servicing of write commands during the routine of may result in further increments to the final staleness count for pending GCUs as discussed next in .

Read commands serviced during the operation of do not present any particular difficulties in that the staleness counts will tend to remain unchanged and the forward mapping data will continue to point to the most current version of each block. Any write operations that occur during the restoration of the staleness data however may tend to affect the staleness counts for the data.

Generally it is contemplated that write operations encountered during the restoration process of may occur in one of three ways the write operation may take place upon a GCU that has not yet been restored the write operation may take place upon a GCU that has already been restored or the write operation may take place upon a GCU that is currently in the process of being restored.

Write operations upon GCUs that have not yet been restored will be accounted for during the normal restoration process. That is the write operation will result in an updated entry in the GCU reverse directory and the subsequent evaluation of that entry in comparison with the forward mapping table will show that the entry is current and hence no increment to the staleness count is necessary.

In the case where the GCU has already been restored it is a straightforward matter to increment the staleness count for the GCU for each write operation that is subsequently performed during the restoration mode for that GCU. For write commands serviced by a GCU currently undergoing restoration an analysis is made whether the particular block s associated with the write command have been evaluated. If the blocks have already been evaluated the staleness count is incremented. If the blocks have not yet been evaluated no increment is provided.

With respect to the flow of the routine is carried out at any time a write command is received from the commencement of the restoration process until the device is transitioned to normal operation. Each of the above contingencies will be addressed in turn.

A write command is initially received at step and the command is serviced at step . This is carried out as described above including a forward search to locate the then most recently stored version of the write data to mark the metadata associated with that version with a staleness flag and a forward pointer and the writing of the data to a new location. The reverse directory for the target GCU is also updated with a new entry reflecting the location within the target GCU of the newly added block.

Decision step next determines whether the target GCU has been restored pursuant to the routine of . If so the virtualized staleness count obtained during the routine of is incremented by one count. If the target GCU has not completed the restoration process the routine passes to step in which an inquiry is made whether the target GCU is currently being restored. If not the routine passes to step and the staleness count is not incremented.

If the target GCU is currently being restored the routine passes to step in which an inquiry is made whether the specific block s associated with the write command have been processed by the routine of . If so the count is not incremented step . If not the staleness count is incremented step .

The routine operates to retrieve the aging data e.g. time date stamp data for each of the active GCUs and to adjust this aging data based on parametric measurements and history data associated with the GCUs. This will provide a virtualized estimated age of the GCU that may take into account a variety of factors such as the time and or temperature of the GCU while the device was in a powered down and an operational state.

As shown by the aging value s and history information for a first selected GCU are retrieved at step . These data may be stored in the GCU metadata as discussed above in . A parametric evaluation is next performed upon the GCU at step . This parametric evaluation can take a variety of forms including performing one or more read operations upon a signature area of the GCU and measuring the degradation of the area.

In some embodiments the parametric evaluation examines variations in the total amount of accumulated charge on individual cells within the GCU. Exemplary charge distribution ranges are provided in at and . These charge distributions represent different amounts of accumulated charge on respective populations of cells programmed to different charge states C0 C3. These states correspond to MLC programming logic states 11 10 00 and 01 as shown. Other forms of programming including SLC programming may be used. Read threshold voltages V1 V4 can be used to differentiate between the respective charge states.

Some of the variation represented in may relate to the programming process whereby discrete quanta of charge are sequentially applied to the cells to raise the total amount of accumulated charge to the desired range. Other variations in the charge distributions can arise due to operational factors for example read disturbance generally operates to modify the amount of total accumulated charge on a cell due to repeated read operations to a cell or to adjacent cells. Read disturbance tends to induce drift in the charge distribution either in terms of more accumulated charge shift to the left in or less accumulated charge shift to the right . Programming operations on adjacent cells can also alter the amount of charge on a cell.

Manufacturing variations can affect the extent to which charge is transferred across the lower barrier layer. Wear can also contribute to charge distribution variation. The greater the number of write erasure cycles on a particular cell generally the less capable the cell may become in terms of both accepting charge during a programming operation and returning charge to the channel during an erasure operation.

It follows that the location and range e.g. width of a respective charge distribution can be used to assess GCU block performance. generally represents three alternative charge distributions and for the cells in a selected erasure block programmed to a selected state in this case 10 .

Distribution is reasonably well behaved and generally has similar range and centering characteristics as the distribution in . Distribution is also reasonably well centered but has a wider relative range. Distribution has a similar range as distribution but is shifted to the left indicating that the cells have experienced read disturbance or other charge leakage effects that has tended to degrade the total amount of charge on the respective cells.

The ranges and locations of the respective distributions can be evaluated by applying a succession of read voltages to the cells in the distribution. shows nominal upper and lower read threshold voltages Va and Vb in conjunction with banded read threshold voltages Va Va Vb and Vb . The banded voltages vary from the nominal read threshold values Va and Vb by some selected interval such as 10 etc.

A voltage source applies a suitable voltage Vto the associated bit line coupled to the cell . A sense amplifier determines whether the applied voltage is sufficient to place the cell into a conductive state through a comparison with a reference voltage Vfrom a reference voltage source . A resulting bit value is output to an output buffer e.g. a 0 or 1 responsive to the comparison.

The range and location of the charge threshold population for a set of cells can be determined by using the circuit of to apply the various read threshold voltages in to each cell in the population and accumulating the results in memory for each of the evaluated memory cells. Referring again to the parametric evaluation step carries out this operation on a selected population of cells in the GCU such as a dedicated area where a special test pattern has been previously written or upon user data at a selected location within the GCU.

The routine proceeds to step where an estimated aging value is generated responsive to the parametric evaluation of step . As desired the estimated aging value is further generated using the history data loaded in step . In some embodiments a virtualized weighted aging value Vcan be obtained using a relation such as the following 1 AGE K2 DRIFT K3 CYCLES K4 TEMP 1 

AGE represents the actual initial age of the GCU determined from the state information e.g. field in . DRIFT represents a numerical value indicative of the presence and or extent of voltage drift determined during the analysis of step . CYCLES represents total write erasure cycles and or read cycles for read heavy environments . TEMP is a temperature measure and K1 K4 are constants. Other formulations can be used including the use of other factors and the use of higher order relationships.

In some embodiments the results from the virtualized age determination may provide a derating factor F that can be combined with the current age value to generate the estimated age. For example the derating factor may be a value such as 0.8 or 1.3 so that the virtual age VAGE of the GCU can thereafter be determined using a relation such as AGE 2 

In some cases the virtualized age Vvalue may provide an older age than that reported by the actual aging value. In other cases the virtualized age Vvalue may indicate a younger age than that reported by the actual aging value. In still further cases the virtualized age Vvalue may provide an estimated value that substantially equals the actual aging value. In each case however the virtualized age provides a better indication of the actual state of the GCU leading to better determinations during system management operations.

The virtualized age value is stored at step such as by replacing the then existing actual age value in the metadata. In this way the virtualized age value will provide the baseline for the next application of the aging restoration routine. This will allow the aging value to converge under steady state conditions and will allow the aging value to be adaptively adjusted under widely changing conditions. In each case the aging value will reflect an accurate indication of the virtual age of the GCU.

Decision step determines whether additional GCUs should be evaluated and if so the routine selects the next GCU at step and returns to step . Once all of the GCUs have been evaluated the process ends at step .

It will now be appreciated that the various embodiments disclosed herein can provide benefits over existing GCU management methodologies. A dynamic GCU state information restoration mechanism as disclosed herein can identify accurate state information for the various GCUs in the system enabling the controller to better select which GCUs to subject to garbage collection operations. The state information can also be used to gain a better understanding of the life cycle of the GCUs allowing operational decisions such as where to store different types of data and how to improve wear leveling to extend the life of the array.

While a flash memory array has been provided as an exemplary environment such is merely for illustration purposes and is not limiting. The techniques disclosed herein are suitable for use in any number of different types of memories including volatile and non volatile memories.

It is to be understood that even though numerous characteristics and advantages of various embodiments of the present disclosure have been set forth in the foregoing description together with details of the structure and function of various embodiments this detailed description is illustrative only and changes may be made in detail especially in matters of structure and arrangements of parts within the principles of the present disclosure to the full extent indicated by the broad general meaning of the terms in which the appended claims are expressed.

