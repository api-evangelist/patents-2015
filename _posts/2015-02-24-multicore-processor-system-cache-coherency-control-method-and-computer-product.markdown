---

title: Multi-core processor system, cache coherency control method, and computer product
abstract: A multi-core processor system includes a processor configured to establish coherency of shared data values stored in a cache memory accessed by a multiple cores; detect a first thread executed by a first core among the cores; identify upon detecting the first thread, a second thread under execution by a second core other than the first core and among the cores; determine whether shared data commonly accessed by the first thread and the second thread is present; and stop establishment of coherency for a first cache memory corresponding to the first core and a second cache memory corresponding to the second core, upon determining that no shared data commonly accessed is present.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09390012&OS=09390012&RS=09390012
owner: FUJITSU LIMITED
number: 09390012
owner_city: Kawasaki
owner_country: JP
publication_date: 20150224
---
This application is a divisional application of U.S. patent application Ser. No. 13 712 816 filed on Dec. 12 2012 which is a continuation application of International Application PCT JP2010 060056 filed on Jun. 14 2010 and designating the U.S. The entire contents of each of the prior applications are incorporated herein by reference.

The present invention relates to a multi core processor system a cache coherency control method and a cache coherency control program that control a cache coherency mechanism.

Recently multi core processor systems have taken a form where an independent cache memory is disposed for each core to maintain coherency of the cache memories using a cache coherency mechanism. Hardware executes maintenance of coherency of shared data stored in the cache memories in the multi core processor system utilizing a cache coherency mechanism and therefore parallel software for a multi core processor can be created easily.

The cache coherency mechanism monitors operations of the cache memories and therefore delay occurs with each access of the cache memory. A technique has been disclosed in which the cache coherency mechanism is controlled based on symmetric multi processing SMP or asymmetry multi processing ASMP to prevent delay see e.g. Japanese Laid Open Patent Publication No. H10 97465 . According to Japanese Laid Open Patent Publication No. H10 97465 the SMP is employed when plural cores execute plural processes and the ASMP is employed when plural cores execute a single process. A process is an execution unit of a program and one or more threads belong to one process. Threads belonging to the same process access the same memory space.

Another technique has been disclosed in which the maintenance of coherency is executed when plural cores execute threads belonging to the same process and the maintenance of coherency is not executed when the plural cores execute threads each belonging to different processes respectively see e.g. Japanese Laid Open Patent Publication No. 2004 133753 .

A further technique of analyzing dependency relations among threads has been disclosed that generates information indicating access of shared data by executing each thread for each statement and thereby analyzes a dependency relation for each statement of the thread see e.g. Japanese Laid Open Patent Publication No. 2000 207248 .

According to the techniques disclosed in the Japanese Laid Open Patent Publication Nos. H10 97465 and 2004 133753 whether coherency is to be maintained is determined for each process. When numerous functions are not used concurrently such as in an embedded device coherency is often maintained for a single process. Therefore even when the techniques according to Japanese Laid Open Patent Publication Nos. H10 97465 and 2004 133753 are applied to an embedded device processing to maintain coherency is always executed whereby operations of the cache coherency mechanism increase. Therefore problems arise in that delay occurs in the access of the cache memory and increased power consumption results.

When the technique according to Japanese Laid Open Patent Publication No. 2000 207248 is used access information of the shared data is analyzed for each statement and therefore the cache coherency mechanism is controlled for each statement. Consequently a problem arises in that the number of control sessions significantly increases.

According to an aspect of an embodiment a multi core processor system includes a processor configured to establish coherency of shared data values stored in a cache memory accessed by multiple cores detect a first thread executed by a first core among the cores identify upon detecting the first thread a second thread under execution by a second core other than the first core and among the cores determine whether shared data commonly accessed by the first thread and the second thread is present and stop establishment of coherency for a first cache memory corresponding to the first core and a second cache memory corresponding to the second core upon determining that no shared data commonly accessed is present.

The object and advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the claims.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are not restrictive of the invention.

Preferred embodiments of a multi core processor system a cache coherency control method and a cache coherency control program according to the present invention are described in detail below with reference to the accompanying drawings.

The CPUs govern overall control of the multi core processor system . The CPUs refer to CPUs that are single core processors connected in parallel. Details of the CPUs will be described hereinafter with reference to . Further the multi core processor system is a system of computers that include processors equipped with multiple cores. Provided that multiple cores are provided implementation may be by a single processor equipped with multiple cores or a group of single core processors in parallel. In the present embodiments for simplicity description will be given taking single core processor CPUs connected in parallel as an example.

The ROM stores therein programs such as a boot program. The RAM is used as a work area of the CPUs . The flash ROM stores system software such as an operating system OS and application software. For example when the OS is updated the multi core processor system receives a new OS via the I F and updates the old OS that is stored in the flash ROM with the received new OS.

The flash ROM controller under the control of the CPUs controls the reading and writing of data with respect to the flash ROM . The flash ROM stores therein data written under control of the flash ROM controller . Examples of the data include image data and video data received by the user of the multi core processor system through the I F . A memory card SD card and the like may be adopted as the flash ROM .

The display displays for example data such as text images functional information etc. in addition to a cursor icons and or tool boxes. A thin film transistor TFT liquid crystal display and the like may be employed as the display .

The I F is connected to a network such as a local area network LAN a wide area network WAN and the Internet through a communication line and is connected to other apparatuses through the network . The I F administers an internal interface with the network and controls the input and output of data with respect to external apparatuses. For example a modem or a LAN adaptor may be employed as the I F . The keyboard includes for example keys for inputting letters numerals and various instructions and performs the input of data. Alternatively a touch panel type input pad or numeric keypad etc. may be adopted.

The cache coherency mechanism is an apparatus that establishes maintains coherency among the cache memories accessed by the CPUs to . Schemes employed by the cache coherency mechanism are roughly classified into a snoop scheme and a directory scheme.

The snoop scheme is a scheme for a cache memory to manage update states of the cache memory of the cache coherence mechanism and cache memories of other CPUs and to exchange information concerning the update states with the other cache memories. A cache coherency mechanism employing the snoop scheme determines which cache memory has the latest data by exchanging the information concerning the update states. The cache coherency mechanism employing the snoop scheme changes the state of the cache memory of the cache coherency mechanism and executes invalidation for the cache memories so that the cache memories can acquire the latest data.

The directory scheme is a scheme for coherency of the cache memories to be centrally managed in a dedicated area that is referred to as a directory . The cache coherency mechanism employing the directory scheme sends data from the cache memories to the directory and whereby all the cache memories share the data.

In either of the schemes the cache coherency mechanism determines whether the cache memory of each CPU coincides with the shared memory which is the main storage. If the cache coherency mechanism determines that the cache memories and the shared memory do not coincide the cache coherency mechanism resolves the incoherency by executing copying updating invalidating etc. of the cache memories to establish maintain coherency. The cache coherency mechanism in the embodiment will be described assuming that the cache coherency mechanism employs the snoop scheme. However the embodiment is also applicable to the cache coherency mechanism if the directory scheme is employed.

Snoop supporting caches to and a snoop supporting bus are present in the cache coherency mechanism . The CPUs to respectively access the corresponding snoop supporting caches to . For example the CPU accesses the snoop supporting cache . The snoop supporting caches will be described in detail with reference to .

The snoop supporting bus is a bus that in addition to the functions of a conventional bus has functions to support the snoop scheme. The snoop supporting bus will be described in detail with reference to . The snoop supporting cache is connected to the snoop supporting bus by a master I F and a slave I F . Similarly the snoop supporting caches to are also connected to the snoop supporting bus by respective master I Fs and slave I Fs.

The shared memory is a storage area accessed by the CPUs to . The storage area is for example the ROM the RAM or the flash ROM .

The software depicted in includes an OS and threads to . The OS is a program that controls the multi core processor system . For example the OS executes a scheduling process for software executed by the CPUs to . The threads to are threads that are assigned to the CPUs to by the OS . The threads to may belong to the same process or may each belong to different processes.

The snoop supporting cache includes a cache line storing unit and a cache line control unit . The cache line storing unit includes a data field an address field and a state field. The data field stores continuous data in a data unit called a line which is about several dozen bytes. The address field stores addresses on the shared memory and corresponding to the lines stored in the data field. The state field stores the state of the data field. The address field and the state field are collectively referred to as a tag area .

The state that the state field can take differs depending on the protocol that realizes the snoop scheme. However typical states include the four states of an M state an E state an S state and an I state .

The M state represents a state where the corresponding line is present only in the corresponding cache memory and is changed from the main storage. The E state represents a state where the corresponding line is present only in the corresponding cache memory and is not changed from the main memory. The S state represents a state where the corresponding line is present in plural cache memories and is not changed from the main storage. The I state represents a state where the corresponding line is invalid. A protocol is also present that uses an O state that is different from the other four states and that represents a state where the corresponding line is present in plural cache memories and the corresponding line is updated. This protocol is responsible for writing the line back into the main storage.

The protocols to realize the snoop scheme are present and are roughly classified into invalid type protocols and update type protocols. The invalid type protocol is a protocol that when a cache memory updates an address that is referred to by plural cache memories determines that the address is dirty and invalidates the corresponding line in all the caches currently referring to the address. The update type protocol is a protocol that when data is updated of an address referred to by plural cache memories notifies the main storage and other cache memories of the updated data.

An example of the invalid type protocol is an MESI Illinois protocol that takes the four states of the M state the E state the S state and the I state and an MOSI Berkeley protocol that takes the four states of the M state the O state the S state and the I state. An example of the update type protocol is an MEI Firefly protocol that takes the three states of the M state the E state and the I state and an MOES DRAGON protocol that takes the four states of the M state the O state the E state and the S state.

In the embodiment the description will be made taking an example of the MESI protocol that is an invalid type protocol. However the embodiment is applicable to any other invalid type protocol and to an update type protocol.

The cache line control unit has various functions that are required for realizing functions of the cache memory such as a data storage structure determining process a line transposing process and a data updating process. The cache line control unit is connected to the corresponding CPU by a CPU I F and to the bus by the master I F and the slave I F .

The cache line control unit includes a snoop control unit to support the snoop. The snoop control unit has a function of controlling the cache line storing unit according to the protocol implementing the snoop scheme. The snoop control unit in the embodiment controls the cache line storing unit according to the MESI protocol. The snoop control unit executes a process of newly fetching a cache line and a process of writing into a cache line. These two processes will be described later with reference to .

The snoop supporting caches are provided one to one with respect to the CPUs to and therefore the cache line storing units and the cache line control units that are internal structures of the snoop supporting caches are also provided one to one with respect to the CPUs. For example the cache line storing unit represents the cache line storing unit of the snoop supporting cache . The cache line storing units and also respectively correspond to the snoop supporting caches and . The cache line control units and the snoop control units corresponding to these reference numerals similarly correspond accordingly.

In the example depicted in the signal sent by the master I F is received by the controller . The controller outputs the selection signal to for example the slave I Fs to . The slave I Fs to each receive the selection signal as well as the address information and the command information and exchange data according to the command information.

The bus supporting snoop has three additional functions including broadcasting blocking and invalidating. Broadcasting is a function of sending a request for a combination of the command information and data information from the master I F to all the slave I Fs that are set in advance as broadcasting destinations. Blocking is a function of forcibly cancelling the current bus connection. Invalidating is a function of invalidating the line corresponding to an address for cache memory. By using these functions the bus fulfills the functions required as the cache coherency mechanism.

Functions of the multi core processor system will be described. is a block diagram of the functions of the multi core processor system . The multi core processor system includes an executing unit a detecting unit an identifying unit a determining unit and a control unit . These functions constituting a control unit units from the detecting unit to the control unit are implemented by an execution of programs stored in the storing apparatus on for example the CPU . The storing apparatus is for example the ROM the RAM or the flash ROM depicted in . The executing unit is implemented by an execution of a program by the cache coherency mechanism .

The multi core processor system can access dependency information that includes a list of threads that do not access the same shared data as an arbitrary thread and an inter process communication area that is not accessed by the arbitrary thread. The dependency information will be described in detail with reference to .

The units from the detecting unit to the control unit may be present as internal functions in a scheduler or may be present outside the scheduler in a state enabling notification of processing results of the scheduler . The scheduler is software included in the OS and has a function of determining processes to be assigned to the CPUs. In the units from the detecting unit to the control unit are present inside the CPU . However the units may be present in any one of the CPUs to or may be present in each of the CPUs to .

For example the scheduler determines threads to be assigned to the CPUs based on priority etc. set in each of the threads. At a predetermined time the scheduler assigns to the CPUs the threads whose dispatchers are determined. The scheduler may include a dispatcher function. In the embodiment the dispatcher function is present in the scheduler .

The executing unit has a function of establishing coherency among values of the shared data stored in the cache memory accessed by the plural cores. For example the cache coherency mechanism is the executing unit and establishes coherency among the values of the shared data in the snoop supporting cache accessed by the CPU and the snoop supporting cache accessed by the CPU .

The detecting unit has a function of detecting a first thread executed by a first core among the cores. For example the detecting unit detects a thread A executed by the CPU that is the first core. For example the timing at which the thread A is detected is the time when the scheduler executes a re scheduling request of the thread. Information concerning the detected thread is stored in a register a local memory etc. of the CPU .

The identifying unit has a function of identifying among the cores when the detecting unit detects the first thread a second thread under execution by a second core other than the first core. For example when the thread A is detected the identifying unit identifies a thread A under execution by for example the CPU other than the CPU among the CPUs to . Information concerning the identified thread is stored to the register the local memory etc. of the CPU .

The determining unit has a function of determining whether shared data is present that is commonly accessed by the first thread and the second thread that is identified by the identifying unit . The determining unit may further determine whether the first and the second threads belong to the same process. The determining unit may determine whether the first and the second threads each belong to a process that is different from that of each other and whether an area is present that is for communication among processes and commonly used by the first and the second threads. The area for communication among the processes will be described in detail with reference to .

The determining unit may determine whether an area is present for communication among processes to be used by the processes to which the first and the second threads belong. When the determining unit determines whether any area is present that is for communication among processes and is commonly used the determining unit may first determine the state where at least one of the first and the second threads does not use the inter process communication area. When the first and the second threads both use the inter process communication area the determining unit may determine whether an area is present that is for communication among processes and that is commonly used by the first and the second threads.

For example the determining unit accesses the dependency information determines whether the second thread is included in the list of the threads that do not access the same shared data of the first thread and depending on the result thereof determines whether any shared data is present that is commonly accessed by the threads. The determining unit may access the dependency information and determine from among areas among processes not accessed by the first and the second threads whether an area is present that is commonly used for communication among processes. The result of the determination is stored in the register the local memory etc. of the CPU .

The control unit has a function of causing the executing unit to stop establishing coherency between the first and the second cache memories respectively corresponding to the first and the second cores when the determining unit determines that no shared data that is commonly accessed is present. The control unit may cause the establishment of coherency to be stopped for the first and the second cache memories when the determining unit determines that the first and the second threads belong to the same process and no shared data that is commonly accessed is present. The control unit may cause the establishment of coherency to be stopped for the first and the second cache memories when the determining unit determines that the first and the second threads each belong to a process different from that of each other and no area is present that is commonly used for communication among processes.

When the control unit causes the establishment of coherency to be stopped for the first and the second cache memories the control unit may cause the shared data stored in the first cache memory to be deleted from the first cache memory.

For example a case is assumed where the determining unit determines that no shared data is present that is commonly accessed by the threads A and A . In this case the control unit causes the establishment of coherency to be stopped for the snoop supporting caches and using the cache coherency mechanism . The control unit flashes the shared data stored in the snoop supporting cache and thereby deletes the shared data from the snoop supporting cache . A flashing operation will be described in detail with reference to .

Based on the premise denoted by the reference numeral the thread A is assigned to the CPU and the thread A is assigned to the CPU in the multi core processor system depicted by reference numeral . In the state denoted by the reference numeral the cache coherency mechanism executes the establishment of cache coherency and thereby the CPUs and can share the data A in a coherent state.

The multi core processor system denoted by a reference numeral depicts a state where the thread assigned to the CPU is switched from the thread A to the thread A i.e. switched from the state indicated by reference numeral . In the state indicated by reference numeral the CPUs and has no commonly accessed data and therefore the cache coherency mechanism may cause the establishment of cache coherency to be stopped. To invalidate the cache coherency for example the suspension of the establishment of cache coherency is implemented by excluding the caches from among the broadcast destinations when broadcast transmission is executed using the bus supporting snoop described above with reference to .

A method of invalidation may be a method according to which the broadcast is stopped to the snoop supporting caches and using the bus . For example when the cache coherency mechanism broadcasts an invalidation notification etc. from the master I F of the snoop supporting cache the cache coherency mechanism does not transmit the invalidation notification etc. to the slave I F but transmits to the slave I Fs and . In this manner when the cache coherency mechanism causes the establishment of cache coherency between specific CPUs to be stopped the transmission destinations are decreased. Therefore the amount of traffic and the amount of processing by the bus can be reduced. Consequently power consumption can be reduced and delay can be prevented.

At process step the dependency relation between the threads belonging to a process to be executed is analyzed by an electronic system level ESL simulator etc. An example of the analysis will be described with reference to . After the analysis at process step a program that is the origin of the process to be executed is rewritten by a compiler. For example the compiler adds information concerning the thread having a dependency relation with a given thread to the program at the head of the given thread etc.

At process step the CPU to execute the process to be executed newly produces a thread. After the production at process step the CPU adds the information of the dependency relation added by the compiler to the dependency information in the OS . The dependency information will be described in detail with reference to . After the addition the process to be executed requests the OS for an assignment of a thread and at process step the CPU whose thread assignment is determined by the scheduler in the OS executes the thread produced.

At process step the scheduler of the OS J determines the thread to be assigned to the CPU. The thread is determined from among the threads produced at process step and the threads that are executable. After determining the thread at process step the scheduler acquires a thread under execution by another CPU.

After acquiring at process step the thread under execution the scheduler determines whether to establish coherency or suspend establishment of coherency based on the registered dependency information . After the determination at process step the scheduler controls the cache coherency mechanism according to the result of the determination. After the control at process step the scheduler assigns the determined thread to the CPU. Process steps to will be described in detail with reference to .

The survey method can be a static approach of acquiring a data area to be used by analyzing source code or a dynamic approach of acquiring a data area to be used by the thread from a record of memory access by actually executing the thread. If comprehensive analysis of the data area for the threads is difficult a combination of threads may be recorded for which as a result of the survey no data area is apparently shared therebetween.

In addition to the survey of the sharing of the data area when an area is present that is apparently not used by the thread to be surveyed among the areas supplied by the OS for communication among processes the area is also recorded. An inter process communication area is an area to execute communication among plural processes and is supplied by the OS using an application programming interface API etc. The memory spaces are generally independent among the processes and a process can not directly access the memory spaces of other processes. Therefore when information is transmitted and received among the processes each of the processes transmits and receives information using the inter process communication area. For example the OS establishes a chunk that is an aggregate of memory spaces and supplies the chunk as inter process communication areas to the processes.

Reference numeral denotes a program that is the origin of the process A. The ESL simulator results from the survey. The program is changed such that information concerning threads that do not share data and information concerning inter process communication areas that are not used are registered in the dependency information when such a thread is started up during the execution of the process A. The compiler compiles the changed program and produces execution code. For example in no shared data is present that is commonly accessed by the threads A and A and therefore the ESL simulator additionally writes into the program of the process A that no dependency exists between the threads A and A .

The OS registers into the dependency information the information concerning the threads that do not share data. In a dependency relation concerning the dependency among the threads of the process A depicted in no dependency is registered for the threads A and A . The OS expands a thread data structure as the dependency information that manages the information concerning the threads that do not share any data and unused inter process communication area. The expanded thread data structure will be described with reference to .

A thread ID field of the thread data structure indicates a value that is collected for each thread. A thread function field indicates the name of a function of the corresponding thread. In addition a field that is present in the conventional thread data structure is included in the thread data structure . Such list fields are expanded in the embodiment as an ID list field of threads sharing no data and a list field of unused inter process communication areas the list fields are elements of the dependency information .

The ID list field of threads sharing no data has pointers to an ID list of threads sharing no data with the thread to be executed. For example in the table for a Browser Main thread whose thread ID is the thread ID list is set in the ID list field of threads sharing no data. The thread ID list has threads registered therein whose thread IDs are and . Thereby it is known that the Browser Main thread does not share data with a Browser Download thread whose thread ID is and a Browser Upload thread whose thread ID is .

Similarly the thread ID list is set in the ID list field of threads sharing no data for Browser Download thread. Based on the content of the thread ID list it is known that the Browser Download thread does not share data with the Browser Main thread.

The list field of unused inter process communication areas has pointers to a list of the inter process communication areas not used by the threads. For example for the Browser Main thread the list field of unused inter process communication areas has the list of inter process communication areas set therein. The list of inter process communication areas has chunks and registered therein.

For an FTP Download thread whose thread ID is and that is executed as a process different from the Browser Main thread the list field of unused inter process communication areas has a list of inter process communication areas set therein. The list of inter process communication areas has chunks and registered therein. When the chunks established by the OS are the chunks to no area is present that is commonly used for communication among the processes in the lists of inter process communication areas and .

As described with reference to the OS manages the threads using the thread data structure . However similarly the OS may manage the processes each of which is an aggregate of threads. The OS may also produce a list of unused inter process communication areas for each process.

The snoop control unit determines a new line fetch step S . After the determination the snoop control unit broadcasts from the master I F to the bus a read request for one line step S .

The snoop control units to each receives the read request and each starts a response for the line fetch process. The snoop control units to all execute the same process and therefore in the description below description will be made with respect to the snoop control unit for simplicity. The snoop control unit searches a tag area of the cache line storing unit for the presence of a line having an address coinciding with the address requested step S . When a line having a coinciding address is searched for the search is started with lines in states other than the I state which is an invalid state.

After the search the snoop control unit determines whether a line having a coinciding address is present step S . If the snoop control unit determines that no line having a coinciding address is present step S NO the snoop control unit causes the response to the line fetch process to come to an end. If the snoop control unit determines that a line having a coinciding address is present step S YES the snoop control unit issues a block instruction to the transmission origin of the read request that is the snoop control unit in the example of step S .

Subsequently the snoop control unit determines whether the state of the coinciding line is in the M state step S . If the snoop control unit determines that the state of the coinciding line is the M state step S YES the snoop control unit writes data of the coinciding line into the shared memory step S . After this writing or if the snoop control unit determines that the state of the retrieved line is a state other than the M state step S NO the snoop control unit changes the state of the line to the S state step S and causes the response to the line fetch process to come to an end.

The snoop control unit determines whether blocking is executed according to a block instruction from any one of the snoop control units to step S . When the snoop control unit determines that no blocking is executed step S NO the snoop control unit stores to the cache line storing unit the line read in the E state step S and causes the line fetch process to come to an end. If the snoop control unit determines that blocking has been executed step S YES the snoop control unit re sends to the bus the read request for one line step S . Subsequently the snoop control unit stores to the cache line storing unit the line read in the S state step S and causes the line fetch process to come to an end.

The snoop control unit determines writing into a line step S . After the determination the snoop control unit determines whether the state of a line that is to be written into is the S state step S . If the snoop control unit determines that the state of the line is the S state step S YES the snoop control unit issues and broadcasts an invalidation request to the snoop control units to step S . After transmitting the invalidation request or if the snoop control unit determines that the state of the line is not the S state step S NO the snoop control unit changes to the M state the state of the line that is to be written into step S . After the changing the snoop control unit writes data into the line that is to be written into step S and causes the writing process to come to end.

The snoop control units to each receives the invalidation request in the process at step S and each starts a response for the writing process. The snoop control units to all execute the same process and therefore in the description below description will be made with respect to the snoop control unit for simplicity.

The snoop control unit searches the tag area of the cache line storing unit for the presence of a line having an address that coincides with the address requested step S . When a line having a coinciding address is searched for the search is started with lines in states other than the I state which is the invalid state. After the search the snoop control unit determines whether a line having a coinciding address is present step S . If the snoop control unit determines that a line having a coinciding address is present step S YES the snoop control unit invalidates the line by setting the line to the I state step S . After the invalidation of the line or if the snoop control unit determines that a line having a coinciding address is not present step S NO the snoop control unit causes the writing process to come to an end.

The CPU detects receipt of a re scheduling request step S . The coherency control process is executed each time a thread is re scheduled. Therefore the coherency control process may reside inside the scheduler or outside the scheduler in a state enabling communication with the scheduler . The CPU determines the thread to be assigned to the CPU for which the re scheduling is to be performed step S . The CPU may be the CPU or when the scheduler also executes the scheduling process for another CPU may be another CPU that receives the re scheduling request.

After the determination the CPU determines whether an assignment prohibition flag has been set step S . If the CPU determines that an assignment prohibition flag has been set step S YES the CPU again executes step S after a specific time period. If the CPU determines that no assignment prohibition flag has been set step S NO the CPU sets the assignment prohibition flag in a CPU other than the CPU for which the re scheduling is performed step S .

After setting the assignment prohibition flag the CPU executes a process of determining a CPU that is to establish coherency step S . The process of determining the CPU that is to establish coherency will be described in detail with reference to . After the determination the CPU determines whether a CPU is present whose state has changed consequent to the process of determining the CPU that is to establish coherency from a state where the CPU establishes coherency to a state where the CPU stops establishing coherency step S . If the CPU determines that a CPU is present whose state has changed step S YES the CPU flashes the cache of the CPU that is to establish coherency step S . Flashing is an operation for example for the snoop control unit to write a line whose data has been updated into the shared memory and sets all the lines including those in the M state to be in the I state.

After the flashing or if the CPU determines that no CPU is present whose state is changed step S NO the CPU controls the cache coherency mechanism step S . It is assumed that the control includes the CPU determining in the process at step S that the CPU that is to establish coherency is the CPU and execution of establishing i.e. maintaining coherency by the CPUs and is stopped.

In this case the CPU instructs the snoop supporting cache to exclude the snoop supporting cache from the broadcast destinations. For example the CPU changes a setting register of the snoop supporting cache and thereby excludes the snoop supporting cache from the broadcast destinations.

Similarly the CPU also instructs the snoop supporting cache to exclude the snoop supporting cache from the broadcast destinations. This exclusion of the snoop supporting cache from the broadcast destinations can reduce the amount of transmission by the broadcasting executed in the processes at steps S and S and can reduce the amount of traffic in the bus . The snoop supporting caches excluded from the broadcast destinations also do not have to execute response processes and thereby enabling a reduction in the amount of processing thereof.

After the control the CPU cancels the assignment prohibition flags of the other CPUs step S and assigns the determined threads to the CPU that is to establish coherency step S . After the assignment the CPU causes the coherency control process to come to an end.

The CPU selects an unselected CPU from among CPUs other than the CPU that is to establish coherency step S . After the selection the CPU determines whether the process to which the thread to be assigned belongs and the process to which the thread under execution by the selected CPU belongs are same process step S .

If the CPU determines that the processes are same step S YES the CPU determines whether the ID list field of threads sharing no data of the thread to be assigned includes the thread under execution by the CPU selected step S . If the CPU determines that the ID list field includes the thread step S YES the CPU determines suspension of the establishment of coherency between the CPU that is to establish coherency and the selected CPU step S . If the CPU determines that the ID list field does not include the thread step S NO the CPU determines establishment of coherency between the CPU that is to establish coherency and the selected CPU step S .

If the CPU determines that the process to which the thread to be assigned belongs and the process to which the thread under execution by the CPU selected belongs are not the same process step S NO the CPU determines whether these processes use the same inter process communication area step S . If the CPU determines that these processes use the same inter process communication area step S YES the CPU determines whether the thread to be assigned and the thread under execution by the selected CPU use the same inter process communication area step S .

If the CPU determines that the threads use the same inter process communication area step S YES the CPU determines establishment of coherency between the CPU that is to establish coherency and the selected CPU step S . If the CPU determines that the threads do not use the same inter process communication area step S No step S NO the CPU determines suspension of the establishment of coherency between the CPU that is to establish coherency and the selected CPU step S .

After the process at any one of steps S S S and S the CPU determines whether an unselected CPU is present among the CPUs other than the CPU that is to establish coherency step S . If the CPU determines that an unselected CPU is present step S YES the CPU progresses to the process at step S. If the CPU determines that no unselected CPU is present step S NO the CPU causes the process of determining a CPU that is to establish coherency to come to an end.

As described according to the multi core processor system the cache coherency control method and a cache coherency control program it is determined whether areas that are accessed by the first and the second threads under execution by the first and the second cores are different areas. If it is determined that the areas are different areas the multi core processor system causes the establishment of coherency to be stopped for the first cache memory corresponding to the first core and the second cache memory corresponding to the second core. Because the areas accessed are different from each other no incoherency occurs between the shared data even if the establishment of coherency is caused to be stopped. Therefore the amount of traffic of the cache coherency mechanism is reduced whereby the multi core processor system can reduce its power consumption and can prevent any delay caused by an increase of the amount of traffic.

The multi core processor system may cause the establishment of coherency to be stopped if it is determined that the first and the second threads belong to the same process and no shared data is present that is commonly accessed by the first and the second threads. Thus even when two cores execute threads of the same process the multi core processor system can reduce the amount of traffic of the cache coherency mechanism as well as power consumption. For an embedded device such as a mobile telephone a case where multiple processes are simultaneously started up is rare and plural threads belonging to the same process are often executed. Therefore the embodiment is especially effective for such a device.

Among the embedded OSs residing on embedded devices an OS is also present that has no concept of process according to which all threads tasks access the same memory space and that is for example ITRON described in Embedded OS Tekizai Tekisho 1 First ITRON and Windows a registered trade mark Understanding Difference of Embedded CE Tech Village CQ Shuppan Co. Ltd. online retrieved on May 13 2010 the Internet .

On the above OS all the threads can access all the memory spaces and therefore coherency is always established even when the conventional approach is applied. However according to the multi core processor system in the embodiment when it is determined that no shared data is present that is commonly accessed the amount of traffic and the amount of processing of the cache coherency mechanism can be reduced and therefore the multi core processor system is especially effective.

The multi core processor system may cause the establishment of coherency to be stopped when the first and the second threads belong to processes that are different from each other and no area that is commonly used by the first and the second threads is present for communication among the processes. Thus the multi core processor system causes the establishment of coherency to be stopped and thereby can reduce the amount of traffic processing and power consumption and can prevent any delay caused by an increase of the amount of traffic except in a case where coherency needs to be established even for different processes.

The multi core processor system may determine whether an inter process communication area is present that is commonly used by processes to which the first and the second threads belong. When the multi core processor system determines whether an inter process communication area is present that is commonly used by the first and the second threads the multi core processor system first may determine a state where at least one of the first and the second threads does not use the inter process communication area.

The determination of whether an area for communication among the processes is used requires a smaller amount of processing than a determination of whether an inter process communication area is present that is commonly used. Therefore the overall amount of processing can be reduced by following a processing order of first determining whether the first and the second threads use the inter process communication area and if it is determined that both of the threads use the area determining whether any area is present that is commonly used.

When the multi core processor system causes the establishment of coherency to be stopped for the first and the second cache memories the multi core processor system may delete from the first cache memory the shared data stored therein. Thereby the multi core processor system can establish coherency of the shared memory even when the multi core processor system causes the establishment of coherency to be stopped.

The cache coherence method described in the present embodiment may be implemented by executing a prepared program on a computer such as a personal computer and a workstation. The program is stored on a computer readable recording medium such as a hard disk a flexible disk a CD ROM an MO and a DVD read out from the computer readable medium and executed by the computer. The program may be distributed through a network such as the Internet.

All examples and conditional language provided herein are intended for pedagogical purposes of aiding the reader in understanding the invention and the concepts contributed by the inventor to further the art and are not to be construed as limitations to such specifically recited examples and conditions nor does the organization of such examples in the specification relate to a showing of the superiority and inferiority of the invention. Although one or more embodiments of the present invention have been described in detail it should be understood that the various changes substitutions and alterations could be made hereto without departing from the spirit and scope of the invention.

