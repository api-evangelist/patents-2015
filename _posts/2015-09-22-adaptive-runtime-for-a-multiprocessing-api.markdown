---

title: Adaptive runtime for a multiprocessing API
abstract: A computer-implemented method includes selecting a runtime for executing a program. The runtime includes a first combination of feature implementations, where each feature implementation implements a feature of an application programming interface (API). Execution of the program is monitored, and the execution uses the runtime. Monitor data is generated based on the monitoring. A second combination of feature implementations are selected, by a computer processor, where the selection is based at least in part on the monitor data. The runtime is modified by activating the second combination of feature implementations to replace the first combination of feature implementations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09465714&OS=09465714&RS=09465714
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09465714
owner_city: Armonk
owner_country: US
publication_date: 20150922
---
This invention was made with Government support under Contract No. B604142 awarded by the Department of Energy. The Government has certain rights in this invention.

Embodiments of the present invention relate to multiprocessing systems and more specifically to an adaptive runtime for a multiprocessing application program interface API .

Various multiprocessing APIs such as open multiprocessing OpenMP exist for programming parallel machines in which memory is shared across multiple processors. Generally processing in parallel machines allows for a master thread to recruit worker threads to perform work in parallel thus more efficiently completing a program s workload.

For the use of a multiprocessing API a compiler transforms a user program into executable code. A runtime environment supports the compiler and when the program runs performs overhead operations to enable some work of the program to be performed in parallel. For example the runtime environment can maintain a list of available worker threads assign work items to the threads and synchronize the threads as needed.

A model for a multiprocessing API may include compiler directives library routines and environment variables which can be implemented in a runtime environment in various ways. The behavior of the runtime environment is dependent on this implementation. Thus a program may run more efficiently with one runtime environment versus another.

According to an embodiment of this disclosure a computer implemented method includes selecting a runtime for executing a program. The runtime includes a first combination of feature implementations where each feature implementation implements a feature of an application programming interface API . Execution of the program is monitored and the execution uses the runtime. Monitor data is generated based on the monitoring. A second combination of feature implementations are selected by a computer processor where the selection is based at least in part on the monitor data. The runtime is modified by activating the second combination of feature implementations to replace the first combination of feature implementations.

In another embodiment a system includes a memory having computer readable instructions and one or more processors for executing the computer readable instructions. The computer readable instructions include selecting a runtime for executing a program. The runtime includes a first combination of feature implementations where each feature implementation implements a feature of an API. Further according to the computer readable instructions execution of the program is monitored and the execution uses the runtime. Monitor data is generated based on the monitoring. A second combination of feature implementations are selected by a computer processor where the selection is based at least in part on the monitor data. The runtime is modified by activating the second combination of feature implementations to replace the first combination of feature implementations.

In yet another embodiment a computer program product for adapting a runtime of a program includes a computer readable storage medium having program instructions embodied therewith. The program instructions are executable by a processor to cause the processor to perform a method. The method includes selecting a runtime for executing a program. The runtime includes a first combination of feature implementations where each feature implementation implements a feature of an API. Further according to the method execution of the program is monitored and the execution uses the runtime. Monitor data is generated based on the monitoring. A second combination of feature implementations are selected by a computer processor where the selection is based at least in part on the monitor data. The runtime is modified by activating the second combination of feature implementations to replace the first combination of feature implementations.

Additional features and advantages are realized through the techniques of the present invention. Other embodiments and aspects of the invention are described in detail herein and are considered a part of the claimed invention. For a better understanding of the invention with the advantages and the features refer to the description and to the drawings.

Various embodiments of this disclosure are configured to adapt or customize a runtime for a program based on a multiprocessing application programming interface API such as open multiprocessing OpenMP or message passing interface MPI by selecting one or more available runtimes through monitoring the program. To this end some embodiments of the customization system provide various feature implementations which may be incorporated into a runtime. The customization system may then monitor the program and decide whether to switch to a different combination of feature implementations.

One feature of the API is the degree of concurrency which refers to the quantity of worker threads that can operate at once. Depending on feature implementations concurrency can be high or low where a high concurrency may negatively impact other features. For example high concurrency may require a large overhead to create the capability of that high concurrency and thus a runtime with high concurrency may also have an undesirably large overhead. Overhead refers to the set of operations and the time spent managing parallelism.

Another feature of the API may be the existence and efficiency of task assignments. Tasks are small items of work. Generally a runtime assigns work to each worker thread in a set of worker threads as part of the overhead for parallelism. Tasks however are small items of work assigned by the runtime after parallelism has begun and after the worker threads are already processing their assigned work. For an example of task management suppose three worker threads are being used to process three binary trees. Further in this example a first binary tree includes only a single node a second binary tree includes a hundred nodes and a third binary tree includes two hundred nodes. It takes an approximately fixed amount of time X for a single node to be processed by a worker thread.

In a first variation of this example when work is assigned in the overhead the runtime assigns a binary tree to each worker thread. The first binary tree is assigned to a first worker thread the second binary tree is assigned to a second worker thread and the third binary tree is assigned to a third worker thread. During processing it takes the first worker thread X time to complete its work it takes the second worker thread 100X time and it takes the third worker thread 200X time. Thus it takes 200X time for all worker threads to complete their work. In this first variation of the example it is clear that the work available was not divided evenly among the available worker threads.

In a second variation of this example when work is assigned in the overhead the runtime assigns only the root node of each binary tree to the worker threads. The root node of the first binary tree is assigned to the first worker thread the root node of the second binary tree is assigned to the second worker thread and the root node of the third binary tree is assigned to the third worker thread. Additionally the runtime maintains a task queue which may initially be empty. During processing of the work assigned each worker thread completes its initially assigned work in X time. The second and third threads observe that one or more additional nodes exist in their binary trees and the runtime adds the processing of those nodes to the task queue. Each node corresponds to a task to be performed where that task is the processing of that node. All three worker threads having finished their assigned work are then assigned additional nodes from the task queue. As processing continues the second and third threads continue to add tasks to the task queue when discovering nodes that require processing and all three nodes may be assigned tasks from the task queue when they complete the work including tasks that has been assigned to them. By the time processing ends all three worker threads may have performed approximately the same amount of work and it may take the worker threads approximately 100X for all of them to complete their work. Thus the use of a task queue in this manner results in more efficient processing of all available work.

Depending on the feature implementations of the runtime a task queue may or may not exist and may operate more or less efficiently. However an implementation with an efficient task queue is likely to have a larger overhead. Thus a tradeoff exists here as with other features. For example at one extreme no task queue is used and the runtime causes each worker thread to execute all work initially assigned to it while at the other extreme each task created is added to the task queue and may be assigned to any worker thread as needed.

Another feature of the API may be the ability and efficiency of performing nested parallelism. As discussed above parallelism occurs when worker threads are used in parallel to complete work that belongs to a master thread. Nested parallelism occurs during parallelism when an initial worker thread s work is further divided among other worker threads making the initial worker thread a master thread for the work assigned to it. Depending on feature implementations of the runtime nested parallelism may or may not be possible and if possible may include small or large additional overhead. For instance the existence of nested parallelism may increase the runtime s overhead and the level of concurrency allowed during nested parallelism may further affect the overhead. Thus once again tradeoffs may be involved when implementing nested parallelism in a runtime . For example at one extreme a runtime may not implement nested parallelism at all while at the other extreme a runtime may require a large overhead to provide full support for this feature with high concurrency.

Another feature of the API may be the use of workshares. Workshares are engaged during iterative loops when each worker thread processes a set of the iterations in parallel with other worker threads processing other sets of iterations for the same loop. If a program includes a no wait clause along with the workshare a worker thread need not wait for other worker threads to finish their iterations before proceeding with other work. The use of a no wait clause at a time when waiting is unnecessary can enable a worker thread to operate more efficiently by allowing that worker thread to move forward rather than waiting unnecessarily. However the ability to wait at a no wait case may require increased overhead in the runtime . For example at one extreme a runtime may ignore no wait clauses such that all worker threads must wait for other iterations to complete while at the other extreme a runtime recognize no wait clauses and thus increase concurrency at the cost of a larger overhead.

It will be understood that the multiprocessing API may support various other features instead of or in addition to the ones described above. For example additional features may provide debugging or performance tracing tools.

As discussed above the feature store may include various feature implementations which may include one or more implementations of each available feature. Thus a runtime s behavior may be modified or adapted by swapping one feature implementation with another feature implementation for the same feature. Through the combinations of various available feature implementations various runtimes may be formed. For example a first runtime may have a small overhead. However this first runtime may not be ideal for a program that requires high concurrency nested parallelism or efficient task management. A second runtime may enable high concurrency but that concurrency may come at the cost of a large overhead and lead to a potentially negative impact on other features. A third runtime may have efficient task management but this may come at the cost of a large overhead and lead to a potentially negative impact on other features. Further a fourth runtime may enable efficient nested parallelism which may also come at the cost of a large overhead and lead to a potentially negative impact on other features.

It is likely the case that one combination of feature implementations is more desirable for running a particular program as opposed to another combination. For example a program may not need nested parallelism and thus the overhead increase caused by efficient nested parallelism in a particular combination of feature implementations may not be worthwhile when executing that program .

In some embodiments a program initially runs with a runtime made up of a default combination of feature implementations of the feature store . This particular runtime is also referred to herein as the default runtime . The feature implementations in the default runtime may be selected by the selector from the feature store based on various criteria. For example and not by way of limitation one feature implementation may be selected for each available feature at random or a fixed default runtime may be used for all programs .

During execution of the program the monitor may monitor the program and may generate monitor data based on that monitoring. For example the monitor data may include runtime statistics of the program . To perform this monitoring for example and not by way of limitation the monitor may remain in communication with the runtime or may access a log file of the executing program .

Based on the monitor data the selector may determine which runtime i.e. which combination of feature implementations the program will use in the future. For example if the selector determines that the monitor data is acceptable and thus that the program is running in a desirable manner the selector may select the runtime currently being used. In that case the current combination of feature implementations need not be changed. Alternatively however if the selector determines that the monitor data is unacceptable and thus the program is not running in a desirable manner the selector may select an alternative runtime made up of an alternative combination of feature implementations from the feature store . The alternative combination may but need not include some overlap of feature implementations with the current combination of feature implementations in the runtime .

The selector may determine acceptability of the monitor data in various ways. In some embodiments to assist with this determination the customization system includes runtime counters to count how many times each feature is used and data from the runtime counters may be included in the monitor data. In one example of determining acceptability of the monitor data the selector may receive monitor data indicating that a first feature is rarely used by the program . In that case if the selector detects that the current runtime includes a fully implemented version of the first feature the selector may deem the monitor data to be unacceptable. Due to this unacceptability the selector may select an alternative combination of feature implementations from the feature store . Specifically for instance the selector may select a feature implementation for the first feature that reduces support for the first feature as the first feature is rarely used. Conversely for another example the selector may receive monitor data indicating that a first feature is often used by the program . In that case if the selector detects that the current runtime includes a reduced implementation of the first feature the selector may deem the monitor data unacceptable. Due to this unacceptability the selector may select an alternative combination of feature implementations from the feature store where the selected combination includes a feature implementation for the first feature that increases support for the first feature. It will be understood that various other mechanisms may be used to determine acceptability of the monitor data.

When a runtime is selected for use in the future it can likely not be used right away because the program may still be in progress. Thus when a runtime is selected its feature implementations may become active at the next appropriate time for switching runtimes . Such a time may occur for example when work is offloaded to a hardware accelerator. Such offloading generally creates a clean start at which time a host machine may change the runtime . Such a time may also occur when a current parallelized phase of the program completes i.e. when work is being performed by a single master thread . In some embodiments the selected feature implementations may be changed individually such that each feature implementation becomes the active implementation for that feature when that feature is not in use. Thus in this case the selected runtime may gradually become active as its feature implementations become active individually. In this manner the customization system may adapt or modify the runtime of a program by replacing its combination of feature implementations with a different combination of features .

In some embodiments the monitor continues to monitor the execution of the program and the selector continues to modify the runtime with new selections as needed while the program runs. In some other embodiments however the customization system may become inactive for the program after stop criteria are met. For example and not by way of limitation the stop criteria may be met when the selector finds the monitor data from the use of a runtime to be acceptable.

In some embodiments the compiler compiles the program before the program can be executed. When compiling the program the compiler has access to program code of the program . Based on this program code the compiler may gain hints about what features of the multiprocessing API may be most useful to the program . In some embodiments the compiler communicates this information to the selector in the form of compiler data. The selector may thus consider this compiler data when selecting a runtime for the program to use.

The execution environment is an environment in which a user runs the program . Within this environment such as when initiating the program the user may provide execution data related to the running of the program . For example and not by way of limitation when calling the program the user may define global variables. In some embodiments the selector considers this execution data when selecting a runtime for the program to use.

Further the selector may use the compiler data execution data or both when deciding on a default runtime for the program to use before monitoring begins.

In some embodiments as shown in the computer system includes a processor memory coupled to a memory controller and one or more input devices and or output devices such as peripherals that are communicatively coupled via a local I O controller . These devices and may include for example a printer a scanner a microphone and the like. Input devices such as a conventional keyboard and mouse may be coupled to the I O controller . The I O controller may be for example one or more buses or other wired or wireless connections as are known in the art. The I O controller may have additional elements which are omitted for simplicity such as controllers buffers caches drivers repeaters and receivers to enable communications.

The I O devices may further include devices that communicate both inputs and outputs for instance disk and tape storage a network interface card NIC or modulator demodulator for accessing other files devices systems or a network a radio frequency RF or other transceiver a telephonic interface a bridge a router and the like.

The processor is a hardware device for executing hardware instructions or software particularly those stored in memory . The processor may be a custom made or commercially available processor a central processing unit CPU an auxiliary processor among several processors associated with the computer system a semiconductor based microprocessor in the form of a microchip or chip set a macroprocessor or other device for executing instructions. The processor includes a cache which may include but is not limited to an instruction cache to speed up executable instruction fetch a data cache to speed up data fetch and store and a translation lookaside buffer TLB used to speed up virtual to physical address translation for both executable instructions and data. The cache may be organized as a hierarchy of more cache levels L1 L2 etc. .

The memory may include one or combinations of volatile memory elements e.g. random access memory RAM such as DRAM SRAM SDRAM etc. and nonvolatile memory elements e.g. ROM erasable programmable read only memory EPROM electronically erasable programmable read only memory EEPROM programmable read only memory PROM tape compact disc read only memory CD ROM disk diskette cartridge cassette or the like etc. . Moreover the memory may incorporate electronic magnetic optical or other types of storage media. Note that the memory may have a distributed architecture where various components are situated remote from one another but may be accessed by the processor .

The instructions in memory may include one or more separate programs each of which comprises an ordered listing of executable instructions for implementing logical functions. In the example of the instructions in the memory include a suitable operating system OS . The operating system essentially may control the execution of other computer programs and provides scheduling input output control file and data management memory management and communication control and related services.

Additional data including for example instructions for the processor or other retrievable information may be stored in storage which may be a storage device such as a hard disk drive or solid state drive. The stored instructions in memory or in storage may include those enabling the processor to execute one or more aspects of the customization systems and methods of this disclosure.

The computer system may further include a display controller coupled to a display . In some embodiments the computer system may further include a network interface for coupling to a network . The network may be an IP based network for communication between the computer system and an external server client and the like via a broadband connection. The network transmits and receives data between the computer system and external systems. In some embodiments the network may be a managed IP network administered by a service provider. The network may be implemented in a wireless fashion e.g. using wireless protocols and technologies such as WiFi WiMax etc. The network may also be a packet switched network such as a local area network wide area network metropolitan area network the Internet or other similar type of network environment. The network may be a fixed wireless network a wireless local area network LAN a wireless wide area network WAN a personal area network PAN a virtual private network VPN intranet or other suitable network system and may include equipment for receiving and transmitting signals.

Customization systems and methods according to this disclosure may be embodied in whole or in part in computer program products or in computer systems such as that illustrated in .

Technical effects and benefits of some embodiments include the ability to automatically adapt or modify a runtime of a program to improve performance of that program. According to some embodiments of the customization system the feature implementations forming a runtime may be customized for suitability to the program being executed thus removing or reducing the need to manually select an appropriate runtime for each program.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiments were chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

The present invention may be a system a method and or a computer program product. The computer program product may include a computer readable storage medium or media having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.

The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be for example but is not limited to an electronic storage device a magnetic storage device an optical storage device an electromagnetic storage device a semiconductor storage device or any suitable combination of the foregoing. A non exhaustive list of more specific examples of the computer readable storage medium includes the following a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory a static random access memory SRAM a portable compact disc read only memory CD ROM a digital versatile disk DVD a memory stick a floppy disk a mechanically encoded device such as punch cards or raised structures in a groove having instructions recorded thereon and any suitable combination of the foregoing. A computer readable storage medium as used herein is not to be construed as being transitory signals per se such as radio waves or other freely propagating electromagnetic waves electromagnetic waves propagating through a waveguide or other transmission media e.g. light pulses passing through a fiber optic cable or electrical signals transmitted through a wire.

Computer readable program instructions described herein can be downloaded to respective computing processing devices from a computer readable storage medium or to an external computer or external storage device via a network for example the Internet a local area network a wide area network and or a wireless network. The network may comprise copper transmission cables optical transmission fibers wireless transmission routers firewalls switches gateway computers and or edge servers. A network adapter card or network interface in each computing processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing processing device.

Computer readable program instructions for carrying out operations of the present invention may be assembler instructions instruction set architecture ISA instructions machine instructions machine dependent instructions microcode firmware instructions state setting data or either source code or object code written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The computer readable program instructions may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider . In some embodiments electronic circuitry including for example programmable logic circuitry field programmable gate arrays FPGA or programmable logic arrays PLA may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry in order to perform aspects of the present invention.

Aspects of the present invention are described herein with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer readable program instructions.

These computer readable program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer a programmable data processing apparatus and or other devices to function in a particular manner such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function act specified in the flowchart and or block diagram block or blocks.

The computer readable program instructions may also be loaded onto a computer other programmable data processing apparatus or other device to cause a series of operational steps to be performed on the computer other programmable apparatus or other device to produce a computer implemented process such that the instructions which execute on the computer other programmable apparatus or other device implement the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of instructions which comprises one or more executable instructions for implementing the specified logical function s . In some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.

The descriptions of the various embodiments of the present invention have been presented for purposes of illustration but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the embodiments the practical application or technical improvement over technologies found in the marketplace or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.

