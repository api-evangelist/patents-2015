---

title: Interfacing application programs and motion sensors of a device
abstract: Interfacing application programs and motion sensors of a device. In one aspect, a high-level command is received from an application program running on a motion sensing device, where the application program implements one of multiple different types of applications available for use on the device. The high-level command requests high-level information derived from the output of motion sensors of the device that include rotational motion sensors and linear motion sensors. The command is translated to cause low-level processing of motion sensor data output by the motion sensors, the low-level processing following requirements of the type of application and determining the high-level information in response to the command. The application program is ignorant of the low-level processing, and the high-level information is provided to the application program.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09342154&OS=09342154&RS=09342154
owner: InvenSense, Inc.
number: 09342154
owner_city: San Jose
owner_country: US
publication_date: 20150106
---
Under 35 U.S.C. 120 this application is a Continuation Application and claims priority to U.S. application Ser. No. 12 106 921 filed Apr. 21 2008 entitled INTERFACING APPLICATION PROGRAMS AND MOTION SENSORS OF A DEVICE and also claims the benefit of U.S. Provisional Application No. 61 022 143 filed Jan. 18 2008 entitled Motion Sensing Application Interface and is related to co pending U.S. Utility application Ser. No. 11 774 488 entitled Integrated Motion Processing Unit MPU With MEMS Inertial Sensing And Embedded Digital Electronics filed Jul. 6 2007 all of which is incorporated herein by reference in its entirety.

The present invention relates generally to motion sensing devices and more specifically to interfacing application programs to motion sensors of a device.

Motion sensors such as accelerometers or gyroscopes are often used in electronic devices. Accelerometers can be used for measuring linear acceleration and gyroscopes can be used for measuring angular velocity. The markets for motion sensors include mobile phones video game controllers PDAs mobile internet devices MIDs personal navigational devices PNDs digital still cameras digital video cameras and many more. For example cell phones may use accelerometers to detect the tilt of the device in space which allows a video picture to be displayed in an orientation corresponding to the tilt. Video game console controllers may use accelerometers and or gyroscopes to detect motion of the hand controller that is used to provide input to a game. Picture and video stabilization is an important feature in even low or mid end digital cameras where lens or image sensors are shifted to compensate for hand jittering measured by a gyroscope. Global positioning system GPS and location base service LBS applications rely on determining an accurate location of the device and motion sensors are often needed when a GPS signal is attenuated or unavailable or to enhance the accuracy of GPS location finding.

Most existing electronic devices tend to use only the very basic of motion sensors such as an accelerometer with peak detection or steady state measurements. For example current mobile phones use an accelerometer to determine tilting of the device which can be determined using a steady state gravity measurement. Such simple determination cannot be used in more sophisticated applications using for example gyroscopes or other applications having precise timing requirements. Without a gyroscope included in the device the tilting and acceleration of the device is not sensed reliably. This is often misleading in non gyroscope navigational devices for example a non gyroscope dead reckoning feature can misjudge automobile location for several blocks while the automobile is stopped at a sloped traffic light. And since motion of the device is not always linear or parallel to the ground measurement of several different axes of motion using an accelerometer or gyroscope is required for greater accuracy.

More sophisticated motion sensors typically are not used in electronic devices. For example image stabilization and dead reckoning features are both important features for a mobile phone with GPS or a higher resolution camera but there is no available solution in the current mobile phone market. Some attempts have been made for more sophisticated motion sensors in particular applications such as detecting motion with certain movements. But most of these efforts have failed or are not robust enough as a product. This is because the use of motion sensors to derive motion is complicated. For example when using a gyroscope it is not trivial to identify the tilting or movement of a device. Using motion sensors for image stabilization for sensing location or for other sophisticated applications requires in depth understanding of motion sensors which makes motion sensing design very difficult.

The difficulty of motion sensing design also causes difficulty in porting a design from one system to another system. Most raw data from motion sensors is gathered and processed at the level of the application software running on the device which does not allow for other applications to utilize the same sensor output. Furthermore motion sensing design is typically very system dependent and intended for one specific application which prevents it from being ported to other systems. For example image stabilization software is typically very dependent on the particular hardware of the digital camera in which it is used such as the available picture resolution and range of zoom.

Accordingly a system and method that provides a simple application interface API to be available for different applications allowing motion sensor data collection to be more easily defined and used by the user and allow easier porting and maintenance of a motion sensing design for different hardware requirements would be desirable in many applications.

The invention of the present application relates to interfacing application programs to motion sensors of a device. In one aspect of the invention providing an interface for one or more applications provided on a motion sensing device includes receiving a high level command from an application program running on the motion sensing device where the application program implements one of a plurality of different types of applications available for use on the motion sensing device. The high level command requests high level information derived from the output of motion sensors of the motion sensing device that include rotational motion sensors and linear motion sensors. The high level command is translated to cause low level processing of motion sensor data output by the motion sensors the low level processing following requirements of the type of application and intelligently determining the high level information in response to receiving the high level command. The application program is ignorant of the low level processing and the high level information is provided to the application program.

In another aspect of the invention a method for providing motion sensor data from motion sensors to an application program running on a motion sensing device includes sampling motion sensor data output by the motion sensors at a first sampling rate where the motion sensors include rotational motion sensors and linear motion sensors. The motion sensor data is stored in a buffer and at least a portion of the buffered motion sensor data is retrieved for the application program at a second sampling rate required by an application implemented by the application program the second sampling rate being lower than the first sampling rate.

In another aspect of the invention a method for processing motion sensor data from motion sensors on a motion sensor device includes sampling motion sensor data output by the motion sensors at a first sampling rate such that the motion sensor data is used to provide information to a first application program implementing a first application on the motion sensor device. The motion sensors include rotational motion sensors and linear motion sensors. The motion sensor data is low pass filtered to a second sampling rate lower than the first sampling rate wherein the filtered motion sensor data is used to provide information to a second application program implementing a second application on the motion sensor device different from the first application. The first and second application programs are running simultaneously on the motion sensor device and the first application requires motion sensor data to be sampled at sampling rate greater than the second sampling rate.

Aspects of the present invention provide an application programming interface to be available for applications running on a motion sensing device. The interface allows easy development of application programs using complex motion sensor data in devices having motion sensors allows application programs to be ported to and from different motion sensing devices having different hardware and operating systems and provides easier maintenance of systems. Other aspects of the invention relax the sampling rate requirements and reduce the processing for an application program to sample information related to sensor data and allow application programs with different sensor data sampling requirements to run simultaneously on a motion sensing device.

The present invention relates generally to motion sensing devices and more specifically to interfacing application programs to motion sensors of a device. The following description is presented to enable one of ordinary skill in the art to make and use the invention and is provided in the context of a patent application and its requirements. Various modifications to the preferred embodiment and the generic principles and features described herein will be readily apparent to those skilled in the art. Thus the present invention is not intended to be limited to the embodiment shown but is to be accorded the widest scope consistent with the principles and features described herein.

To more particularly describe the features of the present invention please refer to in conjunction with the discussion below.

Device includes an application processor memory interface devices a motion processing unit analog sensors and digital sensors . Application processor can be one or more microprocessors central processing units CPUs or other processors which run different software programs for the device . For example different software application programs such as menu navigation software games camera function control navigation software and phone or other functional interfaces can be provided. In some embodiments multiple different applications can be provided on a single device and in some of those embodiments multiple applications can run simultaneously on the device . Examples of software running on the application processor are described in greater detail below with respect to .

Device also includes components for assisting the application processor such as memory RAM ROM Flash etc. and interface devices . Interface devices can be any of a variety of different devices providing input and or output to a user such as a display screen audio speakers buttons touch screen joystick slider printer scanner camera etc. Memory and interface devices can be coupled to the application processor by a bus .

Device also can include a motion processing unit MPU . The MPU is a device including motion sensors that can measure motion of the device or portion thereof in space. For example the MPU can measure one or more axes of rotation and one or more axes of acceleration of the device. In some embodiments the components to perform these functions are integrated in a single package. The MPU can communicate motion sensor data to an interface bus to which the application processor is also connected. In one embodiment processor is a controller or master of the bus . For example in some embodiments the interface bus can be a digital serial interface bus implemented according to such standards as I2C or Serial Peripheral Interface SPI bus. Some embodiments can provide bus as the same bus as interface bus .

MPU includes motion sensors including one or more rotational motion sensors and one or more linear motion sensors . For example in some embodiments the rotational motion sensors are gyroscopes and the linear motion sensors are accelerometers. Gyroscopes can measure the angular velocity of the device or portion thereof housing the gyroscopes . From one to three gyroscopes can typically be provided depending on the motion that is desired to be sensed in a particular embodiment. Accelerometers can measure the linear acceleration of the device or portion thereof housing the accelerometers . From one to three accelerometers can typically be provided depending on the motion that is desired to be sensed in a particular embodiment. For example if three gyroscopes and three accelerometers are used then a 6 axis sensing device is provided providing sensing in all six degrees of freedom.

In some embodiments the gyroscopes and or the accelerometers can be implemented as MicroElectroMechanical Systems MEMS . Supporting hardware such as storage registers for the data from motion sensors and can also be provided.

In some embodiments the MPU can also include a hardware processing block . Hardware processing block can include logic or controllers to provide processing of motion sensor data in hardware. For example motion algorithms or parts of algorithms may be implemented by block in some embodiments. Some embodiments can include a hardware buffer in the block to store sensor data received from the motion sensors and . For example in some embodiments described herein the hardware buffer stores sensor data to be sampled by motion algorithms as described in greater detail below with respect to .

One example of an MPU is described below with reference to . Other examples of an MPU suitable for use with the present invention are described in co pending U.S. patent application Ser. No. 11 774 488 filed Jul. 6 2007 entitled Integrated Motion Processing Unit MPU With MEMS Inertial Sensing and Embedded Digital Electronics and incorporated herein by reference in its entirety. Suitable implementations for MPU in device are available from Invensense Inc. of Santa Clara Calif.

The device can also include other types of sensors. Analog sensors and digital sensors can be used to provide additional sensor data about the environment in which the device is situation. For example sensors such as a barometer a compass a temperature sensor optical sensor such as a camera sensor infrared sensor etc. ultrasonic sensor radio frequency sensor or other types of sensors can be provided. In the example implementation shown digital sensors can provide sensor data directly to the interface bus while the analog sensors can be provide sensor data to an analog to digital converter ADC which supplies the sensor data in digital form to the interface bus . In the example of the ADC is provided in the MPU such that the ADC can provide the converted digital data to hardware processing of the MPU or to the bus . In other embodiments the ADC can be implemented elsewhere in device .

A FIFO first in first out buffer can be used as a hardware buffer for storing sensor data which can be accessed by the application processor over the bus . The use of a hardware buffer such as buffer is described in several embodiments below. For example a multiplexer can be used to select either the DMA writing raw sensor data to the FIFO buffer or the data RAM writing processed data to the FIFO buffer e.g. data processed by the ALU .

The MPU as shown in thus can support one or more implementations of processing motion sensor data. For example the MPU can process raw sensor data fully where programs in the program RAM can control the ALU to intelligently process sensor data and provide high level data to the application processor and application programs running thereon. Or raw sensor data can be pre processed or processed partially by the MPU using the ALU where the processed data can then be retrieved by the application processor for additional low level processing on the application processor before providing resulting high level information to the application programs. Or raw sensor data can be merely buffered by the MPU where the raw sensor data is retrieved by the application processor for the required low level processing into high level data for the application programs. In some embodiments different applications or application programs running on the same device can use different ones of these processing methods as is most suitable to the application or program.

An application software layer includes one or more application programs typically provided by one or more application developers and run on the application processor . An application program implements a particular application or portion thereof which can also be referred to as a mode on the device e.g. each application is implemented by one or more application programs. The application programs can provide processing and input output functions as well as the appropriate user interface functions specific to their application such as controlling a camera lens and displaying images in a camera application implementing a game in a game application outputting directions and current location of the device in a navigation application etc.

The application software layer communicates with system software which manages the resources of the device including communication between hardware and software components. The software structure for the motion sensing in embedded system applications can be defined in separate layers as shown in . Thus system software includes an application programming interface API layer a real time operating system RTOS layer a motion algorithm layer and a sensor device driver layer . Additional layers can also be included as appropriate.

API layer provides a set of abstracted and high level functions for an application program to use which greatly simplifies the interface and communication between an application program and lower level components of the device such as the motion sensors. The API layer facilitates an interface to the motion sensing engine of the device by providing a motion library of different low level functions or algorithms to use which are related to motion sensor data. A particular API within the API layer can be defined to correspond to one or more motion algorithms where those corresponding algorithm s can be used by an application accessing that API.

The API layer can provide predefined high level abstracted commands as well as associated control parameters or settings to be used by an application program to receive information including high level information based on motion sensor data sampled from the motion sensors of the device . The API layer translates a high level command from the application program to the necessary motion algorithms needed to implement the command and can thus translate a request for information related to a particular application to the processing necessary for that particular application. Each type of application running on the device requires a particular set of motion based high level data based on the functions of that application type. For example a user motion cursor control type of application may require 2 D or 3 D coordinates based on motion of device while an image stabilization type of application may require an indication of blur and related information based on motion of device . The motion algorithms the API accesses know the precise requirements associated with the low level processing of motion sensor data to obtain a particular type of high level information that was commanded by the application program as related to the application associated with the high level command. For example the motion algorithms know to sample motion sensor data from the motion sensors at a higher sampling rate such as 500 Hz for an image stabilization application after having received a high level command that indicates it will be used for the image stabilization application or function.

Thus the low level processing can intelligently determine high level information required by the application program and provide it to the application programs while the application program can be ignorant of any required low level processing of motion sensor data and processing and timing requirements used in that processing needed to obtain the high level information. For example an application program developer need only make a call with an API command to for example receive processed motion sensor data appropriate to the developer s application without having to know how to collect and process raw sensor data. The API layer can be defined as operation system independent as possible to make application software as portable as possible.

The API layer can provide multiple particular types of APIs that are useful for one or more types of applications that can be implemented and used on the device . For example a particular motion sensing type of API can be provided which may be used by certain applications such as cell phone or gaming applications. Multiple different types of applications can preferably be implemented on the device and multiple different APIs for these applications are provided. Some types of applications may have no need for a particular type of API. For example a navigation application may not need to use an image stabilization API.

In some embodiments the API can be broken down into a low level API e.g. raw data acquisition calibrated data acquisition initializing sensors setting parameters performing mathematical functions a mid level API e.g. getting processed data such as roll pitch and yaw heading location or blur amount and a high level API e.g. running a DR Kalman filter in one line of code . A mid level API may be used by application developers that wish to construct their own application from more basic algorithmic building blocks. Other embodiments can provide only two of the API layer levels. The API software runs efficiently in the background during system operation and the application programs in layer can be provided in any of several different computer languages or formats. Thus bindings can be created for the API layer that allow it to be used with other programming languages.

RTOS layer can be provided as an operating system for the device to control and manage system resources in real time and enable functions of the application software as well as other layers such as the API layer motion algorithm layer and motion sensor device drivers . The operating system can interface application programs with other software and functions of the device . RTOS layer can be any of a variety of available operating systems suited for embedded systems with real time operation. The RTOS layer can communicate with any of the other layers including the application software which uses functions provided by the RTOS layer . RTOS layer can be implemented as a specific operating system for the device or a more general operating system adapted for use with the device .

Motion algorithm layer provides a motion library of motion algorithms that provide intelligent lower level processing for raw sensor data provided from the motion sensors and other sensors. Such algorithms in layer can take the raw sensor data and combine and form the data into high level information and or application specific information.

For example a motion algorithm can take motion sensor data from several motion sensors and process and or combine the data into high level information useful for a particular application such as roll pitch yaw of the device or X and Y coordinates for positioning a cursor on a two dimensional screen. An algorithm typically has precise timing requirements for sampling the motion sensor data from the motion sensors. For example an algorithm may accumulate motion sensor data and integrate the data points to obtain an angle of motion or other motion characteristic of the device . In addition the algorithms can use data from one or more other sensors in addition to motion sensor data to determine the high level information such as from a pressure temperature and or direction sensor. The output of the algorithms can be reported to or retrieved by the API layer which provides the high level information to an application program and so the processing performed by the motion algorithms need not be known by any application developer. The developer need only use the API functions provided in the API layer to request desired high level information based on motion sensor data.

A motion algorithm can be associated with one or more particular applications and or APIs. For example a motion sensing API can use a gesture recognition motion algorithm that checks a sequence of sensor data and outputs a determined feature such as a gesture when such a feature is detected. This gesture detection is in turn defined in the API layer as a simple command input or event for the application software. The motion algorithm can be designed as operation system independent as possible which reduces obstacles in porting the algorithms between different systems.

The sensor device driver layer provides a software interface to the hardware sensors of the device . The driver layer provides an interface with multiple types of sensors of the device including the gyroscopes accelerometers and other sensors and as described with reference to . For example the sensed results from motion sensors and can be written into registers in the MPU by the hardware and those registers are then accessed by the device driver layer . The driver layer can then provide the accessed sensor data to one or more motion algorithms in the motion algorithm layer for processing. In some embodiments the device driver layer interfaces with the hardware processing of the MPU where the hardware processing may have processed some sensor data using motion algorithms.

The RTOS layer can oversee the other software layers including the API layer the motion algorithms layer and the sensor device driver layer . The API layer can include different types of APIs each API characterized for a specific type of high level information that may be useful to one or more application programs that can be executed by the device . In the example of the API layer includes a motion sensing API an image stabilization API and a navigation API .

The motion sensing API can include high level commands and functions for requesting high level information that describes motion of the device or a portion thereof or describes features determined by the motion of the device. Such high level functions can include gesture recognition which recognizes particular motions input by a user to invoke a particular command. For example a gesture can include moving the device in a particular direction orientation or in a sequence of directions orientations and or for a specified duration to initiate a function associated with that gesture such as delete pan zoom etc. The API can allow the application program developer to simply request whether any of particular predefined gestures have been detected without the developer having to know how to check for those gestures using raw motion sensor data or how to process that sensor data using appropriate algorithms. Other motion sensor applications include requesting motion data relating to user interface functions such as scrolling a view or cursor control and requesting data indicating input has been provided to a game such as motion orientation data or a gesture to move a graphical object on a screen or activate a function within the game such as firing a weapon or opening a door.

Another example of a different API in the API layer is an image stabilization API . This API allows an application program to request status of the device relating to high level image stabilization functions e.g. as used in a digital still camera or video camera. For example such high level image stabilization functions can include estimating the amount or degree of blur within an image that has been captured by the camera lens based on the amount of particular motions detected during image capture. The API can allow an application program to simply request the amount of blur in an image where the application program does not have to compute this blur using raw sensor data or process the raw sensor data with algorithms. Other high level image stabilization functions can include image reconstruction in which the application program can request digital processing on a captured image to correct or reconstruct the original color or other characteristics of a blurred image without having to perform that digital processing itself. Other image stabilization functions can include generating a point spread function PSF blending images or evaluating an image for particular characteristics related to motion sensing such as blur .

Another example of a different API in the API layer is a navigation API . This API allows an application program to request status of the device relating to high level navigation functions e.g. as used with navigational devices. For example such high level navigation functions can include providing a dead reckoning location of the device and compensating for gravity in such a dead reckoning estimation. The API can allow an application program to simply request that gravity be compensated for in the data rather than having to perform this compensation itself. Other high level navigation functions can include applying a navigation Kalman filter to the sensor data to compensate for error in recorded position when providing continuously updated information about the position and or velocity of the device and setting a noise matrix or a process matrix.

The different APIs in the API layer can all be provided on a single device that implements the different multiple applications in the application layer . The ease of using the APIs allows a large and quite different variety of applications to be provided on a single device without each application developer being required to have specialized knowledge in the collection and processing of motion sensor data for a particular application. In some embodiments the multiple applications can be executed simultaneously on the device . This is described in greater detail below with respect to .

The motion algorithms layer can include algorithms such as filters which are called by the APIs in the API layer . Some of the motion algorithms can be basic functional algorithms such as providing the current orientation of the device in space or indicating whether the device is currently being moved in space or not. Algorithms can combine the outputs of different sensors and process the results e.g. using integration derivatives etc. to deliver higher accuracy sensing results as well as providing higher level information derived from the raw sensor data.

More specific algorithms can also be included for particular applications. For example the motion algorithm programs can include gesture recognition algorithms for use with the motion sensing API which determine whether particular gestures have been made by a user with an input device. Such algorithms can determine if the user input a tapping gesture or other gesture based on sensor data etc. or for a more mid level API provide roll pitch and yaw of the device or z rotation of the device. Similarly cursor control algorithms can be used with the motion sensing API to determine the X Y coordinates for a user input device at which location a cursor is to be displayed on a display screen based on roll pitch and yaw data as determined by the algorithm from raw motion sensor data. Other user interface and continuous control algorithms can also be used such as for determining whether icons on a display screen have been selected by a user based on sensor input compensation for hand jitter during cursor control and moving one or more displayed images based on motion sensor data. Gaming algorithms can be used with the motion sensing API to provide data related to a gaming application such as whether a particular gesture or motion was received which the application uses as input to control a game function.

Image stabilization algorithms can include blur estimation and image reconstruction algorithms. Blur algorithms can be used to determine whether a blur has occurred in an image based on motion sensor data at the time of image capture such as an image captured by a camera lens. For example a point spread function PSF can be used by the algorithm to determine the blurriness. Image reconstruction algorithms can be used to correct or reconstruct characteristics of an image that may have been distorted or removed e.g. through blur. Other image stabilization algorithms are described in copending patent application U.S. patent application Ser. No. 11 774 488 and incorporated herein by reference in its entirety. Navigation algorithms can include dead reckoning gravity compensation algorithms that can be used to compensate for gravity when determining a dead reckoning and a navigation Kalman filter that can be used to compensate for errors in sensed positions. For example a dead reckoning location algorithm can use data from one or more of the accelerometers to determine position of the device and data from one or more of the gyroscopes to determine the heading or direction of motion of the device .

The device driver layer provides a software interface to the hardware motion sensors and of the device and other sensors and as described above with respect to . The layer can include drivers for gyroscopes accelerometers barometer compass sensor and other sensors as described with reference to .

In the method an application program interfaces with a particular API of the API layer which provides motion sensing functions useful for the application program. In some embodiments multiple applications can interface with a single API while other application programs may have a dedicated API for their exclusive use. An application program can also access multiple types of APIs as necessary. The interfacing with the API is at a high level that allows the application program to ignore the implementation details of the information it requests. Thus for example a command to the API can be an equivalent to provide the current location of the device or provide the blur kernel for the last image or provide the type of movement the device is exhibiting currently. 

An API of the present invention can also use event driven programming. For example when using a motion sensing API the application program does not typically need to check the input of the motion sensors every 10 ms. Instead if the application program is looking for a gesture composed of particular motion sensor data it requests the API to interrupt the application program when that gesture is detected this is an event . Examples of the use of an API of the present invention by an application program is shown below in Listings 1 and 2 where ml stands for motion library .

Method of starts at and in step the application program initially sends commands to the API to provide settings that set up or register one or more algorithms such as filters to run in the background as callback functions during operation of the device . The settings can specify which types of information the application program wants during system operation. Such settings indicate to the API which algorithms should run and provide information such as positions orientations notifications etc. back to the application program. For example the application program may wish to be continually updated with the position and orientation of the device as it is being moved around in space by the user. The application program can send settings to the API that will set up an algorithm to provide the desired information to the application program continually. In some embodiments the application program can optionally specify parameters to customize the high level information it will receive such as setting the rate at which the application program will receive the information from the API the amount of time during which such information will be sent to the application program the number of times it should be notified etc. In addition the application program can send settings that indicate one or more conditions that cause information to be sent to the application program when those conditions are met as determined based on sensor data. For example the settings can specify which particular motions or gestures will when detected trigger the API to notify the application program of their occurrence or the amount of time required between two detected taps for it to be considered a double tap gesture. The application program may also specify the algorithms or filters which the data is to be processed with or details such as specifying the integral of continuous motion and or angle that the device is rotated through to cause a trigger.

In step the application program receives information from the API based on the callback function algorithms that were requested to be run in the background including high level information. The API provides the desired information to the application program based on the operation of appropriate algorithms that were started based on the information of step and are running in the background. Step can be performed continuously according to any requirements specified by the application program or inherent to the request as implemented by the API and lower layers. For example in a camera application the application program may need to continuously know if there is excess hand jitter on the camera where the application program can issue warning signals to the user if such is the case. Step may also be performed at irregular intervals such as when conditions as previously specified by the application program are met. For example the application program might need to issue output to the user if the device is tilted too far in a certain direction and would need to be notified of such a tilt. Step may be performed during the performance of other steps of method .

In step the application program checks whether it needs information to perform its execution such information being based at least in part on sensor data read by motion sensors of the device . For example the application program may need to know the current position of the device in response to a request for device location from the user. If no information is required in step then the process returns to step to receive information if appropriate . If information is needed then in step the application program requests the needed high level information from the API using a high level command as defined by the API. In step the application program receives the requested information from the API. The process then returns to step .

In step the API starts the requested motion algorithms based on the received commands and settings and these algorithms run in the background during operation of the device . The API can run the particular algorithms which satisfies the request and settings of the application program. In some embodiments the command from the application program is high level enough that it does not specify the particular algorithms to run in the background and the API can associate the proper algorithms to the received commands. In alternate embodiments the received commands can specify particular algorithms. The algorithms can sample and process sensor data at the precise timing required for the application and report derived information to the application program at the required timing of the application program. The algorithms can also check any conditions specified by the application program. In some embodiments a higher software layer such as in the API can check for some or all such specified conditions.

In step the API provides continuous information to the application program if any such information was requested which includes high level information. For example the API can receive processed information from one or more of the algorithms in motion algorithm layer and provide this data to the application program. The API or algorithms preferably provide the information or allow the application program to retrieve and sample the information at a particular rate appropriate to the application implemented by the application program.

In step the API checks to see if it receives a request from the application program for particular information. If not step is initiated described below. If so in step the API provides the requested information to the application program. This information was obtained by querying the appropriate algorithm and receiving information from the algorithm. The process then returns to step . In step the API checks to see if an event has occurred which triggers the sending of information to the application program. For example the event can be one or more conditions as specified by the application program or API being met. If no event has occurred the process returns to step . If an event has occurred the API provides the triggered information typically high level information to the application program in step . This information was obtained from the appropriate algorithm s . The process then returns to step .

In some embodiments the low level processing of the motion algorithms includes intelligent processing particular to the type of application as indicated by the received high level command and parameters or instructions sent by the API to the motion algorithms. A Content Aware API can thus be provided which is intelligent enough to know what application s of the device are currently running and enables key features associated with those applications accordingly. For example if the current running application in use is a gaming application or navigation application the API enables appropriate features related to gaming or navigation respectively including the appropriate sensors to read and timing requirements for reading those sensors and the appropriate high level information and functions to provide including interface functions and outputs to the user.

For example the low level processing can include examining all of the outputs of all of the motion sensors of the motion sensing device to determine the high level information needed for the type of application implemented by the application program. Depending on the type of application the low level processing can selectively use only a subset of the axes of the motion sensors needed for the type of application after examining all of the motion sensor outputs. For example in a particular application running on a 6 axis device an algorithm can examine all three gyroscopes and all three accelerometers to determine that the device is either being held vertically in space in which case only sensed data from the accelerometers are to be processed to create high level information for that application or the device is being held horizontally in space in which case only sensed data from the gyroscopes are to be processed for that application. In other embodiments the high level command received by the API can determine which axes and outputs of the motion sensors to selectively use in determining the high level information based on the type of application. In some embodiments the high level command need not specify the particular axes and outputs to use rather the low level processing can know which sensor outputs to use based on what the particular high level command is and the processing the API associates with that high level command.

In some embodiments the selective use of only some of the axes or outputs of the motion sensors can be further exploited by turning off the operation or sensing function of the motion sensors or particular axes thereof that are not being used for any currently running application. This can save power consumption and or processing bandwidth of the device .

Further power management features can also be included in the API layer including a sleep mode and wake up mode as well as overall power management for motion sensor resources. For example the API layer can implement one or programs running on the application processor or MPU that turn off power to gyroscopes which may consume more power than other sensors any time they are not sensing any data or if their sensed data is not in use. In one embodiment the gyroscopes can be woken up as soon as some motion of the device is sensed by other motion sensors.

Examples of API commands which can be used with an API according to the present invention are provided below.

At least two of the concurrently running applications require motion sensor data to be sampled at different minimum sampling rates. For example an image stabilization application requires motion sensor data to be sampled at a high rate such as 500 Hz while a user interface application may require motion sensor data to be sampled at a lower rate such as 50 Hz.

The process starts at and in step sensor data is received at a first sampling rate. The first sampling rate is determined as the highest minimum sampling rate required by any application currently running on the device a sampling rate greater than the minimum required can also be used . The sampling rates of other application programs that are available on the system but are not currently running are not relevant to the determination of this first sampling rate. In step the sensor data sampled at the first highest sampling rate is used for a first application running on the device or used for multiple first applications if more than one application requires data to be minimally sampled at the first sampling rate . As described above motion algorithms in layer can process the sensor data and provide processed high level information to the API and a first application program implementing the first application.

In step a low pass filter is used on the sensor data received in step at the first sampling rate to achieve a lower second sampling rate that is appropriate for a different second application concurrently running on the device but which is too low of a rate to be used for the first application s . For example the second application may only need sensor data sampled at a lower rate than the first application such that the first sampling rate can be reduced using the filter. The low pass filter of step can be any of a variety of different types such as a point running average an infinite impulse response IIR filter a finite impulse response FIR filter etc. In step the sensor data sampled at the second sampling rate is used for the second application or used for multiple applications if more than one can use sensor data at the second sampling rate . Steps and can performed simultaneously to the other steps of the method .

If additional applications are currently running and can use data at a different sampling rate then in step a low pass filter is similarly used on the filtered sensor data to achieve even lower sampling rates for additional applications currently running if appropriate and the sampled data is used for those additional applications. If such applications are running the second sampling rate of step is the second highest sampling rate required by any application program currently running and the sampling rates of step are lower than the second sampling rate of step . For example if two additional applications can use different lower sampling rates then the data provided at the second sampling rate is filtered to provide a third sampling rate for the appropriate one of the applications and the data at the third sampling rate is filtered to provide a fourth lower sampling rate for the other application. The process is then complete at .

Method thus allows different applications with different sampling rate requirements to be executed simultaneously on a device which is normally a difficult task by low pass filtering the data in a tree format. For example a blur calculation may require sensor data to be sampled at 500 Hz a user interface application may require a sampling rate of 100 Hz and a navigation application may require a sampling rate of 20 Hz. At the application program level the user interface display may be updated at 10 Hz while the navigation data is merged with GPS data at 1 Hz. A motion sensing engine simultaneously running these applications must be able to receive motion sensor data at different sampling rates simultaneously in order to process sensor data for the multiple applications simultaneously. For example a user may want to take a picture without blur while controlling the camera user interface with motion gestures. Simultaneously the device can be dead reckoning so that the location of the device is not lost during the camera application. For a GPS enabled camera phone a user may not want to lose his or her location each time a picture is taken.

The filtering in the tree format described in method allows different sampling rates to be extracted from a single highest sampling rate. For example raw sensor data can be sampled at 500 Hz with a 250 Hz anti aliasing filter for electronic image stabilization. A 10 point running average e.g. one type of low pass filter that can be used of step provides more anti aliasing reducing the bandwidth from 500 Hz to 50 Hz allowing a 100 Hz sampling rate for a user interface application an application can be allowed a sampling rate up to double the sensor sampling rate . Another 10 point running average can be used at 100 Hz providing a 10 Hz bandwidth suitable for a 20 Hz navigation filter. The outputs of all these filters can be updated at their respective sample rates without the user s knowledge. This minimizes the application processor time since only the image stabilization filter needs to be run at the highest sample rates.

In another example an image stabilization application can be combined with a user interface application. Either raw accelerometer data or augmented data in this example gravitational acceleration derived from sensor data from both accelerometers and gyroscopes can be used to track the orientation of the camera used for image rotation portrait or landscape and leveling information. Simultaneously gestures can also be input by the user to control camera modes such as for example switching from still camera mode to video camera mode. Using the present invention the high sample rate gyroscope sensor data used for blur data is captured at the same time as the lower sample rate gyroscope sensor data used for gesture recognition data.

In yet another example navigation can be combined with a user interface application. In addition to running a dead reckoning algorithm for a navigation application a handheld device may also be required to run a map rotation algorithm and a user input algorithm for a user interface application. Using the present invention these algorithms can be running simultaneously at different sample rates since the map rotation requires low latency in order to be an effective user interface but the navigation algorithm may only be required to run at 20 Hz.

The different sampling rates provided by the present invention can also be used for power management of the device . In some embodiments power consumption of the device can be reduced which can be important for handheld and portable applications such as pedestrian navigation. For example in a navigation application a GPS unit not shown can be an additional unit connected to the device to determine the location of the device. A dead reckoning algorithm in layer used in combination with a GPS receiver can more accurately determine current location than if the GPS receiver were solely used to determine location. The dead reckoning filter has the additional benefit that it can reduce the processing required by the GPS unit thus reducing power. If using dead reckoning with GPS location detection a 1 Hz GPS sample rate may be reduced to 0.1 Hz or the satellite tracker may track only 3 satellites instead of 12 satellites. Any inaccuracies in the GPS algorithm can be offset by the additional information achieved by the dead reckoning algorithms.

One reason that hardware such as the MPU is used in device is to reduce the processing burden on the application processor and or other processors of the device . Using only software for capturing motion sensor data can be inefficient due to processor CPU overhead timing constraints and difficulty for coding or customization and portability. Ideally a motion sensing driver should use no more than 1 of the CPU time and guaranteeing correct timing may be difficult within a mobile device operating system. However hardware is not used to perform all sensor functions for several reasons including increased cost and inaccurate and limited features. For example adding extra hardware processing to the sensor integrated circuit increases the die area which may be unnecessary if that same processing can be performed in software on the application processor .

Often the precise timing necessary for motion sensing is required for the input of data to an algorithm but not the output to a user i.e. the timing requirements are more relaxed for the output of an application program to the user. For example in a user interface application the motion sensing is often performed at 100 Hz with precise timing to capture all the necessary motion. However the output to the user by the application program may only be at 10 Hz with imprecise timing.

Embodiments of the present invention can use hardware and or software to take advantage of relaxed timing constraints for the application program output and thereby reduce processing time of the application processor. Some embodiments can provide more processing with software for those systems having a fast processor while other embodiments can provide more processing with hardware for systems with a slower processor or other processing burdens. In any embodiment the same API layer can be used to provide resulting high level information to application programs allowing maximum portability to any system.

The method starts at and in step the MPU samples motion sensor data at a higher rate and records the sensor data to a hardware buffer. For example the hardware buffer can be in the hardware processing block of the MPU as shown in or in different connected hardware of the device . The MPU samples the sensor data at the high rate and precise timing normally required to capture motion data for a particular application.

In step the application processor reads all sensor data accumulated in the hardware buffer since the last time it read the buffer where the processor samples the hardware buffer and sensor data at a lower rate than the MPU used to record the sensor data. The processor reads all these sensor data points in the hardware buffer at once.

In step the motion algorithms are updated in quick succession based on the retrieved multiple sensor data points and the final output of the algorithms is provided to the application program at the lower sampling rate. This provides information to the application program at the lower required sampling rate. The process then returns to step .

The accumulation of sensor data in the buffer allows application programs of application processor to relax timing constraints for sampling data from the MPU without missing any motion information. For example the MPU hardware may record sensor data in the buffer at the higher rate of 100 Hz. An application program on application processor may need to update a display screen based on motion at only a 10 Hz sample rate. Using the method the motion algorithms can read all the data stored in the MPU buffer at once at a rate of 10 Hz. Thus if 10 data points are in the buffer the motion algorithms are updated 10 times in quick succession and the display information output by the motion algorithms is provided to the application program effectively at 10 Hz. This allows the application processor to read the buffer only when it needs to e.g. at a rate of 10 Hz the display refresh rate which reduces the total processing time of the processor . The reduction may not be by a large amount since the motion algorithms are still being run at the higher rate on average using all data points of the received motion data.

The method starts at and in step an interrupt routine samples motion sensor data at a higher rate. The interrupt routine is a software routine running on the application processor and can be provided in the algorithm layer for example. The interrupt routine samples the sensor data from the MPU at the high rate and with the accurate and precise timing normally required to capture motion data appropriate for an application. In step the interrupt routine stores the data read in step in a software buffer without processing the data. For example the software buffer is memory accessible to the application processor and can be provided in the application processor registers RAM etc. in the memory of the device or in other available memory.

In step the interrupt routine interrupts the processor to indicate that enough sensor data is accumulated to be read. In step the application processor e.g. a motion algorithm reads all the sensor data accumulated in the software buffer since the last time it read the buffer. Thus the processor reads the sensor data at a lower rate than the interrupt routine used to sample and store the sensor data. In step the motion algorithms are updated in quick succession based on the retrieved multiple sensor data points and the final output of the algorithms is provided to the application program at the lower sampling rate. This provides information to the application program at the lower required sampling rate. The process then returns to step .

As with the hardware buffer embodiment of the accumulation of sensor data in the buffer allows the application processor to relax its timing constraints with regard to the application program output without missing any motion information. For example the interrupt routine may sample and store sensor data in the buffer at the higher rate of 100 Hz but the application processor can read all the data stored in the software buffer at once at a relaxed rate. Thus at a sample rate of 10 Hz the application processor can retrieve the latest 10 data points in the buffer and process the motion algorithm 10 times in quick succession allowing a display application program to receive appropriate information from the algorithms at 10 Hz and provide its output at 10 Hz.

The method starts at and in step the MPU receives the sensor data and the sensor data is stored in a buffer. This sampling is performed at a high rate and with the accurate and precise timing normally required to capture motion sensor data. The sensor data can be stored in a hardware buffer or in a software buffer.

In step the MPU scans the buffered sensor data. In step the MPU checks whether any interesting properties have been detected in the scanned sensor data. Such properties are patterns or features in the data that may be relevant to a particular algorithm or application such that they should be reported to the application processor . For example the properties can include a predetermined threshold that has been exceeded or a pattern in the data indicating a particular type of motion. For example when a gesture is made by the user thresholds may be exceeded on at least one motion sensor. Or a particular threshold value may have been exceeded indicating a level of jitter on the camera lens portion of device . If no interesting properties are detected by the MPU in step then the process returns to step .

If one or more interesting properties is detected then in step the MPU sends an interrupt to the application processor. This interrupt indicates to the application processor that an interesting property has been detected and should be examined by the application processor. Thus in step the application processor retrieves data stored in a buffer that includes the detected interesting properties e.g. the MPU can buffer the interesting property data in a different buffer or other area of the buffer which the processor can read from or the MPU can designate the location to read from in the main buffer. The application processor then analyzes the retrieved data as appropriate to the application e.g. process the data with an algorithm in the algorithm layer and provide the data via the API to the application program at a reduced sampling rate. The process then returns to step .

The use of the MPU hardware to check for particular properties in the sensed data can reduce the processing overhead of the application processor. Even if the MPU sends interrupts to the application processor at a high rate such as detecting interesting properties five times per second it still reduces the number of times the algorithm processing and application program processing must be run from 100 Hz to 5 Hz. With this embodiment the timing constraints have been reduced for all software on the application processor and the processing time of processor has thus also been reduced.

The method starts at and in step the MPU receives the sensor data and the sensor data is stored in a buffer such as the hardware buffer of the MPU. The data is sampled and stored at a high rate and with the precise timing normally required to capture motion sensor data. In step the MPU pre processes the sensor data to reduce the data to a set of relevant features for one or more applications. The MPU can include motion algorithms similar to or a subset of the motion algorithms present in the motion algorithm layer of the application processor software. For example in some embodiments the MPU can detect particular gestures by processing the sensor data. This processing ability can determine which features are relevant to the applications running on the application processor and or provide high level information for an application program. For example relevant features can be parameters calculated from additional derivatives and integrals of the inertial data.

In step the set of relevant features is provided to the application program on the application processor at a lower sampling rate than the sampling rate used to capture the motion sensor data. Thus for example a 100 Hz sample rate for capturing sensor data can be reduced to a 5 Hz sample rate providing only the relevant information to the application processor. The relevant features can then be provided to the application program at the reduced sampling rate or to an appropriate motion algorithm for further processing which provides information to the application program at the reduced sampling rate . Similar to the embodiment of with this embodiment the timing constraints have been reduced for all software on the application processor and the processing time of processor has thus also been reduced.

Although the present invention has been described in accordance with the embodiments shown one of ordinary skill in the art will readily recognize that there could be variations to the embodiments and those variations would be within the spirit and scope of the present invention. Accordingly many modifications may be made by one of ordinary skill in the art without departing from the spirit and scope of the appended claims.

