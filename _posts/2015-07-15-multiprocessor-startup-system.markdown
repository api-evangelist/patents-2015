---

title: Multi-processor startup system
abstract: A switch includes a PCI bus. A line card processor is coupled to a line card memory system and includes a line card processor port connected to the PCI bus. A management processor is coupled to a management memory system and includes a management processor port connected to the PCI bus and associated with a register. The management processor retrieves an OS image and stores the OS image in the management memory system. The management processor then configures the register with a mapping between the management memory system and the line card memory system. The management processor then provides a write instruction to write the OS image to an address range included in the management memory system, and the management processor port converts the write instruction using the address mapping such that the OS image is written over the PCI bus to the line card memory system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09529601&OS=09529601&RS=09529601
owner: Dell Products L.P.
number: 09529601
owner_city: Round Rock
owner_country: US
publication_date: 20150715
---
The present disclosure relates generally to information handling systems and more particularly to a startup system for an information handling system with multiple processors.

As the value and use of information continues to increase individuals and businesses seek additional ways to process and store information. One option available to users is information handling systems. An information handling system generally processes compiles stores and or communicates information or data for business personal or other purposes thereby allowing users to take advantage of the value of the information. Because technology and information handling needs and requirements vary between different users or applications information handling systems may also vary regarding what information is handled how the information is handled how much information is processed stored or communicated and how quickly and efficiently the information may be processed stored or communicated. The variations in information handling systems allow for information handling systems to be general or configured for a specific user or specific use such as financial transaction processing airline reservations enterprise data storage or global communications. In addition information handling systems may include a variety of hardware and software components that may be configured to process store and communicate information and may include one or more computer systems data storage systems and networking systems.

Some information handling systems include multiple processors. For example in order to achieve higher port densities performance power efficiency and reliability networking devices such as switches may include multiple processors e.g. central processing units CPUs network processing units NPUs and or other processing units known in the art that may be provided on route cards line cards and or other networking subsystems in order to perform tasks such as layer 2 control plane processing layer 3 control plane processing line card processing and or other networking functions known in the art. In such systems one of the processors will typically operate as the primary management interface with capabilities to manage directly attached external high speed Ethernet network connectivity directly attached persistent storage directly attached external serial console ports directly attached Universal Serial Bus USB ports management console connections and or other management functions known in the art. As such a primary CPU may act as the designated controller for chassis management control plane interconnection fabric interconnection and redundancy management. The secondary processors and the primary processor are typically connected via Ethernet ports and interconnects and communicate using Ethernet protocols.

The structure of networking devices including the primary processor and secondary processors discussed above can result in relatively long startup times for the networking device. For example when such a networking device is powered on or reset the primary processor will boot up via a Basic Input Output System BIOS and load an operating system OS image while the secondary processors are held in a reset mode. After reaching the shell prompt the primary processor may start user space networking services e.g. a Trivial File Transfer Protocol TFTP server daemon and bring the secondary processors out of reset mode sequentially. Each of the secondary processors may then start up the boot process sequentially by executing BIOS and then utilizing TFTP to download specific OS images from a predefined location that is specified by the primary processor. To ensure that the OS image is reliably downloaded each packet that is sent using TFTP requires an acknowledgement resulting in a relatively large latency associated with the process. Furthermore both the TFTP sender and receiver use the Transport Control Protocol Internet Protocol TCP IP stack which also requires acknowledgements encapsulation the provisioning of metadata and other overhead while the read write system call nature of copying the OS image for use by the secondary processors further delays the startup of the networking device. Collectively the time to load and execute an OS image for secondary processors such as route processors and line processors can be on the order of seconds due to the overhead of the Ethernet protocol and software protocols discussed above. For example it has been found to take up to 30 seconds to download a 30 MB OS image for a route processor or line processor using TFTP as detailed above.

According to one embodiment a multi processor startup system includes a Peripheral Component Interconnect PCI bus a secondary processing system that is coupled to a secondary memory system and that includes a secondary processing system port that is connected to the PCI bus a primary processing system that is coupled to a primary memory system and that includes a primary processing system port that is connected to the PCI bus and that is associated with at least one primary port register wherein the primary processing system is configured to retrieve a secondary processing system operating system OS image and store the secondary processing system OS image in the primary memory system configure the at least one primary port register with an address mapping between the primary memory system and the secondary memory system and copy the secondary processing system OS image to the secondary memory system by providing a write instruction to write the secondary processing system OS image to an address range included in the primary memory system wherein the primary processing system port converts the write instruction using the address mapping such that the secondary processing system OS image is written over the PCI bus to the secondary memory system.

For purposes of this disclosure an information handling system may include any instrumentality or aggregate of instrumentalities operable to compute calculate determine classify process transmit receive retrieve originate switch store display communicate manifest detect record reproduce handle or utilize any form of information intelligence or data for business scientific control or other purposes. For example an information handling system may be a personal computer e.g. desktop or laptop tablet computer mobile device e.g. personal digital assistant PDA or smart phone server e.g. blade server or rack server a network storage device or any other suitable device and may vary in size shape performance functionality and price. The information handling system may include random access memory RAM one or more processing resources such as a central processing unit CPU or hardware or software control logic ROM and or other types of nonvolatile memory. Additional components of the information handling system may include one or more disk drives one or more network ports for communicating with external devices as well as various input and output I O devices such as a keyboard a mouse touchscreen and or a video display. The information handling system may also include one or more buses operable to transmit communications between the various hardware components.

In one embodiment IHS includes a processor which is connected to a bus . Bus serves as a connection between processor and other components of IHS . An input device is coupled to processor to provide input to processor . Examples of input devices may include keyboards touchscreens pointing devices such as mouses trackballs and trackpads and or a variety of other input devices known in the art. Programs and data are stored on a mass storage device which is coupled to processor . Examples of mass storage devices may include hard discs optical disks magneto optical discs solid state storage devices and or a variety other mass storage devices known in the art. IHS further includes a display which is coupled to processor by a video controller . A system memory is coupled to processor to provide the processor with fast storage to facilitate execution of computer programs by processor . Examples of system memory may include random access memory RAM devices such as dynamic RAM DRAM synchronous DRAM SDRAM solid state memory devices and or a variety of other memory devices known in the art. In an embodiment a chassis houses some or all of the components of IHS . It should be understood that other buses and intermediate circuits can be deployed between the components described above and processor to facilitate interconnection between the components and the processor .

Referring now to an embodiment of a multi processor system is illustrated. In an embodiment the multi processor system may be the IHS discussed above with reference to and or may include some or all of the components of the IHS . In the embodiment of the multi processor system is illustrated and described as a networking device such as a switch. However the teaching of the present disclosure will be beneficial to a variety of other multi processor systems known in the art and thus their application to such systems is envisioned as falling within the scope of the present disclosure. In the illustrated embodiment the multi processor system includes a chassis that houses the components of the multi processor system . For example the chassis in the embodiment illustrated in houses a management system that is coupled to a route card and a plurality of line cards and up to . One of skill in the art will recognize that the management system route card and line cards are components typically found in networking devices such as switches and different numbers and configurations of route cards and line cards as well as other components may be provided in the chassis while remaining within the scope of the present disclosure.

As discussed in further detail below each of the management system route card and line cards may include processing systems not illustrated but which may be the processor discussed above with reference to and memory systems not illustrated but which may be the system memory discussed above with reference to that include instructions that when executed by the processing systems cause the processing systems to provide engines that perform the functions of the management system route card and line cards respectively. For example the route card includes a route engine each of the line cards include respective line engines and the management system includes a management engine that is coupled to each of the route engine and the line engines e.g. via connections between the respective processing systems that provide those engines . While the functionality discussed below for the engines is directed to the multi processor startup taught herein one of skill in the art in possession of the present disclosure will recognize that the management engine the route engine and the line engines may include other functionality that provides for the conventional functioning of networking devices such as switches while remaining within the scope of the present disclosure. Furthermore while the processing system used to provide the management engine is described below as a primary processing system and the processing systems used to provide the route engine and line engines are described below as a secondary processing system one of skill in the art in possession of the present disclosure will recognize that different processing systems may provide the primary and secondary processing systems discussed below while remaining within the scope of the present disclosure.

Referring now to an embodiment of a multi processor system is illustrated. In an embodiment the multi processor system may be used to provide the multi processor system discussed above with reference to and thus may be housed in the chassis . As such the multi processor system may be the IHS discussed above with reference to and or may include some or all of the components of the IHS . The multi processor system includes a primary processing system that includes a primary processor and that is illustrated as a management engine processing system and a primary memory system that may include a primary memory device and that is illustrated as a management engine memory system . As discussed above the management engine processing system and the management engine memory system may provide the management engine discussed above with reference to and in some embodiments may be configured to operate as a primary management interface for the multi processor system e.g. a control processor that acts as a designated controller for chassis management control plane interconnection fabric interconnection redundancy management and or other management features known in the art.

The primary processing system in the multi processor system includes a plurality of primary processor ports that in the illustrated embodiment are Non Transparent Bridge NTB ports and up to that are included on the management engine processing system e.g. provided on the primary processor and connected to Peripheral Component Interconnect express PCIe interconnects and respectfully that may be provided in one or more PCIe buses. While discussed below as PCIe the PCIe interconnects and and PCIe bus may be PCI interconnects and a PCI bus while remaining within the scope of the present disclosure. Furthermore in other embodiments other types of ports are envisioned as falling within the scope of the present disclosure. Each of the NTB ports are coupled to one or more respective primary management NTB port registers and . In an embodiment each of the one or more registers for each NTB port may include NTB port Base Address Registers BARs NTB port Address Translate Registers ATRs NTB message registers NTB doorbell registers and or other registers known in the art. Each NTB port and may be associated with its respective registers and e.g. in the management engine memory system and other information about the NTB ports may be associated with those NTB ports as well.

The multi processor system includes a plurality of secondary processing systems that each include a secondary processor and that are each coupled to a respective secondary memory system that may include a secondary memory device. One of those secondary processing systems secondary memory systems is illustrated as a route card processing system that may include a route card processor that is coupled to a route card memory system . As discussed above the route card processing system and the route card memory system may provide the route engine discussed above with reference to that is configured to perform routing functions known in the art. The route card processing system includes a secondary processor port that in the illustrated embodiment is an NTB port that is included on the route card processing system e.g. provided on the second processor connected to the PCIe interconnect and associated with one or more registers not illustrated but similar to the registers and discussed above .

Others of those secondary processing systems secondary memory systems are illustrated as line card processing systems and up to that may each include a line card processor that is coupled to line card memory systems and up to respectively. As discussed above the line card processing systems and and the line card memory systems and respectively may provide the respective line engines discussed above with reference to that are configured to perform line card functions known in the art. The line card processing systems and each include a secondary processor port that in the illustrated embodiment is an NTB port that is included on the line card processing system e.g. provided on the second processor connected to the PCIe interconnect and associated with one or more registers not illustrated but similar to the registers and discussed above as well as an NTB port that is included on the line card processing system e.g. provided on the second processor connected to the PCIe interconnect and associated with one or more registers not illustrated but similar to the registers and discussed above . Thus the primary processing system and or processor may be connected to the secondary processing systems and or processors through NTB ports and PCIe interconnects. As discussed below the multi processor system provides an embodiment where the each secondary processing system is directly connected to the primary processing system via a respective NTB port on the primary processing system which as discussed below may allow for the startup functions discussed below to be performed for each secondary processing system in parallel.

However in some embodiments the multi processor system may include more secondary processors than there are primary processor ports on the primary processing system or processor. For example illustrates an embodiment of a multi processor system that includes more secondary processing systems than there are NTB ports on the primary processing system. The multi processor system is similar to the multi processor system discussed above with reference to and includes similar reference numbers for similar components. For example each of the management engine memory the route card processing system route card memory system line card processing system line card memory system and the line card processing system line card memory system may be substantially similar to those discussed above with reference to . However the management engine processing system in the multi processor system includes an NTB port that is associated with and connected to one or more registers . The NTB port and one or more registers are substantially similar to the NTB ports and one or more registers discussed above.

However as can be seen the management engine processing system in the multi processor system includes fewer NTB ports than secondary processing systems i.e. a single NTB port for the plurality of secondary processing systems as compared to the one to one NTB port secondary processing system ratio in the multi processor system of . The NTB port on the management engine processing system is coupled to each of the NTB ports and on the route card processing system and the line card processing systems and by a PCIe switch that is coupled to a PCIe bus that connects to each of the NTB ports and up to . As discussed below the use of the PCIe switch to couple the NTB port to the NTB ports and or to may result in the startup functions discussed below being performed for each secondary processing system in series. However one of skill in the art in possession of the present disclosure will recognize that the number of NTB ports on a processing system may vary and thus primary processing systems may be selected based on such one to one NTB port secondary processing system relationships or one to many NTB port secondary processing system relationships as is desired or dictated by the multi processor system in which they are incorporated. Furthermore combinations of one to one and one to many NTB port secondary processing system relationships may be provided when the primary processing system includes a plurality of NTB ports but the multi processor system still includes a number of secondary processing systems that exceed the number of those NTB ports. In such scenarios relatively high priority secondary processing systems may be connected directly to NTB ports on the primary processing system while a plurality of relatively low priority secondary processing systems may be coupled to a PCIe switch that is connected to one of the NTB ports on the primary processing system.

Referring now to an embodiment of a method for starting up a multi processor system is illustrated. As discussed above in conventional multi processor systems the startup time e.g. the time it takes the system processors to boot up their operating system OS images and come online or otherwise be ready for use can be relatively large e.g. on the order of several minutes . For example in response to power on or reset of the system the primary processor will boot up via the BIOS and use a boot loader to load its OS image from a local hard drive or through a network. During the time the primary processor loads its OS image the secondary processors are held in a reset mode. Once the primary processor reaches the shell prompt it starts networking services e.g. a TFTP server daemon and brings the secondary processors out of reset mode sequentially. Each secondary processor brought out of reset mode will then start the boot up process by executing BIOS and using TFTP to download its respective OS image from a predefined location specified by the primary processor. In conventional multi processor systems standard Ethernet switching and Ethernet protocols are used to transfer data to the secondary processors and or their memory systems so depending on the link bandwidth and protocol transfer rate this process can take a few seconds to several dozens of seconds and as discussed above it is repeated sequentially for each of the secondary processors further adding to the system startup boot up time.

The relatively large startup times for such conventional multi processor systems are a result of several of the factors discussed above. For example the Ethernet protocol does not support automatic packet acknowledgement and relies on the use of software to ensure data transfer reliability resulting in the use of TFTP to transfer OS images to the secondary processors. TFTP provides for an acknowledgement for each packet of the OS image that is sent introducing latency into the OS image transfer process. In addition the use of the TCP IP stack which is a connection oriented fully acknowledged protocol that includes encapsulation and metadata generation inclusion in headers introduces further overhead as well. Finally the conventional copy nature of read write systems calls in such conventional multi processor systems results in the moving of data between a user space and the system by copying the data to a kernel buffer and then using direct memory access or programmed input output to read and write data to the system i.e. the TFTP server in the primary processor repeatedly invokes read and write systems calls to read and write data to and from memory systems for the secondary processors during the startup operations .

As discussed below the method and systems described herein provides a hardware software architecture that can reduce the startup time of multi processor systems by an order of magnitude e.g. from several seconds to a few micro seconds . Such startup time reductions are provided by bypassing the Ethernet protocol as an interconnect between the primary and secondary processors as well as bypassing TFTP and the TCP IP stack as a transport protocol and instead using one or more PCIe interconnects to connect the primary processor and secondary processors in the multi processor system. As discussed above for systems with a relatively low number of secondary processors the primary and secondary processors may be interconnected directly via the PCIe interconnects using their integrated PCI controllers while for systems with a relatively high number of secondary processors a PCIe switch may be used with the PCIe interconnects to provide the coupling between the integrated PCI controllers in the primary and secondary processors. The use of processor ports such as the NTB ports discussed above allow for the mapping of the secondary memory systems for the secondary processors into the address space of the primary memory system for the primary processor which allows for the bypassing of the TCP IP stack and system call overhead discussed above. As such data transfer between the primary processor and the secondary processors may be performed using a memory copy memcpy and a software handshake method may be used to verify synchronize or otherwise ensure that OS images transferred to the secondary processors are complete and ready for use by the secondary processors.

The method begins at block where a networking system including a primary processing system and secondary processing system s is initialized. In an embodiment the multi processor system which may be provided by the multi processor systems and or is powered on started up reset and or otherwise initialized at block . In response to initialization of the multi processor system the management engine provided on the management system e.g. the primary processing system and each of the route engine provided on the route card and the line engines provided on the line cards e.g. the secondary processing systems boot up and execute their respective BIOS. In an embodiment each of the management engine the route engine and the line engines may boot up in parallel and execute their respective BIOS.

The method then proceeds to block where secondary processing system OS images are retrieved and stored in the primary memory system. In an embodiment the management engine provided on the management system e.g. the primary processing system retrieves the OS images for each of the route engine provided on the route card and the line engines provided on the line cards e.g. the secondary processing systems from a local hard drive on the multi processor system or over a network using a communication system in the multi processor system . In an embodiment at block the management engine may decode each of the retrieved OS images and determine a size of that OS image and a checksum for that OS image referred to below as a retrieved checksum of the retrieved OS image for use later in method as discussed below.

The method then proceeds to block where a primary port register of the primary processing system is configured with the size of the secondary processing system OS image. In an embodiment the management engine provided in the management system e.g. the primary processing system may be used e.g. by a user or administrator to configure one or more port registers e.g. the primary port registers in the management system with the size of the OS images retrieved at block . For example with reference to at block the management engine processing system may configure a BAR in the registers for the NTB port with the size of the OS image for the route card processing system configure a BAR in the registers for the NTB port with the size of the OS image for the line card processing system and configure a BAR in the registers for the NTB port with the size of the OS image for the line card processing system . In another example with reference to at block the management engine processing system may configure BARs in the registers for the NTB port with the size of the OS image for the route card processing system the size of the OS image for the line card processing system and the size of the OS image for the line card processing system . In an embodiment the configuration of the BAR in the registers for the NTB ports of the primary processing system is performed prior to PCI enumeration. As would be understood by one of skill in the art in possession of the present disclosure the configuration of the BAR in the registers for the NTB ports of the primary processing system may be used to limit the size of the memory window provided between the primary processing system and the secondary processing systems and discussed in further detail below.

The method then proceeds to block where the primary port register of the primary processing system is configured with an address mapping between the primary port memory system and the secondary memory system. In an embodiment the management engine provided in the management system e.g. the primary processing system may be used e.g. by a user or administrator to configure one or more port registers e.g. the primary port registers in the management system with an address mapping between the memory of the management system e.g. the primary memory system and the memory of the route card and the line cards e.g. the secondary memory systems . For example with reference to at block the management engine processing system may configure an address translate register in the registers for the NTB port with an address mapping between the management engine memory system and the route card memory system configure an address translate register in the registers for the NTB port with an address mapping between the management engine memory system and the line card memory system and configure an address translate register in the registers for the NTB port with an address mapping between the management engine memory system and the line card memory system . In another example with reference to at block the management engine processing system may configure address translate registers in the registers for the NTB port with address mappings between the management engine memory system and the route card memory system between the management engine memory system and the line card memory system and between the management engine memory system and the line card memory system .

In an embodiment the address mappings configured at block operate to direct access by the management engine processing system to the BARs in its NTB port s to the secondary memory systems connected to those NTB port s . For example a BAR in an NTB port may include a value 0x40000 and a size of 64 KB and the address translate register may be initialized with a value of 0x50000. In such an example when the management engine processing system accesses an address between 0x40000 and 0x4FFFF that access will be captured by the NTB port and converted to an access of the secondary memory systems between 0x50000 and 0x50FFFF according to the address mapping. In an embodiment the address translate registers may be programmed with the load address of the OS images for the route card processing system and the line card processing systems and which creates address domains in the primary memory system such as a primary processing system domain a route card processing system domain and line card processing domains and permits the primary processing system to access each of the route card memory system and the line card memory systems and as discussed below.

In some embodiments following the configuration of the primary port register s at block and the primary processing system may begin PCI enumeration discover the NTB ports and note the address ranges provided in the registers for each NTB port. As discussed above each NTB port in the management engine processing system may include an address range in one of its registers that is associated with one of the secondary memory systems for a second processing system. Thus with reference to management engine processing system may begin PCI enumeration discover the NTB port and note the address range included in its registers for the route card memory system discover the NTB port and note the address range included in its registers for the line card memory system and discover the NTB port and note the address range included in its registers for the line card memory system . Similarly with reference to management engine processing system may begin PCI enumeration discover the NTB port and note the address ranges included in its registers for the route card memory system the line card memory system and the line card memory system .

The method then proceeds to block where write instructions are provided to write a secondary processing system OS image to an address range in the primary memory systems such that the primary processing system port uses the address mapping to write the secondary processing system OS image to the secondary memory system. In an embodiment with reference to the management engine provided in the management system e.g. the primary processing system provides a write instruction e.g. by invoking a memcpy Application Programming Interface API to copy the secondary processing system OS image to an address range in the primary memory system that is included in the BAR of the registers for the NTB port and the NTB port will use the address mapping provided in the address translate register of the registers to write the second processing system OS image to the route card memory system e.g. the secondary memory system . For example the write instruction may be provided via the pseudocode 

 memcpy BAR Address secondary processing system OS image address secondary processing system OS image size . 

As would be understood by one of skill in the art in possession of the present disclosure write instructions such as memcpy do not use protocols such as TFTP TCP or IP. Rather the hardware in the NTB port will capture the write packets initiated by the write instruction to the management engine memory system and convert that write instruction into a write to the route card memory system e.g. the secondary memory system using the address translation register in the registers . As such in some embodiments the hardware in the NTB port may handle the read write request completely in hardware and without the use of software.

Similarly the management engine may provides a write instruction e.g. by invoking a memcpy API to copy the secondary processing system OS image to an address range in the primary memory system that is included in the BAR of the registers for the NTB port and the NTB port will use the address mapping provided in the address translate register of the registers to write the second processing system OS image to the line card memory system e.g. the secondary memory system . Also similarly the management engine may also provide a write instruction e.g. by invoking a memcpy API to copy the secondary processing system OS image to an address range in the primary memory system that is included in the BAR of the registers for the NTB port and the NTB port will use the address mapping provided in the address translate register of the registers to write the second processing system OS image to the line card memory system e.g. the secondary memory system . With reference to the management engine may provide a write instruction e.g. by invoking a memcpy API to copy secondary processing system OS images to address ranges in the primary memory system that are included in the BARs of the registers for the NTB port and the NTB port will use the address mappings provided in the address translate registers of the registers to write the second processing system OS image to the route card memory system and the line card memory systems and e.g. the secondary memory systems using the PCIe switch . While the embodiments of block discussed above discuss the primary processing system writing the secondary processing system OS images to the secondary memory systems using the NTB ports in other embodiments the secondary processing systems may retrieve the secondary processing system OS images from the primary memory system of the primary processing system and write those secondary processing system OS images to their secondary memory systems using similar techniques as discussed above.

The method then proceeds to block where the writing of the secondary processing system OS image is confirmed. In an embodiment at block the secondary processing systems may determine a checksum referred to below as a written checksum of the written OS image of the secondary processing system OS image that was written to their secondary memory systems and configure a register associated with their secondary processing ports with the written checksum. For example the route card processing system may configure a register not illustrated but similar to the registers associated with the NTB ports in the management engine processing system associated with its NTB port with the written checksum for the secondary processing system OS image written to its route card memory system the line card processing system may configure a register not illustrated but similar to the registers associated with the NTB ports in the management engine processing system associated with its NTB port with the written checksum for the secondary processing system OS image written to its line card memory system and the line card processing system may configure a register not illustrated but similar to the registers associated with the NTB ports in the management engine processing system associated with its NTB port with the written checksum for the secondary processing system OS image written to its line card memory system .

Following the configuration of their registers associated with the secondary processing system ports the secondary processing systems may then send a notification to the primary processing system. For example the route card processing system the line card processing system and the line card processing system may configure PCI doorbell registers associated with their NTB ports and respectively in order to send an interrupt to the management engine processing system . In response to receiving the notification the primary processing system may confirm the writing of the secondary processing system OS image. For example upon receiving a door bell register event from the NTB ports and the management engine processing system may read the written checksums included in the message registers of the NTB ports and and compare those written checksums with the respective received checksums determined as discussed above. As would be understood by one of skill in the art in possession of the present disclosure the comparison of a received checksum for a secondary processing system OS image received by the primary processing system and a written checksum for that secondary processing system OS image that is written to a secondary memory system for a secondary processing system allows for the determination of whether the secondary processing system OS image that was received by the primary processing system was properly written to the secondary memory system. In response to the written checksum not matching the received checksum the primary processing system may attempt to retransmit the secondary processing system OS image some predetermined number of times which may be user configurable after which they primary processing system may abort the transmission of the secondary processing system OS image and notify the user of the failure.

The method then proceeds to block where the secondary processing system is instructed to load the secondary processing system OS image. In an embodiment in response to the written checksum matching the received checksum at block the primary processing system may then instruct the secondary processing systems to load their respective secondary processing system OS images. For example the management engine processing system may configure message registers in the registers and associated with each NTB port and respectively with OK messages and then configure doorbell registers in the registers and associated with each NTB port and respectively in order to send an interrupt to each of the route card processing system the line card processing system and the line card processing system . Upon receiving the interrupt each of the route card processing system the line card processing system and the line card processing system may change its program counter to point to the secondary processing system OS image address range in its route card memory system line card memory system and line card memory system respectively and begin the OS image boot process. As would be understood by one of skill in the art in possession of the present disclosure this process may be performed in parallel for each secondary processing system with a direct connection to the primary processing system e.g. by each of the route card processing system and the line card processing systems and through their direct connections to the NTB ports and on the management engine processing system in or may be performed sequentially for secondary processing systems sharing a connection to the primary processing system e.g. by each of the route card processing system and the line card processing systems and sequentially using the PCIe switch connection to the NTB ports and .

Thus systems and methods have been described that provide for the connection of a primary processing system and secondary processing systems through a PCIe interconnect systems along with the use of the ports connected to that PCIe interconnect systems and the registers associated with those ports in order to allow for the utilization of the primary memory system of the primary processing system and secondary memory systems of the secondary processing system to quickly provide the OS images for the secondary processing systems to their secondary memory systems for use in the startup boot process. Utilizing the PCIe interconnect system and software handshake protocol described above substantial improvements in system startup times may be realized. For example the NTB ports of the primary and secondary processing systems may be connected via a first generation PCIe interconnect system that offers a bandwidth of 2.5 Gbps 250 MB x in each direction. While the effective bandwidth may drop due to PCI link layer and protocol overhead given a max PCI payload size of 128 bytes the effective bandwidth may still exceed 200 MB s. If the OS image size is 30 MB the systems and methods of the present disclosure may provide for the transfer of that OS image in well under a second as compared to the 30 seconds that existing methods may require thus achieving an order of magnitude improvement on system startup boot times.

Although illustrative embodiments have been shown and described a wide range of modification change and substitution is contemplated in the foregoing disclosure and in some instances some features of the embodiments may be employed without a corresponding use of other features. Accordingly it is appropriate that the appended claims be construed broadly and in a manner consistent with the scope of the embodiments disclosed herein.

