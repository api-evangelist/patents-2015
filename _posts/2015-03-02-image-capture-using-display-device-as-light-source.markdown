---

title: Image capture using display device as light source
abstract: A digital image capture system and method uses a display device to illuminate a target with light for improved image capture under poor lighting conditions. Various characteristics of the flash (e.g., brightness, color, duration, etc.) can be adjusted to improve image capture. Users are provided with feedback (e.g., live video feed, audio and/or visual countdowns, etc.) to assist them in preparing for image capture. The captured images are seamlessly integrated with existing applications (e.g., video conferencing, instant text messaging, etc.).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09413978&OS=09413978&RS=09413978
owner: Apple Inc.
number: 09413978
owner_city: Cupertino
owner_country: US
publication_date: 20150302
---
This application is related to the following U.S. patent applications each of which is incorporated by reference herein in its entirety U.S. patent application Ser. No. 11 248 630 filed Oct. 11 2005 and U.S. patent application Ser. No. 11 153 959 filed Jun. 15 2005.

Videoconferencing is one of the fastest growing segments of the computer industry. This growth is based in part on affordable digital video cameras. Digital video cameras e.g. WebCams can be integrated with personal computers and displays to enable users to videoconference from a variety of locations e.g. home office hotels subway trains etc. Unfortunately each location has its own unique lighting conditions which may not be ideal for capturing quality digital images.

Some digital video cameras include a built in flash that is automatically triggered in low light conditions. These cameras however do not allow the user to control the characteristics of the flash e.g. intensity duration color etc. based on ambient light conditions and therefore tend to capture images that are too dark or too bright even when operated in adequate lighting conditions.

For those millions of users who are not fortunate to own a camera with built in flash or external flash the only recourse is to move to a different environment or improve the lighting conditions of the current environment. In some environments however the user may not have control over the lighting conditions e.g. a public building train hotel etc. .

An improved digital image capture system and method uses a display device to illuminate a target with light for improved image capture under poor lighting conditions. Various characteristics of the flash e.g. brightness color duration etc. can be adjusted to improve image capture. In some implementations the system provides users with feedback e.g. live video feed audio and or visual countdowns etc. to assist them in preparing for image capture. The captured images are seamlessly integrated with existing applications e.g. video conferencing instant text messaging etc. .

In some implementations a method of capturing a digital image includes receiving an instruction to illuminate a target to facilitate capturing a digital image and illuminating the target using a display device.

In some implementations a method of capturing a digital image includes receiving an instruction to acquire an image using an image capture device determining when to flash a display device to illuminate the target flashing the display device at the determined time and acquiring an image illuminated by the flash using the image capture device.

In some implementations a method of capturing digital images includes illuminating a target with light emitted from a display device and capturing a digital image of the illuminated target.

In some implementations a method of capturing digital images includes illuminating a target with light emitted from a display device determining if the light has reached a threshold intensity level and capturing the digital image of the target if the light has reached the threshold intensity level.

Various other implementations are described herein including but not limited to implementations associated with computer readable mediums systems and devices.

The disclosed implementations provide one or more advantages over conventional digital capture systems and methods including but not limited to 1 illuminating a target in poor lighting conditions for improved image capture 2 adjusting characteristics of the flash e.g. intensity duration color etc. for improved image capture 3 providing feedback to the user to assist the user in preparing for image capture and 4 providing for seamless porting of captured images into other applications.

In operation a user sits facing a display device e.g. a CRT LCD etc. which includes a screen for presenting a user interface . As shown in the image capture device e.g. a video camera generates a live video feed which is presented in a window of the user interface . The user interface enables the user to take a snapshot of the live video feed commonly known as frame grabbing. To take a snapshot the user clicks the object e.g. a software button which starts a countdown sequence. When the sequence expires one or more frames of the live video feed are captured or grabbed from an image stream or image processing pipeline. In some implementations a still digital camera is used to capture a still shot when the sequence expires.

The countdown sequence gives the user time to prepare for the picture and can be set to any desired duration e.g. 3 sec . In some implementations the device provides visual and or audio feedback in the form of a countdown sequence e.g. live video feed audio etc. . For example when the user clicks the object numerical values on a countdown display are highlighted in succession to indicate the current count. In some implementations audio files e.g. .wav files are played with the countdown sequence. For example an audible beep or other audio effect can be played each time the shade box passes over a number in the countdown display . When the last value of the count is reached shown as a camera icon the screen of the display device is flashed and a digital image is captured and displayed in window . In other implementations the countdown numbers themselves are altered and or augmented e.g. highlighted flashed etc. to simulate a countdown sequence. In some implementations a flashing lamp on the user interface simulates the cadence of the countdown sequence.

It should be apparent that any audio visual or physical feedback e.g. force feedback synthetic speech etc. can be used to simulate a countdown sequence and to alert the user when their image is about to be captured.

In some implementations the device enables a user to capture an image from a video stream stored at the device or from another device e.g. a video broadcast over the Internet . For example the user can click the object which invokes a file directory that the user can browse for video files stored at the device or on a network e.g. the Internet intranet wireless network etc. .

In some implementations the system is located in a poorly lit environment e.g. an office hotel train etc. . Such poor lighting conditions make it difficult to capture quality digital images. In such environments the system can be configured to illuminate a target e.g. the user by controlling the color and brightness of the screen of the display device . For example by presenting an all white background on the screen and increasing the brightness of the screen the target is illuminated by white light emitted from the screen of the display device . If a rapid adjustment in brightness is timed with an image capture and sound effects then the display device can simulate a photo flash. Thus by flashing the screen of the display device a user can improve the quality of images captured in poor lighting conditions. The flash can be automatically enabled based on detected ambient light or manually enabled and disabled by a user via a user interface element or preference pane accessed via the user interface . In some implementations shadows can be lightened by enabling the flash even when there is enough light to capture the image e.g. fill flash .

The captured image can be used in any application that uses digital images including but not limited to video conferencing and instant text messaging applications. For example the user can click the object to set the captured image to be for example a buddy icon picture for Apple Computer s iChat application.

In some implementations the user can review a representation of recent images by clicking on the object . In other implementations clicking on the object directs the user to a file directory that can be browsed by the user for files containing images e.g. thumbnail images . The images can be presented on the user interface in any desired order based on sorting criteria e.g. date subject matter etc. and can include identifying information e.g. timestamp size resolution description etc. . In some implementations clicking on an image in the file directory causes the image to be presented on the user interface adjacent to the recently captured image so that a user can compare the quality of the newly captured image with the stored image.

In some implementations the device controls one or more aspects of the image capture device . For example the device can be configured to control the shutter speed of the image capture device which when combined with a flash can improve the sharpness of the captured image. The device can also initialize a self timer in the image capture device for controlling image capture time. For example the device can compute an absolute image capture time in the future which takes into account frame latency and other factors then sends that value to the image capture device e.g. a still camera to initialize the self timer.

After the countdown sequence expires and prior to the flash phase another delay e.g. 0.01 sec can be added to ensure that the user is provided with properly timed feedback when the flash is launched. Without the delay for example the end of the countdown sequence and the beginning of the flash may be imperceptible to the user thus detracting from the user s experience.

During the pre flash phase and just before the post countdown delay one or more characteristics of the flash are automatically determined including but not limited to the duration and intensity of the flash. At this time a final average video frame latency can also be determined. The intensity of the flash e.g. brightness of the display device can be determined based on the ambient light in the environment. The ambient light can be determined from a light sensor in the display device or by averaging the pixel intensities of the live video feed. Based on the measurement of ambient light the brightness of the display device is set to a suitable value. In some implementations one or more characteristics of the flash can be changed by the user via a preference pane or user interface element. It should also be apparent that the pre flash phase can include more or fewer steps then are shown in depending upon the application.

In some implementations the color of the screen of the display device is determined prior to the flash. For example the screen can be set to various shades of white or to another color e.g. pink yellow etc. which can affect skin tones. In some implementations the color balance of the image can be determined for example by computing a histogram that represents the color distribution of the image to be captured. The color balance can be corrected by changing the color of the screen to a complementary color prior to flash. For example if the scene is too blue the screen color can be changed to a yellow or pink tint to compensate for the blue depending on the color balance the user is trying to capture.

In some implementations the color distribution of the static or nonmoving portions of an image can be used to correct for color balance. Alternatively the color distributions of the moving portions of the image can be used to correct for skin tone exposure. In other implementations a combination of the two can be used to correct color balance.

In some implementations the gamma of the display can be automatically adjusted based on the ambient light and known hardware characteristics as described in U.S. application Ser. No. 11 153 959 filed Jun. 15 2005 entitled Dynamic Gamma Correction .

In some implementations the duration of the flash can be divided into three periods rise time sustain time and fall time. The rise time period e.g. 0.04 sec is the period of time it takes the display device to rise from a nominal level of brightness e.g. normal viewing brightness level to a desired level of brightness. The sustain time period e.g. 0.24 sec is the period of time where the desired level of brightness is sustained. The fall time period e.g. 0.24 sec is the period of time it takes for the level of brightness to fall from the desired level of brightness to nominal brightness. Some digital video cameras include built in light sensors that enable the camera to adjust to changing lighting conditions. For such cameras the sustain time can be made sufficiently short so that the camera does not have enough time to adjust to the flash. If the camera adjusts its sensitivity to the flash the resulting image may not be bright enough.

In some implementations the image is captured during the sustain time period but prior to the fall time period. Due to frame latency however the image that is captured may not be the image the user intended to capture. Since video cameras generate streams of images e.g. 30 frames sec there is a frame latency associated with each video frame. This frame latency can be determined during the pre flash phase and used to determine an image capture time . In some implementations frame latency is equal to the difference between the image timestamp typically provided by the image capture device at the moment when the video frame is captured and the time when the frame is actually displayed onscreen. In some implementations the image capture time is given by the formula image capture time rise time sustain time frame latency.

Prior to the flash phase the frame latency is determined and added to the rise time and sustain time to determine the image capture time which is the time when a snapshot of the video stream is taken. For this implementation the image capture can occur at the beginning of the fall time period.

After the flash phase completes the post flash phase begins. During the post flash phase the captured image can be displayed to the user or further processed using known image processing techniques including those techniques described in co pending U.S. patent application Ser. No. 11 248 630 filed Oct. 11 2005 entitled Image Capture and Manipulation. 

The process begins when a request to initiate an image capture event is received . The request can be initiated by a user through an input device e.g. a mouse click or programmatically either directly or through an application programming interface API . In some implementations the click event can be transmitted to the user device using known remote control technology e.g. infrared remote wireless mouse etc. . The use of remote control technology provides the user with additional flexibility in capturing images by allowing the user to be farther from the display device and or image capture device.

When the click event is received the process starts a frame latency computation and a countdown sequence . In some implementations the process can also start measuring the average ambient light of the target s environment. This can be achieved by scanning the live video feed for pixel intensities or receiving a measurement from an ambient light sensor. Upon completion of the countdown sequence an image capture time is determined based in part on a final average frame latency a final threshold flash brightness is determined based on ambient light measurements and a screen color is determined based on the desired color balance e.g. skin tone in the captured image.

The display device e.g. display device is then configured to flash based on one or more light characteristics e.g. intensity duration color etc. . This configuration includes setting the color of the screen of the display device and setting the brightness of the display to simulate a photo flash. In some implementations the display color and brightness can be controlled via a display driver and or other operating system components that provide support for color and brightness control.

During the flash phase the target image is illuminated. Depending on the amount of frame latency the image may be captured or grabbed at an image capture time which occurs after the flash phase has completed . The image capture time should not be confused with the time the image is captured by the image capture device i.e. captured by the sensor of the video camera which occurs during the sustain time. For example during the flash phase the target is illuminated by the flash and an image frame of the illuminated target enters an image processing pipeline. Thus the flash may appear to be over to the user but the image remains in the image processing pipeline for the measured frame latency until it is captured or grabbed at the image capture time . In some implementations the image capture time is based on average frame latency and the rise and fall times of the brightness level of the display device as described with respect to .

After the image is captured it can be displayed to the user. The user can save the captured image compare it to a stored image and or load the image into an application e.g. image editor video conferencing instant text messaging etc. for further processing.

In some implementations the timestamps of the images in the image processing pipeline are used to determine which image frame will be grabbed from the image processing pipeline. For example the time when the flash phase begins can be stored as a reference time. The timestamps of each image frame in the image processing pipeline can then be compared with the reference timestamp to determine which frame will be captured or grabbed.

In some implementations multiple images are captured and displayed to the user so that the user can manually select the best image s as described with respect to U.S. patent application Ser. No. 11 248 630 filed Oct. 11 2005 entitled Image Capture and Manipulation . The characteristics of the flash can be manually or automatically adjusted to a different setting for each image. The best image can then be manually selected by the user or automatically by the device . For example the histograms of the images can be used to evaluate the quality of the images based on pixel intensity distributions e.g. image contrast bright or dark areas etc. . In some implementations the user can manually select the best image based on visual inspection and the device automatically stores the selected image as a template for future comparisons with other images.

The computer readable medium s further include an operating system e.g. Mac OS X Windows XP Unix Linux etc. a network communications module a browser e.g. Safari Microsoft Internet Explorer Netscape etc. an image capture application frame buffers video and audio files a timer and other applications .

The operating system can be multi user multiprocessing multitasking multithreading real time and the like. The operating system performs basic tasks including but not limited to recognizing input from input devices sending output to display devices keeping track of files and directories on computer readable medium s controlling peripheral devices e.g. disk drives printers image capture device etc. and managing traffic on the one or more buses . The network communications module includes various components for establishing and maintaining network connections e.g. software for implementing communication protocols such as TCP IP HTTP Ethernet etc. . The browser enables the user to search a network e.g. Internet for information e.g. video files . The image capture application provides various software components for performing the process and other image capture functions as described with respect to . The frame buffers are for storing and processing captured images. The video files include video sequences for use by the image capture system as described with respect to . The audio files provide various sound effects for use in for example the countdown sequence as described with respect to . The timer is for example a software timer that can be used to time various events in the event timeline as described with respect to . The other applications include various applications that can manipulate images e.g. video conferencing instant text messaging image editing etc. .

Various modifications may be made to the disclosed implementations and still be within the scope of the following claims.

