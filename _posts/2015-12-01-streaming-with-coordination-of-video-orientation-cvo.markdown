---

title: Streaming with coordination of video orientation (CVO)
abstract: Technology to provide streaming with coordination of video orientation (CVO) is disclosed. In an example, a server can include computer circuitry configured to: receive a device capability for a client; and modify streamed content to the client based on an inclusion of a CVO attribute in the device capability.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09438658&OS=09438658&RS=09438658
owner: INTEL CORPORATION
number: 09438658
owner_city: Santa Clara
owner_country: US
publication_date: 20151201
---
This application is a continuation of U.S. patent application Ser. No. 14 125 599 filed Dec. 12 2013 which is a 371 nationalization of U.S. PCT Patent Application Serial No. PCT US13 67054 filed Oct. 28 2013. PCT US13 67054 claims the benefit of and hereby incorporates by reference the following U.S. Provisional Patent Applications Ser. No. 61 719 241 filed Oct. 26 2012 Ser. No. 61 753 914 filed Jan. 17 2013 and Ser. No. 61 841 230 filed May 28 2013.

Wireless mobile communication technology uses various standards and protocols to transmit data between a node e.g. a transmission station and a wireless device e.g. a mobile device . Some wireless devices communicate using orthogonal frequency division multiple access OFDMA in a downlink DL transmission and single carrier frequency division multiple access SC FDMA in an uplink UL transmission. Standards and protocols that use orthogonal frequency division multiplexing OFDM for signal transmission include the third generation partnership project 3GPP long term evolution LTE the Institute of Electrical and Electronics Engineers IEEE 802.16 standard e.g. 802.16e 802.16m which is commonly known to industry groups as WiMAX Worldwide interoperability for Microwave Access and the IEEE 802.11 standard which is commonly known to industry groups as WiFi.

In 3GPP radio access network RAN LTE systems the node can be a combination of Evolved Universal Terrestrial Radio Access Network E UTRAN Node Bs also commonly denoted as evolved Node Bs enhanced Node Bs eNodeBs or eNBs and Radio Network Controllers RNCs which communicates with the wireless device known as a user equipment UE . The downlink DL transmission can be a communication from the node e.g. eNodeB to the wireless device e.g. UE and the uplink UL transmission can be a communication from the wireless device to the node.

The wireless device can be used receive multimedia delivery of Internet video using various protocols such as hypertext transfer protocol HTTP streaming. A protocol to provide HTTP based delivery of video streaming can include dynamic adaptive streaming over HTTP DASH .

Reference will now be made to the exemplary embodiments illustrated and specific language will be used herein to describe the same. It will nevertheless be understood that no limitation of the scope of the invention is thereby intended.

Before the present invention is disclosed and described it is to be understood that this invention is not limited to the particular structures process steps or materials disclosed herein but is extended to equivalents thereof as would be recognized by those ordinarily skilled in the relevant arts. It should also be understood that terminology employed herein is used for the purpose of describing particular examples only and is not intended to be limiting. The same reference numerals in different drawings represent the same element. Numbers provided in flow charts and processes are provided for clarity in illustrating steps and operations and do not necessarily indicate a particular order or sequence.

An initial overview of technology embodiments is provided below and then specific technology embodiments are described in further detail later. This initial summary is intended to aid readers in understanding the technology more quickly but is not intended to identify key features or essential features of the technology nor is it intended to limit the scope of the claimed subject matter.

The growth of multimedia services including streaming and conversational services is one of the drivers of the evolution to new mobile broadband technologies and standards. With a high consumer demand for multimedia services coupled with developments in media compression and wireless network infrastructures enhancing the multimedia service capabilities of cellular and mobile broadband systems is desirable where the multimedia service capabilities can be used to deliver a high quality of experience QoE to the consumers ensuring ubiquitous access to video content and services from any location at any time with any device and technology. Supporting various mobile devices and providing media handling procedures and session management protocols optimized for various device classes and capabilities can be used to enable delivery of multimedia content with high QoE in a ubiquitous fashion.

With the introduction of orientation sensors in mobile devices used in real time video communication the display content can be rotated to be aligned with the device orientation. In example the orientation sensor can detect the device orientation by measuring the gravity field. Other types of orientation sensors may also be used. The device orientation can then be used in applications to adjust device functions according to orientation. For instance the device can rotate the user interface or video orientation to either a portrait or landscape mode based on device orientation.

Because some client devices contain an orientation sensor the content or service provider may provide different encoded versions of the content optimized for different device orientations or the content service provider may capture or transcode the content during content capture e.g. on the fly in order to deliver an optimized experience. Signaling from the user equipment UE to the network of the orientation sensor capabilities and or the current device orientation can provide opportunities to adapt the content on the network side to deliver a high quality client experience. Multimedia adaptation based device and or video orientation adaptation can apply to both two dimensional 2D and three dimensional 3D video applications. For a 2D video example portrait or landscape video views and or different viewing angles may be adapted based on device orientation. For a 3D video example the different viewing angles and depth information may be adapted based on device orientation.

Capability exchange signaling can be an important functionality in third generation partnership project s 3GPP s packet switched streaming service PSS as described in 3GPP technical specification TS 26.234 V11.1.0 2012 09 dynamic adaptive streaming over HTTP DASH as described in 3GPP TS 26.247 V11.0.0 2012 09 and integrated multimedia subsystem IMS based PSS and multimedia broadcast and multicast service MBMS abbreviated as IMS PSS MBMS as described in 3GPP TS 26.237 V11.0.0 2012 06 . Capability exchange enables PSS DASH and IMS PSS MBMS servers to provide a wide range of devices with content suitable for the particular device in question based on the knowledge of specific capabilities of the mobile terminal To facilitate server side content negotiation for streaming the PSS or IMS PSS MBMS server may have access to a description of the specific capabilities of the mobile terminal MT via a device capability description. The device capability description can contain a number of attributes. For DASH the attributes of device capability signaling can include the following parameters A pre decoder buffer size an initial buffering period a decoder capability display properties e.g. screen size resolution or bit depth a streaming method e.g. real time streaming protocol RTSP or HTTP adaptation support QoE support extended real time transport protocol RTP control protocol RTCP reporting support and fast content switching support as well as supported RTP profiles and session description protocol SDP attributes.

During the set up of a streaming session a server can use the device capability description to provide the mobile terminal with a correct type of multimedia content. The servers can use information about the capabilities of the mobile terminal to determine which stream to provision to the connecting terminal e.g. mobile terminal . For instance the server can compare the requirements on the mobile terminal for multiple available variants of a stream with the actual capabilities of the connecting terminal to determine a best suited stream for that particular mobile terminal. Capability exchange also allows for delivery an optimized session description protocol SDP file to a client terminal e.g. mobile terminal for a PSS or IMS PSS MBMS session or an optimized media presentation description MPD metadata file to the client terminal for a DASH session.

The technology e.g. servers client devices or terminals mobile terminals methods computer circuitry and systems as described herein can provide coordination of video orientation CVO capability of the mobile terminal or client device. Different streaming paradigms e.g. PSS DASH and IMS PSS MBMS can use different multimedia adaptation methods and processes which is explained in greater detail below.

A service can use a pull based streaming process or a push based streaming process. DASH provides an example of pull based streaming. For a DASH session a HTTP server provides the content optimized for different CVO to a DASH client as illustrated in . The HTTP server may use the device capability exchange signaling from the DASH client describing the various supported CVO states . The set of CVOs and corresponding content information can be signaled to the DASH client in the media presentation description MPD metadata file with different encoded content for different CVOs which server client interaction is depicted in . The DASH client player can then track the current CVO and request the corresponding versions of the content optimized for the current CVO.

The PSS services based on the real time streaming protocol RTSP and the IMS PSS MBMS service based on the session initiation protocol SIP provide examples of push based streaming. For the PSS or IMS PSS MBMS service the server can receive the CVO information from the client and adapt the content based on the CVO as illustrated in . For instance the server can select a most suited content version among stored content versions or dynamically transcodes the content based on the CVO and stream the content to the client which server client interaction is depicted in . The session related metadata carried in the session description protocol SDP may carry the CVO for the streamed content.

Additional attributes can be added in PSS vocabulary device capability exchange signaling. For instance attributes StreamingCVOCapable StreamingHighGranularityCVOCapable ThreeGPCVOCapable and ThreeGPHighGranularityCVOCapable or attributes with similar functionality can be included or added in the Streaming and ThreeGPFileFormat component of the PSS base vocabulary in TS 26.234 describing the 3GPP PSS unicast streaming specification and TS 26.244 V11.1.0 2012 09 describing the 3GPP file format specification. The attributes can have a name definition a component a type legal values or valid options and a resolution rule. A possible syntax for these additional attributes can be as follows 

Attribute definition Indicates whether the client is a CVO capable receiver of RTP streams i.e. provided that the video orientation information for the delivered content is communicated to the client in an RTP extension header corresponding to urn 3gpp video orientation the client can interpret the video orientation and align the video correctly for rendering display purposes. If this attribute is reported and the StreamingHighGranularityCVOCapable attribute is reported as a Yes then the value of this attribute can be a Yes .

Attribute definition Indicates whether the client is a Higher Granularity CVO capable receiver of RTP streams i.e. provided that the video orientation information of the delivered content is communicated to the client in an RTP extension header corresponding to urn 3GPP video orientation 6 the client can interpret the video orientation and align the video correctly for rendering display purposes.

Attribute definition Indicates whether the client is a CVO capable receiver of 3GP files i.e. provided that the video orientation information corresponding to urn 3gpp video orientation of the delivered content is communicated to the client in a 3GP file the client can interpret the video orientation and align the video correctly for rendering display purposes. If this attribute is reported and the ThreeGPHighGranularityCVOCapable attribute is reported as a Yes then the value of this attribute can be a Yes .

Attribute definition Indicates whether the client is a Higher Granularity CVO capable receiver of 3GP files i.e. provided that the video orientation information corresponding to urn 3gpp video orientation 6 of the delivered content is communicated to the client in a 3GP file the client can interpret the video orientation and align the video correctly for rendering display purposes.

The technology described herein can also embed CVO information into the captured content such as a 3GP file. Embedding CVO information in a 3GP file as described in 3GPP technical specification TS 26.244 V11.1.0 2012 09 e.g. mp4 file in a moving picture experts group 4 MPEG 4 file format as an instantiation of an International Organization for Standardization ISO Base Media File Format BMFF for later use by servers as part of streaming and download applications can be beneficial as illustrated in . The inclusion of such CVO information in the 3GP file can better enable the server to perform orientation aware multimedia adaptation for optimizing content delivery to devices e.g. correcting the video to avoid misalignment problems prior to sending to an orientation unaware device . The embedded CVO information can be provided in device orientation capability attributes in the PSS vocabulary and device capability signaling framework. The content file e.g. mp4 file can include an initialization segment such as a moov box and media data mdat . The moov box can include initial object descriptor IOD a BInary Format for Scene BIFS trak an object descriptor OD trak a video trak and an audio trak . The embedded CVO information can be included in the video trak or track . The mdat can include interleaved time ordered BIFS OD video and audio access units AC .

In another example a service specification can support orientation aware streaming. For example for RTP streaming which can rely on the SDP coordination of video orientation CVO can be added into the PSS specification. In the PSS RTP streaming context CVO can include signaling of a current orientation of an image to a CVO capable PSS client for appropriate rendering and displaying. A CVO capable PSS server can perform signaling of the CVO by indicating the CVO in the SDP and using RTP header extensions with a byte formatted for CVO corresponding to urn 3gpp video orientation and a byte formatted for Higher Granularity CVO corresponding to urn 3gpp video orientation 6 . The RTP header extensions can be defined by 3GPP technical specification TS 26.114 V11.5.0 2012 09 .

A CVO capable PSS client can rotate the video to compensate the rotation for CVO and Higher Granularity CVO. When compensating for both rotation and flip operations can be performed in the LSB to MSB order i.e. rotation compensation first and then flip compensation .

A CVO capable PSS server can add the payload bytes to a last RTP packet in each group of packets which make up a key frame e.g. inter frame I frame or instantaneous decoding refresh IDR in a H.264 . The PSS server may also add the payload bytes onto the last RTP packet in each group of packets which make up another type of frame e.g. a predicted frame P frame when the current value is different from a previous value sent.

An inter frame I frame is a frame in a video compression stream which can be expressed in terms of one or more neighboring frames. An IDR access unit can contain an intra picture i.e. a coded picture that can be decoded without decoding any previous pictures in a Network Abstraction Layer NAL unit stream and the presence of an IDR access unit can indicate that no subsequent picture in the stream will use reference to pictures prior to the intra picture the IDR access unit contains in order to be decoded . The H.264 moving picture experts group 4 MPEG 4 H.264 MPEG 4 part 10 or advanced video coding AVC is a video compression format which can be used for the recording compression and distribution of high definition video. A P frame can be a type of I frame to define forward predicted pictures. The prediction can be made from an earlier picture mainly an I frame for less data coding.

If a CVO RTP header extension is the only header extension present a total of 8 bytes can appended to the RTP header and the last packet in the sequence of RTP packets can be marked with both a marker bit and an extension bit.

If CVO information is signaled in the RTP header extension the PSS server can signal the CVO information in the SDP by including an a extmap attribute indicating an CVO uniform resource name URN under a relevant media line scope. The CVO URN can be represented as urn 3gpp video orientation. An example usage of a URN to signal CVO relative to a media line is as follows a extmap 7 urn 3gpp video orientation . The number 7 in the CVO URN example may be replaced with any number in a range 1 14.

If Higher Granularity CVO information is signaled in the RTP header extension the PSS server can signal the Higher Granularity CVO information in the SDP in a similar fashion with the CVO URN where a Higher Granularity CVO URN can be represented as urn 3gpp video orientation 6. An example usage of a URN to signal CVO relative to a media line is as follows a extmap 5 urn 3gpp video orientation 6 .

Accordingly in an example the inclusion of CVO information can be logged within a 3GP file format as a continuous recording of a series of orientation values of the images captured. A box can be defined in the ISO base media file format ISO BMFF or the 3GPP file format for timed CVO information. For instance the video track or the RTP hint track of the 3GPP file format 3GP may be used to embed the orientation information. For content formatted based on DASH the CVO information may be carried within a file level ISO BMFF box such as in initialization segment e.g. in a moov box for ISO BMFF or in media segments e.g. in a moof box for ISO BMFF as illustrated in . In another example the timed metadata track of the ISO BMFF may be chosen as the track to contain the CVO information. For instance a new box can be created specifically for CVO such as a CVOSampleEntry with a description of the CVO parameters. Other boxes within the sample description box in the ISO file format box structure hierarchy as shown in may also be used to contain the CVO information. The ISO file format box structure hierarchy can include a movie box a track box a media box a media information box a sample table box and the sample description box where higher order boxes are listed first. The sample description box can have one or more sample entries such as MP4VisualSampleEntry AVCSampleEntry HintSampleEntry or CVOSampleEntry.

In another example the video orientation e.g. CVO information can be included in a 3GP file format which can be included in TS 26.244. When CVO data is stored in the 3GP file format a timed metadata track can be used with a CVOSampleEntry box. The CVOSampleEntry can indicate that the metadata sample format is a single byte of CVO data. Each metadata track containing CVO data can reference a video track where the metadata track describes the video track using a cdsc track reference as defined in the ISO base media file format ISO BMFF .

In an example a box type of the CVOSampleEntry Box can have a codecs attribute set to be 3gvo . The CVOSampleEntry Box can be defined as follows 

The fields for the CVOSampleEntry Box can be defined by Table 1. The CVOSampleEntry Box fields can include a field name type details and a value.

The technology described provides streaming or download of content with oriented video components e.g. CVO components . Device orientation aware multimedia adaptations provide streaming or download of previously captured and uploaded content with oriented video components. For example as part of a PSS download or MBMS download application the server may push captured content with oriented video components to the client in a non real time fashion for later playback. Or as part of a DASH based streaming service an HTTP server may deliver user generated content UGC to DASH clients that may contain oriented video components. For a RTP based streaming of UGC content may be delivered from PSS servers.

In these contexts the server may receive information on the video orientation capabilities supported by the client device and determine an optimal delivery mechanism e.g. select the most suited content version among various stored content versions and or dynamically transcode the content based on the video orientation capabilities of the terminal and deliver the optimally chosen content to the client.

For example if the server determines that the content was captured by an orientation aware terminal e.g. through the inspection of the 3GP based content file while the receiving client device is not orientation aware e.g. known based on PSS device capability signaling mechanisms the server may process e.g. apply transcoding to the content to correct and avoid misalignment problems during later rendering and display. If the receiving client device is orientation aware then the server may not have to correct the misalignment but instead can choose to send the content as is i.e. without modification along with video orientation information embedded in the content e.g. in an RTP extension header for RTP streaming or inside a 3GP file for HTTP streaming and DASH so that the receiving client device can correct the misalignment.

In another example consistent with a server client interaction as illustrated in a DASH server can learn from the client e.g. rendering client that the client has the ability to process CVO information and correct for misalignment. The server can then designate in a MPD on the presence of CVO information in the DASH representations i.e. if the DASH segments are stored content the DASH server may have to detect the presence of CVO information before the DASH server can determine by parsing the 3GP files corresponding to the DASH segments and can check if video orientation information is indicated in the metadata track . The DASH client upon reception of the MPD can then activate a video orientation engine to process the signaled CVO information i.e. parsing of the 3GP files corresponding to DASH representations in the DASH segments and correct any misalignments and cand render display video with correct alignment.

Also consistent with server client interaction as illustrated in a DASH server can learn from the client that the client does not have the ability to process CVO information and correct for misalignment. The server can detect the presence of CVO information in the content since the MPD can indicate the CVO information. In response DASH server can process the 3GP files corresponding to the DASH representations offered in the MPD in order to correct for any misalignments and can send the requested content to the DASH client after this processing.

In another configuration a CVO information indication can be implemented in a DASH MPD based on TS 26.247. For instance a CVO indication attribute e.g. cvo granularity can be included in the MPD where the MPD can have common attributes and elements. The elements AdaptationSet Representation and SubRepresentation can have assigned common attributes and elements such as the CVO indication attribute. The semantics of the CVO indication attribute can be as shown in Table 2 which illustrates a table of common adaptation set representation and sub representation attributes and elements. Each element or attribute can have an element or attribute name use or description. The use column in Table 2 can interpret an attribute marked with M mandatory as available for a representation. For instance the attribute or element may either be present in the Representation element or if not the attribute or element may be in the AdaptationSet element. An attribute marked with 0 optional may be absent in both the Representation element and the AdaptationSet element.

The extensible markup language syntax XML syntax for the CVO indication attribute e.g. cvo granularity can be as shown in Table 3 illustrated in .

As previously discussed DASH is a standardized HTTP streaming protocol. As illustrated in DASH can specify different formats for a media presentation description MPD metadata file that provides information on the structure and different versions of the media content representations stored in the server as well as the segment formats. The MPD metadata file contains information on the initialization and media segments for a media player e.g. the media player can look at initialization segment to determine a container format and media timing information to ensure mapping of segments into a media presentation timeline for switching and synchronous presentation with other representations. DASH technology has also been standardized by other organizations such as the moving picture experts group MPEG open IP television IPTV forum OIPF and hybrid broadcast broadband TV HbbTV .

A DASH client can receive multimedia content by downloading the segments through a series of HTTP request response transactions. DASH can provide the ability to dynamically switch between different bit rate representations of the media content as the bandwidth that is available to a mobile device changes. Thus DASH can allow for fast adaptation to changing network and wireless link conditions user preferences and device capabilities such as display resolution the type of central processing unit CPU employed the memory resources available and so forth. The dynamic adaptation of DASH can provide a better quality of experience QoE for a user with shorter startup delays and fewer rebuffering events than other streaming protocols.

In DASH a media presentation description MPD metadata can provide information on the structure and different versions of the media content representations stored in a web media server. In the example illustrated in the MPD metadata is temporally divided into periods having a predetermined length such as 60 seconds in this example. Each period can include a plurality of adaptation sets . Each adaptation set can provide information about one or more media components with a number of encoded alternatives. For example adaptation set 0 in this example might include a variety of differently encoded audio alternatives such as different bit rates mono stereo surround sound CVO and so forth. In addition to offering different quality audio for a multimedia presentation over the period ID the adaptation set may also include audio in different languages. The different alternatives offered in the adaptation set are referred to as representations .

In Adaptation set 1 is illustrated as offering video at different bitrates such as 5 mega bits per second Mbps 2 Mbps 500 kilo bits per second kbps or a trick mode. The trick mode can be used for seeking fast forwarding rewinding or other changes in location in the multimedia streaming file. In addition the video may also be available in different formats such as two dimensional 2D or three dimensional 3D video or portrait or landscape oriented video e.g. CVO . Each representation can include segment information . The segment information can include initialization information and the actual media segment data . In this example an MPEG 4 MP4 file is streamed from a server to a mobile device. While MP4 is used in this example a wide variety of different codecs may be used as previously discussed.

The multimedia in the adaptation set can be further divided into smaller segments. In the example of the 60 second video segment of adaptation set 1 is further divided into four sub segments of 15 seconds each. These examples are not intended to be limiting. The actual length of the adaptation set and each media segment or sub segment is dependent on the type of media system requirements potential types of interference and so forth. The actual media segments or sub segments may have a length that is less than one second to several minutes long.

Another example provides a method for signaling coordination of video orientation CVO capability of a mobile terminal MT at a server as shown in the flow chart in . The method may be executed as instructions on a machine or computer circuitry where the instructions are included on at least one computer readable medium or one non transitory machine readable storage medium. The method includes the operation of receiving a device capability for a client at the server as in block . The next operation of the method can be identifying when the device capability includes a CVO attribute as in block . The method can further include adapting streamed content to the client based on an inclusion of the CVO attribute the CVO attribute as in block .

In an example the operation of adapting the streamed content can further include modifying a display orientation of the a hypertext transfer protocol HTTP stream dynamic adaptive streaming over HTTP DASH or real time transport protocol RTP stream for misalignment when the device capability for the client does not include the CVO attribute indicating that the client is not an orientation aware terminal or embedding a CVO indication attribute in a media presentation description MPD metadata file or a session description protocol SDP file when the device capability for the client includes the CVO attribute indicating that the client is an orientation aware terminal to modify the display orientation of a stream.

In another example the method can further include delivering a media presentation description MPD metadata file for a streamed dynamic adaptive streaming over hypertext transfer protocol HTTP DASH content to the client with a CVO indication attribute provided in a codecs common attribute or element for an AdaptationSet Representation or SubRepresentation. The codecs attribute can be set to 3gvo indicating a presence of an oriented video component and associated CVO information in the stream DASH content. The method can further include deliver a session description protocol SDP file for a real time transport protocol RTP stream to the client with a CVO indication via an a extmap attribute with a CVO uniform resource name URN urn 3gpp video orientation representing a 2 bit granularity for a CVO or urn 3gpp video orientation 6 representing a 6 bit granularity for a Higher Granularity CVO on the CVO information contained in a RTP extension header.

In another configuration the operation of adapting the streamed content can further include receiving user generated content UGC video including embedded CVO information for the UGC video in a third generation partnership project 3GPP file format 3GP file. The 3GP file can uses a CVOSampleEntry for a CVO timed metadata track in a sample description box of International Organization for Standardization ISO file format box structure. The CVOSampleEntry fields can include a BoxHeader size or type a Data reference index or a Granularity where the BoxHeader type can be configured for a 3gvo value. Or the 3GP file can use a codecs common attribute or element for an AdaptationSet Representation or SubRepresentation of a media presentation description MPD . The codecs attribute can be set to 3gvo indicating a presence of an oriented video component and associated CVO information in a streamed dynamic adaptive streaming over hypertext transfer protocol HTTP DASH content.

In another example the operation of adapting the streamed content can further include storing CVO data in a third generation partnership project 3GPP file format 3GP file using a CVOSampleEntry for a CVO timed metadata track in a sample description box of International Organization for Standardization ISO file format box structure. The CVOSampleEntry fields can include a BoxHeader size or type a Data reference index or a Granularity where the BoxHeader type can be configured for a 3gvo value. Or the operation of adapting the streamed content can further include storing CVO data for a real time transport protocol RTP stream in a RTP extension header.

In another configuration the operation of receiving the device capability for the client can further include exchanging a packet switched streaming service PSS client capability for the client. The CVO capability can include a StreamingCVOCapable attribute to indicate whether the client is a CVO capable receiver of real time transport protocol RTP streams a StreamingHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of RTP streams a ThreeGPCVOCapable attribute to indicate whether the client is a CVO capable receiver of third generation partnership project 3GPP file format 3GP files or a ThreeGPHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of 3GP files.

Another example provides functionality of computer circuitry of a server operable to provide streaming with coordination of video orientation CVO as shown in the flow chart in . The functionality may be implemented as a method or the functionality may be executed as instructions on a machine where the instructions are included on at least one computer readable medium or one non transitory machine readable storage medium. The computer circuitry can be configured to receive a device capability for a client as in block . The computer circuitry can be further configured to modify streamed content to the client based on an inclusion of a CVO attribute in the device capability as in block .

In an example the computer circuitry configured to modify the streamed content can be further configured to correct a rendering orientation of the a real time transport protocol RTP stream or streamed dynamic adaptive streaming over hypertext transfer protocol HTTP DASH content for misalignment prior to delivery to the client when the device capability for the client does not include the CVO attribute indicating that the client is not an orientation aware terminal.

In another example the computer circuitry configured to modify the streamed content can be further configured to deliver a media presentation description MPD metadata file for a streamed dynamic adaptive streaming over hypertext transfer protocol HTTP DASH content to the client with a CVO indication attribute provided in a codecs common attribute or element for an AdaptationSet Representation or SubRepresentation wherein the codecs attribute is set to 3gvo indicating a presence of an oriented video component and associated CVO information in the streamed DASH content. Or the computer circuitry configured to modify the streamed content can be further configured to deliver a session description protocol SDP file for a real time transport protocol RTP stream to the client with a CVO indication via an a extmap attribute with a CVO uniform resource name URN urn 3gpp video orientation representing a 2 bit granularity for a CVO or urn 3gpp video orientation 6 representing a 6 bit granularity for a Higher Granularity CVO on the CVO information contained in a RTP extension header.

In another configuration the computer circuitry can be further configured to store CVO data in a third generation partnership project 3GPP file format 3GP file using a CVOSampleEntry for a CVO timed metadata track in a sample description box of International Organization for Standardization ISO file format box structure. The CVOSampleEntry fields can include a BoxHeader size or type a Data reference index or a Granularity where the BoxHeader type can be configured for a 3gvo value. Or the computer circuitry can be further configured to store CVO data for a real time transport protocol RTP stream in a RTP extension header.

In another example the computer circuitry configured to receive the device capability can be further configured to exchange a packet switched streaming service PSS capability. The CVO attribute can include a StreamingCVOCapable attribute to indicate whether the client is a CVO capable receiver of real time transport protocol RTP streams a StreamingHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of the RTP streams a ThreeGPCVOCapable attribute to indicate whether the client is a CVO capable receiver of third generation partnership project 3GPP file format 3GP files or a ThreeGPHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of the 3GP files.

In another configuration the computer circuitry configured to modify the streamed content can be further configured to perform orientation aware content adaptation orientation aware content selection orientation aware transcoding or orientation aware format conversion to correct a video orientation misalignment and ensure a content playback at the client with a correct video orientation. The server can include a third generation partnership project 3GPP long term evolution LTE packet switched streaming service PSS server a dynamic adaptive streaming over hypertext transfer protocol HTTP DASH server or an integrated multimedia subsystem IMS based PSS and multimedia broadcast and multicast service MBMS IMS PSS MBMS server.

Referring back to the mobile terminal can include a processor a transceiver and an orientation sensor . The processor can be configured for determining an MT s CVO capability. The transceiver can be configured to transmit the MT s CVO capability in a streaming component attribute to the server.

In an example the transceiver can be further configured to receive a real time transport protocol RTP extension header for an RTP stream or a third generation partnership project 3GPP file format 3GP file for a hypertext transfer protocol HTTP stream or dynamic adaptive streaming over HTTP DASH . The processor can be further configured to parse a media presentation description MPD metadata file for the 3GP file for a CVO indication attribute or parse the 3GP file for embedded CVO information determine a orientation correction term based on the parsed CVO information and a current orientation of the MT and correct a rendering orientation of the HTTP stream or DASH for misalignment based on the determined orientation correction term when the MPD metadata file includes the CVO indication attribute and the MT is an orientation aware terminal Or the processor can be configured to parse a session description protocol SDP file for the RTP stream for the CVO indication attribute or parse the RTP extension header for the RTP stream for the embedded CVO information determine a orientation correction term based on the parsed CVO information and current orientation of the client device and correct a rendering orientation of the RTP stream for misalignment based on the determined orientation correction term when the SDP file includes the CVO indication attribute and the MT is the orientation aware terminal Correcting the rendering orientation can compensate for rotation or flip of an orientation.

In another example the transceiver can be further configured to receive a media presentation description MPD metadata file from the server for streamed dynamic adaptive streaming over hypertext transfer protocol HTTP DASH content with a CVO indication attribute provided in a codecs common attribute or element for an AdaptationSet Representation or SubRepresentation. The codecs attribute can be set to 3gvo indicating a presence of an oriented video component and an associated CVO information in the streamed DASH content. The processor can be further configured to parse the MPD metadata file for the CVO indication attribute and modify a rendering orientation of a HTTP stream or the streamed DASH content for misalignment when the MPD metadata file includes the CVO indication attribute and the MT is an orientation aware terminal.

In another configuration the transceiver can be further configured to receive a third generation partnership project 3GPP file format 3GP file including a CVOSampleEntry for a CVO timed metadata track in a sample description box of International Organization for Standardization ISO file format box structure. The CVOSampleEntry fields can include a BoxHeader size or type a Data reference index or a Granularity where the BoxHeader type can be configured for a 3gvo value. The processor can be further configured to parse the 3GP file for the CVOSampleEntry and modify a rendering orientation of a hypertext transfer protocol HTTP stream or streamed dynamic adaptive streaming over HTTP DASH content for misalignment when the 3GP file includes the CVOSampleEntry and the MT is an orientation aware terminal.

In another example the transceiver can be further configured to exchange a packet switched streaming service PSS client capability with the MT s CVO capability. The MT s CVO capability can include a StreamingCVOCapable attribute to indicate whether the client is a CVO capable receiver of real time transport protocol RTP streams a StreamingHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of RTP streams a ThreeGPCVOCapable attribute to indicate whether the client is a CVO capable receiver of third generation partnership project 3GPP file format 3GP files or a ThreeGPHighGranularityCVOCapable attribute to indicate whether the client is a Higher Granularity CVO capable receiver of 3GP files.

In another configuration the processor can be further configured to capture user generated content UGC video with a specified orientation and embed CVO information for the UGC video in a third generation partnership project 3GPP file format 3GP file. The transceiver can be further configured to upload a 3GP file for a hypertext transfer protocol HTTP stream or dynamic adaptive streaming over HTTP DASH .

In another example the processor can be further configured to capture CVO data with a specified orientation and store the CVO data in a third generation partnership project 3GPP file format 3GP file using CVOSampleEntry for a CVO timed metadata track in a sample description box of International Organization for Standardization ISO file format box structure. The CVOSampleEntry fields can include a BoxHeader size or type a Data reference index or a Granularity where the BoxHeader type can be configured for a 3gvo value. The transceiver can be further configured to upload a 3GP file for a hypertext transfer protocol HTTP stream or dynamic adaptive streaming over HTTP DASH .

In another configuration the MT s CVO capability can be provided in a third generation partnership project 3GPP long term evolution LTE packet switched streaming service PSS session a dynamic adaptive streaming over hypertext transfer protocol HTTP DASH session or an integrated multimedia subsystem IMS based PSS and multimedia broadcast and multicast service MBMS IMS PSS MBMS session. The mobile terminal can include the orientation sensor to determine an orientation of the MT.

Various techniques or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes compact disc read only memory CD ROMs hard drives non transitory computer readable storage medium or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the various techniques. Circuitry can include hardware firmware program code executable code computer instructions and or software. A non transitory computer readable storage medium can be a computer readable storage medium that does not include signal. In the case of program code execution on programmable computers the computing device may include a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. The volatile and non volatile memory and or storage elements may be a random access memory RAM erasable programmable read only memory EPROM flash drive optical drive magnetic hard drive solid state drive or other medium for storing electronic data. The node and wireless device may also include a transceiver module i.e. transceiver a counter module i.e. counter a processing module i.e. processor and or a clock module i.e. clock or timer module i.e. timer . One or more programs that may implement or utilize the various techniques described herein may use an application programming interface API reusable controls and the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s may be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and combined with hardware implementations.

It should be understood that many of the functional units described in this specification have been labeled as modules in order to more particularly emphasize their implementation independence. For example a module may be implemented as a hardware circuit comprising custom very large scale integration VLSI circuits or gate arrays off the shelf semiconductors such as logic chips transistors or other discrete components. A module may also be implemented in programmable hardware devices such as field programmable gate arrays programmable array logic programmable logic devices or the like.

Modules may also be implemented in software for execution by various types of processors. An identified module of executable code may for instance comprise one or more physical or logical blocks of computer instructions which may for instance be organized as an object procedure or function. Nevertheless the executables of an identified module need not be physically located together but may comprise disparate instructions stored in different locations which when joined logically together comprise the module and achieve the stated purpose for the module.

Indeed a module of executable code may be a single instruction or many instructions and may even be distributed over several different code segments among different programs and across several memory devices. Similarly operational data may be identified and illustrated herein within modules and may be embodied in any suitable form and organized within any suitable type of data structure. The operational data may be collected as a single data set or may be distributed over different locations including over different storage devices and may exist at least partially merely as electronic signals on a system or network. The modules may be passive or active including agents operable to perform desired functions.

Reference throughout this specification to an example or exemplary means that a particular feature structure or characteristic described in connection with the example is included in at least one embodiment of the present invention. Thus appearances of the phrases in an example or the word exemplary in various places throughout this specification are not necessarily all referring to the same embodiment.

As used herein a plurality of items structural elements compositional elements and or materials may be presented in a common list for convenience. However these lists should be construed as though each member of the list is individually identified as a separate and unique member. Thus no individual member of such list should be construed as a de facto equivalent of any other member of the same list solely based on their presentation in a common group without indications to the contrary. In addition various embodiments and example of the present invention may be referred to herein along with alternatives for the various components thereof. It is understood that such embodiments examples and alternatives are not to be construed as defacto equivalents of one another but are to be considered as separate and autonomous representations of the present invention.

Furthermore the described features structures or characteristics may be combined in any suitable manner in one or more embodiments. In the following description numerous specific details are provided such as examples of layouts distances network examples etc. to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components layouts etc. In other instances well known structures materials or operations are not shown or described in detail to avoid obscuring aspects of the invention.

While the forgoing examples are illustrative of the principles of the present invention in one or more particular applications it will be apparent to those of ordinary skill in the art that numerous modifications in form usage and details of implementation can be made without the exercise of inventive faculty and without departing from the principles and concepts of the invention. Accordingly it is not intended that the invention be limited except as by the claims set forth below.

