---

title: Distributed metering and monitoring system
abstract: The distributed metering and monitoring service (DMMS) system provides a way to gather and maintain metrics data which remains distributed, until requested. The DMMS system uses messaging queues to scale the number of servers that may be monitored and metered to a hyperscale of greater than 10,000 servers. The DMMS system determines how many servers (nodes) to assign to a cluster, and uses a metric aggregator to collect and store metrics data for the nodes. The DMMS system creates message queues for the instances, injects instance identifiers into the cluster state data and metrics data, listens for request messages for metering information for instances, retrieves the metrics data for users identified by the instance identifiers stored locally at the nodes, and calculates the metering information for the instance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09432462&OS=09432462&RS=09432462
owner: Accenture Global Services Limited
number: 09432462
owner_city: Dublin
owner_country: IE
publication_date: 20151217
---
This application a continuation application of U.S. patent application Ser. No. 13 159 042 filed on Jan. 13 2011 the content of which is incorporated in its entirety herein by reference for all purposes.

The present description relates generally to a system and method to monitor and meter networked resources and more particularly but not exclusively to maintaining metrics data distributed to the network cluster until requested and using messaging queues to scale the number of servers per networked environment that may be monitored and metered to the hyperscale of greater than 10 000 nodes.

Many industry approaches to metering and billing information include continuously aggregating metrics for the nodes of a networked environment into a central repository. Current solutions configure servers with agents and those agents provide information through the network to be stored in a single database. Large proprietary software and internet companies are cornering the enterprise virtualization and cloud computing market and require a low cost elastic and efficient enterprise data center stack to monitor and meter networked environments at the hyperscale that is currently emerging. In an embodiment hyperscale computing may refer to systems composed of greater than 10 000 servers nodes . Current methods for monitoring virtual machine instances that include installing software on each virtual machine instance to monitor the instance are impractical to use at the hyperscale of networked environments today. Current metering and monitoring solutions that employ a centralized repository to collect metrics data do not scale well because the upper limit of the number of nodes that may be monitored depends on multiple factors including the number of nodes monitored the metrics data to be collected and the intended frequency to perform the data collection. Monitoring is about resource utilization so that from a system administrator perspective monitoring typically includes making sure that system resources are not over tasked. Metering is about which users are using which resources and less about which resources are being used and are those resources being overloaded. As service providers such as those in the information and energy industries identify new markets products and services the ability to accurately monitor and meter at the hyperscale of networked devices used to deliver the products and services is necessary.

A distributed metering and monitoring service DMMS system provides a way to scale the number of nodes servers monitored and metered to the hyperscale of greater than 10 000 servers by maintaining metrics data distributed to clusters until requested and using messaging queues to maintain state information and metrics data in the messaging layer of the DMMS system. The DMMS system provides a user aggregate access to data without aggregating the data requested until the data is requested. The DMMS system includes a DMMS memory coupled to a DMMS processor and the DMMS memory includes messaging queue logic to receive and route request messages for metering information and receive and route reply messages to return the locally retrieved metering information. The DMMS system determines the number of nodes networked to assign to a cluster and respective messaging queue. Each node includes instances responsive to respective user interactions through a user interface. The DMMS system collects metrics data for the nodes including the virtual machine instances on the nodes. The DMMS system communicates through the messaging system to request retrieval of metrics data identified in a request message e.g. the instances assigned the node by the user identifiers and or instances identifiers.

Other systems methods and features will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and be included within this description be within the scope of the disclosure and be protected by the following claims.

The principles described herein may be embodied in many different forms. Not all of the depicted components may be required however and some implementations may include additional components. Variations in the arrangement and type of the components may be made without departing from the spirit or scope of the claims as set forth herein. Additional different or fewer components may be provided.

Large proprietary software and internet companies are cornering the enterprise virtualization and cloud computing market. The DMMS system enables enterprises to build a lower cost elastic and efficient enterprise data center stack. Many solutions for metering users in a networked environment scale well to a certain level but not to the hyperscale that is currently emerging e.g. 10 000 servers or nodes to monitor meter per networked environment . The DMMS system configuration implements a purpose built overlay network built to use an instance identifier and or user information to route messages. The DMMS system provides a novel approach for metering and billing in a hyperscale networked environment which allows for the collection and storage of metrics data to stay distributed. The DMMS system allows a user to aggregate access to data without aggregating the data requested until the data is requested. In contrast to other industry approaches the DMMS system does not require that the metering and billing information be continuously aggregated in a central repository. The DMMS system metering and billing information stays distributed in each cluster of a compute system until requested. The DMMS system allows for specific user e.g. instance information to be requested by the end user or a billing system of a networked environment e.g. a cloud computing environment and or an electric power grid environment and then the request is routed to the node where the instance information is stored and then the request is processed. In an embodiment the DMMS architecture may utilize open source Software to obtain system wide metrics pertaining to all levels of infrastructure contained in a networked environment. In addition to computing clusters the DMMS system may be used in an electric power grid environment as an example to monitor and meter appliances used by customers of energy providers and provide energy providers and consumers the ability to bill be billed at the granularity of the appliance e.g. any device or process networked and or connected to the electric grid . The DMMS system utilizes features in standardization of message queuing AMQP to allow components of the system to cooperate in a distributed environment. The message queuing system allows The DMMS system to keep metering information locally at the node level. The DMMS system may be implanted using extremely scalable components including for example the Open Source RabbitMQ Broker and the Ganglia monitoring system and allows the DMMS system to scale according to the ability of the RabbitMQ broker for example by storing the systems state information within the clusters of the system and coordinating collection of the information through the network messaging component of the system. The DMMS system allows for simpler integration with a billing system e.g. a consuming system requesting instance and user metering information so that a service provider e.g. a cloud operator and or an electrical energy provider may bill users according to metering data at various levels of granularity.

In an embodiment the DMMS architecture creates an Open Source IaaS Private Cloud powered by Eucalyptus OpenStack and KVM QEMU that scales the Open Source IaaS Private Cloud to a production environment that can support several hundred virtual machines. The DMMS architecture integrates with Open Source ITSM software proprietary virtualization tools and public and or internet based clouds. Eucalyptus is an open source software platform that implements IaaS style cloud computing using the existing Linux based infrastructure found in the modern data center. OpenStack is a collection of open source technologies that deliver a scalable cloud operating system. The QEMU KVM hypervisor interface is a libvirt QEMU driver that manages QEMU emulators and also manages KVM which provides the QEMU command line syntax and monitors interaction. The libvirt QEMU driver is a multi instance driver providing a single system wide privileged driver the system instance and per user unprivileged drivers the session instance and the URI driver protocol is qemu .

Table 1 shows example connection URIs for the libvirt driver. Accessing the QEMU driver in libvirt the qemu session family of URIs connect to a libvirtd instance running as the same user group ID as the client application. The QEMU instances spawned from the driver share the same privileges as the client application. The intended use case for the driver is desktop virtualization with virtual machines storing their disk images in the user s home directory and being managed from the local desktop login session. The qemu system family of URIs connect to a libvirtd instance running as the privileged system account root . The QEMU instances spawned from the driver may have much higher privileges than the client application managing them. The intended use case for the driver is server virtualization where the virtual machines may need to be connected to host resources e.g. block PCI USB and network devices whose access requires elevated privileges.

The DMMS system collects physical host performance metrics as well as virtual machine metrics and evaluates the metrics according to the DMMS cost model e.g. for billing purposes . The DMMS system may receive a cost breakdown policy from a billing system to incorporate and or use to identify which physical host performance metrics as well as virtual metrics to collect and evaluate. The infrastructure metering component collects usage statistics to track consumption overall and by user instance . The DMMS system polls the metrics on a configurable interval from the underlying infrastructure layers. DMMS usage records and data collected may include date and time of usage occurrence customer identifying information quantity consumed and consumption description. The DMMS system records the collected metrics throughout the month e.g. reporting period and or billing period and dependent on the chosen pricing model aggregated to reflect that periods billing and or any other configurable collection frequency. Metric collection occurs on both the hypervisor e.g. instances and client machine levels e.g. nodes . The DMMS system pulls the metrics to provide usage analysis broken down by user group and overall. The DMMS system analyzes the aggregated set of data according to the DMMS cost model e.g. the DMMS system uses the DMMS cost model to identify metrics of particular interest . The DMMS system may use another cost model provided by a billing system information consuming system or some other source to translate and or associate the metrics collected from the nodes to the associated costs for user to instance metering information. The billing policy may be a variable policy set with a client e.g. a billing system . The DMMS system may itemize invoice reports according to the charges incurred during the billing cycle. The invoices may include both scheduled runs and ad hoc generating methods. The DMMS system provides a user interface for the user to make adjustments to invoices incorporate credits debits and line item adjustments.

The DMMS system allows for specific user e.g. instance information to be requested by an end user or a billing system of a networked environment e.g. a cloud computing environment and or an electric power grid environment routed to where the information is stored and then processed. The DMMS system may be used to monitor and meter appliances used by customers of energy providers and provide users the ability to be billed at the granularity of the appliance e.g. any device networked and or connected to the electric grid .

Table 2 is a list of metrics that the DMMS system may collect from the networked environment. The DMMS system may collect the metrics data listed in Table 2 in order to calculate the general usage of the environment and in particular each user instance usage.

Table 3 shows user selectable metrics to schedule for collection in the networked environment depending on the usage requirements established by the end user. The DMMS system may collect the user selectable metrics by default but the DMMS system may not report the user selectable metrics unless specifically requested or indicated and or configured to do so.

The DMMS system configuration uses message queues for each instance to retrieve metering information for the instances. The DMMS monitor listens for requests for information for any of the nodes for which the aggregator is collecting metrics data. The DMMS system includes a communications interface in communications with a virtual machine controller VMC system e.g. includes virtualization management application programming interface API logic that maintains information regarding the link between the instances and users. Each instance identifies a user for whom the metering logic calculates the metering information and the DMMS system uses instance identifiers as routing identifier to route request messages to retrieve metering information for users. The virtualization management API facilitates the request for metering information from the message queue provides a way to connect to the message queue and the message queue then contacts the appropriate DMMS monitor to retrieve the appropriate information e.g. from the aggregator database and or node memory . The DMMS monitor returns the appropriate information to the virtual machine control solution and the message queue .

A cluster defines node identifiers for the nodes assigned to the cluster. The node memory includes metric aggregator logic that stores the node identifiers for the nodes assigned to the cluster in the node memory collects the cluster state data that identifies the state of the cluster collects the metrics data for the node identifiers and stores the cluster state data and metrics data in the node memory and or a cluster aggregator database . The metric aggregator logic monitors the nodes of a cluster and collects node level information while linking the respective instances of the nodes and the instance information to the node level information. Each node includes a memory coupled to a processor. The memory includes the cluster state data and the metrics data for the node identifiers. The state information of each node and the cluster may be communicated and propagated to each other node of the cluster by using a protocol e.g. XER over XML XML governed by XML Encoding Rules XER a canonical called OXER and used e.g. for digital signatures and a non canonical variant of the XML Encoding Rules . The memory also includes a hypervisor that manages the instances that consume networked resources and instance state information stored in the memory. The hypervisor assigns an instance identifier that also identifies the assigned node by a node identifier. The node memory includes metering logic to retrieve instance state information from the hypervisor e.g. via a hypervisor API for the instances identified by the instance identifiers and generate a reply message that includes the metering information for the instances assigned the node. The DMMS logic may implement collector agent modules which interact with the hypervisor API to retrieve metric information from the virtual machines instances without installing software on the virtual machines instances and tags the metric information with the instance identifiers of the virtual machine. Consumer systems may access the DMMS system through the authorization manager or directly if for example the consumer system is a trusted system. The DMMS system may use the auth manager for server defined security e.g. node access . The DMMS system allows the networked environment to scale at hyperscale by optimizing a message queue to cluster ratio of a networked environment of multiple nodes divided into multiple clusters e.g. a message queue may be assigned cluster of nodes where multiple clusters may be configured to monitor and meter thousands of nodes . In contrast to the configuration used by the DMMS system installing software on each virtual machine instance imposes substantial overhead on the node metrics data aggregator and network environment overall and accordingly does not scale anywhere near to the hyperscale of greater than 10 000 nodes.

The DMMS system configuration uses message queues for each instance to retrieve metering information for the instances. The DMMS monitor listens for requests for information for any of the nodes for which the aggregator is collecting metrics data. The DMMS system includes a communications interface in communications with a virtual machine controller VMC system e.g. OpenStack that maintains information regarding the link between the instances and users. Each instance identifies a user for whom the metering logic e.g. the usage log processing and metering synthesis logic calculates the metering information and the DMMS system uses instance identifiers as routing identifier to route request messages to retrieve metering information for users. The DMMS system may implement the OpenStack or another virtual machine control solution API integration that contains information regarding the link between virtual machine instance identifiers and user identifiers and the API integration calls to the DMMS producer to request metering information from the message queue . The DMMS producer is a client that connects to the message queue and the message queue then contacts the appropriate DMMS monitoring component and not shown replications of to retrieve the appropriate information e.g. from the aggregator database and or node memory . The DMMS monitor returns the appropriate information to the virtual machine control solution e.g. OpenStack the DMMS producer usage log processing and metering synthesis logic e.g. used to calculate a metering calculation compute cluster monitoring system and the message queue of the appropriate messaging system .

Each cluster defines node identifiers for each of the nodes assigned to the cluster . The hypervisor assigns an instance identifier that also identifies the assigned node by a node identifier. The node memory includes retrieved instance state information from the hypervisor e.g. via libvrt driver for the instances identified by the instance identifiers and generated reply message that includes the metering information for the instances assigned the node. A node e.g. the processor of the node of the cluster may operate as a primary controller as indicated by the dotted line with arrows of the metrics aggregator and monitoring component while the other nodes of the cluster operate as backup and or failover controllers as indicated by the dotted lines with arrows for the metrics aggregator. The DMMS logic may implement Ganglia dynamic shared object DSO modules that interact with libvrt to inject metric information from the virtual machines instances and tags the metric information with the instance identifiers of the virtual machine without installing software on the virtual machines instances . The DMMS system allows the networked environment to scale at hyperscale by optimizing a message queue to cluster ratio of a networked environment of multiple nodes divided into multiple clusters e.g. replicates where a message queue may be assigned a cluster of nodes where multiple clusters may be configured to monitor and meter thousands of nodes . The DMMS system allows the networked environment to further scale at hyperscale by optimizing API servers to message queues e.g. replicates of message queues to clusters e.g. replicated by of multiple nodes divided into multiple clusters. For example in order to scale the virtualization management API servers at hyperscale a master message queue may be placed between a master virtualization management API server in communications with networked slave virtualization management API servers so that the master virtualization management API server may control a number of the slave API servers that control a number of nodes via respective message queues up to a number limit of message queues manageable by a virtualization management API server.

The computer system may include a processor such as a central processing unit CPU a graphics processing unit GPU or both. The processor may be a component in a variety of systems. For example the processor may be part of a standard personal computer or a workstation. The processor may be one or more general processors digital signal processors application specific integrated circuits field programmable gate arrays servers networks digital circuits analog circuits combinations thereof or other now known or later developed devices for analyzing and processing data. The processors and memories discussed herein as well as the claims below may be embodied in and implemented in one or multiple physical chips or circuit combinations. The processor may implement a software program such as code generated manually i.e. programmed .

The computer system may include a memory that can communicate via a bus. The memory may be a main memory a static memory or a dynamic memory. The memory may include but may not be limited to computer readable storage media such as various types of volatile and non volatile storage media including but not limited to random access memory read only memory programmable read only memory electrically programmable read only memory electrically erasable read only memory flash memory magnetic tape or disk optical media and the like. In one case the memory may include a cache or random access memory for the processor. Alternatively or in addition the memory may be separate from the processor such as a cache memory of a processor the system memory or other memory. The memory may be an external storage device or database for storing data. Examples may include a hard drive compact disc CD digital video disc DVD memory card memory stick floppy disc universal serial bus USB memory device or any other device operative to store data. The memory may be operable to store instructions executable by the processor. The functions acts or tasks illustrated in the figures or described herein may be performed by the programmed processor executing the instructions stored in the memory. The functions acts or tasks may be independent of the particular type of instructions set storage media processor or processing strategy and may be performed by software hardware integrated circuits firm ware micro code and the like operating alone or in combination. Likewise processing strategies may include multiprocessing multitasking parallel processing and the like.

The computer system may further include a display such as a liquid crystal display LCD an organic light emitting diode OLED a flat panel display a solid state display a cathode ray tube CRT a projector a printer or other now known or later developed display device for outputting determined information. The display may act as an interface for the user to see the functioning of the processor or specifically as an interface with the software stored in the memory or in the drive unit .

Additionally the computer system may include an input device configured to allow a user to interact with any of the components of system. The input device may be a number pad a keyboard or a cursor control device such as a mouse or a joystick touch screen display remote control or any other device operative to interact with the system.

The computer system may also include a disk or optical drive unit . The disk drive unit may include a computer readable medium in which one or more sets of instructions e.g. software can be embedded. Further the instructions may perform one or more of the methods or logic as described herein. The instructions may reside completely or at least partially within the memory and or within the processor during execution by the computer system. The memory and the processor also may include computer readable media as discussed above.

The present disclosure contemplates a computer readable medium that includes instructions or receives and executes instructions responsive to a propagated signal so that a device connected to a network may communicate voice video audio images or any other data over the network. Further the instructions may be transmitted or received over the network via a communication interface . The communication interface may be a part of the processor or may be a separate component. The communication interface may be created in software or may be a physical connection in hardware. The communication interface may be configured to connect with a network external media the display or any other components in system or combinations thereof. The connection with the network may be a physical connection such as a wired Ethernet connection or may be established wirelessly as discussed below. Likewise the additional connections with other components of the system may be physical connections or may be established wirelessly. In the case of a service provider server the service provider server may communicate with users through the communication interface.

The network may include wired networks wireless networks or combinations thereof. The wireless network may be a cellular telephone network an 802.11 802.16 802.20 or WiMax network. Further the network may be a public network such as the Internet a private network such as an intranet or combinations thereof and may utilize a variety of networking protocols now available or later developed including but not limited to TCP IP based networking protocols.

The computer readable medium may be a single medium or the computer readable medium may be a single medium or multiple media such as a centralized or distributed database and or associated caches and servers that store one or more sets of instructions. The term computer readable medium may also include any medium that may be capable of storing encoding or carrying a set of instructions for execution by a processor or that may cause a computer system to perform any one or more of the methods or operations disclosed herein.

The computer readable medium may include a solid state memory such as a memory card or other package that houses one or more non volatile read only memories. The computer readable medium also may be a random access memory or other volatile re writable memory. Additionally the computer readable medium may include a magneto optical or optical medium such as a disk or tapes or other storage device to capture carrier wave signals such as a signal communicated over a transmission medium. A digital file attachment to an e mail or other self contained information archive or set of archives may be considered a distribution medium that may be a tangible storage medium. Accordingly the disclosure may be considered to include any one or more of a computer readable medium or a distribution medium and other equivalents and successor media in which data or instructions may be stored.

Alternatively or in addition dedicated hardware implementations such as application specific integrated circuits programmable logic arrays and other hardware devices may be constructed to implement one or more of the methods described herein. Applications that may include the apparatus and systems of various embodiments may broadly include a variety of electronic and computer systems. One or more embodiments described herein may implement functions using two or more specific interconnected hardware modules or devices with related control and data signals that may be communicated between and through the modules or as portions of an application specific integrated circuit. Accordingly the present system may encompass software firmware and hardware implementations.

The methods described herein may be implemented by software programs executable by a computer system. Further implementations may include distributed processing component object distributed processing and parallel processing. Alternatively or in addition virtual computer system processing maybe constructed to implement one or more of the methods or functionality as described herein.

Although components and functions are described that may be implemented in particular embodiments with reference to particular standards and protocols the components and functions are not limited to such standards and protocols. For example standards for Internet and other packet switched network transmission e.g. TCP IP UDP IP HTML HTTP represent examples of the state of the art. Such standards are periodically superseded by faster or more efficient equivalents having essentially the same functions. Accordingly replacement standards and protocols having the same or similar functions as those disclosed herein are considered equivalents thereof.

The illustrations described herein are intended to provide a general understanding of the structure of various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus processors and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Additionally the illustrations are merely representational and may not be drawn to scale. Certain proportions within the illustrations may be exaggerated while other proportions may be minimized. Accordingly the disclosure and the figures are to be regarded as illustrative rather than restrictive.

The above disclosed subject matter is to be considered illustrative and not restrictive and the appended claims are intended to cover all such modifications enhancements and other embodiments which fall within the true spirit and scope of the description. Thus to the maximum extent allowed by law the scope is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited by the foregoing detailed description.

