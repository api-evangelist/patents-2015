---

title: Distributed cache for state transfer operations
abstract: A network arrangement that employs a cache having copies distributed among a plurality of different locations. The cache stores state information for a session with any of the server devices so that it is accessible to at least one other server device. Using this arrangement, when a client device switches from a connection with a first server device to a connection with a second server device, the second server device can retrieve state information from the cache corresponding to the session between the client device and the first server device. The second server device can then use the retrieved state information to accept a session with the client device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09479589&OS=09479589&RS=09479589
owner: DELL PRODUCTS L.P.
number: 09479589
owner_city: Round Rock
owner_country: US
publication_date: 20150526
---
The present application is a continuation and claims the priority benefit of U.S. patent application Ser. No. 13 907 213 filed May 31 2013 now U.S. Pat. No. 9 043 476 which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 13 252 170 filed Oct. 3 2011 now U.S. Pat. No. 8 458 340 which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 12 694 198 filed Jan. 26 2010 now U.S. Pat. No. 8 032 642 which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 11 927 350 filed Oct. 29 2007 now U.S. Pat. No. 7 720 975 which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 09 783 147 filed Feb. 13 2001 now U.S. Pat. No. 7 383 329 the disclosures of which are incorporated herein by reference.

This application is related to U.S. patent application Ser. No. 11 927 362 filed Oct. 29 2007 now U.S. Pat. No. 7 870 380 which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 09 783 146 filed Feb. 13 2001 now U.S. Pat. No. 7 360 075 which is a continuation in part and claims the priority benefit of U.S. patent application Ser. No. 09 782 593 filed Feb. 12 2001 all of which are incorporated herein by reference for all purposes.

The present invention relates to a distributed cache system for storing state transfer information. The cached state transfer information relates to the state of sessions between one or more client devices and at least one server device. For example the state information may be credential information that has been exchanged between a client device and a server device to established secure communication between the two devices. According to the invention the state information is cached at distributed locations accessible to a second server device. If the connection between a client device and the first server device is terminated the second server device can then accept a connection from the client device using the cached state information.

Device networks have become ubiquitous in our modern society. Perhaps the most well known of these networks is the Internet which may facilitate communication connections between thousands of individual devices smaller proprietary and public device networks and other devices. Typically networks operate using a client server relationship. With this relationship one device i.e. the client device requests information from a server device that provides the requested information in response. The information may be of any type including for example pages written in the hypertext markup language HTML or other markup language results of a particular calculation or even raw digital data retrieved by the server device from a storage unit.

In order for the client device to request information from the server device and for the server device to provide the information to the client device in reply the client device must establish a connection with the server device. A variety of protocols for these connections are known in the art. Two commonly used protocols for example are the transmission control protocol TCP and the Internet protocol IP . As is known in the art these protocols define the parameters used to exchange sets of data between the server device and the client device during a session. As is also known in the art a session may have a particular state at any given time based upon the history of data exchanged between the client device and the server device.

For example some device networks employ a security arrangement to ensure that unauthorized persons do not intercept or insert data exchanged between a client device and a server device. To establish a secure session the client device may provide the server device with a password or other credential information that will authenticate the client device s identity to the server device. As is known in the art credential information may include one or more of a public or private encryption key a password an authentication key a digital signature a digital certificate a Kerberos ticket or any other information used to encrypt data or authenticate the identity of a party. Also the client and server device may exchange information in order to designate an encryption key for encrypting data to be exchanged between the client and server devices. Both the credential information and the designated encryption key are examples of state information for the session between the client device and the server device as they both reflect a history of information previously exchanged between the two devices.

While the server client device relationship offers many advantages to computer networks one significant problem with this arrangement will now be described with reference to . This figure illustrates a typical computer network configuration . The network includes a number of client devices A B C D . . . a plurality of proxy server devices A B C D . . . and at least one master server device . As will be understood by those of ordinary skill in the art each of these devices can be implemented on a single computer or other computing unit employing a programmable processing device. Typically a computer will have a microprocessor a memory medium and one or more input and output devices. Alternately multiple client and or server devices may be implemented on a single computer or other computing unit or a single client or server device can be distributed among multiple computers or computing units.

As shown in the figure each client device communicates with a proxy server device through a communication medium such as the Internet or a direct dialed telephone connection. For example the client device A communicates with the proxy server device A. Each proxy server device then communicates with the master server device . Thus the proxy server device A can relay messages between the client devices A and the master server device . The network also includes a firewall for limiting access to the proxy server devices A B C D . . . and a load balancer for distributing connections from the client devices A B C D . . . evenly among the proxy server devices A B C D . . . . It should be noted that while illustrates only a single master server device for convenience of understanding the proxy server devices A B C D . . . might normally communicate with a plurality of master server devices simultaneously.

In this example the client devices A B C D . . . communicate with the master server device through the proxy server device A B C D . . . . This arrangement is commonly used where e.g. the proxy server devices A B C D . . . perform a function for the master server device in order to conserve the resources of the master server device . For example if identity of a client device must be authenticated before the master server device can respond to a request for information the proxy servers A B C D . . . may be used to authenticate the client devices A B C D . . . before passing a request for information to the master server . This frees the master server from the responsibility of authenticating the identity of each client device and allows the master server to dedicate its resources e.g. its microprocessor operations to providing requested information.

The proxy server devices A B C D . . . may also be used to provide secure communication between the master server device and the client device . With this arrangement for example the client device and the server device A may designate an encryption key to encrypt messages exchanged between the two devices. Once a secure session is established between the client device A and the server device A the proxy server device A can simply decrypt information from the client device A and relay it to the master server device . The proxy server device A can also encrypt information from the master server device and relay it to the client device A. As will be appreciated by those of ordinary skill in the art this arrangement shifts the overhead of providing secure communication from the master server to the proxy server devices A B C D . . . thereby allowing the master server device to more quickly respond to requests from the client devices.

A problem with this arrangement occurs however if the connection between a client device e.g. the client device A and its associated proxy server device e.g. the proxy server device A is terminated. The client device A may then try to reestablish communication with the master server device through another proxy server device e.g. proxy server device B. For example the first proxy server device A may have failed and be unavailable or the load balancer may simply have routed the new connection from the client device A to the proxy server device B to reduce the communication load on the first proxy server device A. In any case the new proxy server device B will not have the authentication information authenticating the identity of the client device A. Also the new proxy server device B will not have the encryption key established with the previous proxy server device A. Accordingly the state of the session between the client device and the original proxy server device A is lost and the client device must reestablish its authentication information and an encryption key with the new proxy server device B.

This process is time consuming and may require a substantial amount processing time from the new proxy server device B. Moreover depending upon the state of the original session between the client device and the proxy server device A the loss of the previous session s state may be irreplaceable. For example if the state of the earlier session was established by exchanging data that cannot be duplicated then the state of that session cannot be recreated.

To address this problem some network systems attempt to ensure that a terminated connection between a client device and its associated proxy server device is reestablished with that original proxy server device rather than with a new proxy server device . For example some systems design the load balancer to recognize when the client device A has established a session with the proxy server device A and then routing all future connections from client device A to the proxy server device A. This solution has a number of drawbacks however. It requires that the load balancer be very complex and perform a variety of functions. Further it does not address the situation that occurs if the initial proxy server device A becomes unavailable e.g. if it fails and cannot reestablish a connection with the client device . It also does not address the situation where the first proxy server device A becomes overloaded with connections to other client devices . In effect this solution may prevent the load balancer from performing a load balancing function.

Accordingly there is a need for a network arrangement that will allow a client device to switch between a communication connection with a first server device to a second server device while maintaining the state of the session established between the client device and the first server device. Moreover there is a need for a network arrangement that permits such a switch from a connection with a first server to a connection with a second server even if the first server becomes unavailable due to failure or other problems.

Advantageously the invention provides a network arrangement that employs a cache having copies distributed among a plurality of different locations. According to the invention state information for a session with any of the server devices is stored in the cache so that it is accessible to at least one other server device. Using this arrangement when a client device switches from a connection with a first server device to a connection with a second server device the second server device can retrieve state information from the cache corresponding to the session between the client device and the first server device. The second server device can then use the retrieved state information to accept a session with the client device having a similar or identical state. According to some embodiments of the invention identical copies of the cache are stored for each server device in the network arrangement and each server device accesses its own copy of the cache to obtain necessary state information. With other embodiments of the invention a copy of the cache is maintained at a single source e.g. a redundant set of cache storage devices that is accessible to all of the server devices in the network arrangement. Each server device then maintains a copy of only a portion of the entire cache for its local use.

According to various embodiments of the invention server devices in a network store state information reflecting the state of sessions with client devices. In particular each server device stores its state information in a cache so that it is accessible to at least one other server device in the network. Thus if the connection for a session between a client device and a server device is terminated the client device can establish a new session with another server device using the state information for the previous session that was stored in the cache. For example if a first server device and a client device have designated an encryption key for exchanging encrypted messages the first server device can store the encryption key in the cache. If the connection between the client device and the first server device is then terminated and the client device seeks to establish a new connection to a second server device the second server device can retrieve the encryption key from the cache in order to maintain secure communications with the client device. The new proxy server device thus will not need to exchange data with the client server device to determine a new encryption key.

Because the state information in the cache must be accessible to multiple server devices in the network the cache should be stored so that each of the server devices in the network can efficiently retrieve state information from the cache. Further if the copies of the cache or copies of portions of the cache are physically distributed among different locations each server device in the network should be able to efficiently communicate with each copy of the cache i.e. to efficiently update each copy of the cache with new or updated state information or to retrieve stored state information from more than one copy of the cache. Accordingly the storage arrangements and communication techniques employed by various embodiments of the invention will be discussed in detail below.

One network arrangement including a first embodiment of the invention is illustrated in . As with the network described above with reference to the network shown in includes a number of client devices A B C D . . . and a plurality of proxy server devices A B C D . . . each of which is connected to a master server device . Also a connection from each client device is carried through a communication medium to a load balancer which then routes communications from each client device to one of the proxy server devices A B C D . . . for relay to the master server device . As previously noted any of the server and client devices can be implemented on a single computing unit or distributed across multiple computing units. Also multiple client and or server devices may be implemented on a single computing unit.

While only the single master server device is shown in for ease of understanding the network can include a number of master client server devices each communicating with a number of proxy server devices simultaneously. The number of client devices communicating with each proxy server in the network could be for example more than 100. Similarly the network could include a large number e.g. in excess of 100 of server devices A B C D . . . communicating with each master server device . The communication medium may be any suitable medium. For example if the client server device A is configured to communicate with the proxy server A using a Web based communication program e.g. a browser then the communication medium may be the Internet. Alternately if the client server device D is configured to communicate with the proxy server B using a remote dial up communication program then the communication medium may be a direct plain old telephone system POTS connection.

Unlike the network arrangement shown in each of the proxy server devices A B C D . . . in the network includes a cache memory . According to the invention each of the cache memories A B C D . . . contains a copy of a cache . As will be explained in detail below the cache contains a collection of state information based upon the states of various sessions between the multiple client devices A B C D . . . and the multiple proxy server devices A B C D . . . . For example the cache contains state information corresponding to the state of the session between the client device A and the proxy server device A. Thus if the connection between the client device and the proxy server device A is terminated the client device A can establish a new session with any of the other proxy server devices B C D . . . that has the same state as the earlier session between the client device A and the proxy server device A.

In one embodiment of the invention each cache memory A B C D . . . contains a complete copy of the cache . As each proxy server device obtains new state information for a new session with a client device or updated state information for an existing session with a client device the proxy server device sends the new or updated state information to each copy of the cache for storage.

The network embodying the invention provides significant advantages over the conventional network arrangement shown in . Because a client device can establish a session with any of the proxy server devices using the state information obtained during a previous session the load balancer does not need to try to route a connection from a client device back to the proxy server device with which it had previously established a session. Thus the function of the load balancer can be simplified to distributing incoming communications from client devices A B C D . . . evenly among the available proxy servers A B C D . . . . Further even if a proxy server device becomes completely unavailable i.e. it suffers a complete failure the client device can establish a new session with another proxy server device without having to recreate the state information previously obtained in the earlier session.

While the above described embodiment maintains a complete copy of the cache in each cache memory other embodiments of the invention may keep a copy of only a portion of the cache in each cache memory as shown in . With these embodiments however the state information for each session should still be stored in the multiple cache memories A B C D . . . so that each proxy server device can access the state information. For example the state information for the session between the client A and the proxy server device A may be stored in only the cache memory A associated with proxy server device A cache memory B associated with proxy server device B and cache memory C associated with proxy server device C . If the proxy server device A then becomes unavailable and the client device A is switched to a connection with the proxy server device B then the proxy server device B can establish a session with the client device A using the state information retrieved from its own memory cache B.

Moreover even if the client device A is instead switched to a connection with a proxy server device that does not have the state information in its cache memory e.g. proxy server device D then that proxy server device can request the state information from another available proxy server device e.g. proxy server device B that does have the appropriate state information in its cache memory . For example if the connection with the client device A is switched to proxy server device D that proxy server device D can sequentially request the state information from the other available proxy server devices until it receives the state information in reply. Alternately the proxy server device D may issue simultaneous requests to all of the other available proxy server devices and employ e.g. the state information in the first received reply.

The above described embodiments of the invention may be referred to as peer configurations type embodiments as the proxy server devices alone are responsible for maintaining the cache . With these peer configuration embodiments of the invention maintaining copies of the entire cache or copies of overlapping portions of the cache in each cache memory A B C D . . . requires that each proxy server device transmit new or updated state information to multiple cache memories in a write process. Preferably this write process is performed using a reliable communication technique that requires a positive acknowledgement from the receiving device so that each proxy server device can confirm that its associated cache memory has processed the new or updated state information. If the number of proxy server devices in the network is relatively small the type and amount of state information being saved by the proxy server devices is relatively stable and the total amount of state information in the cache is relatively small then writing the necessary state information to each cache memory A B C D . . . with this configuration using a reliable positive acknowledgement based communication technique will not create a large resource overhead for the network .

For example if the type of state information being stored in the cache is simply credential information authenticating the client devices or encryption keys for encrypting communications with the client devices then the number of write operations performed by the proxy server devices A B C D . . . to the cache memories A B C D . . . may be small. Typically a client device will authenticate itself or establish an encryption key only once during a designated time period. Once this state information has been established with a proxy server device and written to two or more of the cache memories A B C D . . . it will probably not be updated for the remainder of the designated time period. Similarly if the network only has nine proxy server devices then writing new or updated state information to each proxy server device does not consume an inordinate amount of the network s resources.

If on the other hand the type of state information stored in the cache must be updated frequently or the network includes a large number of TCP proxy server devices e.g. more than nine proxy server devices then writing each piece of new or updated state information to every proxy server device in the network may divert significant resources from the network . For example if the state information is TCP IP header data for data packets transmitted during a session with the client device the cache must be updated each time the proxy server device A receives a data packet. Also as the number of client devices increases even infrequent updates to multiple cache memories for each client device using a reliable positive acknowledgement communication technique may divert a significant amount of resources from the network . Similarly as the number of proxy server devices increases writing new or updated state information to the cache memory of each proxy server device using a reliable positive acknowledgement communication technique may divert a significant amount of resources from the network . Further if the cache becomes too large it may be difficult to store a complete copy of the cache in the cache memory of a proxy server device .

Accordingly a network implementing yet another embodiment of the invention is shown in . As with the previously discussed network arrangements and the network includes a plurality of client devices A B C D . . . and a plurality of proxy server devices A B C D . . . each of which are connected to the master server device . As also previously described each client device is connected to a load balancer through a communication medium and a firewall . The load balancer routes a connection from each client device to one of the proxy server devices e.g. from client device A to proxy server device A as shown in the figure . Also as with the network shown in each of the proxy server devices A B C D . . . in the network has an associated cache memory A B C D . . . .

This embodiment of the invention additionally includes however a cache repository for storing one or more copies of the cache . As will be understood from the following explanation this embodiment is thus a two tiered configuration for storing the cache rather than a peer configuration as with the previously discussed embodiments of the invention. That is this embodiment has one tier of state information storage provided by the cache memories A B C D . . . of the proxy server devices A B C D . . . and a second tier of state information storage provided by the cache repository .

As seen in the cache repository may include two cache memory server devices and . Each of these cache memory server devices and stores a complete copy of the cache . It should be noted however that the cache repository includes the two cache memory server devices and for redundancy. Thus if one of the cache memory server devices and fails or otherwise becomes unavailable the cache repository will still include a complete copy of the cache in the remaining cache memory server device. Other embodiments of the invention may alternately employ only a single cache memory server device as the repository if redundancy is not desired or three or more cache memory server devices if redundancy is a priority.

The cache memories A B C D . . . in the embodiment of might not store copies of the entire cache . Instead if the cache is larger than can be stored in the cache memories A B C D . . . each cache memory may store only a portion of the cache that relates to its associated proxy server device . For example the portion of the cache copied into cache memory A may only include the state information for sessions established with the proxy server devices A and B. Thus if the client device A loses its connection to the proxy server device A and then tries to establish a new session with the proxy server device B the cache memory B may not contain state information for the earlier session with the proxy server device A.

With this embodiment however when a proxy server receives a request to establish a session with a client device for which it s memory cache does not have state information the proxy server device can obtain the relevant state information from the cache repository . Thus in the foregoing example the proxy server device B will obtain the state information for the client device s A previous session from the cache repository . The new proxy server device can then use the state information to establish a new session with the same or a similar state as the previous session.

In addition to being useful where the size of the cache is too large for an entire copy of the cache to efficiently be stored in the cache memory of a proxy server device this embodiment of the invention employing a cache repository will typically also be more efficient for networks with very large numbers of proxy server devices A B C D . . . e.g. networks with more than ten proxy server devices depending upon whether the type of state information being stored in the cache requires the cache to be updated frequently . With this embodiment each proxy server device will normally need to use a reliable positive acknowledgement communication technique to write new or updated state information to only the cache repository thereby reducing the amount of communication traffic created by write operations and their confirmations across the network. The other proxy server devices in the network can then obtain the new or updated state information through less reliable communication techniques or directly from the cache repository as will be discussed below.

It should be noted however that the two tiered arrangement shown in is exemplary. Those of ordinary skill in the art will appreciate that three tier four tier and other multiple tier arrangements can be employed depending upon the total size of the cache . For example if the size of the cache is too large to be efficiently stored in a single cache memory server device or then two or more cache repositories can be employed each storing a different portion of the cache . An entire copy of the cache may then be stored on a relatively inefficient storage device e.g. a bank of magnetic disk storage devices accessible to each of the cache repositories . Also each proxy server device may then be associated with a particular cache repository and store some or the entire portion of the cache maintained by its associated cache repository . Various other embodiments will be apparent to those of ordinary skill in the art. Accordingly the term multi tiered will be used hereafter to refer to embodiments of the invention having two or more hierarchical levels of devices storing at least a portion of the cache .

It also should be noted that with alternate embodiments of invention the different portions of the cache A B C D . . . stored in cache memories A B C D . . . may overlap. For example the portion of the cache A may contain state information that is also stored in the portion of the cache B and the portion of the cache C. Having some overlap between the different portions of the cache may reduce the amount of network traffic as a proxy server device may already have state information for a new client device seeking connection. Further each of the cache memories A B C D . . . may contain a copy of the entire cache as shown in . This embodiment of the invention may be preferable to the embodiment shown in when e.g. the size of the cache is sufficiently small to be stored in its entirety in a cache memory .

One possible embodiment of a proxy server device will now be described with reference to . As seen in this figure the proxy server device includes a proxy application a distributed cache application programming interface API a distributed cache application a communicator application and the cache memory . As will be discussed in detail below the proxy application performs the primary functions of the proxy server device . For example in the illustrated embodiment the proxy application establishes secure communication with a client device and relays messages between the client device and the master server . The proxy application also sends state information for a session with a client device to the distributed cache application via the distributed cache API .

The distributed cache API retrieves information from the cache memory and facilitates requests to send information to or delete information from the cache memory by passing them along to the distributed cache application . The distributed cache application stores information in the cache memory and also controls the exchange of information between the cache memory other proxy server devices and where applicable the cache repository . The distributed cache application communicates with the other proxy server devices and the cache repository where applicable through the communicator application .

The proxy application may be any application that establishes a session with a client device . In this particular embodiment the proxy application operates to establish a secure session with a client device and relay messages from that secure session to the master server device . For example in some preferred embodiments of the invention the proxy application may employ the Secure Socket Layers SSL protocol to establish a secure session with a client device . The SSL protocol is well known in the art. It should be noted that after undergoing various revisions SSL was renamed the Transport Layer Security TLS protocol and adopted by the Internet Engineering Task Force IETF as reflected in RFC 2246. Therefore it will be appreciated that the term SSL as used hereafter is intended to include both the SSL and TLS protocols.

According to the SSL protocol the client device initiates a session by completing a full SSL handshake with the proxy application . During this handshake the client device and the proxy application exchange SSL version numbers cipher settings session specific data authentication certificates and other information that they need to communicate with each other using the SSL protocol. Using this information both the client device and the proxy application generate the same master secret key which in turn is used to generate individual session keys. These session keys are symmetric keys used to encrypt and decrypt individual groups of information exchanged during the session and to verify the integrity of exchanged information.

As will be appreciated by those of ordinary skill in the art conducting a full SSL handshake to initiate a SSL session is time consuming and presents a heavy load on the network s resources both in terms of network communication traffic and in processing time for the client device and the proxy application . Once the proxy application has received the required SSL session information in a full SSL handshake however the proxy application may subsequently resume that SSL session with the client device using only a partial SSL handshake. Advantageously the partial SSL handshake is much quicker and consumes less network resources than the full SSL handshake.

Accordingly after completing the full SSL handshake the proxy application sends SSL session information obtained from the full SSL handshake to the cache memory for storage. As is known in the art the SSL information can include a session identifier e.g. an arbitrary byte sequence chosen by the proxy application to identify an active or resumable session state and a peer certificate. The SSL information may also include a cipher specification specifying the bulk data encryption algorithm such as null DES etc. the message authentication check MAC algorithm such as MD5 or SHA and the cryptographic attributes such as the hash size used by the client device and the proxy application . Still further the SSL information may include the algorithm used to compress data prior to encryption the master secret key and flag information indicating whether or not the session can be used to initiate new connections.

More particularly the proxy application may form a record for storage in the cache that includes a data field with the SSL resumption information and a key field with the SSL session identifier. The record may also include a time to live field with a time at which the record will expire and should be removed from the cache. In addition the record may include a record identifier pre pended to the key information i.e. the session identifier as will be discussed below. The proxy application passes this record through the distributed cache API to the distributed cache application for storage in the cache memory .

When the proxy application receives a request from a client device to initiate a session the request will include a SSL session identifier if that client device has already established an SSL communication with a proxy application either the same proxy application now receiving the request or another proxy application . The proxy application then passes the SSL session identifier onto the cache API as a search key so that the API may request the distributed cache application to retrieve the SSL information from the cache memory corresponding to the SSL session identifier.

As previously noted the function of the distributed cache API is to retrieve an existing record from the cache memory using a GET operation. Further the some embodiments of the invention the distributed cache API facilitates requests to add delete or modify a record by passing these commands onto the distributed cache application . Thus the distributed cache application may perform ADD DELETE and UPDATE operations on the cache memory . Preferably the ADD operation adds a record to the cache memory based upon the information in the record s key field even if the record for that key already exists in the cache memory . The DELETE operation removes a record from the cache memory while the UPDATE operation updates a record already existing in the cache memory . Also the distributed cache application may have the capability forcing a purge of each of the cache memories A B C D . . . .

It should be noted that the cache API will first attempt to complete a GET operation by obtaining the requested record from the local copy of the cache or the copy of the portion of the cache from the cache memory . With some preferred embodiments of the invention this request will be immediately successful as each cache memory stores a complete copy of the cache . If the requested record is not found in the local cache memory e.g. if the cache memory contains only a portion of the cache that does not have the requested record or a copy of the cache that has been corrupted however then the cache API will involve the distributed cache application to obtain the record from another source. With the peer configured embodiment of the invention shown in the distributed cache application will attempt to retrieve the requested record from one or more of the other proxy server devices . In the multi tier configured embodiment of the invention shown in however the distributed cache application may instead attempt to retrieve the requested record from the cache repository .

Similarly when the distributed cache application adds updates or deletes a record from its local cache it also relays the corresponding add update or delete command to other devices in the network. For example in the peer configured embodiment of the invention shown in the distributed cache application will relay the command to each of the other proxy server devices . In the multi tier configured embodiment of the invention shown in however the distributed cache application may relay the command to the cache repository . The cache repository may then in turn relay the command to one or more of the other proxy server devices . In this manner new or updated state information obtained by the proxy application of one proxy server device is conveyed to the other proxy server devices for use in future sessions with the client device .

The storage of the state information in the cache by the distributed cache application will now be discussed. As will be appreciated by those of ordinary skill in the art as the number of proxy server devices A B C D . . . increases the number of possible sessions between client devices and proxy server devices A B C D . . . also increases. Accordingly the amount of state information stored in the cache will increase as well. This is true for both the peer distributed cache embodiment exemplified in and for the multi tiered distributed cache embodiment exemplified in . Accordingly state information should be stored in the cache so that it can be quickly and efficiently retrieved when necessary. Some preferred embodiments of the invention may therefore use a hash table to implement the cache and employ a hashing function to store and retrieve state information from the hash table.

As is known in the art and discussed above each piece of state information may be stored in the cache as part of a record. To enter a record into a hash table the distributed cache application performs a mathematical algorithm or hash operation on the key data in the key field e.g. the SSL session identifier in order to map the key data to a numerical value. The state information identified by the key data is then stored in the hash table at a location sometimes referred to as a bucket corresponding to the numerical value against which the key data was mapped by the hash operation.

It should be noted that different key values may hash to the same hash value. Thus different records may be stored in the same location in or bucket in the hash value. Accordingly the hash operation preferably is selected so that an even distribution of hash values is obtained for the entire range of possible key data values. This is to ensure that a disproportionate number of records are not stored at a particular location in the hash table. That is it is preferable to employ a hash operation that evenly distributes records in the hash table. Thus when a record must be retrieved the average retrieval time for a record from any location in the hash table should be close to or the same as from any other location in the hash table.

According to some preferred embodiments of the invention the BUZhash hashing algorithm may be employed to evenly distribute state information records in the cache . This hashing algorithm is described in the article Hashing Concepts and the Java Programming Language by Robert Uzgalis 1996 which article is incorporated entirely herein by reference. As explained in the article the BUZhash algorithm conventionally operates as described below using the Sketchy Algorithm Language 

As discussed in the Uzgalis article when applied to a binary key value the BUZhash algorithm is particularly good at both generating a random number from any given key value and distributing the possible range of key values evenly in a table. Those of ordinary skill in the art will appreciate however that other hash algorithms known in the art may also be employed to store the state information in the cache . Also it will be apparent that new hash algorithms may be developed which can be used to store state information in the cache .

It should be noted that the distributed cache application treats all key values opaquely and operates under the assumption that all key values are unique. That is a unique key can only identify a single record in the cache . If a second record is added to the cache with the same key data as an existing record only one of the records will survive. It may be desirable however to use the same key data to refer to different records. For example as previously explained a SSL session identifier may be used as key data to identify a record with SSL resumption information. It may also be desirable to use the SSL session identifier to identify a different record such as a record with authentication information for the user employing the client device e.g. authentication information used to determine the data that the client device s user may access from the master server device .

Accordingly with various embodiments of the invention the cache API may provide for the use of a table identifier to distinguish between two different records that share the same key data. With these various embodiments of the invention the proxy application specifies a table identifier value that is pre pended to the key data as part of all calls through the cache API that involve the specification of key data. This allows the proxy application to in effect specify a virtual table to which the record identified by a particular key should be written to or read from. Of course as will be appreciated by those of ordinary skill in the art because all records of the cache are stored in a single hash table as described above this is only a logical construct.

Preferably the proxy application is the responsible for ensuring that each table identifier value is properly created and consistently applied. The proxy application may prepend the table identifier to the key and then pass the key to the cache API or alternatively to omit a buffer allocation operation and a copy operation the proxy application may pass the table identifier to the cache API and the cache API may prepend the table identifier. Because the cache API treats the table identifier as part of the key data the proxy application should preferably minimize the size of this value is as much as possible. Minimizing the size of the table identifier will allow for both optimal memory usage and optimal hashing performance.

The cache memory may be any type of memory medium. As will be appreciated by those of ordinary skill in the art however the cache memory may be preferably embodied in a readable and rewritable semiconductor memory device commonly referred to as RAM or main memory as this type of memory device allows information to be both quickly stored and retrieved. Currently computers that are conventionally used as server devices may have such memories that can store between 2 gigabytes and 4 gigabytes of information. Thus approximately 2 4 million 1 kilobyte records can be stored in this type of memory device for each proxy server device . Of course other types of memory medium such as a magnetic medium or an optical medium may alternately be employed.

According to some embodiments of the invention the communicator application provides for point to point i.e. acknowledgement based communication such as a unicast or TCP IP like communication between devices in the network. This type of communication is useful for example to synchronize state information between a newly initiated cache memory with an existing cache memory to ensure that all of the state information is accurately copied to the new cache memory before it is used by its corresponding proxy application .

This type of point to point communication e.g. unicast or TCP IP like communication provided by the communicator application can also be used by distributed cache application to update or add individual records in the cache memories of other proxy server devices . As discussed above however with the embodiment of the invention shown in the overhead on the network resources for writing state information to each cache memory increases as the number of proxy server devices increases. This is because each proxy server device must write new or updated state information to each cache memory using a separate write process and then receive an acknowledgement of receipt of the write command from each cache memory in reply requiring a significant amount of network traffic and processor time for each proxy server device in the network . More specifically the number of data packets that must be transmitted for each communication is 2N where N is the number of devices e.g. proxy server devices receiving the communication.

Thus while the messages from the communicator application can be individually delivered to each appropriate recipient device in the network using e.g. point to point messaging this type of communication restricts the speed and efficiency of the invention. Accordingly with some preferred embodiments of the invention the communicator application also provides reliable multicast communication. As is known in the art a communication technique may be considered reliable if a data packets transmitted according to the technique are correctly ordered and duplicates can be discarded by the receiving party b the technique allows the receiving party to detect when data packets are missing from a transmission and c the technique provides a repair mechanism of the receiving party to obtain data packets missing from a transmission. Multicasting as is also well known in the art is a procedure whereby different network devices receive a message sent to a single network address.

Therefore the communicator application may use reliable multicast transmissions to add update or delete state information to or from the appropriate devices in the network. By using reliable multicasting these embodiments of the invention advantageously convey state information to a number of different devices simultaneously simply by transmitting the state information to a single shared multicast address. As previously noted the process of multicasting is well known in the art and several multicasting protocols such as the multicast transfer protocol MTP have been established to facilitate multicast communications.

One type of reliable multicast communication technique is the multicast communication with positive application acknowledgement. With this technique an application receiving the multicast transmission sends an acknowledgement back to the device originating the multicast transmission after the application has successfully processed the transmitted data. This type of reliable multicast communication may preferably be employed by the communicator application when relaying an ADD command from the distributed cache application to add state information to other cache memories in a peer configuration embodiment or to the cache repository in a multi tier configuration embodiment . In the peer configuration embodiment using a reliable positive acknowledgement multicast communication technique reduces the number of data packets that must be transmitted across the network for each communication to 1 N where N is the number of devices e.g. proxy server devices receiving the communication. That is one communication is multicast to each of N devices and N positive acknowledgements are transmitted back to the originating device.

While reliable positive acknowledgement multicasting allows multiple devices to reliably receive updated or new state information simultaneously it may still require significant network resources to implement with the peer configuration. Because each device receiving a multicast message will need to individually acknowledge receipt of the communication to the network device from which the message originated in a network with a large number of proxy server devices i.e. where N becomes large transmitting information to each proxy server device using reliable positive acknowledgement multicasting may still substantially impair the performance of the network.

For various applications of the invention however employing the multi tier configuration embodiments described above can reduce the use of network resources still further. With these embodiments new or updated state information need be transmitted to only the cache repositories using a reliable positive acknowledgement based communication technique. The proxy server devices can then obtain the new or updated state information using a less reliable and thus typically less expensive in terms of network resources communication technique or obtain the new or updated state information from a cache repository when needed. Thus by using the multi tier configuration the number of packets that must be transmitted across the network for each addition of new or updated state information can be reduced still further to 1 n where n is the number of cache repositories receiving the new or updated state information. Because the number n of cache repositories will typically be much smaller than the number N of proxy server devices in the invention using the multi tier configuration can substantially reduce the use of network resource both in network traffic and processing time for individual resources required to cache new or updated state information.

With the multi tier configurations embodiments of the invention the proxy server devices may then receive new or updated state information using for example a negative acknowledgment NACK technique to provide reliable multicast communication instead of the positive acknowledgment technique discussed above. With a negative acknowledgment multicast procedure the devices receiving the multicast message do not send an acknowledgment to the originating device upon receipt of the message. Instead each receiving device responds to the originating device only when it determines that it has missed a portion of the multicast communication.

For example some communication protocols require that each segment of data in a communication be sequentially numbered. Thus with the negative acknowledgement procedure a device receiving a communication according to such a protocol a might respond to the originating device only when it recognized that it had not received one of the data segments i.e. when it determined that it was missing a sequentially numbered data segment . Accordingly the communicator application according to various embodiments of the invention employs this technique to provide negative acknowledgements to another device in the network when it recognizes that it has not received data from that device.

Thus this negative acknowledgement reliable multicast arrangement can be used to deliver new or updated state information to each of the proxy server devices in multi tier configuration embodiments of the invention thereby reducing the amount of communication traffic between the devices. Of course both a positive acknowledgement multicast communication and a negative acknowledgement multicast communication can be accomplished using a single multicast transmission at all of the relevant receiving devices. The device sending the transmission will then wait until receiving positive acknowledgements from all of the devices designated to communicate using the positive acknowledgement technique before sending another multicast transmission. The sending device will then also respond to any negative acknowledgement it receives according to the appropriate negative acknowledgement multicast communication protocol.

Conventional negative acknowledgement reliable multicast communication techniques present an additional problem however sometimes referred to as overrunning. In this situation the transmitting device sends data faster than one or more of the receiving devices can process it resulting in some of the transmitted data being lost. Further the transmitting device may send out too much information to receive a negative acknowledgment from another device indicating that a portion of the communication was lost. The extent of this problem is dependent upon the flow rate of communication traffic across the network however. When there is little communication traffic over the network however then the device initiating the multicast communication will be able to transmit information faster without overrunning a receiving device or missing a negative acknowledgement. Likewise when the communication traffic over the network increases the device initiating the multicast communication should transmit data more slowly to avoid overrunning a receiving device or missing a negative acknowledgement.

To address this problem some prior art negative acknowledgment multicast systems have proposed to set an absolute limit on the rate at which data is transmitted in a multicast communication to ensure that a negative acknowledgment from another device is received under all circumstances. This constant rate solution of the prior art however does not take into varying communication traffic flow across the network. Instead it always operates at the lowest possible efficiency to ensure that all negative acknowledgments are received. Other prior art systems use deterministic techniques with a master and token arrangement but these systems are relatively slow inefficient and complex.

Accordingly with some preferred embodiments of the invention the communicator application may provide negative acknowledgement reliable multicast communication in conjunction with a traffic flow rate detection process for determining the flow of communication traffic across the network. By accurately detecting the flow of communication traffic across the network the communicator application can correspondingly increase or decrease the rate at which it transmits data in the reliable negative acknowledgement multicast communication. This flow rate detection process will now be discussed with reference to .

As shown in these figures the communicator application has a data interface portion . The interface includes an output queue containing data segments to be multicast to other devices in the network. The interface also has an input queue containing data segments that have been received via multicast communications from other devices. According to these preferred embodiments of the invention the communicator application may include itself as a recipient of its own multicast transmission. Thus the communicator application will receive the data segment it transmitted to other devices in the network. By determining when a recently transmitted packet of data is received back at the communicator application the communicator application can determine the level of traffic flow in the network. For example with some preferred embodiments of the invention the communicator application may refrain from outputting another data segment from the output queue until it has received a previously transmitted data segment in its input queue .

As will be appreciated by those of ordinary skill in the art a number of variations for this flow rate detection technique are possible. For example the communicator application may postpone sending a new data segment e.g. Data shown in until the transmitted data segment immediately preceding it e.g. Data is received in the input queue see . Alternately the communicator application may determine an average number of data segments in the input queue that occur between its own transmitted data segments to ascertain the current flow conditions of traffic across the network. Numerous other modifications are also possible using the receipt of self transmitted data segments to determine flow conditions of traffic across the network. Further this technique can be employed even for communications that are not multicast. For example the communicator application may be able to send a copy of a point to point message to itself on a feedback loop. The communicator application can then use the occurrence of a message in the input queue that the communicator application has sent to itself to determine the amount of traffic on the network.

Also as previously explained the same multicast transmissions can be employed to deliver messages using both a positive acknowledgement multicast communication technique and a negative acknowledgement multicast communication technique. It should be noted that when the negative acknowledgement multicast communication technique is used in conjunction with flow detection the flow control feature used with the negative acknowledgement multicast technique will control the operation of the positive acknowledgement multicast technique. That is the sending device will not send out multicast transmissions to any device including those devices communicating with the positive acknowledgement multicast communication technique faster than permitted by the flow control feature.

This flow controlled negative acknowledgment multicast communication technique may therefore preferably be provided by the communication application in multi tier configurations of the invention to distribute new and updated cache information to the proxy server devices without significantly increasing the use of the network s resources both in terms of network traffic and in processing time required by the transmitting and receiving devices. Of course the communicator application may also provide communication techniques with no reliability for various administrative functions of the proxy server .

Thus by using the reliable multicast communication techniques i.e. the positive acknowledgement multicast communication technique and the flow controlled negative acknowledgement multicast communication technique to deliver state information to multiple devices at the same time state information for a session between a proxy server device and a client device can be efficiently cached in a plurality of different cache memories and cache repositories . If a connection between a client device and one proxy server device is terminated another proxy server device can then resume the session with the client device using the cached state information.

The present invention has been described above by way of specific exemplary embodiments and the many features and advantages of the present invention are apparent from the written description. For example while many of the embodiments described above relate to the storage of SSL session information other types of state information can be cached at multiple locations according to the invention. As previously noted the state information may be TCP IP header data for data packets transmitted during a session with the client device . Further the state information may be any type of data segment information for controlling the transmission data segments between the client device and the proxy server device according to any communication protocol.

Also as previously noted the state information may any type of identification and or authentication information. For example the master server device may include information that is accessible to only specified persons. Thus when a user employs a client device to communicate with the master server device through a session with a proxy server device the proxy server device may receive a user name and password to authenticate the user s identity. With this arrangement if the connection for a session between the client device and the proxy server device is terminated the client device can reinitiate the session with another proxy server device according to the embodiments of the invention described above. The user however will still have to resubmit his or her user name and password to repeat the authentication process for the master server . Accordingly alternate embodiments of the invention may store a user s user name and password as state information in the cache at multiple locations according to the invention. As will be appreciated by those of ordinary skill in the art the user s authentication information can be stored in the cache according to the associated SSL session identifier or with any other appropriate key.

Still further various embodiments of the invention may omit the master server device . For example the proxy server devices A B C D . . . may be server devices employed without the master server to maintain a Web site. If the Web site is one from which items are purchased or otherwise obtained the state information may include items designated for purchase from the Web site or other purchase information for a user employing a client device . Thus this information may include a billing address of the user financial transaction information for the user such as a credit card account or electronic cash information delivery information etc. Thus if the connection for a session between a client device and a proxy server device is terminated a user will not have to redesignate the items he or she wishes to receive or resubmit his or her purchase information. Instead the user s client device can reinitiate the session with another proxy server device having access to the state information for the session.

Therefore it is intended that the appended claims cover all such features and advantages of the invention. Further since numerous modifications and changes will readily occur to those skilled in the art the specification is not intended to limit the invention to the exact construction and operation ad illustrated and described. For example the invention may include any one or more elements from the apparatus and methods described herein in any combination or subcombination.

Additionally although the present invention has been described using a particular series of transactions and steps it should be apparent to those skilled in the art that the scope of the present invention is not limited to the described series of transactions and steps. There is inherent flexibility in creating the logic system flow tables and data structures used for programming the present invention. Data structures and values upon which calculations are performed may be explicit derived from other data imported from other sources or result from program calculations or logical operations all without departing from the spirit or limiting the scope of the invention. The algorithms for indexing searching and data processing in this patent may be substituted or modified to support various performance and or systems integration requirements all without deviating from the spirit or limiting the scope of the invention.

Further while the present invention has been described using a particular combination of hardware and software it should be recognized that other combinations of hardware and software are also within the scope of the present invention. The present invention may be implemented only in hardware or only in software or using combinations thereof. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. Accordingly there are any number of alternative combinations for defining the invention which incorporate one or more elements from the specification including the drawings claims and summary of the invention in any combinations or subcombinations. Hence all suitable modifications and equivalents may be considered as falling within the scope of the appended claims.

