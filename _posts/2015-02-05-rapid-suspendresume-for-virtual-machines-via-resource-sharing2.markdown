---

title: Rapid suspend/resume for virtual machines via resource sharing
abstract: Examples quickly suspend and resume virtual desktops on demand or on schedule. Virtual desktops, or desktops as a service, are provided to users, where the virtual desktop is a forked VM, cloned VM, or otherwise at least a partial duplicate of an existing VM. The virtual desktop points to existing memory maintained by the existing VM, and the virtual desktop only writes to memory the pages that the virtual desktop creates or modifies.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619268&OS=09619268&RS=09619268
owner: VMware, Inc.
number: 09619268
owner_city: Palo Alto
owner_country: US
publication_date: 20150205
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 62 041 044 filed Aug. 23 2014 entitled Rapid Suspend Resume for Virtual Machines via Resource Sharing and U.S. Provisional Patent Application Ser. No. 62 041 045 filed Aug. 23 2014 entitled Machine Identity Persistence for Users of Non Persistent Virtual Desktops both of which are incorporated by reference herein in their entireties.

This application is related to U.S. Non Provisional Patent Application entitled Machine Identity Persistence for Users of Non Persistent Virtual Desktops filed concurrently herewith which is incorporated by reference herein in its entirety.

Virtual desktops enable the same infrastructure to serve many users. A stateless virtual desktop infrastructure VDI offers improved density by allowing any user to connect to any virtual machine VM desktop. For example this allows shift workers e.g. task workers to share a common set of VMs thereby reducing the set of VMs that need to be serviced by infrastructure to only what is needed to serve concurrent users rather than all existing users. In certain environments such as hospitals that run 24 hours these gains may reduce the VMs needed to approximately one third of what might otherwise be needed to serve three shifts.

However stateless desktops are less effective for users with more complicated processing needs. For example knowledge workers tend to have long running sessions that must survive across many connect and disconnects. Knowledge workers often open many applications work on multiple documents simultaneously and tend to have applications positioned across the various screens in ways that require some effort to configure at login. Such users prefer to disconnect while the applications are running and resume those applications at a later time e.g. even days or weeks later without ever logging out. However stateless designs do not exhibit nearly the same efficiency for knowledge workers as compared to task workers because many idle VMs accrue as knowledge workers initiate sessions and later disconnect.

Some existing systems suspend all data associated with the VM but for knowledge workers who may have larger memory allocations e.g. 2 GB to 4 GB there is much data to be moved back and forth between random access memory RAM and the storage system. As such the existing systems are very input output I O intensive potentially flooding already saturated storage resources that often struggle to deliver I O in support of a quality VDI user experience. As an example an ESX host from VMware Inc. may host 100 VDI sessions of 4 GB each. If a suspend on disconnect policy is in place and most of the users disconnect near the end of their work day there is 400 GB of data needing to be written from RAM in the hypervisor to the storage system to prepare the ESX host for a new set of incoming users. In a larger cluster of perhaps 8 ESX hosts a traditional shared array might be subject to 400 GB 8 or 3.2 TB of data flowing from the cluster as a result of such a policy. This I O surge of writes takes a long time to complete and poses a substantial risk to experience of any remaining users. The surge may also inhibit the ability of the VDI cluster to properly serve users attempting to initiate new VDI sessions during this window of time.

In addition to massive write storms there is a severe challenge when users with suspended VMs return later to access their VMs. Upon logging in users must wait for their VM to be reanimated. The wait time depends on retrieval of their machine state from the storage system. The transfer of a 2 GB to 4 GB of session data back into RAM takes time as much as several minutes depending on the performance of the storage system at the time of the request. If many users need to retrieve their machines within a narrow time window such as around the beginning of the workday the storage system is subject to large read storms that further amplify the delays users experience and further degrade the I O performance for users attempting to work.

Some existing solutions focus on use of flash technologies to ensure a more reliable and faster resume path than was available using hard drive technology but these approaches do not significantly reduce the quantity of data involved and are thus at the very least inefficient.

The present disclosure permits rapid suspension and resumption of operation of a virtual machine VM . Aspects of the disclosure permit a child VM to share memory and storage with a parent VM. The child VM only tracks and records its own writes to memory creating copy on write COW pages. When a request for suspension of the child VM is received the child VM compresses the COW pages and transfers them to storage. The compressed COW pages are then decompressed in some examples only upon demand after the child VM is resumed.

This summary introduces a selection of concepts that are described in more detail below. This summary is not intended to identify essential features nor to limit in any way the scope of the claimed subject matter.

The present disclosure achieves rapid suspend and resume functionality for virtual desktops while eliminating most of the large input output I O burden associated with traditional VM suspend resume activities. Among other items rapid suspend and resume of virtual desktops increases density in the desktop as a service DaaS arena.

Some aspects of the disclosure describe a suspend and resume path for VMs which leverages resource sharing such as with forking hot cloning and the like. For example VMFork from VMware Inc. allows a parent VM to remain resident in host memory which becomes the template for hot cloning of child VMs which initially share all of its memory pages but which generate their own copy on write COW memory pages as they execute. The disclosure suspends a VM by processing only these COW memory pages to greatly reduce the number of memory pages that need to be processed. Initially in some examples these pages are compressed and held in memory based on a policy period and later evicted to the storage system. These pages may be later copied back to RAM upon user demand or proactively in anticipation of user demand based on previous user activity. The combination handling only COW pages and first compressing them in a staging area may reduce the data volume that goes to disk e.g. as much as 90 in some examples leaving a more manageable quantity of data flowing between RAM and storage. In some examples the staging area is a logical portion of RAM that has been allocated dedicated designated assigned and or formatted to contain compressed memory pages. Size limits may be imposed on the staging area e.g. first in first out aging based policy evictions etc. and or other maintenance operations.

Examples described herein quickly suspend and resume virtual desktops on demand by users. The virtual desktops are clones of permanently existing VMs or forked from existing VMs which the virtual desktops rely upon as a template. The memory utilized by the cloned or forked virtual desktop or child VM is maintained by a parent VM whose template was utilized to create the child VM. The child VM only writes to memory pages that the child VM independently creates or modifies. From the hypervisor perspective there are two classes of pages those maintained by the parent e.g. the child VMs initially include just pointers to parent VM pages and ones generated and maintained by the child VM hereafter referred to as copy on write COW pages.

Some examples of the rapid suspend resume design described herein take advantage of such sharing capabilities to segment or otherwise separate shared from non shared memory pages in a way that allows reduced input output I O transfers when saving state to storage. Some examples also leverage memory page compression capability to proactively stage compressed memory pages in random access memory RAM as a means of providing ultra rapid resume of desktops. After a policy based residency period in the staging mechanism compressed memory pages evict to disk with an estimated 90 reduction in data flows as compared to traditional suspend operations. Based on user activity patterns users who regularly reconnect to their desktops at predictable times may be proactively restaged in RAM for the best user experience. Aspects of the disclosure rapidly evict idle desktops from shared infrastructure resulting in reduced charges per desktop.

Aspects of the disclosure leverage memory page tracking and segmentation to achieve significant data reduction.

Aspects of the disclosure accommodate the needs of knowledge workers while driving better densities for cost conscious virtual desktop infrastructure VDI adopters and for Desktop as a Service DaaS solutions.

Aspects of the disclosure preserve user state while simultaneously pruning the idle VMs to drive better density.

Aspects of the disclosure reduce the amount of data processing on the host increase the speed of the host and other devices reduce an amount of data being transferred from RAM to storage improve the functioning of the host itself reduce the set of VMs that need to stay resident in hypervisor RAM service a greater quantity of named users on the same infrastructure e.g. rotate people on and off the same resources for improved user rotation efficiency reduce power consumption e.g. reduced use of memory reduces power consumption reduce processor load reduce network bandwidth usage improve operating system resource allocation and or increase efficiency.

Some operations described herein are described in the context of forking operations such as those provided by VMFork from VMware Inc. Forking and VMFork in particular differs from linked clones for VM instantiation. Linked clones are a storage construct whereas VMFork is a memory construct and a storage construct. VMFork uses linked clones but also has a COW memory strategy such that all content is initially shared and changes are tracked as COW memory pages for each child VM. For example while some linked VM clones use small delta disks that reference a larger base disk of another VM these systems lack a mechanism for online customization of the instantiated VMs e.g. performed while the VMs are powered on . For example as linked VM clone functionality does not inherently include customization some of the existing systems rely on offline domain join techniques e.g. performed while the VMs are powered off . As another example these systems are unable to configure instantiated VMs with different states. Further many guest operating systems require rebooting or other operations with a high time cost to set identities within the instantiated VMs due to restrictions at the operating system level.

VMFork based desktops entail the ability to know at the hypervisor level which memory pages in the desktop VM are shared and which are unique. The VMFork parent VM initially shares all its memory pages with child VMs. Each memory page changed by the child VM is called a COW memory page. Thus for VMFork based VMs a suspend operation by the hypervisor writes only these COW memory pages to disk rather than the full memory space of the VM. So long as the VMFork parent remains resident in memory on each host a resume operation loads only the COW pages back into memory and re attaches them to the VMFork parent logically. This is a form of logical deduplication. The VM may be powered on by logically merging it with the contents of the replica on the fly presenting what appears to be a standalone disk and memory image for each VM.

VMFork based desktops initially share all of their memory pages but over time as users conduct their desktop activities more COW memory pages will be generated. For shorter running sessions or sessions where only a few applications are used the percentage of memory pages that remains shared with the VMFork parent may remain high e.g. over 90 . The ability to eliminate the shared memory pages represents a significant advance reducing the amount of data handled by a suspend resume operation by for example 75 .

VMFork aware suspend resume attempts to reduce the quantity of data handled by the storage system through the elimination of shared memory pages. Alternatively or in addition a way to both enhance user experience and limit the remaining storage burden is to recognize that many users will reconnect to their VMs within a short period such as 24 hrs. Aspects of the disclosure handle these shorter term idle periods in a way that avoids loading the storage system and also offers a nearly instant re animation of the virtual desktop upon user request. One example is to target the COW memory pages and compress them using memory page compression built into the hypervisor. Compression of memory pages may occur when the host is under memory pressure to avoid swapping activity by the host. However the advanced suspend resume strategy described herein may compress all COW pages and later evict them to disk after a policy based expiration e.g. 16 hours or the typical time between end of workday and the next morning when users are likely to resume their desktop . Resuming a VM whose memory pages are already in RAM is faster. The VM to be resumed is made live almost immediately and its memory pages may be decompressed asynchronously as the user starts to work on it with accessed pages being decompressed on demand. In some cases the VM s memory pages remain in their original locations within the hypervisor for a policy period then they may be compressed but still held in memory and only later sent to disk. A resume operation may in some examples involve resuming the scheduling of the previously suspended or stunned VM but in other cases it may involve retrieval of a limited set of memory data from disk.

This compressed staging pool provides nearly instant reanimation of desktops for users who return within the policy period and greatly reduced data flows for users outside the policy period by compressing the set of COW pages before sending them down to the storage system. In some examples use of low latency flash storage systems may accelerate the remaining and already reduced data flow of suspend and resume operations.

In this context the suspend and resume of the already curtailed set of COW memory pages may be executed rapidly. The staging pool ensures that the COW memory pages are already compressed further reducing the volume of data that must be sent and retrieved from an all flash virtual storage array network vSAN target design or other high speed storage system. As a prophetic example if the VMFork aware strategy reduces the volume of data by 75 compression obtained during the initial residency in the staging pool may further reduce data volume by 60 e.g. based on typical zLib compression leaving only 10 of the original data volume to be sent down to disk and retrieved on demand.

Given that recently written data remains resident in a caching tier of vSAN Virtual SAN by VMware Inc. for some time some example resume operations import this already reduced amount of data from high performance flash devices such as the Memory Channel Storage flash on dual in line memory module DIMM technology that achieves over 1 gigabyte second and latencies under 20 microseconds. For a 4 GB desktop 10 is 400 MB which is retrievable in a brief enough period so as to avoid irritating the user waiting to regain access to their desktop upon authenticating to the VDI broker or otherwise logging in.

Another example includes a policy based proactive retrieval element to reduce delay when granting a virtual desktop to a user. Retrieval from storage back to the staging area or pool may be performed based on any criteria. The criteria may be defined based on heuristics and may be performed proactively e.g. ahead of user re connection points . For example an initial residency period in the stage pool such as 4 hours may be followed by eviction to the storage tier to reduce memory needed to maintain the pool. However for users with a record of logging in regularly a heuristic analysis may provide the average time of day when they reconnect to the system. The compressed pages of the VM may be proactively retrieved from storage and placed back into the staging area to ensure a very rapid resume. The transfer of contents between the staging area and vSAN may be flow controlled to avoid excessive I O storms. If a host supporting 100 users with 4 GB each may reduce the compressed and VMFork aware set of COW pages down to just 10 or 400 megabytes per user the staging pool may accommodate the contents of all 100 users with only 40 GB of RAM or 10 of the total system RAM. Assuming that some users go on vacation or don t use their desktop each day most users may achieve a resume from RAM level of service most of the time from the staging pool using approximately only 70 of the total requirement or roughly 30 GB which is just 7 of host s system RAM.

In some examples the retrieval aspects e.g. from storage back to the staging area in RAM rely on a history log or other maintained history data describing user connect habits disconnect habits re connect habits and or other user behavior cycles. The history data includes for example time stamps for each of these activities. The history data may be maintained as an audit trail from a virtual desktop broker or other server e.g. DaaS management server . The history data may be derived from machine learning algorithms in some examples. Further the retrieval aspects described herein may be implemented in addition to or separate from the resource sharing operations and the compression operations.

While described with reference to VMFork in some examples those skilled in the art will note that any infrastructure operations components and or configuration of hardware software and or firmware implementing the operations or their equivalents or variations described herein are within the scope of the disclosure.

Further the operations described herein are not limited to improving suspend resume of virtual desktops. Rather aspects of the disclosure operate to avoid idle machines consuming resources. For example one or more of the operations are operable in web farms to collapse portions of the web farms during period of less demand and to resume portions of the web farms when demand increases. Suspending and resuming the portions of the web farms are better e.g. faster with less CPU cycles etc. than rebooting those portions of the web farms.

Host computing device may include a user interface device for receiving data from a user and or for presenting data to user . User may interact indirectly with host computing device via another computing device such as vCenter Server from VMware Inc. or other management device. User interface device may include for example a keyboard a pointing device a mouse a stylus a touch sensitive panel e.g. a touch pad or a touch screen a gyroscope an accelerometer a position detector and or an audio input device. In some examples user interface device operates to receive data from user while another device e.g. a presentation device operates to present data to user . In other examples user interface device has a single component such as a touch screen that functions to both output data to user and receive data from user . In such examples user interface device operates as a presentation device for presenting information to user . In such examples user interface device represents any component capable of conveying information to user . For example user interface device may include without limitation a display device e.g. a liquid crystal display LCD organic light emitting diode OLED display or electronic ink display and or an audio output device e.g. a speaker or headphones . In some examples user interface device includes an output adapter such as a video adapter and or an audio adapter. An output adapter is operatively coupled to processor and configured to be operatively coupled to an output device such as a display device or an audio output device.

Host computing device also includes a network communication interface which enables host computing device to communicate with a remote device e.g. another computing device via a communication medium such as a wired or wireless packet network. For example host computing device may transmit and or receive data via network communication interface . User interface device and or network communication interface may be referred to collectively as an input interface and may be configured to receive information from user .

Host computing device further includes a storage interface that enables host computing device to communicate with one or more datastores which store virtual disk images software applications and or any other data suitable for use with the methods described herein. In some examples storage interface couples host computing device to a storage area network SAN e.g. a Fibre Channel network and or to a network attached storage NAS system e.g. via a packet network . The storage interface may be integrated with network communication interface .

The virtualization software layer supports a virtual machine execution space within which multiple virtual machines VMs may be concurrently instantiated and executed. Hypervisor includes a device driver layer and maps physical resources of hardware platform e.g. processor memory network communication interface and or user interface device to virtual resources of each of VMs such that each of VMs has its own virtual hardware platform e.g. a corresponding one of virtual hardware platforms each virtual hardware platform having its own emulated hardware such as a processor a memory a network communication interface a user interface device and other emulated I O devices in VM . Hypervisor may manage e.g. monitor initiate and or terminate execution of VMs according to policies associated with hypervisor such as a policy specifying that VMs are to be automatically restarted upon unexpected termination and or upon initialization of hypervisor . In addition or alternatively hypervisor may manage execution VMs based on requests received from a device other than host computing device . For example hypervisor may receive an execution instruction specifying the initiation of execution of first VM from a management device via network communication interface and execute the execution instruction to initiate execution of first VM .

In some examples memory in first virtual hardware platform includes a virtual disk that is associated with or mapped to one or more virtual disk images stored on a disk e.g. a hard disk or solid state disk of host computing device . The virtual disk image represents a file system e.g. a hierarchy of directories and files used by first VM in a single file or in a plurality of files each of which includes a portion of the file system. In addition or alternatively virtual disk images may be stored on one or more remote computing devices such as in a storage area network SAN configuration. In such examples any quantity of virtual disk images may be stored by the remote computing devices.

Device driver layer includes for example a communication interface driver that interacts with network communication interface to receive and transmit data from for example a local area network LAN connected to host computing device . Communication interface driver also includes a virtual bridge that simulates the broadcasting of data packets in a physical network received from one communication interface e.g. network communication interface to other communication interfaces e.g. the virtual communication interfaces of VMs . Each virtual communication interface for each VM such as network communication interface for first VM may be assigned a unique virtual Media Access Control MAC address that enables virtual bridge to simulate the forwarding of incoming data packets from network communication interface . In an example network communication interface is an Ethernet adapter that is configured in promiscuous mode such that all Ethernet packets that it receives rather than just Ethernet packets addressed to its own physical MAC address are passed to virtual bridge which in turn is able to further forward the Ethernet packets to VMs . This configuration enables an Ethernet packet that has a virtual MAC address as its destination address to properly reach the VM in host computing device with a virtual communication interface that corresponds to such virtual MAC address.

Virtual hardware platform may function as an equivalent of a standard x86 hardware architecture such that any x86 compatible desktop operating system e.g. Microsoft WINDOWS brand operating system LINUX brand operating system SOLARIS brand operating system NETWARE or FREEBSD may be installed as guest operating system OS in order to execute applications for an instantiated VM such as first VM . Aspects of the disclosure are operable with any computer architecture including non x86 compatible processor structures such as those from Acorn RISC reduced instruction set computing Machines ARM and operating systems other than those identified herein as examples.

Virtual hardware platforms may be considered to be part of virtual machine monitors VMM that implement virtual system support to coordinate operations between hypervisor and corresponding VMs . Those with ordinary skill in the art will recognize that the various terms layers and categorizations used to describe the virtualization components may be referred to differently without departing from their functionality or the spirit or scope of the disclosure. For example virtual hardware platforms may also be considered to be separate from VMMs and VMMs may be considered to be separate from hypervisor . One example of hypervisor that may be used in an example of the disclosure is included as a component in VMware s ESX brand software which is commercially available from VMware Inc.

The host computing device may include any computing device or processing unit. For example the computing device may represent a group of processing units or other computing devices such as in a cloud computing configuration. The computing device has at least one processor and a memory area. The processor includes any quantity of processing units and is programmed to execute computer executable instructions for implementing aspects of the disclosure. The instructions may be performed by the processor or by multiple processors executing within the computing device or performed by a processor external to computing device. In some examples the processor is programmed to execute instructions such as those illustrated in the figures.

The memory area includes any quantity of computer readable media associated with or accessible by the computing device. The memory area or portions thereof may be internal to the computing device external to computing device or both.

The memory stores a plurality of VM templates . In some examples VM templates are arranged in a hierarchy such as a tree hierarchy. However aspects of the disclosure are operable with VM templates stored in any structure. In such examples VM templates include a plurality of powered on parent VM templates . The powered on parent VM templates may be created and maintained by the computing fabric cloud service and or by cloud services or by any other computing device . The parent VM templates may be classified categorized or otherwise described as derived VM templates and standalone VM templates. Derived VM templates are derived from one of the parent VM templates and inherit one or more disk blocks e.g. common disk blocks from that corresponding parent VM template . The standalone VM templates lack any such inherited disk block from parent VM templates . Aspects of the disclosure are operable with any form of disk block inheritance such as via a redo log array level snapshots e.g. using block reference counting etc.

In some examples each parent VM template includes a virtual device state for one of VMs and a memory state for that VM . Memory further stores data describing a plurality of powered on child VMs .

In some examples cloud service specifies whether to create a standalone template or a derived VM template e.g. from another parent VM template . Cloud service also creates a defined quantity of registered e.g. to the cloud operating system but powered off child VMs using a function call such as createChildren . The createChildren function call also takes as input a childProperties argument which defines for example the identities e.g. hostname IP MAC address etc. and particular processor and or memory sizes of the child VMs. If the sizes are different from that of parent VM template computing fabric cloud service may either add those resources when powering on child VM e.g. a hot add or create a new parent VM template . In addition the childProperties argument also specifies how the created child VM behaves when powered on and or reset. For example the child VM may act as an ephemeral entity that returns to the same original parent state or a regular VM that goes through a usual boot process.

In the execution phase child VMs are instantiated using a function call such as powerOnChildren . The powerOnChildren function call leverages fast VM instantiation techniques such as those as described herein to quickly spawn VMs with minimal processor overhead. Child VMs may also be powered off or reset using the powerOffChildren function call and a function call such as powerResetChildren .

The computing device further includes storage . In contrast to memory exemplary storage includes one or more disks. Storage stores data describing a plurality of powered off child VMs . Each of the powered off child VMs is instantiated on demand from one of the plurality of parent VM templates . Until then powered off child VMs do not occupy any memory resources. For example powered off child VMs are present in storage and when powered on the child VMs share memory pages with parent VMs and enter into memory and the writes of the child VMs are entered into memory as COW.

Child VMs have one or more properties characteristics or data associated therewith. Exemplary child VM properties include but are not limited to hostname IP address MAC address domain identity processor size and or memory size. In some examples the child VM properties for each child VM e.g. second VM may be referred to as configuration data . Storage further stores parent VM disks and child VM disks e.g. .vmdk files for use by VMs .

After instantiation powered off child VMs are registered e.g. to a cloud operating system or other management logic . The cloud operating system is executed by the computing device . Registration of one of powered off child VMs includes identifying powered off child VM to the cloud operating system and occurs before powered off child VM is powered on or otherwise executed. In this manner powered off child VM is said to be pre registered with the cloud operating system. In some examples the cloud operating system is the hypervisor . By registering powered off child VMs the cloud operating system is no longer in the critical path when cloud services commission VMs thus reducing the amount of time needed for child VMs to become available. However aspects of the disclosure are also operable with registration occurring on the child VM instantiation path.

In some examples configuration data for the child VM is defined created received and or registered prior to receiving a request to fork the child VM e.g. from a management level application . In other examples configuration data is defined in response to receiving the request to fork the child VM . Configuration data may be defined from default values set by an administrator received in the request from the management level application and or populated with data from other sources. Exemplary configuration data for the child VM includes an IP address a MAC address a hostname a domain identity and or any other state data to be applied when customizing the identity of the child VM . In some examples configuration data is stored in a file such as a .vmx file with one file per child VM . Configuration data may be registered with virtualization software such as the cloud operating system.

In some examples the computing device defines a virtual device state of the child VM based on a virtual device state of the parent VM. For example defining the virtual device state of the child VM includes copying virtual device state from the parent VM template . As another example defining the virtual device state of the child VM includes creating a COW delta disk referencing virtual device state of the parent VM. Alternatively the virtual device state of the child VM depends for example on user criteria the system capabilities or the applications the child VM is running.

The computing device in some examples defines creates receives and or registers persistent storage for the child VM based on persistent storage .vmdk of the parent VM template . In some examples persistent storage for the child VM is stored in a file such as a .vmdk file. For example defining the persistent storage for the child VM includes referencing persistent storage of the parent VM. In some examples referencing persistent storage of the parent VM includes creating a read only base disk referencing persistent storage of the parent VM and creating a COW delta disk associated with the child VM to store changes made by the child VM to the base disk.

In some examples computing device defines creates receives and or registers memory for the child VM based on memory state of the parent VM. In some examples referencing memory state of the parent VM includes creating COW memory associated with the child VM to store changes made by the child VM to memory state of the parent VM. In this manner the child VM shares memory state of the parent VM with COW memory pages in contrast with linked clones that use COW delta disks.

The computing device executes e.g. powers on the powered off child VM which becomes powered on child VM . Execution of the powered off child VM includes configuring an identity of child VM using configuration data . In some examples execution of the powered off child VM includes configuration and execution of a boot process or bootup process to access and apply configuration data to the powered on child VM . In this manner the powered on child VM customizes itself during bootup. The now executing child VM has a virtual device state that is a copy of virtual device state of the parent VM with persistent storage referencing persistent storage of the parent VM.

In some examples the bootup process is executed by a guest operating system on the powered on child VM . The bootup process includes for example a command to perform a synchronous remote procedure call RPC to the cloud operating system to obtain and apply configuration data . An example format for the RPC is rpc info get .

The powered on child VM or simply child VM also known as the forked VM may be configured in different ways dependent in part on a type of guest operating system executing on child VM . One example for configuring an identity of child VM is next described.

In some examples of the disclosure the boot process applies customization to the child VM . The boot process includes a blocking agent that prevents the powered off child VM from completing bootup until certain operations have completed. For example the blocking agent is injected into the boot process to prevent the guest operating system on the child VM from accepting user level commands until the identity of the child VM has been configured.

The child VM in some examples accesses configuration data that specifies a domain identity to be applied to the child VM . The domain identity is one of a plurality or pool of previously created domain identities available to the child VM . The plurality of domain identities are created for example by an administrator before the virtual device state of the child VM and the persistent storage of the parent VM e.g. disks are defined.

The domain identity is pre selected e.g. explicitly identified in configuration data in some examples or selected during execution of the bootup process e.g. based on characteristics of executing child VM . The specified domain identity is from the pool of previously created identities. Then the obtained domain identity is applied to the powered on child VM . In some examples applying the obtained domain identity includes performing an offline domain join operation or any method that allows a computer system to join a domain without a reboot.

In operation preparing the powered on parent VM template for forking may be performed for example by a guest agent residing inside a guest operating system of the powered on parent VM template . The guest agent issues a fork command to quiesce the powered on parent VM template into the ready to fork state at an appropriate boot stage. As provisioning operations are initiated the one or more powered off child VMs are forked without a committed identity. As the boot process begins inside each powered on child VM the various identities are applied to each powered on child VM . For example due to the forking process as described herein a copy of the guest agent from the powered on parent VM template appears in each powered on child VM . The copy of the guest agent resumes execution inside each powered on child VM as part of the boot process of the guest operating system. In this post fork stage for each powered on child VM the guest agent obtains e.g. from a data store available to the guest operating system of the powered on child VM and applies one or more identities to the powered on child VM . For example the identities or other parameters are stored as part of configuration data in a .vmx file or other file stored by the cloud operating system and accessible via API from within the guest operating system. In operation the guest operating system synchronously requests and receives one of the identities from the cloud operating system to perform an offline domain join e.g. update the identity in place before proceeding through the tail end of the bootup process e.g. before the system launches the logon service .

The operations discussed above may be embodied as computer executable instructions stored on one or more computer readable media. The instructions when executed by processor configure an identity of a forked VM based on a pool of available domain identities.

The forking and state customization operations illustrated and described may be implemented using templates and an API to configure and deploy the powered off child VM in response to a request from cloud service . In an example computing device creates and maintains a hierarchy of parent VM templates and powered off child VMs which are ready to be executed. Parent VM templates are created in some examples in response to a request from at least one of cloud services . Alternatively or in addition parent VM templates are created on demand by computing device after detecting patterns in VM provisioning requests from cloud services . Maintaining the set of parent VM templates includes for example powering on each of parent VM templates . Each powered off child VM is instantiated from one of parent VM templates in response to a request for the child VM. Maintaining the set of powered off child VMs includes for example pre registering each instantiated powered off child VM to the cloud operating system e.g. before being initiated or otherwise powered on .

Alternatively or in addition one or more of cloud services may create and maintain one or more of parent VM templates .

In the teardown phase parent VM templates and child VMs may be destroyed using function calls such as destroyParentTemplate and destroyChildren . Depending on whether parent VM template is part of the template hierarchy e.g. a derived VM template or a standalone template destroying the template may not remove it completely from disk. The destroyChildren function call turns off child VM e.g. power down and resets the child VM properties such as identity etc.

In automatic mode rather than have parent VM templates be explicitly created via the function calls available in manual mode parent VM templates are automatically generated based on demand. For example cloud service uses a function call such as createChildrenAuto to create child VMs. When a particular type of child VM is requested repeatedly e.g. a plurality of requests are received for the same type of child VM computing fabric cloud service creates a new powered on parent VM template deriving it from the appropriate parent VM template in the hierarchy. This optimization further simplifies the setup and teardown phases by eliminating the need for cloud services to explicitly create destroy and otherwise manage powered on parent VM templates . In some examples the new powered on parent VM template is created only if additional requests are expected for such VMs. For example if the request for a particular VM is a one off request the new parent VM template is not created.

VM instantiation operations are performed on VMs stored in one or more datastores. Exemplary VM instantiation operations include but not limited to cloning copying forking and the like. VM instantiation operations may be performed by virtualization products such as VMware s ESX brand software e.g. in a kernel layer . In some examples VM instantiation operations implement fast suspend resume technology with COW page references e.g. rather than handing over pages entirely . While described in some examples herein with reference to VM forking routines those of ordinary skill in the art will note that the disclosure is not limited to these VM forking routines. Rather the disclosure is operable with any fast VM instantiation routines.

Five types of regions are illustrated on the machine pages . The first type of machine pages illustrated are boot pages illustrated with lines slanting upwards from left to right . Shared application pages shared app pages are illustrated with lines slanting downwards from left to right. Unmapped pages are illustrated by white area on the representation of the parent VM. The unmapped pages are represented in this example only on the powered on parent template VM . In other examples unmapped pages may also be illustrated on the powered on child VM . However since they are unmapped unmapped pages are not illustrated on the machine pages . Other pages created by the VMs are illustrated by crosshatches. Newly mapped pages are illustrated by horizontal lines.

After forking but before creating any new content the powered on child VM has no independent pages but rather relies on the stored pages on the parent VM disk . The computing device tags marks configures or otherwise indicates that persistent storage of the parent VM is COW. Tagging the persistent storage and memory of the powered on parent VM template as COW prevents the parent VM from modifying persistent storage or memory that the powered on child VM is relying upon. Instead if the powered on parent VM template attempts to modify either persistent storage or memory a copy of that data is created for the powered on parent VM leaving the original persistent storage or memory intact.

Once the powered on child VM writes it creates its own copy of a page a copy on write COW version of that page. In the example of the child VM writes to the shared application pages thus creating a COW page the newly mapped page in the figure. Once this new write has occurred the powered on parent VM template still points to the shared application pages but the powered on child VM now points to its newly mapped page . reflects that after the COW pages are created the powered on child VM in this example does not point to the shared application pages of the powered on parent VM template and thus the reference count for the shared application pages drop to 1. The reference counts for the newly mapped pages increase to 1 since the powered on child VM created that new page and now points to it. The reference counts for the boot pages and the other pages remain at since in the example illustrated both the child VM and the powered on parent VM template still point to those pages.

After the powered on child VM has created a newly mapped page the powered on child VM writes that page to the physical machine pages . After that newly mapped page is written there is one reference to it by the powered on child VM . In the example of there are two newly mapped pages created.

The first newly mapped page is a modification of an existing page stored by the powered on parent VM template . In some examples the newly mapped page points back to the shared application pages which it modifies and only the changes made by the powered on child VM to the shared application pages are recorded on the newly mapped pages . In other examples the powered on child VM no longer relies on the powered on parent VM template for the modified shared application pages and instead the powered on child VM only utilizes its newly created page.

The second newly mapped page is original content created by the powered on child VM . That newly mapped page does not indicate that it is a modification of any previously existing page. Instead that newly mapped page is solely tied to the powered on child VM and only the powered on child VM references it in some examples.

In the present disclosure the powered on child VM under the methods disclosed and illustrated by is suspended and executed based on the references to the powered on parent VM template and based on content created which solely relates to the powered on child VM in some examples. In the present example if the powered on child VM illustrated were suspended the pages that it does not share with the powered on parent VM template would be written to storage. For instance in the newly mapped pages are distinct from pages shared with the powered on parent VM template . The newly mapped pages under method would be sent to storage as part of the suspension of the powered on child VM .

The powered on child VM shares pages with its powered on parent VM template . The powered on parent VM template maintains various machine pages on storage . In storage refers to memory and or storage. However in some examples storage may refer only to memory in host computing device and exclude storage units such as disk drives and hard drives. Other definitions of memory are contemplated.

Host computing device may include a user interface device for receiving data from a user and or for presenting data to user . User may interact indirectly with host computing device via another computing device such as vCenter Server from VMware Inc. or other management device. User interface device may include for example a keyboard a pointing device a mouse a stylus a touch sensitive panel e.g. a touch pad or a touch screen a gyroscope an accelerometer a position detector and or an audio input device. In some examples user interface device operates to receive data from user while another device e.g. a presentation device operates to present data to user . In other examples user interface device has a single component such as a touch screen that functions to both output data to user and receive data from user . In such examples user interface device operates as a presentation device for presenting information to user . In such examples user interface device represents any component capable of conveying information to user . For example user interface device may include without limitation a display device e.g. a liquid crystal display LCD organic light emitting diode OLED display or electronic ink display and or an audio output device e.g. a speaker or headphones . In some examples user interface device includes an output adapter such as a video adapter and or an audio adapter. An output adapter is operatively coupled to processor and configured to be operatively coupled to an output device such as a display device or an audio output device.

Host computing device also includes a network communication interface which enables host computing device to communicate with a remote device e.g. another computing device via a communication medium such as a wired or wireless packet network. For example host computing device may transmit and or receive data via network communication interface . User interface device and or network communication interface may be referred to collectively as an input interface and may be configured to receive information from user .

Host computing device further includes a storage interface that enables host computing device to communicate with one or more datastores which store virtual disk images software applications and or any other data suitable for use with the methods described herein. In some examples storage interface couples host computing device to a storage area network SAN e.g. a Fibre Channel network and or to a network attached storage NAS system e.g. via a packet network . The storage interface may be integrated with network communication interface .

In the illustrated example the powered on child VM in accordance with the method illustrated in accesses various machine pages located on the storage . The powered on child VM does not alter the pages it shares with the powered on parent VM template . For instance in the present example the boot pages shared application pages and various other pages are shared with the powered on parent VM template . As the powered on child VM operates in some examples it attempts to alter the machine pages it shares with the powered on parent VM template . When a powered on child VM attempts to write to one of the shared pages instead it creates a new COW page. The COW pages illustrated as newly mapped pages are in some examples initially written to a staging memory area . In the staging memory area the pages may be compressed before writing to the storage . Only pages that the powered on child VM maintains exclusively are written by the child VM to storage in this example. Other pages shared by the powered on child VM and the powered on parent VM template are maintained by the powered on parent VM template .

In some examples the powered on child VM creates an entirely new page when it attempts to alter a page maintained by the powered on parent VM template . In other examples the powered on child VM maintains a log of changes made to a page hosted by the powered on parent VM template . In the second example when the powered on child VM is executed after a period of suspension the altered pages may be recreated upon demand based on the log of changes.

At the powered on child VM compares its memory blocks to the memory blocks of the powered on parent VM template resident on the same host and identifies any memory blocks that the powered on child VM does not share with the powered on parent VM template . The memory blocks which are identified are in some examples COW memory blocks.

Optionally at the identified blocks are compressed. In some examples some of the identified blocks are compressed while some remain uncompressed. In examples where compression occurs selectively identified memory blocks are compressed for example based on system and usage restraints or based on protocols defined by the user .

At the identified memory blocks are transferred to storage . In some examples the identified memory blocks are transferred to storage immediately. In other examples the identified memory blocks are transferred after a period of idle time. The identified memory blocks are also in some examples transferred after a user has logged off on a rotating schedule when shifts change at the request of a user or on any other programmed basis.

In some examples the powered on child VM is replicated to a plurality of host computing devices . This replication permits the suspended powered on child VM to be resumed on any of the host computing devices . This permits users to operate desktops as a service. A user accesses the same powered on child VM on different host computing devices depending on the needs of the user . This results in a virtual desktop experience wherein the user accesses the same powered on child VM from a stored powered off child VM state regardless of the physical location of the user .

If any of the retrieved memory blocks are compressed at the compressed memory blocks are decompressed. In some examples all of the retrieved memory blocks are compressed. In alternative examples none of the retrieved memory blocks is compressed. Alternatively some memory blocks are compressed and the remainder are uncompressed. In other examples the memory blocks are not decompressed until they are utilized by the powered on child VM .

The powered off child VM is then executed becoming the powered on child VM at utilizing memory blocks shared with the powered on parent VM template and the retrieved memory blocks. In some examples the powered on child VM is executed on more than one host computing device .

To prepare the powered off child VM for execution the child VM is configured to leverage the existing memory device and disk state of the powered on parent VM template . To share the disk of the powered on parent VM template the child VM is configured with a redo log pointing to the disk of the powered on parent VM template as the base disk of the child VM e.g. similar to a linked clone VM . In addition the powered on child VM may be configured with its own dedicated storage that is not related to the powered on parent VM template . For example the dedicated storage may include a data disk or access to shared storage if the powered on child VM desires to persist state in storage other than its redo log.

A configuration file e.g. .vmx file associated with the powered off child VM is updated to indicate that the powered off child VM inherits the memory and device state of the powered on parent VM template upon power on. The configuration file may also be updated with additional information such as a desired MAC address and IP address for the powered off child VM to be associated with it upon power on. The configuration file is registered with the cloud operating system e.g. executing on a host and the powered off child VM is ready to be powered on on demand.

In some examples the redo log of the powered off child VM is marked as non persistent. In such examples upon each power on the powered on child VM inherits a fresh copy of the memory device and disk state of the powered on parent VM template e.g. re forks from the quiesced image of the powered on parent VM template . In other examples the redo log of the powered off child VM is marked as persistent.

After preparation the powered off child VM is ready to be powered on e.g. spawned upon receipt of a power on request e.g. from cloud service or from computing fabric cloud service . In response to receipt of such a power on request the now powered on child VM inherits the memory state and device state of parent VM template. As such rather than performing a normal boot process such as through the basic input output system BIOS the powered on child VM instead resumes from the state of powered off child VM . For example the powered on child VM inherits a COW reference to the memory state of parent VM template such as shown in . Referencing COW memory on the same host eliminates overhead for unmapped pages and results in a small overhead for mapped pages e.g. less than one microsecond for four kilobyte pages thus providing fast powered on child VM instantiation. also illustrates the reference counts for each of the example pages shown in the figure before and after forking when writing a page and when creating a new page.

Further by referencing COW memory the powered on child VM is able to begin execution in a fraction of a second from the precise instruction e.g. fork guest RPC at which powered on parent VM template was quiesced. From the perspective of the powered on child VM the powered on child VM sees the fork guest RPC returning successfully from hypervisor . The powered on child VM may then be migrated away from the powered on parent VM template without need for one to many migrations e.g. one to many vMotion operations .

Computing fabric cloud service handles return of the fork guest RPC by customizing the child VM. Customizing the child VM includes for example reading and applying a desired configuration state from the configuration file specified when preparing the child VM. As described herein some examples customize the child VM by identifying and applying a MAC address IP address hostname and other state to the child VM. Leveraging the customization data the child VM may then spoof its MAC address to the desired MAC address update its hostname IP address etc. and bring up its network interface. The child VM then continues execution as a unique VM e.g. separate from parent VM with its own identity

Aspects of the disclosure contemplate a policy based driver mechanism to replicate and instantiate the parent VM on each of the hypervisors in the cluster. VMs are provisioned using a forking based strategy that involves maintaining a parent VM in memory on each host in the cluster and every cluster on the hybrid cloud where VMs may be migrated. The parent VM image is specific to each OS type so for example if a cluster is used for Linux Windows 7 and Windows 2008R2 three generic parent VM images need to be available on each host in some examples. This memory overhead is taken into account for planning purposes so the sum of memory allocations for each parent VM is deducted from projections for the memory available to working VMs. Because live migration of child VMs e.g. using vMotion from VMware Inc. presumes logical attachment of unique memory pages to an identical parent VM image on the target host the parent VM is replicated from the original host on which it was prepared and transferred onto all target hosts. Creating separate parent VMs on each host does not work in some examples because each host s parent VM is slightly different and not able to logically bind their shared pages to children from other hosts. Instead aspects of the disclosure boot up a parent VM on one host e.g. a seed host get the parent VM to a state for forking and copy the parent VM image to each hypervisor of the other hosts in the cluster or target hosts in the remote clusters containing target hosts to create replicas on those hosts. The suspended child VM may then be resumed on any host in the cluster because all parent VMs on the cluster are identical. Likewise child VMs may be migrated to any target host with an identical parent VM resident in memory. Aspects of the disclosure contemplate a policy based driver mechanism to replicate and instantiate the parent VM on each of the hypervisors in the cluster or to clusters of hosts or hosts at remote datacenters.

Aspects of the disclosure contemplate various cleanup and or maintenance operations. For example if a parent VM closes e.g. the host reboots aspects of the disclosure eliminate or otherwise flag suspended child VMs associated with that parent VM because those child VMs may no longer resume.

If a cluster shuts down or restarts aspects of the disclosure contemplate a mass resume operation by resuming the parent VM on each host e.g. by transferring over the network via vMotion or replication or resuming from disk if from a local cluster and then resuming the child VMs.

Examples herein instantly fork and configure live child VMs from a powered on parent VM with underlying memory and disk resource sharing. In some examples a script is executed to customize a state of each new forked VM to produce a child VM with a different state than the parent VM. For example based on a virtual device state of a suspended parent VM e.g. a first VM a virtual device state of the child VM e.g. a second VM is defined. Persistent storage of the child VM is also defined based on persistent storage of the parent VM.

Examples further configure a state of each newly instantiated child VM based on configuration data for the child VM including configuring one or more identities on the fork path. The identities are configured without involving a reboot of the child VM despite any guest operating system level restrictions requiring reboot operations when configuring identities. Rebooting the child VM prevents the memory page sharing achieved by the forking operations described herein at least because the memory page sharing would be lost with the reboot. In this manner aspects of the disclosure are operable to instantly provision child VMs. Further eliminating reboot operations reduces overall provisioning time which reduces overall cost of ownership for users. The level of boot storm is also significantly reduced when customizing large quantities of child VMs thus reducing input output commands per second IOPS at the storage array level. Reducing IOPS reduces storage cost for users.

An exemplary identity set includes but is not limited to one or more of the following items computer name domain machine account with domain join license client machine identifier with key management service KMS volume license activation media access control MAC address and or Internet Protocol IP address. For example a domain identity is selected at fork time from a pool of previously created domain identities. The selected domain identity is applied to the child VM in a way that does not confuse existing processes in the child VM. For example some examples prevent boot completion of the child VM until customization has finished.

In some examples the forking and identity configuration operations are implemented as part of a shared computing fabric cloud service that efficiently supports fast elastic and automatic provisioning of VMs for multiple cloud services e.g. tenants of the computing fabric cloud service . Some examples of computing fabric cloud service present an application programming interface API that may be leveraged by many of cloud services to quickly scale in and scale out of VMs such as VMs based on demand. In operation cloud services request resources and properties of the resources and computing fabric cloud service makes the resources available immediately instantaneously or otherwise faster than existing systems.

Aspects of the disclosure include a shared infrastructure e.g. computing fabric cloud service accessible via an API that enables quick provisioning of VMs by managing a hierarchy of powered on templates and employing fast VM instantiation operations to quickly spawn VMs with desired properties. Some examples store parent VM templates in a tree hierarchy with each parent VM template representing a linked clone of its parent with its memory shared via copy on write COW . In some of those examples a set of child VMs pre registered to a cloud operating system is internally maintained for each template. The child VMs are created as a linked clone of the corresponding parent VM template . When one of cloud services commissions or otherwise requests provisioning of one or more VMs aspects of the disclosure create a COW share of parent VM template memory to give to requesting cloud service .

In this manner and as described further herein the computing fabric cloud service supports the instantaneous provisioning of VMs on demand allows for memory and disk content sharing across cloud services using parent VM templates common to cloud services and improves cloud service performance by eliminating use of hot spare VMs .

Examples are operable with any cloud service such as those managing very large datasets e.g. big data those supporting virtual desktops and those providing a cloud computing platform as a service or other cloud service provider e.g. CLOUD FOUNDRY brand computer services . In part by creating and managing parent VM templates as described herein and performing the forking routines aspects of the disclosure are able to instantly provision e.g. under a second these and other cloud services with fully functional VMs with low e.g. minimal processor overhead.

Aspects of the disclosure are operable with any type kind form or model of guest operating system to be executed by the parent VM and child VMs. For child VMs with guest operating systems such as the WINDOWS brand operating system that require a reboot to apply identity settings some examples operate to apply a set of identities without requiring a reboot. An example set of identities includes computer name domain machine account with domain join license client machine identification with a key management service KMS volume license activation MAC address and IP address. To eliminate the reboot these examples contemplate execution of two components within a guest agent residing inside the parent VM. One component is a native application while the other component is a service e.g. a post fork identity service . The native application is executed at the beginning of session manager initialization which occurs after a boot loader phase and a kernel initialization phase of the bootup process. The post fork identity service is a system service launched by a service control manager and configured such that other services e.g. a Netlogon service a software protection platform service and a TCP IP protocol driver service are dependent on this service as further described below.

The native application executes as the parent VM is powered on and boots up to issue the fork command. The fork command quiesces the parent VM into a ready to fork state. By setting the forking point of the parent VM at the beginning of session manager initialization the computer name may be set before subsystems and any system services of the guest operating system refer to the computer name. By preventing the subsystems and system services from referring to the computer name conflicts are avoided thus eliminating any potential reboot threat. Then as each child VM is forked during the fork process the native application continues its execution inside the guest operating system of each child VM.

As the native application resumes execution inside each child VM the set of identities is applied to each child VM. In an example involving one child VM the native application applies the computer name change to directly set the new name to a full list of registry entries or other configuration entries.

In another example a domain machine account with domain join is achieved in two phases. The first phase may be performed by any application e.g. external to the child VM before each child VM is forked. The first phase includes pre creating a machine account for each forked child VM against a directory service of the target domain. The application passes the machine password of the pre created machine account to each child VM as an identity value. The second phase occurs after forking the child VM e.g. during a post fork stage and is executed by a post fork identity service associated with a guest agent inside the guest operating system of each child VM. The post fork identity service retrieves the pre specified machine password and directly inserts it into the machine private data store. After this the machine password stored inside the guest operating system of each child VM now matches the corresponding computer account password stored in the directory service of the target domain thus completing the domain join.

Aspects of the disclosure configure authentication services e.g. Netlogon in the child VM to not start until after the domain join has been completed to prevent attempts to authenticate the guest computer and or users against the target domain. In this way the authentication services depend on the post fork identity service.

A license client machine identifier with KMS volume license activation in some examples is also obtained by the post fork identity service. First the cached content files that store the existing license activation status and the client machine identifier copied from the parent VM are removed. After the post fork identity service completes its startup a KMS volume license activation command is issued to activate the volume license and generate a new license client machine identifier.

Aspects of the disclosure configure software validation activation services e.g. Software Protection Platform in the child VM to not start until after the license client machine identifier has been generated to prevent attempts to validate software associated with the child VM. In this way the software validation activation services depend on the post fork identity service.

The MAC address setting is also performed by the post fork identity service. To set a new MAC address for a network adapter associated with the child VM the post fork identity service directly sets the MAC address through its network address property and then disables and re enables the network adapter. Aspects of the disclosure configure communication services e.g. a TCP IP service in the child VM to not start until after the new MAC address has been set to prevent potential conflicts e.g. a TCP IP conflict . In this way the communication services depend on the post fork identity service.

The IP address setting depends on whether the configuration uses dynamic host configuration protocol DHCP or a static IP. For DHCP configuration the forking point is placed before the DHCP client service is launched so no additional work is performed by the guest agent during the post fork stage to configure the IP address. Once each child VM is forked the DHCP client service starts and obtains an IP address from the DHCP server automatically.

In a static IP configuration the post fork identity service sets the IP address of a network adapter and then disables and re enables the network adapter. Aspects of the disclosure configure communication services e.g. a TCP IP service in the child VM to not start until after the new IP address has been set to prevent potential conflicts e.g. a TCP IP conflict . In this way the communication services depend on the post fork identity service.

The operations described herein may be performed by a computer or computing device. The computing devices communicate with each other through an exchange of messages and or stored data. Communication may occur using any protocol or mechanism over any wired or wireless connection. A computing device may transmit a message as a broadcast message e.g. to an entire network and or data bus a multicast message e.g. addressed to a plurality of other computing devices and or as a plurality of unicast messages each of which is addressed to an individual computing device. Further in some examples messages are transmitted using a network protocol that does not guarantee delivery such as User Datagram Protocol UDP . Accordingly when transmitting a message a computing device may transmit multiple copies of the message enabling the computing device to reduce the risk of non delivery.

By way of example and not limitation computer readable media comprise computer storage media and communication media. Computer storage media include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media are tangible non transitory and are mutually exclusive to communication media. In some examples computer storage media are implemented in hardware. Exemplary computer storage media include hard disks flash memory drives digital versatile discs DVDs compact discs CDs floppy disks tape cassettes and other solid state memory. In contrast communication media typically embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media.

Although described in connection with an exemplary computing system environment examples of the disclosure are operative with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with aspects of the disclosure include but are not limited to mobile computing devices personal computers server computers hand held or laptop devices multiprocessor systems gaming consoles microprocessor based systems set top boxes programmable consumer electronics mobile telephones network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

Examples of the disclosure may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. The computer executable instructions may be organized into one or more computer executable components or modules. Generally program modules include but are not limited to routines programs objects components and data structures that perform particular tasks or implement particular abstract data types. Aspects of the disclosure may be implemented with any number and organization of such components or modules. For example aspects of the disclosure are not limited to the specific computer executable instructions or the specific components or modules illustrated in the figures and described herein. Other examples of the disclosure may include different computer executable instructions or components having more or less functionality than illustrated and described herein.

Aspects of the disclosure transform a general purpose computer into a special purpose computing device when programmed to execute the instructions described herein.

The examples illustrated and described herein as well as examples not specifically described herein but within the scope of aspects of the disclosure constitute exemplary means for rapidly suspending a VM. For example the elements illustrated in the figures such as when encoded to perform the operations illustrated in the figures constitute exemplary means for receiving a request to suspend a VM executing on a host the VM having a plurality of memory blocks at least a portion of which are shared with another VM wherein the another VM is resident in the host exemplary means for identifying memory blocks from the plurality of memory blocks that are not shared with the another VM and exemplary means for transferring only the identified memory blocks to storage responsive to receiving the request.

At least a portion of the functionality of the various elements illustrated in the figures may be performed by other elements in the figures or an entity e.g. processor web service server application program computing device etc. not shown in the figures.

In some examples the operations illustrated in the figures may be implemented as software instructions encoded on a computer readable medium in hardware programmed or designed to perform the operations or both. For example aspects of the disclosure may be implemented as a system on a chip or other circuitry including a plurality of interconnected electrically conductive elements.

The order of execution or performance of the operations in examples of the disclosure illustrated and described herein is not essential unless otherwise specified. That is the operations may be performed in any order unless otherwise specified and examples of the disclosure may include additional or fewer operations than those disclosed herein. For example it is contemplated that executing or performing a particular operation before contemporaneously with or after another operation is within the scope of aspects of the disclosure.

When introducing elements of aspects of the disclosure or the examples thereof the articles a an the and said are intended to mean that there are one or more of the elements. The terms comprising including and having are intended to be inclusive and mean that there may be additional elements other than the listed elements. The term exemplary is intended to mean an example of. 

Having described aspects of the disclosure in detail it will be apparent that modifications and variations are possible without departing from the scope of aspects of the disclosure as defined in the appended claims. As various changes could be made in the above constructions products and methods without departing from the scope of aspects of the disclosure it is intended that all matter contained in the above description and shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense.

