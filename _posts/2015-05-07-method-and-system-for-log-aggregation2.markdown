---

title: Method and system for log aggregation
abstract: Systems and methods for aggregating one or more log records are provided. An example method includes receiving an indication that a request has been completed. The method also includes aggregating, at the log aggregator, log records that were created based on processing the request. The log records include a unique identifier associated with the request. The method further includes sending the aggregated log records to the log client.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633204&OS=09633204&RS=09633204
owner: PAYPAL, INC.
number: 09633204
owner_city: San Jose
owner_country: US
publication_date: 20150507
---
The present application is related to the following co pending applications each filed on even date herewith 1 U.S. application Ser. No. 14 706 542 filed on May 7 2015 entitled Method and System for Providing a Framework as a Service and naming Akara SUCHARITAKUL as the sole inventor and 2 U.S. application Ser. No. 14 706 786 filed on May 7 2015 entitled Method and System for Providing a Pipeline Infrastructure and naming Akara SUCHARITAKUL as the sole inventor. Each of the aforementioned co pending applications is incorporated by reference herein.

The present disclosure generally relates to computing systems and more particularly to providing log aggregation.

Companies invest heavily in protecting their electronic assets. A system breach may result in lost profits and a decline in consumer confidence in a company. A large portion of business is done through networked computers. Nowadays applications may be written to run on different platforms stacks and programming environments. It is oftentimes a daunting task to defend these applications against intrusion. Additionally even if a solution were found it may be difficult to rollout crucial fixes to the applications in a short amount of time. Each fix may be a huge engineering effort associated with high costs and a lot of manpower.

Embodiments of the present disclosure and their advantages are best understood by referring to the detailed description that follows. It should be appreciated that like reference numerals are used to identify like elements illustrated in one or more of the figures wherein showings therein are for purposes of illustrating embodiments of the present disclosure and not for purposes of limiting the same.

III. Process Flow of an Application Receiving a Decorated Request and Retrieving Information Responsive to the Request

An application framework may generally refer to a software architecture that allows applications to plug their business logic in. Components of an application framework usually run in the same process and are typically tightly integrated within the application. It may be desirable to provide a framework as a service.

The present disclosure provides a system and method for providing a framework as a service. is a flowchart illustrating an embodiment of a method for providing a framework as a service. Method is not meant to be limiting and may be used in other applications other than the applications discussed below. Method includes blocks . In a block an action on a first request is performed at an incoming pipeline handler in a first process. A framework may be provided as a service to different applications. The framework may include pipeline handlers and cubes. For example a computer system may include pipeline handlers and cubes and also run one or more applications. An application may run on the computer system in a first process and the pipeline handlers and cubes may run in a second process that is separate from the first process. Accordingly another application running in a third process in the computer system may plug into the framework and use the services of the pipeline handlers and cubes. The pipeline handler may decorate a request to an application with information that is used by the application. The pipeline handler may decorate a request by adding information to the request and passing it along to the next component which may be another pipeline handler in the pipeline or the application.

In a block the first request is sent to the application running in a second process. In a block a second request from an application is received at a cube in the first process the second request being based on the first request. The incoming pipeline handler and application may reside in the same computer system. The cube may respond to requests from the application as will be further discussed below.

It should be understood that additional processes may be performed before during or after blocks discussed above. It is also understood that one or more of the blocks of method described herein may be omitted combined or performed in a different sequence as desired

One or more incoming pipeline handlers may perform actions on request before it reaches the application. In an example incoming pipeline handlers may decorate request thus generating a decorated request that is passed along to application for processing. A request may be decorated by adding information to the request. An incoming pipeline handler may also keep track of how the request has been decorated. Outgoing pipeline may include outgoing pipeline handlers that intercept and act on responses from application . Application may process decorated request and provide a response responsive to the request. One or more outgoing pipeline handlers may perform actions on response before it is sent to client .

An incoming and or outgoing pipeline may be associated with and provided as part of a cube which may provide multiple services and functions. An infrastructure may refer to a hardware or software component that is not part of the application logic or application code but may provide services e.g. load balancer or firewall . The pipeline infrastructure is the machinery that executes the pipeline handlers and the pipelines may reference the cubes. Application may call into a cube by invoking an application programming interface API call to request the cube s services. Cubes respond to requests from application and may be a service delivery architecture. A cube may obtain information from pipeline handlers in incoming pipeline and or outgoing pipeline and or via a service call to a computer system outside of computer system . The cube may make the outside service call if computer system does not store all the information for responding to a request from application .

Application is associated with an API shim that may be implemented for every language in which application is written. In an example if application is written in Python API shim is a Python API shim. Using API shim it may be unnecessary to update application and the infrastructure for it because the infrastructure has been generalized with the use of pipeline handlers and cubes.

API shim may be a small library that sits with application inside the same address space. API shim may communicate with cubes by making calls through hypertext transfer protocol HTTP or by sending messages through a messaging queue to cubes . In particular API shim may communicate with a service inside a cube similarly to a regular service call except that API shim and the cube both reside in computer system .

Application may want to talk to other services and databases outside of computer system . As will be explained further below application may communicate with a client proxy to communicate with other information sources.

Application and each of the pipeline handlers and cubes are executable on computer system and may reside in the same computer system. Each of the pipeline handlers and cubes may be software modules executable on one or more hardware processors included in computer system . In some examples incoming pipeline outgoing pipeline and cubes are referred to as a framework that may be provided as a service to one or more applications. In particular incoming pipeline outgoing pipeline and cubes may be implemented as a framework as a service. The framework as a service may be coupled to one or more applications.

The framework as a service may be in a different process than the applications that communicate with the framework as a service. In particular application may run in a different process than the incoming and outgoing pipeline handlers and cubes. In other words the components in the framework may be separate from application . In an example application may run in a first process that is separate from a second process in which incoming pipeline outgoing pipeline and cubes run. Additionally the application may run in the same or different virtual machine as incoming pipeline outgoing pipeline and cubes .

When a cube is installed in the framework as a service the application may look inside the cube and identify services provided by the cube. In an example request includes a unique identifier e.g. globally unique identifier GUID and application invokes one or more APIs exposed by cube for information based on the identifier. If cubes are implemented for a framework as a service the cubes may be configured to listen for an incoming request and an outgoing response in order to function properly.

In some examples an incoming pipeline handler and its associated outgoing pipeline handler and cube may be added to the infrastructure. As such pipeline handlers and cubes may be plugged into the infrastructure and provided as a service to one or more applications. For example incoming pipeline handlers and outgoing pipeline handlers may be added to incoming pipeline and outgoing pipeline respectively. Similarly one or more cubes may be added to cubes and communicate with application via API shim . An advantage of plugging pipeline handlers and cubes into the infrastructure may provide flexibility because new pipeline handlers and cubes may be independently incorporated into the infrastructure. This may be particularly advantageous if pipeline handlers and their associated cubes if applicable are supplied by different teams of developers.

If the environment in which computer system is in or interacts with has been compromised a security development team may provide security pipeline handlers and a security cube and add them to the infrastructure. For example if request is received incoming pipeline may include an incoming security handler that decorates the request with security information. In an example the security information asks whether this particular request is permitted to access application . If the request is permitted the incoming security handler may pass the request along in the pipeline or to application . If the request is not permitted the incoming security handler may drop the request and send an error message to the sender of the request. In another example the security cube may have one or more APIs and the security pipeline handler may make an API call into the security cube to ensure that particular actions are allowed. Accordingly rather than implement one fix for all the application stacks the security pipeline hander and cube may be used to secure the environment in which multiple applications operate because the framework as a service sits in a different process than the applications. Additionally the fix provided by the security pipeline hander and cube may be applied in a shorter amount of time compared to providing a fix for all the application stacks. Moreover if another security issue arises the security cube may be updated with a new version of the security pipeline handler.

III. Process Flow of an Application Receiving a Decorated Request and Retrieving Information Responsive to the Request

Incoming logging handler is associated with outgoing logging handler . Incoming personalization handler is associated with personalization cube and outgoing personalization handler . Incoming tracking handler is associated with tracking cube and outgoing tracking handler . Incoming experimentation handler is associated with experimentation cube and outgoing experimentation handler

It should be understood that the order of pipeline handlers in a pipeline may be modified if the pipeline handlers have no dependencies. If two pipeline handlers have no dependencies the order in which a request or response is processed with respect to the two pipeline handlers may be modified. In an example based on dependencies incoming tracking handler should be before the incoming experimentation handler in incoming pipeline . Accordingly it is undesirable to modify their order. In another example a security pipeline handler does not have dependencies. Accordingly the security pipeline handler may be placed anywhere in the pipeline.

A pipeline handler may be supplied as part of its associated cube. Cubes may respond to requests from application . Services within a cube may be unable to determine the boundaries of a request to or response from application . The pipeline handlers inside incoming pipeline or outgoing pipeline may understand those boundaries and ensure that the request and or response is processed accordingly.

In incoming logging handler may be added to the infrastructure to intercept requests to application before they are received by the application and may log each of those requests. Logging handler may decorate the request with logging information. Logging information may include for example the date and time the request was received and an identifier that identifies the recipient of the request. In an example request may be given a unique identifier e.g. globally unique identifier GUID that is included in the request. In such an example incoming logging handler may identify the unique identifier in the request and log the unique identifier along with other information. Incoming logging handler may be separate from and run in a different process than application . As such it may be unnecessary for incoming logging handler to be integrated into application .

Request may traverse each of the pipeline handlers included in incoming pipeline before being sent to application . If another pipeline handler is included in incoming pipeline after incoming logging handler request may be passed along to this next pipeline handler otherwise incoming logging handler may pass request to application .

In incoming logging handler may pass request to incoming personalization handler which may decorate request by adding personal information to the request. Incoming personalization handler may be separate from and run in a different process than application . As such it may be unnecessary for incoming personalization handler to be integrated into application .

In an example client see is a Web browser and incoming personalization handler identifies a user associated with client likely to have sent request . The user may have used the same Web browser to access application multiple times. For example incoming personalization handler may associate the user with a cookie which is a small file containing a string of characters sent to the Web browser. Incoming personalization handler may determine that request was sent from that particular user and also determine the user s personal information based on the received cookie. In an example the user is Jane Doe and her area of interest is fashion.

Incoming personalization handler may decorate request with the personal information e.g. name of the user is Jane Doe and fashion as her area of interest to generate at least a portion of decorated request . If another pipeline handler is included in incoming pipeline after incoming personalization handler request may be passed along to this next pipeline handler otherwise incoming personalization handler may pass decorated request to application .

Application may receive decorated request from incoming pipeline and identify the personal information in the request. In an example application is a homepage application that identifies elements based on the personal information in decorated request and renders the elements into the homepage. The homepage including the elements will be displayed to the user. For example in response to discovering that Jane Doe s area of interest is fashion application may include the latest fashion trends in the homepage e.g. most popular shoes and purses of Y2014 .

An incoming pipeline handler may decide how much to decorate a request. If the incoming pipeline handler provides too much information in the request then too much information may be passed to application and decorated request may be too big. Information not included in the request but wanted from application may be requested from the cube associated with the pipeline handler. If application does not have enough information e.g. Jane Doe s area of interest age etc. based on the personal information in decorated request to render the homepage application may send a request to personalization cube for more information about Jane Doe. Request may be a request for Jane Doe s area of interest age range gender and location.

In some examples application uses API shim to call into personalization cube to request information about Jane Doe. In an example request is associated with a username and password and application provides this information in request to personalization cube so that it can obtain personal information for the correct person. API shim may send request via an HTTP call or a messaging queue to personalization cube to request information from personalization cube about Jane Doe. In an example personalization cube may communicate with one or more personalization services to request information about the user. Personalization service may be any information source e.g. within the enterprise or outside of the enterprise and may return a response including at least some of the requested information.

Responsive to request personalization cube may send response including the requested information to application . Application receives response which may include personal information about Jane Doe. In an example response specifies that Jane Doe s area of interest is fashion she is female and between the ages of 24 30 and resides in Austin Tex. After application is finished processing decorated request received from incoming pipeline application may create a response responsive to request .

In incoming personalization handler may pass request to incoming tracking handler which may decorate request by adding tracking information to the request. Incoming tracking handler may be separate from and run in a different process than application . As such it may be unnecessary for incoming tracking handler to be integrated into application .

Incoming tracking handler may decorate request with the tracking information e.g. a list of Jane Doe s behaviors X Y and Z to track to generate at least a portion of decorated request . For example the tracking information may include behaviors such as the user s purchases etc. If another pipeline handler is included in incoming pipeline after incoming tracking handler request may be passed along to this next pipeline handler otherwise incoming tracking handler may pass decorated request to application .

Application may receive decorated request from incoming pipeline and identify the tracking information in the request. In an example the tracking information is a request to application to track the user s purchasing behavior. Application may make a service call into tracking cube e.g. invoke an API specifying that application is tracking the user s purchasing behavior. Application may continue to execute logic and responsive to observing the user purchase a good or service or browsing particular goods or services application may make another service call into tracking cube to inform it of the user s purchases or browsing behavior. In this way tracking cube may then log the user s purchasing behavior and browsing behavior. After application is finished processing decorated request received from incoming pipeline application may create a response responsive to request .

In incoming tracking handler may pass request to incoming experimentation handler which may decorate request by adding experimentation information to the request. Incoming experimentation handler may be separate from application . As such it may be unnecessary for incoming experimentation handler to be integrated into application .

Incoming experimentation handler may decorate request with the experimentation information e.g. what information to provide to the user based on her choices to generate at least a portion of decorated request . Experimentation information may include displaying different advertisements or colors on the webpage to the user and recording the user s behavior. If another pipeline handler is included in incoming pipeline after incoming experimentation handler request may be passed along to this next pipeline handler otherwise experimentation handler may pass decorated request to application . Application may receive decorated request from incoming pipeline and identify the experimentation information in the request.

It should be understood that decorated request may include at least one of logging information personalization information tracking information and experimentation information.

In keeping with the above example in which fashion is Jane Doe s area of interest application may send a search request for appropriate promotion items e.g. shoes and purses that fit the user s profile. Application may want to talk to other services and databases outside of computer system . To do so application may send requests to client proxy which may be thought of as a cube that provides services.

In client proxy includes a client service layer a client routing layer and a client resilience layer . In an example service client layer communicates with service routing layer to identify a uniform resource locator URL to which promotion items map. Service client layer may make a service call to a service remote from computer system . In an example the service is a search service and service client layer does not know where the item is located. The search service may be given a common name that is a URL or uniform resource identifier URI which may not have a location.

In some examples the URL depends in which data center computer system is located because it may be desirable to not cross data centers although this may happen . Service routing layer may also determine the URL based on the environment in which computer system is in and whether it is requesting information from an internal or external service. For example if computer system is located in a quality assurance environment in Phoenix service routing layer may send the request for one or more promotion items to itemservice.QA.phoenix.acme.com. In contrast if computer system is located in a production environment in Salt Lake City service routing layer may send the request for one or more promotion items to itemservice.prod.SLC.acme.com. Client routing layer may then route request to the URL or URI to retrieve the promotion item s . Service resilience layer may watch for a response responsive to request .

Client proxy may obtain promotion items include the promotion items in response and send response to computer system . In this example client proxy receives a list of fashion items that application will render into the homepage for the user to view. In application sends response which includes the promotion items through outgoing pipeline for processing. In an example application may send response to client and outgoing pipeline may intercept the response without application knowing.

If the itemservice does not respond it may be overcapacitated. If client proxy does not receive a response from the search service within a threshold amount of time service resilience layer sends response to application where response includes an indication that the search service is not responding. The threshold amount of time may be based on a service level agreement or a pre defined timeframe. In this way service resilience layer may prevent application from hanging indefinitely. A waiting application is a blocking application that hogs useful resources and prevents them from being available to other applications or components executing in computer system .

Application may include in response the unique identifier that was included in request . Application sends response to outgoing pipeline . Response may traverse each of the pipelines in outgoing pipeline in a linear fashion starting from outgoing experimentation handler to outgoing logging handler . Each of outgoing experimentation handler outgoing tracking handler outgoing personalization handler and outgoing logging handler may be separate from application . As such it may be unnecessary for outgoing experimentation handler outgoing tracking handler outgoing personalization handler and or outgoing logging handler to be integrated into application . An outgoing pipeline handler may extract information from response and send the information to an associated cube or to an information repository.

Outgoing experimentation handler receives response and closes out request for the request identifier included in the response. By outgoing experimentation handler closing out request this indicates to experimentation cube that the request has been responded to by the application. Additionally responsive to the close indication by outgoing experimentation handler experimentation cube may push out the experimentation information to other information systems e.g. an associated cube or to an information repository .

If another pipeline handler is included in outgoing pipeline after outgoing experimentation handler response may be passed along to this next pipeline handler otherwise outgoing experimentation handler may pass the response to client . In outgoing experimentation handler may pass response to outgoing tracking handler . Outgoing tracking handler receives response and closes out request for the request identifier included in the response. By outgoing tracking handler closing out request this indicates to tracking cube that the request has been responded to by the application. Additionally responsive to the close indication by outgoing tracking handler tracking cube may push out the tracking information to other information systems e.g. an associated cube or to an information repository . In an example the tracking information specifies that for this particular unique request identifier application logged behaviors X Y and Z. 

If another pipeline handler is included in outgoing pipeline after outgoing tracking handler response may be passed along to this next pipeline handler otherwise outgoing tracking handler may pass the response to client . In outgoing tracking handler may pass response to outgoing personalization handler . Outgoing personalization handler receives response and closes out request for the request identifier included in the response. By outgoing personalization handler closing out request this indicates to personalization cube that the request has been responded to by the application. Additionally responsive to the close indication by outgoing personalization handler personalization cube may push out the personalization information to other information systems e.g. an associated cube or to an information repository .

If another pipeline handler is included in outgoing pipeline after outgoing personalization handler response may be passed along to this next pipeline handler otherwise outgoing personalization handler may pass the response to client . In outgoing personalization handler may pass response to outgoing logging handler . Outgoing logging handler receives response and closes out request for the request identifier included in the response by logging the close time and the associated identifier. Outgoing logging handler may push out the logging information to other information systems e.g. an associated cube or to an information repository . Outgoing pipeline may send response to client and client may receive the response.

In some embodiments a pipeline may be part of the application framework. For example in the pipelines e.g. incoming and outgoing pipelines may be integrated into the application framework. In an example if an application is written in JAVA the pipelines typically fit in the same process written in JAVA and may only work for those frameworks. Trademarks are the property of their respective owners. Traditionally a new pipeline is reconstructed for each new application framework. It may be costly and inefficient to reconstruct a new pipeline for each new application framework.

The pipeline may be taken out of the process in which the application or cubes run. In this example the pipeline handlers that are part of incoming pipeline and or outgoing pipeline may run in a process separate from the application and cubes thus providing a pipeline as a service. Providing a pipeline as a service may provide a neutral pipeline that can be easily integrated with other architectures that are not native to current implementations. As such it may be unnecessary to have one infrastructure per language specification resulting in saved costs. Rather the pipeline may be used for all the languages in which an application is written and is independent of the framework.

Additionally it may be unnecessary for a developer developing the business logic for application to set up a context e.g. programming language etc. before the application is accessed. The developer may be better able to focus on application logic and not the infrastructure below it. Further if pipeline handlers that are part of a pipeline are developed by different teams they may be easily integrated into the pipeline. Additionally the pipeline may be lighter weight than conventional pipelines which are native to a framework.

In some examples the pipeline e.g. incoming pipeline and or outgoing pipeline is a separate component that exists outside of the application framework and may be connected to different frameworks. The pipeline may provide the same functionality and services to different applications or the same application written in different languages. As such other applications may receive requests from or send responses to the pipeline.

Pipeline as a service may be plugged into different application frameworks e.g. see and may be coupled to any framework. For example pipeline as a service may be coupled to a first framework and to a second framework. In incoming pipeline may decorate a request received from a client and generate a decorated request . Additionally outgoing pipeline may receive response which is responsive to request . Outgoing pipeline may process response and send it to the client.

To integrate pipeline as a service into an application framework the integration of the framework s request and response management may be removed from the pipeline. Additionally the communication interface in and out of the pipeline may be defined. When a pipeline is integrated into a framework the pipeline and application may run in the same process so it may be unnecessary to provide this communication interface. With pipeline as a service however the pipeline runs in a different process than the application and possibly the cubes. Incoming pipeline and outgoing pipeline in pipeline as a service may communicate with services and components outside of computer system . It may be desirable for these communication interfaces to be lightweight because if they are too heavy pipeline as a service may be unable to handle a large amount of requests.

A cube may be one service delivery mechanism but it should be understood that other service delivery mechanisms are possible. Additionally not only may pipeline as a service be coupled to an application framework pipeline as a service may also be coupled to infrastructure components that process requests or responses e.g. load balancer .

In some examples a pipeline handler may receive an input and emit zero one or more outputs. A developer of a pipeline handler may choose one or more models of a plurality of models for the pipeline handler to implement. The developer may choose an interface that makes the most sense for the pipeline handler and provide a service provider interface SPI at the pipeline handler for invocation by other components to implement the model. In an example a first model provides zero output based on a single input a second model provides one output based on a single input a third model provides a plurality of outputs based on a single input and a fourth model provides a future output based on a single input. A pipeline handler or application may have one or more SPIs that forward zero one multiple and or future outputs. In an example an application or load balancer invokes an SPI at a pipeline handler.

A pipeline handler may forward zero outputs based on a single request if the content in the request does not have enough information for the pipeline handler to make an informed decision or to process the request. In this case the pipeline handler may wait for another request before passing it to the next pipeline handler in the pipeline. In an example an authentication pipeline handler may provide zero outputs based on a single input. The authentication pipeline handler may receive a request including partial authentication information. In an example the request does not provide the authentication pipeline handler with enough information to process the authentication request. In this example the authentication pipeline handler may wait for another request including more authentication information to process and then pass the request along to the next pipeline handler. Accordingly the authentication pipeline handler may have a first SPI that forwards zero responses based on a single input and may also have a second SPI that forwards one response based on a single input.

A pipeline handler may forward one output based on a single request if the content in the request provides the pipeline handler with enough information to make an informed decision and to process the request. In an example a personalization pipeline handler may provide one output based on a single input. Accordingly the personalization pipeline handler may have an SPI that forwards one response based on the single input.

A pipeline handler may forward a plurality of outputs based on a single request. A request may be broken down into a plurality of request chunks. A response may be broken down into a plurality of response chunks. In an example application may be thought of as a pipeline handler that can receive a response and provide one or more outputs based on the response. Accordingly application may have a first SPI that forwards one response based on a single input and may also have a second SPI that forwards a plurality of response chunks based on a single input. Application may receive a request and break it down into request chunks process each of the request chunks and output a response chunk for each request chunk.

Application may log one or more events associated with the request and create one or more log records based on the logging. Application may open a transaction based on logging a request associated with a new unique identifier. Log aggregator may receive an indication that a request has been completed. In response to the indication log aggregator may aggregate all log records created based on processing the particular request and send them to log client to store in a centralized access log . Log records may include a unique identifier associated with the request. Centralized access log is a logging system that may receive one or more requests from log client to store aggregated log records associated with a request. Centralized access log has the notion of a request and each request may be associated with a unique identifier. Centralized access log may be a system that is integrated into a framework as a service or pipeline as a service.

Application log aggregator and log client may keep track of the log records associated with a request and log client may insert them into centralized access log to complete the transaction. In an example in response to receiving the aggregated log records log client closes the transaction associated with the request or the unique identifier that identifies the request .

As discussed log aggregator may receive an indication that a request has been completed and thus log aggregator may aggregate the log records associated with the request and send them to log client . Timing issues however may present themselves because there is no guarantee that when application logs events that the log records are immediately created. Rather the events may be buffered and then logged. Accordingly log aggregator may be unaware of when it should aggregate the log records associated with the request and send the aggregated log records to log client because log aggregator does not know when all events that can be associated with the request have been logged.

In some examples log aggregator sets a timeout period e.g. 15 milliseconds and collects information and identifies currently active transactions associated with requests. If log aggregator determines that no log records associated with the request have been created within the timeout period then this may be an indication to log aggregator that the request has been completed. Accordingly log aggregator may aggregate all log records associated with the request and send them to log client to store in centralized access log . In an example a transaction is open when a request associated with a new unique identifier is received. Log client may send a request including the aggregated log files associated with the request to centralized access log . After centralized access log stores the log records associated with the unique identifier log client may close the transaction. A request may be closed based on its associated transaction being closed.

The timeout period may be relative to the most recently created log record and may depend on for example the framework or stack. If application logs an event based on processing a request associated with a closed transaction the administrator may manually go back and edit the transaction to include the log record. If a log worthy event occurs that should be recorded in centralized access log and log aggregator no longer has an active request associated with the log worthy event open an administrator may determine that the transaction associated with the request closed too soon. For example log aggregator may detect a log record that has not been sent to log client and based on a request associated with a closed transaction. In this example log aggregator may send an alert indicating that the log record has not been sent to log client for storage in centralized access log but should have been. The administrator may be alerted and manually edit the transaction to include this log record.

In response to detecting the log record associated with a closed transaction an administrator or log aggregator may extend the timeout period to a longer time e.g. 25 milliseconds . To prevent adjusting the timeout period too much and to provide a stable timeout period log aggregator may count the number of log records that have been associated with a closed transaction. If the number of log records that have been associated with a closed transaction exceeds a threshold the timeout period may be too short and the administrator or log aggregator may increase the timeout period. Referring back to log aggregator may reside in computer system and may be part of the same process as application .

It should be understood that additional processes may be performed before during or after blocks and discussed above. It is also understood that one or more of the blocks of method described herein may be omitted combined or performed in a different sequence as desired.

It should be understood that additional processes may be performed before during or after blocks discussed above. It is also understood that one or more of the blocks of method described herein may be omitted combined or performed in a different sequence as desired.

Referring now to an embodiment of a computer system suitable for implementing for example the framework as a service pipeline as a service and or log aggregation is illustrated. It should be appreciated that other devices discussed above may be implemented as computer system in a manner as follows.

In accordance with various embodiments of the present disclosure computer system such as a computer and or a network server includes a bus or other communication mechanism for communicating information which interconnects subsystems and components such as a processing component e.g. processor micro controller digital signal processor DSP etc. a system memory component e.g. RAM a static storage component e.g. ROM a disk drive component e.g. magnetic or optical a network interface component e.g. modem or Ethernet card a display component e.g. CRT or LCD an input component e.g. keyboard keypad or virtual keyboard and or a cursor control component e.g. mouse pointer or trackball . In one implementation disk drive component may include a database having one or more disk drive components.

In accordance with embodiments of the present disclosure computer system performs specific operations by processor executing one or more sequences of instructions contained in memory component such as described herein with respect to incoming pipeline outgoing pipeline applications or cubes . Such instructions may be read into system memory component from another computer readable medium such as static storage component or disk drive component . In other embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the present disclosure.

Logic may be encoded in a computer readable medium which may refer to any medium that participates in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. In one embodiment the computer readable medium is non transitory. In various implementations non volatile media includes optical or magnetic disks such as disk drive component volatile media includes dynamic memory such as system memory component and transmission media includes coaxial cables copper wire and fiber optics including wires that include bus . In one example transmission media may take the form of acoustic or light waves such as those generated during radio wave and infrared data communications.

Some common forms of computer readable media includes for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge carrier wave or any other medium from which a computer is adapted to read. In one embodiment the computer readable media is non transitory.

In various embodiments of the present disclosure execution of instruction sequences e.g. methods and or to practice the present disclosure may be performed by computer system . In various other embodiments of the present disclosure a plurality of computer systems coupled by a communication link to network e.g. such as a LAN WLAN PTSN and or various other wired or wireless networks including telecommunications mobile and cellular phone networks may perform instruction sequences to practice the present disclosure in coordination with one another.

Computer system may transmit and receive messages data information and instructions including one or more programs e.g. application code through communication link and network interface component . Network interface component may include an antenna either separate or integrated to enable transmission and reception via communication link . Received program code may be executed by processor as received and or stored in disk drive component or some other non volatile storage component for execution.

Where applicable various embodiments provided by the present disclosure may be implemented using hardware software or combinations of hardware and software. Also where applicable the various hardware components and or software components set forth herein may be combined into composite components comprising software hardware and or both without departing from the scope of the present disclosure. Where applicable the various hardware components and or software components set forth herein may be separated into sub components comprising software hardware or both without departing from the scope of the present disclosure. In addition where applicable it is contemplated that software components may be implemented as hardware components and vice versa.

Software in accordance with the present disclosure such as program code and or data may be stored on one or more computer readable mediums. It is also contemplated that software identified herein may be implemented using one or more general purpose or specific purpose computers and or computer systems networked and or otherwise. Where applicable the ordering of various steps described herein may be changed combined into composite steps and or separated into sub steps to provide features described herein.

The foregoing disclosure is not intended to limit the present disclosure to the precise forms or particular fields of use disclosed. As such it is contemplated that various alternate embodiments and or modifications to the present disclosure whether explicitly described or implied herein are possible in light of the disclosure. Having thus described embodiments of the present disclosure persons of ordinary skill in the art will recognize that changes may be made in form and detail without departing from the scope of the present disclosure. Thus the present disclosure is limited only by the claims.

