---

title: Texture pipe as an image processing engine
abstract: A texture pipe of a graphics processing unit (GPU) may receive a texture data. The texture pipe may perform a block-based operation on the texture data, wherein the texture data comprises one or more blocks of texels. Shader processors of the GPU may process graphics data concurrently with the texture pipe performing the block-based operation. The texture pipe may output a result of performing the block-based operation on the one or more texture data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09659341&OS=09659341&RS=09659341
owner: QUALCOMM Incorporated
number: 09659341
owner_city: San Diego
owner_country: US
publication_date: 20150624
---
This application claims priority to U.S. Provisional Patent Application No. 62 016 967 filed Jun. 25 2014 the entirety of which is incorporated by reference herein.

Block based image processing operations may be useful in processing image data. For example convolution and correlation operations may be useful for performing image filtering such as BOX Gaussian edge detection Laplacian down sampling mean high low pass correlation and the like. These operations may typically be performed by shader processors of a graphics processing unit GPU .

In general the present disclosure relates to using a texture pipe as an image processing engine such that the texture pipe may be able to perform generic block based operations such as convolutions sums of absolute differences and the like. The texture pipe may be able to perform these operations concurrently while the shader processor executes other instructions. In this way the GPU may accelerate commonly used image processing functions.

In one example the present disclosure is directed to a method. The method may include receiving by a texture pipe of a graphics processing unit GPU texture data. The method may further include performing by the texture pipe a block based operation on the texture data wherein the texture data comprises one or more blocks of texels. The method may further include processing graphics data with shader processors of the GPU concurrently with the texture pipe performing the block based operation. The method may further include outputting by the texture pipe a result of performing the block based operation on the texture data.

In another example the present disclosure is directed to a computing device. The computing device may include a memory configured to store texture data. The computing device may further include a texture pipe configured to receive texture data from the memory perform a block based operation on the texture data wherein the texture data comprises one or more blocks of texels and output a result of performing the one or more block based operations on the one or more texture data. The computing device may further include shader processors configured to process graphics data concurrently with the texture pipe performing the block based operation.

In another example the present disclosure is directed to a non transitory computer readable medium containing instructions. The instructions cause a programmable processor to receive by a texture pipe of a GPU texture data perform by the texture pipe a block based operation on the texture data wherein each of the one or more texture data comprises one or more blocks of texels process graphics data with shader processors of the GPU concurrently with the texture pipe performing the block based operation and output by the texture pipe a result of performing the one or more block based operations on the one or more texture data.

In another example the present disclosure is directed to an apparatus. The apparatus may include means for receiving texture data. The apparatus may further include means for performing a block based operation on the texture data wherein the texture data comprises one or more blocks of texels. The apparatus may further include means for processing graphics data concurrently with the means for performing the block based operation. The apparatus may further include means for outputting a result of performing the block based operation on the one or more texture data.

The details of one or more aspects of the present disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages of the present disclosure will be apparent from the description and drawings and from the claims.

In general the present disclosure relates to using a texture pipe on a GPU as an image processing engine such that the texture pipe may be configured to perform generic block based operations such as convolutions sums of absolute differences and the like to process graphics data thereby leveraging the texture pipe to enhance the performance of image processing performed by the GPU. Block based operations may be operations that operate on blocks of graphics data. For example a block may comprise one or more texels and block based operations may operate on the one or more texels of a block. Block based operations may include block to block operations. Block to block operations may include applying an arithmetic operation between two independent blocks of the same size that may or may not have overlapping regions. Block to block based operations may include operations on a single block such as computing the sum of all values of the pixels in the block the mean of all values of the pixels in the block and the like. Such block to block based operations may be useful in the context of image processing. Currently these operations may mostly be performed by shader processors of a GPU. However the performance of the GPU can be increased by off loading these operations from the shader processors to a texture pipe of the GPU. The texture pipe may be able to perform these operations concurrently while the shader processor is busy executing instructions other than instructions for the block based operations on the one or more texture data. For example the shader processor may execute instructions to process graphics data while the texture pipe performs block to block operations. In this way the GPU may accelerate commonly used image processing functions.

Computing device may include additional modules or units not shown in for purposes of clarity. For example computing device may include a speaker and a microphone neither of which are shown in to effectuate telephonic communications in examples where computing device is a mobile wireless telephone or a speaker where computing device is a media player. Computing device may also include a video camera. Furthermore the various modules and units shown in computing device may not be necessary in every example of computing device . For example user interface and display may be external to computing device in examples where computing device is a desktop computer or other device that is equipped to interface with an external user interface or display.

Examples of user interface include but are not limited to a trackball a mouse a keyboard and other types of input devices. User interface may also be a touch screen and may be incorporated as a part of display . Transceiver module may include circuitry to allow wireless or wired communication between computing device and another device or a network. Transceiver module may include modulators demodulators amplifiers and other such circuitry for wired or wireless communication.

Processor may be a microprocessor such as a central processing unit CPU configured to process instructions of a computer program for execution. Processor may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause processor to execute one or more software applications. The software applications that execute on processor may include for example an operating system a word processor application an email application a spreadsheet application a media player application a video game application a graphical user interface application or another program. Additionally processor may execute GPU driver for controlling the operation of GPU . The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad or another input device that is coupled to computing device via user input interface .

The software applications that execute on processor may include one or more graphics rendering instructions that instruct processor to cause the rendering of graphics data to display . In some examples the software instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API a Direct3D API an X3D API a RenderMan API a WebGL API an Open Computing Language OpenCL RenderScript or any other heterogeneous computing APIs or any other public or proprietary standard graphics or compute API. The software instructions may also be instructions directed towards renderless algorithms such as computational photography convolution neural networks video processing scientific applications and the like. In order to process the graphics rendering instructions processor may issue one or more graphics rendering commands to GPU e.g. through GPU driver to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

GPU may be configured to perform graphics operations to render one or more graphics primitives to display . Thus when one of the software applications executing on processor requires graphics processing processor may provide graphics commands and graphics data to GPU for rendering to display . The graphics data may include e.g. drawing commands state information primitive information texture information etc. GPU may in some instances be built with a highly parallel structure that provides more efficient processing of complex graphic related operations than processor . For example GPU may include a plurality of processing elements such as shader units that are configured to operate on multiple vertices or pixels in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to draw graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than drawing the scenes directly to display using processor .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry. GPU may also include one or more processor cores so that GPU may be referred to as a multi core processor.

Graphics memory may be part of GPU . Thus GPU may read data from and write data to graphics memory without using a bus. In other words GPU may process data locally using a local storage instead of off chip memory. Such graphics memory may be referred to as on chip memory. This allows GPU to operate in a more efficient manner by eliminating the need of GPU to read and write data via a bus which may experience heavy bus traffic. In some instances however GPU may not include a separate memory but instead utilize system memory via a bus. Graphics memory may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

In some examples GPU may store a fully formed image in system memory . Display processor may retrieve the image from system memory and output values that cause the pixels of display to illuminate to display the image. Display may be the display of computing device that displays the image content generated by GPU . Display may be a liquid crystal display LCD an organic light emitting diode display OLED a cathode ray tube CRT display a plasma display or another type of display device.

Memory available to processor and GPU may include system memory and frame buffer . Frame buffer may be a part of system memory or may be separate from system memory . Frame buffer may store rendered image data.

Software application may be any application that utilizes the functionality of GPU . For example software application may be a GUI application an operating system a portable mapping application a computer aided design program for engineering or artistic applications a video game application or another type of software application that uses 2D or 3D graphics.

Software application may include one or more drawing instructions that instruct GPU to render a graphical user interface GUI and or a graphics scene. For example the drawing instructions may include instructions that define a set of one or more graphics primitives to be rendered by GPU . In some examples the drawing instructions may collectively define all or part of a plurality of windowing surfaces used in a GUI. In additional examples the drawing instructions may collectively define all or part of a graphics scene that includes one or more graphics objects within a model space or world space defined by the application.

Software application may invoke GPU driver via graphics API to issue one or more commands to GPU for rendering one or more graphics primitives into displayable graphics images. For example software application may invoke GPU driver via graphics API to provide primitive definitions to GPU . In some instances the primitive definitions may be provided to GPU in the form of a list of drawing primitives e.g. triangles rectangles triangle fans triangle strips etc. The primitive definitions may include vertex specifications that specify one or more vertices associated with the primitives to be rendered. The vertex specifications may include positional coordinates for each vertex and in some instances other attributes associated with the vertex such as e.g. color coordinates normal vectors and texture coordinates. The primitive definitions may also include primitive type information e.g. triangle rectangle triangle fan triangle strip etc. scaling information rotation information and the like.

Based on the instructions issued by software application to GPU driver GPU driver may formulate one or more commands that specify one or more operations for GPU to perform in order to render the primitive. When GPU receives a command from CPU a graphics processing pipeline may execute on shader processors to decode the command and to configure the graphics processing pipeline to perform the operation specified in the command. For example an input assembler in the graphics processing pipeline may read primitive data and assemble the data into primitives for use by the other graphics pipeline stages in a graphics processing pipeline. After performing the specified operations the graphics processing pipeline outputs the rendered data to frame buffer associated with a display device.

Frame buffer stores destination pixels for GPU . Each destination pixel may be associated with a unique screen pixel location. In some examples frame buffer may store color components and a destination alpha value for each destination pixel. For example frame buffer may store Red Green Blue Alpha RGBA components for each pixel where the RGB components correspond to color values and the A component corresponds to a destination alpha value. Although frame buffer and system memory are illustrated as being separate memory units in other examples frame buffer may be part of system memory .

In some examples a graphics processing pipeline may include one or more of a vertex shader stage a hull shader stage a domain shader stage a geometry shader stage and a pixel shader stage. These stages of the graphics processing pipeline may be considered shader stages. These shader stages may be implemented as one or more shader programs that execute on shader units in GPU . Shader units may be configured as a programmable pipeline of processing components. In some examples shader unit may be referred to as shader processors or unified shaders and may perform geometry vertex pixel or other shading operations to render graphics. Shader units may include shader processors each of which may include one or more components for fetching and decoding operations one or more ALUs for carrying out arithmetic calculations one or more memories caches and registers.

GPU may include texture pipe . In some examples texture pipe may be included in shader units but it should be understood that in other examples texture pipe may also be disposed outside of shader units . Texture pipe may include one or more hardware units separate from shader processors in GPU that are configured to operate on one or more texture data such as one or more of texture data A N texture data stored in graphics memory to perform texture operations such as texture filtering and to output the result of operating on the one or more texture data. Shader processors may instruct texture pipe to perform operations on texture data and texture pipe may send the results of operating on texture data to shader processor for further processing. For example texture pipe may be a dedicated set of hardware units that are dedicated to operating on texture data such as dedicated to performing texture filtering on texture data or configured to calculate dot products of texture data and the like.

Each of texture data A N for example may be but is not necessary limited to a one dimensional two dimensional or three dimensional texture or a one dimensional two dimensional or three dimensional array of texture. In some examples a texture may be an object that contains one or more images where pixels of the one or more images may be referred to as texels. Texture data may include multiple textures e.g. textures A B etc. . In one example a texture data e.g. texture data A of texture data may include an array of texture elements also known as texels which contain color and alpha values for the texture data. In some example a texture data e.g. texture data A of texture data may include one or more quads which may be a block of four texels.

In some examples each texture data of texture data may be a two dimensional image that GPU maps to three dimensional graphics. For instance a pixel in a texture data e.g. texture data A also referred to as a texel may be identified by a u v coordinate and a texture data e.g. texture data A may be made up of an array of texels. In some examples GPU may map the u v coordinates of the array of texels of a texture data e.g. texture data A to x y z w coordinates. GPU may also perform additional graphics processing on the texels of a texture data e.g. texture data A e.g. additional graphics processing on the red green blue RGB values of the texels . In some examples a block may include one or more texels so that a texture may include multiple blocks that each includes one or more texels. In some examples a block may include a quad which may be a block of four texels.

GPU may designate shader units to perform a variety of shading operations such as vertex shading hull shading domain shading geometry shading pixel shading and the like by sending commands to shader units to execute one or more of a vertex shader stage a hull shader stage a domain shader stage a geometry shader stage and a pixel shader stage in a graphics processing pipeline. In some examples GPU driver may include a compiler configured to compile one or more shader programs and to download the compiled shader programs onto one or more programmable shader units contained within GPU . The shader programs may be written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language an OpenCL C kernel etc. The compiled shader programs may include one or more instructions that control the operation of shader units within GPU . For example the shader programs may include vertex shader programs that may be executed by shader units to perform the functions of a vertex shader stage hull shader programs that may be executed by shader units to perform the functions of a hull shader stage domain shader programs that may be executed by shader unit to perform the functions of a domain shader stage geometry shader programs that may be executed by shader unit to perform the functions of a geometry shader stage and or pixel shader programs that may be executed by shader units to perform the functions of a pixel shader. A vertex shader program may control the execution of a programmable vertex shader unit or a unified shader unit and include instructions that specify one or more per vertex operations.

Graphics memory is on chip storage or memory that physically integrated into the integrated circuit of GPU . Because graphics memory is on chip GPU may be able to read values from or write values to graphics memory more quickly than reading values from or writing values to system memory via a system bus. Graphics memory may store texture data . As described above each of texture data may comprise texture elements also referred to as texels which are the fundamental units of texture space.

As also discussed above in some examples shader units may include shader processors as well as texture pipe . Texture pipe may operate concurrently with shader processors to operate on texture data . For example shader processor may perform operations of a graphics pipeline while texture pipe operates concurrently to operate on texture data . In another example shader processor may operate on some portion of texture data that has already been previously processed by texture pipe as texture pipe concurrently operates on some other portion of texture data .

Shader processors may offload work onto texture pipe including sending operations to texture pipe or programming texture pipe to perform image processing operations so that texture pipe may operate on texture data while shader processors concurrently performs graphics rendering operations and texture pipe may send the result of the image processing operations on texture data such as texels of texture data that result from the processing by texture pipe to shader processor . For example shader processors may execute shader programs to perform image processing on images and textures stored in graphics memory .

As part of performing image processing the shader programs may include instructions to perform certain image processing operations which may be offloaded to texture pipe . For example those instructions to perform image processing operations may include instructions to perform block based operations as described throughout this disclosure. GPU or components of GPU such as a high level sequencer may determine based on the instructions that shader processors may be able to offload those block based operations to texture pipe and may enable shader processors to send to texture pipe instructions to perform specified block based operations on specified one or more texture data of texture data . In some examples shader processors may send instructions per quad four texels to texture pipe to perform a block based operation on the respective quad. Texture pipe may based on the instructions received from shader processors retrieve the specified one or more texture data of texture data perform the specified block based operations on the specified one or more texture data of texture data and return the results of performing the specified block based operations to shader processors .

In this way by offloading certain image processing operations onto texture pipe shader processors may save processing cycles by receiving texels and or other graphics data from texture pipe that have already been operated on by texture pipe . Furthermore off loading texture processing to texture pipe may enable better scalability of shader units . In some examples instead of sending processed texels to shader processor texture pipe may also access graphics memory to store the results of the operations performed by texture pipe into graphics memory and shader processors may be able to access the results stored in graphics memory .

As shown in texture pipe may include cache which may be a level one L1 cache which may store texture data retrieved from graphics memory . Cache may be configured to store two or more texture data of texture data e.g. store two pieces of texture data A and B retrieved from graphics memory at the same. By storing two textures at the same time cache may enable texture pipe to perform basic image processing operations between two pieces of texture data rather than limiting texture pipe to performing dot products between a texture and a set of weights.

In some examples one of the two or more pieces of texture data cached by cache may comprise one or more convolution weights such as a weight matrix which may be cached in cache . Because some image processing algorithms performed by operations engine may use the same block of texels e.g. same quad of texels over and over to process another block of texels cache may cache such blocks of texels thereby more efficiently utilizing memory bandwidth. For example texture pipe may perform a block matching operation such as a sum of absolute difference operation or a sum of squared difference operation to find the block of texels that best matches a given reference template within a pre defined search area. In this example texture pipe may more efficiently utilize memory bandwidth by caching the reference block in cache such that texture pipe may compare the same reference block against a plurality of different blocks to determine whether a particular block of the plurality of different blocks matches the reference block.

Texture pipe may also include format converter which may convert the format of the texels of texture data . For example format converter may convert between one or more of 16 bit floating point textures 32 bit floating point textures signed normalized integer textures unsigned normalized integer textures red green blue alpha RGBA color space red green blue RGB color space red green RG color space red R color space YUV color space and the like. Format converter may also decompress texture data compressed via compression schemes such as adaptive scalable texture compression ASTC BCx ETCx EACx MIPI and the like. In this way format converter may be able to decode image formats of texture data before operations engine processes the quads of texture data . As such format converter may be able to decode texture data before it is processed by operations engine .

In some examples operations engine may further include cache which may be memory cache that caches the format converted textures resulting from format converter . Texture pipe may also include operations engine . Operations engine may comprise one or more arithmetic logic units ALUs as well as other components that may perform one or more operations on texels of texture data . For example the ALUs of operations engine may perform arithmetic operations such as addition subtraction multiplication and division as well as bitwise operations exponential operations and the like on any set of texels of one or more texture data of texture data in order to perform operations on texture data . Operations that operations engine may perform on texture data may include dot product operations sum of absolute differences operations sum of square differences operations one dimensional and two dimensional convolution and correlation operations image thresholding operations determining areas of objects block histogram frame difference frame addition minimum or maximum of a block and the like. If operations engine includes cache operations engine may retrieve the format converted textures cached in cache to perform on the retrieved format converted textures one or more of the operations listed above.

Operations engine may perform dot product operations on texture data . First texture data A and second texture data B may each include a block of texels such as a quad of texels. A dot product operation may include multiplying each texel in first texture data A of second texture data B and summing the product of the texels from first texture data A of second texture data B. For example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may compute the dot product of first texture data A and second texture data B as t t t t t t t t. The dot product operation may be useful for example for performing texture blending for adding shading to a geometry. Texture pipe may output the result of performing the dot product operation of first texture data A and second texture data B to for example shader processors .

Operations engine may also perform convolution and correlation operations on texture . A convolution operation may include multiplying each texel in first texture data A with weights included in second texture data B and summing the product of the texels and weights from the first and second texture data A and B. In this example weights for performing the convolution can be stored as texture data that may be stored in graphics memory and cached in cache . For example if first texture data A includes texels t t t and t and if second texture data B includes weights w w w and w operations engine may compute the two dimensional convolution of first texture data A and second texture data B as t w t w t w t w. First texture data A may differ in size and or format from second texture data B that includes the weights for computing the convolution. In the example shown above each texel of first texture data A may use a different convolution weight from second texture data B such that operations engine may perform per pixel convolution on the texels of first texture data A. In another example second texture data B may include convolution weights common to all texels of first texture data A such that second texture data B can include weight w and the convolution of first and second texture data A and B may be computed as t w t w t w t w.

Texture pipe may also perform several and different convolutions by selecting different textures stored in graphics memory . For example given first second third and fourth texture data A D of texture data texture pipe may select one of either the second texture data B third texture data C or fourth texture data D to use as weights with which to convolute first texture data A. Texture pipe may select one of second texture data B third texture data C or fourth texture data D stored in graphics memory to receive the selected texture data and store the selected texture data in cache . Operations engine may then perform a convolution operation on first texture data A and the selected texture data. In this way the weight for convolving a texture data of texture data may pass from software application via graphics API and GPU driver to graphics memory as texture data that may be selected by texture pipe from graphics memory for use in performing a convolution operation without having to be received by texture pipe from shader processors . The convolution operation may be useful for performing image filtering such as BOX Gaussian edge detection Laplacian down sampling mean high low pass correlation operations and the like. The correlation operation may be useful for finding locations in an image that are similar to a template. Operations engine may also perform one dimensional convolution to produce two outputs t w t wand t w t w. Operations engine may in some examples perform one dimensional convolution faster than two dimensional convolution.

In some examples convolution weights may change at each pixel location as opposed to remaining constant for the entire image. In such an example the convolution may not be arbitrary or random. Rather the convolution weights may be selected from a list of pre computed weights. These pre computed weights may be of different dimensions and or size. Two dimensional arrays or three dimensional textures may be used to define the pre computed weight sets and the two dimensional array and or the depth of the three dimensional textures may be programmed to enable texture pipe to select the requisite two dimensional texture for the final convolution operation.

Operations engine may also perform a sum of absolute differences SAD operation on first texture data A and second texture data B of texture data . The SAD operation may perform block matching between two images or between a reference template window and an image to measure the similarity between sets of texture data . Operations engine may perform the SAD operation on first texture data A and second texture data B by taking the absolute difference between texels in first texture data A with corresponding texels in second texture data B and summing the differences to create a simple metric of block similarity. The SAD operation may be used for a variety of purposes such as object recognition the generation of disparity maps for stereo images motion estimation for video compression and the like. In some examples texture pipe may increase the performance of performing the SAD operation by four times compared to shader processors . In one example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may compute the SAD of first texture data A and second texture data B as t t t t t t t t .

Operations engine may also perform a sum of square differences SSD operation on texture data . Similar to the SAD operation the SSD operation may be another approach to perform block matching between sets of texture data . Operations engine may perform the SSD operation on first texture data A and second texture data B by taking the square of the difference between texels in first texture data A with corresponding texels in second texture data B and summing the differences to create a simple metric of block similarity. Similar to the SAD operation the SSD operation may also be used for a variety of purposes such as object recognition the generation of disparity maps for stereo images motion estimation for video compression and the like. In some examples texture pipe may increase the performance of performing the SSD operation by four times compared to shader processors . In one example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may compute the SSD of first texture data A and the second texture data B as t t t t t t t t .

Operations engine may also determine the area of an object by counting all the pixels contained in the object. For example given a texture data in texture data e.g. texture data A operations engine may sum all of the pixels in texture data A. In some examples operations engine may pre process texture data A by performing image thresholding on texture data A so each texel may be either 0 or 1.

Operations engine may also perform image thresholding on a texture data in texture data e.g. texture data A . Texture pipe may receive a constant such as from shader processors . Operations engine may determine for each texel in texture data A whether the value of the texel is larger than the constant. For each texel the operations engine may output the value of the texel if the value of the texel is larger than the constant or the operations engine may output 0 if the value of the texel is not larger than the constant.

Texture pipe may be able to output more than one result of operations engine based at least in part on the image processing algorithm performed by texture pipe . For example if texture pipe combines all texels of a texture data of texture data using certain operations such as a two dimensional convolution operation texture pipe may output a single two dimensional convolution output. If texture pipe combines row wise texels using certain operations such as a one dimensional convolution operation texture pipe may output two one dimensional convolution outputs. If texture pipe combines pairwise texels using certain operations such as frame image difference operations texture pipe may output four frame difference outputs.

As shown above operations engine may be used by texture pipe to perform image filtering operations. Besides performing image filtering operations including the convolution block matching SAD and correlation operations described above texture pipe may use operations engine to perform many other operations. For example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may be configured to perform frame difference operations such as by producing four outputs t t t t t t t tor to perform frame addition operations such as by producing four outputs t t t t t t t t. The frame difference operation may be useful for determining movement in a frame detection of interested moving objects in a frame tracking objects from frame to frame analysis of object tracks for recognizing object behavior and estimation the trajectory of objects.

In some examples operations engine may also be used by texture pipe to perform simple blending operations. For example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may produce texel1 blend texel2 blend texel3 blend and texel4 blend. Some examples of these operations may include add subtract reverse subtract minimum and maximum operations.

Operations engine may perform the addition operation to output t1.rgb t.alpha trgb talpha texel1 blend t.rgb t.alpha t.rgb t.alpha texel2 blend t.rgb t.alpha t.rgb t.alpha texel3 blend and t.rgb t.alpha t.rgb t.alpha texel4 blend. Operations engine may perform the subtraction operation to output t1.rgb t.alpha trgb talpha texel1 blend t.rgb t.alpha t.rgb t.alpha texel2 blend t.rgb t.alpha t.rgb t.alpha texel3 blend and t.rgb t.alpha t.rgb t.alpha texel4 blend. Operations engine may perform the reverse subtraction operation to output t1.rgb talpha trgb t.alpha texel1 blend t.rgb t.alpha t.rgb t.alpha texel2 blend t.rgb t.alpha t.rgb t.alpha texel3 blend and t.rgb t.alpha t.rgb t.alpha texel4 blend. Operations engine may perform the minimum operation to output min t.rgb t.alpha trgb talpha texel1 blend min t.rgb t.alpha t.rgb t.alpha texel2 blend min t.rgb t.alpha t.rgb t.alpha texel3 blend and min t.rgb t.alpha t.rgb t.alpha texel4 blend. Operations engine may perform the maximum operation to output max t.rgb t.alpha trgb t.alpha texel1 blend max t.rgb t.alpha t.rgb t.alpha texel2 blend max t.rgb t.alpha t.rgb t.alpha texel3 blend and max t.rgb t.alpha t.rgb t.alpha texel4 blend.

In some examples operations engine may also be used by texture pipe to perform morphological operations which may be image processing operations that process images based on shapes. In a morphological operation the value of each pixel in the output image may be based on a comparison of the corresponding pixel in the input image with its neighbors. A morphological operation that is sensitive to specific shapes in the input image may be constructed by selecting the size and shape of the neighborhood. Some examples of these operations may include dilation operations and erosion operations. A dilation operation may add pixels to the boundaries of objects in an image while an erosion operation may remove pixels on object boundaries. Operations engine may perform a dilation operation on a texel of a texture data by determining the value of the output texel as the maximum value of all the texels in the input texel s neighborhood. Operations engine may also perform an erosion operation by a texel of a texture data by determining the value of the output texel as the minimum value of all the texels in the input texel s neighborhood.

In some examples operations engine may also be used by texture pipe to perform pixelwise logical operations. Some examples of these operations may include general operations such as relational operations e.g. bigger than smaller than equal to and operations or operations exclusive or operations and the like. In some examples pixelwise logical operations may include simple thresholding operations as described above. In some examples pixelwise logical operations may include per pixel thresholding. For example if first texture data A includes texels t t t and t and if second texture data B includes texels t t t and t operations engine may perform per pixel thresholding of first texture data A and first texture data B to output if t t telse t if t t telse t if t t telse t and if t t telse t. Operations engine may also perform an expanding operation of texture data A which changes a pixel from 0 to 1 if any neighbors are 1 such that for tif t 1 t 1 t 1 tis set to 1 else 0. Operations engine may also perform a shrinking operation of texture data A which changes a pixel from 1 to 0 if any or all neighbors are 1 such that for tif t 0 t 0 t 0 tis set to 0 or else tis set to 1. Thus these pixelwise operations may be achieved by applying a logical operator such as AND OR XOR to each of the pixels in a quad with a mask. For example given pixels in a quad p00 p01 p10 and p11 and a mask 1 1 1 0 the new value of the pixels may be p00 p00 1 p01 p01 1 p10 p10 1 and p11 p11 0 . Shrinking operations expanding operations smoothing operations and the like may be applied depending on the mask and the logical operator. Operations engine may also be configured to perform any other pixel wise logical operations.

In some examples operations engine may also be used by texture pipe to perform geometric property operations. Some examples of these operations may include determining the size or area determining a position determining an orientation determining an X projection and determining a Y projection. Operations engine may determine the size or area by determining the area of a quad in texture data A which may be t t t t. Operations engine may determine an x projection by producing two outputs t t xprojection and t t xprojection. Operations engine may determine a Y projection by producing two outputs t t yprojection and t t yprojection.

In some examples operations engine may also be used by texture pipe to perform histogram operations. For example operations engine may perform a quad histogram operation on four texels t t t and tof each of a plurality textures of texture data such that count t count t count t and count t produces four output pairs value1 and count1 value2 and count2 value3 and count3 and value4 and count4.

In addition to the operations described above texture pipe is not necessarily limited to performing the operations described above. Techniques of the present disclosure may similarly be applied such that texture pipe may also perform any other operations related to image processing video post processing camera image processing computer vision and the like. Furthermore although the above examples include four texel by four texel examples operations engine may in some examples be usable to perform the operations disclosed herein for up to N N block operations where N may be any positive integer. For example operations engine may be usable to perform 8 8 block operations 32 32 block operations and the like. For example texture pipe may accumulate 2 2 partial results and return the partial results to shader processor . It should also be understood that image blocks may be rectangular such as in an M N arrangement e.g. 32 16 8 3 11 12 and the like .

Operations engine may further include ALUs A G ALUs for performing operations such as addition subtraction multiplication division bitwise operations e.g. AND operations or OR operations exponential operations greater than operations lesser than operations equals to operations and the like on texels A and B. For example if operations engine is performing a convolution operation on texture data A and B ALU A may multiply texel tfrom texels A with weight wfrom texels B ALU B may multiply texel twith weight wfrom texels B ALU C may multiply texel tfrom texels A with weight wfrom texels B and ALU D may multiply texel tfrom texels A with weight wfrom texels B. ALU E may sum the result from ALUs A and B and ALU F may sum the result from ALUs C and D. ALU may sum the result from ALUs E and F to produce the result of convoluting texture data A with texture data E. As discussed above in some examples texture pipe may send the result from operations engine to shader processors . In some other examples texture pipe may store the result from operations engine into graphics memory . If texture pipe outputs four results those four results may be the results output from ALUs A D. If texture pipe outputs two results those two results may be the results output from ALUs E and F. If texture pipe outputs a single result that result may be the result output from ALU G.

The following is application level sample code written in OpenCL for setting up textures sending data to texture memory passing parameters to the kernel and calling the kernel 

The following is kernel level sample code for executing a two dimensional loop per pixel and performing convolution SAD SSD 

The following is kernel level sample code for executing a two dimensional loop per pixel and performing convolution SAD SSD via proposed new API extensions to OpenCL conv imageui sad imageui and ssd imageui that may assist in taking advantage of the techniques of the present disclosure 

In some examples texture data may comprise a first texture data A and a second texture data B. In some examples texture pipe of GPU receiving texture data may include cache memory of texture pipe receiving first texture data A and second texture data B. Cache memory may store both first texture data A and second texture data B at the same time.

In some examples texture pipe may perform the block based operation on texture data by determining a sum of differences of first texture data A and second texture data B. In some examples texture pipe may perform a block based operation on texture data by determining a sum of square differences of first texture data A and second texture data B.

In some examples texture pipe may perform a block based operation on texture data by convoluting first texture data with one or more convolution weights wherein second texture data B may comprise the one or more convolution weights. In some examples texture pipe may convolute first texture data A with the one or more convolution weights by performing per pixel convolution of first texture data A with the one or more convolution weights.

In some examples first texture data A may differ from second texture data B in at least one of size or format. In some examples first texture data A may be of a first format and second texture data B may be of a second format and texture pipe may convert first texture data A from the first format to the second format.

In some examples texture pipe may perform a block based operation on texture data by determining an area of an object based at least in part on texture data . In some examples texture pipe may perform a block based operation on texture data by performing an image thresholding operation on texture data . In some examples texture pipe may perform a block based operation on texture data by performing a morphological operation on texture data .

In one or more examples the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media may include computer data storage media or communication media including any medium that facilitates transfer of a computer program from one place to another. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also any connection is properly termed a computer readable medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of medium. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and Blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more digital signal processors DSPs general purpose microprocessors application specific integrated circuits ASICs field programmable logic arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor and processing unit as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules configured for encoding and decoding or incorporated in a combined codec. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs i.e. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various aspects of the disclosure have been described. These and other embodiments are within the scope of the following claims.

