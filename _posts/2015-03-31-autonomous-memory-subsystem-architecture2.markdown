---

title: Autonomous memory subsystem architecture
abstract: An autonomous sub-system receives a database downloaded from a host controller. A controller monitors bus traffic and/or allocated resources in the subsystem and re-allocates resources based on the monitored results to dynamically improve system performance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09612750&OS=09612750&RS=09612750
owner: Micron Technologies, Inc.
number: 09612750
owner_city: Boise
owner_country: US
publication_date: 20150331
---
A problem for parallel distributed systems is how to assign and manage memory resources. Memory is typically attached to a host processor using a shared bus where appropriate protocols are applied to enable coherency and consistency. In this strategy memory controller hardware on the processor core can observe the traffic on the common bus then update or invalidate cache lines to reflect the operations performed by the other processors. A many node multiprocessor system may also use directory based coherence techniques to allow processor nodes to see memory traffic that relates to pages or cache lines on which they are working. These strategies become increasingly performance hampering and improvements in distributed systems are needed.

It will be appreciated that for simplicity and clarity of illustration elements illustrated in the figures have not necessarily been drawn to scale. For example the dimensions of some of the elements may be exaggerated relative to other elements for clarity. Further where considered appropriate reference numerals have been repeated among the figures to indicate corresponding or analogous elements.

In the following detailed description numerous specific details are set forth in order to provide a thorough understanding of the invention. However it will be understood by those skilled in the art that the present invention may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail so as not to obscure the present invention.

Use of the terms coupled and connected along with their derivatives may be used. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause and effect relationship .

The embodiment illustrated in shows an architecture that enables a processor and multiple autonomous memory devices to be configured for communicating in a distributed sub system in accordance with the present invention. In order to facilitate communication between a large number of devices each of the autonomous memory devices in distributed sub system is assigned their own address. This gives each autonomous memory device the ability to route messages to other devices in the sub system. Although the figure illustrates autonomous memory devices in a 3 3 array distributed sub system may be configured having much larger numbers of devices in the network.

In one embodiment the addressing scheme may be absolute where each autonomous memory device is assigned a unique static address as determined by a route to the autonomous memory device e.g. the memory device may be specified as being on a particular port of the device and electrically connected to a port of the root device. In an alternative embodiment the address of the autonomous memory device may be dynamically determined while operating within the system. By allowing the address to be determined dynamically the addressing scheme may be modified for purposes of optimization during system operation.

On system startup the network may initialize by transferring routing information to allow this inter device communication to take place. Alternatively the system may self organize as autonomous memory devices build a routing table using a scan technique to determine neighbors. The routing table keeps track of the devices within distributed sub system and may store parameters such as for example the latency cost based on location of any one device talking to another device.

The message passing on the bus that connects the distributed autonomous memory devices may be modeled or it may be a standard network. One such standard network may be the Transmission Control Protocol Internet Protocol TCP IP that is responsible for verifying the correct delivery of data from one device to another. TCP IP also provides support to detect errors or lost data that triggers retransmission until the data is verified as being correct and completely received. Another type of network that distributed sub system may employ is the InfiniBand architecture that creates a fabric to allow low latency communication high bandwidth clustering and storage traffic. Also communication among autonomous memory devices may use Ethernet in a frame based network.

The figure shows that different memory types may be attached to autonomous memory devices . As an example each node of this autonomous memory may have NAND DRAM or other volatile nonvolatile combinations attached for offline storage or scratchpad space. Also illustrated in the figure is a wireless architecture embodiment that shows memory devices coupled to an antenna to transfer wireless signals. The antennas may be near field loop antennas capacitive plates or dipole antennas that allow the radio associated with the memory device to program the memory arrays and download algorithms and databases by communicating using over the air communication signals. A configuration routing table tracks the memory devices to facilitate communications between devices within distributed sub system .

The figure shows a wireless connection between the control block and the dice shown as the autonomous memory devices in the memory subsystem. In this embodiment the control block monitors and reacts to congestion in traffic to the various blocks. Bus traffic is one aspect of a resource that may constrain system performance. To alleviate performance constraints the monitor block may move portions of a database to a different die to parallelize searches or fully utilize computing resources. As such the monitor block monitors constrained resources to optimize system performance with bus traffic being just one example of a resource that may be optimized by relocation of data among memory devices .

In this embodiment the die to die wireless communication may use antennae that are physically located to only communicate with other dice that are in the same stack. To achieve inter die wireless communication each autonomous memory devices would have antenna on input ports to receive signals and antennae on output ports to transmit signals. The wireless communication would minimize the need for bond wires.

Autonomous memory device includes both an operating system and processing capabilities and is aware of the meaning of its contents. Put another way device is aware of the details where certain database tables are located the field definitions for each of those tables and how they re interlinked. Using this information autonomous memory device independently processes data in the stored database to get results that may be returned to the host processor.

A hardware accelerator provides smart memory processing engine with the acceleration hardware for computations and manipulations of the contents stored within memory . Hardware accelerator is capable of handling matrix operations simple comparisons with mask bits memory copies and moves etc. A code storage block stores code downloaded from a host processor through host interface for use by the general purpose control engine . An Application Programming Interface API management block executes the stored routines and protocols provided by libraries or the operating system services in order to support the building of applications. The software API s are flexible and make use of knowledge of the underlying hardware to achieve optimal performance. A configuration routing table keeps track of the other memory devices within distributed sub system . The configuration of distributed sub system may be dynamically determined and the route table updated while autonomous memory device operates within the system.

It is common to store data structures in a flat memory space. While there are an endless number of possible data structures a few common structures such as for example matrices and linked lists can be used to illustrate how autonomous memory can be used to enhance memory functionality. Matrices cover a wide spectrum of domains including those arising from a wide variety of problems with underlying 2D or 3D geometries such as for example structural engineering computational fluid dynamics model reduction semiconductor devices thermodynamics materials acoustics computer graphics vision robotics kinematics among others. Matrices may also cover applications that typically do not have such geometry such as optimization circuit simulation economic and financial modeling theoretical and quantum chemistry chemical process simulation mathematics and statistics power networks and other networks and graphs.

In processing information stored in matrices all or part of the matrices are read from memory and computations are performed by hardware accelerator on the contents of the matrices. In prior art systems large portions of the matrices were retrieved from the main memory and paged for storage in the processor cache. These matrices involve calculations that are iterative and may involve the entire matrices so prior art systems can not store the entire contents required for processing into processor cache.

However autonomous memory device significantly improves the efficiency in executing matrix algorithms. Autonomous memory device may store the matrices using a flat memory map and utilize a close coupling of memory and embedded hardware accelerator to greatly accelerate operations on these matrices. Matrix computations may further be enhanced by judiciously organizing matrices within distributed sub system to facilitate high performance matrix operations. As an example commonly shared operands in an operation may be planned to advantageously reside within the same autonomous memory device such that completion of these operations does not require communication with other devices.

It is common to create linked lists in a flat memory map to enable storage and manipulation of ordered sets of information. In traversing a linked list it is generally required that each record be inspected to determine if it matches a pattern or simply to obtain a pointer to the subsequent record. Using distributed sub system it is possible to parse linked lists with a minimum of host bus traffic. Then each autonomous memory device may inspect each record looking for specific patterns and find a pointer to the next record before repeating. Once results are found autonomous memory device uses host interface to return pertinent results to the host.

Databases are commonly comprised of large data sets that are organized in groups of inter linked tables. Index files are created and maintained and utilized to accelerate searches for information in these tables. In prior art systems some databases are larger than the near memory available to the processor operating on the databases and a significant portion of memory accesses may have long latency IO calls that gate system performance.

In contrast to the prior art systems distributed sub system may have a very large number of autonomous memory devices configured to communicate with each other and the host processor. The memory density found in distributed sub system may be limited primarily by the cost of the memory. Further with control engine embedded on the same die as memory most operations would involve bus traffic internal to the memory die and limited traffic external to the memory die. Given the close coupling of a general purpose control engine and the large density of memory the bandwidth bottleneck caused by a processor accessing external memory may be eliminated. Simple hardware acceleration techniques in hardware accelerator may be used to dramatically increase performance of distributed sub system .

With distributed sub system designed for the specific purpose of manipulating memory content a finite set of useful hardware primitives may be implemented. To implement a database in distributed sub system the database is transferred all or in part to the memory subsystem along with information about how the database is organized. Algorithms for processing information in the database are also downloaded. With the initialization process complete the host generates very high level commands to distributed sub system . Rather than reading and writing specific addresses to perform a higher level function the host processor can issue a command like parse table A to find all records matching a pattern extract pointers to table B for each of these records return fields a b c from table A and d and e from table B . All operations are run within distributed sub system and a short list of results is returned to the host processor.

Autonomous memory has a profound advantage in the case where a linear search is performed on a large database. By way of example using pipelining for one autonomous memory device having 1 GB memory density containing 8 banks of 2 M pages of 64 B each a page can be compared to a target pattern at a beat rate of about 10 nsec per page resulting in a possible search time for the 1 GB die of about 20 mS. While this is an impressive result by itself the value is that this solution is scalable and thus the search time for two autonomous memory devices each having 1 GB memory density would also be about 20 mS as would the search time for a peta byte of memory or for any sized pool of memory. Using autonomous memory devices in a distributed sub system to perform linear searches would be limited by the cost of the array of memory devices along with thermal management and power constraints.

System administration functions may also take advantage of autonomous memory devices in a distributed sub system . For example a data center may perform a virus scan on distributed sub system and when a virus is detected the data center would be downed for 20 mS during which time a search and destroy algorithm would be executed on every byte to isolate and disable any occurrence of the target virus.

Autonomous memory devices in distributed sub system provide an advantage over prior art systems when executing the Scatter Gather operations. Scatter Gather operations provide a sequence of writes at different addresses that are compiled into a single composite instruction that is executed by the memory or IO subsystem. These operations are parsed and sent out to multiple die in distributed sub system at which point they are executed autonomously. The resulting status is accumulated and reported to the host when the entire operation is complete.

Autonomous memory devices in distributed sub system are ideal for some classes of applications such as image processing. These classes are well suited to parallel computing where the image may be divided into many smaller segments which are processed relatively independently. After calculations on these small segments have been completed then further calculations may be performed on groups of these segments to form a larger segment until the image is processed at a level encompassing the entire image.

Using autonomous memory devices many or all of these low level calculations may be done in parallel at the level of a bank of the autonomous memory. Calculations crossing bank boundaries may be done within the one device and by utilizing inter die communication higher level calculations may be done at the subsystem level. Other parallel computing tasks follow a similar model and may involve iteration to refine accuracy of results or to step the simulation through time.

Distributed sub system provides interaction beyond the expected read and write operations that are enabled by memory storage devices. Autonomous memory device interacts with the existing computing infrastructure using one or more interfaces that allow communication both with the host computer and with the network. From the host computer s perspective the interaction may be a memory or block interface but to the autonomous memory device a flexible interface is provided on top of which software APIs may be built. These APIs may be scaled to either expose functionality to the host system or provide a way of passing on the request among other autonomous memory devices.

The autonomous memory device interface to other devices in distributed sub system provides a way of passing messages that may contain a command and a list of parameters. The parameters may contain actual data addressing information that refers to data in the array and object identifiers that reference an object located in the array. Parameters may also contain or refer by address or object identification Object ID to the code required to operate on a given data set. The code passed into autonomous memory device may fit the paradigm established by the OpenCL standard possibly MapReduce. Many of the existing clustering and cloud computing infrastructure pieces may be reusable within distributed sub system .

The memory controller or an autonomous memory device in distributed sub system can perform condition monitoring to determine bus activities due to data transfers between the memory devices. Based on the monitored results a re allocation of resources can be dynamically executed to improve system performance. By way of example after monitoring the traffic within distributed sub system it may be determined that high bandwidth traffic commonly occurs between two memory devices. If these memory devices are not neighboring devices the subsystem may select one of these memory devices and relocate the contents of the other memory device to allow a single autonomous memory device to provide the processing that completes the algorithm. Alternatively the memory contents of relatively distant devices may be redistributed to near by nodes to reduce bus traffic.

Further searches of distributed sub system for read only content may cause a subset of the network to be constantly active. In this case the subsystem may replicate the contents in this portion of the network so that multiple autonomous memory devices can perform parallel operations on the read only content within distributed sub system .

By now it should be apparent that embodiments of the present invention allow increased memory storage efficiencies through autonomous data storage. By connecting the autonomous memory device in a distributed memory sub system a host can download a database to the autonomous memory device. The autonomous memory device can initiate instructions to disperse portions of the database to neighboring die using an interface to handle inter die communication within a pool of autonomous memory. The autonomous memory device can then extract information from the pool of autonomous memory that is passed through the host interface to the host controller.

While certain features of the invention have been illustrated and described herein many modifications substitutions changes and equivalents will now occur to those skilled in the art. It is therefore to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit of the invention.

