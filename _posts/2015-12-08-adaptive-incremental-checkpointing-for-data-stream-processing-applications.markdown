---

title: Adaptive incremental checkpointing for data stream processing applications
abstract: A system, method and computer program product for adaptive incremental checkpointing an operator state in a streaming application. The system and method enable reduced costs of checkpointing an operator state in a streaming application, by i) logging updates to operator state and checkpointing operator state in either base (full state) or delta (logged updates) form, ii) dynamically and adaptively adjusting checkpointing options, and iii) maintaining dependencies between checkpoints to allow automatic restoration and checkpoint recycling.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09471438&OS=09471438&RS=09471438
owner: International Business Machines Corporation
number: 09471438
owner_city: Armonk
owner_country: US
publication_date: 20151208
---
The present disclosure relates to adaptive incremental data checkpoint system and method for reducing costs of fault tolerance for data stream processing applications via adaptive incremental checkpointing.

Stream processing applications have emerged as a paradigm for analyzing streaming data e.g. audio video sensor readings and business data in real time. Stream processing applications are typically built as data flow graphs comprising interconnected stream operators that implement analytics over the incoming data streams. Each of these operators is a component.

During operation of a stream processing application a stream operator may fail i.e. stop executing its operations or responding to other operators for any one or more of several reasons including but not limited to a heisenbug i.e. a computer bug that disappears or alters its characteristics when an attempt is made to study it in the stream operator code e.g. a timing error a node failure e.g. a power outage a kernel failure e.g. a device driver crashes and forces a machine reboot a transient hardware failure e.g. a memory error corrupts an application variable and causes the stream processing application to crash or a network failure e.g. the network cable gets disconnected and no other node can send data to the operator .

Many data stream processing applications in the form of one and more operators connected via data streams maintain large state in memory such as sliding windows or bloom filters in order to perform various analytics such as sorting aggregation and join . For fault tolerance purposes a data stream processing application may need to periodically checkpoint its state to a persistent storage termed checkpoint data store so that in case of a failure the application can recover its state from saved checkpoint and resume normal operations.

Unfortunately checkpointing a large operator state can incur significant overheads to the stream processing application and the checkpoint data store. The standard approach of checkpointing an operator state is to serialize all the operator state data and store the serialized data onto the checkpoint data store. For an operator with a large state the application needs to spend substantial amounts of time in serializing and writing the state to the checkpoint data store which stalls normal processing. Furthermore the checkpointed large state data usually consume a huge storage space and I O bandwidth of the checkpoint data store.

However in many stream processing applications the amount of changes of an operator state between two consecutive checkpoints is usually much smaller than the total operator state size. In this case it would be more efficient to checkpoint only the changed portion of the large operator state rather than the whole state. Hence a need is recognized to devise an incremental checkpointing method for stream processing applications.

While prior existing incremental checkpointing schemes exist including paging based approaches pre copying based approaches and hash based approaches all of these approaches more or less address the recording of changes to application state during normal computation and checkpointing the logged changes as a delta checkpoint. Some of them checkpoint the whole application address apace e.g. by detecting and tracking dirty pages in application address space and saving the dirty pages as delta checkpoint and are inappropriate for checkpointing an operator state which is only a part of application address space. Most paging and pre copy approaches require modification to Operating System or Virtual Machine Monitor or installing kernel modules which may not be feasible in practice. Besides prior incremental checkpointing approaches largely ignores the restoration cost and can degrade the restoration time arbitrarily this is inappropriate for data stream processing applications as long restoration time may not only lead to unacceptable delay in stream processing but also overwhelm the data sources and intermediate buffers and cause data loss.

A system method and computer program product for adaptive incremental checkpointing an operator state in a stream processing application.

The system and method enable reduced costs of checkpointing an operator state in a stream processing application by i logging updates to operator state and periodically checkpointing operator state in either base full state or delta logged updates form ii dynamically and adaptively adjusting checkpointing options and iii maintaining dependencies between checkpoints to allow automatic restoration and checkpoint recycling.

In one aspect there is provided a computer implemented method for adaptively and incrementally checkpointing an operator state in a data stream processing application. The application comprising during operation of the stream processing application logging changes to variables in an operator state and one of apply checkpointing to the operator state variables according to a base checkpoint data form which saves data of a whole full operator state or apply incremental checkpointing of only the logged changes to those operator state variables as a delta checkpoint data in a data storage device and upon performing a base checkpoint determining adaptively how many subsequent checkpoints will be stored as delta checkpoints between two consecutive base checkpoints.

There is further provided a system for adaptively and incrementally checkpointing an operator state in a data stream processing application. The system comprises a data storage device and a processor device running a data stream processing application in communication with the data storage device the processor device further configured to during operation of the stream processing application log changes to variables in an operator state and one of apply a checkpoint the operator state variables according to a base checkpoint data form which saves data of a whole full operator state or apply an incremental checkpoint of only the logged changes to those operator state variables as a delta checkpoint data in a data storage device and upon performing a base checkpoint determine adaptively how many subsequent checkpoints will be stored as delta checkpoints between two consecutive base checkpoints.

In a further aspect there is provided a computer program product for performing operations. The computer program product includes a storage medium readable by a processing circuit and storing instructions run by the processing circuit for running a method. The method is the same as listed above.

A system method and computer program product are provided for incrementally checkpointing an operator state in a stream processing application. In particular an adaptive incremental checkpointing method for data stream processing applications is provided.

Here plural processing nodes A . . . N are shown each node running a respective stream processing system A B . . . N that provides a runtime environment for a respective Streaming Application A B . . . N. Here a stream processing application A . . . N resides in a node and is managed at a respective node via a respective stream processing system. Each stream processing system A B . . . N includes an executable component for incrementally checkpointing application state data according to the methods described herein. The processing results include incrementally checkpointed application state data A B . . . N that are stored in a checkpoint data storage device such as a persistent storage device . The system processing nodes may be encompassed by computing devices e.g. desktop laptops services mobile devices that may accessible via networked and or cloud communications infrastructure e.g. via a LAN WAN wireless and or wired public or private communications network e.g. via internet or virtual private network. Thus via networked communications devices A . . . N may enable applications to read write and delete checkpoints relating to application state A B . . . N.

In one embodiment stream processing applications A B . . . N are run on multiple local or externally distributed compute nodes. Alternatively the checkpoint data can be stored in a Key Value Store which is locally available on each compute node as depicted by a respective storage device local to the compute nodes. This key value store may be a persistent data store. In such an alternative embodiment read write delete checkpoints are performed at the local storage medium. The respective checkpointed data A B . . . N may also be stored on a networked key value store on a network enabling storage such as open source software products Redis and Cassandra e.g. Redis is a trademark of Salvatore Sanfilippo and Cassandra is a trademark of the Apache Software Foundation .

In one embodiment if the size of changed portion is smaller than the whole operator state size the checkpoint size is reduced and the checkpointing time is improved as well. Upon restoring the operator state the base and delta checkpoints are fetched back from the checkpoint data store and get merged to re create the latest state of the operator.

Upon restoring the operator state the base and delta checkpoints are fetched back from the checkpoint data store and get merged to re create the latest state of the operator.

In after an stream processing application operator performs a computation on a piece of data at the checkpointing component performs a first checkpoint Checkpoint 1 which is to checkpoint a full operator state i.e. a base checkpoint. For purposes of description a time duration for performing normal computation between two checkpoints is defined as a time duration parameter Tcomp and a time duration for performing a full operator state checkpoint is defined as a time duration parameter TckptBase . After a further computation is performed at the changes to data variables are logged as operator state data at . A time duration for logging changes to operator state e.g. insertions and or deletions is defined as a time duration parameter Tlog . Please note that logging may be spread over a whole normal computation duration and for purpose of simplifying illustration the timeline in shows the logging time durations in periods denoted by L which are separate from normal computation durations. Then at corresponding to a time Checkpoint 2 a delta checkpoint is performed to save those recently logged changes to operator state data in the checkpoint data store . A time duration for taking a delta checkpoint is defined as a time duration parameter TckptDelta . This process is continued and after a next computation is performed at the changes to data variables are logged as operator state data at . Then at corresponding to a time Checkpoint 3 a delta checkpoint is performed to save those recently logged operator state data changes in the checkpoint data store . This process is continued and results in subsequent delta checkpoints 4 to D 1 to be generated. Then after a next computation involving that operator is performed at the checkpointing method in this embodiment is programmed to store a second full base checkpoint state at corresponding time Checkpoint D 2.

In one embodiment there is used measured historical checkpoint time sizes to determine the values for TckptBase Tcomp TckptDelta and Tlog parameter values.

Thus as depicted in the example timelines of there are two key trade offs when using incremental checkpointing 1 logging cost e.g. for logging changes made to operator state data such as at times vs. reduced checkpoint time and size i.e. size of delta checkpoint data stored and time it takes to store the delta checkpoint data and 2 reduced checkpoint time e.g. reduced at corresponding delta checkpoint times defined as a time duration TckptDelta vs. increased restore time i.e. the time it takes to read the base checkpoint and all related delta checkpoints from the checkpoint data store and merge them to restore the latest operator state.

That is with incremental checkpointing an operator first saves its full state in a base checkpoint. Each subsequent checkpoint only saves the portion of the state which is changed since previous checkpoint. As shown in there are two fundamental trade offs with incremental checkpointing. 1. Reducing checkpointing cost vs. Increasing overhead to normal computation in order to generate a delta checkpoint some logging work is needed to identify what is changed since the last checkpoint. Such logging adds overheads to normal computation and in turn reduces the checkpointing cost. 2. Reducing checkpointing cost vs. Increasing restoration cost if a delta checkpoint is smaller than a full checkpoint then taking more delta checkpoints would increase the performance gains. However doing so would also increase the time to restore the last delta check point because the base checkpoint and all previous delta checkpoint s need to be retrieved and merged with the last delta checkpoint. Therefore the number of consecutive delta checkpoints should be set so that the restoration cost is bounded to an acceptable level while the application still gets as much savings from delta checkpoints as possible.

Bounding the restoration time is important for data stream processing applications even through restoration may rarely occur. A long pause during restoration may violate application s throughput and latency requirements. Besides for many applications with high ingestion rates a long restoration time can overwhelm the data source and any intermediate buffers or cause tuple loss due to load shedding.

In one embodiment the present method and checkpointing system is adaptive in that it handles dynamics in operator state s change pattern. An operator state s change pattern is defined as the amount of changes to operator state in a time unit. Throughout an application s runtime the change pattern may vary sometimes dramatically e.g. due to fluctuations in input rate . Accordingly the sizes of delta checkpoints may change over time. As illustrated in in a first instance when delta check points are small a large number of delta checkpoints can be taken to obtain great savings in checkpoint time without unduly degrading restoration cost. In a second instance when delta checkpoints are large fewer delta checkpoints should be taken to keep the same restoration cost.

The method of in one aspect 1 Tracks changes to the operator state during normal computations of . This enables generating of delta checkpoints resulting in lower overheads to normal computation 2 Determines whether or not incremental checkpointing is beneficial and adjust the checkpointing option base or delta accordingly to improve overall application performance and additionally meanwhile bound the restore time to a configurable level. Such determination and adjustment is automatically performed at runtime to cope with dynamics in the change pattern to operator state 3 Stores checkpoints in a key value store. The data organization reflects the dependency among checkpoints so that checkpoints can be correctly restored and deleted. The data organization achieves good storage efficiency and fast read write and deletion performance. The data organization should be applicable to any key value storage scheme 4 When restoring from a delta checkpoint retrieves and merges the related base and delta checkpoints to restore operator state. The identification retrieval and merge of related checkpoints are transparent to application and 5 When deleting a checkpoint ensures that the deletion does not render the operator state unrecoverable.

In order to generate a delta checkpoint changes made to operator state are tracked since the previous checkpoint. Existing methods of tracking changes to application state can be divided into two categories. The first category is coarse grained they consider the state of an application to be all the memory pages and system resources e.g. files opened owned by application processes. The second category is fine grained they only track changes made to certain ranges of memory addresses or a set of data variables as specified by application. For both categories one implementations can be based on dirty bit in page table entries write protection and copy on write or hashing. For many stream processing systems fine grained tracking methods are more desirable than coarse grained ones. The operator state to checkpoint is usually a set of in memory variables e.g. a counter or a sliding window which is a part of the whole address space. Therefore a tracking method which targets changes to only those variables to be checkpointed is more efficient than coarse grained methods. As one such fine grained tracking method a data structure level logging method may be used.

Nevertheless any method can be used to track changes to operator state provided that the time and space overhead posed to normal computation is kept at an acceptable level. However the used tracking method provides a control interface to enable and disable tracking at runtime. If a coarse grained tracking method is used the whole address space may be treated as a single variable hence making it a special case of fine grained tracking.

In once a stream processing application is up and running and the checkpointing mechanism has started the checkpoint method includes a first determination at as to whether a current checkpoint to be taken is a base checkpoint i.e. checkpointing a full operator state or delta checkpoint logged changes to operator state . If it is determined that the current checkpoint is a base checkpoint then the process proceeds to where the checkpointing component obtains and serializes operator state in its full form e.g. all variable states are stored. The full base checkpointed data is stored at as serialized data in a checkpoint data store e.g. database of . In one embodiment a checkpoint data store may be a persistent data storage device. Then at there is performed an update of statistics e.g. performance statistics that represent the base checkpoint size and or time it takes to perform the base checkpoint. At the checkpointing method decides the number of consecutive delta checkpoints a parameter termed Delta Checkpoint Number to take.

Otherwise referring to step if it is determined that a current checkpoint to be taken is not a base checkpoint i.e. not checkpointing a full operator state the process proceeds to step in which a delta checkpoint is obtained i.e. there is obtained and serialized a changed portion delta of the operator state. The serialized checkpointed data is stored at in the checkpoint data store e.g. database of . Then at the checkpointing method performs an update of statistics e.g. performance statistics that represent the delta checkpoint size and or time it takes to perform the delta checkpoint.

In view of the method of when an operator starts the Delta Checkpoint Number is set to an initial value DO e.g. a value of 1 or any positive integer and change tracking is disabled. Upon the first checkpoint the runtime saves full operator state to form a base checkpoint. Because the next checkpoint will be a delta as Delta Checkpoint Number is non zero change tracking is enabled in subsequent computation period. For the next DO checkpoints the method generates DO delta checkpoints. Upon the completion of the last delta checkpoint the method disables change tracking. Since then the operator performs normal computation without tracking change until it reaches the next checkpoint. This checkpoint is saved as a new base checkpoint. As one step of taking this base checkpoint a function named adjustD is called at step to determine a new Delta Checkpoint Number i.e. how many consecutive delta checkpoints to generate after this base checkpoint. From the new Delta Checkpoint Number D the method knows whether the next checkpoint will be base if D is zero or delta otherwise and disables or enables change tracking accordingly.

After this base checkpoint is taken the operator resumes normal computation and takes another D delta checkpoints. After the last delta checkpoint is taken change tracking is disabled again. Then the operator performs normal computation and takes another new base checkpoint during which a new Delta Checkpoint Number value is calculated. This procedure repeats throughout operator runtime.

The Delta Checkpoint Number D is a single parameter which can be used to manage both trade offs at the same time the number of consecutive delta checkpoints between two base checkpoints. Regarding the first trade off suppose the delta checkpointing time is shorter than full state checkpointing. In this case increasing the Delta Checkpoint Number D would gain more benefit from incremental checkpointing. On the other hand if incremental checkpointing does not pay off decreasing the Delta Checkpoint Number would alleviate the negative impact to application runtime. In the case where the operator state is changed completely between two checkpoints the Delta Checkpoint Number can be set to 0 and change tracking be disabled to fall back the baseline i.e. full state checkpointing. Regarding the second trade off the worst case restoration cost is for restoring the last delta checkpoint the Ddelta checkpoint so the worst case restoration cost can be bounded by capping the Delta Checkpoint Number D.

In the method also referred to as the adjustD function includes a first step at of determining whether a given specified number of consecutive base checkpoints has been taken. If a number of base checkpoints has been taken then at the process enables change tracking and returns a positive number for parameter D at . Returning to if it is determined that there has not been performed the given number of consecutive base checkpoints then the process proceeds to where a determination is made as to whether the delta checkpoint is smaller or faster than the base checkpoint. In one embodiment this determination ensures that the following inequality holds Base comp Delta comp log That is Base Delta log where TckptBase is the time duration parameter for performing a full operator state checkpoint Tlog is the time duration parameter representing the time it takes to log the changes to operator state data and TckptDelta is the time duration parameter for checkpointing only logged changes to operator state data. In one embodiment there may be used measured historical checkpoint time sizes to determine the values for TckptBase Tcomp TckptDelta and Tlog parameter values as measured and collected at and .

As an example to determine a value D the method performs estimating of TckptBase and TckptDelta Tlog based on measured timing results of previous checkpoints. For example TckptBase is estimated as the latest base checkpoint time TckptDelta is a weighted average time of delta checkpoint times and Tlog TckptDelta ratio e.g. ratio 10 in one implementation. With estimated TckptBase and Tlog TckptI it can be determined if incremental checkpointing is beneficial and if so increase D to a larger value at otherwise decrease D to a smaller value at .

In one embodiment checkpoint size instead of checkpoint time may be used to determine whether incremental checkpointing is beneficial. The method may compare weighted average size of recent delta checkpoints with the size of the latest base checkpoint at step . The average delta checkpoint size may be enlarged by some extent e.g. 10 in the comparison at step . The enlarged portion is to account for the cost of logging. To balance the trade off between reducing checkpointing cost vs. increasing overhead to normal computation the total cost of taking a delta checkpoint and tracking changes should be smaller than the cost of checkpointing full state. In one embodiment the average delta checkpoint size may be enlarged by 10 meaning that the cost of logging is estimated to be 10 of checkpointing the changes. This is an over estimation as tracking changes to in memory state is much faster than writing checkpoint to storage. Such over estimation helps ruling out cases with marginal return in applying incremental checkpointing. By assessing the benefit of incremental checkpointing at the algorithm covers the first trade off in 0040 .

For example returning to with respect to obtaining base and delta checkpoint time size parameter values the stream processing system at runtime is configured to measure checkpoint time size of base checkpoints and delta checkpoints in time period between two consecutive base checkpoints and . The decision regarding how to adjust the parameter D is made at as part of taking a new base checkpoint. The measured time of previous base and delta checkpoints may be used to decide if incremental checkpointing is beneficial. The runtime environment will measure checkpoint times sizes to obtain a history of base and delta checkpoint times sizes.

Returning to . if the delta checkpoint size is smaller and or speedier in time to take than the base checkpoint size and speed the process proceeds to in order to increase the parameter D so that more delta checkpoints will be taken. Subsequently at the value of D is adjusted in order to bound the restoration cost. That is D is adjusted to ensure that the worst case restoration cost is kept to an acceptable level. Then at the value of D is returned to the checkpointing component running the incremental checkpointing algorithm in .

In one embodiment the algorithm bounds the restoration cost by capping the Delta Checkpoint Number D at as follows. It may use the average delta checkpoint size and base checkpoint size to calculate the maximum number of consecutive delta checkpoints whose total size does not exceed a configured ratio of a base checkpoint size. That is the total size of delta checkpoints may be specified as not exceeding a ratio e.g. 1 of a base checkpoints. For example assume the average delta checkpoint size is 100 Bytes and the current base checkpoint is 400 Bytes. With a given ratio of 1.5 the total size of consecutive delta checkpoints in this example should be no larger than 400 1.5 600 Bytes. So the Delta Checkpoint Number D should be no larger than a value 600 100 6. The adjustD method ensures the new Delta Checkpoint Number does not exceed this maximum value at step . By setting the ratio between a full checkpoint and aggregated size of consecutive delta checkpoints one can bound the worst case restoration cost with respect to the baseline restoration cost i.e. the cost to restore a full checkpoint .

In another embodiment there may be specified a maximum value for Delta Checkpoint Number D e.g. there can be at most 5 consecutive delta checkpoints . Then at the value of D is compared with the specified maximum value and the smaller of the two is used as the new value of D to be returned at .

In a further embodiment there may be specified a hard limit on the worst case restoration time e.g. 1.0 second . The worst case restoration time TR is the total time of reading a base checkpoint plus reading and applying all D delta checkpoints. base checkpoint delta checkpoint 1 delta checkpoint 2 . . . delta checkpoint where TR base checkpoint is the time for restoring a base checkpoint and quantity TR delta checkpoint i is the restoration time for restoring the i th delta checkpoint. In one embodiment those times can be estimated by using measured historical checkpoint times. For example as the checkpoint time TckptBase is already known for the base checkpoint there is estimated a value base checkpoint Base 1.2. where the time to restore a base checkpoint i.e. TR base is estimated to be 1.2 times of the time to take a base checkpoint TckptBase . For most checkpoint data stores the read performance is actually faster than write performance e.g. during checkpointing data may be written to multiple replicas but during restoration only one copy is read back . Therefore such estimation is over estimation and conservative.

Similarly the average time to restore a delta checkpoint may be estimated by using the average checkpoint time of recent delta checkpoints e.g. average delta average Delta 1.2.

In one embodiment if user provides via an interface an upper bound of restore time e.g. TRmax then there is calculated maximum value of D Dmax by solving the following inequality Base 1.2max average Delta 1.2max.

Returning to step if it is determined that the delta checkpoint size is not smaller nor speedier in time to take than the base checkpoint then the process proceeds to where the number D is decreased. Then at a determination is made as to whether the current value of D is zero. If the current value of D is not zero the method proceeds to where the value of D is returned to the checkpointing component running the incremental checkpointing algorithm in . Otherwise if at it is determined that the current value of D is zero then change tracking is disabled at and then the current value of D is returned at .

As mentioned in cases incremental checkpointing is not beneficial the algorithm in decreases the Delta Checkpoint Number at and eventually sets it to zero. Since then change tracking is disabled at and the operator is checkpointed in full form. However as the change pattern of operator state evolves over time incremental checkpointing may later become beneficial. To cope with this situation the algorithm enters a probing mode once the Delta Checkpoint Number becomes zero. In one embodiment the algorithm starts counting the number of full checkpoints and once it is determined that it reaches a threshold e.g. full checkpoints in a row at it resets the Delta Checkpoint Number to a positive number at and re enables change tracking at to force the next checkpoint to be a delta checkpoint. This way the system can obtain the size of a delta checkpoint and upon the base checkpoint after the delta checkpoint it can assess based on recent statistics whether incremental checkpointing has become beneficial at . If so it further increases the Delta Checkpoint Number at Otherwise it decreases the Delta Checkpoint Number to zero again at and disables change tracking at and the operator falls back to making full checkpoints until the next probing point.

The algorithm of is adaptive to dynamics in the change pattern of operator state. In one embodiment it adapts to dynamics in the change patterns of the same operator over time and adapts to different operators within the same application. Incremental checkpointing techniques herein exploit the change pattern in operator s state and apply incremental checkpointing when it s beneficial. It may further turn off logging and incremental checkpointing when it s not beneficial. Additionally it may adjust the Delta Checkpoint Number to respect a user specified restoration cost limit. Its adaptiveness not only helps improving application performance but saves users the burden of manual tuning.

The overhead of the algorithm shown in is negligible. The algorithm is invoked every time an operator is checkpointed. The time complexity of each invocation is constant and can be omitted with respect to the time to write checkpoint to storage. The size of each checkpoint can be obtained via consulting the data serialization facility after the operator state has been serialized and incurs negligible overhead. For each operator the algorithm keeps a small amount of information i.e. he weighted average of delta checkpoint size and the number checkpoints made since last base checkpoint so the memory overhead is negligible.

In deleting an old checkpoint it must be ensured that the dependency is maintained. The runtime methods keep identifiers sequence numbers of the latest base checkpoint and delta checkpoints performed so far and delete incremental checkpoints in a delayed fashion. That is the runtime method deletes old checkpoints to respect the dependency between checkpoints. It maintains a record of checkpoint sequence numbers since last base checkpoint and deletes those checkpoints after a new base checkpoint is taken.

In one embodiment to delete an old checkpoint from the checkpoint data store there is first determined whether there is any subsequent delta checkpoint which depends on the checkpoint to be deleted. If there is any dependent checkpoint the method marks the given checkpoint as to be deleted and maintains marks either in deleting program s local memory or in the local operator memory. If there is no dependent checkpoint deleting the given checkpoint. In addition there is performed checking if the previous checkpoints on which the given checkpoint is dependent are all marked as to be deleted . If so deleting all those checkpoints.

There is further provided a method to organize incremental checkpoints in a key value store. This method is applicable to many key value stores and achieves high I O and storage efficiency.

To achieve generality data organization according to the methods herein is based on an abstract key value store model. It is assumed a key value store has a two level name space. At the higher level is a set of store entries each of which is uniquely identified by a name. Each store entry itself is a set of key value pairs. Within a store entry each key value pair consists of a unique key which is a byte string and a value which is also a byte string. The size of a value is subject to certain maximum limit. A user can create and delete a store entry by its name and put get and delete a key value pair within a given store entry. Such a key value store abstraction can be easily implemented on top of many existing key value stores such as with several example KV stores from Redis is a networked key value store. It provides rich data types and the value of a key value pair can be a byte string a hash table or a list etc. The abstract key value store model may be realized on top of Redis by storing a store entry as a Redis hash table named by the store entry name. Putting getting and deleting a key value pair within a store entry can be implemented by the Redis HSET HGET and HDEL commands with the key value pair on the store entry s hash table respectively. The size limit of a value is 512 MB in Redis .

LevelDB is an embedded key value store Leveldb is a trademark of Google Inc. . Unlike Redis LevelDB supports byte string as value. The abstract key value store model can be realized with LevelDB by storing each store entry as a separate LevelDB database in a common directory. The key value pairs within a store entry are saved as key value pairs in the corresponding LevelDB database and the put get and delete operations can directly map to LevelDB s Put Get and Delete APIs. LevelDB does not limit the value size so a size limit can be configured to an arbitrary number.

In one embodiment an approach to organize checkpoints in the abstract key value store model is to create a store entry for each operator and store each checkpoint as a key value pair whose key is a checkpoint sequence number and value is the serialized operator state. However this is not sufficient for a checkpoint which exceeds the size limit of a single value.

To store an arbitrarily large key value pair under the constraint of value size limit a large value is broken into multiple chunks that fit within the size limit and store the original key value pair as multiple key value pairs. For a key value pair whose value is of size M the value is broken into chunks of size C. The chunk size C may be a configurable parameter for each key value pair upon its insertion into the store entry. The original value is then broken into M C chunks. The it chunk is keyed by

Besides a key value pair termed chunk header is added. Chunk header s key is originalKey H . Its value is a concatenation of three integers the chunk size last chunk s index and last chunk s size.

Operator state to checkpoint is usually a set of in memory variables. When changes are tracked and checkpointed at the variable level the dependency between checkpoints drills down to the individual variables.

When restoring a variable that variable s own dependency chain is followed to find related checkpoints. To record the dependency between checkpoints there is built additional index data and store the index alongside the serialized checkpoint data.

In one embodiment in each checkpoint all the non incrementally checkpointed variables e.g. data1 and data2 in may be serialized and concatenated into one byte string and form a key value pair whose value is the concatenated byte string. The key to the key value pair may be a string in the form of checkpointSequenceNumber NON e.g. 1 NON in Checkpoint1 and 2 NON in Checkpoint 2 in . All the incrementally checkpointed variables e.g. data3 data4 and data5 in may be serialized and concatenated into a separate byte string and form a key value pair with the value being the concatenated byte string and the key being checkpointSequenceNumber e.g. 1 INCR in Checkpoint 1 and 2 INCR in Checkpoint 2 in . For each incrementally checkpointed variable there may be stored additional index data and all the index data are serialized and concatenated into a third byte string and form a key value pair whose key is checkpointSequenceNumber INDEX e.g. 1 INDEX in Checkpoint 1 and 2 INDEX in Checkpoint 2 in . Each variable s index has at least two fields i type indicator whether the variable is in base or delta form ii offset of the serialized variable in the byte string of checkpointSequenceNumber INCR . If the variable is in delta form the index further contains iii Sequence number of the checkpoint which contains the previous version of the variable iv offset of the index entry in the previous checkpoint s index key value pair. Fields iii and iv are used to traverse the dependency chain of the variable and retrieve all previous versions until the base version.

Thus for the example incremental checkpoint at Checkpoint 1 of variable data4 there may be stored additional index data including a corresponding indicator as data4 being in base or delta form e.g. Base an offset value e.g. Offset in checkpointSequenceNumber INCR e.g. 1 INCR having a value of 0 which indicates the starting position of serialized variable data4 in the checkpointSequenceNumber INCR serialized byte string e.g. the offset of data4 in 1 INCR is 0 .

For the next example checkpoint Checkpoint 2 shows stored the first two variables data1 and data2 again as not being incrementally checkpointed but are serialized into the 2 NON key value pair. Variable data3 is checkpointed in base form in Checkpoint 2 and variable data4 is checkpointed in delta form in Checkpoint 2. Both data3 and data4 are serialized into the 2 INCR key value pair. Furthermore shows the index data having additional index data for the incrementally checkpointed variables e.g. data3 and data4 . For the variable data4 index data shows a corresponding indicator for this variable data as being in Delta form in Checkpoint 2 an Offset in 2 INCR indicating the starting position of serialized variable data4 in the serialized byte string keyed by 2 INCR e.g. a value of K bytes as shown by arrow in sequence number of previous dependent checkpoint e.g. a value of 1 indicating data4 in Checkpoint 2 is the changes made to data4 since Checkpoint 1 and the index offset of a previous dependent checkpoint as 0 as index of data4 in Checkpoint 1 is at the position 0 in the value of 1 INDEX key value pair .

Thus when an operator state is checkpointed all the variables in operator state are serialized into internal memory buffers in the checkpointing component and data of different types are serialized into different buffers and transferred to the checkpoint data store as key value pairs and the checkpointing component internally maintains the sequence numbers of base and delta checkpoints and automatically generates index data for those incrementally checkpointed variables.

When restoring operator state from a given checkpoint variables are deserialized in the same order of checkpointing so the index data of the given checkpoint are scanned in sequential order. For each variable being restored the current index is consulted. First the restoration method decides whether the variable is in base or delta form in current checkpoint. If it is in base form the serialized variable is located according to the starting offset recorded in index Field ii and the variable is deserialized from it. If it is in delta form the index Fields iii and iv are used to traverse all previous index entries and use those index entries to locate and retrieve the previous versions of the variables and merge them locally to restore the variable.

In a restoration operation 1 shows the restoring of the non incrementally checkpointed first and second data variables data1 data2 directly from Checkpoint 3. Then the restoration operation proceeds to the third data variable data3 at 2 where data3 is shown as being in delta form in Checkpoint 3. Then at 3 there is reading of the index data in a previous dependent delta checkpoint Checkpoint 2 and based on the index information which records the offset position of serialized data3 in the 2 INCR key value pair at 4 there is reading and deserializing the base form of data3 from the 2 INCR key value pair in Checkpoint 1. The method traces back to operation 5 reading deserializing and re applying delta checkpoints to data3 taken at Checkpoint 3 which restores the variable data3 to the state when Checkpoint 2 was taken. The restoration operation then proceeds to 6 restore the fourth variable data4 in a similar manner as variable data3 .

Further embodiments for checkpointing optimizations are available. One further embodiment includes a reducing of the Indexing Cost As an example implementation of an index entry that would consume 1 8 9 Bytes for base and 1 8 8 8 25 Bytes for a delta. If the checkpointed variable size is small especially when it is in delta form the index overhead can be substantial. The index entry size may be reduced by using a variable length encoding format.

In a further embodiment the index data may be reduced by first organizing the index fields in a column oriented format and then compressing the fields. The same field of different index data is aligned together as a column resulting in four columns for Fields i to iv respectively. For example in Checkpoint 2 shown in the index contains index data for two variables data3 and data4 . illustrates that in the column oriented format Field i of the two indices are aligned together to form Column i Field ii of the two indices are aligned together to form Column ii and so are Field iii and Field iv. Then each column may be compressed by using certain compression method such as run length encoding.

A further embodiment includes avoiding waste in restoring non incrementally checkpointed data. This may be done by classifying the checkpointed variables into incremental and non incremental data based on how the data is restored. Restoring incremental data requires merging the versions in base and delta checkpoints while non incremental data is always checkpointed in full form and can directly restore from the latest checkpoint. As an example suppose an operator has three variables to checkpoint. The first is a sliding window the second is an integer counter and the third is a hash table from a legacy library which only provides interfaces to serialize and deserialize the hash table in full form. When the sliding window is checkpointed it saves the full window in a base checkpoint and saves only the changed portion in each delta checkpoint. When restoring the sliding window from the latest delta checkpoint it fetches the checkpointed window data in the base checkpoint and all related delta checkpoints and merge them. On the other hand when the counter is checkpointed in one embodiment it always saves the counter value in checkpoint no matter whether it is a base or delta checkpoint. Upon restoring the counter from the latest delta checkpoint it can directly restore the value saved in that delta checkpoint there is no need to retrieve and merge older values. Similarly since the hash table can only be checkpointed in full form it can be restored just from the version in the latest checkpoint.

Those non incremental data may be restored in the same way as incremental data by retrieving all versions and merging them via over writing older versions in time order if such retrieval and merge efforts is not costly. The incremental and non incremental data of a checkpoint can be stored into separate key value pairs to distinguish them and avoid the waste. For a checkpoint with sequence number K all the serialized non incremental data are concatenated into a byte string and keyed by K NON all the serialized incremental data are concatenated into another byte string and keyed by K INCR . The incremental data is indexed by a third KV pair K INDEX . By storing all non incremental data in a separate key value pair the data access path involving index may be bypassed and the non incremental data restored directly from the latest checkpoint. Besides this separated storage reduces index cost compared to an alternative approach which still stores non incremental data together with incremental data but uses a flag in each variable s index entry for distinction. With the separated storage deletion of a checkpoint can be more aggressive the non incremental data can be deleted without delay but the incremental data could be deleted lazily.

A further optimization may include use of buffering to speed up a restoration e.g. restoring a variable may require reading index and data from multiple checkpoints. The checkpoint data and index are read in chunks. Since variables are restored in the same order as checkpointing the index and data chunks fetched for one variable is likely to be read soon for the next variable. Buffering may be used to exploit this locality and speed up restoration any chunk fetched during restoration is kept in memory and only reclaimed when the intended read offset passes the chunk boundary or restoration is complete.

The present invention may be a system a method and or a computer program product. The computer program product may include a computer readable storage medium or media having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.

The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be for example but is not limited to an electronic storage device a magnetic storage device an optical storage device an electromagnetic storage device a semiconductor storage device or any suitable combination of the foregoing. A non exhaustive list of more specific examples of the computer readable storage medium includes the following a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory a static random access memory SRAM a portable compact disc read only memory CD ROM a digital versatile disk DVD a memory stick a floppy disk a mechanically encoded device such as punch cards or raised structures in a groove having instructions recorded thereon and any suitable combination of the foregoing. A computer readable storage medium as used herein is not to be construed as being transitory signals per se such as radio waves or other freely propagating electromagnetic waves electromagnetic waves propagating through a waveguide or other transmission media e.g. light pulses passing through a fiber optic cable or electrical signals transmitted through a wire.

Computer readable program instructions described herein can be downloaded to respective computing processing devices from a computer readable storage medium or to an external computer or external storage device via a network for example the Internet a local area network a wide area network and or a wireless network. The network may comprise copper transmission cables optical transmission fibers wireless transmission routers firewalls switches gateway computers and or edge servers. A network adapter card or network interface in each computing processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing processing device.

Computer readable program instructions for carrying out operations of the present invention may be assembler instructions instruction set architecture ISA instructions machine instructions machine dependent instructions microcode firmware instructions state setting data or either source code or object code written in any combination of one or more programming languages including an object oriented programming language such as Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The computer readable program instructions may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider . In some embodiments electronic circuitry including for example programmable logic circuitry field programmable gate arrays FPGA or programmable logic arrays PLA may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry in order to perform aspects of the present invention.

Aspects of the present invention are described herein with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer readable program instructions.

These computer readable program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer a programmable data processing apparatus and or other devices to function in a particular manner such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function act specified in the flowchart and or block diagram block or blocks.

The computer readable program instructions may also be loaded onto a computer other programmable data processing apparatus or other device to cause a series of operational steps to be performed on the computer other programmable apparatus or other device to produce a computer implemented process such that the instructions which execute on the computer other programmable apparatus or other device implement the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of instructions which comprises one or more executable instructions for implementing the specified logical function s . In some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.

Processor unit serves to execute instructions for software that may be loaded into memory . Processor unit may be a set of one or more processors or may be a multi processor core depending on the particular implementation. Further processor unit may be implemented using one or more heterogeneous processor systems in which a main processor is present with secondary processors on a single chip. As another illustrative example processor unit may be a symmetric multi processor system containing multiple processors of the same type.

Memory and persistent storage are examples of storage devices . A storage device is any piece of hardware that is capable of storing information such as for example without limitation data program code in functional form and or other suitable information either on a temporary basis and or a permanent basis. Memory in these examples may be for example a random access memory or any other suitable volatile or non volatile storage device. Persistent storage may take various forms depending on the particular implementation. For example persistent storage may contain one or more components or devices. For example persistent storage may be a hard drive a flash memory a rewritable optical disk a rewritable magnetic tape or some combination of the above. The media used by persistent storage may be removable. For example a removable hard drive may be used for persistent storage .

Communications unit in these examples provides for communication with other data processing systems or devices. In these examples communications unit is a network interface card. Communications unit may provide communications through the use of either or both physical and wireless communications links.

Input output unit allows for the input and output of data with other devices that may be connected to data processing system . For example input output unit may provide a connection for user input through a keyboard a mouse and or some other suitable input device. Further input output unit may send output to a printer. Display provides a mechanism to display information to a user.

Instructions for the operating system applications and or programs may be located in storage devices which are in communication with processor unit through communications fabric . In these illustrative examples the instructions are in a functional form on persistent storage . These instructions may be loaded into memory for execution by processor unit . The processes of the different embodiments may be performed by processor unit using computer implemented instructions which may be located in a memory such as memory .

These instructions are referred to as program code computer usable program code or computer readable program code that may be read and executed by a processor in processor unit . The program code in the different embodiments may be embodied on different physical or computer readable storage media such as memory or persistent storage .

Program code is located in a functional form on computer readable media that is selectively removable and may be loaded onto or transferred to data processing system for execution by processor unit . Program code and computer readable media form computer program product . In one example computer readable media may be computer readable storage media or computer readable signal media . Computer readable storage media may include for example an optical or magnetic disc that is inserted or placed into a drive or other device that is part of persistent storage for transfer onto a storage device such as a hard drive that is part of persistent storage . Computer readable storage media also may take the form of a persistent storage such as a hard drive a thumb drive or a flash memory that is connected to data processing system . In some instances computer readable storage media may not be removable from data processing system .

Alternatively program code may be transferred to data processing system using computer readable signal media . Computer readable signal media may be for example a propagated data signal containing program code . For example computer readable signal media may be an electro magnetic signal an optical signal and or any other suitable type of signal. These signals may be transmitted over communications links such as wireless communication links an optical fiber cable a coaxial cable a wire and or any other suitable type of communications link. In other words the communications link and or the connection may be physical or wireless in the illustrative examples. The computer readable media also may take the form of non tangible media such as communications links or wireless transmissions containing the program code.

In some illustrative embodiments program code may be downloaded over a network to persistent storage from another device or data processing system through computer readable signal media for use within data processing system . For instance program code stored in a computer readable storage media in a server data processing system may be downloaded over a network from the server to data processing system . The data processing system providing program code may be a server computer a client computer or some other device capable of storing and transmitting program code .

The different components illustrated for data processing system are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to or in place of those illustrated for data processing system . Other components shown in can be varied from the illustrative examples shown. The different embodiments may be implemented using any hardware device or system capable of executing program code. As one example data processing system may include organic components integrated with inorganic components and or may be comprised entirely of organic components excluding a human being. For example a storage device may be comprised of an organic semiconductor.

As another example a storage device in data processing system is any hardware apparatus that may store data. Memory persistent storage and computer readable media are examples of storage devices in a tangible form.

In another example a bus system may be used to implement communications fabric and may be comprised of one or more buses such as a system bus or an input output bus. Of course the bus system may be implemented using any suitable type of architecture that provides for a transfer of data between different components or devices attached to the bus system. Additionally a communications unit may include one or more devices used to transmit and receive data such as a modem or a network adapter. Further a memory may be for example memory or a cache such as found in an interface and memory controller hub that may be present in communications fabric .

The descriptions of the various embodiments of the present invention have been presented for purposes of illustration but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the one or more embodiment the practical application or technical improvement over technologies found in the marketplace or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.

