---

title: Immersive telepresence
abstract: In general, the immersive telepresence implementations described herein allow desired telepresence experiences of users or telepresence travel participants to be automatically matched with travel volunteers that can provide these telepresence experiences. The mobile computing devices of the travel volunteers provide audio, video and other data to the travel participant so that the travel participant can experience the sights and sounds of a desired telepresence experience (which can include location and time, as well as a desired activity) without the travel participant physically being present. The immersive telepresence implementations described herein automatically find matches between telepresence experiences on a list (e.g., bucket list) of a travel participant and one or more travel volunteers and provide for various features to provide an immersive and personalized telepresence experience for the travel participant.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09591260&OS=09591260&RS=09591260
owner: Microsoft Technology Licensing, LLC
number: 09591260
owner_city: Redmond
owner_country: US
publication_date: 20151203
---
There are various scenarios where a person may want to view a far away locale but may not be able to do so themselves. For example many older or disabled people are homebound or confined to a hospital bed making it impossible for them to travel to locations they wish to see or participate in experiences they wish to experience. As another example natural disasters such as floods fires and earthquakes often make it difficult for rescue personnel to enter a given location because roads are impassible or there is no ingress available to remote locations. Similarly in armed conflicts or scenes of terrorist acts it is often impossible for groups of people to enter the location of conflict or crime because it is not possible to freely move personnel into the area.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

In general the immersive telepresence implementations described herein allow desired telepresence experiences of users or telepresence travel participants sometimes called travel participants herein to be automatically matched with travel volunteers that can provide these telepresence experiences. The mobile computing devices of the travel volunteers provide audio video and other data to the travel participant so that the travel participant can experience the sights and sounds of a desired telepresence experience which can include location and time as well as a desired activity without the travel participant physically being present. The immersive telepresence implementations described herein automatically find matches between telepresence experiences on a list e.g. bucket list of a travel participant and one or more travel volunteers and provide for various features to provide an immersive and personalized telepresence experience for the travel participant. These features can include for example allowing the travel participant to take snap shots of the telepresence experience creating a scrapbook or photo album of these snap shots allowing the travel participant to take a picture of themselves appearing to be within the telepresence experience and automatically searching for information about the telepresence experience using implicit contextualized queries among others.

In the following description of immersive telepresence implementations reference is made to the accompanying drawings which form a part thereof and which show by way of illustration examples by which implementations described herein may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the claimed subject matter.

The following sections provide an overview of the immersive telepresence implementations an exemplary environment in which immersive telepresence implementations described herein can be implemented as well as exemplary systems a process and user interfaces for practicing these implementations.

As a preliminary matter some of the figures that follow describe concepts in the context of one or more structural components variously referred to as functionality modules features elements etc. The various components shown in the figures can be implemented in any manner. In one case the illustrated separation of various components in the figures into distinct units may reflect the use of corresponding distinct components in an actual implementation. Alternatively or in addition any single component illustrated in the figures may be implemented by plural actual components. Alternatively or in addition the depiction of any two or more separate components in the figures may reflect different functions performed by a single actual component.

Other figures describe the concepts in flowchart form. In this form certain operations are described as constituting distinct blocks performed in a certain order. Such implementations are illustrative and non limiting. Certain blocks described herein can be grouped together and performed in a single operation certain blocks can be broken apart into plural component blocks and certain blocks can be performed in an order that differs from that which is illustrated herein including a parallel manner of performing the blocks . The blocks shown in the flowcharts can be implemented in any manner.

A travel participant travel volunteer matching module that runs on or in conjunction with the server computing cloud automatically matches the desired telepresence experiences from a list e.g. of a telepresence travel participant with one or more travel volunteers using information extracted from the mobile computing devices of the travel volunteer and the travel participant . Details of the matching will be described in greater detail later.

When the travel participant wishes to participate in an immersive telepresence experience the travel participant can generate a list of telepresence experiences e.g. places times activities the travel participant would like to experience. The travel participant can specify an activity e.g. hang gliding visiting the Eiffel tower a geographic location and can also specify time either specifically or generally for example that they would like to see the sunset over Rio. The telepresence experiences on the list are matched to a travel volunteer by using information extracted from an associated mobile device and also other information. The matching of the experiences on the list to a travel volunteer is performed by using the matching module . e.g. on the server computing cloud . For example this matching can be performed by using calendar information of each of the travel volunteers and the geographic location of each of the travel volunteers as well as the profile information of the travel participant and the travel volunteers . The calendar and location information can be extracted from the mobile devices of the travel volunteers. Travel volunteers can also fill out profiles with interests and hobbies for experience matching. Detailed calendar data can be pulled from the volunteer s mobile computing device and keywords in appointments can be matched to keywords in desired experiences. Some volunteer activities can also be inferred based on social media check ins at certain locations or geolocation provided by a volunteer s mobile computing device or location provided by certain services i.e. the volunteer is at the coordinates for a hang gliding store so it can be inferred that the volunteer is about to hang glide. In some implementations travel participants can manually initiate matches. For example after filtering potential matches with some basic constraints e.g. general available times language etc participants can browse and select from a list of potential telepresence experiences activities or travel participant travel volunteer match ups.

Once the matched travel volunteer is at the location of the place on the list that the travel participant wishes to visit or the travel volunteer is ready to start the experience the travel participant wishes to participate in the travel volunteer begins a travel session wherein the travel volunteer streams video associated audio communications data and possibly other data from the travel volunteer s mobile device over the network to the travel participant via the server computing cloud so that the travel participant can vicariously experience the sights and sounds of the desired location activity without actually being physically present. In some implementations the audio video data can be sent directly from the travel volunteer to the travel participant without going through the server computing cloud .

In some implementations the computing device of the travel participant and the computing devices of the travel volunteers have an application not shown on their respective computing devices that allow for the travel participant and the travel volunteers to participate in the telepresence experiences and to communicate with each other over a network. This allows the travel participant to request changes in a telepresence experience in real time and allows the travel participant to provide information to a travel volunteer. The application provides many features that enhance the telepresence experience for both the travel participant and the travel volunteers. Some of the features to increase immersiveness of the telepresence experience for the travel participant can include 1 the ability for the travel participant to take snap shots of the telepresence experience for example by using a camera button to take a still photo during the streaming video 2 the ability to create a photo album of a telepresence experience 3 the ability for the travel participant to superimpose imagery from the streaming video beyond them to create an image e.g. that can be shared on social media of them enjoying their virtual trip 4 the ability to automatically search for information about the telepresence experience for example via a pane displayed to the travel participant containing implicitly fetched search results displayed to the travel participant that can supplement the travel participant s knowledge of the location of the telepresence experience and also provide them with insightful information that they may wish to share with the travel volunteer. Queries to find such search results can be triggered by metadata such as any human typed name for the session or list item e.g. the favelas of Rio the geo location being reported by the mobile phone of the travel volunteer or live speech to text translation of any commentary from the travel volunteer supplemented by entity extraction. In one implementation the implicit query pane provides a combination of images text derived from an online document social media posts and maps that are relevant to the target location and topics. These features will be described in greater detail later.

One exemplary system for providing immersive telepresence according to the immersive telepresence implementations described herein comprises one or more computing devices connected by one or more networks and a computer program that has a plurality of sub programs executable by the one or more computing devices. The one or more computing devices are directed by the sub programs of the computer program to receive a list of telepresence experiences a telepresence travel participant wishes to experience match a telepresence experience from the list with a travel volunteer using location and or calendar information retrieved from a mobile computing device of the travel volunteer receive video and associated audio of the matched telepresence experience from the mobile computing device of the travel volunteer over a network and output the received video and associated audio to the telepresence travel participant using immersive features.

Another exemplary system for providing immersive telepresence according to the immersive telepresence implementations described herein comprises one or more computing devices connected by one or more networks and a computer program having a plurality of sub programs executable by the one or more computing devices that receive a list of desired telepresence experiences for a telepresence travel participant to visit match a telepresence experience from the list with the location of a travel volunteer at a point in time using calendar information retrieved from a computing device of the travel volunteer receive video and associated audio of the matched telepresence experience from the travel volunteer over a network and output the received video and associated audio of the matched place to the telepresence travel participant. This implementation is advantageous in that it allows a travel participant and a travel volunteer to arrange for an immersive telepresence experience for a time in the future.

One exemplary process for providing immersive telepresence according to the immersive telepresence implementations described herein comprises using one or more computing devices for defining a list of telepresence experiences for a telepresence travel participant to experience matching an telepresence experience from the list with a location of a travel volunteer using calendar information and geographic location on the travel volunteer s mobile computing device receiving a notice from a travel volunteer that the travel volunteer is able to capture video and audio of the matched telepresence experience receiving a response to the notice that the telepresence travel participant would like to receive video and audio of the matched place and sending video and associated audio of the matched telepresence experience from the mobile computing device of the travel volunteer over a network to the travel participant. In some implementations the list of places can be created by a third party instead of a travel participant.

The immersive telepresence implementations described herein are advantageous in that they can provide real time personalized immersive experiences for home bound or disabled users in which the user can request a travel volunteer to show them places and experiences that they otherwise might not experience. Additionally the implementations described herein automatically match a travel participant with a travel volunteer by using location information extracted from the travel volunteers calendar or geographic location extracted from a mobile computing device of the travel volunteer as well as by using profile information of the user and the travel volunteer. Furthermore the immersive telepresence implementations described herein provide many features that allow the user to be immersed in a telepresence experience such as for example by taking a still picture photo of the place they are viewing by automatically creating a scrapbook of such pictures taking a photo of themselves in the place they are virtually visiting and by automatically obtaining information about the location or experience by receiving results in response to automatically submitted context implicit queries e.g. initiated based on conversations between the travel participant and the travel volunteer title of the travel session between the travel participant and the travel volunteer or other meta data derived from the experience . The travel participant can also share these search results with the travel volunteer to make the telepresence experience more informative and enjoyable for both of them.

The immersive telepresence implementations described herein can also have applications in natural disasters or military conflicts where it might be difficult to place people at desired locations so that existing personnel in these locations may be used to provide situation reports. For example travel volunteers can be automatically matched to locations in areas where natural disasters have occurred and these travel volunteers that are already in place can capture and provide video audio and other data of their surroundings so that assessments can be made and appropriate aid can be provided.

An overview of various immersive telepresence implementations having been provided the following sections provide exemplary systems a process and user interfaces for practicing various immersive telepresence implementations.

In one implementation the travel participant generates a list of telepresence experiences that the telepresence travel participant wishes to experience. This list can be generated by specifying the activities locations and possibly times of the telepresence experiences that the travel participant wishes to experience. For example the travel participant can specify that they would like to see Manhattan Beach at sunrise or that they would like to take in the view from the Eiffel Tower in spring. One can sort or filter the list in many ways e.g. by location by season by activity type by recency of an entry to the list etc. Each request to be entered on the list can be generated using a template some components of which may be left blank if they are not relevant. Template items can include date range time range location activity type and custom notes. There can also be a take me on an adventure option which gives the travel volunteer complete freedom to select an activity from a predetermined list. The travel participant can prioritize the list to state which items they would like to experience more than others. For example the travel participant can mark priority experience with a star to indicate it is a favorite activity.

The travel participant can also generate a user profile in which he or she can specify various pertinent information such as for example the language the travel participant speaks their name information about their background or situation their age their occupation and so forth. Likewise the travel volunteers can specify similar profile information about themselves. These travel participant or travel volunteer profiles can be stored in a profile database and used by a matching module to assist in matching the experiences on the list that the travel participant wishes to experience with a travel volunteer .

In some implementations the matching module on the server computing cloud matches a telepresence experience e.g. activity location possibly time from the list of telepresence experiences the telepresence travel participant wishes to experience with the location time of a travel volunteer . This can be done using some or all of the location data as well as calendar information retrieved from of the mobile computing device of one or more of the travel volunteers and the profile information of the travel participant and the travel volunteers. For example a location on the travel participant s list is matched to a location and optionally time in the travel volunteer s calendar e.g. by accessing information such as travel itineraries scheduled trips and so forth on a travel volunteer s mobile computing device or to the present location of the travel volunteer. Future planned trips of the travel volunteer extracted from the calendar can be used to plan a trip with the travel participant. Alternately the present location of the travel volunteer can be matched with a place on the list. For example the geographic location of the mobile computing device as measured by a Global Positioning System GPS on the device or other means can be used to match the location of the travel volunteer to a location on the travel participant s list . Additionally the profile information can be used to better match a telepresence experience of a travel participant with a travel volunteer for example by matching a travel participant and a travel volunteer that speak the same language. Or the profile information can be used to match a travel participant with a travel volunteer that has the same interests or occupation or other attribute in common. Key words in the travel participant s travel volunteer s profile and proposed activity descriptions can be used to perform the automatic matching. In some implementations the travel participant and or travel volunteer are asked to provide scheduling constraints before a match is suggested. A travel volunteer s mobile device s GPS location can also trigger a notification of location specific experiences in which travel participants may wish to partake. In some immersive telepresence implementations the matching module allows a travel participant to browse a list of available telepresence experiences and manually match a telepresence experience on the list with a travel volunteer. Furthermore in some immersive telepresence implementations a screening process or a rating system for travel participants and or travel volunteers can be used.

Once the travel volunteer is selected and is at the location and possibly the time e.g. sunrise sunset etc. of the desired telepresence experience and ready to perform the desired activity video and associated audio of the telepresence experience output from the mobile computing device can be sent over a network and then output to the telepresence travel participant . For example the video can be displayed on a display of the computing device located at the telepresence travel participant and the audio is output over one or more loudspeakers or headsets to the travel participant and possibly other travel participants that are sharing the travel experience with the travel participant . Other data can also be displayed on the display of the travel participant s computing device .

As discussed previously many features can be implemented to make the telepresence experience more immersive and more personalized for the travel participant. For example a snap shot module can be implemented on the computer computing cloud or on the computing device of the travel participant that allows the travel participant to take a snap shot of an image in the video stream that is streamed to the travel participant. In one implementation the travel participant can take a snap shot of an image of the video stream that is displayed to the travel participant by selecting a snap shot button on the user interface displayed to the travel participant from the display associated with the travel participant s computing device . This feature will be described in greater detail later.

Another feature that is available is a photo album or scrapbook album feature that automatically formats the snap shots taken by the travel participant into a scrapbook that the travel participant can share with others. Scrapbook processing can be performed in a scrapbook module on the server computing cloud or on the computing device of the travel participant . In some implementations snapshots or photos taken by the travel participant are automatically formatted into a scrapbook using templates. This photo album feature will be described in greater detail later.

Various telepresence implementations allow the telepresence travel participant to create an image or snapshot of themselves that displays the received video as a background behind the telepresence travel participant. This processing can be achieved by employing a participant in scene module . The snapshot can be sent or posted to a social media site or used in a variety of other ways that photographs or snapshots can be used. In some implementations live streaming video can be displayed behind the travel participant.

Yet another feature that is available to provide a more immersive and personalized telepresence experience is the automatic retrieval and display of search results related to the context of the telepresence experience. This feature can be implemented by using an implicit context search module . In one implementation a pane containing search results fetched in response to an implicit query is displayed to the travel participant. These search results can supplement the travel participant s knowledge of the location of the telepresence experience or the telepresence experience itself and also can provide insightful information that the travel participant may wish to share with the travel volunteer . The implicit query or queries can be triggered by metadata such as any human typed name for the session or list item e.g. the favelas of Rio the geo location being reported by the mobile computing device or live speech to text translation of any commentary from the travel volunteer possibly supplemented by entity extraction. In one implementation an implicit query pane displayed to the travel participant provides a combination of images text extracted from online encyclopedias or other documents social media posts and maps that are relevant to the target location and topics among others. This information can also be displayed and manipulated on the travel volunteers mobile computing devices via user interfaces . In some implementations queries to provide context information can be manually entered by the travel participant.

A list of telepresence experiences the telepresence travel participant wishes to experience is generated. This list can be generated by specifying the locations and possibly activities and times the travel participant wishes to experience. In some implementations this list is generated by a third party . The third party can prioritize the list to indicate which experiences are higher priority than others such as for example by numbering items on the list or indicating favorites with a star.

The travel participant or the travel volunteers can also generate user profiles in which they can specify various pertinent profile information.

A matching module on the server computing cloud matches a telepresence experience from the list with the location of a travel volunteer . This can be done by using the location of a mobile computing device of the travel volunteers and calendar or time information retrieved from the mobile computing devices of the travel volunteers as well as the profile information of the travel participant and the travel volunteers. A telepresence experience on the travel participant s list is matched to a location and optionally time and activity in the travel volunteer s calendar or time information e.g. by accessing information such as travel itineraries scheduled trips a clock on the device and so forth or to the present location of the travel volunteer. Future planned trips of the travel volunteer extracted from the calendar or provided by the travel volunteer can be used to plan a trip with the travel participant. Alternately the present location of the travel volunteer can be matched with a place on the list. For example the geographic location of the mobile computing device as measured by a Global Positioning System GPS or other method can be used to match the location of the travel volunteer to a location on the list. Additionally the profile information can be used to better match a travel participant with a travel volunteer for example by matching a travel volunteer to a place on the list based on the skills the travel volunteer has or some other attribute.

Once the travel volunteer is at the location on the list and possibly the time e.g. sunrise sunset etc. and ready to begin the telepresence session the travel volunteer can begin to stream audio video and other data from their mobile computing device to the travel participant s computing device over a network . The travel participant s computing device can receive this video associated audio and data and output it to a display and or loudspeakers . For example it is displayed on the display located at the telepresence travel participant and output over one or more loudspeakers or headsets to the travel participant and possibly other travel participants that are sharing the travel experience with the travel participant .

In addition to the features supported by the snapshot module the scrapbook module the participant in scene module and the context search module which operate in a manner as described with respect to this implementation can also include a real time map module that can display a real time map of the travel volunteer and or the telepresence experience to the travel participant using a real time map module . This real time map module can reside on the server computing cloud or on the travel participant s computing device . The map can enable the travel participant to contribute to the travel volunteer s experience for example by offering directions to specific locations or pointing out nearby attractions that the travel volunteer might not be aware of.

Various immersive telepresence implementations provide features which increase the immersiveness of the telepresence travel experience and personalize it for the travel participant. For example one feature allows the travel participant to participate in the experience such as for example by taking a still picture photo of the place they are viewing and creating a scrap book of such pictures. Another feature allows a travel participant to take a photo of them in the telepresence experience while another automatically obtains information about the telepresence experience using automatic context implicit queries. This information can be shared with the travel volunteer. Additionally one feature displays a real time map of the location of the travel volunteer during the telepresence experience.

In various immersive telepresence implementations the telepresence travel participant can capture still images of the telepresence experience by taking a snapshot of the video stream that is sent to them by the travel volunteer. In some implementations as shown in a user interface is displayed to the travel participant on a display associated with their computing device. In one pane streaming video received from the travel volunteer is displayed. In another pane the travel participant s image is displayed. A virtual snapshot button is also displayed to the travel participant. If the travel participant selects and activates the snapshot button via a mouse or other pointing device or via touch if the display is touch sensitive a snapshot of the displayed streaming video is captured and stored. Furthermore the other buttons can be used to enact other immersive features such as for example a button to add a snapshot to a scrapbook e.g. to bring up the interface shown in a button to capture an image to use as a background for inserting the travel participant in the scene or otherwise operating in a mode where the travel volunteer can show a view that would be good for a background to insert the travel participant in or a button to display the search pane for more contextual information about the place being visited. Additional buttons can also include buttons to hang up a video call mute the microphone used for the video call or any other buttons for typical video calling interfaces.

Various telepresence implementations allow the telepresence travel participant to create a scrap book or travel album from multiple captured still images e.g. captured as described above . This can be done automatically using pre defined templates and fitting the snap shots the travel participant takes into slots in the pre defined templates. Such a user interface is shown in . As shown in snapshots can be automatically filled into slots and on the user interface . In one implementation snapshots or still images captured e.g. by using the snapshot button shown in during the telepresence experience are automatically inserted into the slots in the order they are captured by the travel participant. The travel participant can change the order of the still image e.g. via click and drag . Additionally the travel participant can add text or labels to the images by typing text into a box associated with each image.

Various telepresence implementations allow the telepresence travel participant to create an image or snapshot of themselves that displays the received video as a background behind the telepresence travel participant. This snapshot can be sent or posted to a social media site or used in a variety of other ways that photographs or snapshots can be used. shows an exemplary user interface that depicts an image of the travel participant superimposed on a background of the streaming video received from the travel volunteer. In one implementation this image is obtained by segmenting out the foreground of a picture of the travel participant such as the one captured and displayed in pane of and superimposing the segmented foreground of the image of the travel participant over the streamed video received from the travel volunteer. A snapshot of the segmented image of the travel participant superimposed over the streamed video background can be captured in a manner similar to that described above.

Various telepresence implementations provide for contextual implicit search that automatically retrieves search results associated with location the travel volunteer visits based on audio associated with the location. Search results associated with the location can automatically be retrieved based on conversations between the telepresence travel participant and the travel volunteer. Alternately search results can be automatically retrieved using text messages or email messages between the travel participant and a travel volunteer. The search results can be displayed in conjunction with the video of the location. Or they can be provided from the telepresence travel participant to the travel volunteer for example in real time as the travel volunteer is capturing and sending audio and video of the location using his or her mobile computing device. depicts an exemplary user interface that is displayed to the travel participant. The user interface includes a pane where search results in response to an implicit query are displayed on the display of the computing device of the travel participant.

The pane containing the implicitly fetched search results can supplement the travel participant s knowledge of the location and also provide them with insightful information that they may wish to share with the travel volunteer. The implicit queries can be triggered as described above as well as by metadata such as any human typed name for the session or list item e.g. the favelas of Rio the geo location being reported by the mobile phone of the travel volunteer or live speech to text translation of any commentary from the travel volunteer supplemented by entity extraction. In one implementation the implicit query pane provides a combination of images text social media posts and maps that are relevant to the target location and topics.

Some immersive telepresence implementations provide a real time map of the travel volunteer s real time location. If available an interactive Street View centered on the travel volunteer s location can also be displayed. The map can enable the travel participant to contribute to the travel volunteer s experience for example by offering directions to specific locations or pointing out nearby attractions the travel volunteer might not be aware of. The additional Street View increases immersion offering travel participants a way to explore other views of the same space in a self driven manner be it different viewing angles or different times of day and year.

In the implementations described above the travel participant and the travel volunteers are human beings each equipped with computing devices. However a travel volunteer could also be a mobile telepresence robot although such a robot would also be restricted to travelling only in places accessible to a robot non paved terrain stairs etc. would not be possible . Drones could also potentially be used to similar effect. For example a person can fly their personal hobby drone to the desired location.

What has been described above includes example implementations. It is of course not possible to describe every conceivable combination of components or methodologies for purposes of describing the claimed subject matter but one of ordinary skill in the art may recognize that many further combinations and permutations are possible. Accordingly the claimed subject matter is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of detailed description of the recommendation request implementation described above.

In regard to the various functions performed by the above described components devices circuits systems and the like the terms including a reference to a means used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. a functional equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary aspects of the claimed subject matter. In this regard it will also be recognized that the foregoing implementations include a system as well as a computer readable storage media having computer executable instructions for performing the acts and or events of the various methods of the claimed subject matter.

There are multiple ways of realizing the foregoing implementations such as an appropriate application programming interface API tool kit driver code operating system control standalone or downloadable software object or the like which enable applications and services to use the implementations described herein. The claimed subject matter contemplates this use from the standpoint of an API or other software object as well as from the standpoint of a software or hardware object that operates according to the implementations set forth herein. Thus various implementations described herein may have aspects that are wholly in hardware or partly in hardware and partly in software or wholly in software.

The aforementioned systems have been described with respect to interaction between several components. It will be appreciated that such systems and components can include those components or specified sub components some of the specified components or sub components and or additional components and according to various permutations and combinations of the foregoing. Sub components can also be implemented as components communicatively coupled to other components rather than included within parent components e.g. hierarchical components .

Additionally it is noted that one or more components may be combined into a single component providing aggregate functionality or divided into several separate sub components and any one or more middle layers such as a management layer may be provided to communicatively couple to such sub components in order to provide integrated functionality. Any components described herein may also interact with one or more other components not specifically described herein but generally known by those of skill in the art.

The following paragraphs summarize various examples of implementations which may be claimed in the present document. However it should be understood that the implementations summarized below are not intended to limit the subject matter which may be claimed in view of the foregoing descriptions. Further any or all of the implementations summarized below may be claimed in any desired combination with some or all of the implementations described throughout the foregoing description and any implementations illustrated in one or more of the figures and any other implementations described below. In addition it should be noted that the following implementations are intended to be understood in view of the foregoing description and figures described throughout this document.

Various immersive telepresence implementations are by means systems processes for providing a telepresence experience for a travel participant. Such a travel participant can be for example a homebound or hospital bound person a student or virtually anyone that would benefit from participating in an immersive telepresence experience.

As a first example immersive telepresence implementations are implemented in a system that provides for immersive telepresence experiences. The system includes one or more computing devices the computing devices being in communication with each other whenever there is a plurality of computing devices and a computer program having a plurality of sub programs executable by the one or more computing devices. The one or more computing devices are directed by the sub programs of the computer program to receive a list of telepresence experiences a telepresence travel participant wishes to experience match an experience from the list with the location of a travel volunteer using the location of a mobile computing device of the travel volunteer and calendar information retrieved from the mobile computing device receive video and associated audio of the telepresence experience from the mobile computing device of the travel volunteer over a network and output the received video and associated audio of the telepresence experience with features that enhance the immersiveness of the telepresence experience for the telepresence participant.

As a second example in various implementations the first example is further modified by means processes or techniques such that a telepresence experience from the list is matched with a travel volunteer using profile information of the telepresence travel participant.

As a third example in various implementations the first example and the second example is further modified by means processes or techniques such that an experience from the list is matched by allowing a travel participant to browse a list of available telepresence experiences and manually matching a telepresence experience on the list with a travel volunteer.

As a fourth example in various implementations the first example the second example or the third example is further modified by means processes or techniques to allow the telepresence travel participant to communicate with the travel volunteer while the video and associated audio are being captured.

As a fifth example in various implementations the first example the second example the third example or the fourth example are further modified by means processes or techniques to include a feature that allows the telepresence travel participant to capture still images of the telepresence experience from the received video.

As a sixth example in various implementations the first example the second example the third example the fourth example or the fifth example are further modified by means processes or techniques to include a feature that automatically creates a scrapbook from multiple captured still images of the telepresence experience.

As a seventh example in various implementations the first example the second example the third example the fourth example the fifth example or the sixth example are further modified by means processes or techniques to include a feature that displays the received video or a still image from the video as a background behind the telepresence travel participant.

As an eighth example in various implementations the first example the second example the third example the fourth example the fifth example the sixth example or the seventh example are further modified by means processes or techniques to include a feature that captures an image of the telepresence travel participant with the received video or images in the background.

As a ninth example in various implementations the first example the second example the third example the fourth example the fifth example the sixth example the seventh example or the eighth example is further modified by means processes or techniques to send the image of the telepresence travel participant with the received video in the background to a social media site.

As a tenth example in various implementations the first example the second example the third example the fourth example the fifth example the sixth example the seventh example the eighth example or the tenth example is further modified by means processes or techniques to automatically retrieve search results associated with the location of the telepresence experience that are provided to the travel participant.

As an eleventh example in various implementations the first example the second example the third example the fourth example the fifth example the sixth example the seventh example the eighth example the ninth example or the tenth example is further modified by means processes or techniques to automatically retrieve search results associated with location the travel volunteer visits based on conversations between the telepresence travel participant and the travel volunteer.

As a twelfth example in various implementations the first example the second example the third example the fourth example the fifth example the sixth example the seventh example the eighth example the ninth example the tenth example or the eleventh example is further modified by means processes or techniques to display search results in conjunction with the video and images of the telepresence experience.

As a thirteenth example immersive telepresence implementations are implemented in a process that provides for immersive telepresence experiences. The process uses one or more computing devices for defining a list of telepresence experiences for a telepresence travel participant to visit matching a telepresence experience from the list to a travel volunteer using calendar information and geographic location retrieved from the travel volunteer s mobile computing device receiving a notice from a travel volunteer that the travel volunteer is able to capture video and audio of the matched telepresence experience receiving a response to the notice that the telepresence travel participant would like to receive video and audio of the matched telepresence experience and receiving video and associated audio of the matched telepresence experience from the mobile computing device of the travel volunteer over a network.

As a fourteenth example in various implementations the thirteenth example is further modified by means processes or techniques to output the received video and associated audio of the matched telepresence experience as an interactive live video and audio stream to the telepresence travel participant.

As a fifteenth example in various implementations the thirteenth example or fourteen example is further modified by means processes or techniques to store the received video and associated audio and outputting the received video and associated video to the telepresence travel participant at a later time.

As a sixteenth example immersive telepresence implementations are implemented in a system that provides for immersive telepresence experiences. The process uses one or more computing devices the computing devices being in communication with each other whenever there is a plurality of computing devices. The computer program has a plurality of sub programs executable by the one or more computing devices the one or more computing devices being directed by the sub programs of the computer program to receive a list of telepresence experiences for a telepresence travel participant to visit match a telepresence experience from the list of places with a travel volunteer at a point in time using calendar information retrieved from a computing device of the travel volunteer receive video and associated audio of the matched telepresence experience from the travel volunteer over a network and output the received video and associated audio of the matched telepresence experience to the telepresence travel participant.

As a seventeenth example in various implementations the sixteenth example is further modified by means processes or techniques to extract location information from the calendar information and use it in matching.

As an eighteenth example in various implementations the sixteenth example or the seventeenth example is further modified by means processes or techniques to extract geographic location information from the computing device of the travel volunteer and use it in matching.

As a nineteenth example in various implementations the sixteenth example the seventeenth example or the eighteenth example is further modified by means processes or techniques so that a third party specifies the list of places for the telepresence participant to visit.

As a twentieth example in various implementations the sixteenth example the seventeenth example the eighteenth example or the nineteenth example is further modified by means processes or techniques so that the travel volunteer is selected from a set of several travel volunteers by determining the best match.

The immersive telepresence implementations described herein are operational within numerous types of general purpose or special purpose computing system environments or configurations. illustrates a simplified example of a general purpose computer system on which various elements of the immersive telepresence implementations as described herein may be implemented. It is noted that any boxes that are represented by broken or dashed lines in the simplified computing device shown in represent alternate implementations of the simplified computing device. As described below any or all of these alternate implementations may be used in combination with other alternate implementations that are described throughout this document.

The simplified computing device is typically found in devices having at least some minimum computational capability such as personal computers PCs server computers handheld computing devices laptop or mobile computers communications devices such as cell phones and personal digital assistants PDAs multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers and audio or video media players.

To allow a device to realize the immersive telepresence implementations described herein the device should have a sufficient computational capability and system memory to enable basic computational operations. In particular the computational capability of the simplified computing device shown in is generally illustrated by one or more processing unit s and may also include one or more graphics processing units GPUs either or both in communication with system memory . Note that that the processing unit s of the simplified computing device may be specialized microprocessors such as a digital signal processor DSP a very long instruction word VLIW processor a field programmable gate array FPGA or other micro controller or can be conventional central processing units CPUs having one or more processing cores and that may also include one or more GPU based cores or other specific purpose cores in a multi core processor.

In addition the simplified computing device may also include other components such as for example a communications interface . The simplified computing device may also include one or more conventional computer input devices e.g. touchscreens touch sensitive surfaces pointing devices keyboards audio input devices voice or speech based input and control devices video input devices haptic input devices devices for receiving wired or wireless data transmissions and the like or any combination of such devices.

Similarly various interactions with the simplified computing device and with any other component or feature of the immersive telepresence implementation including input output control feedback and response to one or more users or other devices or systems associated with the immersive telepresence implementation are enabled by a variety of Natural User Interface NUI scenarios. The NUI techniques and scenarios enabled by the immersive telepresence implementation include but are not limited to interface technologies that allow one or more users user to interact with the immersive telepresence implementation in a natural manner free from artificial constraints imposed by input devices such as mice keyboards remote controls and the like.

Such NUI implementations are enabled by the use of various techniques including but not limited to using NUI information derived from user speech or vocalizations captured via microphones or other input devices or system sensors. Such NUI implementations are also enabled by the use of various techniques including but not limited to information derived from system sensors or other input devices from a user s facial expressions and from the positions motions or orientations of a user s hands fingers wrists arms legs body head eyes and the like where such information may be captured using various types of 2D or depth imaging devices such as stereoscopic or time of flight camera systems infrared camera systems RGB red green and blue camera systems and the like or any combination of such devices. Further examples of such NUI implementations include but are not limited to NUI information derived from touch and stylus recognition gesture recognition both onscreen and adjacent to the screen or display surface air or contact based gestures user touch on various surfaces objects or other users hover based inputs or actions and the like. Such NUI implementations may also include but are not limited to the use of various predictive machine intelligence processes that evaluate current or past user behaviors inputs actions etc. either alone or in combination with other NUI information to predict information such as user intentions desires and or goals. Regardless of the type or source of the NUI based information such information may then be used to initiate terminate or otherwise control or interact with one or more inputs outputs actions or functional features of the immersive telepresence implementations.

However it should be understood that the aforementioned exemplary NUI scenarios may be further augmented by combining the use of artificial constraints or additional signals with any combination of NUI inputs. Such artificial constraints or additional signals may be imposed or generated by input devices such as mice keyboards and remote controls or by a variety of remote or user worn devices such as accelerometers electromyography EMG sensors for receiving myoelectric signals representative of electrical signals generated by user s muscles heart rate monitors galvanic skin conduction sensors for measuring user perspiration wearable or remote biosensors for measuring or otherwise sensing user brain activity or electric fields wearable or remote biosensors for measuring user body temperature changes or differentials and the like. Any such information derived from these types of artificial constraints or additional signals may be combined with any one or more NUI inputs to initiate terminate or otherwise control or interact with one or more inputs outputs actions or functional features of the immersive telepresence implementations.

The simplified computing device may also include other optional components such as one or more conventional computer output devices e.g. display device s audio output devices video output devices devices for transmitting wired or wireless data transmissions and the like . Note that typical communications interfaces input devices output devices and storage devices for general purpose computers are well known to those skilled in the art and will not be described in detail herein.

The simplified computing device shown in may also include a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computing device via storage devices and include both volatile and nonvolatile media that is either removable and or non removable for storage of information such as computer readable or computer executable instructions data structures program modules or other data.

Computer readable media includes computer storage media and communication media. Computer storage media refers to tangible computer readable or machine readable media or storage devices such as digital versatile disks DVDs blue ray discs BD compact discs CDs floppy disks tape drives hard drives optical drives solid state memory devices random access memory RAM read only memory ROM electrically erasable programmable read only memory EEPROM CD ROM or other optical disk storage smart cards flash memory e.g. card stick and key drive magnetic cassettes magnetic tapes magnetic disk storage magnetic strips or other magnetic storage devices. Further a propagated signal is not included within the scope of computer readable storage media.

Retention of information such as computer readable or computer executable instructions data structures program modules and the like can also be accomplished by using any of a variety of the aforementioned communication media as opposed to computer storage media to encode one or more modulated data signals or carrier waves or other transport mechanisms or communications protocols and can include any wired or wireless information delivery mechanism. Note that the terms modulated data signal or carrier wave generally refer to a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. For example communication media can include wired media such as a wired network or direct wired connection carrying one or more modulated data signals and wireless media such as acoustic radio frequency RF infrared laser and other wireless media for transmitting and or receiving one or more modulated data signals or carrier waves.

Furthermore software programs and or computer program products embodying some or all of the various immersive telepresence implementations described herein or portions thereof may be stored received transmitted or read from any desired combination of computer readable or machine readable media or storage devices and communication media in the form of computer executable instructions or other data structures. Additionally the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device or media.

The immersive telepresence implementations described herein may be further described in the general context of computer executable instructions such as program modules being executed by a computing device. Generally program modules include routines programs objects components data structures and the like that perform particular tasks or implement particular abstract data types. The immersive telepresence implementations may also be practiced in distributed computing environments where tasks are performed by one or more remote processing devices or within a cloud of one or more devices that are linked through one or more communications networks. In a distributed computing environment program modules may be located in both local and remote computer storage media including media storage devices. Additionally the aforementioned instructions may be implemented in part or in whole as hardware logic circuits which may or may not include a processor.

Alternatively or in addition the functionality described herein can be performed at least in part by one or more hardware logic components. For example and without limitation illustrative types of hardware logic components that can be used include field programmable gate arrays FPGAs application specific integrated circuits ASICs application specific standard products ASSPs system on a chip systems SOCs complex programmable logic devices CPLDs and so on.

The foregoing description of the immersive telepresence implementations have been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the claimed subject matter to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. Further it should be noted that any or all of the aforementioned alternate implementations may be used in any combination desired to form additional hybrid implementations of the recommendation request implementation. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto. Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims and other equivalent features and acts are intended to be within the scope of the claims.

