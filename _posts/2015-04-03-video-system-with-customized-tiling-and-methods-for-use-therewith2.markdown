---

title: Video system with customized tiling and methods for use therewith
abstract: A tile processor is configured to analyze sensor data to identify the at least one viewer and to generate tile configuration data in response to the identification of the at least one viewer that indicates a tiled partitioning of a screen display into a plurality of tiled regions. An A/V player generates tiled display data for display of the at least video program on a display device in accordance with the tile configuration data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09628870&OS=09628870&RS=09628870
owner: ViXS Systems, Inc.
number: 09628870
owner_city: Toronto
owner_country: CA
publication_date: 20150403
---
The present U.S. Utility patent application claims priority pursuant to 35 U.S.C. 120 as a continuation in part of U.S. Utility application Ser. No. 14 590 303 entitled AUDIO VIDEO SYSTEM WITH INTEREST BASED AD SELECTION AND METHODS FOR USE THEREWITH filed Jan. 6 2015 which is a continuation in part of U.S. Utility application Ser. No. 14 217 867 entitled AUDIO VIDEO SYSTEM WITH USER ANALYSIS AND METHODS FOR USE THEREWITH filed Mar. 18 2014 and claims priority pursuant to 35 U.S.C. 120 as a continuation in part of U.S. Utility application Ser. No. 14 477 064 entitled VIDEO SYSTEM FOR EMBEDDING EXCITEMENT DATA AND METHODS FOR USE THEREWITH filed Sep. 4 2014 all of which are hereby incorporated herein by reference in their entirety and made part of the present U.S. Utility patent application for all purposes.

The present disclosure relates to audio video systems that process and present audio and or display video signals.

Modern users have many options to view audio video programming. Home media systems can include a television a home theater audio system a set top box and digital audio and or A V player. The user typically is provided one or more remote control devices that respond to direct user interactions such as buttons keys or a touch screen to control the functions and features of the device. Audio video content is also available via a personal computer smartphone or other device. Such devices are typically controlled via a buttons keys a mouse or other pointing device or a touch screen.

Video encoding has become an important issue for modern video processing devices. Robust encoding algorithms allow video signals to be transmitted with reduced bandwidth and stored in less memory. However the accuracy of these encoding methods face the scrutiny of users that are becoming accustomed to greater resolution and higher picture quality. Standards have been promulgated for many encoding methods including the H.264 standard that is also referred to as MPEG 4 part 10 or Advanced Video Coding AVC . While this standard sets forth many powerful techniques further improvements are possible to improve the performance and speed of implementation of such methods. Further encoding algorithms have been developed primarily to address particular issues associated with broadcast video and video program distribution.

The devices and each represent examples of electronic devices that incorporate one or more elements of a system that includes features or functions of the present disclosure. While these particular devices are illustrated system includes any device or combination of devices that is capable of performing one or more of the functions and features described in conjunction with and the appended claims.

The received signals s can contain one or more video programs in an audio video signal such as a broadcast video signal a multicast video signal a unicast video signal streaming video signal or other video signal that has been transmitted over a wireless medium either directly or through one or more satellites or other relay stations or through a cable network optical network or other transmission network without or without an accompanying audio signal. In addition received signals s can be generated from a stored video file played back from a recording medium such as a magnetic tape magnetic disk or optical disk and can include a broadcast video signal a multicast video signal a unicast video signal streaming video signal or other video signal that is transmitted over a public or private network such as a local area network wide area network metropolitan area network or the Internet.

Received signals s can include a compressed digital video signal complying with a digital video codec standard such as H.264 MPEG 4 Part 10 Advanced Video Coding AVC VC 1 H.265 or another digital format such as a Motion Picture Experts Group MPEG format such as MPEG1 MPEG2 or MPEG4 QuickTime format Real Media format Windows Media Video WMV or Audio Video Interleave AVI etc. When the received signals s include a compressed digital video signal the decoding module or other video codec decompresses the audio video signals s to produce a decoded audio video signals s suitable for display by a video display device of audio video player that operates under the control of the viewer s to create an optical image stream of the video programs contained in the decoded audio video signals s . In an embodiment the display device includes a high resolution display such as a high definition display an ultra high definition 4K display or 8K display or other high resolution display that can be partitioned into multiple viewing tiles.

When the received signals s include a compressed digital audio signal the decoding module can decompress the audio video signals s and otherwise process the audio video signals s to produce a decoded audio signal suitable for presentation by an audio player included in audio video player . The decoded audio video signals s can include a high definition media interface HDMI signal digital video interface DVI signal a composite video signal a component video signal an S video signal and or one or more analog or digital audio signals.

When A V signals s are received and the decoded video signals s are produced in a digital video format the digital video signal may be optionally scrambled or encrypted may include corresponding audio and may be formatted for transport via one or more container formats. Examples of such container formats are encrypted Internet Protocol IP packets such as used in IP TV Digital Transmission Content Protection DTCP etc. In this case the payload of IP packets contain several transport stream TS packets and the entire payload of the IP packet is encrypted. Other examples of container formats include encrypted TS streams used in Satellite Cable Broadcast etc. In these cases the payload of TS packets contain packetized elementary stream PES packets. Further digital video discs DVDs and Blu Ray Discs BDs utilize PES streams where the payload of each PES packet is encrypted. When the received signals s are scrambled or encrypted the decoding module further operates to descramble and or decrypt the received signals s to produce the decoded audio video signals s .

In an embodiment the decoding module not only decodes the A V signal s but also includes a pattern recognition module to detect patterns of interest in the video signal and to generate time coded metadata that indicates patterns and corresponding features such as people objects places activities or other features as well as timing information that correlates the presence or absence of these people objects places activities or other features in particular images in the decoded A V signal s . Examples of such a decoding module is presented in conjunction with the U.S. Published Application 2013 0279603 entitled VIDEO PROCESSING SYSTEM WITH VIDEO TO TEXT DESCRIPTION GENERATION SEARCH SYSTEM AND METHODS FOR USE THEREWITH the contents of which are incorporated herein by reference for any and all purposes. In addition or in the alternative the decoding module extracts time coded metadata that was already included in the A V signal s . For example the A V signal s can have the time coded metadata embedded as a watermark or other signal in the video content itself or be in some different format that includes the video content from the received signal and the time coded metadata .

The system includes one or more sensors that generate sensor data corresponding to a viewing of video program s via the A V player by one or more viewers. The viewer sensor can include a digital camera such as a still or video camera that is either a stand alone device or is incorporated in any one of the devices or or other device that generates the sensor data that includes image data. In addition or in the alternative the viewer sensor s can include an infrared sensor thermal imager background temperature sensor or other thermal imaging sensor an ultrasonic imaging sensor or other sonar based sensor and or other sensors for generating sensor data that can be used by the tile processor In addition or in the alternative image data can be generated by cameras associated with one or more portable devices associated with the viewer s .

The tile processor analyzes the sensor data to determine the presence of the viewer s to identify the viewer s and to generate tile configuration data in response to the identification of the viewer s . The tile configuration data indicates a tiled partitioning of a screen display into a plurality of tiled regions. The A V player generates tiled display data for display of the video program s on a display device in accordance with the tile configuration data .

The tile processor can further generate tile data in response to the identification of the viewer s . In an embodiment the tile processor includes a metadata selection generator that selects time coded metadata or metadata associated with the video programs s retrieved from a metadata source for display as tile data in accordance with the viewer s that are identified. The tile data can also include other media such as advertisements messaging or social media from at least one secondary tile data source such as an ad server messaging server or social media server . In this fashion the plurality of tiled regions of the screen display can include one or more video regions for display of one or more video programs and one or more other regions for display of the tile data .

In an embodiments the tile processor also includes a viewer fovea tracking generator that generates fovea tracking data corresponding to the viewer s that indicates which or the particular tiled regions of the screen display correspond to a region of viewer focus for each of viewer s i.e. which of the tiled regions each viewer is watching at any given time. When the particular tiled regions corresponding to the region of viewer focus correspond to a video region the metadata selection generator can select metadata corresponding to the particular video program currently displayed in that tiled region. In this fashion if multiple video programs are displayed in different tiled regions metadata can be selected that corresponds to the video program or programs that are currently being followed by the viewer or viewers. In addition or in the alternative the tile processor can also adjust the tile configuration data in response to the fovea tracking data to further adapt to the particular tiled region or regions that are currently being watched by the viewer s .

In an embodiment the tile processor includes a viewer profile database that stores viewer profile data for one or more viewers. The viewer profile data can include viewer images of know viewers and or other viewer data that can be used to identify the viewers based on the sensor data as well as viewer demographic information preferred tile configurations for each viewer portable device information for the portable devices associated with the viewers and or other preferences and profile data. In an embodiment the tile processor analyzes the sensor data or portable devices in use in the viewing area to identify the viewer s based a comparison of the sensor data or portable device to viewer profile data stored in a viewer profile database . The tile processor can generate the tile configuration data based on the preferred tile configuration for one or more viewers that are currently identified as being in the viewing area of the A V player . Another potential viewer identification method is that where the portable device is a smartphone or tablet that often is only used by a unique user the presence of an interface application on the device as a portal into the system can also be used to identify a unique user as commands or navigation requests entered into the portable device can be used to improve future responsiveness as well as the system understanding of this user s preferences.

In this fashion the identification of which particular viewer or viewers are watching can be used to learn the desired partitioning profile for each user either individually or by particular groups and to select a preferred partitioning profile based on the viewer or specific group of viewers that are present. Display tiles can be used to present content that is customized to a recognition of which viewers are present. The tiles can include one or more video streams such as multiple feeds of a single video program or live event an advertising window a social window or text messaging window that displays social media communications or group text communication between the viewers and their friends and that can automatically notify friends what viewers are watching in the presentation area of A V player and what content is being watched.

The decoding module A V player and the tile processor can each be implemented using a single processing device or a plurality of processing devices. Such a processing device may be a microprocessor co processors a micro controller digital signal processor microcomputer central processing unit field programmable gate array programmable logic device state machine logic circuitry analog circuitry digital circuitry and or any device that manipulates signals analog and or digital based on operational instructions that are stored in a memory. These memories may each be a single memory device or a plurality of memory devices. Such a memory device can include a hard disk drive or other disk drive read only memory random access memory volatile memory non volatile memory static memory dynamic memory flash memory cache memory and or any device that stores digital information. Note that when decoding module A V player and the tile processor implement one or more of their functions via a state machine analog circuitry digital circuitry and or logic circuitry the memory storing the corresponding operational instructions may be embedded within or external to the circuitry comprising the state machine analog circuitry digital circuitry and or logic circuitry.

While system is shown as an integrated system it should be noted that the system can be implemented as a single device or as a plurality of individual components that communicate with one another wirelessly and or via one or more wired connections. As described in conjunction with system can be implemented entirely via a mobile communication device such as a laptop tablet or smartphone with a back facing camera that serves as a sensor .

The further operation of system including illustrative examples and several optional functions and features is described in greater detail in conjunction with that follow.

The viewer identification processor analyzes the sensor data and optionally portable device input from one or more portable devices in the viewing area to determine the presence of the viewer s to identify the viewer s and to generate viewer identification data that indicate the specific viewer or viewers that are present. In an embodiment the viewer identification processor analyzes the sensor data and or portable device input to identify the viewer s based a comparison of the sensor data or portable device input to viewer profile data stored in a viewer profile database . The viewer identification processor via its viewer fovea tracking generator also generates fovea tracking data corresponding to the identified viewer s that indicates which of the particular tiled regions of the screen display correspond to a region of viewer focus for each of viewer s i.e. which of the tiled regions each viewer is watching at any given time.

In an embodiment the viewer identification processor is configured to analyze sensor data generated by one or more viewer sensors corresponding to a viewing of the video program or programs via the A V player by the viewer s . For example a viewer sensor generates sensor data in a presentation area of the A V player . The viewer sensor can include a digital camera such as a still or video camera that is either a stand alone device or is incorporated in any one of the devices or or other device that generates the sensor data as image data. In addition or in the alternative the viewer sensor can include an infrared sensor thermal imager background temperature sensor or other thermal imaging sensor an ultrasonic imaging sensor or other sonar based sensor and or other sensors for generating sensor data that can be used by the viewer identification processor for determining the presence of viewers for identifying particular viewers and or for determining the portions of the screen display that can be correlated to the particular tiles of the display that the viewers are currently watching. As discussed the fovea tracking data can indicate the portions of the screen display or particular tiles that that the viewers are currently watching. In addition or in the alternative image data generated by cameras associated with one or more portable devices and shared as portable device input can be used to identify the viewer s along with other portable device input such as the identification of the particular users of each device.

Consider an example where a family is watching TV. One or more video cameras are stand alone devices or are built into the TV a set top Blu Ray player and or portable devices associated with the viewers. The camera or cameras capture video of the presentation environment and viewers. The viewer identification processor processes the video and detects if there are viewers present how many viewers are present the identities of each of the viewers to generate viewer identification data and further to determine the focus of interest by each of the viewers to generate fovea tracking data corresponding to the viewer s .

In an embodiment the viewer fovea tracking generator tracks that viewers eyes and or head to determine the region of the screen display that is being watched by the viewer an area of viewer focus of the viewer of viewers. As used herein the area of viewer focus is a prediction of estimation of the region of the screen display corresponding to the viewer s visual fovea i.e. the portion of the display that is subject to viewer s central vision as opposed to the viewer s peripheral vision. The fovea tracking data is generated to indicate the region of viewer focus in the screen display corresponding to the viewer s .

The tile configuration generator generates the tile configuration data in response to the viewer identification data . The tile configuration data indicates a tiled partitioning of a screen display into a plurality of tiled regions and further indicates the content to be displayed either a video program received by the A V player as received signals or other media. The tile processor can generate the tile configuration data based on the preferred tile configuration for identified viewers retrieved from the viewer profile database. When no profile data is present for a particular viewer the tile configuration generator can learn the desired partitioning profile for each unknown viewer As discussed preferred tile configurations can be learned and stored both individually and for particular groups and to select a preferred partitioning profile based on the viewer or specific group of viewers that are present. Consider a family that includes a father mother son and daughter. The father and son may both have individual profiles but a group profile may be learned and stored corresponding to situations when both are watching that may be different from either individual profile.

In addition time coded metadata that identifies the content of one or more of the video programs being watched can also be used by the tile configuration generator to determine the tile configuration data . Dad may have one profile for sports and another profile for movies. In situations where he is watching a particular football club Sheffield Wednesday he might prefer to have separate tiles for multiple feeds of the same game whereas when he is watching golf a single larger tile with a single feed is preferred.

In addition or in the alternative the tile configuration generator can also adjust the tile configuration data in response to the fovea tracking data to further adapt to the particular tiled region or regions that are currently being watched by the viewer s . For example if tiles are presented that are not being viewed the tile configuration generator can adjust the tile configuration data . In an embodiment the tile configuration generator analyzes the fovea tracking data to consider the percentage of time each tile is viewed and enlarge the tiles that are consistently viewed having viewing percentages above a first threshold and reduces or eliminate that tiles that are not being viewed or that are seldom viewed having viewing percentages below a second threshold .

As discussed the tile configuration data indicates a tiled partitioning of a screen display into a plurality of tiled regions and further indicates the content to be displayed either a video program received by the A V player as received signals or other media. The A V player responds to the tile configuration data to fill the video tile regions with corresponding video programs that are received and decoded as the processed video signal s . For tiles that contain other media such as messaging social media advertisements or metadata etc. the tile data generator generates the tile data in response to the particular tile configuration data to provide this other media to the A V player to fill in these other tiles of the screen display. The tile data generator receives the tile configuration data that indicates the other media to be included in the one or more tiles. The tile data generator receives the viewer ID data and viewer profile data from the viewer profile database to identify advertisements messaging and social media associated with one or more viewers that are present in conjunction with their viewer profile data. The tile data generator is coupled to secondary tile sources such as messaging server ad server and social media server to retrieve the media required for the current tile configuration to be provided as tile data .

In situations where the tile configuration data specifies that one or more tiles are to include metadata the metadata selection generator selects time coded metadata or metadata associated with the video programs s retrieved from a metadata source for display as tile data in accordance with the viewer s that are identified. For example when a viewer s profile indicates an interest in cars and the time coded metadata indicates the presence of a car in a current scene of a video program being displayed the metadata selection generator can generate selected metadata that include portions of the time coded metadata relating to cars and further additional metadata retrieved from the metadata source that provides supplemental media. In addition when the fovea tracking data for one or more viewers indicate that a particular tiled region with video programming is being watched the metadata selection generator can select metadata corresponding to the particular video program currently displayed in that tiled region. In this fashion if multiple video programs are displayed in different tiled regions metadata can be selected that corresponds to the video program or programs that are currently being followed by the viewer or viewers.

In this example a viewer sensor generates sensor data in a presentation area of the A V player . The A V player includes a flat screen television and speakers and . The viewer sensor can include a digital camera such as a still or video camera that is either a stand alone device or is incorporated in the flat screen television and that generates sensor data . The viewer identification processor analyzes the sensor data to detect and recognize the viewers and of the A V player and their particular viewing vectors and in three dimensions . These viewing vectors and can be used to generate the fovea tracking data by determining the regions of viewer interest in the display that correspond to the tile or tiles of the screen display that are being watched by the viewers and .

In an embodiment the viewer identification processor generates the viewer ID data and the fovea tracking data based on facial modelling recognition and tracking of the point of focus on the display device of the viewer s eyes. In an embodiment the viewer identification processor analyzes the video image included in the sensor data to determine a number of users that are present the locations of the users the viewing angle for each of the users and a corresponding region of focus on the display device for each viewer. In the example shown a single viewer is present.

In one mode of operation the viewer identification processor analyzes video image together with a skin color model used to roughly partition face candidates. The viewer identification processor identifies and tracks candidate facial regions over a plurality of images such as a sequence of images of the image data and detects a face in the image based on the one or more of these images. For example viewer identification processor can operate via detection of colors in the video image . The viewer identification processor generates a color bias corrected image from the image data and a color transformed image from the color bias corrected image. The viewer identification processor then operates to detect colors in the color transformed image that correspond to skin tones. In particular viewer identification processor can operate using an elliptic skin model in the transformed space such as a CCsubspace of a transformed YCCspace. In particular a parametric ellipse corresponding to contours of constant Mahalanobis distance can be constructed under the assumption of Gaussian skin tone distribution to identify a facial region based on a two dimension projection in the CCsubspace. As exemplars the 853 571 pixels corresponding to skin patches from the Heinrich Hertz Institute image database can be used for this purpose however other exemplars can likewise be used in broader scope of the present disclosure.

In an embodiment the viewer identification processor tracks candidate facial regions over a sequence of images and detects a facial region based on an identification of facial motion and or facial features in the candidate facial region over the sequence of images. This technique is based on 3D human face model that looks like a mesh that is overlaid on the image data. For example face candidates can be validated for face detection based on the further recognition by viewer identification processor of facial features such as the shape size motion and relative position of face eyebrows eyes nose mouth cheekbones and jaw. Any of these facial features extracted from the image data can be used by viewer identification processor to detect each viewer that is present.

Further the viewer identification processor can employ temporal recognition to extract three dimensional features based on different facial perspectives included in the plurality of images to improve the accuracy of the detection and recognition of the face of each viewer. Using temporal information the problems of face detection including poor lighting partially covering size and posture sensitivity can be partly solved based on such facial tracking. Furthermore based on profile view from a range of viewing angles more accurate and 3D features such as contour of eye sockets nose and chin can be extracted. Based on the number facial regions that are detected the number of users present can be identified. In addition the viewer identification processor can identify the viewing angle of the users that are present and the region of viewer interest in the displayed video program based on the position of the detected faces in the field of view of the image data and their head and or eye orientations.

In the example shown screen display is partitioned into tiles and by tile configuration data that present content A B C D E and F respectively. The shape of tiles are suited to the display of content in the form of either video programs or other tile data while tiles and based on the shape are more suited to the display of other tile data such as metadata messaging data or social media data.

It should be noted that this example presents only one possible partitioning of a screen display into tiles in accordance with tile configuration data and many other possible configurations based on other partitionings and a greater or fewer number of tile are likewise possible.

In the example shown screen display is partitioned in response to tile configuration data into tiles and . The tiles and are video tiles that are filled by A V Player with different contemporaneous video streams of a football match extracted from received signals . The A V player fills the tile with tile data in the form of advertising data chosen for example based on the viewer profile data corresponding to the viewer or viewers and or based on the content of the video programs being presented in the tiles and or . The A V player also fills the tile with tile data in the form of messaging data corresponding to messaging from or addressed to one or more of the viewer or viewers. In an embodiment messages sent and received by the viewers via portable devices during the video program are retrieved via the messaging server and presented for display in tile as shown.

In the example shown screen display is partitioned in response to tile configuration data into tiles and . The tiles and are video tiles that are filled by A V Player with different contemporaneous video streams of a football match extracted from received signals . The A V player fills the tile with tile data in the form of selected metadata chosen for example based on the time coded metadata data or additional metadata corresponding to the video programs being presented in the tiles and or . The A V player also fills the tile with tile data in the form of Twitter social media data corresponding to social media of viewer or viewers or otherwise corresponding to the content of the time coded metadata data or additional metadata . In an embodiment messages sent and received by the viewers via portable devices during the video program are retrieved via the messaging server and presented for display in tile as shown.

In the example shown screen display is partitioned in response to tile configuration data into tiles and . The tiles and are video tiles that are filled by A V Player with different contemporaneous video streams of a football match extracted from received signals . The A V player fills the tile with tile data in the form of advertising data chosen for example based on the viewer profile data corresponding to the viewer or viewers and or based on the content of the video programs being presented in the tiles and or . The A V player also fills the tile with tile data in the form of messaging data corresponding to messaging from or addressed to one or more of the viewer or viewers.

The viewer fovea tracking generator tracks that viewers eyes and or head to determine the region of the screen display that is being watched by the viewer an area of viewer focus of the viewer of viewers. In the example shown there are two viewers and and the fovea tracking data is generated to indicate the regions of viewer focus and in the screen display indicating that viewer is currently viewing tile and view is currently viewing tile . It should also be noted that neither of the viewers are currently viewing tiles or .

As previously discussed the tile configuration generator can also adjust the tile configuration data in response to the fovea tracking data to further adapt to the particular tiled region or regions that are currently being watched by the viewer s . For example if tiles are presented that are not being viewed the tile configuration generator can adjust the tile configuration data . If tiles and are not being viewed more than a threshold percentage of time they can be eliminated from the partitioning.

The method can further include generating tile data in response to the identification of the at least one viewer wherein the tile data includes media from at least one secondary tile data source. The plurality of tiled regions can include at least one video region for display of the at least one video program and at least one other region for display of the tile data. The secondary tile sources can include a social media server or a messaging server.

The method can also include generating tile data in response to the identification of the at least one viewer. The tile data can include metadata associated with the at least one video program. The plurality of tiled regions can include at least one video region for display of the at least one video program and the method can further include generating fovea tracking data corresponding to the at least one viewer wherein the fovea tracking data indicates at least one of the plurality of tiled regions corresponding to a region of viewer focus in the video program for the at least one viewer. When the at least one of the plurality of tiled regions corresponding to the region of viewer focus in the video program is the at least one video region the metadata can be selected corresponding to a particular one of the at least one video program currently displayed in the at least one of the plurality of tiled regions.

The method can also include generating fovea tracking data corresponding to the at least one viewer that indicates at least one of the plurality of tiled regions corresponding to a region of viewer focus in the video program for the at least one viewer and also adjusting the tile configuration data in response to the indication of the at least one of the plurality of tiled regions corresponding to a region of viewer focus in the video program for the at least one viewer.

In an embodiment the sensor data includes image data. The image data can be analyzed to identify the at least one viewer based a comparison of the image data to at least one viewer image stored in a viewer profile database.

As may also be used herein the term s configured to operably coupled to coupled to and or coupling includes direct coupling between items and or indirect coupling between items via an intervening item e.g. an item includes but is not limited to a component an element a circuit and or a module where for an example of indirect coupling the intervening item does not modify the information of a signal but may adjust its current level voltage level and or power level. As may further be used herein inferred coupling i.e. where one element is coupled to another element by inference includes direct and indirect coupling between two items in the same manner as coupled to . As may even further be used herein the term configured to operable to coupled to or operably coupled to indicates that an item includes one or more of power connections input s output s etc. to perform when activated one or more its corresponding functions and may further include inferred coupling to one or more other items. As may still further be used herein the term associated with includes direct and or indirect coupling of separate items and or one item being embedded within another item.

As may also be used herein the terms processing module processing circuit processor and or processing unit may be a single processing device or a plurality of processing devices. Such a processing device may be a microprocessor micro controller digital signal processor microcomputer central processing unit field programmable gate array programmable logic device state machine logic circuitry analog circuitry digital circuitry and or any device that manipulates signals analog and or digital based on hard coding of the circuitry and or operational instructions. The processing module module processing circuit and or processing unit may be or further include memory and or an integrated memory element which may be a single memory device a plurality of memory devices and or embedded circuitry of another processing module module processing circuit and or processing unit. Such a memory device may be a read only memory random access memory volatile memory non volatile memory static memory dynamic memory flash memory cache memory and or any device that stores digital information. Note that if the processing module module processing circuit and or processing unit includes more than one processing device the processing devices may be centrally located e.g. directly coupled together via a wired and or wireless bus structure or may be distributedly located e.g. cloud computing via indirect coupling via a local area network and or a wide area network . Further note that if the processing module module processing circuit and or processing unit implements one or more of its functions via a state machine analog circuitry digital circuitry and or logic circuitry the memory and or memory element storing the corresponding operational instructions may be embedded within or external to the circuitry comprising the state machine analog circuitry digital circuitry and or logic circuitry. Still further note that the memory element may store and the processing module module processing circuit and or processing unit executes hard coded and or operational instructions corresponding to at least some of the steps and or functions illustrated in one or more of the Figures. Such a memory device or memory element can be included in an article of manufacture.

One or more embodiments have been described above with the aid of method steps illustrating the performance of specified functions and relationships thereof. The boundaries and sequence of these functional building blocks and method steps have been arbitrarily defined herein for convenience of description. Alternate boundaries and sequences can be defined so long as the specified functions and relationships are appropriately performed. Any such alternate boundaries or sequences are thus within the scope and spirit of the claims. Further the boundaries of these functional building blocks have been arbitrarily defined for convenience of description. Alternate boundaries could be defined as long as the certain significant functions are appropriately performed. Similarly flow diagram blocks may also have been arbitrarily defined herein to illustrate certain significant functionality.

To the extent used the flow diagram block boundaries and sequence could have been defined otherwise and still perform the certain significant functionality. Such alternate definitions of both functional building blocks and flow diagram blocks and sequences are thus within the scope and spirit of the claims. One of average skill in the art will also recognize that the functional building blocks and other illustrative blocks modules and components herein can be implemented as illustrated or by discrete components application specific integrated circuits processors executing appropriate software and the like or any combination thereof.

In addition a flow diagram may include a start and or continue indication. The start and continue indications reflect that the steps presented can optionally be incorporated in or otherwise used in conjunction with other routines. In this context start indicates the beginning of the first step presented and may be preceded by other activities not specifically shown. Further the continue indication reflects that the steps presented may be performed multiple times and or may be succeeded by other by other activities not specifically shown. Further while a flow diagram indicates a particular ordering of steps other orderings are likewise possible provided that the principles of causality are maintained.

The one or more embodiments are used herein to illustrate one or more aspects one or more features one or more concepts and or one or more examples. A physical embodiment of an apparatus an article of manufacture a machine and or of a process may include one or more of the aspects features concepts examples etc. described with reference to one or more of the embodiments discussed herein. Further from figure to figure the embodiments may incorporate the same or similarly named functions steps modules etc. that may use the same or different reference numbers and as such the functions steps modules etc. may be the same or similar functions steps modules etc. or different ones.

Unless specifically stated to the contra signals to from and or between elements in a figure of any of the figures presented herein may be analog or digital continuous time or discrete time and single ended or differential. For instance if a signal path is shown as a single ended path it also represents a differential signal path. Similarly if a signal path is shown as a differential path it also represents a single ended signal path. While one or more particular architectures are described herein other architectures can likewise be implemented that use one or more data buses not expressly shown direct connectivity between elements and or indirect coupling between other elements as recognized by one of average skill in the art.

The term module is used in the description of one or more of the embodiments. A module implements one or more functions via a device such as a processor or other processing device or other hardware that may include or operate in association with a memory that stores operational instructions. A module may operate independently and or in conjunction with software and or firmware. As also used herein a module may contain one or more sub modules each of which may be one or more modules.

While particular combinations of various functions and features of the one or more embodiments have been expressly described herein other combinations of these features and functions are likewise possible. The present disclosure is not limited by the particular examples disclosed herein and expressly incorporates these other combinations.

