---

title: Balancing a load on a multiple consumer queue
abstract: Disclosed are various embodiments for balancing a load on a queue among multiple consumers. A target polling hit rate is derived for at least one queue from a consumer load. The consumer load on the at least one queue is adjusted responsive to a change in an observed polling hit rate for the at least one queue.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09455928&OS=09455928&RS=09455928
owner: Amazon Technologies, Inc.
number: 09455928
owner_city: Seattle
owner_country: US
publication_date: 20150306
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 13 619 329 filed on Sep. 14 2012 which issued Mar. 10 2015 as U.S. Pat. No. 8 978 043 which is a continuation of and claims priority to U.S. application Ser. No. 12 821 299 filed on Jun. 23 2010 which issued Dec. 18 2012 as U.S. Pat. No. 8 336 058. Each of these applications is incorporated by reference in its entirety herein.

Queues are used as a method of communicating between software entities. One or more producers add items to a queue that is managed by a server and one or more consumers remove items from the queue. The server provides asynchronous operation for producers and consumers such that a producer is not required to wait for a consumer to finish accessing the queue and vice versa. The queue read operation uses polling such that a consumer checks to see if any data is available before removal.

In scenarios involving many consumers significant server resources are used to handle the polls. Significant consumer resources are also used in competing with each other for access to the queue. This can lead to an imbalance between consumers such that some consumers get an increased and disproportionate access to the queue while other consumers receive inadequate access.

The present disclosure relates to balancing a load on a queue having multiple consumers. In various embodiments the present disclosure provides a mechanism for balancing consumer access to a queue managed by a server. This mechanism balances the tradeoff between performance of the queue consumer and increased load on the server. Each consumer periodically calculates and stores a polling hit rate which is a measure of successful reads. The polling hit rate is used as an indirect communication mechanism between consumers allowing each consumer to tune its read rate for the queue. A predetermined relationship between polling hit rate and read rate allows a target hit rate to be derived. Each consumer then adjusts its read rate to approach this target hit rate. In the following discussion a general description of the system and its components is provided followed by a discussion of the operation of the same.

With reference to shown is a networked environment according to various embodiments. The networked environment includes a computing device that is in data communication with one or more consumer computing devices by way of a network . The computing device may also be in communication with one or more producer computing devices by way of the network . The network may include for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks.

The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks computer banks or other arrangements. To this end a plurality of computing devices together may comprise for example a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be dispersed among many different geographical locations. In one embodiment the computing device represents a virtualized computer system executing on one or more physical computing systems. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above.

Various applications and or other functionality may be executed in the computing device according to various embodiments. The components executed on the computing device for example include a queue service as well as other applications services processes systems engines or functionality not discussed in detail herein. The queue service is executed to provide coordinated access to one or more queues . In some embodiments a queue may reside on a particular computing device . In other embodiments a queue may be distributed among more than one computing device . The queue service provides a mechanism through which a producer and a consumer can communicate with each other asynchronously i.e. without waiting on each other . In various embodiments the queue service may utilize any type of middleware framework to communicate with a client application executing on a consumer computing device and or a client application executing on a producer computing device . Examples of such frameworks include remote procedure calls service oriented architecture protocol SOAP representational state transfer REST and other frameworks. In some embodiments a queue may reside on a particular computing device . In other embodiments a queue may be distributed among more than one computing device .

The consumer computing device and the producer computing device are representative of a plurality of client devices that may be coupled to the network . The consumer computing device may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a server computer a desktop computer a laptop computer a personal digital assistant a cellular telephone a set top box a music player a web pad a tablet computer system or other devices with like capability.

A producer computing device may be configured to execute various components such as one or more producers . A producer is associated with at least one queue and may be executed in a producer computing device for example to add data items to the associated queue using the queue service . These data items may be of a variety of types and sizes.

A consumer computing device may be configured to execute various components such as one or more consumers . A consumer is associated with at least one queue and may be executed in a consumer computing device for example to remove data items from the associated queue using the queue service . The consumer may include an instance of a queue balancer that is configured to adjust a consumer load on the queue . This adjustment balances the queue removal rate also known as read rate among multiple consumers that are accessing the same queue . Some embodiments of the queue balancer utilize multiple consumer threads to read from the queue. In some embodiments of the queue balancer the load is described by the number of consumer threads reading from the queue . In other embodiments of the queue balancer the load is described by the time between reads. In still other embodiments of the queue balancer the load is described by the current queue depth i.e. the number of items in the queue .

A given consumer computing device may be configured to execute one or more consumers producers or both. The consumer computing device may also be configured to execute components and applications beyond the consumer and or producer such as for example browser applications email applications instant message applications and or other applications.

Moving now to shown is a block diagram that provides one example of the operation of a portion of the queue balancer according to various embodiments. In this example three consumers compete to read from the queue . Each consumer includes a corresponding instance of the queue balancer .

Associated with the queue is an actual polling hit rate defined as the number of successful reads divided by the total number of attempted reads. Each instance of the queue balancer maintains an observed polling hit rate and . As each consumer attempts a read from the queue the corresponding observed polling hit rate and is updated. Thus each observed polling hit rate and can be viewed as a reflection of or a proxy for the actual polling hit rate .

Each queue balancer has a read rate parameter which controls queue read behavior. That is the read rate parameter dictates how often the queue balancer attempts to read from the queue . In some embodiments the read rate parameter is the number of threads used by the queue balancer to read from the queue . In other embodiments the read rate parameter is the time between reads or inversely the read rate. In some embodiments a range is specified for the read rate parameter .

Each queue balancer has its own target polling hit rate . Each queue balancer then adjusts its read rate parameter based on a comparison of its target polling hit rate and its observed polling hit rate and . In this manner the observed polling hit rate and is used to tune each queue balancer . In some embodiments a range is specified for the target polling hit rate . In such embodiments each queue balancer uses the target range and the read rate parameter to derive the target polling hit rate which is then used to adjust the read rate parameter .

The queue balancer uses a predetermined relationship between the read rate parameter and the target polling hit rate which results in the read behavior of consumers balancing relative to each other. As a particular consumer reaches its maximum load on the queue e.g. number of threads the addition of another consumer results in the high consumer reducing its load due to a reduction in the observed polling hit rate i.e. more read misses . The new consumer increases its load on the queue until the new consumer sees a reduction in the observed polling hit rate . At that point the consumers balance at approximately the same target polling hit rate .

The operation of the queue balancer as shown in involves different threads of control. One thread adjusts the load on the queue . Other threads read from the queue . In some embodiments load is adjusted by adding and deleting read threads. In other embodiments a fixed number of read threads is used and the load is adjusted by varying time between reads in a thread. In still other embodiments load is adjusted by taking into account additional parameters like queue depth.

Turning now to shown is a flowchart that provides one example of the operation of a portion of the queue balancer according to various embodiments. Specifically the flowchart of illustrates the operation of a read thread . It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the queue balancer as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the consumer computing device according to one or more embodiments.

The read thread begins with box reading from the queue . Next in box the read thread calculates the observed polling hit rate and stores this value. This calculation may perform a non blocking read operation on the queue . In some embodiments the read thread stores not only the last hit rate but also previous hit rates. The queue balancer can use this hit rate history to compute an average of past hit rates rather than a single last value and this average may be used in place of a last value. This average may be for example a moving or rolling average of a predetermined number of values.

Next in box a determination is made as to whether the read thread has been terminated. If in box the determination is made that the read thread has not been terminated the read thread repeats boxes and . If instead in box the determination is made that the read thread has been terminated the thread ends.

With reference now to shown is a flowchart that provides one example of the operation of a portion of the queue balancer according to various embodiments. Specifically the flowchart of illustrates the operation of a load adjuster thread . It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the queue balancer as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the consumer computing device according to one or more embodiments.

The load adjuster thread begins with box deriving the target polling hit rate based on the consumer load on the queue . In some embodiments the consumer load is measured by the number of threads reading from the queue . In other embodiments the consumer load is measured by the time between reads from the queue .

Next in box the load adjuster thread compares the target polling hit rate and the last calculated observed polling hit rate . If in box the load adjuster thread determines that the target polling hit rate is more than the last calculated observed polling hit rate the load adjuster thread moves to box . In box the load adjuster thread decreases the load based on the comparison. If instead in box the load adjuster thread determines that the target polling hit rate is less than the observed polling hit rate the load adjuster thread moves to box . In box the load adjuster thread decreases the load based on the comparison. Next in box a determination is made as to whether the load adjuster thread has been terminated. If in box the determination is made that the load adjuster thread has not been terminated the load adjuster thread repeats boxes and . If instead in box the determination is made that the load adjuster thread has been terminated the thread ends.

The load adjuster thread and the read thread interact as follows. The number of read misses by the read thread is affected by the increase or decrease in load on the queue caused by the load adjuster thread . This behavior is reflected in a change to the observed polling hit rate which is calculated and stored by the read thread . The change in the observed polling hit rate in turn affects the behavior of the load adjuster thread since the load adjuster thread uses the observed polling hit rate in determining how to adjust the load on the queue .

Reference is now made to which depicts a graph showing how a change in the load on the queue affects the target polling hit rate . Line is a plot of the load on the queue . In some embodiments the load corresponds to a read rate parameter used by the queue balancer . The load ranges from a minimum load to a maximum load . Line is a corresponding plot of the target polling hit rate ranging from a minimum target to a maximum target . The lines may be generated in a variety of ways for example using empirical data theoretical prediction heuristics etc. Although straight lines are used in this example in other scenarios line and or line may be strictly increasing curves.

As can be seen from graph each position on the load line has a corresponding position on the target polling hit rate line that can be derived from the load. That is given a current or last stored load on the queue the target polling hit rate that is desired for that load can be computed by mapping the position of the load along the load range to a corresponding position along the target range.

Given this relationship between load on the queue and the target polling hit rate the derivation can be performed in a variety of ways. Some embodiments determine where the load falls within the load range to produce a scaling factor and then apply that scaling factor to the target range to produce the target polling hit rate . Other embodiments use a lookup table rather than performing calculations which may be desirable when such calculations are complex for example in situations where the load is not linear.

Referring next to shown is a schematic block diagram of the consumer computing device according to an embodiment of the present disclosure. The consumer computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end the consumer computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor are the consumer the queue balancer and potentially other components and applications. In addition an operating system may be stored in the memory and executable by the processor . While not illustrated the computing device also includes components like those shown in whereby the queue service and the queue are stored in a memory and executable by a processor.

It is understood that there may be other components and applications that are stored in the memory and are executable by the processor as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java Java Script Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the consumer the queue balancer the queue service the queue service and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowchart of shows the functionality and operation of an implementation of portions of the queue balancer . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowchart of shows a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the consumer the queue balancer the queue service and the queue that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system. The computer readable medium can comprise any one of many physical media such as for example electronic magnetic optical electromagnetic infrared or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

