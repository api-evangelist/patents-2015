---

title: Dynamic tree determination for data processing
abstract: Data can be processed in parallel across a cluster of nodes using a parallel processing framework. Using Web services calls between components allows the number of nodes to be scaled as necessary, and allows developers to build applications on the framework using a Web services interface. A job scheduler works together with a queuing service to distribute jobs to nodes as the nodes have capacity, such that jobs can be performed in parallel as quickly as the nodes are able to process the jobs. Data can be loaded efficiently across the cluster, and levels of nodes can be determined dynamically to process queries and other requests on the system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09489237&OS=09489237&RS=09489237
owner: Amazon Technologies, Inc.
number: 09489237
owner_city: Reno
owner_country: US
publication_date: 20150619
---
This application is a continuation of U.S. application Ser. No. 14 107 570 filed on Dec. 16 2013 issued to U.S. Pat. No. 9 063 976 on Jun. 23 2015 and entitled DYNAMIC TREE DETERMINATION FOR DATA PROCESSING which is a continuation of U.S. application Ser. No. 13 620 240 filed on Sep. 14 2012 issued to U.S. Pat. No. 8 612 476 on Dec. 17 2013 and entitled DYNAMIC TREE DETERMINATION FOR DATA PROCESSING which is a continuation of U.S. patent application Ser. No. 12 200 821 filed on Aug. 28 2008 issued to U.S. Pat. No. 8 312 037 on Nov. 13 2012 and entitled DYNAMIC TREE DETERMINATION FOR DATA PROCESSING the contents of all of which are hereby incorporated by reference in their entireties.

In networks and other electronic environments it is common for multiple users to send requests to a host service server etc. As the number of users and requests increases as well as the amount of information associated with each request the number and or size of resources needed to handle those requests increases as well. Unfortunately the cost of purchasing and maintaining these resources can limit the amount of resources made available which can reduce throughput and capacity and can potentially cause users to move their data and or processing to other providers.

For some users such as enterprise users the amount of data for any request can require a large complicated system to process using existing approaches. For example an enterprise user might desire to analyze information such as log sales and or billing data for each previous day which for certain enterprises might have terabytes of data. Other users might not have a large volume of data to process with each request but may instead send a large number of requests at very high frequencies.

A conventional approach to handling such traffic involves utilizing a large enterprise database system or a data warehousing vendor that typically relies upon a proprietary hardware solution. Such approaches are expensive and limited in flexibility. Further they do not provide scalability and flexibility with respect to the languages and protocols that can be utilized. Further such approaches can be at least impractical for any particular user to implement on their own.

Systems and methods in accordance with various embodiments of the present disclosure may overcome one or more the aforementioned and other deficiencies experienced in conventional approaches to processing information in an electronic environment. Systems and methods in accordance with various embodiments provide for distributed and parallel processing of data. Such an approach can be used with standard computing devices and can scale as needed through the use of additional devices. Each device can act as a node of a tree to process the information where the nodes of the tree are assigned dynamically based on factors such as load and anticipated results such that the size of the overall tree can be reduced. A distributed scheduling component can assign the nodes and direct jobs as the nodes have capacity such that the jobs can be performed quickly and efficiently in parallel across the nodes to perform tasks such as loading and querying data.

The illustrative environment includes at least one application server and a data store . As used herein the term data store refers to any device or combination of devices capable of storing accessing and retrieving data which may include any combination and number of data servers databases data storage devices and data storage media in any standard distributed or clustered environment. The application server can include any appropriate hardware and software for integrating with the data store as needed to execute aspects of one or more applications for the client device handling a majority of the data access and business logic for an application. The application server provides access control services in cooperation with the data store and is able to generate content such as text graphics audio and or video to be transferred to the user which may be served to the user by the Web server in the form of HTML or other such content for at least one Web page using hypertext transfer protocols. The handling of all requests and responses as well as the delivery of content between the client device and the application server can be handled by the Web server. It should be understood that the Web and application servers are not required and are merely example components as structured code discussed herein can be executed on any appropriate device or host machine as discussed elsewhere herein. Further the environment can be architected in such a way that a test automation framework can be provided as a service to which a user or application can subscribe. A test automation framework can be provided as an implementation of any of the various testing patterns discussed herein although various other implementations can be used as well as discussed or suggested herein.

The environment also includes a development and or testing side which includes a user device allowing a user such as a developer data administrator or tester to access the system. The user device can be any appropriate device or machine such as is described above with respect to the client device . The environment also includes a development server which functions similar to the application server but typically runs code during development and testing before the code is deployed and executed on the production side and is accessible to outside users for example. In some embodiments an application server can function as a development server and separate production and testing storage may not be used.

The data store can include several separate data tables databases or other data storage mechanisms and media for storing data relating to a particular aspect. For example the data store illustrated includes mechanisms for storing production data and user information which can be used to serve content for the production side. The data store also is shown to include a mechanism for storing testing data which can be used with the user information for the testing side. It should be understood that there can be many other aspects that may need to be stored in the data store such as for page image information and access right information which can be stored in any of the above listed mechanisms as appropriate or in additional mechanisms in the data store . The data store is operable through logic associated therewith to receive instructions from the application server or development server and obtain update or otherwise process data in response thereto. In one example a user might submit a search request for a certain type of item. In this case the data store might access the user information to verify the identity of the user and can access the catalog detail information to obtain information about items of that type. The information then can be returned to the user such as in a results listing on a Web page that the user is able to view via a browser on the user device . Information for a particular item of interest can be viewed in a dedicated page or window of the browser.

Each server typically will include an operating system that provides executable program instructions for the general administration and operation of that server and typically will include a computer readable medium storing instructions that when executed by a processor of the server allow the server to perform its intended functions. Suitable implementations for the operating system and general functionality of the servers are known or commercially available and are readily implemented by persons having ordinary skill in the art particularly in light of the disclosure herein.

The environment in one embodiment is a distributed computing environment utilizing several computer systems and components that are interconnected via communication links using one or more computer networks or direct connections. However it will be appreciated by those of ordinary skill in the art that such a system could operate equally well in a system having fewer or a greater number of components than are illustrated in . Thus the depiction of the system in should be taken as being illustrative in nature and not limiting to the scope of the disclosure.

In this example an interface such as a Web service application programming interface API is provided that can interface with various components of the system. Using such an interface a developer can build new applications or modify existing applications based on the framework and can make calls through the Web service API and or any other appropriate APIs. The framework in this embodiment also provides a dashboard interface that allows users or non developers to manually select or otherwise specify or enter queries or instructions for utilizing the system. In one example the dashboard in a simple graphical user interface GUI that enables users to load and query the distributed data without having to write any code.

The framework also includes at least one job scheduling component which can comprise a dedicated device e.g. server or can take the form of a distributed scheduling service. The job scheduling component in one embodiment is a distributed and dependency driven enterprise task or job scheduling device module system and or service. The job scheduling component enables users to schedule jobs in series or in parallel including recurring processing and accounting for job dependencies across multiple distributed nodes. Jobs which can comprise any executable programs requests or instructions can be submitted and configured via Web service calls. A job scheduling component can include a scheduling server that is able to perform tasks such as calculating the time needed to run jobs calculating job dependencies scheduling jobs across multiple nodes monitoring job status and providing support for job functions such as add delete update kill and or restart. The system also can include a client component that can be installed on each node . Each client component is able to perform tasks such as updating the scheduling server with information about node health such as via a Web service heartbeat mechanism as well as dequeuing jobs assigned to a node or node group work queue executing the jobs and updating updates the start and or end status to the scheduling server.

The framework also includes a schema management component which can comprise a device and or service. A schema management component can perform tasks such as creating tables deleting tables and altering a retention policy of distributed databases of a system cluster. If a user wants a particular structure to the data the tables can be created on each node according to a user specified schema such that identically structured tables exist on each node and the data can be loaded easily onto each such node. The schema management service can help to ensure that the proper tables are formed on the nodes according to the appropriate schema.

The framework in this example also includes a distribution queue . As with many other components described herein the queue can comprise a device and or service in different embodiments. A distribution queue can balance information such as input data files across multiple machines. The distribution queue also can be used to define metadata for loaded data in the distributed system. The distribution queue can keep track of file and or block loaded node information which is used in case of node failure to redistribute the data to others nodes in the system. The system can include other services such as a data loading service that loads data into a data store local to each node . A data loading service can allow users to plug in any desired storage engine and take advantage of the load data Web service. Data thus can be loaded into the distributed nodes using a load data Web service that can scale to thousands of nodes in synchronous or asynchronous fashion and that can periodically determine the load status and otherwise monitor the load process. The incoming data can be formatted as needed such that the service can successfully load the data into the local data store.

The system also can include a file transfer service to assist in copying files between nodes. The file transfer service can be used by a query engine service to move the data between nodes and file systems of the nodes for example. The file transfer service also can be used with the dashboard to allow for the viewing of log files in the distributed cluster. Each node also can contain a library referred to herein as an extract parse and load EPL library which can be a default library used to load terabytes of data into the cluster of nodes.

The query engine service can accept information such as query input from a user. A user in one embodiment specifies at least three pieces of information an instance query a summary query and an output location. The instance query is a query to be executed on every node used to process the user request and may take the form of a structured query language SQL statement or a command line executable for example. A summary query may take a similar form will instead be executed on a subset of nodes and is used to summarize data results from the instance query across the distributed cluster of nodes as will be discussed later herein. It should be understood that the term query as used herein can refer to any approach known or used in the art for requesting or otherwise accessing data or information as would be apparent to one of ordinary skill in the art and although SQL statements will be used for purposes of simplicity of explanation any appropriate querying technique can be used within the scope of the various embodiments.

The output location may include any appropriate location address device etc. for storing the output such as a data store storage service email message or a local file system. In some embodiments the output location also can serve as an input location or other source of data allowing for further processing and or querying. Advanced options can allow users to upload custom code libraries to execute across the distributed cluster. Once the query input is received the query engine service can create and schedule jobs across the cluster and execute summary jobs using a tree factor summarization as discussed elsewhere herein. A library such as a query runner library in each node can be responsible for executing queries based on parameters received then pass the results to the next node in a specified location. A final summary job then can output final results back to a designated location.

As mentioned above such a framework can provide for parallel computing with high performance and scalability using standard computing components with the various nodes of the system. High efficiency and throughput can be obtained for both loading and querying of data in a way that can provide for interoperability with a plurality of systems languages platforms protocols etc. Such a system can provide continuous loading with functions such as data retention and querying that typically are not available for large data systems. Since the framework in at least several embodiments is built around the use of services such as Web services the system can easily scale to thousands of nodes without need for manual reconfiguration recoding etc. The framework then can accept a large set of data separate the data into multiple data subsets and then distribute the data out to various nodes across the system or cluster. The framework subsequently can receive a request or query that treats the distributed subsets as a single dataset on a single database for example such that a user can access the data without having to have any knowledge as to where the data is actually stored how it is separated etc. The framework can issue a received user query in parallel to each node with data for the query and can ask each node to return the data or information corresponding to the query. The information that is reported back from the various nodes then can be summarized or further analyzed on a smaller set of nodes that are assigned or otherwise determined for the query in order to finally report back cumulative data for the user query. A single answer then can be returned in an efficient manner that will appear to the user as if the query had been entered into a single large data warehouse but is more efficient and less expensive.

The use of Web services throughout the framework also allows developer to integrate directly into the system. Whether feeding data into the system or submitting queries to obtain data out of the system developers can take advantage of standard Web services protocols that allow any system or platform to work with the processing framework.

The distributed scheduling service can include a job store such as local memory etc. that can store information for all the jobs to be executed for a user request for example as well as any dependencies between jobs. A first job can be designated to execute on a first node and a second job on a second node and the scheduling service can monitor the job on each node. If one of the nodes fails the scheduler can restart the job s for that node and or move the job s to another node. As discussed the designating monitoring and moving of jobs can all be done via Web services calls. In this example the scheduler might designate the first and second jobs to execute in parallel. Once both those jobs have executed a summary job can be designated to execute on a third node which in one embodiment can be one of the first two nodes or a different node and accept the input from the first two nodes. This scheduling of jobs in one embodiment involves issuing commands to the scheduling server via Web services as well as the scheduling server communicating with each of the child nodes via Web services. The scheduling service can execute any type of job in any language e.g. Perl C C and the service is very extensible as any developer seeking to extend the system or build on top of the system can utilize any appropriate language to make a Web services call. The use of Web services also allows for significant scalability decoupling of the clients and servers ease of load balancing etc. The scheduler can schedule thousands of jobs across the nodes of the system taking into account the various dependencies etc. Once the schema is selected and the tables created across the node cluster the load data web service can be used to load data into the system.

Once the data is loaded across the cluster according to the schema a user can query or otherwise access the data. The user thus can take advantage of the query engine service . The query engine service in one embodiment utilizes two required stages and one optional stage although additional or fewer stages can be used in other embodiments. In this embodiment the query engine service utilizes an initial or instance stage wherein a first query executes on each node or instance storing data for the query and a summary stage that operates on at least one node and generates a final result or summary in response to the query once the data for all the instances is collected in one place. In some cases a user might wish to perform various operations or transformations on the data and might submit an intermediate query for an optional intermediate stage wherein the intermediate query will execute on a subset of the nodes. The user also can specify a location for the results such as a table or email message. The information can be accepted as inputs through a Web services call to the system which can be submitted through the dashboard or Web services API for example. The query engine service registers the query and provides the pertinent information to the scheduling service to schedule the necessary jobs. Each node includes a query library in order to execute the jobs such that the client component is able to receive information for the job determine how to execute the job then execute the job and pass the results on to the appropriate node. While libraries such as schema libraries and EPL libraries can be included on each node as discussed above users also can insert code onto the nodes by allowing users to upload custom libraries which can be used to perform functions such as data transformation. The user can simply submit the library and the system will distribute the library to all the appropriate nodes.

When loading data into the system it is desirable in many instances to relatively evenly distribute the load across the cluster of nodes. The framework in one embodiment utilizes the queuing service to distribute the data across the nodes. The queuing service can accept a definition for the data and any appropriate metadata and store that data to a queue. The queuing service then can dequeue the data one file block or grouping at a time. Each grouping of data can be sent to at least one node for processing and loading into the system. When a node finishes processing a group another group can be dequeued until all the data is dequeued. In this way each node takes data as quickly as possible which not only causes the data to be loaded more efficiently but also helps to dynamically spread the data across the system based on factors such as load and capacity. The queue in at least one embodiment is a block queue which allows a user to decide the size or grouping of data to be distributed across the system.

When loading data through a dashboard for example a user can be presented with an interface page such as the example illustrated in . The interface can have tabs or other options used for loading and querying the data. In this example a user can create and submit a Web services call to be submitted to load the data. In this example the user specifies a location of the data to be loaded using a data source option . The user also can specify a schema to be used in creating the tables and loading the data using a schema select option . In some embodiments a user can be asked to submit an expected number of results such that the system can display to the user a predicted number of nodes to use for the data. The user then can select a number of nodes to use for the data through a blocking option and can submit the Web service call to be generated using a submit or similar option . For example a user can submit a Web service call that indicates a particular file is to be distributed across ten nodes etc. In other embodiments the system can analyze the file and or aspects of the system and automatically determine how many nodes to use to load the data. The system thus specifies how many instance nodes should be used but does not specify how much data is to be loaded on each node as the nodes themselves control the relative distribution as nodes with a higher load or slower speed will not be able to consume as many files. The nodes can however load the data in parallel until all data is loaded.

The information as to where the data is loaded is maintained such that the system is able to perform queries on the data. This information is also needed if a node becomes at least temporarily unavailable. When a node becomes unavailable the system can determine the data that was dequeued to that node such that the system can load the data into the queue and dequeue the relevant data to other nodes in the cluster. This allows for quick failure recovery using Web services calls.

Once the data is fully loaded into the system a user can begin to query the data. illustrates steps of an example method in accordance with one embodiment for querying the loaded data using a system such as that described with respect to . As discussed at least two queries are received in this embodiment an instance query and a summary query . In one example an instance query might ask for a count of the number of rows meeting a certain criteria and the summary query might ask to sum the total count from each node. In some embodiments a user can submit additional intermediate queries as discussed above and in other embodiments a user does not need to submit a separate summary query as the system will automatically summarize the results based on the instance query. A destination for the results of the query also is received although in some embodiments the destination can be selected separately or ahead of time or may be otherwise determined. Based on the received queries and any metadata for the stored data a set of jobs is created to be used in querying the data . The jobs for the instance and summary queries are then scheduled accounting for any dependencies between jobs . The instance jobs are executed in parallel with each node executing at least one job at any time a job is available . Once the instance jobs are completed the results of the instance jobs are passed to the nodes for the summary jobs or any intermediate jobs and the summary jobs are executed on the selected nodes . As discussed there may be multiple levels of summary jobs such that data has to be passed to the appropriate node s for summarizing. If the data exists on multiple nodes the process continues with data being passed to the parent node and a summary query executed on each parent node. Once all the results are summarized the results are written to the specified destination .

In some cases the results of the instance queries on the various nodes might be too large to summarize or otherwise process on any single node. In such a case there may need to be multiple levels of summarization in order to handle the full set of results. For example illustrates an example node tree wherein a first layer of nodes A B C each stores data locally that is used to process an instance query. The results of the instance queries are passed to a second layer of nodes D E that perform summarization on the instance results. The summarization results are then passed to a third level of nodes F which does the final summarization. It should be understood that the number of levels and nodes can vary as discussed herein. Further if there are intermediate queries then these queries also will need to be handled by another set of nodes and will create at least another level of nodes in the hierarchy.

Systems and methods in accordance with various embodiments dynamically generate the node hierarchies such as that shown in in order to maximize efficiency of querying data by assigning jobs at the appropriate number of levels for a query. In conventional approaches a projection SQL is run on the nodes in the cluster to determine a node to accept the results. Such an approach can be very inefficient when dealing with very large datasets since the final processing node has to accept and process a very large result.

Since a cluster of nodes exists that has the data loaded as discussed above commands such as SQL or other querying commands can be issued to execute an instance query for the distributed data on each node. The instance results can be stored locally on each node in some embodiments and a reference to the results can be placed in a queue service such as discussed above. Using a merge ratio or tree determination algorithm for example the system can determine a next set of nodes to handle the results of the instance queries. If there is at least one intermediate query then the next level will handle the intermediate query. If not the next level will begin executing the summary query. Once the next set or level or nodes is determined the jobs can be scheduled for those nodes and sent when the instance query data is finished and available. The next level of nodes can then copy the instance data from the first set of nodes and execute the appropriate intermediate or summary query in effect reducing the overall result set with each execution at each level. The process continues until a next level of nodes is determined that only contains a single node wherein a final summary query can be executed and the result output to the destination specified by the user.

Referring back to the system diagram of the system can include a query runner library on each node such that various queries can be run against the local data store for each node . This component can be configurable to run other executables as well although a default implementation can be used to execute queries. The queue service can again be used to enqueue and dequeue data. The service can load balance data blocks or files amongst multiple nodes during the query process which can help distribute the work load during different phases of the tree reduction. The file server Web service can assist in copying files between nodes as discussed above being active in each node and accepting requests to transfer data between nodes.

When a user submits a query it can be desirable to hide all information from the user relating to the number and levels of nodes used to process the query as well as other such information. When the user submits an instance query a series of jobs will be created in the system as discussed above that are sent to specific nodes that will execute the instance query on the local data stores. The query sent to each node can be modified or wrapped to include information such that the result of the query creates another table such as may be given a random or otherwise unique identifier ID . The results from the instance query then can be placed into this temporary table for each node processing an instance query. Since each node has executed the same instance query on an identically structured table the temporary tables will have the same structure.

An example of this is shown in the table hierarchy of . Each node in this example processes a table from a local data store here a Logs table. The instance query for each node causes a table to be created here referred to as Temp . The results of the instance query for each node here a count CNT is stored in the temp table for that node. The results in the temporary tables then can be transferred to the assigned parent node as designated by the scheduling service. When the parent node receives the job and query from the scheduling service the parent node creates another temporary table according to the schema and copies in the data from the temporary tables from the child nodes. In this example the new temporary table on each parent node is referred to as Temp 2. The two parent nodes in this example thus have the results of the instance query from all their child nodes inside the temporary table.

Since there are no intermediate queries in this example each of nodes D and E executes a summary query which results in a data set that defines a table structure and another temporary table is created on each respective node herein referred to as a temporary summary or Sum Temp table. The steps of creating another table and inserting the data from each node into that table for a parent node are repeated creating table Temp 3 which contains the results from nodes D and E. Since there is only one node at this top level the summary query is executed regardless of the presence of any intermediate queries. A temporary summary table can be created to store the results of the summary query until the results are stored to the location specified by the user.

In this example it is assumed that a process has inserted log entries into the table for each instance node. The example assumes that an instance query is submitted that wants to obtain a count of all records having a specified aspect such as each log entry for a previous day. The instance query thus can look like the following 

In conventional systems a user would have to try to load all data into a single device and then execute a single query. Such an approach can be problematic when the data set gets sufficiently large as the performance of the system can decrease significantly. Further such an approach would require expensive specialized hardware. In the distributed approaches described herein relatively inexpensive and conventional computing devices can be used to perform the processing in a distributed parallel fashion. Further such an approach allows for the number of nodes and or levels used to process the data to be determined and or adjusted dynamically such as may depend upon the size of the data set for each request. The depth e.g. number of levels of the processing tree can be based in part on the number of nodes and the size of the data set. A query such as an intermediate or summary query then can be repeated at multiple levels if necessary depending upon the depth of the tree and the capacity of the nodes. In such a system once the data is loaded into the nodes then there will not be a need to reparse the data. Any number of queries can be executed against the data and these queries can run in parallel as discussed above. Further each node can have multiple tables loaded and can be running queries in parallel against different tables.

When determining the node structure dynamically the query engine service can take all the nodes and shuffle them and then can assign jobs and choose nodes randomly. In other embodiments the query engine service can select nodes based on factors such as load performance and capacity. The scheduler can determine factors such as the number of nodes needed for the various jobs etc. In some embodiments the depth of the tree structure can be determined at least in part by the user who can specify factors such as how large the result set is expected to be. In other embodiments each layer is created and the number of nodes assigned based upon results of processing the previous layer. Other embodiments determine the tree structure automatically based on factors such as load on the system size of the data set aspects of the query etc. A schema manager or other component also can collect statistics about the system each node etc. such that when enough data is available the necessary tree structure can be predicted relatively accurately.

Once the number of nodes and levels is determined jobs are created and scheduled that are distributed initially to at least the first level of nodes accounting for any dependencies between jobs . Once the instance jobs are completed the results of the instance jobs are passed to the nodes for the next level which can include intermediate combine and or summary jobs and the next level of jobs are executed on the selected nodes . As discussed there may be multiple levels of jobs such that data has to be passed to the appropriate node s for summarizing. If the process is at the top level and the data is summarized on a single node the results are written to the specified destination . Otherwise the process continues with data being passed to the next level of nodes and a query is executed on each node of that level.

As discussed above the various embodiments can be implemented in a wide variety of operating and or electronic environments which in some cases can include one or more user computers computing devices or processing devices which can be used to operate any of a number of applications. User or client devices can include any of a number of general purpose personal computers such as desktop or laptop computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also can include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also can include other electronic devices such as dummy terminals thin clients gaming systems and other devices capable of communicating via a network.

Most embodiments utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of commercially available protocols such as TCP IP OSI FTP UPnP NFS CIFS and AppleTalk. The network can be for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network and any combination thereof.

In embodiments utilizing a Web server the Web server can run any of a variety of server or mid tier applications including HTTP servers FTP servers CGI servers data servers Java servers and business application servers. The server s also may be capable of executing programs or scripts in response requests from user devices such as by executing one or more Web applications that may be implemented as one or more scripts or programs written in any programming language such as Java C C or C or any scripting language such as Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM .

The environment can include a variety of data stores and other memory and storage media as discussed above. These can reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers are remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device can include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU at least one input device e.g. a mouse keyboard controller or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also can include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader can be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or Web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the a system device. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

For the Examiner s convenience Applicants note that this application is a continuation of U.S. Pat. No. 8 612 476 which is a continuation of U.S. Pat. No. 8 312 037. The claims of the present application are different and possibly at least in some aspects broader in scope than the claims pursued in the parent application. To the extent any prior amendments or characterizations of the scope of any claim of the parent or any cited documents could be construed as a disclaimer of any subject matter supported by the present disclosure Applicants hereby rescind and retract such disclaimer. Accordingly the references previously presented in the parent applications may need to be revisited.

