---

title: Enhancing video conferences
abstract: Implementations generally relate to enhancing video conferences. In some implementations, a method includes determining one or more characteristics of a video stream provided by a first camera. The method further includes determining one or more functions of the first camera based on the one or more characteristics. The method further includes enabling a browser to control the one or more functions of the first camera, and wherein the browser is remote relative to the first camera.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09661208&OS=09661208&RS=09661208
owner: Google Inc.
number: 09661208
owner_city: Mountain View
owner_country: US
publication_date: 20151113
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 14 171 086 filed Feb. 3 2014 now U.S. Pat. No. 9 215 411 the contents of which are incorporated herein by reference in their entirety.

Video conferencing enables participants to share video and audio content with each other in real time across geographically dispersed locations. A communication device at each location typically uses a video camera and microphone to send video and audio streams and uses a video monitor and speaker to play received video and audio streams. Video conferencing involves digital compression of video and audio streams which are transmitted in real time across a network from one location to another. The communication devices perform the compressing and decompressing of the video and audio streams and maintain the data linkage via the network.

Implementations generally relate to enhancing video conferences. In some implementations a method includes determining one or more characteristics of a video stream provided by a first camera. The method further includes determining one or more functions of the first camera based on the one or more characteristics. The method further includes enabling a browser to control the one or more functions of the first camera and where the browser is remote relative to the first camera.

With further regard to the method in some implementations the one or more functions include controls for one or more of exposure contrast white balance temperature and aperture. In some implementations the one or more functions include controls for one or more of capture rate and flicker. In some implementations the one or more functions include controls for one or more of panning and zooming. In some implementations the enabling of the browser to control the one or more functions includes providing one or more controls in the browser where the one or more controls correspond to the one or more functions. In some implementations the enabling of the browser to control the one or more functions includes analyzing one or more video characteristics associated with the video stream and providing one or more controls in the browser based on the analyzing of the one or more video characteristics where the one or more controls correspond to the one or more functions. In some implementations the enabling of the browser to control the one or more functions includes providing one or more controls in the browser where the one or more controls correspond to the one or more functions and where the one or more controls correspond to one or more settings associated with the one or more functions. In some implementations the first camera is associated with a first user and the browser is associated with a second user.

In some implementations a method includes determining one or more characteristics of a video stream provided by a first camera. The method further includes determining one or more functions of the first camera based on the one or more characteristics where the one or more functions include controls for one or more of capture rate flicker white balance exposure contrast temperature and aperture. The method further includes enabling a browser to control the one or more functions of the first camera where the browser is remote relative to the first camera where the enabling of the browser to control the one or more functions includes providing one or more controls in the browser and where the one or more controls correspond to the one or more functions.

With further regard to the method in some implementations the one or more functions include controls for one or more of panning and zooming. In some implementations the enabling of the browser to control the one or more functions includes analyzing one or more video characteristics associated with the video stream and providing one or more controls in the browser based on the analyzing of the one or more video characteristics where the one or more controls correspond to the one or more functions. In some implementations the enabling of the browser to control the one or more functions includes providing one or more controls in the browser where the one or more controls correspond to the one or more functions and where the one or more controls correspond to one or more settings associated with the one or more functions. In some implementations the enabling of the browser to control the one or more functions includes overriding one or more settings associated with the one or more functions.

In some implementations a system includes one or more processors and logic encoded in one or more tangible media for execution by the one or more processors. When executed the logic is operable to perform operations including determining one or more characteristics of a video stream provided by a first camera determining one or more functions of the first camera based on the one or more characteristics and enabling a browser to control the one or more functions of the first camera and where the browser is remote relative to the first camera.

With further regard to the system in some implementations the one or more functions include controls for one or more of exposure contrast white balance temperature and aperture. In some implementations the one or more functions include controls for one or more of capture rate and flicker. In some implementations the one or more functions include controls for one or more of panning and zooming. In some implementations to enable the browser to control the one or more functions the logic when executed is further operable to perform operations including providing one or more controls in the browser and where the one or more controls correspond to the one or more functions. In some implementations to enable the browser to control the one or more functions the logic when executed is further operable to perform operations including analyzing one or more video characteristics associated with the video stream and providing one or more controls in the browser based on the analyzing of the one or more video characteristics where the one or more controls correspond to the one or more functions. In some implementations to enable the browser to control the one or more functions the logic when executed is further operable to perform operations including providing one or more controls in the browser where the one or more controls correspond to the one or more functions and where the one or more controls correspond to one or more settings associated with the one or more functions.

Implementations described herein enhance video conferences. In various implementations a system determines one or more functions of a first camera providing a video stream where the first camera is associated with a first user. In some implementations the functions may include controls for one or more of capture rate flicker white balance exposure contrast temperature aperture panning and zooming.

The system then enables a browser to control the one or more functions of the first camera where the browser is associated with a second user and where the browser is remote relative to the first camera. In some implementations the enabling of the browser to control the one or more functions includes analyzing one or more video characteristics associated with the video stream and providing one or more controls in the browser based on the analyzing of the one or more video characteristics where the one or more controls correspond to the one or more functions and where the one or more controls correspond to one or more settings associated with the one or more functions. In some implementations the enabling of the browser to control the one or more functions includes overriding the one or more settings associated with the one or more functions.

For ease of illustration shows one block for each of system server device and social network database and shows four blocks for client devices and . Blocks and may represent multiple systems server devices and social network databases. Also there may be any number of client devices. In other implementations network environment may not have all of the components shown and or may have other elements including other types of elements instead of or in addition to those shown herein.

In various implementations users U U U and U may communicate with each other using respective client devices and . For example users U U U and U may interact with each other in a multi user video conference where respective client devices and transmit media streams to each other.

In the various implementations described herein processor of system causes the elements described herein e.g. browser control buttons etc. to be displayed in a user interface on one or more display screens.

In various implementations system may utilize a recognition algorithm to enhancing a video conference. Example implementations of recognition algorithms are described in more detail below.

In various implementations the one or more characteristics may include more advanced aspects of a video. For example system may determine values for power line frequency anti flicker flicker capture rate backlight compensation focus etc.

In various implementations system detects behavior in the video stream and detects where any one or more of these characteristics are not optimal. For example in some implementations system may determine if the color saturation the video stream is off if there is flicker in the video stream etc. In the flicker example electricity in some countries may run at one frequency e.g 50 hertz Hz but a given camera may be set to another frequency e.g. 60 Hz which may cause flicker. System detects such flicker characteristics. As described below system may provide a user with controls to remotely modify the frequency settings of the camera in order to correct for flicker and or system may automatically modify such settings to correct for flicker.

In various implementations system may determine the one or more characteristics of the video stream based on image processing at any suitable location. For example in some implementations system may perform the processing local to system or at any other server accessible to system . In some implementations system may cause some image processing to occur at any suitable browser. For example if the images are processes at any one or more of the browsers associated with the video conference. System may access such data from any one or more of such browsers and then analyze the data in order to determined the characteristics of the video stream.

In some implementations the one or more characteristics may include features and or elements in a video. For example system may detect faces in the video whether faces as objects or particular faces associated with particular users. In some implementations system may detect skin tone of particular faces on the video.

The particular characteristics and particular combination of characteristics will vary depending on the specific implementation. System may use any suitable recognition algorithm to detect the characteristics described herein. Example implementations of recognition algorithms are described in more detail below.

In block system determines one or more functions of the first camera based on the one or more characteristics. For example in various implementations system determines the functions by checking the application programming interface API functions associated with each camera providing a video stream in the video conference.

In some implementations system determines the functions by checking the low level API functions associated with each camera providing a video stream in the video conference. Such low level API functions enable system to control fine grained settings including presets native events etc.

In various implementations the one or more functions may include controls for basic aspects of a video. For example system may determine available controls for exposure exposure time brightness contrast saturation sharpness white balance temperature e.g. white balance temperature aperture etc. In various implementations the one or more functions may include controls for more advanced aspects of a video. For example system may determine values for power line frequency anti flicker flicker capture rate backlight compensation focus etc. In the flicker example described above system may determine if any settings associated with flicker e.g. anti flicker are available for modification via the low level API.

In various implementations the one or more functions may include one or more controls for video effects. For example in some implementations system may determine functions for panning zooming tilt etc.

In various implementations system determines the functions described herein based on the determined characteristics e.g. from block . In some implementations system may specifically determine a particular function based on a particular characteristic.

For example in one scenario system may detect a particular skin tone in the video stream. That particular determination may trigger system to determine from the low level API functions if panning zooming tilt etc. are available. Similarly system may determine such low level API functions e.g. panning zooming tilt etc. based on detection of objects such as faces etc.

In block system enables a browser to control the one or more functions of the first camera where the browser is remote relative to the first camera. In various implementations the first camera is associated with a first user and the browser is associated with a second user. In various implementations described herein control of camera setting may be performed in real time or based on stored settings in a database. In either case control data may be passed to the browser associated with the camera being controlled via any suitable data connection protocol such as transfer protocol HTTP Web Real Time Communication WebRTC data channel API etc.

As described in various implementations herein the control of functions of the first camera may be performed by user provided manipulation of controls by system automatically manipulating controls or by preset settings stored in a database. System may then cause appropriate control signals to be pushed to the browser and or other software associated with a given camera. The browser or software may then in turn push the control signals to the camera for direct control of the camera hardware or for control over software that modifies the video stream.

In various implementations first camera is associated with a first user. For ease of illustration various example implementations are described herein in the context of first camera . These implementations also apply each camera involved in a multi user video conference. For example these implementations may apply to second camera associated with a second user. In such an example the browser controlling second camera may be browser or any browser that is remote to second camera where browser is associated with the first user. The various implementations described herein may apply to any type of browser. Furthermore while implementations are described herein in the contact of browsers these implementations also apply to other softer applications that may be use for a video conference.

Referring to in various implementations to enable browser to control one or more functions of remote camera system provides one or more controls in browser where the one or more controls correspond to the one or more functions. In various implementations system causes such controls to be displayed in browser in real time as system determines the available functions of low level API . In other words the controls that where not previously displayed in browser become displayed after determining the available functions. For ease of illustration controls are described in the context of browser . In various implementations system may cause such controls to be displayed in other browsers not shown that are associated with other users in the particular video conference. Such other browsers may also include browser .

In various implementations system may detect face using an appropriate facial recognition algorithm as described herein. System may detect face by detecting the skin tone of particular faces on the video. For ease of illustration one face is shown. In other example implementations there may be multiple faces in a given video stream that system detects.

In various implementations to enable browser to control the one or more functions system analyzes one or more video characteristics associated with the video stream provided by camera as described in block of . In this particular example the characteristics include a face and or skin tone. Other characters are possible such as the other characteristics described herein. System then provides one or more controls in browser based on the analyzing of the video characteristics. As indicated herein the one or more controls correspond to the one or more determined functions. In various implementations the one or more controls correspond to the one or more settings associated with the one or more functions. In various implementations to enable browser to control the one or more functions system overrides one or more settings of camera associated with the one or more functions.

In some implementations where system detects multiple faces in a given video stream. System may based on such detection further detect available functions such as pan tilt and or zoom. System may then provide controls to manipulate the camera capturing the video stream to pan tilt and or zoom in order to focus on a single participant in the same room as other participants. In some implementations system may automatically manipulate the controls to cause the camera to pan tilt and or zoom to focus on a single participant based on facial recognition. In some implementations system may also enable a remote user to manipulate the controls to cause the camera to pan tilt and or zoom to focus on a single participant.

In some implementations system may use other suitable recognition algorithms to pan tilt and or zoom to focus on a particular participant. For example system may use a recognition algorithm to detect lip movement in order to determine which participant to potentially focus on. In some implementations through the use of microphones and or sound analysis system may enable controls for panning tilting and zooming on a particular participant in a room. For example system may enable controls to move the camera towards the loudest signal. In some implementations system may triangulate information using multiple microphones. Example controls are described in more detail below in connection with .

As describe herein system may automatically apply changes to camera settings based on the determined characteristics. For example based on the detection of a face whether by facial recognition and or by detection of skin tone system may cause the video stream to zoom in and or track the head of the person talking. Such zooming and or tracking may be performed using hardware control of the camera and or software control of the video stream.

In some implementations system may enable controls to zoom in on a given object or element in the video stream. For example in some implementations system may detect a given face such as face and then provide controls in browser to focus zoom in on face . In some implementations system may cause camera to record in a high resolution mode and then enable zoom controls to zoom in on face . In some implementations system may enable a user e.g. the user associated with browser to apply a rectangle to indicate where to zoom. In some implementations where the display is a touch screen system may enable the user to zoom in and out using the user s fingers as well as to perform other functions such as panning tilting etc.

In various implementations changes in settings may modify a video stream using hardware software or combination thereof. In some implementation if hardware is being controlled e.g. hardware of camera changes may be viewed on all browsers associated with the video conference. In some implementations if software is being controlled e.g. at any given browser changes may be viewed at any one or more browsers e.g. at browser and need not be viewed on all browsers.

In some implementations system may enable the user who owns the camera being remotely manipulated to place some limitations on the control. For example system may enable that user to view how the video stream is being changed and or limit how the video is being changed e.g. placing some limits on panning zooming etc. .

As indicated above in some implementations system may store one or more settings e.g. favorite settings for a given user in a database. System may later automatically apply such settings whenever the user associated with the settings enters a video conference. In some implementations if the settings for a given user is applied and that user then leaves the video conference the settings may return to default settings.

As indicated above while some implementations are described herein in the context of system providing controls for a remote user to manipulate system may apply such change automatically without require action from a user. For example system may automatically detect flicker and then automatically apply anti flicker changes to a camera such as camera .

While some implementations are described herein in the context of improving suboptimal characteristics in a video stream these implementations and others may also apply to other characteristics for entertainment and or artistic purposes. For example system may enable a user to remotely modify the colors of a video stream e.g. color to black and white etc. .

In some implementations system may enable a given user to modify the frame rate of a video stream. For example if the frame rate is 15 frames per second instead of a desired 30 system may detect such a low frame rate and based on such detection provide controls to change the frame rate. Such control may be useful for example to a user who uses sign language. Such a user may prefer to have a higher frame rate even at the expense of video quality.

Implementations described herein provide various benefits. For example implementations enable each user e.g. video conference participant to optimize various characteristics of video streams from his or her browser. Implementations also enable each user to optimize various characteristics of video streams that are typically managed at a particular video camera. Implementations described herein also increase overall engagement among users in a social networking environment.

Although the steps operations or computations may be presented in a specific order the order may be changed in particular implementations. Other orderings of the steps are possible depending on the particular implementation. In some particular implementations multiple steps shown as sequential in this specification may be performed at the same time. Also some implementations may not have all of the steps shown and or may have other steps instead of or in addition to those shown herein.

While system is described as performing the steps as described in the implementations herein any suitable component or combination of components of system or any suitable processor or processors associated with system may perform the steps described.

In various implementations system may utilize a variety of recognition algorithms to recognize faces landmarks objects etc. in images. Such recognition algorithms may be integral to system . System may also access recognition algorithms provided by software that is external to system and that system accesses.

In various implementations system enables users of the social network system to specify and or consent to the use of personal information which may include system using their faces in images or using their identity information in recognizing people identified in images. For example system may provide users with multiple selections directed to specifying and or consenting to the use of personal information. For example selections with regard to specifying and or consenting may be associated with individual images all images individual photo albums all photo albums etc. The selections may be implemented in a variety of ways. For example system may cause buttons or check boxes to be displayed next to various selections. In some implementations system enables users of the social network to specify and or consent to the use of using their images for facial recognition in general. Example implementations for recognizing faces and other objects are described in more detail below.

In situations in which the systems discussed here collect personal information about users or may make use of personal information the users may be provided with an opportunity to control whether programs or features collect user information e.g. information about a user s social network social actions or activities profession a user s preferences or a user s current location or to control whether and or how to receive content from the content server that may be more relevant to the user. In addition certain data may be treated in one or more ways before it is stored or used so that personally identifiable information is removed. For example a user s identity may be treated so that no personally identifiable information can be determined for the user or a user s geographic location may be generalized where location information is obtained such as to a city ZIP code or state level so that a particular location of a user cannot be determined. Thus the user may have control over how information is collected about the user and used by a content server.

In various implementations system obtains reference images of users of the social network system where each reference image includes an image of a face that is associated with a known user. The user is known in that system has the user s identity information such as the user s name and other profile information. In some implementations a reference image may be for example a profile image that the user has uploaded. In some implementations a reference image may be based on a composite of a group of reference images.

In some implementations to recognize a face in an image system may compare the face e.g. image of the face and match the face to reference images of users of the social network system. Note that the term face and the phrase image of the face are used interchangeably. For ease of illustration the recognition of one face is described in some of the example implementations described herein. These implementations may also apply to each face of multiple faces to be recognized.

In some implementations system may search reference images in order to identify any one or more reference images that are similar to the face in the image. In some implementations for a given reference image system may extract features from the image of the face in an image for analysis and then compare those features to those of one or more reference images. For example system may analyze the relative position size and or shape of facial features such as eyes nose cheekbones mouth jaw etc. In some implementations system may use data gathered from the analysis to match the face in the image to one more reference images with matching or similar features. In some implementations system may normalize multiple reference images and compress face data from those images into a composite representation having information e.g. facial feature data and then compare the face in the image to the composite representation for facial recognition.

In some scenarios the face in the image may be similar to multiple reference images associated with the same user. As such there would be a high probability that the person associated with the face in the image is the same person associated with the reference images.

In some scenarios the face in the image may be similar to multiple reference images associated with different users. As such there would be a moderately high yet decreased probability that the person in the image matches any given person associated with the reference images. To handle such a situation system may use various types of facial recognition algorithms to narrow the possibilities ideally down to one best candidate.

For example in some implementations to facilitate in facial recognition system may use geometric facial recognition algorithms which are based on feature discrimination. System may also use photometric algorithms which are based on a statistical approach that distills a facial feature into values for comparison. A combination of the geometric and photometric approaches could also be used when comparing the face in the image to one or more references.

Other facial recognition algorithms may be used. For example system may use facial recognition algorithms that use one or more of principal component analysis linear discriminate analysis elastic bunch graph matching hidden Markov models and dynamic link matching. It will be appreciated that system may use other known or later developed facial recognition algorithms techniques and or systems.

In some implementations system may generate an output indicating a likelihood or probability that the face in the image matches a given reference image. In some implementations the output may be represented as a metric or numerical value such as a percentage associated with the confidence that the face in the image matches a given reference image. For example a value of 1.0 may represent 100 confidence of a match. This could occur for example when compared images are identical or nearly identical. The value could be lower for example 0.5 when there is a 50 chance of a match. Other types of outputs are possible. For example in some implementations the output may be a confidence score for matching.

For ease of illustration shows one block for each of processor operating system memory I O interface social network engine and media application . These blocks and may represent multiple processors operating systems memories I O interfaces social network engines and media applications. In other implementations server device may not have all of the components shown and or may have other elements including other types of elements instead of or in addition to those shown herein.

Although the description has been described with respect to particular embodiments thereof these particular embodiments are merely illustrative and not restrictive. Concepts illustrated in the examples may be applied to other examples and implementations. For example some implementations are described herein in the context of a social network system. However the implementations described herein may apply in contexts other than a social network. For example implementations may apply locally for an individual user.

Note that the functional blocks methods devices and systems described in the present disclosure may be integrated or divided into different combinations of systems devices and functional blocks as would be known to those skilled in the art.

Any suitable programming languages and programming techniques may be used to implement the routines of particular embodiments. Different programming techniques may be employed such as procedural or object oriented. The routines may execute on a single processing device or multiple processors. Although the steps operations or computations may be presented in a specific order the order may be changed in different particular embodiments. In some particular embodiments multiple steps shown as sequential in this specification may be performed at the same time.

A processor includes any suitable hardware and or software system mechanism or component that processes data signals or other information. A processor may include a system with a general purpose central processing unit multiple processing units dedicated circuitry for achieving functionality or other systems. Processing need not be limited to a geographic location or have temporal limitations. For example a processor may perform its functions in real time offline in a batch mode etc. Portions of processing may be performed at different times and at different locations by different or the same processing systems. A computer may be any processor in communication with a memory. The memory may be any suitable data storage memory and or non transitory computer readable storage medium including electronic storage devices such as random access memory RAM read only memory ROM magnetic storage device hard disk drive or the like flash optical storage device CD DVD or the like magnetic or optical disk or other tangible media suitable for storing instructions for execution by the processor. The software instructions can also be contained in and provided as an electronic signal for example in the form of software as a service SaaS delivered from a server e.g. a distributed system and or a cloud computing system .

