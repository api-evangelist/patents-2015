---

title: System and method of providing speech processing in user interface
abstract: Disclosed are systems, methods and computer-readable media for enabling speech processing in a user interface of a device. The method includes receiving an indication of a field and a user interface of a device, the indication also signaling that speech will follow, receiving the speech from the user at the device, the speech being associated with the field, transmitting the speech as a request to public, common network node that receives and processes speech, processing the transmitted speech and returning text associated with the speech to the device and inserting the text into the field. Upon a second indication from the user, the system processes the text in the field as programmed by the user interface. The present disclosure provides a speech mash up application for a user interface of a mobile or desktop device that does not require expensive speech processing technologies.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09530415&OS=09530415&RS=09530415
owner: AT&T Intellectual Property I, L.P.
number: 09530415
owner_city: Atlanta
owner_country: US
publication_date: 20151030
---
The present application is a continuation of U.S. patent application Ser. No. 12 128 345 filed May 28 2008 which is the non provisional of U.S. Provisional Application No. 61 022 668 filed Jan. 22 2008 the contents of which are incorporated herein by reference in their entirety.

The present invention relates to speech processing and more specifically relates to providing speech processing in a user interface of a client device via a common network node that receives and processes speech and returns text to the client device.

The present Disclosure generally relates to a desire and a need in the speech environment to improve on the ability of individuals and companies to create voice enabled services over a network. For example typically companies that utilize voice enabled services from such companies as Nuance and AT T may often need to invest a large amount of money in a customized system. In a standard spoken dialog system there are many components that need training and development in order to operate effectively to both receive speech from a user and generate it in an intelligent and conversational synthetic response. An automatic speech recognition ASR module converts a user s audible voice input into text. The text can be transmitted to a spoken language understanding SLU module which will seek to identify the intent or the purpose of the words spoken by the user. The output from the SLU module is communicated to a dialog management DM module which processes the meaning identified by the SLU module and generates an appropriate response. The substance of the response is transmitted to a text to speech synthesis TTS module which will synthesize an audio output that is communicated to and heard by the user. Various training data is utilized to communicate with each of these modules in order to enable the experience to be as life like as possible for the user. For many companies there is a large barrier to entry for building voice enabled services. Due to the high degree of expertise needed to provide any services utilizing such features as speech recognition or speech synthesis the barrier can be very high. Complex components include speech processing engines hardware a large database of speech in order to make the experience realistic enough for users to be used and profitable and so forth. A large investment in money and expertise is needed prior to generating any revenue for any aspect of a voice enabled service.

Because of this barrier very few companies are capable of affording and building voice enabled services that don t own the engine or the servers. Those that do not own the speech processing engines however do have many profitable technologies that do not relate to voice enabled services. For example many companies may know how to build and deploy a messaging system communication system or particular websites for performing a wide variety of web based services. Websites such as Amazon.com and Travelocity.com have pioneered web based processes for purchasing products online and reserving airfare car rentals and hotel rooms.

What is needed in the art is an improved mechanism for enabling companies that already have expertise in one particular area to be able to build in a voice component into their website or other user interface without the need of spending a large amount of money to custom design buy or license the complex engines and servers necessary for voice enabled services. Accordingly what is needed generally in the art is an improved ability for users to be able to easily implement voice enabled services especially in the context of a browser on a desktop or laptop computer or via a mobile device.

Additional features and advantages of the invention will be set forth in the description which follows and in part will be obvious from the description or may be learned by practice of the invention. The features and advantages of the invention may be realized and obtained by means of the instruments and combinations particularly pointed out in the appended claims. These and other features of the present invention will become more fully apparent from the following description and appended claims or may be learned by the practice of the invention as set forth herein.

The present invention addresses the deficiencies set forth above and provides an architecture and a design that lowers the barrier of entry to make it easier for entities to write applications for any network but that can utilize an application programming interface API within the network that provides voice enabled services or speech technology from the network. The API would allow anybody anywhere to access the technology wherein a particular user face can include a relatively small amount of code to have a voice enabled application written into it. The approach disclosed herein simplifies the creation of new services because the speech processing part is done in the network and accessible via an IP protocol rather than over a phone communication.

Embodiments of the invention include systems methods and computer readable media for enabling speech processing in a user interface of a device. The method embodiment includes receiving an indication of a field in a user interface of a device the indication also signaling that speech will follow. One embodiment relates to a method of enabling speech processing in a user interface of a device. The method includes receiving an indication of a field in a user interface of a device the indication also signaling that speech will follow receiving the speech from a user at the device the speech being associated with the field transmitting the speech as a request to a public common network node that receives speech wherein the request comprises at least one standardized parameter to control a speech recognizer on the network node receiving text associated with the speech from the network node at the device and inserting the text into the field.

An illustrative embodiment of this method in the context of a directory assistance service on a mobile device will be found in the body of the specification below. A system is described that performs the various steps of the method. Once the system receives an indication of a field in a user interface of the device the system receives the speech from the user at the device transmits the speech as an HTTP request to a network server processes the transmitted speech and returns text associated with the speech to the device and inserts text into the field. The network server represents a public common network node that receives speech from one or more client devices. In this regard this aspect of the disclosure enables a company to provide the ability of interacting with the user interface via speech to provide input into various fields of the interface without the need of developing or owning the various components of a voice enabled service as would normally be required. In one aspect the system receives a second indication from the user and upon receiving the second indication the system processes the text in the field as programmed by the user interface. The second indication from the user may signal that the speech intended for a particular field has ended and that the back end processing should process the speech in return in the text into the input field on the device. Then the second indication is essentially the equivalent of the context wherein absent the voice enabled service associated with the interface a user had typed into the field the desired text and hit an enter key or a search key for processing the request.

Various embodiments of the invention are discussed in detail below. While specific implementations are discussed it should be understood that this is done for illustration purposes only. A person skilled in the relevant art will recognize that other components and configurations may be used without parting from the spirit and scope of the invention.

With reference to an exemplary system includes a general purpose computing device including a processing unit CPU and a system bus that couples various system components including the system memory such as read only memory ROM and random access memory RAM to the processing unit . Other system memory may be available for use as well. It can be appreciated that the invention may operate on a computing device with more than one CPU or on a group or cluster of computing devices networked together to provide greater processing capability. The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. A basic input output BIOS stored in ROM or the like may provide the basic routine that helps to transfer information between elements within the computing device such as during start up. The computing device further includes storage devices such as a hard disk drive a magnetic disk drive an optical disk drive tape drive or the like. The storage device is connected to the system bus by a drive interface. The drives and the associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the computing device . The basic components are known to those of skill in the art and appropriate variations are contemplated depending on the type of device such as whether the device is a small handheld computing device a desktop computer or a computer server.

Although the exemplary environment described herein employs the hard disk it should be appreciated by those skilled in the art that other types of computer readable media which can store data that are accessible by a computer such as magnetic cassettes flash memory cards digital versatile disks cartridges random access memories RAMs read only memory ROM a cable or wireless signal containing a bit stream and the like may also be used in the exemplary operating environment.

To enable user interaction with the computing device an input device represents any number of input mechanisms such as a microphone for speech a touch sensitive screen for gesture or graphical input keyboard mouse motion input speech and so forth. The device output can also be one or more of a number of output mechanisms known to those of skill in the art. In some instances multimodal systems enable a user to provide multiple types of input to communicate with the computing device . The communications interface generally governs and manages the user input and system output. There is no restriction on the invention operating on any particular hardware arrangement and therefore the basic features here may easily be substituted for improved hardware or firmware arrangements as they are developed.

For clarity of explanation the illustrative system embodiment is presented as comprising individual functional blocks including functional blocks labeled as a processor . The functions these blocks represent may be provided through the use of either shared or dedicated hardware including but not limited to hardware capable of executing software. For example the functions of one or more processors presented in may be provided by a single shared processor or multiple processors. Use of the term processor should not be construed to refer exclusively to hardware capable of executing software. Illustrative embodiments may comprise microprocessor and or digital signal processor DSP hardware read only memory ROM for storing software performing the operations discussed below and random access memory RAM for storing results. Very large scale integration VLSI hardware embodiments as well as custom VLSI circuitry in combination with a general purpose DSP circuit may also be provided.

As noted above the basic goal of the present disclosure is to provide speech technology inside of a network with an API that allows any device to access the technology and reduce the barrier to entry for those who provide applications and interfaces for desktops laptops and mobile devices. Thus with the concepts disclosed herein one of skill in the art of programming a standard user interface may be able to enhance that interface to provide additional voice or speech technologies without the need for spending a prohibitive amount of money or requiring a high level of expertise as has traditionally been the case.

Therefore an aspect of the disclosure is the combination of speech with web services. illustrates a network that provides the voice enabled services and APIs. Various edge devices are shown. For example a smart phone A a cell phone B a laptop C and an iPhone D are shown. These are simply representative of the various types of devices and of course it is contemplated that any device including a desktop computer or any other type of device having a user interface may be applicable to the present invention. Each of these devices is a speech API that is used to access a database using a particular interface. The basic principles of this disclosure provide interoperability for distribution for voice enabled capabilities. For example available web services provide users with an easy and convenient way to discover and exploit new services and concepts that can be operating system independent and enable mash ups or web application hybrids.

The basic concept of a mash up or a web hybrid is known in the art. A mash up is a web application that leverages the compositional nature of public web services. For example one can be created when several data sources and services are mashed up or combined to create a new service. There are a number of known technologies used in the mash up environment. These include Simple Object Access Protocol SOAP Representational State Transfer REST Asynchronous JavaScript and XML AJAX Javascript JavaScript Object Notiation JSON and various public web services such as Google Yahoo Amazon and so forth. These protocols are known to those of skill in the art but we shall provide a basic summary of each. SOAP is a protocol for exchanging XML based messages over a network which is preferably done over HTTP HTTPS. SOAP makes use of an internet application layer protocol as a transport protocol. Both SMTP and HTTP HTTPS are valid application layer protocols used as transport for SOAP but HTTP is preferable. Several of the advantages of SOAP is that via the use of HTTP it allows easier communication between proxies and firewalls then other remote execution technology and it is versatile enough to allow the use of different transport protocols beyond HTTP such as SMTP or RTSP.

REST is a design pattern for implementing network system and is intended to evoke an image of how a well designed web application behaves. For example a network of web pages can be viewed as a virtual state machine wherein the user progresses through an application by selecting links as state transitions which result in the next page which represents the next state in the application being transferred to the user and rendered for their use. Technologies associated with the use of REST include HTTP and relative methods GET POST PUT and DELETE. Other features of REST include resources that can be identified by a URL and accessible through a resource representation which can include one or more of XML HTML GIF JPEG etc. Resource types can include text HML text HTML image GIF image JPEG and so forth. Typically the transport mechanism for REST is XML or JSON.

In an example of the REST representation the client browser references a web resource using a URL such as www.att.com. A representation of the resource is returned via an HTML document. The representation places the client in a new state and when the client selects a hyper link such as index.html it acts as another resource and the new representation places the client application into yet another state and the client application transfers state within each resource representation. These and other features of REST are known to those of skill in the art.

AJAX allows the user to send an HTTP request in a background mode and dynamically update the Document Object Model or DOM without reloading the page. The DOM is a standard platform independent representation of the HTML or XML of a web page. The DOM is used by Javascript to update a webpage dynamically. This is a feature that is supported by virtually any modern browser that supports Javascript.

JSON involves a light weight data interchange format. The features of this aspect of the environment is that it is a subset of ECMA 262 3Edition and could be language independent. Inasmuch as it is text based light weight and easy to parse it provides a preferable approach for object notation.

These various technologies are utilized in the mash up environment and mash ups which would provide service and data aggregation are typically done at the server level but there is an increasing interest in providing web based composition engines such as Yahoo Pipes Microsoft Popfly and so forth. Known in the art are different kinds of mash ups. For example there are client side mash ups in which HTTP requests and responses are generated from several different web servers and mashed up on a client device. Also known are server side mash ups in which a single HTTP request is sent to a server which separately sends another HTTP request to a second server and receives an HTTP response from that server and mashes up the content and generates a single HTTP response to the client device which can update the user interface.

As introduced above an aspect of the present disclosure is to provide speech mash ups. Speech resources can be accessible through a simple REST interface or a SOAP interface without the need for any telephony technology. An application client running on device A D is responsible for audio capture. This may be performed through various approaches such as J2ME for mobile .net Java applets for regular browsers Perl Python Java clients and so forth. The particular method or client application for audio capture is irrelevant to the present invention as long as audio capture is provided. Server side support is required for sending and receiving speech packets over HTTP or another protocol. This may be a process that is similar to the real time streaming protocol RTSP inasmuch as a session ID may be used to keep track of the session when needed. Client side support is preferable for sending and receiving speech packets over HTTP SMTP or other protocols. The system may use AJAX pseudo threading in the browser or any other HTTP client technology. Also required is support for both client and server side mash up approaches as discussed above.

Returning to network includes media servers which can provide at least ASR and TTS technologies. The media servers represent a common public network node that processes received speech from various client devices. Servers can communicate with various third party communications . Another network based application is shown as a network based application . This may represent an application that provides such services as the 411 service . The benefits of this particular approach enable many new services and provide additional vendors and new business models for many different applications. As is shown the various applications and may involve a number of different types of services and user interfaces. Several examples are shown. These include the 411 service any type of advertising collaborative efforts blogging entertainment and information and search . These services provide only a general description of several different types of several different businesses or business models and of course any kind of interaction with a user interface may benefit from the basic speech mash up discussed herein. One advantage of the present invention is while many traditional web players are publishing their APIs such as Yahoo Google Amazon and so forth mobile communication providers such as Vodafone and British Telecom are entering the service space by making telephony and mobile based APIs available. By publishing advanced speech recognition APIs and TTS APIs as web services this enables the opportunity to attract even more innovative concepts and ideas with potential revenues for a network based or the provider of such speech services.

One possible network that would be particularly suitable for the technologies disclosed herein is the IP Multi media Subsystem IMS . IMS wireline and wireless network seamless mobility and convergence of services and devices in one consistent architecture is an ideal environment for advanced speech and multi modal services. The present invention also provides synergies with location based services WIFI 3G GPRS EGPRS EDGE mobility instant messaging presence information video and picture sharing conferencing IPTV Voice over IP and so forth.

In an exemplary embodiment the system combines the current location of a tourist like Gettysburg with the home location of the tourist like Texas. The system selects an appropriate grammar based on what the system is likely to encounter when interfacing with individuals from Texas visiting Gettysburg. The system selects a grammar to anticipate either a Texas southern drawl accent or a Hispanic accent. The system selects a grammar to anticipate a likely vocabulary for tourists at Gettysburg taking in to account prominent attractions commonly asked questions or other words or phrases. The system can automatically select a grammar based on available information the system can present its best guess for a grammar to the user for confirmation or the system can offer a list of grammars to the user for a selection of the most appropriate.

The system receives the speech from the user at the device the speech being associated with the field . The system transmits the speech as a request to a public common network node that receives speech. The request includes at least one standardized parameter to control a speech recognizer in the network node . The client device controlled by the user will receive text associated with the speech at the device and insert the text into the field .

Next the user clicks on button which labels the find field . Again this is another example wherein the system will receive an indication of another field in the user interface of the device which also signals that speech will follow. Here after the user touches the find label the user says Japanese Restaurants. The user then touches the find button again which is an ending indication from the user that the speech has ceased. The system then again performs steps to process the speech Japanese Restaurants to recognize the speech and return the text and insert it into the Find field . Based on these two interactions the user has indicated that they want to find Japanese restaurants in Florham Park N.J. As noted above a step in the method involves receiving a speech from the user at the device the speech being associated with the field . Optionally the user may provide a second indication notifying the system to start processing the text in the field as programmed by the user interface .

Further aspects of this disclosure also relate to . For example typically once the text is received from the ASR server it is inserted into the appropriate field . Then the user must provide an indication to process that text by clicking the found button . The purpose of this may be to enable the user to preview the text before processing the data in the field. One aspect of the disclosure removes this step in the process. Here the server may send an indication with the processed text that causes the user interface to process the insert text without further user input. This may optionally be done only if the speech recognizer recognizes speech according to a confidence threshold. Therefore for example if the speech recognizer has at least 90 confidence that the speech was recognized correctly it can transmit an instruction with the recognized text such that the text is inserted into the field and the instruction performs the find clicking operation for the user. There may be some notification accompanying this process to notify the user that the find operation is being performed and that they do not need to do anything further but to view the results of the operation. This may be an audible visual or combination of queues indicating that the operation is being performed for the user. This feature could also be enabled or disabled depending on the application.

In another aspect the system may only present an action button such as the find button associated with the text in the field only if a confidence level from the speech recognizer is below a threshold. In this case the returned text would be inserted into the field and then processed without further user input. The find button may be replaced with an indication of processing such as Searching for Japanese Restaurants . . . In another aspect if the speech recognizer returns two possible interpretations of the speech then the system may inserting each possible interpretations into a separate text field present both fields to the user with an indication instructing the user to select which text field to process. Here different find buttons may be presented next to different fields. The user can then view both simultaneously and only have to enter in a single action by clicking on the appropriate find button to process the desired request.

Embodiments within the scope of the present invention may also include computer readable media for carrying or having computer executable instructions or data structures stored thereon. Such computer readable media can be any available media that can be accessed by a general purpose or special purpose computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium which can be used to carry or store desired program code means in the form of computer executable instructions or data structures. When information is transferred or provided over a network or another communications connection either hardwired wireless or combination thereof to a computer the computer properly views the connection as a computer readable medium. Thus any such connection is properly termed a computer readable medium. Combinations of the above should also be included within the scope of the computer readable media.

Computer executable instructions include for example instructions and data which cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions. Computer executable instructions also include program modules that are executed by computers in stand alone or network environments. Generally program modules include routines programs objects components and data structures etc. that perform particular tasks or implement particular abstract data types. Computer executable instructions associated data structures and program modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps. Program modules may also comprise any tangible computer readable medium in connection with the various hardware computer components disclosed herein when operating to perform a particular function based on the instructions of the program contained in the medium.

Those of skill in the art will appreciate that other embodiments of the invention may be practiced in network computing environments with many types of computer system configurations including personal computers hand held devices multi processor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers and the like. Embodiments may also be practiced in distributed computing environments where tasks are performed by local and remote processing devices that are linked either by hardwired links wireless links or by a combination thereof through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

Although the above description may contain specific details they should not be construed as limiting the claims in any way. Other configurations of the described embodiments of the invention are part of the scope of this invention. Accordingly the appended claims and their legal equivalents should only define the invention rather than any specific examples given.

