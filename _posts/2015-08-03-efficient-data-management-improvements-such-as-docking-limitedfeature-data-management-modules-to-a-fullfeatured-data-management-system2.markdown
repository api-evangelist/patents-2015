---

title: Efficient data management improvements, such as docking limited-feature data management modules to a full-featured data management system
abstract: Software, firmware, and systems are described herein that permit an organization to dock previously-utilized, limited-feature data management modules with a full-featured data management system. By docking limited-feature data management modules to a full-featured data management system, metadata and data from the various limited-feature data management modules can be integrated and utilized more efficiently and effectively. Moreover, additional data management features can be provided to users after a more seamless transition.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09588972&OS=09588972&RS=09588972
owner: Commvault Systems, Inc.
number: 09588972
owner_city: Tinton Falls
owner_country: US
publication_date: 20150803
---
This application is a continuation of U.S. patent application Ser. No. 13 926 332 entitled EFFICIENT DATA MANAGEMENT IMPROVEMENTS SUCH AS DOCKING LIMITED FEATURE DATA MANAGEMENT MODULES TO A FULL FEATURED DATA MANAGEMENT SYSTEM filed Jun. 25 2013 now U.S. Pat. No. 9 098 514 which is a divisional of U.S. patent application Ser. No. 13 250 962 entitled EFFICIENT DATA MANAGEMENT IMPROVEMENTS SUCH AS DOCKING LIMITED FEATURE DATA MANAGEMENT MODULES TO A FULL FEATURED DATA MANAGEMENT SYSTEM filed Sep. 30 2011 now U.S. Pat. No. 8 620 870 which claims the benefit of U.S. Provisional Patent Application No. 61 388 574 entitled DETECTING AND ARCHIVING IDLE VIRTUAL MACHINES filed Sep. 30 2010 each of which is incorporated by reference in its entirety.

Comprehensive and full featured data management systems may be prohibitively expensive require an operator with specialized expertise and consume substantial processing and data storage resources. However full featured data management systems can also offer substantial benefits to an organization including top down policy driven data management data replication and protection cloud storage integration storage resource management analysis optimization and reporting data archiving deduplication compression and encryption electronic discovery E discovery privacy violation retention life cycle and compliance management backup and recovery content indexing data classification enterprise and collaborative data mining and search migration from legacy data storage solutions virtual server protection disaster recovery access control and security and many others.

One example of a data management system that provides such features is the Simpana storage management system by CommVault Systems of Oceanport N.J. The Simpana system leverages a modular storage management architecture that may include among other things storage manager components client or data agent components and media agent components as further described in U.S. Pat. No. 7 246 207 filed Apr. 5 2004 entitled SYSTEM AND METHOD FOR DYNAMICALLY PERFORMING STORAGE OPERATIONS IN A COMPUTER NETWORK. The Simpana system also may be hierarchically configured into backup cells to store and retrieve backup copies of electronic data as further described in U.S. Pat. No. 7 395 282 filed Jul. 15 1999 entitled HIERARCHICAL BACKUP AND RETRIEVAL SYSTEM.

To avoid the overhead of a comprehensive data management system an organization may initially choose to forego these advantages and instead deploy limited feature data management software applications that provide piecemeal feature coverage. For example an organization may choose to deploy a first limited feature backup application that performs data backups of a limited number of client computers as well as a second limited feature archive application that archives data. However as an organization s data management needs grow and diversify the organization may struggle to make a smooth transition from using a piecemeal patchwork of limited feature software applications to using a comprehensive and full featured data management system that provides an overarching data management framework. For example a comprehensive and full featured data management system may be unable to integrate the data and or metadata previously generated by each limited feature application used by the organization.

As a first specific example an organization may initially use a limited feature module to manage and provision virtual machines VM but later wish to receive additional features related to the management of virtual machines. In general virtualization refers to the simultaneous hosting of one or more operating systems on a physical computer. Such virtual operating systems and their associated virtual resources are called virtual machines. Virtualization software sits between the virtual machines and the hardware of the physical computer. One example of virtualization software is ESX Server by VMware Inc. of Palo Alto Calif. Other examples include Microsoft Virtual Server and Microsoft Windows Server Hyper V both by Microsoft Corporation of Redmond Wash. and Sun xVM by Oracle America Inc. of Santa Clara Calif.

Virtualization software provides to each virtual operating system virtual resources such as a virtual processor virtual memory a virtual network device and a virtual disk. Each virtual machine has one or more virtual disks. Virtualization software typically stores the data of virtual disks in files on the file system of the physical computer called virtual machine disk files in the case of VMware virtual servers or virtual hard disk image files in the case of Microsoft virtual servers . For example VMware s ESX Server provides the Virtual Machine File System VMFS for the storage of virtual machine disk files. A virtual machine reads data from and writes data to its virtual disk much the same way that an actual physical machine reads data from and writes data to an actual disk.

One advantage of virtualization is that virtual machines can be easily created. For example organizations often provide web based or other interfaces to virtualization software that allow users to easily create virtual machines. Often times however users do not delete virtual machines when the users no longer have need of the virtual machines and the virtual machines may be completely or nearly completely unused. However such virtual machines even unused consume resources e.g. memory storage space processor cycles of the physical computer on which the virtualization software operates. In certain cases the resources of the physical computer may be fully or nearly fully utilized by the virtual machines that the physical computer hosts. In such cases users may be unable to create new virtual machines until the physical computer becomes less utilized which can occur if virtual machines are shut down or deleted.

As other examples an organization may initially use a limited feature module to a provide private search capabilities b perform backups and other secondary storage operations for a limited number of client computers c create content stores or d perform other data management operations. However the organization may later wish to receive additional value added features related to these tasks.

The need exists for systems and methods that overcome the above problems as well as systems and methods that provide additional benefits. Overall the examples herein of some prior or related systems and methods and their associated limitations are intended to be illustrative and not exclusive. Other limitations of existing or prior systems and methods will become apparent to those of skill in the art upon reading the following detailed description.

The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the disclosure.

Software firmware and systems are described herein that permit an organization to interface with or dock previously utilized limited feature data management modules with a full featured data management system. By docking limited feature data management modules to a full featured data management system metadata profiles configurations and data from various limited feature data management modules can be integrated and utilized more efficiently and effectively. Moreover additional data management features can be provided to users using a more seamless transition.

This application first describes in detail one example for ease of understanding before providing details on a more generalized system. In other words this application first describes with respect to one particular example of a data management feature VM life cycle management. Second after providing an introduction to the VM life cycle management system the application describes generally how limited feature data management modules may dock or interface with a full featured data management system in order to provide additional data management features in a seamless fashion.

More specifically a software firmware and or hardware system for VM life cycle management is disclosed the virtual machine VM life cycle management system . The VM life cycle management system provides management for numerous phases in the life cycle of a virtual machine including creating the virtual machine initially providing ongoing policy based management and backup protection of the virtual machine detecting shutting down and or archiving the virtual machine when it has been idle for a period of time and restoring the virtual machine after it has been archived.

Virtual machines are hosted by virtualization software that operates on computing systems. Such virtualization software may be referred to as a virtual machine host. The VM life cycle management system monitors virtual machines to detect idle virtual machines. For example the VM life cycle management system may query virtual machine hosts or another server that manages virtual machines.

When the VM life cycle management system determines that a virtual machine has been idle for a first period of time the VM life cycle management system shuts down the virtual machine. After it has been shut down the virtual machine no longer utilizes memory and processor cycles of the computing system hosting the virtual machine. Accordingly the computing system can utilize such resources for other purposes. Additionally the system and methods described herein that relate to shutting down idle virtual machines may also be applied to idle physical machines so that the system shuts down and powers off physical machines that are determined to be idle for some predefined period of time. By shutting down idle machines either virtual or physical the life cycle management system may assist in meeting green energy certifications standards or other benchmarks such as being a Green Energy Compliant System.

After the virtual machine has been shut down for a second period of time the VM life cycle management system archives the virtual machine file associated with the virtual machine by copying the virtual machine file to a storage device and replacing the virtual machine file with a stub. The stub points or refers to the location of the copied virtual machine file. After the virtual machine file has been archived the virtual machine no longer utilizes as much storage space of the computing system as the virtual machine utilized before the archive process.

The VM life cycle management system may replace an icon normally associated with the virtual machine with a new icon corresponding to archived virtual machines thereby providing a visual indication that the virtual machine has been archived. If the VM life cycle management system detects that a user selects the archived virtual machine the VM life cycle management system can provide an option to restore and restart the virtual machine. For example upon detecting a right click of the new icon the VM life cycle management system can provide a selectable right click option to restore and restart the virtual machine. If the VM life cycle management system detects that the option is selected the VM life cycle management system can retrieve and restore the archived virtual machine file to the computing system and then start the virtual machine.

The application also provides below a first example of how a limited feature virtual machine VM life cycle management module which provides only a subset of the features of the VM life cycle management system may be docked with a full featured data management system in order to provide additional virtual machine management features.

Finally the discussion of provides additional specific examples of limited feature data management modules that may be docked with a full featured data management system in order to provide additional features including a providing private search capabilities b merging backup or other secondary data from different groups of client computers c providing top down data management from a hosted software service and d creating backup archive or other secondary copies of data stores in secondary storage. Of course many other additional features are possible.

Various examples of the invention will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand however that the invention may be practiced without many of these details. Likewise one skilled in the relevant art will also understand that the invention may include many other obvious features not described in detail herein. Additionally some well known structures or functions may not be shown or described in detail below so as to avoid unnecessarily obscuring the relevant description.

The terminology used below is to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific examples of the invention. Indeed certain terms may even be emphasized below however any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section.

The virtual machine host e.g. a VMware ESX server a Microsoft Virtual Server a Microsoft Windows Server Hyper V host or any other type of virtualization software hosts one or more virtual machines e.g. VMware virtual machines Microsoft virtual machines or any other type of virtual machine . Each virtual machine has its own operating system and one or more applications executing on the operating system or loaded on the operating system. The operating systems may be any type of operating system e.g. Microsoft Windows Linux operating systems Sun Solaris operating systems UNIX operating systems or any other type of operating system that can be hosted by the virtual machine host . The applications may be any applications e.g. database applications file server applications mail server applications web server applications transaction processing applications or any other type of application that may run on the operating systems .

Each virtual machine host has a primary storage data store that stores the virtual disks of the virtual machines . Virtual disk is used by virtual machine and virtual disk is used by virtual machine . Although each virtual machine is shown with only one virtual disk each virtual machine may have more than one virtual disk in the primary storage data store . A virtual disk corresponds to one or more virtual machine disk files e.g. one or more .vmdk .vhd files or any other type of file on the primary storage data store . The primary storage data store stores a primary copy of the data of the virtual machines . Additionally or alternatively the virtual disks may be stored by other storage devices in the environment e.g. on storage devices in a Storage Area Network SAN .

The virtual machine manager e.g. a VMware Virtual Center server a Microsoft System Center Virtual Machine Manager or any other virtual machine manager software manages or facilitates management of the virtual machines and or the virtual machine hosts . The virtual machine manager and the virtual machine hosts may each include an Application Programming Interface API component to expose or provide various types of APIs such as an API for accessing and manipulating virtual disks and an API for performing other functions related to management of virtual machines .

The virtual machine proxy includes a data agent configured to perform storage operations on data of virtual machines . The data agent is configured to access the primary storage data stores . The secondary storage computing device can initiate storage operations on the data of the virtual machines and assist in the transfer of virtual machine data by the virtual machine proxy to the storage device . The secondary storage computing device or the virtual machine proxy or any other component described herein may perform functions such as encrypting compressing single or variable instancing deduplicating and or content indexing data that is transferred to the storage device .

The components may include subcomponents modules or other logical entities that assist with or enable the performance of some or all of the functionality. For example the components include a virtual machine creation component to fulfill requests to create new virtual machines using the VM creation data . The virtual machine creation component may for example identify available resources and apply policies during virtual machine creation. The components also include an idleness determination component that uses the idleness data to determine that a virtual machine has been idle. The components also include an archiving component that archives data associated with virtual machines using the archiving data . The components also include a restore component that uses the restore data to restore data associated with virtual machines . The components also include a user interface component that provides a user interface for managing virtual machines a management component that provides virtual machine management functionality and an API component that provides functions that enable programmatic interaction with the virtual machine manager the virtual machines and or the virtual machine hosts .

While items and are illustrated as stored in memory those skilled in the art will appreciate that these items or portions of them may be transferred between memory and a persistent storage device for example a magnetic hard drive a tape of a tape library etc. for purposes of memory management data integrity and or other purposes.

The computing system further includes one or more central processing units CPU for executing software and a computer readable media drive for reading information or installing software from tangible computer readable storage media such as a floppy disk a CD ROM a DVD a USB flash drive and or other tangible computer readable storage media. The computing system also includes one or more of the following a network connection device for connecting to a network an information input device for example a mouse a keyboard etc. and an information output device for example a display .

The computing system can be implemented by or in any of the components illustrated in such as by or in the virtual machine hosts the virtual machine manager the virtual machine proxy or the secondary storage computing device . In some examples some or all of the software components and data of the computing system may be implemented as a plug in to third party virtualization software such as the VMware ESX Server or VMware vCenter software. In some examples the plug in may be downloaded to the various virtual machine hosts e.g. from a server running VMware vCenter software and or system components such as the virtual machine manager . The functionality of the computing system may be performed by any or all of such components. For example the virtual machine manager may include the user interface component and the management component to provide a user interface for managing virtual machines . The secondary storage computing device may include the archiving component and the restore component to archive and restore virtual machine data. Accordingly the components are not limited to being implemented by or in a single computing device.

At step the VM life cycle management system creates a new virtual machine and associated virtual disks in accordance with applicable virtual machine policies e.g. using APIs provided by the API component . The applicable virtual machine policies may require that the VM life cycle management system select a virtual machine host for the new virtual machine in order to facilitate load distribution. For example the virtual machine policy may dictate that a new virtual machine should be hosted by the virtual machine host in the network that is currently providing the lowest amount of virtual resources to other virtual machines e.g. either as a percentage of its total resources and or in absolute terms . As another example the virtual machine policy may select the virtual machine host for the new virtual machine using a round robin technique. Similarly the policy may specify that the primary storage data store for storing the new virtual disks should be selected in order to facilitate load distribution.

Once the virtual machine has been created at step the VM life cycle management system may also manage various backup and other secondary storage operations that create secondary copies of the virtual machine and its associated virtual disks such as snapshot copies and backup copies. Also at step the VM life cycle management system may provide user interfaces that permit users to manage aspects of the virtual machine including for example altering its specification generating reports regarding its performance and use of virtual resources and other management tasks.

At step the VM life cycle management system discovers virtual machines in the network including the virtual machine created at step . For example the VM life cycle management system may use APIs provided by the API component to discover virtual machines . As another example the VM life cycle management system may query a virtual machine host or a virtual machine manager in order to discover virtual machines . Additionally or alternatively the VM life cycle management system may analyze processes and ascertain that the processes match a particular signature associated with virtual machines .

As another example to discover virtual machines the VM life cycle management system may include logic for crawling or spidering the network. The VM life cycle management system may utilize route tables or other data structures and crawl or spider various computing systems that could potentially host virtual machines to determine whether or not the computing systems are hosting virtual machines . Accordingly instead of relying on a static input e.g. a name of a virtual machine host or the virtual machine manager to discover virtual machines the VM life cycle management system could dynamically discover virtual machines using the dynamic techniques described herein. Additionally or alternatively the VM life cycle management system can use a combination of static and dynamic techniques to discover virtual machines . More details as to the discovery detection and or identification of virtual machines are described in commonly assigned co pending U.S. Patent Application Publication Number 2010 0070725 the entirety of which is incorporated by reference herein.

As another example the VM life cycle management system can create and maintain a data structure containing entries for virtual machines as well as an indication of whether or not each virtual machine is active and the last time the virtual machine was found to be active. The VM life cycle management system can access the data structure and use the entries as a starting point for discovering virtual machines .

At step the VM life cycle management system determines that the created virtual machine has been idle for at least a first predefined period of time. For example to determine that a virtual machine has been idle the VM life cycle management system may intercept alerts transmitted with respect to the virtual machine analyze the content of the alerts and look for specific content in the alerts. If the VM life cycle management system finds that the alerts contain the specific content the VM life cycle management system may determine that the virtual machine associated with the alerts has been idle for at least the first predetermined period of time. As another example the VM life cycle management system may call an API e.g. an API of the virtual machine manager or of a virtual machine host in order to determine that a virtual machine has been idle for a period of time.

As another example the VM life cycle management system may determine that all or substantially all of the application level processes of the virtual machine have been idle for at least the first predefined period of time. There may be operating system level processes that have been running but the VM life cycle management system may ignore such processes to focus on application level processes. The VM life cycle management system may look for activity above and beyond operating system level activity such as looking to see if any applications are active. To determine such activity the VM life cycle management system may call APIs e.g. an API of a virtual machine operating system to determine the level or extent of idleness of applications running on the virtual machine . Additionally or alternatively the VM life cycle management system may monitor application level events such as keyboard and mouse events. Such events may show that a user has logged onto a virtual machine and has been utilizing the virtual machine . As another example the VM life cycle management system may monitor user and or process activity on the virtual machine such as by monitoring metadata that may indicate whether certain user level processes are active.

After determining that the virtual machine has been idle for at least the first predefined period of time at step the VM life cycle management system shuts down the idle virtual machine . For example the VM life cycle management system may call an API e.g. an API of the virtual machine manager or of a virtual machine host to cause the virtual machine to shut down. As another example the VM life cycle management system may issue commands to the virtual machine host or the virtual machine manager to cause the virtual machine to shut down. In this context shut down can mean that the virtual machine is completely shut down e.g. powered off or is only partially shut down e.g. in a standby state or hibernating .

After shutting down the virtual machine at step the VM life cycle management system starts a timer for a second predefined period of time. The VM life cycle management system may require the virtual machine to be shut down for the entirety of the second predefined period of time or may simply require that the virtual machine be shut down at the conclusion of the second predefined period of time. The VM life cycle management system may use default values for the first and second predefined periods of time. For example the VM life cycle management system may set the first predefined period of time to be equal to 90 days and the second predefined period of time to be equal to 30 days. Additionally or alternatively the VM life cycle management system can allow a user to configure the first and second predefined periods of time.

After the timer expires the VM life cycle management system archives the virtual machine file associated with the virtual machine . In this context a virtual machine file can include any file or data object utilized by or associated with the virtual machine e.g. the .vmdk utilized by VMware virtual servers the .vhd files utilized by Microsoft virtual servers or any other type of file or data object .

The VM life cycle management system archives the virtual machine file by copying the virtual machine file to the storage device . The VM life cycle management system may preserve the state of the virtual machine file so that the VM life cycle management system can restart the virtual machine at that same point upon restoration. The VM life cycle management system may also perform other operations upon the virtual machine file such as compressing the virtual machine file encrypting the virtual machine file and or single instancing or deduplicating data objects within the virtual machine file. After the VM life cycle management system has copied the virtual machine file to the storage device the VM life cycle management system replaces the virtual machine file with a stub. A stub is typically a small data object that indicates points to or refers to the location of the secondary copy of the virtual machine file and facilitates recovery of the virtual machine file. More details as to archiving operations may be found in the commonly assigned currently pending U.S. patent application No. 2008 0229037 the entirety of which is incorporated by reference herein. The stub allows the virtual machine file to be retrieved in case a user wishes to recover the virtual machine file.

The VM life cycle management system may apply archive rules or criteria to archive virtual machine files. Such archive rules or criteria may be based on any combination of data object type data object age data object size percentage of disk quota remaining storage and or other factors. The VM life cycle management system could also apply policies such as storage policies to determine if and when to archive virtual machine files. For example the virtual machine could be associated with an archive policy that indicates that if the virtual machine has been idle for a first predefined period of time the virtual machine is to be shut down and then immediately archived. As another example a virtual machine could be associated with a storage policy that indicates that regardless of whether or not the virtual machine is idle the virtual machine is never to be shut down or archived.

At step the VM life cycle management system restores the archived virtual machine e.g. as described in greater detail herein with respect to . After step the process concludes.

Although described herein as shutting down idle virtual machines the system and methods described herein may similarly detect physical machines that have been idle for a predefined period of time and shut down or power off the idle physical machines or otherwise reduce their functionality. By shutting down idle machines either virtual or physical the VM life cycle management system may assist in meeting green energy certifications standards or other benchmarks such as being a Green Energy Compliant System.

At step the VM life cycle management system restores the archived virtual machine file by copying the archived virtual machine file from the storage device to the virtual machine host . As virtual machine files may be quite large the recovery process may be somewhat lengthy. During the recovery process the VM life cycle management system may display an indication of the status of the recovery process. The VM life cycle management system may also perform other operations upon the virtual machine file such as decompressing the virtual machine file decrypting the virtual machine file and or replacing data objects that had been removed from the virtual machine file by e.g. deduplication or single instancing processes. After the VM life cycle management system has recovered the virtual machine file at step the VM life cycle management system provides a notification that the archived virtual machine has been restored to the virtual machine host . For example the VM life cycle management system may send an electronic message to the user that requested that the virtual machine be recovered. The electronic message notifies the user of the recovery of the virtual machine . At step the VM life cycle management system starts the recovered virtual machine . The VM life cycle management system may start the virtual machine in the state it was in when it was archived.

The VM life cycle management system may also perform other actions once the virtual machine has been recovered. For example the VM life cycle management system may cause services running on the virtual machine to start the VM life cycle management system may cause an operation to be performed by the virtual machine such as running a batch job or perform other actions. As another example the VM life cycle management system may have a standard set of operations that the virtual machine is to perform upon being recovered. The VM life cycle management system may provide the standard set of instructions to the virtual machine so that the virtual machine can perform the instructions upon restarting. Those of ordinary skill in the art will understand that the virtual machine upon being recovered can perform various actions or operations and is not limited to the examples given herein. After step the process concludes.

One advantage of the techniques described herein is that the VM life cycle management system can detect idleness of virtual machines across different types of heterogeneous virtual machine environments. For example the VM life cycle management system may be able to detect idleness of VMware virtual machines Microsoft hyper v virtual machines Amazon Cloud virtual machines and other types of virtual machines. Accordingly the detection of idle virtual machines can work across disparate vendors and across heterogeneous operating systems.

Another advantage is that such techniques both facilitate the freeing up of limited resources of virtual machine hosts and provide the capability of easily recovering archived virtual machines . Accordingly a user can both quickly and easily delete virtual machines that may no longer be necessary or required while retaining the option of recovering the deleted virtual machines . Such option may be quite useful if in the future it is determined that the archived virtual machines are necessary or required.

Although the techniques described herein have been described in the context of detecting and archiving idle virtual machines the techniques may also be used to detect and archive virtual machines for other purposes or virtual machines that are not idle. For example virtual machines may be leased by or associated with customers on a per virtual machine basis. If the customer discontinues the lease or stops paying for the virtual machine the techniques described herein may be used to detect such refusal to pay and then shut down and archive the virtual machine . For example the VM life cycle management system could access a billing server process a job to determine which virtual machines are associated with unpaid bills and then shut down and archive such virtual machines . Upon receiving payment for the virtual machine the VM life cycle management system can recover the virtual machine file associated with the virtual machine such that the user can continue once again to utilize the virtual machine .

As another example the techniques described herein may be used to detect virtual machine hosts that are over utilized. The VM life cycle management system can detect such over utilized virtual machine hosts and then shut down and archive the least important or the lowest priority virtual machines . Additionally or alternatively instead of archiving the virtual machine file to the storage device the VM life cycle management system may instead move the virtual machine file and other associated files to another virtual machine host that the VM life cycle management system has determined is capable of hosting the virtual machine .

The VM life cycle management system may manage virtual machines based on historical trends. For example the system may use historical data to determine that a virtual machine host has had a peak load on the virtual machine and may reconfigure the virtual machine host to give the virtual machine more resources at this peak load time. Additionally or alternatively the system may dynamically move virtual machines from an over utilized virtual machine host to another virtual machine host . The system may do this in real time based on historical trends and in such a fashion that it is transparent to end users of the virtual machine .

As another example the VM life cycle management system may perform virtual machine management by correlating trending information or historical reports and information obtained from and or during data storage operations as well as forecast data for future operations and performance. The system may employ flexible virtual machine management policies and may monitor the operation utilization and storage of virtual machine data for a given period to modify or redistribute virtual machines based on results obtained during the monitoring period or determined in forecasts. The system may modify virtual machine configurations during the monitoring period or may use any obtained information to modify virtual machine configurations.

The system may generally include combinations of hardware and software components associated with performing storage operations on electronic data. Storage operations include copying backing up creating storing retrieving and or migrating primary storage data e.g. data stores and or and secondary storage data which may include for example snapshot copies backup copies hierarchical storage management HSM copies archive copies and other types of copies of electronic data stored on storage devices . The system may provide one or more integrated management consoles for users or system processes to interface with in order to perform certain storage operations on electronic data as further described herein. Such integrated management consoles may be displayed at a central control system or several similar consoles distributed throughout multiple network locations to provide global or geographically specific network data storage information.

In one example storage operations may be performed according to various storage preferences for example as expressed by a user preference a storage policy a schedule policy and or a retention policy. A storage policy is generally a data structure or other information source that includes a set of preferences and other storage criteria associated with performing a storage operation. The preferences and storage criteria may include but are not limited to a storage location relationships between system components network pathways to utilize in a storage operation data characteristics compression or encryption requirements preferred system components to utilize in a storage operation a single instancing or variable instancing policy to apply to the data and or other criteria relating to a storage operation. For example a storage policy may indicate that certain data is to be stored in the storage device retained for a specified period of time before being aged to another tier of secondary storage copied to the storage device using a specified number of data streams etc.

A schedule policy may specify a frequency with which to perform storage operations and a window of time within which to perform them. For example a schedule policy may specify that a storage operation is to be performed every Saturday morning from 2 00 a.m. to 4 00 a.m. In some cases the storage policy includes information generally specified by the schedule policy. Put another way the storage policy includes the schedule policy. A retention policy may specify how long data is to be retained at specific tiers of storage or what criteria must be met before data may be pruned or moved from one tier of storage to another tier of storage. Storage policies schedule policies and or retention policies may be stored in a database of the storage manager to archive media as metadata for use in restore operations or other storage operations or to other locations or components of the system .

The system may comprise a storage operation cell that is one of multiple storage operation cells arranged in a hierarchy or other organization. Storage operation cells may be related to backup cells and provide some or all of the functionality of backup cells as described in the assignee s U.S. patent application Ser. No. 09 354 058 now U.S. Pat. No. 7 395 282 which is incorporated herein by reference in its entirety. However storage operation cells may also perform additional types of storage operations and other types of storage management functions that are not generally offered by backup cells.

Storage operation cells may contain not only physical devices but also may represent logical concepts organizations and hierarchies. For example a first storage operation cell may be configured to perform a first type of storage operations such as HSM operations which may include backup or other types of data migration and may include a variety of physical components including a storage manager or management agent a secondary storage computing device a client and other components as described herein. A second storage operation cell may contain the same or similar physical components however it may be configured to perform a second type of storage operations such as storage resource management SRM operations and may include monitoring a primary data copy or performing other known SRM operations.

Thus as can be seen from the above although the first and second storage operation cells are logically distinct entities configured to perform different management functions i.e. HSM and SRM respectively each storage operation cell may contain the same or similar physical devices. Alternatively different storage operation cells may contain some of the same physical devices and not others. For example a storage operation cell configured to perform SRM tasks may contain a secondary storage computing device client or other network device connected to a primary storage volume while a storage operation cell configured to perform HSM tasks may instead include a secondary storage computing device client or other network device connected to a secondary storage volume and not contain the elements or components associated with and including the primary storage volume. The term connected as used herein does not necessarily require a physical connection rather it could refer to two devices that are operably coupled to each other communicably coupled to each other in communication with each other or more generally refer to the capability of two devices to communicate with each other. These two storage operation cells however may each include a different storage manager that coordinates storage operations via the same secondary storage computing devices and storage devices . This overlapping configuration allows storage resources to be accessed by more than one storage manager such that multiple paths exist to each storage device facilitating failover load balancing and promoting robust data access via alternative routes.

Alternatively or additionally the same storage manager may control two or more storage operation cells whether or not each storage operation cell has its own dedicated storage manager . Moreover in certain embodiments the extent or type of overlap may be user defined through a control console or may be automatically configured to optimize data storage and or retrieval.

Data agent may be a software module or part of a software module that is generally responsible for performing storage operations on the data of the client stored in data store or other memory location. Each client may have at least one data agent and the system can support multiple clients . Data agent may be distributed between client and storage manager and any other intermediate components or it may be deployed from a remote location or its functions approximated by a remote process that performs some or all of the functions of data agent .

The overall system may employ multiple data agents each of which may perform storage operations on data associated with a different application. For example different individual data agents may be designed to handle Microsoft Exchange data Lotus Notes data Microsoft Windows 2000 file system data Microsoft Active Directory Objects data and other types of data known in the art. Other embodiments may employ one or more generic data agents that can handle and process multiple data types rather than using the specialized data agents described above.

If a client has two or more types of data one data agent may be required for each data type to perform storage operations on the data of the client . For example to back up migrate and restore all the data on a Microsoft Exchange 2000 server the client may use one Microsoft Exchange 2000 Mailbox data agent to back up the Exchange 2000 mailboxes one Microsoft Exchange 2000 Database data agent to back up the Exchange 2000 databases one Microsoft Exchange 2000 Public Folder data agent to back up the Exchange 2000 Public Folders and one Microsoft Windows 2000 File System data agent to back up the file system of the client . These data agents would be treated as four separate data agents by the system even though they reside on the same client .

Alternatively the overall system may use one or more generic data agents each of which may be capable of handling two or more data types. For example one generic data agent may be used to back up migrate and restore Microsoft Exchange 2000 Mailbox data and Microsoft Exchange 2000 Database data while another generic data agent may handle Microsoft Exchange 2000 Public Folder data and Microsoft Windows 2000 File System data etc.

Data agents may be responsible for arranging or packing data to be copied or migrated into a certain format such as an archive file. Nonetheless it will be understood that this represents only one example and any suitable packing or containerization technique or transfer methodology may be used if desired. Such an archive file may include metadata a list of files or data objects copied the file and data objects themselves. Moreover any data moved by the data agents may be tracked within the system by updating indexes associated with appropriate storage managers or secondary storage computing devices . As used herein a file or a data object refers to any collection or grouping of bytes of data that can be viewed as one or more logical units.

Generally speaking storage manager may be a software module or other application that coordinates and controls storage operations performed by the system . Storage manager may communicate with some or all elements of the system including clients data agents secondary storage computing devices and storage devices to initiate and manage storage operations e.g. backups migrations data recovery operations etc. .

Storage manager may include a jobs agent that monitors the status of some or all storage operations previously performed currently being performed or scheduled to be performed by the system . One or more storage operations are alternatively referred to herein as a job or jobs. Jobs agent may be communicatively coupled to an interface agent e.g. a software module or application . Interface agent may include information processing and display software such as a graphical user interface GUI an application programming interface API or other interactive interface through which users and system processes can retrieve information about the status of storage operations. For example in an arrangement of multiple storage operations cell through interface agent users may optionally issue instructions to various storage operation cells regarding performance of the storage operations as described and contemplated herein. For example a user may modify a schedule concerning the number of pending snapshot copies or other types of copies scheduled as needed to suit particular needs or requirements. As another example a user may employ the GUI to view the status of pending storage operations in some or all of the storage operation cells in a given network or to monitor the status of certain components in a particular storage operation cell e.g. the amount of storage capacity left in a particular storage device .

Storage manager may also include a management agent that is typically implemented as a software module or application program. In general management agent provides an interface that allows various management agents in other storage operation cells to communicate with one another. For example assume a certain network configuration includes multiple storage operation cells hierarchically arranged or otherwise logically related in a WAN or LAN configuration. With this arrangement each storage operation cell may be connected to the other through each respective interface agent . This allows each storage operation cell to send and receive certain pertinent information from other storage operation cells including status information routing information information regarding capacity and utilization etc. These communications paths may also be used to convey information and instructions regarding storage operations.

For example a management agent in a first storage operation cell may communicate with a management agent in a second storage operation cell regarding the status of storage operations in the second storage operation cell. Another illustrative example includes the case where a management agent in a first storage operation cell communicates with a management agent in a second storage operation cell to control storage manager and other components of the second storage operation cell via management agent contained in storage manager .

Another illustrative example is the case where management agent in a first storage operation cell communicates directly with and controls the components in a second storage operation cell and bypasses the storage manager in the second storage operation cell. If desired storage operation cells can also be organized hierarchically such that hierarchically superior cells control or pass information to hierarchically subordinate cells or vice versa.

Storage manager may also maintain an index a database or other data structure . The data stored in database may be used to indicate logical associations between components of the system user preferences management tasks media containerization and data storage information or other useful data. For example the storage manager may use data from database to track logical associations between secondary storage computing device and storage devices or movement of data as containerized from primary to secondary storage .

Generally speaking the secondary storage computing device which may also be referred to as a media agent may be implemented as a software module that conveys data as directed by storage manager between a client and one or more storage devices such as a tape library a magnetic media storage device an optical media storage device or any other suitable storage device. In one embodiment secondary storage computing device may be communicatively coupled to and control a storage device . A secondary storage computing device may be considered to be associated with a particular storage device if that secondary storage computing device is capable of routing and storing data to that particular storage device .

In operation a secondary storage computing device associated with a particular storage device may instruct the storage device to use a robotic arm or other retrieval means to load or eject a certain storage media and to subsequently archive migrate or restore data to or from that media. Secondary storage computing device may communicate with a storage device via a suitable communications path such as a SCSI or Fibre Channel communications link. In some embodiments the storage device may be communicatively coupled to the storage manager via a SAN.

Each secondary storage computing device may maintain an index a database or other data structure that may store index data generated during storage operations for secondary storage SS as described herein including creating a metabase MB . For example performing storage operations on Microsoft Exchange data may generate index data. Such index data provides a secondary storage computing device or other external device with a fast and efficient mechanism for locating data stored or backed up. Thus a secondary storage computing device index or a database of a storage manager may store data associating a client with a particular secondary storage computing device or storage device for example as specified in a storage policy while a database or other data structure in secondary storage computing device may indicate where specifically the data of the client is stored in storage device what specific files were stored and other information associated with storage of the data of the client . In some embodiments such index data may be stored along with the data backed up in a storage device with an additional copy of the index data written to index cache in a secondary storage device. Thus the data is readily available for use in storage operations and other activities without having to be first retrieved from the storage device .

Generally speaking information stored in cache is typically recent information that reflects certain particulars about operations that have recently occurred. After a certain period of time this information is sent to secondary storage and tracked. This information may need to be retrieved and uploaded back into a cache or other memory in a secondary computing device before data can be retrieved from storage device . In some embodiments the cached information may include information regarding format or containerization of archives or other files stored on storage device .

One or more of the secondary storage computing devices may also maintain one or more single instance databases . Single instancing alternatively called data deduplication generally refers to storing in secondary storage only a single instance of each data object or data block in a set of data e.g. primary data . More details as to single instancing may be found in one or more of the following commonly assigned U.S. patent applications 1 U.S. patent application Ser. No. 11 269 512 entitled SYSTEM AND METHOD TO SUPPORT SINGLE INSTANCE STORAGE OPERATIONS 2 U.S. patent application Ser. No. 12 145 347 entitled APPLICATION AWARE AND REMOTE SINGLE INSTANCE DATA MANAGEMENT or 3 U.S. patent application Ser. No. 12 145 342 entitled APPLICATION AWARE AND REMOTE SINGLE INSTANCE DATA MANAGEMENT 4 U.S. patent application Ser. No. 11 963 623 entitled SYSTEM AND METHOD FOR STORING REDUNDANT INFORMATION 5 U.S. patent application Ser. No. 11 950 376 entitled SYSTEMS AND METHODS FOR CREATING COPIES OF DATA SUCH AS ARCHIVE COPIES or 6 U.S. patent application Ser. No. 61 100 686 entitled SYSTEMS AND METHODS FOR MANAGING SINGLE INSTANCING DATA each of which is incorporated by reference herein in its entirety.

In some examples the secondary storage computing devices maintain one or more variable instance databases. Variable instancing generally refers to storing in secondary storage one or more instances but fewer than the total number of instances of each data block or data object in a set of data e.g. primary data . More details as to variable instancing may be found in the commonly assigned U.S. patent application Ser. No. 61 164 803 entitled STORING A VARIABLE NUMBER OF INSTANCES OF DATA OBJECTS .

In some embodiments certain components may reside and execute on the same computer. For example in some embodiments a client such as a data agent or a storage manager coordinates and directs local archiving migration and retrieval application functions as further described in the previously referenced U.S. patent application Ser. No. 09 610 738. This client can function independently or together with other similar clients .

As shown in secondary storage computing devices each has its own associated metabase . Each client may also have its own associated metabase . However in some embodiments each tier of storage such as primary storage secondary storage tertiary storage etc. may have multiple metabases or a centralized metabase as described herein. For example rather than a separate metabase or index associated with each client in the metabases on this storage tier may be centralized. Similarly second and other tiers of storage may have either centralized or distributed metabases. Moreover mixed architecture systems may be used if desired that may include a first tier centralized metabase system coupled to a second tier storage system having distributed metabases and vice versa etc.

Moreover in operation a storage manager or other management module may keep track of certain information that allows the storage manager to select designate or otherwise identify metabases to be searched in response to certain queries as further described herein. Movement of data between primary and secondary storage may also involve movement of associated metadata and other tracking information as further described herein.

In some examples primary data may be organized into one or more sub clients. A sub client is a portion of the data of one or more clients and can contain either all of the data of the clients or a designated subset thereof. As depicted in the data store includes two sub clients. For example an administrator or other user with the appropriate permissions the term administrator is used herein for brevity may find it preferable to separate email data from financial data using two different sub clients having different storage preferences retention criteria etc.

Various discrete data management functionalities provided by the data storage system including virtual machine management may be distributed or divided so the functionalities are implemented across software modules on various devices capable of docking with a full featured data management system. illustrates an environment in which discrete data management functionalities provided by the data storage system are distributed between software modules on various devices capable of docking with a full featured data management system. As shown the environment includes one or more limited feature data management devices each coupled via one or more networks to a full featured data management system .

Each of the limited feature devices includes a memory having software that in turn includes one or more limited feature data management modules . Each limited feature module is capable of providing a particular but limited set of data management features alone without the assistance or intervention of other modules or the full featured system . However each limited feature module may also be capable of providing in whole or in part additional synergistic features outside of its limited set of data management features but only after it has been docked to the full featured as described in greater detail herein.

 1 A limited feature virtual machine life cycle management module configured to provide the standalone ability to shut down virtual machines which may include the virtual machine creation component idleness determination component and API described above.

 2 A limited feature private search module configured to provide the standalone ability to provide search results for a selected restricted set of Internet sites.

 3 A limited feature backup module configured to back up the data of client computers but in a limited manner that is a constrained by the number of client computers or subclients that are backed up b constrained by the volume of data that is backed up or c otherwise constrained in the volume or quantity of data that is backed up.

 6 A limited feature content store module that is configured to provide the standalone ability to create content stores in primary storage as described further herein but is unable to create content stores in secondary storage. Additional functionality that may be provided by limited feature modules and details on such functionality may be found in the commonly assigned patent application Ser. No. 12 751 804 entitled PERFORMING DATA STORAGE OPERATIONS WITH A CLOUD ENVIRONMENT INCLUDING CONTAINERIZED DEDUPLICATION DATA PRUNING AND DATA TRANSFER filed Mar. 31 2010 now U.S. Patent Publication No. 2010 0332454.

The memory of each limited feature device also comprises data which in turn includes one or more sets of metadata or data generated by used by or otherwise associated with a particular limited feature module . For example the set of metadata or data A may include secondary copies of data or metadata generated by storage operations performed by module A and or configuration settings including storage policies and other policies used by module A. A single limited feature device may have any combination of one or more limited feature modules installed on it.

The limited feature device can be implemented by or in any of the components illustrated in such as by or in the virtual machine hosts the virtual machine manager the virtual machine proxy the secondary storage computing device the client or the storage manager . The functionality of the limited feature device may be performed by any or all of such components.

The full featured system is configured to provide or facilitate numerous additional data management features namely features that are not provided by any of the limited feature modules alone. For example the full featured system may provide features such as those described in the commonly assigned patent applications incorporated by reference herein including policy driven data management data replication and protection cloud storage integration storage resource management analysis optimization and reporting data archiving deduplication compression and encryption electronic discovery E discovery privacy retention life cycle and compliance management backup and recovery content indexing data classification enterprise and collaborative data mining and search migration from legacy data storage solutions virtual server protection disaster recovery access control and security. As shown the memory of the full featured system typically includes software such a storage manager and its constituent components described herein and may also include global storage policies and other types of policies applicable to numerous limited feature devices . One example of a full featured system is the Common Technology Engine of the Simpana system introduced above.

Each limited feature device and the full featured system also comprise a communication module for connecting to networks and for initiating and conducting communications with other devices on the networks. The communication module also permits each limited feature device and the full featured system to perform authentication procedures. The communication module is configured to conduct communications with other devices via the Windows Management Instrumentation WMI service via another operating system interface via a Secure Shell SSH or similar network connection and or by listening for and exchanging messages via a designated port e.g. port . In other words the limited feature device and the full featured system employ a common protocol and known APIs to ensure seamless connectivity and interface between the two.

Each limited feature device and the full featured system further includes one or more central processing units CPU for executing software and a computer readable media drive for reading information or installing software from tangible computer readable storage media such as a floppy disk a CD ROM a DVD a USB flash drive and or other tangible computer readable storage media. Each limited feature device and the full featured system may also include one or more of the following an information input device for example a mouse a keyboard microphone remote control etc. and an information output device for example a display printer speakers etc. 

While various items are described as stored in memory those skilled in the art will appreciate that these items or portions of them may be transferred between memory and a persistent storage device for example a magnetic hard drive a tape of a tape library etc. for purposes of memory management data integrity and or other purposes.

Although only a single full featured system is shown a single limited feature device may dock to two or more different full featured systems .

At block the limited feature module discovers and docks with the full featured system . The discovery and docking at block may occur upon a user provided or automated command to the limited feature module and or full featured system . As a first example the limited feature module may display a graphical interface option e.g. a button or menu option that permits a user to indicate that he wants to dock the module to a full featured system . After the user indicates that docking is desired the limited feature module may detect e.g. using its associated communication module any full featured systems present on the networks e.g. on a particular organization s network or another local area network . The module may then present a list of these systems to the user so that the user can indicate which full featured system he wants to dock the module to. As a second example the full featured system may display a graphical interface option e.g. a button or menu option that permits a user such as an administrator to indicate that he wants to dock one or more modules to the full featured system. After the user indicates that docking is desired the full featured system may detect e.g. using its associated communication module any limited feature modules present on the networks e.g. on a particular organization s network or another local area network . The full featured system may then present a list of these modules to the user so that the user can indicate which modules he wants docked to the full featured system. Under either example the interface may provide an option to provide subsequent automatic docking when certain conditions are met such as temporal conditions docking daily weekly monthly volume conditions when amount of data in primary storage exceeds a certain storage limit e.g. a percent of a maximum capacity or a certain MB or GB limit or other conditions.

The discovery and docking may occur for example by the limited feature module and or the full featured system utilizing a Windows Management Instrumentation WMI service another operating system interface a Secure Shell SSH or similar network connection or by exchanging messages via a designated port e.g. port . During the docking either the limited feature module the full featured system and or both may conduct various authentication procedures to verify that the docking is authorized by using any known authorization such as standard username password access control logic available in many operating systems etc.

At block the limited feature module receives configuration settings and other commands from the full featured system . For example the limited feature module may receive data storage policies scheduling policies other policies or commands to perform specific data storage operations. At block the full featured system either alone or in conjunction with the limited feature module performs storage operations different than those performed at block that 1 analyze or integrate generated metadata and or data and or 2 create copies of the generated metadata and or data typically secondary copies such as backup or archive copies stored in secondary storage.

As one example at block the full featured system may integrate the metadata and or data generated at block with existing metadata and data that are already under management by the full featured system. As part of the integration of metadata and or data the full featured system may perform some normalization association or deduplication of the generated metadata and or data. For example if the full featured system manages the metadata and data from numerous different limited feature modules it may check for identical and therefore duplicative metadata or data received from the various modules. To identify identical metadata and data the system may use hardware based identifiers e.g. NIC cards MAC addresses content based identifiers e.g. GUIDs hashes etc. and or a combination of these.

At block a user of the limited feature device may receive additional data management features or functionalities related to the metadata or data e.g. either synergistic features of the limited feature module that were the unlocked as a result of the docking and or directly from the full featured system . For example the user may receive additional data management features or functionalities such as content indexing data classification compression encryption deduplication or other features mentioned herein.

Returning to the specific example of managing virtual machines shows a flow diagram illustrating a process for docking a limited feature virtual machine VM life cycle management module with a full featured data management system . The process begins at block when a limited feature VM life cycle management module generates and stores metadata and or data related to virtual machines in primary storage which may occur for example by the limited feature VM life cycle management module performing blocks and or of process . Next at block the limited feature VM life cycle management module shuts down idle virtual machines which may occur for example by the limited feature VM life cycle management module performing block of process . At block the limited feature VM life cycle management module discovers and docks with a full featured system as described above.

At block the limited feature VM life cycle management module receives virtual machine life cycle management configuration settings other configuration settings or policies and or other commands from the full featured system . For example the VM life cycle management module may receive the archive or storage rules criteria and policies described previously that among other things determine if when and how virtual machines should be shut down backed up and or archived.

At block the limited feature VM life cycle management module and or full featured system performs storage operations that may for example create secondary copies of the stored metadata or data integrate the generated metadata or data or restore metadata or data. At block the limited feature VM life cycle management module in conjunction with the full featured system may backup and or archive the virtual machine disk files virtual hard disk image files and or similar virtual machine files e.g. as described at block of process . Also at block the limited feature VM life cycle management module may transmit the generated metadata in primary storage to the full featured system in order to integrate the generated metadata with metadata related to other virtual machines or other clients in other storage operation cells managed by the full featured system . As yet another example the limited feature VM life cycle management module in conjunction with the full featured system may restore an archived virtual machine e.g. by performing process of . Additionally in conjunction with these storage operations the full featured system may provide additional storage management features such as deduplication compression content indexing data classification or other operations e.g. upon backed up or archived virtual machine files.

The data storage system may also provide private search functionality whereby only a selected restricted set of internet sites are searchable by users. Private search functionality provides a way for organizations such as schools and libraries to automatically restrict the scope of internet search results provided to their users e.g. students and library patrons. As described in greater detail herein such private search functionality may be divided between a limited feature private search module and a full featured system . Moreover the data storage system may provide different groups of selected sites to different groups of users e.g. based upon access policies or other security measures.

At block the limited feature private search module discovers and docks with a full featured data management system as described herein. At block the limited feature private search module receives private search configuration settings and other commands from the full featured data management system . For example the private search module may receive additional search policies that define different groups of users and define which selected sites each group of users may access. As another example the private search module may receive storage policies that dictate if when and how selected internet sites or sources should be copied to a local cache review set or content store.

At block the limited feature private search module and or full featured data management system performs a storage operation to integrate the searchable metadata with other metadata managed by the full featured data storage system. At block the limited feature private search module in conjunction with the full featured system performs storage operations to create a private cached copy of one or more selected sites e.g. in private primary or secondary storage within the data storage system e.g. in a review set content store legal hold archive or other legal hold repository. In some examples these storage operations are performed at the request of a user who is browsing search results provided by the private search module. At block upon receiving a search query from a user after docking the limited feature private search module performs searches of the searchable database and returns search results that direct users only to private cached copies of selected sites that match the search criteria. At block after docking the limited feature private search module does not direct users to other unselected sites that match the search criteria or to the original locations of the selected sites that are available on the Internet.

As described in greater detail herein the data storage system may also permit piecemeal backup protection whereby different limited feature backup modules are deployed throughout an organization each of which is responsible for backing up a different group of clients. At a later time the various modules may be docked to a full featured system so that the data and metadata generated from these different piecemeal backup modules can be integrated at a global repository cell. Also after docking the various limited feature backup modules may receive global settings policies and commands from the full featured system in a top down manner.

At block the limited feature backup module discovers and docks with a full featured system as described herein. At block the limited feature backup module receives secondary storage operation configuration settings and other commands from the full featured system and performs storage operations in accordance with those configuration settings and commands. For example the limited feature backup module may receive storage policies or scheduling policies from the full featured system and may subsequently perform data backup operations or other secondary storage operations in accordance with such policies. At block the limited feature backup module performs storage operations to integrate the generated metadata or backup copy data with other metadata or data managed by the full featured system . For example the limited feature backup module may copy metadata to the system in order to integrate it with other metadata generated by another limited feature backup module that is responsible for backing up a different group of clients. At block the limited feature backup module or its users receive additional storage management features or functionalities from the full featured system such as content indexing data classification deduplication compression encryption or archiving of the generated backup copies or metadata.

Although the process of focuses on backup operations it will be appreciated that instead the process could feature other types of data management such as other secondary storage operations that create other types of secondary copies of client data and metadata including snapshot copies hierarchical storage management HSM copies and archive copies.

In some examples the system may be implemented so that top down data management such as the management functionality of a storage manager is provided as a cloud based hosted software service to which other limited feature modules dock. Such an implementation may permit faster and simpler deployment of a data management solution. shows a process for providing top down data management by docking a secondary storage computing device and or data agent s with a full featured data storage system operating as a hosted software service. In some examples the full featured data storage system is the Common Technology Engine of the Simpana system described above which is provided as a hosted software service and is accessible via HTTP protocols.

The process begins at block when one or more limited feature modules such as a secondary storage computing device and or data agent generate data and metadata during storage operations such as backup operations or archive operations. At block the limited feature modules discover and dock with a full featured data storage system that is operating as a hosted cloud software service. The limited feature storage operation modules may discover the full featured data storage system by using HTTP protocols and the docking may utilize firewall techniques such as those described in commonly assigned U.S. patent application Ser. No. 10 818 747 filed Apr. 4 2004 entitled SYSTEM AND METHOD FOR PERFORMING STORAGE OPERATIONS THROUGH A FIREWALL now U.S. Pat. No. 7 631 351 issued Dec. 8 2009 and commonly assigned U.S. patent application Ser. No. 12 643 653 entitled MANAGING CONNECTIONS IN A DATA STORAGE SYSTEM filed Dec. 21 2009 now U.S. Patent Publication No. 2010 0242096 both of which are hereby incorporated herein in their entirety. At block the limited feature modules receive secondary storage operation configuration settings and other commands and perform storage operations in accordance with the configuration settings and commands. For example the limited feature modules may receive storage policies or scheduling policies and subsequently perform storage operations such as backup or archive operations in accordance with those policies. At block the limited feature modules perform storage operations to integrate previously generated metadata and data with other metadata and data managed by the same data storage system . In some examples for security reasons no data flows up to the data storage system for integration but metadata may flow up to the data storage system so that it may be effectively integrated managed and utilized by the data storage system. In still other examples for security reasons neither metadata nor data flows up to the data storage system for integration but the data storage system provides only configuration settings and commands. At block the limited feature modules or their users receive additional data management functionality such content indexing data classification deduplication compression encryption or archiving of the generated data and or metadata.

In some examples the system permits users or applications to select data objects such as files and add a copy of those objects to a data repository called a content store as described in commonly assigned patent application Ser. No. 12 876 916 entitled LEGAL COMPLIANCE ELECTRONIC DISCOVERY AND ELECTRONIC DOCUMENT HANDLING OF ONLINE AND OFFLINE COPIES OF DATA filed Sep. 7 2010 now U.S. Patent Publication No. 2011 0093471 which is hereby incorporated herein in its entirety. In some examples the creation and management of a content store may be divided between a limited feature module and a full featured system . shows a process for receiving additional features related to a content store by docking a limited feature content store module to a full featured system . The process begins at block when a limited feature device such as a client executes a limited feature content store module in order to create within primary storage a content store having selected data and metadata. At block the limited feature content store module discovers and docks with a full featured system . At block the limited feature content store module receives configuration settings and other commands from the full featured system and performs storage operations in accordance with the configuration settings and commands. At block the limited feature content store module and or full featured system perform storage operations to integrate the metadata and or data from the content store with other metadata and or data managed by the system . The limited feature content store module and or full featured system may also perform storage operations such as archive or backup operations to create secondary copies of the content store such as archive or backup copies within secondary storage. At block the client or its users receive additional features from the full featured system such as deduplication compression encryption content indexing and data classification of the data and metadata within the content store.

Systems and modules described herein may comprise software firmware hardware or any combination s of software firmware or hardware suitable for the purposes described herein. Software and other modules may reside on servers workstations personal computers computerized tablets PDAs and other devices suitable for the purposes described herein. Modules described herein may be executed by a general purpose computer e.g. a server computer wireless device or personal computer. Those skilled in the relevant art will appreciate that aspects of the invention can be practiced with other communications data processing or computer system configurations including Internet appliances hand held devices including personal digital assistants PDAs wearable computers all manner of cellular or mobile phones multi processor systems microprocessor based or programmable consumer electronics set top boxes network PCs mini computers mainframe computers and the like. Indeed the terms computer server host host system and the like are generally used interchangeably herein and refer to any of the above devices and systems as well as any data processor. Furthermore aspects of the invention can be embodied in a special purpose computer or data processor that is specifically programmed configured or constructed to perform one or more of the computer executable instructions explained in detail herein.

Software and other modules may be accessible via local memory a network a browser or other application in an ASP context or via another means suitable for the purposes described herein. Examples of the technology can also be practiced in distributed computing environments where tasks or modules are performed by remote processing devices which are linked through a communications network such as a Local Area Network LAN Wide Area Network WAN or the Internet. In a distributed computing environment program modules may be located in both local and remote memory storage devices. Data structures described herein may comprise computer files variables programming arrays programming structures or any electronic information storage schemes or methods or any combinations thereof suitable for the purposes described herein. User interface elements described herein may comprise elements from graphical user interfaces command line interfaces and other interfaces suitable for the purposes described herein.

Examples of the technology may be stored or distributed on computer readable media including magnetically or optically readable computer disks hard wired or preprogrammed chips e.g. EEPROM semiconductor chips nanotechnology memory biological memory or other data storage media. Indeed computer implemented instructions data structures screen displays and other data under aspects of the invention may be distributed over the Internet or over other networks including wireless networks on a propagated signal on a propagation medium e.g. an electromagnetic wave s a sound wave etc. over a period of time or they may be provided on any analog or digital network packet switched circuit switched or other scheme .

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in the sense of including but not limited to. As used herein the terms connected coupled or any variant thereof means any connection or coupling either direct or indirect between two or more elements the coupling or connection between the elements can be physical logical or a combination thereof. Additionally the words herein above below and words of similar import when used in this application refer to this application as a whole and not to any particular portions of this application. Where the context permits words in the above Detailed Description using the singular or plural number may also include the plural or singular number respectively. The word or in reference to a list of two or more items covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above Detailed Description is not intended to be exhaustive or to limit the invention to the precise form disclosed above. While specific examples for the invention are described above for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. For example while processes or blocks are presented in a given order alternative implementations may perform routines having steps or employ systems having blocks in a different order and some processes or blocks may be deleted moved added subdivided combined and or modified to provide alternative or subcombinations. Each of these processes or blocks may be implemented in a variety of different ways. Also while processes or blocks are at times shown as being performed in series these processes or blocks may instead be performed or implemented in parallel or may be performed at different times. Further any specific numbers noted herein are only examples alternative implementations may employ differing values or ranges.

The teachings of the invention provided herein can be applied to other systems not necessarily the systems described herein. The elements and acts of the various examples described above can be combined to provide further implementations of the invention.

Any patents and applications and other references noted above including any that may be listed in accompanying filing papers are incorporated herein by reference. Aspects of the invention can be modified if necessary to employ the systems functions and concepts of the various references described above to provide yet further implementations of the invention.

These and other changes can be made to the invention in light of the above Detailed Description. While the above description describes certain examples of the invention and describes the best mode contemplated no matter how detailed the above appears in text the invention can be practiced in many ways. Details of the system may vary considerably in its specific implementation while still being encompassed by the invention disclosed herein. As noted above particular terminology used when describing certain features or aspects of the invention should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics features or aspects of the invention with which that terminology is associated. In general the terms used in the following claims should not be construed to limit the invention to the specific examples disclosed in the specification unless the above Detailed Description section explicitly defines such terms. Accordingly the actual scope of the invention encompasses not only the disclosed examples but also all equivalent ways of practicing or implementing the invention under the claims.

While certain examples are presented below in certain forms the applicant contemplates the various aspects of the invention in any number of claim forms. Accordingly the applicant reserves the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the invention.

