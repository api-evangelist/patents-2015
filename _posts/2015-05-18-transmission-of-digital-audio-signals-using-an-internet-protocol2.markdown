---

title: Transmission of digital audio signals using an internet protocol
abstract: Described is a network system and method of use for distributing audiovisual data. The network comprises two or more audio sinks, each of the audio sinks having a corresponding audio format capability, a first source adapted to generate and transmit audiovisual data, wherein the audiovisual data includes an audio file formatted with a first audio format capability, and the at least one source being further adapted to transmit the audiovisual data to the two or more audio sinks through the network system using both an high definition multimedia interface (HDMI) and internet protocol (IP), and a first transmitter adapted to receive the transmitted audiovisual data from the first source. The first transmitter is further adapted to generate two or more transmission streams of audiovisual data, wherein each of the two or more audiovisual data transmission streams include audio data formatted according to the audio format capability of the audio sink to which it is being transmitted.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09628868&OS=09628868&RS=09628868
owner: CRESTRON ELECTRONICS, INC.
number: 09628868
owner_city: Rockleigh
owner_country: US
publication_date: 20150518
---
The present application claims priority under 35 U.S.C. 119 e to U.S. Provisional Patent Application Ser. No. 62 025 473 filed 16 Jul. 2014 the entire contents of which are expressly incorporated herein by reference and the present application further claims priority under 35 U.S.C. 120 to U.S. Non provisional patent application Ser. No. 14 517 494 filed 17 Oct. 2014 as a Continuation in Part Application the entire contents of which are also expressly incorporated herein by reference.

Related subject matter is disclosed in co pending U.S. Non provisional patent application Ser. No. 14 714 471 filed May 18 2015 and co pending U.S. Non provisional patent application Ser. No. 14 714 625 filed May 18 2015 the entire contents of both of which are expressly incorporated herein by reference.

Aspects of the embodiments relate to internet protocol networks and more particularly to systems modes and methods for digital media transmission over internet protocol networks.

Video distribution throughout a facility is often accomplished through an audiovisual distribution network. Audiovisual AV distribution networks are increasingly common installations in commercial and residential facilities. Components of an audiovisual distribution network are typically distributed throughout a facility and networked to allow video to be distributed from one or more AV sources to one or more video sinks. For example a corporate audiovisual distribution network may comprise multiple AV sources such as media servers personal computer devices disc players such as digital video disc DVD player and Blu ray disc players and cable boxes distributed throughout a corporate campus. Audio sinks can include televisions displays projectors video cassette recorders VCRs digital versatile disk DVD recorders computers digital video records and other types of display storage play back devices.

Internet Protocol IP is a communication protocol that can be employed to transmit video throughout the audiovisual distribution network. An IP protocol audiovisual distribution network may be implemented as a local area network LAN a wide area network WAN global area network GAN or various combinations thereon.

In a LAN a group of devices are connected together in a localized area to communicate with one another and share resources. Ethernet the most widely employed LAN technology is specified in Institute of Electrical and Electronics Engineers IEEE 802.3 standard. Other LAN networking technologies can include for example Token Ring and fiber distributed data interface FDDI .

A WAN is a network that covers a broad area using private or public network transports. For example any telecommunications network that links across metropolitan regional or national boundaries is considered a WAN. It is common for the physical layer of these kinds of networks to be implemented with category CAT cable coaxial cable optical fiber or wireless transmission media. A WAN can include two or more LANs.

A GAN refers to a networks comprised of several or more different interconnected networks that cover an unlimited geographical area. Those of skill in the art have sometimes referred to the internet as a GAN.

Traditionally to network several devices in a LAN network equipment such as a network switch is required. A network switch is a computer networking device that links network segments or network devices by forwarding data from one device to another. In the past network switches and the physical interconnections between devices had limited capacity and therefore the networks had limited bandwidth. Bandwidth limits may limit the amount or type of video distributed on an IP network. In addition there may be applications where it is desirable to provide content or digital copy protection such as high bandwidth digital content protection HDCP when transmitting over IP networks.

In consideration of the above and taking into account the demands users have made on networks to provide streaming audio video products improvements in audio distribution are needed. Among these developments are 10 Gbit copper Ethernet transmission is becoming commonplace the broadcast industry has embraced video and audio over IP and finally HDMI 1.4 is being replaced by HDMI 2.0 which is designed to have a top speed of about 18 Giga pixels per second Gpps to support 4 k resolution at up to 60 Hz refresh rate . Accordingly an improved system for distributing video and audio that can accommodate such speeds and developments and especially for switching between audio video sources at said rates is desired.

Furthermore it is known that consumer A V source components have the ability to output various audio formats. The type of audio format output by the source component depends on the source content and the source itself. That is some source components might only be able to output the audio in the format that it was created with and which is stored in the source component. For example one type of audio source component might be able to store audio data file 1 that is in surround sound 5.1 and it can only output audio data file 1 with the audio in surround sound 5.1. Further there are source components that when connected directly to a sink are capable of outputting the audio data file in an audio format that is compatible with the directly connected sink capabilities. Suppose that the first device mentioned can change the format of the audio that is stored in audio data file 1 if the source recognizes the player as being capable of only using stereo audio then the first source device can output the audio data file 1 in stereo so that the sink connected to it can play it.

The problem of incompatible audio format devices is compounded when dealing with sources and sinks that connected over networks and in particular Ethernet networks. While there are various distribution systems that can convert these audio and video formats to Ethernet compatible network formats a problem occurs it is necessary or desired to distribute from one source to multiple sinks each of which can have different capabilities. It is known that the majority of consumer source devices can only output a single audio format at a time. If a user want to use this content in multiple rooms i.e. on multiple different sinks the user is forced to use an audio format that is compatible with the equipment in all the devices that might use this content i.e. at the lowest common format which is generally stereo . That means a room that has high bit rate surround sound capabilities e.g. Dolby Atmos for example will be limited to receiving stereo from the source device because the same content is also being used on a television in another room which in this example can only play audio files in stereo. In other words the lowest capable audio format takes precedent and the audio that is output from a source with a higher or better capability will be degraded as a result. illustrates a chart of the most common audio formats currently available in alphabetical order. Those of skill in the art can appreciate that the list of the most common audio formats does not reflect an order of actual or perceived quality that is while many of skill in the art can agree that a surround 7.1 audio system generally sounds better than for example a simple stereo or mono audio signal to some extent there is a level of subjectiveness to the quality of the different audio formats. But what can be objectively measured is the bit rate or bandwidth requirements that the different audio formats shown in entail.

Accordingly there is a need for an audiovisual distribution network that efficiently utilizes IP communication protocol and incorporates a system and method for transporting a plurality of audio formats to satisfy different capabilities at different users of the audio files.

It is an object of the embodiments is to substantially solve at least the problems and or disadvantages discussed above and to provide at least one or more of the advantages described below.

It is therefore a general aspect of the embodiments to provide systems methods and modes for transporting a plurality of audio formats to satisfy different capabilities at different users of the audio files that will obviate or minimize problems of the type previously described.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Further features and advantages of the aspects of the embodiments as well as the structure and operation of the various embodiments are described in detail below with reference to the accompanying drawings. It is noted that the aspects of the embodiments are not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

According to a first aspect of the embodiments a network system for distributing audiovisual data is provided comprising two or more audio sinks each of the audio sinks having a corresponding audio format capability a first source adapted to generate and transmit audiovisual data wherein the audiovisual data includes an audio stream formatted according to a first audio format capability and wherein the first source is further adapted to output the audio stream according to a first transmission protocol a first transmitter adapted to receive the outputted audio stream from the first source and wherein the first transmitter is further adapted to generate two or more audio streams and transmit the same using an internet protocol IP wherein a first of the audio streams include audio data formatted according a second audio format capability and a second of the audio streams include audio data formatted according to a third audio format capability and two or more receivers adapted to receive the transmitted audio streams and wherein a first of the two or more receivers is further adapted to receive the first audio stream that includes audio data formatted according to the second audio format capability and a second of the two or more receivers is further adapted to receive the second audio stream that includes audio data formatted according to the third audio format capability and further wherein each of the first and second receivers of the two or more receivers is further adapted to generate respective audio streams with audio data formatted according to an audio format capability compatible with the audio format capability of the audio sink to which it is being transmitted.

According to the first aspect of the embodiments the network system is an Ethernet network system and the network system further comprises a switch wherein the switch is adapted to receive the two or more audio streams and is further adapted to be directed to output the received two or more audio streams to corresponding two or more receivers. Still further according to the first aspect of the embodiments the audio formats are selected from the group consisting of Dolby Atmos 128 channels 64 2 Dolby Digital 5.1 Dolby Digital 6.1 EX Dolby Digital 7.1 Plus lossy Dolby Digital 7.1 TrueHD lossless Dolby Pro Logic Dolby Pro Logic II Dolby Pro Logic IIX 5.1 to 6.1 7.1 Dolby Pro Logic IIZ 5.1 to 6.1 7.1 DTS 6.1 Discrete DTS 6.1 Matrix DTS 7.1 HD lossy DTS 7.1 Master HD lossless Mono and Stereo audio formats.

According to the first aspect of the embodiments the first and second audio formats are the same and the third audio format is different.

According to the first aspect of the embodiments the first second and third audio formats are all different and the first transmission protocol is one of a high definition multimedia interface HDMI transmission protocol a DisplayPort transmission protocol and a Sony Philips digital interface transmission protocol. Still further according to the first aspect of the embodiments the first transmission protocol used an advanced encryption standard AES as an encryption protocol and the first receiver is further adapted to transmit the audio stream according to a second transmission protocol and the second receiver is further adapted to transmit the audio stream according to a third transmission protocol.

According to the first aspect of the embodiments the second transmission protocol is the same as the third transmission protocol the second and third transmission protocols use one of a high definition multimedia HDMI transmission protocol DisplayPort transmission protocol and a Sony Philips digital interface format transmission protocol and the second and third transmission protocols use an advanced encryption standard AES as an encryption protocol.

According to the first aspect of the embodiments the second transmission protocol is different from the third transmission protocol and the second transmission protocol is a high definition multimedia interface HDMI transmission protocol and the third transmission protocol uses one of a DisplayPort transmission protocol and a Sony Philips digital interface transmission protocol.

According to the first aspect of the embodiments the second transmission protocol uses one of a DisplayPort transmission protocol and a Sony Philips digital interface transmission protocol the third transmission protocol is a high definition multimedia interface HDMI transmission protocol and the second and third transmission protocols use an advanced encryption standard AES protocol as an encryption protocol.

According to a second aspect of the embodiments a method for distributing audiovisual data in a network is provided comprising outputting an audio stream formatted according to a first audio format capability from a source using a first transmission protocol receiving the audio stream at a transmitter the transmitter generating and transmitting at least two audio streams using an internet protocol IP wherein the first audio stream is formatted according to a second audio format capability and the second audio stream is formatted according to a third audio format capability and receiving the at least first and second audio streams at respective two or more receivers wherein a first receiver receives the first audio stream with the second audio format capability and further wherein a second receiver receives the second audio stream with the third audio format capability and further wherein each of the first and second receivers of the two or more receivers is further adapted to generate respective audio streams with audio data formatted according to an audio format capability compatible with the audio format capability of the audio sink to which it is being transmitted to.

According to the second aspect of the embodiments the method further comprises receiving the two or more audio streams transmitted by the transmitter at a switch wherein the switch is adapted to be directed to transmit the received two or more audio streams to two or more receivers and the network is an Ethernet network.

According to the second aspect of the embodiments the audio formats are selected from the group consisting of Dolby Atmos 128 channels 64 2 Dolby Digital 5.1 Dolby Digital 6.1 EX Dolby Digital 7.1 Plus lossy Dolby Digital 7.1 TrueHD lossless Dolby Pro Logic Dolby Pro Logic II Dolby Pro Logic IIX 5.1 to 6.1 7.1 Dolby Pro Logic IIZ 5.1 to 6.1 7.1 DTS 6.1 Discrete DTS 6.1 Matrix DTS 7.1 HD lossy DTS 7.1 Master HD lossless Mono and Stereo audio formats.

According to the second aspect of the embodiments the first and second audio formats are the same and the third audio format is different and according to still further aspects of the embodiments the first second and third audio formats are all different.

According to the second aspect of the embodiments the first transmission protocol uses one of a high definition multimedia interface HDMI transmission protocol DisplayPort transmission protocol and a Sony Philips digital interface format transmission protocol and the first transmission protocol uses an advanced encryption standard AES as an encryption protocol.

According to the second aspect of the embodiments the first receiver is further adapted to transmit the audio stream according to a second transmission protocol and the second receiver is further adapted to transmit the audio stream according to a third transmission protocol. According to the second aspect of the embodiments the second transmission protocol is the same as the third transmission protocol and the second and third transmission protocols use one of a high definition multimedia interface HDMI transmission protocol DisplayPort transmission protocol and a Sony Philips digital interface format transmission protocol. Still further according to the second aspect of the embodiments the second and third transmission protocols use an advanced encryption standard AES as an encryption protocol.

According to the second aspect of the embodiments the second transmission protocol is different from the third transmission protocol the second transmission protocol is a high definition multimedia interface HDMI transmission protocol and the third transmission protocol uses one of a DisplayPort transmission protocol and a Sony Philips digital interface format transmission protocol.

According to the second aspect of the embodiments the second transmission protocol uses one of a DisplayPort transmission protocol and a Sony Philips digital interface format transmission protocol and the third transmission protocol is a high definition multimedia interface HDMI transmission protocol and still further the second and third transmission protocols use an advanced encryption standard AES protocol as an encryption protocol.

The embodiments are described more fully hereinafter with reference to the accompanying drawings in which embodiments of the inventive concept are shown. In the drawings the size and relative sizes of layers and regions may be exaggerated for clarity. Like numbers refer to like elements throughout. The embodiments may however be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the scope of the inventive concept to those skilled in the art. The scope of the embodiments is therefore defined by the appended claims. The detailed description that follows is written from the point of view of an audiovisual data distribution systems company so it is to be understood that generally the concepts discussed herein are applicable to various subsystems and not limited to only a particular audiovisual data distribution device or class of devices such as digital media data distribution systems.

Reference throughout the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with an embodiment is included in at least one embodiment of the embodiments. Thus the appearance of the phrases in one embodiment on in an embodiment in various places throughout the specification is not necessarily referring to the same embodiment. Further the particular feature structures or characteristics may be combined in any suitable manner in one or more embodiments.

Aspects of the embodiments are directed to an audiovisual AV distribution network AV NW communicating via internet protocol and implemented as a framework of local area networks LANs . Transmitters and receivers in the AV distribution network leverage multicast transmission technology and compression standards to switch seamlessly between sources transmitting audiovisual data that may be content protected by a security protocol scheme.

While the various aspects of the embodiments are described as being deployed in a framework of LANs the embodiments are not necessarily limited thereto. Similarly while the AV NW is described as employing a variety of formats protocols and standards the formats protocols and standards it should be understood by those of skill in the art that such descriptions are for illustrative purposes only and are not to be taken in a limiting manner. For example while the high bandwidth digital content protection HDCP 1.x and 2.x and the h.264 compression standards are described in the specification the AV distribution network is not limited to a particular security protocol or a particular compression standard. Those of skill in the art will appreciate that one or more elements of the described embodiments can be interchanged and or combined with and among each other.

For over 40 years Crestron Electronics Inc. has been the world s leading manufacturer of advanced control and automation systems innovating technology to simplify and enhance modern lifestyles and businesses. Crestron designs manufactures and offers for sale integrated solutions to control audio video computer and environmental systems. In addition the devices and systems offered by Crestron streamlines technology improving the quality of life in commercial buildings universities hotels hospitals and homes among other locations. Accordingly the systems methods and modes of the aspects of the embodiments described herein as embodied as networks and among others can be manufactured by Crestron Electronics Inc. located in Rockleigh N.J.

AV NW distributes AV data from one or more sources to one or more sinks via one or more switches and networked intermediate transceiver devices functioning as transmitters receivers or both. Each source can transmit AV data to an intermediate transceiver device functioning as a transmitter . Transmitter relays the AV data to one or more intermediate transceiver devices functioning as receiver . Each of the one or more receivers then transmits the AV data to AV sink .

According to aspects of the embodiments AV sources can be Blu Ray Disc Players media servers digital video disc DVD players digital video recorders DVR and cable boxes or any device other device capable of transmitting audiovisual data. AV sources are adapted for transmitting audiovisual data to an intermediate transceiver device or transmitter over an audiovisual interface. The audiovisual data can be transmitted as an industry standard signal. For example the audiovisual data can be transmitted via a high definitional multimedia interface HDMI as shown in . The HDMI specification defines an interface for carrying digital audiovisual data. Throughout this discussion AV source will be described as transmitting digital audiovisual data over an HDMI interface. However as those of skill in the art can appreciate the audiovisual interface can be any other interface for transmitting video such as a video graphics array VGA interface a digital video interface DVI interface or a DisplayPort DP interface among others.

In addition the audiovisual interface can serve as a protected interface thereby allowing the video source to transmit audiovisual data protected under a security protocol to an intermediate transceiver device discussed in greater detail below in regard to or transmitter . Various content protection schemes have been developed for a variety of reasons. For example certain content protection schemes are employed to ensure that a user may not intercept transmissions of television shows movies and music.

One content protection scheme to protect digital content that is transmitted over cables between devices is known as high bandwidth digital content protection HDCP . HDCP is a specified method administered by Digital Content Protection L.L.C. DCP for protecting digital content as it travels across connection interfaces and protocols such as DP DVI and HDMI. Other security protocols for content encryption include secure real time transfer protocol SRTP secure sockets layer SSL and transport layer security TLS among others.

A commonly implemented form of a content protection scheme is HDCP 1.x e.g. ver. 1.4 . Traditionally HDCP 1.x is used to communicate content from point to point. In other words transmitter can only send content to first AV sink using HDCP 1.x but cannot send it to second AV sink . The use of intermediate transceiver devices known as repeaters is permitted however it requires further decrypting and re encrypting as well as additional security steps. Revisions of the HDCP scheme HDCP 2.x implement an interface independent scheme thereby allowing a device to transmit protected content to multiple sinks .

According to aspects of the embodiments AV NW as shown in is an HDCP protected network and accordingly one or more of AV sinks can receive HDCP protected content from one or more of AV sources . Additionally transmitter can distribute HDCP content to more than one receiver simultaneously as provided in HDCP 2.x. The interfaces between each HDCP source and sink can be HDCP protected interfaces. As such transmitters receivers and intermediate transceiver devices can decrypt the HDCP content at the HDCP receiver on each of its inputs and re encrypt the data with an HDCP transmitter on each of its outputs. The intermediate transceiver device informs the upstream device of its downstream connections and it is the responsibility of the intermediate transceiver device to maintain the HDCP protection of those connections.

In the Figures that follow other interfaces are shown aside from the ones in some interfaces are used between modules some between components of circuit boards and some within devices such as within a field programmable gate array FPGA . As those of skill in the art can appreciate the interfaces can define a physical construct of the interconnections between apparatus which can include different signal paths signal levels and so on. By way of example HDMI has three physically separate communication channels which are described below. Other versions of HDMI have added channels such as audio return channel ARC and HDMI Ethernet channel HEC but such detailed discussion is both beyond the scope of the this discussion and not necessary to understand the aspects of the embodiments.

The first HDMI channel is the display data channel DDC or enhanced DDC E DDC which is a communication channel based on the IC bus specification inter integrated circuit also referred to as IIC or I2C is a multi master multi slave single ended serial computer bus used for attaching low speed peripherals to computer motherboards and embedded systems . According to the HDMI specification an IC standard mode speed of 100 Kbit s must at least be maintained and further provides for a fast mode speed of operation of 400 Kbit s. The DDC channel is actively used for HDCP.

The second HDMI channel is the TMDS channel which actually refers to a method of transmitting data known as transition minimized differential signaling TMDS which is described in greater detail below. The TMDS channel interleaves video audio and auxiliary data using three different packet types called the video data period the data island period and the control period. During the video data period the pixels of an active video line are transmitted. During the data island period which occurs during the horizontal and vertical blanking intervals audio and auxiliary data are transmitted within a series of packets. The control period occurs between video and data island periods. The final channel is referred to as the consumer electronics control CEC channel and is an HDMI feature designed to allow the user to command and control up to 15 CEC enabled devices that can be connected through HDMI by using only one of their remote controls. CEC also allows for individual CEC enabled devices to command and control each other without user intervention.

Thus as those of skill in the art can appreciate each interface type has its own particular specifications and while certain types of data are more readily transmitted by some interfaces than others according to further aspects of the embodiments the interface in and of itself should not be construed as determining what type of data is being transmitted within it i.e. video audio command status and other types of signals .

The encryption algorithm HDCP 2.x comprises at least two functions authentication of receiving devices and encryption of audiovisual data. Before a device can receive a session key necessary to decrypt audiovisual data encrypted by the HDCP transmitter it undergoes a multistep process. Included in the process are at least four steps 1 authentication and key exchange 2 locality check 3 authentication with repeaters and 4 session key exchange. Each will be described in turn.

The authentication and key exchange step involves the verification of the HDCP receiver s public key certificate. During this step a master key k is transmitted from receiver to transmitter .

The locality check step allows transmitter to verify that receiver is located in the vicinity of transmitter . To verify that receiver is in the same vicinity as transmitter transmitter performs a round trip time test that checks to see that the delay between a pair of messages is not more than about 7 milliseconds MS .

The authentication with repeater step is employed if receiver is a repeater. This step involves the communication of the downstream topology from repeaters in the path to transmitter .

The session key exchange step is performed after the authentication checks steps 1 and 3 and locality check step 2 are complete. The session key k originates from and is sent by transmitter to receiver in order to encrypt and decrypt the audiovisual data. Unlike HDCP 1.x which is a point to point link HDCP 2.x allows for multiple receivers to decode the same content using the same encryption key.

To transmit the same content to multiple receivers on an IP network there are three forms of IP communication unicast multicast and broadcast. Unicast communications provide a route for sending datagrams from one end point to another end point. Multicast communications provide routes for datagrams to be sent from at least one end point to a pre designated group of end points. In broadcast communications an end point sends the same datagrams to all connected end points. Each of the three forms of IP communications will be described in turn.

Common unicast communications can use any one of hypertext transfer protocol HTTP file transfer protocol FTP user datagram protocol UDP and transmission control protocol TCP . While a detailed discussion of the nature of each of these communication protocols is both unnecessary and beyond the scope of this discussion and therefore in fulfillment of the dual purposes of clarity and brevity has been omitted herein a short discussion of each will aid in understanding the various aspects of the embodiments.

Unicast is the most common of the three IP communications. Transmitter can transmit multiple copies of audiovisual data by a unicast message that uses TCP UDP HTTP or FTP. However as the number of receivers increase the amount of data transmitter needs to transmit increases as well. Thus at some point it becomes more efficient to use a multicast or broadcast type of communication.

In addition to unicast transmitter can transmit multiple copies of the audiovisual data via a broadcast stream. Broadcasts force all devices on the network segment to receive the traffic. While this ensures that each device on a network receives a communication this manner of communication also wastes bandwidth. Broadcasting to devices that are not involved with the broadcasted content burdens those devices and results in wasted network bandwidth.

Multicast is a form of communication that optimizes the use of bandwidth. Multicast achieves this optimal use of transmission bandwidth by sending the audiovisual data in this case only to a subset of devices using a special set of addresses. Multicast uses internet group management protocol IGMP as the communications protocol. IGMP assists in managing the group of receivers that will receive the multicast transmission. One way to minimize inefficient use of transmission bandwidth when communicating using multicast is by having network switches implement IGMP snooping to reduce network traffic on segments with no devices in the group. Accordingly transmitters can transmit HDCP 2.x encrypted content to multiple receivers via an IP multicast stream. This reduces both the bandwidth on the network as well as the processing burden on devices. As those of skill in the art can appreciate snooping is the process of listening to IGMP network traffic such that network switches can maintain a map of which links need which IP multicast streams. Consequently multicasts transmissions can be filtered from links that do not need them and thus network switch controls which ports receive which specific multicast traffic.

Referring back to transmitter comprises transmitter HDMI transceiver uncompressed packet formatter FPGA packet formatter FPGA transmitter Ethernet PHY module PHY module transmitter central processing unit CPU transmitter memory buffer memory buffer and transmitter digital signal processor transmitter DSP . According to an embodiment transmitter is further adapted for unencrypting the HDCP protected content and re encrypting it for transmission over an IP based network. Transmitter can be further adapted for substantially simultaneously transmitting the audiovisual data in both a compressed format and an uncompressed format. According to an embodiment transmitter compresses the audiovisual content according to the h.264 video compression format or the Motion Pictures Experts Group MPEG 4 Part 10 Advanced Video Coding AVC video compression format. Both of these formats are known to those of skill in the art and in fulfillment of the dual purposes of clarity and brevity do not need to be discussed in any greater detail.

In operation transmitter receives the encrypted audiovisual content HDCP 1.x or 2.x over HDMI HDCP interface . HDMI transceiver then removes the HDCP encryption from the audiovisual data by decrypting the AV data. The signal output from HDMI transceiver is in the form of TMDS. As those of skill in the art can appreciate TMDS is a technology for transmitting high speed serial data and can be used by HDMI video interfaces as well as other types of digital interfaces. TMDS seeks to reduce electromagnetic interference by using advanced coding algorithms. The coding algorithms have the effect of reducing electromagnetic interference and enabling robust clock recovery and high slew tolerance by converting each one of a data word into an equivalent longer data word that when decoded contains the same information but is designed to spread out more evenly the number of high logic signals and low logic signals e.g. the ones and zeros . This averages out the power being distributed and keeps the clock recovery fairly uniform over time. For example an eight bit word has 256 possible combinations. These can include 1000000 and 00001111 for example. While over an amount of time the number of low and high logic signals will average out transmissions such as the ones shown above can cause difficult clock recovery and very high or very low electromagnetic transmissions as well as power usage. Thus TMDS uses up to 460 ten bit words to represent the 256 possible values. Words such as those shown are avoided. The front end processing of the transmitter will be described in great detail below in regard to .

After being received and processed by HDMI transceiver the unencrypted audiovisual content is then routed to packet formatter FPGA . Packet formatter FPGA conditions or processes the TMDS signal comprising the audiovisual content to a format that can be encrypted using HDCP 2.x. The conditioned audiovisual data is routed to an IP encoder such as an society of motion picture and television engineers SMPTE 2022 5 6 encoder and on to an Ethernet 10 gigabit GBit Media Access Controller MAC using multicast UDP messages. The audiovisual data then exits packet formatter FPGA and is routed to PHY module such as a 10 GBit PHY or fiber module. CPU implements the low bandwidth authentication locality check and key exchange portion of HDCP. The encapsulation functions of transmitter will be described in greater detail below in regard to .

Transmitter DSP then converts the audio content portion from the first source content into one or more formats that are compatible with the audio format capability of the one or more sinks connected to one or more receivers . As those of skill in the art can appreciate substantially all sinks and sources will be able to use or transmit audio in the stereo format some can do at least two audio format capabilities stereo and something else some can do three or more and some may only be able to do stereo.

According to aspects of the embodiments the conversion that occurs in transmitter DSP and in receiver DSP as discussed below is performed using the known programming capabilities of typically available DSPs that is while one particular DSP can be used in the transmitters and receivers as manufactured by Crestron Electronics Inc. e.g. such as the Cirrus Logic CS49834A DSP current specifications of which can be found at http www.cirrus.com en products cs49834 44.html prodKey CS49834 other DSPs can be used as long as the programming and conversion speed capabilities can meet the overall processing requirements within network and networks described below . While such programming techniques and capabilities are known to those of skill in the art the particular implementation of conversion between one or more audio formats to one or more different audio formats as described herein within the network environment are believed to be within the aspects of the embodiments described herein novel un obvious and possess utility. In addition while such conversion programming takes place in the embodiment of a DSP such conversion is not limited thereto. That is generally known programming techniques available to one or more microprocessors of different types can also accomplish the conversion between audio formats as described here including having one or more microprocessors dedicated to decoding and having one or more other microprocessor dedicated to encoding. All such programmable devices and additional devices not mentioned capable of such programming are to be considered to be within the aspects of the embodiments as well. Further still those of skill in the art can appreciate that any and all such decoding encoding are subject to the availability of one or more licenses from the developers of such audio format encoding standards.

For example referring to and network first source outputs a first audio stream ASin a first format AFC and first transmitter receives the audio stream ASin the first audio format AFC. If ASis to be sent to three separates sinks sinks and each having a different audio format formats AFC AFC and AFC respectively transmitter DSP will generate three audio streams AS AS and AS each with respective different audio formats AFC AFC and AFC. Transmitter then transmits the three separate streams of data AS AS and ASthrough switch or whichever switch it might be connected to and the audio streams will be sent to the correct receivers and ultimately the appropriate sinks . According to aspects of the embodiments one or more of the audio streams output from transmitter in this example can have the same audio format as was received from source however that need not necessarily be the case. DSP can generate new audio streams of data with the same or different audio formats than was originally received from source

According to aspects of the embodiments transmitter is told or determines the audio format capability that each sink can use. According to aspects of the embodiments in network and and as described in detail below each of receivers when connected to sink will interrogate its respective sink and determine its audio format capability. Receivers will then broadcast this information to all of the transmitters in network . Alternatively according to still further aspects of the embodiments transmitters can also interrogate all the devices of network find the receivers and query what type of sinks are attached to them if any and in that manner determine the audio format capability of the sinks . illustrates a non exhaustive list of currently available audio format capabilities. According to further aspects of the embodiments a user can manually input the audio format capability of each sink in a manner as described in greater detail below.

In source outputs audio stream AS with a first audio format AFC. Transmitter receives the first audio stream AS and either determines or is informed that three different sinks sinks and are scheduled to receive audio stream AS but in their own native audio formats. DSP in transmitter then reformats the audio stream ASinto three separate audio streams AS each with the audio formatted in correspondence to the sink that it is being sent to. Thus transmitted from transmitter in is ASwith AFC ASwith AFC and ASwith AFC. Switch receives the three audio streams and sends them to the appropriate receiver ASto receiver and sink ASto receiver and sink and ASto receiver and sink . Finally each respective audio sink receives its particular audio stream with its uniquely formatted audio information.

As briefly discussed above while different audio formats will be viewed or heard by users differently i.e. there is no universally accepted best audio format it is also the case that converting from one format to another can be accomplished but with some degradation in sound quality. For example a conversion from a 7.1 audio format to stereo can be accomplished the result will be acceptably adequate stereo sound but with a loss of the 7.1 audio immersive experience. A conversion from stereo to 7.1 can also be accomplished but with a less than full audio experience than would be the case in which original 7.1 audio format was output through a 7.1 audio format system. Such technology conversion from stereo to the upper audio formats stereo to 5.1 7.1 among others is currently available These products are known as ProLogic and Neo. As those of skill in the art can appreciate conversion from 7.1 to stereo back to 7.1 can be a lossy process. However encoding the channels separately usually results in less loss. Such is the case with other audio formats. Depending on the level of complexity some audio formats require more or less data and an according amount of network bandwidth. Further it is known that some formats can be converted readily and effectively to others while some cannot be converted. Still further there is the question of licensing. At least several of the audio formats illustrated in alphabetical order in are proprietary and or subject to patent s and thus could require the payment of licensing fees prior to use.

As those of skill in the art can appreciate the plurality of sinks do not have to have different audio formats they can all be the same or all different or any combination thereof. Further as those of skill in the art can appreciate there are certain tradeoffs in configuring a digital audio re formatting system and method according to aspects of the embodiments in the manner shown and described herein in regard to . That is while preserving the highest capability audio signal possible for the respective sources and sinks this comes at the price of transmission bandwidth. Where before only one audio stream was sent there can be up to N audio signals where N is the number of different audio formats. Furthermore whereas before only one high capability audio format transmission might have been sent through network now there could be two three or more relatively high capability audio transmission streams and this will require additional data and bandwidth requirements. Thus increased audio fidelity comes at the cost of increased use of network resources i.e. bandwidth .

Referring again to and network a first example according to an aspect of the embodiment will be described. For example within a home network environment there could be a Blue Ray player as source and it is desired to watch this content in multiple rooms. The house has Ethernet network running to these rooms or Wi Fi is installed which can also be considered to be network . The A V content is output from source as HDMI and then converted at transmitter to a network compatible stream using various techniques depending on network capacity network physical layer and the amount of latency that can be tolerated. In some cases there can be a 10 Gbit infrastructure that can handle uncompressed audio video data rates. In other instances the audio video needs to be compressed to fit into the 10 100 1000 mbit type wired network or some type of 802.11 wireless network. The audio formats can consist of compressed or uncompressed audio various channel number configurations and different audio sample rates. Regardless of the compression channel number configuration and other characteristics the audio video content or only audio content is converted into a network appropriate protocol and transmitted. According to further aspects of the embodiments such a protocol can be an IP.

As known to those of skill in the art common consumer AN transmission links such as HDMI transmitter have the capability to interrogate one or more sink devices using extended display identification data EDID to determine their respective audio capabilities. That is transmitter can determine respective audio format capabilities of each of audio sinks using EDID. Transmitter obtains the audio format capability per audio sink information and uses it to create multiple audio streams AS with respective audio formats AFCaccording to aspects of the embodiments. According to further aspects of the embodiments transmitter can determine or obtain from receivers the respective audio format capabilities of each of the audio sinks . As known to those of skill in the art the HDMI standard defines some mandatory formats that all devices must support so that all combinations of sources and sinks results in compatible audio communication.

Referring back to and network in this example source can be directed to distribute audio to three audio sinks . Transmitter uses EDID information from each of receivers connected to respective audio sinks to determine that audio sink accepts Dolby Atmos which is the native format output by source audio sink accepts Dolby Digital 7.1 Plus which is a lossy form of audio format and audio sink accepts Dolby Pro Logic. Source outputs the audio content in Dolby Atmos in an audio stream and transmitter receives it and then generates three separate streams using DSP ASwith AFCof Dolby Atmos to send to audio sink in this case no processing was done as this is a pass through and forward case thus ASis substantially the same as AS and AFCis substantially the same as AFC ASwith AFCof Dolby Digital 7.1 to send to audio sink and ASwith AFCof Dolby Pro Logic to send to audio sink . Switch receives the three separate streams and directs them to the appropriate receivers ASto receiver ASto receiver and ASto receiver . Each of the three receivers then forwards the properly formatted audio content to their respective audio sinks AS AS and AS . According to further aspects of the embodiments one some or all of the transmission between sources and transmitters transmitters and switches switches and receivers and receivers and sinks can be encrypted use an advanced encryption standard AES . The same applies to each of the networks of .

An example of a distribution of audio content from source to sinks using network will now be discussed using essentially the same distribution of audio formats as was described in the example in regard to network system and . That is source outputs an original audio stream ASwith an audio format AFC and in this case transmitter passes that through to switch along with appropriate addressing information i.e. to which sink s ASwith AFCshould be sent . Switch receives ASwith AFCand forwards it to receivers using an IP mode of transmission . Receiver DSP in receiver knowing that its corresponding sink accepts audio with an audio format capability of AFC generates ASwith a format of AFCfrom ASwith an audio format AFC and transfers it to sink according to aspects of the embodiments. A substantially similar process occurs with each of receivers and albeit with different audio formats for their respective sinks as shown in according to aspects of the embodiments.

According to further aspects of the embodiments a hybrid of networks and can also be implemented as shown in . illustrates network for transmitting one or more streams of formatted audio data such that one or more of the transmitted streams can be converted to an audio data format that is compatible to an intended audio sink according to an embodiment. illustrates network that combines aspects of both networks and that is both transmitters and receivers contain respective DSP s such that more discriminatory re formatting can take place.

According to further aspects of the embodiments the processing that occurs in either or both of transmitter DSP and receiver DSP can be split between the two in the embodiment shown in . For example source can output original audio stream ASwith an original audio format AFC. Transmitter with DSP can receive audio stream ASwith audio formatted according to AFC and generate two streams ASwith AFC and ASwith AFC. Transmitter transmits ASand ASto switch which forwards the received audio streams according to EDID information received from transmitter . For example ASwith AFCcan be forwarded to receiver and ASwith AFCcan be forwarded to receivers and . Receiver knows that sink with which it communicates accepts audio formatted according to AFC so no re formatting need occur. That is ASwith AFCis received by receiver and then forwarded to sink . ASwith AFCis also forwarded by switch and sent to receiver in this case sink which corresponds to receiver accepts audio formatted according to AFC. Therefore no additional re formatting is necessary by receiver DSP of receiver . But in the case of receiver and its corresponding sink sink the audio needs to be formatted with AFC. Thus receiver DSP of receiver re formats the received audio AS2 with AFC and generates ASwith AFC which is then sent to sink according to aspects of the embodiments. As those of skill in the art can now appreciate the audio stream received by receiver could also have been ASwith AFC and then a re formatting between AFCand AFCwould have had to occur. There can be practical considerations as to which formats can be generated based on licensing issues as briefly described above and there can be practical considerations as well. For example attempting to generated a Dolby Digital 7.1 TrueHD audio signal from a stereo signal might generate outputs from all eight speaker groups but would not be true 7.1 as there are only two channels to begin with. Thus formatting can occur in either or both of DSP at transmitter or in receiver DSP at receiver . At least one advantage of this configuration and method is that the demand on the bandwidth of network is reduced than if TMS1 with AFC1 were to be transmitted directly through the network.

Furthermore in the event that there is an accompanying video signal within TMS1 audio video synchronization can be more readily maintained. According to the aspects of the embodiments the latter advantage can be realized in network as well. According to further aspects of the embodiments other audio processing related advantages can be realized such as echo cancellation among other improvements. As known to those of skill in the art most humans can tolerate up to about 20 milliseconds ms mismatch between video and accompanying video signals. Thus substantially near real time audio processing can be important. Such audio video processing can occur through the use of digital signal processors such as those used for transmitter DSP and receiver DSP . That is transmitter DSP and receiver DSP can perform complex processing of the audio signal at or less than 20 ms in regard to the accompanying video signal. One so called acid test of audio video processing and mis match testing includes viewing and listening to a video of a person speaking into a microphone. Not only is there the actual physical video and audio signals to compare but because of the nature of the video seeing a person speaking into a microphone the effect is emphasized if there is any mismatch.

Aspects of the embodiments involve a networked based distribution system that can implement a 1 to many or N M cross point switching matrix. As those of skill in the art can appreciate a video to network convertor box can be configured as either a transmitter or receiver such a configuration is shown in . Further it is known that transmitters can separate the elements of an HDMI signal into the video and audio data. The video data can be compressed using h.264 JPEG2000 Joint Photographer Engineer s Group image compression method 2000 or the video data can be uncompressed and prepared for network transmission by packetizing. According to further aspects of the embodiments the audio data is also packetized. illustrates the block diagram of the device configured as an uncompressed transmitter. According to further aspects of the embodiments DSP as shown in can receive the extracted audio content over a plurality of I2S interfaces e.g. four if high bit rate audio content such as Digital Theater Systems high definition DTS HD or Dolby TrueHD is being distributed. A single I2S interface is adequate to communicate a stereo down mix back to the packet encapsulater.

In method step each receiver receives the same transmission stream and converts the audio stream from the format as transmitted from source to the audio format capability that corresponds to the capability of the audio sink it is being transmitted to unless of course the respective audio sink can accept that same audio format capability that the audio stream was originally transmitted in then no conversion need occur . The appropriately formatted audio file is then sent to the corresponding audio sink . This ensures the highest audio fidelity signal is received at the respective audio sink .

In method step transmitter receives the transmitted audio file in its native format i.e. in the format transmitted by source and generates two or more transmission streams with at least two different audio formats. For example if transmitter receives ASwith AFC and is directed to transmit two audio streams it could generate and transmit ASwith AFCand ASwith AFC or ASwith AFCand ASand AFC. Each transmission stream is transmitted to its intended audio sink through their respective receiver with the audio file contained therein at the audio format capability that corresponds to the capability of the audio sink it is being transmitted to. Transmitter transmits the audio streams using an IP although other protocols can also be used. This ensures the highest audio fidelity signal is received at the respective audio sink . In method step transmitter transmits the two or more audio streams through switch to two or more receivers that correspond to intended recipients audio sinks . In method step receivers receive their respective audio streams and generate or forward the audio stream with the audio format capability that is compatible with its corresponding sink . According to aspects of the embodiments at least one of the audio format capabilities of sink will be generated by receiver DSP of receiver and at least one of the audio format capabilities of the audio stream forwarded to a sink will either have been generated by transmitter or be the same as output by source according to aspects of the embodiments.

Attention is now directed to network switch shown in . In addition to distributing the audiovisual content from transmitters to receivers network switch is further adapted to communicate information e.g. such as command and status information among other types between transmitters and receivers . For example network switch can facilitate the communication of information necessary for HDCP authentication between devices transmit control and status information and extended display identification data EDID information from sink to source as well as other information. As those of skill in the art can appreciate EDID information is a data structure provided by a digital display e.g. sink to describe its capabilities to a video source e.g. source . EDID is defined by a standard published by VESA. The EDID includes manufacturer name and serial number product type phosphor or filter type timings supported by the display display size and luminance data among other types of display related data.

To facilitate multicast communication on the network network switch implements a multicast group management protocol. According to an embodiment network switch implements internet group management protocol IGMP snooping. IGMP is a communications protocol used by hosts and adjacent routers on IP networks to establish multicast group membership.

According to further aspects of the embodiments network switch implements multicast listener discovery MLD to manage multicast groups. As those of skill in the art can appreciate MLD is a component of the IP version 6 IPv6 suite. MLD is used by IPv6 routers for discovering multicast listeners on a directly attached link much like IGMP is used in IPv4. While AV NW is described throughout this specification as implementing IGMP those of skill in the art can appreciate that this is for illustrative purposes only and the multicast group management protocol is not limited thereto. In addition and according to further aspects of the embodiments AV NW is not limited to use of a single AV NW switch but can as shown in include a plurality of NW switches 

According to further aspects of the embodiments receiver reverses the process of transmitter with the added function of recovering the pixel clock signal. Receiver is adapted to receive both compressed and uncompressed audiovisual data from transmitter over an IP based network link. For example receiver can receive a multicast UDP message via an Ethernet PHY interface. As described above receiver can receive HDCP protected content from transmitter via an HDCP protected interface such as LAN interface . Receiver is further adapted to unencrypt HDCP protected content and re encrypt the same for transmission over an AV interface such as HMDI HDCP interface .

Receiver is adapted to receive the encrypted audiovisual content HDCP 2.x over the HDCP protected network link as a UDP multicast HDMI HDCP interface . Referring back to it can be seen that transmitter employs HDMI transceiver to remove the HDCP encryption processes it as an unencrypted TMDS signal re encrypts the audiovisual content and then transmits it via PHY module on LAN interface . Once received at receiver the encrypted audiovisual content is unencrypted in packet decoder FPGA to form an unencrypted TMDS signal. While encryption of the TMDS signal does not occur in packet decoder FPGA according to aspects of the embodiments those of skill in the art should appreciate that encryption of the TMDS signal could occur in packet decoder FPGA . The signal comprising the audiovisual content then exits packet decoder FPGA and is routed to HDMI transceiver . CPU implements the low bandwidth authentication locality check and key exchange portion of the HDCP encryption process.

Transceiver can be used as either or both transmitter and receiver . That is either or both of transmitter and receiver can be replaced by transceiver or they can remain as shown in with AV NW . While the multi functional aspect of transceiver provides benefits such as versatility transmitter and receiver can each be single function devices dedicated to either transmitting or receiving and comprising the elements described herein for each.

According to an embodiment transceiver can also be an endpoint in AV NW . An endpoint is a device that allows conversion of audio and video from one medium to another. When functioning as transmitter transceiver can be adapted to receive audiovisual data from source over an industry standard interface such as an HDMI interface. As described above transmitter can also receive HDCP protected content from source over an HDCP protected interface.

Transceiver comprises HDMI HDCP interface LAN interface HDMI ports VGA interface VGA port analog audio interface analog audio port VGA to HDMI converter HDMI w o HDCP interface scaler infra red IR port infra red transceiver universal serial bus USB interface RS 232 interface USB port DSP module 4 IS inter IC Source interface 1 IS interface 5 2 HDMI transceiver switch HDMI transceiver system on chip SoC module transistor transistor logic TTL 1080p Max interface 10 100 Mbit Ethernet interface FPGA 10 100 Mbit Ethernet media independent interface MII 10 100 Mbit switch PHY interface first and second splitters Ethernet courtesy port HDMI Converter module and 10 Gbit Ethernet port .

Among one of many capabilities of HDMI transceiver is its ability to receive an HDCP protected HDMI signal from a video source on HDMI HDCP interface and HDMI port . HDMI transceiver can also output HDCP encoded video data via HDMI HDCP interface and HDMI port . According to aspects of the embodiments the AV data on HDMI HDCP interface can be encrypted or unencrypted. If the AV data is encrypted HDMI transceiver removes HDCP protection by decrypting the AV data using the session key received when authenticating with the source of the AV data the session key is described below in greater detail in regard to . According to an aspect of the embodiments HDMI transceiver can be an ADV7625 5 2 HDMI Transceiver switch available from Analog Devices Inc. of Norwood Mass. or a similar transceiver switch as known to those of skill in the art. HDMI transceiver is substantially equivalent to HDMI transceiver of transmitter of and HDMI transceiver of receiver of .

Transceiver also comprises VGA to HDMI converter such as an ADV7850 available from Analog Devices or some other such similar converter. VGA to HDMI converter converts a VGA signal received from a source which can be transmitted via VGA interface along with an analog audio signal transmitted via analog audio interface to a TMDS signal that is then routed to HDMI transceiver via HDMI transition minimized differential signaling TMDS without HDCP HDMI w o HDCP interface .

As described above transceiver also comprises DSP module that is in communication with HDMI transceiver . According to an embodiment DSP module can be a DSP module available from Cirrus Logic of Austin Tex. DSP module is adapted for audio down mixing. In certain applications users desire to down mix audio from a surround sound format to stereo audio. As those of skill in the art can appreciate a surround sound system such as a Dolby 5.1 which is the most popular surround sound system at present provides six speakers front left front right front center rear left rear right and a sub woofer that essentially surrounds the intended listener. The original audio from a movie of show is processed into the distinct channels and added to the video data. However some people watching the video may not have the surround sound speaker systems and so will want the audio converted to a more traditional stereo system. DSP module receives the surround sound formatted audio from HDMI transceiver as a plurality of IS streams and returns a single IS stream. As those of skill in the art can appreciate IS is an electrical serial bus interface standard used for connecting digital audio devices together. It is used to communicate pulse code modulated PCM audio data between devices. The IS bus separates clock and serial data signals resulting in a lower jitter than is typical of communications systems that recover the clock from the data stream. IS can be used for digital audio devices and technologies such as compact disc CD players digital sound processors and digital TV DTV sound.

Transceiver further comprises first splitter such as a 1 2 splitter as shown in . According to an embodiment first splitter can be an EP9142 1 2 Splitter available from Explore Microelectronics of Taiwan. First splitter receives a TMDS signal comprising AV data without HDCP encryption from HDMI transceiver via HDMI w o HDCP interface and transmits a TMDS signal to both FPGA and scaler via HDMI w o HDCP interfaces as shown . Splitters as those of skill in the art can appreciate simply reproduce the input digital data signal into two but substantially similar digital signals.

FPGA conditions the received TMDS signal that comprises the audiovisual content to a format that can be encrypted using HDCP 2.x. As described below in greater detail in regard to which along with illustrates some of the inner components of FPGA one or more of the internal components of FPGA conditions the audiovisual data so that it can then be routed to IP encapsulation and forward error correcting FEC device IP encoder such as an SMPTE 2022 5 6 encoder and on to an 10 gigabit 10 GBit Ethernet MAC 10G Ethernet MAC also shown in using multicast UDP messages on a 64 bit frame IP encapsulated with FEC AV data interface also referred to as 64 bit advanced extensible interface bus 64 bit advanced extensible interface AXI bus . FPGA is in further communication with PHY module which can also be a small form factor pluggable transceiver SFP . PHY module interfaces with switch and the remaining components of AV NW .

Also part of transceiver is scaler . As those of skill in the art can appreciate scalers convert video signals from one display resolution to another typically scalers are used to convert a signal from a lower resolution to a higher resolution n a process known as up conversion or up scaling. But scalers in general can also be used to down scale. According to aspects of the embodiments scaler is further adapted to downscale TMDS signal for h.264 encoding. Scaler is further adapted to scale the received TMDS signal to a native resolution of a corresponding AV sink such as when functioning as receiver . According to further aspects of the embodiments by scaling the received TMDS signal to a native resolution of sink scaler substantially eliminates or reduces downstream processing of the AV data. According to further aspects of the embodiments receiver can receive the native signal of the corresponding sink as EDID information. As those of skill in the art can appreciate scaling video can result in flicker effects. Flicker effects are visual artifacts in a video presentation due to adaptive layer switching. As further known to those of skill in the art there are at least three types of flicker noise blur and motion flicker.

Scaler is further adapted to scale one or more received Internet Protocol multicast streams to a common resolution. As will be described later this is a necessary step to generator locking i.e. genlocking the AV data from more than one internet protocol multicast stream. As those of skill in the art can appreciate generator locking or genlock is a common technique wherein the video output of one source or a specific reference signal from a signal generator is used to synchronize other video sources together. The aim in video applications is to ensure the coincidence of signals in time at a combining or switching point.

According to still further aspects of the embodiments scaler is adapted to maintain an authenticated connection with sink . Scaler is still further adapted to generate video timing data during switching events. With the generated video timing data receiver can maintain an HDCP authenticated interface with sink thereby reducing switching times.

Also part of transceiver is SoC module . SoC module is adapted to compress audio data using MP3 advanced audio compression AAC and H.2.64 and other mechanisms. MP3 is an audio coding format for digital audio that uses a form of lossy data compression. It is a common audio format for consumer audio streaming or storage as well as a de facto standard of digital audio compression for the transfer and playback of music on most digital audio players. AAC is another audio coding standard for lossy digital audio compression. AAC was designed to be the successor of the MP3 format and generally achieves better sound quality than MP3 at similar bit rates.

H.264 or MPEG 4 Part 10 advanced video coding MPEG 4 AVC is a video compression format that is currently one of the most commonly used formats for the recording compression and distribution of video content. As those of skill in the art can appreciate H.264 MPEG 4 AVC is a block oriented motion compensation based video compression standard developed by the ITU T Video Coding Experts Group VCEG together with the ISO IEC JTC1 Moving Picture Experts Group MPEG . H.264 is known as being one of the video encoding standards for Blu ray Discs all Blu ray Disc players must be able to decode H.264. It is also widely used by streaming internet sources such as videos from Vimeo YouTube and the iTunes Store web software such as the Adobe Flash Player and Microsoft Silverlight and also various HDTV broadcasts over terrestrial ATSC ISDB T DVB T or DVB T2 cable DVB C and satellite DVB S and DVB S2 . H.264 is typically used for lossy compression in the strict mathematical sense although the amount of loss may sometimes be imperceptible. It is also possible to create truly lossless encodings using it for example to have localized lossless coded regions within lossy coded pictures or to support rare use cases for which the entire encoding is lossless.

SoC module is in communication with 10 100 Mbit switch via 10 100 Mbit Ethernet interface through which SoC module communicates with FPGA and then to switch . SoC module is also in communication with Ethernet courtesy port via 10 100 Mbit Ethernet interfaces and 10 100 Mbit switch . SoC module further communicates with infrared IR transceiver via USB interface . SoC module is further adapted to receive and generate RS232 signals which it can receive transmit on RS232 interface and RS232 port .

Attention is directed to which illustrates detailed block diagram of scaler . According to an aspect of the embodiments scaler is adapted to generate image content data. For example scaler can generate a repeated frame of image content data such as a repeated frame of video during switching discontinuities. Sink can then receive the image content data and present an aesthetically pleasing switch according to aspects of the embodiment in which make before break transitions cannot be made.

Scaler comprises input scaling block frame rate processing block memory framer buffer memory and output scaling block . Scaler receives input audiovisual data video timing data and image content data received as input audio visual data that is configured as HDMI signal without HDCP interface . Frame rate processing block is adapted for receiving asynchronous input video timing data from input scaling block and writing the incoming image content data into memory .

Frame rate processing block is further adapted for receiving the free running output video timing data from free running output timing generator and reading incoming video data from memory as required by the output resolution of scaler i.e. native resolution of sink . Frame rate processing block is further adapted for performing frame rate conversion if the input refresh rate and the output refresh rate of the audiovisual data differ.

Input scaling block is adapted for receiving the asynchronous input video timing data and performing scaling if required. According to different aspects of the embodiments depending on the input and output setup input scaling can be performed before frame rate processing. According to other aspects of the embodiments output scaling can be performed subsequent to frame rate processing. In these applications output scaling block receives the free running output video timing data and performs scaling as required. According to still further aspects of the embodiments one or both of input scaling and output scaling can occur via input scaling block and output scaling block . Free running output timing generator is further adapted for substantially continuously generating free running output video timing data used to give downstream video sink a fixed resolution. As those of skill in the art can appreciate scaling down prior to frame rate processing reduces the memory bandwidth requirements while scaling down afterwards will increase the memory bandwidth requirements.

According to aspects of the embodiments in which scaler generates audiovisual data comprising a repeated frame of image content data e.g. when switching between at least two sources the last frame of video received by scaler i.e. the frame to be repeated from first source is repeatedly read from memory and output by scaler . When scaler achieves scaler lock with audiovisual data from second source a frame of image content data from audiovisual data received from second source is read from memory and output by scaler .

Referring again to scaler outputs the scaled TMDS signal via HDMI w o HDCP interface to second splitter such as the 1 2 splitter shown in . According to an embodiment second splitter can be an EP9142 1 2 Splitter available from Explore Microelectronics of Taiwan. Second splitter splits the output of scaler scaled AV data to be received by both HDMI transceiver via HDMI w o HDCP interface and HDMI converter module also via HDMI w o HDCP interface . The scaled AV data output to HDMI transceiver is then output to sink from HDMI transceiver via HDMI with HDCP interface . Such scaled AV data output from scaler can be AV data transmitted from receiver at the native resolution to sink .

HDMI converter module receives the scaled and split HDMI signal via HDMI w o HDCP interface converts the received HDMI TMDS into a TTL signal and transmits the TTL signal to SoC module . According to an embodiment SoC module can be an ARM SoC designed by ARM of Great Britain. SoC module further comprises an encoder such as h.264 encoder and a decoder such as an h.264 decoder. According to further aspects of the embodiments the encoder can be an h.265 encoder and h.265 decoder a JPEG2000 encoder and decoder or an MJPEG encoder and decoder among other types of encoders and decoders. The h.264 encoder is adapted for compressing AV data according to the h.264 video compression standard for transmission on AV NW . The h.264 decoder is configured for decoding AV data compressed according to the h.264 video compression standard. The h.264 decoder can be employed to decode compressed AV data for transmission on an AV interface to sink such as an HDMI interface. According to an embodiment the encoding and decoding functions are performed by an FPGA within HDMI converter module . SoC module can also encrypt received signal with HDCP and can therefore transmit AV signals via HDMI HDCP interface to HDMI transceiver

Attention is now directed to . illustrates a detailed functional block diagram of first portion processing block of FPGA of transceiver as shown in according to an embodiment. First portion processing block of FGPA shown in comprises TMDS decoder data formatter and framer AXI bus AES encryption module and several different input intermediate and output signals all of which are described in greater detail below.

First portion processing block of FPGA of transceiver as shown in conditions the TMDS signal comprising the audiovisual content and received via HDMI w o HDCP interface to a format that can be encrypted using HDCP 2.x. First portion processing block as shown in provides a substantially seamless interface between the balance of FPGA and HDMI transceiver . According to further aspects of the embodiments First portion processing block of FPGA shown in provides TMDS clock alignment TMDS character detection TMDS de skewing TMDS decoding to separate image content data signals i.e. red green blue RGB signal and generation of auxiliary data and video timing data signals i.e. video synchronization signal video control signal auxiliary data and video clock . Several of these functions are performed by TMDS decoder along with data formatter and framer .

As described previously HDMI transceiver receives AV data over a plurality of interfaces including a plurality of HDMI interfaces. According to aspects of the embodiments the received AV data can be encrypted HDMI HDCP interface or unencrypted HDMI without HDCP interface . If the AV data is encrypted HDMI transceiver can remove HDCP protection by decrypting the AV data using the session key received when authenticating with the source of the AV data in the manner as described above.

The newly unencrypted AV data can then be transmitted from HDMI transceiver as a TMDS signal to FPGA over HDMI w o HDCP interface . First portion processing block of FPGA as shown in comprises TMDS decoder that receives the TMDS signal and decodes extracts and outputs separate image content data signals RGB signal video timing data i.e. video synchronization signal video control signal auxiliary data signal and video clock signal to data formatter and framer module .

Data formatter and framer module further comprises a first in first out FIFO buffer . Data formatter and framer module receives AXI clock from a phase lock loop circuit not shown in the Figures. Data formatter and framer module is adapted for tagging various data types and packing the data into 128 bit words. FIFO buffer or alternatively a dual port random access memory RAM is adapted for crossing the clock domain prior to AES encryption. As those of skill in the art can appreciate the function of crossing the clock domain entails referencing the video data from a first clock to a second clock. In this case video clock clocks the data into data formatter and framer and AXI clock clocks the data out of data formatter and framer and into FIFO buffer and is used in subsequent processing such as in AES encryption module . As those of skill in the art can further appreciate video clock is obtained from the network transmitted video data and so is affected by the same jitter problems as the video data itself meaning that it is not necessarily fixed and stable. AXI clock however while asynchronous to video clock is substantially fixed and stable and thus assists or facilitates a consistent manner of clocking the video data from this point on. The output of FIFO buffer is transmitted via AXI bus to AES encryption module .

Two signals are also output by data formatter and framer video synchronization Vsync signal and video info . According to aspects of the embodiments Vsync is extracted by data formatter and framer from TMDS decoder information and represents the start of a frame boundary. Video Info is also extracted by data formatter and framer and represents the image size among other things pertaining to the video data as discussed below. Use of both Vsync and Video info are discussed below.

AES encryption module is adapted to implement two components of HDCP authentication HDCP key exchange and AES 128 encryption. AES encryption module also receives AXI clock and further receives private encryption key which is received Digital Content Protection Inc. the licensor of HDCP through an internal or external source. As known to those of skill in the art each HDCP device has a unique set of private keys along with a public key. Private encryption key is received by AES encryption module which contains an algorithm to convert the private key into a public key. AES encryption module then sends a message with the public key to the receiver and expects the receiver to return its public key. The transmitter in this case AES encryption module verifies the validity of the received public key and calculates a secret key. The receiver also generates its own secret key these are never transmitted but need to match. These are used to generate a message that is transmitted and the receiver using its hopefully matching secret key receives it and verifies that it would match a message that it would generate using the same secret key. If they match then a valid HDCP interface has been established. As those of skill in the art can appreciate this description is brief and does not provide all of the details in fulfillment of the dual purposes of clarity and brevity. Additional information regarding the HDCP encryption procedure can be found in a document entitled High Bandwidth Digital Content Protection System Interface Independent Adaptation revision 2.1 18 Jul. 2011 DCP LLC and Intel Corporation.

According to aspects of the embodiments as shown in AES encryption module employs AES encryption in 128 counter CTR mode to output AES encrypted uncompressed video on AXI bus . As those of skill in the art can appreciate in cryptography a mode of operation is an algorithm that uses a block cipher to provide an information service such as confidentiality or authenticity. A mode of operation describes how to repeatedly apply a cipher s single block operation to securely transform amounts of data larger than a block. Counter mode turns a block cipher into a stream cipher. It generates the next keystream block by encrypting successive values of a counter. The counter can be any function that produces a sequence that is guaranteed not to repeat for a long time although an actual increment by one counter is the simplest and most popular.

Attention is now directed towards . illustrates a detailed functional block diagram of second portion processing block of FPGA of transceiver as shown in according to an embodiment. Second portion processing block of FPGA of transceiver that is shown in performs among other functions an encapsulation and FEC function in regard to the AV data in transceiver according to an embodiment. Second portion processing block of FPGA of transceiver device as shown in comprises payload assembly header insertion payload assembler module IP encoder 10 Gbit Ethernet MAC and serializer deserializer SERDES .

Payload assembler module receives encrypted AV data from the first portion processing block via AXI bus and encodes the data for transmission throughout AV NW . Payload assembler module also received unencrypted AV data via HDMI w o HDCP interface . The encrypted AV data is routed from payload assembler module to IP encoder via AXI bus wherein the encrypted AV data is encapsulated according to IP protocols and forward error correction algorithms are performed. According to further embodiments IP encoder can be an SMPTE 2022 5 6 encoder. The IP encapsulated unencrypted AV data is then forwarded to 10 Gbit Ethernet MAC using multicast UDP messages via AXI bus .

As mentioned above payload assembler module is further adapted for receiving uncompressed AES encrypted AV data via AXI bus as well as uncompressed and unencrypted AV data via HDMI w o HDCP interface and assemble the data into 64 bit words for presentation to IP encoder . In presenting the IP encapsulated data payload assembler module inserts an additional payload header at predetermined intervals. The additional payload header comprises video standard information such as image dimensions frame rate and the pixel clock. The image dimensions can be obtained from the video info signal the frame rate information can be obtained from the Vsync signal and the pixel clock can be obtained from the output of timestamp module that generates a timestamp on pixel clock . According to an embodiment the timestamp information can be used by receiver in a clock recovery algorithm and the remainder of the video standard information can also be used at receiver .

According to still further aspects of the embodiments the timestamp of as imparted by timestamp module can be employed to transition from a compressed version of AV data to an uncompressed version. That is the timestamp is utilized by receiver to synchronize a compressed version of AV data with an uncompressed version of AV data. By synchronizing the two streams according to matching time stamps receiver can output a seamless transition between the two streams. According to an embodiment FPGA can receive both an AES encrypted signal comprising compressed AV data and an AES encrypted signal comprising uncompressed AV data and processes both for transmission on AV NW .

Payload assembler module outputs assembled AV data to IP encoder via 64 bit AXI bus for IP encapsulation and forward error correction FEC . According to aspects of the embodiments IP encoder can be a 10G SMPTE 2022 5 6 encoder. SMPTE 2022 5 is a standard for the transport of high bitrate media over IP networks. SMPTE 2022 6 is a standard for forward error correction for high bitrate media transport over IP networks. IP encoder encapsulates the payload AV data from payload assembler module into RTP UDP IP packets and optionally generates and transmits forward error correction packets. IP encoder is scalable to multiple channels allowing transmitter to transmit more than one channel of audiovisual data and additional non AV data. According to aspects of the embodiments the output of IP encoder can be characterized as 64 bit frame IP encapsulated with FEC AV data.

While IP encoder is shown as an SMPTE 2022 5 6 encoder and described herein as an SMPTE 2022 5 6 encoder IP encoder is not limited to an SMPTE 2022 5 6 encoder. In other embodiments IP encoder can encapsulate the packets according to the real time transport protocol RTP or MPEG 2 transport stream TS protocol. IP encoder encoder is communicatively coupled to external RAM such as an external synchronous dynamic random access memory SDRAM double data rate type three DDR3 via external RAM databus .

IP encoder is further adapted for queuing generic Ethernet traffic for transmitted and receiving generic Ethernet packets from a 10 Gbit link. IP encoder communicates with a media independent interface MII to memory mapped interface MMI module MII to MMI module to provide a path from the host processor or local Ethernet switch to the 10G link. As shown in MII comprises the interconnects between 10 100 Mbit switch and MII to MMI module and the interconnects between MII to MMI module and IP encoder . MII transmits and receives Ethernet traffic via Ethernet courtesy port .

IP encoder outputs IP encapsulated encrypted AV data both compressed and uncompressed to 10 Gbit Ethernet MAC via 64 bit AXI bus . 10 Gbit Ethernet MAC further comprises SERDES . Encapsulated serialized and encrypted AV data is output to 10 Gbit PHY module which completes the modification of the AV data to be put on LAN interface . According to aspects of the embodiments the combination of devices and provides the functions of a creating frame boundary delimitation and frame synchronization for the AV data b handling of source and destination addresses c error detection in regard to physical medium transmission errors d media access management e medium allocation in the form of collision avoidance and f contention resolution.

As shown in FPGA further comprises host CPU interface in communication with external host processor . According to aspects of the embodiments external host processor can be a processor in the STM32 family available from STMicroelectronics of Geneva Switzerland. Host CPU interface performs substantially as a transceiver for external host processor and communicates with external host processor via processor bus and substantially all of the components of FPGA as shown by interface . In addition 156 MHz clock is used by modules and .

The apparatus of can be used as both a transmitter and receiver notwithstanding that the discussion of FPGA has been in the context of a transmitter. discussed below focuses on recovering a clock that is necessary for proper operation of transceiver as a receiver particularly receiver As those of skill in the art can therefore appreciate transceiver can receive data at PHY module on LAN interface in and proceed from right to left.

Clock recovery circuit comprises video data buffer which is connected to moving average filter via video data buffer level indicator buffer level indicator . Recovered video stream is received by video data buffer in bursts due to jitter over the network. One purpose of video data buffer is to facilitate the generation of a clock that can be used to process the video data and make it less jittery over time. This means that the flow of video data is smoother more consistent and can be used to generate high quality video signals.

Buffer level indicator is a signal that indicates the level of the buffer of video data according to aspects of the embodiments an optimum level of performance is achieved when buffer level indicator is about 50 . According to aspects of the embodiments moving average filter averages buffer level indicator over ten buffer read enable cycles. According to further aspects of the embodiments different numbers of buffer read enable cycles can be used to determine the average of the buffer level indicator . The output of moving average filter moving average filter output is connected to format converter . Format converter error output sends the converted signal to second order low pass filter LPF which also receives as an input loop gain G and outputs its signal via LPF output to control logic . The output of control logic control logic output is connected to phase locked loop PLL circuit . PLL circuit receives as an input the output of programmable clock generator reference clock . Programmable clock generator receives as an input I2C configuration signal . PLL output clock is sent to clock divider and jitter cleaner . Jitter cleaner also receives as in input I2C configuration signal . Clock divider generates divided clock output that is sent to video data buffer and moving average filter . Divided clock output is used by video data buffer to dump the video data within the buffer and to generate the output of moving average filter i.e. moving average filter counts the number of pulses of divided clock output and generates an average value every ten pulses .

Video data buffer as part of clock recovery portion circuit receives AV data over LAN interface and facilitates circuit to match the received video data rate see and video clock with the recovered pixel clock rate embodied as pixel clock . As those of skill in the art can appreciate a pixel clock rate is the speed at which the pixels are transmitted such that a full frame of pixels fits within one refresh cycle.

As described above moving average filter receives buffer level indicator . As those of skill in the art can appreciate moving average filter averages the value represented by buffer level indicator over a number of samples and feeds the average to format converter as moving average filter output . According to aspects of an embodiment moving average filter averages buffer level indicator over ten samples although different numbers of samples can also be used. The output of moving average filter moving average filter output therefore represents a smoothed or averaged version of buffer level indicator .

The output of moving average filter is then presented to format converter as moving average filter output . Format converter processes the now smoothed buffer level indicator to a mapped control signal which is then input to LPF . LPF passes only the low frequency components of the output of format converter . 156 MHz clock is used by each of modules circuits and .

LPF can be implemented as a second order LPF. According to aspects of the embodiments second order loop filter has a cutoff frequency of about 1.25 MHz. The output of LPF is low pass filtered error signal filtered error signal that is then sent to control logic . Control logic generates control signals and outputs control logic output to PLL circuit to create PLL output clock . According to aspects of the embodiments control logic converts filtered error signal into a pulse width modulated PWM signal that is further filtered not shown to become the control voltage of a programmable voltage controlled crystal oscillator VCXO clock generator that is part of PLL circuit . According to aspects of the embodiments generation of PLL controls signals are well known to those of skill in the art and therefore in fulfillment of the dual purposes of clarity and brevity a detailed discussion thereof has been omitted from this discussion.

PLL circuit also receives as an input reference clock which is the clock signal generated by programmable clock generator in response to data and commands received via I2C configuration signal . Reference clock is a clock signal that has a frequency that is dependent upon the received video resolution. Thus the received video resolution is obtained and put onto the I2C bus and input to programmable clock generator to be used to generate input reference clock . In other words input reference clock is an estimation of a clock that is used to generate pixel clock via clock recovery circuit .

As those of skill in the art of PLL design can appreciate when the reference clock is input to PLL circuit it acts to adjust and pull in the frequency of reference clock to be substantially similar to that of the required pixel clock frequency. As those of skill in the art can further appreciate while PLL circuits can be substantially precise in adjusting clock frequencies there will be a first range of frequencies of the output clock signal which in this case is PLL output clock . This first range of frequencies makes allowance for the frequency error of programmable clock generator and the original pixel clock as found in the recovered AV data stream as received on LAN interface according to aspects of the embodiments.

As shown in PLL output clock is transmitted to clock divider where it can be divided down by a factor of 1 to N wherein according to aspects of the embodiments N equals 64 but can be as high as 256 512 1024 among other divide by factors or less than 64 as the case may be . The output of clock divider is divided clock output . Divided clock output enables video data buffer to read the AV data received on LAN interface and close the recovery timing loop. According to further aspects of the embodiments divided clock output matches the video frame rate of AV data received on LAN interface .

According to further aspects of the embodiments PLL output clock is also transmitted out of FPGA to jitter cleaner . Jitter cleaner receives both PLL output clock and data commands from I2C configuration signal . The output of jitter cleaner is sent back to FPGA and received by pixel clock generator which generates pixel clock shown and used in . Jitter cleaner is located in a different portion of transceiver . Jitter cleaner helps remove any last vestiges of jitter that might remain in the output of PLL circuit PLL output clock .

According to an embodiment audiovisual network administrators can configure AV NW through a dedicated software configuration tool configuration tool stored locally or accessed via a web interface. The network administrator can access the configuration tool via a personal computer laptop computer tablet mobile phone or any other portable electronic device. The configuration tool or Digital Media DM tool is a tool or software application that can be used by an operator to monitor and change aspects of the operation of different portions of the network. By way of a non limiting example the configuration tool can facilitate the manual insertion of EDID information regarding a source or sink. Other uses are possible according to further aspects of the embodiments.

The configuration tool can provide an introspective look into digital video distribution systems that includes among other features a detailed view of advanced source and display information source select functions and system topology views. According to further aspects of the embodiments the configuration tool is a resource for deploying and troubleshooting audiovisual distribution networks such as AV NW .

According to aspects of the embodiments the configuration tool can use graphical user interfaces to represent the hardware that the tool can access through network interfaces. According to further aspects of the embodiments inputs are shown on the left outputs on the right and transceiver devices are connected via colored lines with text stating resolution connection and HDCP status. Functions or greater signal detail can be displayed by simply hovering over different parts of the system with a pointer controlled by a mouse device or equivalent.

The configuration tool can further provide one or more interfaces to reorder inputs and outputs in AV NW . According to an aspect of the embodiments the configuration tool provides a graphic user interface adapted to provide the ability to drag and drop symbols that represent features and functions in a manner known to those of skill in the art. The configuration tool can also provide an interface geared toward experienced users based on a grid that allows for minimal keystrokes.

According to aspects of the embodiments AV NW further implements one or more methods for automatically visualizing the network topology. The network switch can then mine this information from address resolution protocol ARP tables and provide it to the configuration tool for visual display.

As represented through the configuration tool each transceiver device can include a dropdown box used for selecting the input to be routed. This quick route tool aids in testing sources during system commissioning. Setup buttons on each of transmitter and receiver brings the user to additional menus that can be organized in a convenient tabbed format. Transmitter menus provide EDID setup HDCP testing test signal generation and other advanced features receiver menus provide a means to adjust cable type and enable deep color support. Transmitters can also have their own setup screens allowing adjustments to incoming source signals. Receivers views present resolution cable length HDCP and routing data among other types of set up screens. Through use of the configuration tool users can quickly identify signal behaviors and take action to remedy unwanted results.

As can be appreciated by those of skill in the art and as discussed above EDID is a crucial part of digital AV signals. According to aspects of the embodiments therefore the configuration tool can provide the ability to view manage and or manually edit EDID. In addition to video resolution refresh rate and format information the configuration tool can supply audio information such as number of channels resolution format among other types of information.

The configuration tool further provides additional features that allow EDID copying from a display so that it can be applied to a set group of sources . One such feature is an advanced button for deep color that exposes compatible resolutions that work within the deep color guidelines. Another such feature is audio selection. When using the audio selection feature and choosing Best Common an audio format is selected that is compatible with all selected displays. Another feature available with audio selection is Best Overall which provides integrators of AV NW the choice of audio format regardless of downstream device support.

According to further aspects of the embodiments the configuration tool can further include simple network management protocol s and can interface with the Fusion Building Management software program that is available from Crestron Electronics Inc. of Rockleigh N.J.

As described above encoding processes are discussed in reference to . The encoding processes are not meant to limit the aspects of the embodiments or to suggest that the aspects of the embodiments should be implemented following the encoding process. The purpose of the encoding processes described herein are to facilitate the understanding of one or more aspects of the embodiments and to provide the reader with one or many possible implementations of the processed discussed herein. illustrate flowcharts of various steps performed during the encoding process. The steps of are not intended to completely describe the encoding process but only to illustrate some of the aspects discussed above.

To solve the aforementioned problems the aspects of the embodiments are directed towards systems modes and methods for transmission of digital media over internet protocol networks wherein two or more uncompressed streams of video data from two or more different sources can be substantially synchronized such that switching can occur substantially seamlessly with little or no degradation in audio video quality.

The disclosed embodiments provide a system software and a method for switching between two or more uncompressed sources of audio video data such that little or no degradation of the perceived quality of the audio video signal occurs. It should be understood that this description is not intended to limit the embodiments. On the contrary the embodiments are intended to cover alternatives modifications and equivalents which are included in the spirit and scope of the embodiments as defined by the appended claims. Further in the detailed description of the embodiments numerous specific details are set forth to provide a comprehensive understanding of the claimed embodiments. However one skilled in the art would understand that various embodiments may be practiced without such specific details.

Although the features and elements of aspects of the embodiments are described being in particular combinations each feature or element can be used alone without the other features and elements of the embodiments or in various combinations with or without other features and elements disclosed herein.

This written description uses examples of the subject matter disclosed to enable any person skilled in the art to practice the same including making and using any devices or systems and performing any incorporated methods. The patentable scope of the subject matter is defined by the claims and may include other examples that occur to those skilled in the art. Such other examples are intended to be within the scope of the claims.

The above described embodiments are intended to be illustrative in all respects rather than restrictive of the embodiments. Thus the embodiments are capable of many variations in detailed implementation that can be derived from the description contained herein by a person skilled in the art. No element act or instruction used in the description of the present application should be construed as critical or essential to the embodiments unless explicitly described as such. Also as used herein the article a is intended to include one or more items.

All United States patents and applications foreign patents and publications discussed above are hereby incorporated herein by reference in their entireties.

Alternate embodiments may be devised without departing from the spirit or the scope of the different aspects of the embodiments.

