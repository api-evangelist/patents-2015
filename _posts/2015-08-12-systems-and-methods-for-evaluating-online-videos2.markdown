---

title: Systems and methods for evaluating online videos
abstract: Systems and methods for evaluating online videos. One method includes receiving a URL; determining a URL type; detecting whether the URL includes one or more videos; determining at least one of a size of the video, a position of the video on a web page of the web page URL, whether the video is set to autoplay, and whether the video is set to mute; computing a score based on one or more of the size of the video, the position of the video on the web page of the web page URL, whether the video is set to autoplay, and whether the video is set to mute; obtaining at least two frames of at least part of the video, wherein each frame is obtained at one or more predetermined intervals during playback of the video; and classifying each detected video based on the at least two frames.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09661360&OS=09661360&RS=09661360
owner: Integral Ad Science, Inc.
number: 09661360
owner_city: New York
owner_country: US
publication_date: 20150812
---
This application is a continuation of U.S. Nonprovisional patent application Ser. No. 14 281 484 filed May 19 2014 which claims the benefit of priority to U.S. Provisional Patent Application No. 61 825 403 filed May 20 2013 the entireties of each of which are incorporated herein by reference.

Various embodiments of the present disclosure relate generally to evaluating online videos such as digital videos distributed over the Internet. More specifically particular embodiments of the present disclosure relate to systems and methods for evaluating online videos distributed over the Internet for improving advertising metrics.

As people increasingly consume content online i.e. over the Internet the importance of evaluating and tracking the quality and quantity of that consumption has increased. For example many Internet entities such as publishers of online content and online advertisers are now creating and distributing online videos over the Internet. Videos are often either a segment of content requested by an Internet user an Internet advertisement created by an advertiser e.g. a video ad similar to a television commercial or some combination of requested content and a video ad.

Traditionally advertisers and ad networks had little knowledge of the factors that affect true viewability of an online video autoplay player size and position on the page. This lack of knowledge resulted in invalid impressions which themselves caused a great deal of lost value in video ad buys.

Accordingly a need exists for systems and methods for evaluating online videos such as digital videos distributed over the Internet. More specifically a need exists for systems and methods for evaluating online videos distributed over the Internet such as for improving advertising metrics.

According to certain embodiments methods are disclosed for evaluating online videos. One method includes receiving at one or more servers a URL to be reviewed determining by the one or more servers a URL type for the received URL wherein the URL type of the received URL is one of a web page URL and a video URL detecting by the one or more servers whether the URL includes one or more videos determining by the one or more servers for each video detected on a web page of a web page URL at least one of a size of the video a position of the video on a web page of the web page URL whether the video is set to autoplay and whether the video is set to mute computing by the one or more servers for each video detected for a web page URL a score based on one or more of the size of the video the position of the video on the web page of the web page URL whether the video is set to autoplay and whether the video is set to mute obtaining by the one or more servers for each video detected at least two frames of at least part of the video wherein each frame is obtained at one or more predetermined intervals during playback of the video and classifying by the one or more servers each detected video based on the at least two frames.

According to certain embodiments systems are disclosed for evaluating online videos. One system includes a data storage device storing instructions for evaluating online videos and a processor configured to execute the instructions to perform a method including receiving at one or more servers a URL to be reviewed determining by the one or more servers a URL type for the received URL wherein the URL type of the received URL is one of a web page URL and a video URL detecting by the one or more servers whether the URL includes one or more videos determining by the one or more servers for each video detected on a web page of a web page URL at least one of a size of the video a position of the video on a web page of the web page URL whether the video is set to autoplay and whether the video is set to mute computing by the one or more servers for each video detected for a web page URL a score based on one or more of the size of the video the position of the video on the web page of the web page URL whether the video is set to autoplay and whether the video is set to mute obtaining by the one or more servers for each video detected at least two frames of at least part of the video wherein each frame is obtained at one or more predetermined intervals during playback of the video and classifying by the one or more servers each detected video based on the at least two frames.

Additional objects and advantages of the disclosed embodiments will be set forth in part in the description that follows and in part will be apparent from the description or may be learned by practice of the disclosed embodiments. The objects and advantages of the disclosed embodiments will be realized and attained by means of the elements and combinations particularly pointed out in the appended claims.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the disclosed embodiments as claimed.

Reference will now be made in detail to the exemplary embodiments of the disclosure examples of which are illustrated in the accompanying drawings. Wherever possible the same reference numbers will be used throughout the drawings to refer to the same or like parts.

In view of the challenges outlined above systems and methods are disclosed for evaluating online videos such as digital videos distributed over the Internet.

Referring now to the figures depicts a screenshot of an exemplary web page of any given website. The web page may be formatted for any type of desktop or mobile browser and may be accessed by any device configured to send and receive HTTP communications and or HTML content. As shown in web page may have embedded therein a digital video . The digital video may be of any type or format including a flash video HTML5 video and so on. The digital video may be positioned at any location of the web page and may have any desired size. In one embodiment digital video may be positioned on web page such that it appears above the fold that is it is visible within the browser window when a user first visits the web page. In another embodiment the digital video may be positioned partially or entirely below the fold meaning the user may have to scroll down to view the entire video.

In one embodiment of the present disclosure systems and methods relate to detecting and evaluating the position of a video on a web page the size of the video player and or whether the video is on autoplay or muted. In one embodiment the presently disclosed systems and methods may be delivered through a video indexing API that detects and evaluates one or more of those features or characteristics. In one embodiment the presently disclosed systems and methods may detect these factors and allow each Internet customer e.g. an online advertiser or publisher to define their own viewability standard or score for uniformly evaluating video viewability. For example if the video is more than 50 above the fold and set to autoplay the impression could be classified as valid. However if the video is set to autoplay and located below the fold then the video could be classified as invalid. The absence of audio during autoplay could also impact the validity of the impression. In addition to elimination of various forms of impression pre roll fraud the disclosed systems and method may bring further transparency to the rapidly growing video ad industry.

As shown in a plurality of server systems may also be disposed in communication with electronic network . In general server systems may be configured to receive over electronic network any number of videos and or uniform resource locators URLs to web pages that may contain embedded videos and then evaluate and or score videos according to one or more video viewability techniques. As shown in the embodiment of server systems may include a viewability processor which may be configured to execute an evaluation and or scoring algorithm which may evaluate and or score videos and or web pages containing videos received over electronic network . Server systems may also include one or more databases that store evaluation and or scoring algorithms in memory e.g. on a computer readable medium and where viewability processor may be configured to store received videos and or URLs of web pages containing videos and or results of performing the evaluation and or scoring algorithm in memory e.g. on a computer readable medium . Any received data may be stored in the databases in an encrypted form to increase security of the data against unauthorized access. Any of the devices or functionality of server systems content distribution network and or a video hosting site may be combined together or separated and may be operated by a single administrative entity or outsourced to one or more other entities such as a web hosting entity web storage entity and or cloud computing service possibly disposed remotely of each other.

Server systems may also include a viewability application programming interface API interface module that facilitates receiving videos and or URLs of web pages containing videos from one or more of users viewers video publishers video advertisers content distribution network video hosting site and ad network servers . API interface module may also be configured to update and transmit revised or updated video or evaluation content including lists of scores featured videos etc. as will be described in and with respect to the exemplary method of .

In one embodiment method may include determining the viewability of a video or video ad on a web page such as through a video downloading process to effectively measure various characteristics of the video related to the video s viewability such as i a video player size ii whether the video is set to autoplay or not iii whether the video is set to mute iv the presence of additional videos on the page and or v the positioning of the player on the page. In addition other characteristics of the video s viewability may also be measured such as the duration of the video quality of the video e.g. low definition standard definition or high definition etc. In one embodiment the size of the player the percent of the player that is above the fold i.e. within viewable screen space and whether the video is on autoplay mute may contribute to a score that represents the viewability value of the video.

In general method may include collecting frames of online videos and ascertaining the geometric viewability of a video on a page by downloading frames and or imagery from a video for visual indexing. The method may include the use of an automated web browser operating for example on viewability processor of server systems that grabs information about videos embedded on arbitrary web pages. Obtained information may include one or more of the following x position which is the offset from the left side of the browser window assuming a defined window width y position which is the offset from the top of the page width which is the width of the embedded video height which is the height of the embedded video autoplay which is whether the embedded video is set to automatically play upon page visit relevancy score which may be a floating point number relative to other scores on the page which determines relevancy to the viewer a mathematical estimation of which videos a user is most likely to view on a page from highest to least likely and or frames which are frames of still images from the video at one or more specified interval e.g. from about 0.1 seconds to about 10 seconds .

Referring now to method may begin with receiving one or more URLs or one or more web pages step . For example in one embodiment a frame grabber such as frame grabber as shown in may be an automated server based system that is relayed a page URL that may or may not contain a video.

This page URL could come from i a large list of page URLS ii a standard ad call embedded in a 1 1 pixel and or iii a call to the viewability API interface module or one of a number of other methods used to send data.

The frame grabber or other module of server system may request the web page associated with each URL step . The frame grabber or other module of server system may then search the code of the received web page to locate any embedded videos step . In one embodiment the automated web browser running on server system may parse the web content into a document object module DOM using query APIs searching for all elements of the type OBJECT EMBED and or VIDEO given that most Flash videos are of type OBJECT for historical reasons some Flash videos are of the type EMBED and all instances of the HTML 5 VIDEO element are considered to be videos. In one embodiment to eliminate unlikely videos objects of small size may be eliminated from the query list. Secondly objects that do not match height and width aspect ratio specifications may be eliminated from the query list.

Likely videos on aspect ratio alone may be determined with the following formulas based on fuzzy forgiveness of standardized 16 9 and 4 3 aspect ratios 

Objects such as videos that do not fall within these parameters may be eliminated from consideration.

Also in another embodiment IFRAME elements may be evaluated for their ability to contain videos. Elements that do not match the same aspect ratio requirements of OBJECT and EMBED elements may be eliminated. Elements that are left over may be inspected for video elements. In one embodiment inspection is done through the contentDocument property available through the browser s JavaScript API. For browsers subject to the same origin policy preventing inspection of the contentDocument on remote iframes cross domain requests may be enabled by disabling browser security.

In one embodiment method may then include for each detected video step determining a size and or position of the video step . First the frame grabber or another module running on server systems may measure the pixel position of the one or more videos from the northwest top left corner of the web page Y pixels down and X pixels right from the NW page origin . The frame grabber or another module running on server systems may then measure the player size in pixels width and height of the videos on the page.

In one embodiment after initial query each element may be processed using the browser s JavaScript API and WC3 properties may be utilized to determine element position on screen and size.

Because the offsetLeft and offsetTop properties give the position relative to the offsetParent to determine the position relative to the document the DOM may be traversed through all of the parents until the document is reached.

The frame grabber or another module running on server systems may then take screenshots at any one or more suitable intervals such as intervals of about 0.1 seconds to about 10 seconds of those video areas to detect any initial changes autoplay in the visual content of those screens. Visual changes may indicate autoplay or non user initiated commencement of content. When the web page loads screenshots may be taken of the entire browser window at a set interval. Once the presence of autoplay is determined for every video on the web page and an attempt has been made to start each video screenshots may be cropped based on X Y Height and Width of each set of parameters and catalogued for each corresponding video by saving these screenshots in memory.

If autoplay is detected step yes then the frame grabber or another module running on server systems may automatically download additional frames at any one or more suitable intervals such as intervals of about 0.1 seconds to about 10 seconds for the length of the actual video content step . These frames may be used for content subject indexing subject categories classification moderation etc as discussed below. After a set number of frames have been cropped from screenshots a certain number of frames may be discarded at the beginning of the frame set and the rest may be compared for equality either by byte size or generated hash. Before comparison frames may be cropped even more using only a small sample from the center of each frame to avoid most false autoplay positives found on videos with animating user interfaces around the border area. If a video is found not to autoplay then the frames may be scraped and an attempt may be made to start the video and recursively enter the frame scrape cycle again.

If autoplay is not detected step no then the frame grabber or another module running on server systems may execute a play command using automated user interface UI tools and then automatically download additional frames at any one or more suitable intervals such as intervals of about 0.1 seconds to about 10 seconds for the length of the actual video content step . Again these frames may be used for content subject indexing subject categories classification moderation etc. Specifically if it is determined that a video does not autoplay then a play command may be executed step . First the JavaScript method of HTMLElement.play may be attempted which usually returns an error in the case of OBJECT or EMBED. Upon an error the mouse cursor may be moved to the center of the object and simulate a click event. This technique may achieve very high accuracy and reliability.

The duration of the video may then be calculated after the video has been downloaded based on knowledge of the frames per second and the whole number of frames step 

The presence or non presence of sound i.e. muting may then be detected by measuring sound changes when video is played during detection of autoplay step .

Multiple videos on a single web page may be detected and the same processing may be run on all instances of videos on the web page step .

If additional web pages are to be evaluated step yes then method may repeat in relation to additional received web pages or URLs to web pages.

Using the above method to gather positional size sound duration and or autoplay information enables assembly of unique metrics to create a video viewability score which may be used in online advertising methods.

In one embodiment the score may be comprised of one or more pieces of information as discussed below.

One piece of information that may be used to determine a viewability score is the percent of a video that exists above the average fold of the computer screen such as 1200 pixels calculated using the video and or player size and coordinates. For example the percentage above the fold may be divided by 2 for a total maximum score of fifty points.

If autoplay is not detected for the video in question then the video may receive an additional 20 points. If autoplay is detected then the video may receive zero additional points.

If there are no other videos on the web page then the video may receive an additional 10 points. If there are other videos on the web page and none of those other videos do not have autoplay then the video in question may receive 5 additional points. If there are additional videos on the web page that have autoplay then the video may receive no additional points.

If the video in question is not on mute has sound then the video may receive 20 additional points. If the video in question is on mute then the video may receive no additional points.

The total viewability score represented above may range in total from 0 to 100 points. However points assigned to each piece of information may be any value and the total viewability score may be an open ended range.

In order to improve accuracy of information returned videos may be scored with a floating point number. This number may represent a comparison to other videos on the web page and allow returning the videos in an order of most to least relevant. In one embodiment the relevancy score formula may be calculated as follows Score Base Score Position Center Score Base Center Score Distance from Center 2 Base Score Score Center Score Size Adjustment Score Video Area Largest Video Area Final Score Size Adjustment Score Base Score

The above scoring is just one example of the types of viewability scores that may be provided using the above disclosed systems methods and APIs. It is expected that additional scoring systems may be developed and contemplated within the scope of this disclosure based on receiving data including video player size video player coordinates autoplay enabled disabled muting enabled disabled and multi video detection.

In one embodiment system may handle two fundamentally different job types such as a video job and a web page job also referred to as a page job . A video job may be used when a user wants to analyze a single video with a well defined media URL hereafter video URL in a well defined format. A page job may be used to analyze a URL of a HTML web page hereafter page URL which may or may not contain one or more videos. The page URLs may be of an unknown media that is running various video players in various video formats which the system may find and analyze. A video job may produce a result for the video analyzed and or evaluated or may produce no result when a video is not found or the system is unable to analyze and or evaluate the video. A page job may produce one or more results. For a page job each result produced corresponds to a video of the one or more videos found and analyzed evaluated on the web page. If no videos are found on the web page or if a particular video is unable to be analyzed and or evaluated then no result will be produced for the web page or the particular video.

In one embodiment the system consists of one or more of the following subsystems a public site a video scanner a page scanner a scraper a frame grabber a classifier and or quality assurance QA .

Public site may be a public facing website available via web page UI as well as a representational state transfer REST API or other type of API. The functions of public site may include customer account creation and administration functions that allows the creation setup and or administration of a customer account. For example this function may include the creation setup and or administration of usernames passwords API key management etc. Public site also includes functions that handle customer payments and balances provide online documentation and ancillary information accept and process API requests from authorized users customers and or gather and display statistics. Public site also includes various job functions that may be accessed via a web page UI and or an API. These job functions include creating of new jobs such as a video job or a page job and viewing existing jobs. Viewing existing jobs allows for a customer to view a job status one or more job results job errors etc. Jobs may be viewed through various selection methods including but not limited to selections on a customer basis sorting searching etc. Another job function may also be the ability for a customer to delete one or more jobs.

Video scanner is responsible for scanning and or analyzing videos from one or more video jobs. Video scanner by itself or through other subsystems may analyze one or more videos by downloading each video using the video s URL may split each video into two or more still frame images at a 1 second interval or any one or more intervals as mentioned above and may present a selected list of still frames directly or indirectly to classifier .

Page scanner is responsible for scanning web pages from one or more page jobs. Page scanner may scan web pages by using scraper or frame grabber as discussed below. Starting with a URL for a web page page scanner through scraper or frame grabber may produce a list of still frames which may be sent directly or indirectly to classifier .

Scraper may use a site specific script to actually scrape a web page to find any video URLs. Each video URL may then be treated as a video job in which videos are downloaded and split as discussed above in reference to video scanner .

Frame grabber may use technology as described above to produce frames by interacting with a web page through an embedded headless web browser. Since the web page is not a video URL any number of videos may be found and processed for the web page. In addition to producing frames frame grabber may find and or determine viewability data for each video as discussed above. A benefit of using frame grabber is that audio and frames from a video may be accessed and stored without having direct access to video.

Classifier may receive frames of a video which were produced by video scanner and or page scanner and determines a classification. Classifier may also receive audio and other data for the video and use the audio and other data in the determination of a classification. The universe of possible classifications for a given video is specified when the job is created. The system may use one or more of computer vision CV crowdsourcing and or crowd based human techniques to obtain an accurate classification.

QA may be responsible for allowing automatic evaluation and or human evaluation and editing of final results produced by system . Additionally QA allows for the creation and managing of gold samples which are sets of frames with a predetermined set of possible correct classifications. These gold samples may be sent through the system masquerading as actual samples for videos so that accuracy may be gauged via statistical techniques.

The system of either alone or together with the systems and methods of may be configured to perform a method of evaluating and or classifying videos. In one embodiment a customer program via an API makes a job request to the public site to create a new job as shown by arrow A. Alternatively a customer may enter a job request directly into public site via the web page UI. The job request may contain various pieces of information including classifications to use a type of classification list to use a job type one or more URLs of one or more videos and or one or more web pages etc.

For video jobs public site may send the video URL to video scanner as shown by arrow B. Video scanner may call downloader with the video URL and other information as shown by arrow C. Downloader may download the video into a local accessible storage and may call splitter with a location of video file as shown by arrow D. Splitter may split the video file into frames at one or more intervals as discussed above and may store each frame as a separate file in the local accessible storage. Splitter may then passes a list of frames to a frame selector as shown by arrow E.

For page jobs public site may send a web page URL to page scanner as shown by arrow B. After receiving the web page URL page scanner may send the web page URL and other information to either i scraper as shown by arrow F or ii frame grabber as shown by arrow F. Whether page scanner sends the web page URL to scraper or frame grabber is determined by one or more different factors including but not limited to the nature of the web page URL the job profile system defaults etc.

For a web page URL sent to scraper scraper may search and or analyze the web page to attempt to find one or more video URLs. If scraper finds one or more video URLs scraper may send for each video URL found the video URL to downloader as shown by arrow G where the video URL is processed as discussed above.

For a web page URL sent to frame grabber frame grabber may find one or more videos on the web page and may obtain frames for each video found on the web page. Frame grabber may store each frame as a separate file in the local accessible storage. Frame grabber may then sends a list of frames and other information to frame selector as shown by arrow H.

Frame selector may receive for each video a list of frames from either splitter or frame grabber . Frame selector may decide which frames are suitable for subsequent analysis may create a list of suitable frames and may pass this filtered list with other information to classifier as shown by arrow I.

Using techniques involving CV and or crowdsourcing classifier may compute determine one or more classifications for a video based on each set of frames received and any other information including audio that was received and that is associated with the video. If classifier uses CV techniques to classify a video each set of frames and any other information including audio may be sent to computer vision module as shown by arrow J. Computer vision module may compute determine one or more raw classification results and may send the one or more raw classification results to classifier post processor as shown by arrow K. Computer vision module may also search for and or identify one or more objects within each frame. Each of the objects found and or identified within each frame may be tagged. The object tags may be mapped to one or more particular classifications and or the object tags may be used to look up one or more previously mapped classifications for the tag. Once the object tag is mapped and or looked up the resulting one or more classifications for the object may be used to compute determine one or more raw classification results for the video being evaluated.

If classifier uses crowdsourcing techniques to classify a video each set of frames and any other information including audio may be sent to crowdsourcing module as shown by arrow J. Crowdsourcing module may compute determine one or more raw classification results and may sends the one or more raw classification results to classifier post processor as shown by arrow L.

Classifier post processor may filter and or modify the one or more raw classification results depending on certain conditions. The one or more processed classification results and or the one or more raw classification results may be stored by classifier post processor in the local accessible storage. Classifier post processor may send the one or more processed classification results and or the one or more raw classification results to QA as shown by arrow M.

Using one or more of a variety of techniques including advanced statistics heuristics and or personnel of various experience levels one or more processed classification results and or the one or more raw classification results may be quality assured and may be given final approval in QA . QA may send one or more final classification results as well as one or more processed classification results and or the one or more raw classification results to public site as shown by arrow N where each of the results may be stored along with other important information. A customer may view the one or more final classification results one or more processed classification results and or the one or more raw classification results through a web page UI of public site and or through an appropriate API call to public site via customer program as shown by arrow O.

In one embodiment of the present disclosure a domain based viewability score analysis and or classification analysis hereafter assay may be performed for a plurality of URLs for a domain including but not limited to a particular web page of a domain a portion of all of the web pages of a domain and or all of the web pages of a domain. An assay allows for the tracking of how often videos and or web pages change. In an assay URLs may be reviewed using duplication technology and or other techniques to determine if a video and or a web page has changed which would allow unnecessary analysis to be skipped if no change was detected. For example an assay of a domain such as www.veenome.com may be requested. The assay may then automatically visit crawl a particular web page of a domain a portion of all of the web pages of a domain and or all of the web pages of a domain. Each of the web pages crawled may be analyzed as a web page URL as discussed above.

For each web page visited the assay may attempt to detect one or more videos on the web page. For each video detected the assay may perform a viewability evaluation and or a classification evaluation as described above. The results may then be stored in a database. Further for each run of an assay the results may be stored separately to provide historical information. An assay may use any of the one or more steps of method as described in reference to and or one or more of the processes of system as described in reference to .

There may be several configuration options for an assay including but not limited to i scheduling for automatic repeating of an assay at one or more predetermined intervals ii setting an assay to be performed on all web pages of a domain or a portion of web pages of a domain iii setting an assay when repeating a previous assay to continue where the previous assay left off and or to continue to crawl a web page where a previous crawl left off in a case of partial crawl iv setting an assay to randomly crawl web pages of a domain to breadth first crawl web pages of a domain or to depth first crawl web pages of a domain for either an assay on a portion of web pages of a domain and or an assay on all web pages of a domain v setting a maximum and or minimum number of videos to find vi setting which information to save for each video such as whether to save the general category classification brand safety information viewability score date etc. vii setting which configurations to actually use when running classification viewability scoring category and or brand safety determinations and or viii setting crawling rules such as each domain having associated rules that instruct the assay which web pages to visit where the rules may be implemented using a general purpose rule system which may be regular expressions and or other descriptions that provide instructions.

In one embodiment an assay may be configured into an assay group which allows a group of domains to have an assay run with similar rules. Alternatively or additionally an assay group may have a different set of rules for each domain.

As mentioned above duplication technology and or other techniques may be used to determine if a video and or a web page has changed. For each video being analyzed and or evaluated via an assay a video job and or a page job sixty or more images may be produced as frames for example when the video is evaluated at approximately a 1 second interval. When a new page URL is evaluated for one or more videos and or a video of a new video URL is evaluated a duplicate detection engine may determine if a video with similar images has been previously analyzed. The duplicate detection engine may be able to determine whether a video is a duplicate even if the frames produced for a potential duplicate video are not identical to the frames of a previously analyzed video. The frames of the potential duplicate may differ from the frames of the previously analyzed video in one or more ways including but not limited to a scale of the frames video a time in the video when the frames were produced which may be caused by a video jitter and or other reasons an offset of the frames by an amount which may be caused by different framing areas and or a number of images taken.

The duplicate detection engine may analyze each video and or associated frames that have been stored and may compare one or more of the previously analyzed videos and or associated frames against the potential duplicate video. The duplicate detection engine may then assign a duplicate score for each comparison. If a particular duplicate score is high the potential duplicate video may be determined to be a duplicate. If there are no high duplicate scores then the potential duplicate video may be stored for subsequent comparisons. When a potential duplicate video is determined to be a duplicate no further analysis is needed as the information stored in relation to the previously analyzed video may be copied and returned.

The duplicate detection engine may also be used to detect if a particular sequence of frames has been previously analyzed. For example a scene in a video being analyzed may also be a scene in a previously analyzed video. When a potential duplicate scene in a video is determined to be a duplicate no further analysis is needed as the information stored in relation to the previously analyzed scene in a stored video may be copied and returned. Using this video and or scene duplicate analysis the duplicate detection engine may be able to determine if a particular scene and or video contains one or more of video games and or advertisements which may be used for ad detection.

When a video is determined to be an advertisement and or a scene is determined to be an advertisement by the duplicate detection engine this information may be stored. Such advertising information may be used to create an advertisement inventory in which video advertisements and or the brands being represented in the video advertisements are monitored and or tracked for a particular web page of a domain a portion of a domain and or a domain at a given time. The rate at which the advertisements change may also be computed and stored. Advertisers and or other entities may use the results to see what competitors are doing and or may use the results as a guide for what to do.

Results of an assay may be provided in one or more formats and or displays. Results may be transmitted and or downloaded as a comma separated values CSV file. The CSV file may contain details of all of the configurations and operations performed on web pages of domains. Alternatively the CSV file may contain a summary aggregated report. A summary report for a domain may include rolled up results for all parameters being studied in total in percentages and or may include only the top 10 parameters. Additionally assay reports may be viewed through a website and or API such as public site and or customer program . Results may be viewed for a single assay and or for assays conducted at various time intervals to see how various results for a domain change with each assay performed over time. All parameters for assay and or an assay group may be set via a web page and or an API such as public site and or customer program .

An assay as well as a page job may be used to determine one or more rates at which video content of a web page portions of a domain and or a domain change. Each time an assay and or a page job analyzes a web page a subsequent time videos subsequently found may be compared against videos previously found. The result of the comparison may be used to compute a rate of change and stored in the results of the assay and or the results of the page job. Advertisers and or any other interested entity may use this information to fine tune the desire to repeat a page job and or to repeat an assay for a particular web page a portion of a domain and or a domain. The average rate of change may also be used to determine how often a page job an assay for a particular web page an assay for a portion of a domain and or an assay for a domain may be repeated to maintain accuracy.

A benefit of the present disclosure is that a supply side platform SSP which sends and or receives offers for advertisements to be provided on videos and or web pages may be able to use one or more of the viewability scores classification results assay results and or group assay results. The offers that an SSP sends and or receives may be bids at various bid rates depending on information provided by the SSP. For example if nothing is known about a video the bid rates may be low. However if a lot information is known about the video the bid rates may be high. One or more assays may be performed for an SSP at a time before the bidding process. The assay results may be collected for one or more domains and the assay result may be quickly accessed which may involve using a real time bidding system.

The assay results for one or more domains may increase the possibility of higher bid prices. For example an advertiser via a Demand Side Platform DSP may want to advertise only on sports videos that were deemed brand safe. Without the assay results in the bidding process the bid prices may be low because the advertiser may not know anything about a particular video. However if there were detailed information available for the particular video from the assay results then the advertiser may bid a higher price because the advertiser may be able to determine that the video is sports related and or brand safe. Further the SSP may use statistical percentages provided in and or derived from the assay results to determine an initial bid price. For example an SSP may have a low initial bid price for an offer to advertise in a video and or web page when no viewability information is available and the SSP may have a high initial bid price for an offer to advertise in a video and or web page when detailed information is available from the assay.

As a further example a domain that has assay results may show that 80 of the videos on the web pages of the domain contain sports. Higher bids may be obtained from an advertiser that wants to advertise sports related advertisements. Further if the assay results show that a particular video for a web page is sports related even higher bids may be obtained from an advertiser that wants to advertise on a sports video.

In one another embodiment of the present disclosure one or more assay results from a domain may be used to arbitrage an offer for an advertisement. If the category classification brand safety information and or other viewability information of a particular video is unknown the price a publisher may charge for an offer for an ad may be low. A third party entity other than a publisher or an advertiser may have an assay performed and or use one or more assay results of a domain of a publisher to buy a low offer and sell the low offer at a higher price to an advertiser that would be interested in the offer.

An arbitrage system of the present disclosure may buy video advertising slots from an exchange at a low price. In one embodiment the arbitrage system may buy video advertising slots that are uncategorized unclassified of unknown brand safety and or have no viewability information. The arbitrage system may conduct an assay of the domain in which the video advertising slot resides after buying the slots. Alternatively the arbitrage system may conduct an assay of the domain in which the advertisement slot resides prior to buying the video advertising slots. The assay may be setup to determine specific information for the video advertising slots such as a desirable category and or classification. Once the video advertising slots are bought and an assay has been performed the video advertising slots may be placed back on the same exchange and or a different exchange at a higher price with additional information based on the assay results.

In another embodiment of the present disclosure an advertiser may redirect attempts to serve an advertisement from advertisement servers of the advertiser to an advertisement server proxy hereafter ASP instead of via a content distribution network CDN . The ASP may determine and keep statistics on impressions page URLs and or video URLs directed to the ASP by the advertiser. The ASP may use an assay a viewability score analysis and or a classification evaluation as described above to obtain information about one or more web pages and or videos that have been redirected to it. Once the ASP has obtained the information the ASP may redirect ad requests back to the CDN to serve the ad. The information gathered by the ASP may be stored for each advertisement request including but not limited to an impression count a page URL one or more video URLs a category a classification brand safety information viewability etc. The information collected by the ASP may then be collated and presented to the advertiser in the form of a report an online dashboard a web page and or through an API.

In yet another embodiment of the present disclosure an advertiser and or ad server may be set up to send a tracking pixel to a video analyzer server each time a video advertisement is served. The tracking pixel may include information about the web page URL the video URL the advertiser etc. The video analyzer server may determine whether the web page and or the video has been previously analyzed for one or more of a viewability score category classification and or brand safety information. If the video analyzer server has previous analysis the results may be immediately forwarded to the advertiser and or ad server via a predetermined protocol.

If the video and or the web page have not been previously analyzed the video analyzer may use the system to analyze the video and or web page. The results obtained may then be forwarded to the advertiser and or ad server. The advertiser and or ad sever may then decide on the basis of information forwarded by the video analyzer which advertisement to serve on a particular video. For example if a video is not brand safe the advertiser and or ad server may decide not to serve an advertisement. If the category and or classification of the video is sports for example the advertiser and or ad server may serve an advertisement that requires a sports category or classification or serve an advertisement that is generic to a category or classification.

Any of the above described techniques be implemented by server systems as shown in including components therein. Additionally any of the above described techniques may implement one or more steps of method as described in reference to and or one or more of the processes of system as described in reference to .

Any of devices of users viewers video publishers video advertisers server systems content distribution network video hosting site ad network servers and or the system and or subsystems of system may include any type or combination of computing systems such as handheld devices personal computers servers clustered computing machines and or cloud computing systems. In one embodiment devices servers systems and or databases may be an assembly of hardware including a memory a central processing unit CPU and or optionally a user interface. The memory may include any type of RAM or ROM embodied in a physical storage medium such as magnetic storage including floppy disk hard disk or magnetic tape semiconductor storage such as solid state disk SSD or flash memory optical disc storage or magneto optical disc storage. The CPU may include one or more processors for processing data according to instructions stored in the memory. The functions of the processor may be provided by a single dedicated processor or by a plurality of processors. Moreover the processor may include without limitation digital signal processor DSP hardware or any other hardware capable of executing software. The user interface may include any type or combination of input output devices such as a display monitor touchpad touchscreen microphone camera keyboard and or mouse.

Program aspects of the technology may be thought of as products or articles of manufacture typically in the form of executable code and or associated data that is carried on or embodied in a type of machine readable medium. Storage type media include any or all of the tangible memory of the computers processors or the like or associated modules thereof such as various semiconductor memories tape drives disk drives and the like which may provide non transitory storage at any time for the software programming. All or portions of the software may at times be communicated through the Internet or various other telecommunication networks. Such communications for example may enable loading of the software from one computer or processor into another for example from a management server or host computer of the mobile communication network into the computer platform of a server and or from a server to the mobile device. Thus another type of media that may bear the software elements includes optical electrical and electromagnetic waves such as used across physical interfaces between local devices through wired and optical landline networks and over various air links. The physical elements that carry such waves such as wired or wireless links optical links or the like also may be considered as media bearing the software. As used herein unless restricted to non transitory tangible storage media terms such as computer or machine readable medium refer to any medium that participates in providing instructions to a processor for execution.

While the presently disclosed sharing application methods devices and systems are described with exemplary reference to mobile applications and to transmitting Internet HTTP data it should be appreciated that the presently disclosed embodiments may be applicable to any environment such as a desktop or laptop computer an automobile entertainment system a home entertainment system etc. Also the presently disclosed embodiments may be applicable to any type of Internet protocol that is equivalent or successor to HTTP.

Additional objects and advantages of the disclosed embodiments will be set forth in part in the description that follows and in part will be apparent from the description or may be learned by practice of the disclosed embodiments. The objects and advantages of the disclosed embodiments will be realized and attained by means of the elements and combinations particularly pointed out in the appended claims.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the disclosed embodiments as claimed.

Other embodiments of the disclosure will be apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. It is intended that the specification and examples be considered as exemplary only with a true scope and spirit of the invention being indicated by the following claims.

