---

title: Batch processing of oversubscribed system based on subscriber usage patterns
abstract: Some embodiments include a method of scheduling batch processing of a batch processing system based on subscriber usage patterns. The method includes steps of recording a last job commencement event for a subscriber when the batch processing system starts processing a batch process for the subscriber; recording a last usage event for the subscriber when the subscriber uses the batch processing system; in an event that a time period elapsed since the last usage event for the subscriber is less than a time period elapsed since the last job commencement event for the subscriber, placing a next batch process of the subscriber into a recently used queue; identifying the next batch process of the subscriber as the oldest batch process from the recently used queue; and start processing the identified batch process for the subscriber.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09311139&OS=09311139&RS=09311139
owner: Flexera Software LLC
number: 09311139
owner_city: Itasca
owner_country: US
publication_date: 20150529
---
At least one embodiment of this disclosure relates generally to batch processing scheduling and in particular methods and systems to schedule batch processing of oversubscribed systems based on subscriber usage patterns.

There is an increasing demand for automatic scheduling of batch processing tasks. In particular users of online services e.g. cloud based services or applications can submit large amounts of requests every day to the servers of the online services. The online services generally offer levels of service including soft or hard guarantees on when to finish the users tasks and to provide results to the users. However with an increasing number of subscribers signing up for an online service the current computational capacity of the online service may not be able to handle the submitted tasks within a planned time frame. In other words due to the cost control or system scalability limits the demands of the batch processing tasks exceed the available capacity of the service.

To alleviate the discrepancy between the capacity limitation of batch processing system and the increasing demand of batch processing tasks the disclosure provides a batch scheduling method to prioritize batch processing based on subscriber usage patterns. The goal of the scheduling method is to achieve soft guarantees for returning the processed results at least for some subscribers where hard guarantees of finishing the batch processing are not mandated.

Subscribers of the batch processing system also referred to as users can have various usage patterns. One subscriber may use the batch processing system on an hourly or daily basis while another subscriber may use the batch processing system once in a week or even a month. Active subscribers with frequent usage patterns are more likely to be negatively affected by delayed batch processing. On the other hand the inactive subscribers with infrequent usage patterns likely do not notice the delays. Therefore the batch processing system can prioritize the batch processing for the active subscribers without actual negative consequence to the inactive subscribers.

The batch processing system can implement multiple priority queues such as an overdue queue a recently used queue and a low priority queue. The overdue queue includes overdue batch processes that need immediate attention from the batch processing system. A batch process for a subscriber is determined to be overdue when the time elapsed since the last batch process commencement for the subscriber is more than an adjusted overdue threshold. The adjusted overdue threshold depends on a total time taken by the batch processing system to complete all batch processes of the last cycle and a limit factor determining how far batch processes in the overdue queue are allowed to lapse before being processed.

If the overdue queue is empty the batch processing system starts processing the batch processes in the recently used queue. The recently used queue includes batch processes for subscribers who have recently used the batch processing system. The usage event is recorded when the subscriber interacts with the batch processing system via a user interface provided by the batch processing system or when a background usage for the subscriber happens e.g. generating report on the background or making application programming interface API calls provided by the batch processing system. A batch process for a subscriber is moved into the recently used queue when the time period elapsed since the last usage by the subscriber is less than the time period elapsed since the last batch process commencement for the subscriber. In other words a batch process is determined to be in the recently used queue if the subscriber of the batch process has recently used the batch processing system after the system started processing the last batch process for the subscriber.

If the overdue queue and the recently used queue are empty the batch processing system starts processing batch processes from a low priority queue. The low priority queue includes batch processes that are not given priority for processing. In some embodiments the subscribers can also request the batch processing system to expedite their batch processes. In response to the requests the batch processing system moves the requested batch processes into an expedite queue. The batch processing system may first execute the batch processes in the expedite queue before handling other batch processes from the overdue queue the recently used queue and the low priority queue.

Such a scheduling method is particular useful for an oversubscribed system. Since many subscribers are inactive users who do not need to access the processed result frequently prioritizing the order in which batch processes are performed based on user usage allows the batch processing system to meet the desired result update frequency for the active subscribers that have been frequently using the batch processing system.

Some embodiments of this disclosure have other aspects elements features and steps in addition to or in place of what is described above. These potential additions and replacements are described throughout the rest of the specification

The figures depict various embodiments of this disclosure for purposes of illustration only. One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein.

The client systems A N may access the client interface module via network which can be a packet switched network for example a local area network LAN a wide area network WAN the Internet or any other type of network.

The client interface module can make some or all of computational capacity of the task scheduling and processing module available to the client systems A N. Similarly the client interface module can make some or all of the storage space on the mass storage devices A M available to the client systems A N. The client interface module can communicate with the client systems A N according to well known protocols e.g. the Hypertext Transfer Protocol HTTP .

The client interface module can present or export task results to the client systems A N through the NetApp in various ways. For example the client interface module can host a HTTP Hypertext Transfer Protocol web server. The client systems A N can use web browser applications to review or retrieve task results by accessing web pages hosted on the HTTP web server.

In various embodiments the task processing system can be a batch processing system that regularly performs extract transform and load ETL batch processing. The ETL batch processing task can take a significant amount of time and resources to complete. One example of such ETL batch processing system is a server or cloud based service that running FlexNet Manager Suite. FlexNet Manager is a trademark of Flexera Software LLC. The FlexNet Manager Suite is a solution for hardware and software assets management as well as software license compliance and optimization. Enterprise customers use the FlexNet Manager Suite to track the software and hardware assets within customers organizations and monitor their license consumption. The FlexNet Manager Suite can provide information regarding what license rights a customer is entitled to and what license rights the customer is actually using to support the client s organization.

In order to collect and analyze the information about the assets and licenses the FlexNet Manager Suite collects information about each device that is in a customer s organization data that relate to the hardware of the device data that relate to the software running on top of the device hardware. Such an ETL processing task involves extracting the information from different sources transforming the extracted information e.g. normalizing the information into a common format and then loading the transformed information into the system.

In order to facilitate the data movement and transformation the ETL process in first extracts data from one or more sources as illustrated in . Then the ETL process transforms the data by e.g. cleansing reformatting standardization aggregation or applying business rules. The ETL process loads the resulting data set into specific target systems. The ETL process may support massive parallel processing for large data volumes and is a reusable component that can be scheduled to perform data movement and processing jobs on a regular basis. Typically the ETL process is used for data movement across or within systems involving high data volumes and complex business rules such as bulk data integration flat file based and hierarchical transformations or high scale batch oriented data delivery. Multiple ETL processes can be grouped and executed together.

For example the FlexNet Manager Suite performs the ETL processes on a daily basis as batch processes. The users of the FlexNet Manager Suite interact with result data by using a web browser to access a web server interface of the FlexNet Manager Suite. With an increasing number of service subscribers e.g. tenants especially when the system is implemented as a cloud based service the system may have problems to handle all of the batch processing that ideally should be finished within a desired time frame. For example a cloud based FlexNet Manager Suite may desire to complete all batch processes every 24 hours for all subscribers. However due to the current task load and computational capacity limits the batch processes to extract transform and load for all subscribers may take more than 40 hours to finish.

To handle the discrepancy between the capacity limitation and the need of batch processing the system uses a scheduling method to prioritize batch processing based on subscriber usage patterns to achieve a soft guarantee where hard guarantees are not mandated.

Subscribers of a system may have different usage patterns across the full spectrum of hourly daily weekly or monthly time frames. Subscribers with frequent usage are more likely to be negatively affected by delayed batch processing whereas for infrequent users delays are likely to be unnoticed without actual negative consequence. For example some subscribers of FlexNet Manger may not use the system every single day. So prioritizing the order in which batch processes are performed based on usage will allow the system to meet the desired 24 hour update for the subscribers that have been actively using FlexNet Manager Suite.

Usage of the system includes e.g. interactive use of the service via a web browser user interface UI . However the usage may also include scheduled background tasks such as generating report at the background or making application programming interface API calls that are provided by the service.

DT is a desired maximum time since the last batch process commencement for a subscriber. In some embodiments the system specifies the metric DT for all subscribers. For example the FlexNet Manager Suite may specify the metric DT for all subscribers as 24 hours. In other words the FlexNet Manager Suite specifies the desired maximum time for each individual subscriber since the last batch process commencement for that individual subscriber is 24 hours. DT is a goal also referred to as soft target that the system prefers to achieve for as many subscribers as possible. The prioritization of batch processes ensures that most of the subscribers especially the active or frequent subscribers can have their batch processes finished within the time frame of DT.

In some embodiments the metric DT remain as a constant. In some other embodiments the system or the subscribers can change the value of DT during the scheduling.

By the definition of the metric TB the goal that the system tries to achieve is to keep the metric TB to be less than the time DT. In other words it is ideal for a subscriber if the time elapsed since the last batch process commencement for the subscriber is less than the desired maximum time since the last batch process commencement for the subscriber. However for an oversubscribed system with a large amount of active subscribers the total processing cycle time taken to complete all pending batch processing in a time cycle is going to be more than DT SUM DB DT. In some embodiments the total time in one time cycle is not a literal sum since batch processing can occur in parallel based on server capability.

In some embodiments where the system can process multiple batch processes simultaneously i.e. in parallel the metric SUM DB can have a slightly different meaning. In those situations the metric SUM DB may not be the literal summation of all metrics DB of the batch processes from the last cycle. The metric SUM DB can be the time from the commencement of the first batch process of the last cycle till the end of the last batch process of the last cycle regardless of whether there are batch processes running in parallel. If the system is able to get every batch processed done within the desired time frame because the system s server s have enough parallel processing power then the system may not need the priority scheduling since there is no danger of overdue. Therefore it is enough to record the actual total time for completing the batch processes of the last cycle as SUM DB .

The metric N is a limit factor determining how far overdue batch processes are allowed to go before being given priority for processing. The metric N is used to ensure that the batch processes are eventually performed even in the absence of recent subscriber usage of the system. In some embodiments N is specified to be larger than 1.0 for the scheduling method to be effective.

Larger values for the metric N will lead to improved responsiveness for active subscribers who recently have used the system at the expense of responsiveness for inactive subscribes without recent usage. However an N factor with a too large value will lead to starvation meaning the batch processes will wait for a long time before they will be identified as being overdue. In that scenario the system effectively has no priority control over the batch processes. If the N factor has a value that is too small the system has not opened up enough of a time window to be able to fit in enough subscribers that have recently used the system.

In some embodiments the N factor is a constant that the system determines for all subscribers. In some other embodiments the subscribers can specify the N factor for each individual subscriber. Alternatively the N factor can be adjusted as a way to adjust the levels of service for different subscribers.

In the horizontal axis represents the time dimension. The rectangles A A and B B represent the batch processes and the horizontal lengths of the rectangles A A and B B represent the time lengths used for the system to perform the corresponding batch processes respectively. For example the first rectangle is a batch process request by subscriber s the horizontal length of the rectangle represents the value of metric DB s .

The horizontal positions of the white dots represent the time points when the subscribers use the system by interactive usage or background usage . For example the white dot indicates that subscriber s uses the system at the end of a time period when the system processes the batch process . Similarly the white dot indicates that subscriber s uses the system at the middle of a time period when the system processes the batch process .

The horizontal position of the cross presents the time point when the subscriber s requests to expedite the batch process of subscriber s.

The dotted line represents a time period of the desired maximum time metric DT. The downward gull brace represents a time period of a total processing cycle time SUM DB . For the scenario without parallel processing as illustrated in SUM DB DB s DB s DB s DB s DB s . Since the system is oversubscribed SUM DB DT. As shown in the downward gull brace representing SUM DB is longer in time dimension than the dotted line representing DT.

The downward gull brace represents an adjusted overdue threshold. The adjusted overdue threshold equals the total processing cycle time SUM DB times the limit factor N N SUM DB . Since usually the value of N is larger than 1.0 the downward gull brace is longer than the downward gull brace in time dimension.

The horizontal positions of the black dots represent each time point when the system triggers a batch scheduler to make a scheduling decision based on four priority queues. The batch scheduler is illustrated in .

In the embodiment as illustrated in the system schedules the batch processing using four priority queues. The first priority queue i.e. the queue has the highest priority is the expedite queue . A subscriber of the system can specifically request e.g. via a web browser user interface a particular batch process to be expedited. Accordingly the system places the requested batch process in the expedite queue . The batch processes in the expedite queue will be handled with top priority.

The queue having the second highest priority is the overdue queue . The overdue queue includes overdue batch processes. A batch process for a subscriber is overdue if the metric TB for the subscriber is larger than the total processing cycle time SUM DB times the limit factor N TB N SUM DB . The N SUM DB is an adjusted overdue threshold. Once the threshold is passed the batch process is highlighted by being moved into the overdue queue . The tunable factor N is to determine how far the system allows subscribers batch processes to wait beyond a desired timeframe before the batch scheduler prioritizes the batch processes above average.

In some alternative embodiments the batch scheduler may treat the overdue queue as the top priority queue and the expedite queue as having the second highest priority. Especially in situation where there are lots of expedite requests the large amount of requests themselves can cause a starvation. The system needs to make sure that the expedite requests will not cause the majority of batch processes in the overdue queue lapse for a long time. Alternatively instead of swapping the priority order of the expedite queue and the overdue queue the batch scheduler may choose to run some batch processes from the overdue queue even when there are batch processes left in the expedite queue . For example the batch scheduler may choose to run an overdue batch process ignoring the priority order if the overdue batch process has been overdue for a predetermined threshold e.g. a value even larger than the adjusted overdue threshold N SUM DB .

The queue having the third highest priority is the recently used queue . The recently used queue includes batch processes of subscribers who recently have used the system. In other words the recently used queue includes batch processes of subscribers with TU

The queue having the lowest priority is called low priority queue in . The low priority queue includes batch processes of other subscribers that are not included in the other three queues and . The system only handles batch processes in the low priority queue when the other three priority queues are empty. The subscribers of batch processes in the low priority queue do not use the system regularly and likely do not notice whether the system delays the batch processing. The low priority queue ensures that even if a subscriber has not logged into the system or used the system recently the batch process of that subscriber will eventually run. In some embodiments the low priority queue has a cutoff period. Any batch process that has not been performed for a time period longer than the cutoff period will be moved into the expedite queue or overdue queue to have more attention from the batch scheduler .

The batch scheduler is triggered when each batch process is finished. As shown in . The black dots in represent the time points when the batch scheduler makes scheduling decisions. The batch scheduler identifies the next batch process based on the scheduling decisions and instructs the batch scheduler to perform the identified next batch process.

The batch scheduler can proceed to a sleep mode when the batch processor is handling the batch processes. Once the batch processor finishes the steps as in blocks and the batch processor notifies the batch scheduler . The batch scheduler wakes up from the sleep mode to trigger another scheduling decision.

At decision block the batch scheduler of the system first determines whether there are any expedite batch processes in the expedite queue . If there is no expedite batch processes in the expedite queue the batch scheduler moves to the next decision block . If there is one or more expedite batch processes in the expedite queue the batch scheduler identifies the oldest batch process left in the expedite queue . Then the batch scheduler instructs the batch processor to handle the identified batch process.

In response to the batch scheduler the batch processor at block records the current metric TB for the subscriber of the identified batch process i.e. the time elapsed since the last batch process commencement for the subscriber. At block the batch processor processes the identified batch process. After finishing the identified batch process at block the batch processor records the current metric DB for the subscriber of the just finished batch process i.e. the time duration of processing the just finished batch process. The metrics TB and DB for the subscriber are recorded for determine the priority queue for the next batch process requested by the subscriber. The metric DB is also used to calculate SUM DB for the next cycle.

At decision block the batch scheduler determines whether there are any overdue batch processes in the overdue queue . If there is no overdue batch processes in the overdue queue the batch scheduler moves to the next decision block . If there is one or more overdue batch processes in the overdue queue the batch scheduler identifies the oldest batch process left in the overdue queue . Then the batch scheduler instructs the batch processor to handle the identified batch process.

Similarly at decision block the batch scheduler determines whether there are any batch processes of subscribers who recently have used the system in the recently used queue . If there is no such batch processes in the recently used queue the batch scheduler moves to the next decision block . If there is one or more such batch processes in the overdue queue the batch scheduler identifies the oldest batch process left in the recently used queue . Then the batch scheduler instructs the batch processor to handle the identified batch process.

At decision block the batch scheduler determines whether there are any low priority batch processes in the low priority queue . If there is no low priority batch processes left in the low priority queue the batch scheduler proceeds to check if there is any newly submitted batch process. If there is one or more low priority batch processes in the low priority queue the batch scheduler identifies the oldest batch process left in the low priority queue . Then the batch scheduler instructs the batch processor to handle the identified batch process.

Turning back to which illustrates an example process using the four priority queues there are five subscribers in the example illustrated in . However there can be an arbitrary number of subscribers in other various embodiments. The white dots represent the time points when the subscribers use the system. Using the information of the time points of white dots the batch scheduler can re arrange batch processes in the four queues and therefore readjusts the priority of the batch processes.

If there is no batch scheduler the batch processes would not be prioritized. In that situation the system may perform the batches processes based on the sequence of the previous cycle as shown by the rectangles A A. Instead with the help of the batch scheduler the system ensures that a more important or urgent batch process will be handled in a prioritized manner.

For example at the time point of black dot the batch scheduler decides that the batch process B of s should be the next batch process to run because the subscriber s has requested to expedite the batch process at a previous time point represented by cross . After the batch processor finishes the batch process B for the subscriber s the batch scheduler needs to determine the next batch process to run.

Since there is no more batch process in the expedite queue the batch scheduler then looks into the overdue queue . After determining at this time point there is no batch process in the overdue queue whose TB N SUM DB the batch scheduler looks into the recently used queue . At the time point there are multiple batches processes of subscribers who recently used the system. The batch scheduler determines the batch process B of subscriber s is the oldest batch process in the recently used queue and decides to run the batch process B of subscriber s.

At the time point again the expedite queue and the overdue queue are empty. The next batch process in the recently used queue is the batch process B of subscriber s. The batch processes of subscribers s and s have just been processed. So the batch scheduler decides to run the batch process B of subscriber s.

Next at the time point the batch scheduler determines that there is an overdue batch process in the overdue queue TB s N SUM DB . The previous batch process of subscriber s is performed in the beginning of the last cycle as shown in . The time elapsed since last batch process commencement for subscriber s is more than the total cycle processing time times the factor N. Therefore the batch scheduler instructs the batch processor to perform the batch process B of subscriber s next.

Then at the time point the batch scheduler determines that subscriber s has again used the system at time point and the batch process of subscriber s is again the oldest batch process in the recently used queue . So the batch process B of subscriber s will run next.

At the time point the batch scheduler determines that the expedite queue the overdue queue and the recently used queue are empty. The batch scheduler then picks the batch process of subscriber s from the low priority queue and instructs the batch processor to perform the batch process B of subscriber s.

As shown in the usage patterns are important for the batch scheduler to make the scheduling decisions. A system with a large number of subscribers can collect usage patterns of the subscribers and identifies the inactive or infrequent subscribers based on the metrics of the subscribers. The inactive or infrequency subscribers are treated with lower priority like in . However the inactive or infrequent subscribers likely will not notice the difference due to their sparse usage patterns. This enables the system to focus on the more urgent tasks associated with active or frequent subscribers.

Note that although the example described above can involve scheduling batch processes for extract transform and load ETL tasks a person having ordinary skill in the art will readily appreciates that the prioritized scheduling method can be used to schedule processes or tasks other than ETL tasks in other embodiments.

The subscribers of the system can affect the scheduling prioritization decisions by various ways. For example a subscriber can explicitly request expediting the submitted batch process through the user interface. The subscriber can use the system more often by e.g. interacting with the system through the user interface or background usage such as generating a report in the background or utilizing APIs of the system. In some embodiments the subscribers may request to adjust the N factor as a way to adjust the level of service.

The system measures metrics internally and records e.g. how long it takes for the subscribers to have their batch processing data come in the batch process runs the DB duration of the last batch process the time elapse since the last process started TB etc. These metrics are for internal calculations within the system and are not subject to subscribers dictation.

In some alternative embodiments the N factor can be dynamically adjusted either by the batch scheduler or a subscriber. For example the batch scheduler can dynamically adjust the N factor on the fly based on the load situation. When the batch scheduler increases the value of the N factor the batch scheduler effectively increases the time window for allowing running the batch processes from the recently used queue to meet their DT target. On the other hand when the batch scheduler decreases the value of the N factor the batch scheduler may focus more on the overdue queue because the load situation of the system causes a large number of overdue batch processes.

One of ordinary skill in the relevant art will recognize that the terms machine readable storage medium or computer readable storage medium include any type of device that is accessible by the processor . The memory is coupled to the processor by for example a bus . The memory can include by way of example but not limitation random access memory RAM e.g. dynamic RAM DRAM and static RAM SRAM . The memory can be local remote or distributed.

The bus also couples the processor to the non volatile memory and drive unit . The non volatile memory may be a hard disk a magnetic optical disk an optical disk a read only memory ROM e.g. a CD ROM Erasable Programmable Read Only Memory EPROM or Electrically Erasable Programmable Read Only Memory EEPROM a magnetic or optical card or another form of storage for large amounts of data. The non volatile memory can be local remote or distributed.

The data structures modules and instruction steps described in the figures above may be stored in the non volatile memory the drive unit or the memory . The processor may execute one or more of the modules stored in the memory components.

The bus also couples the processor to the network interface . The network interface can include one or more of a modem or network interface. A modem or network interface can be considered to be part of the computer system . The network interface can include an Ethernet card a Bluetooth card an optical fiber interface a cable modem a token ring interface or other interfaces for coupling a computer system to other computer systems.

It is to be understood that embodiments may be used as or to support software programs or software modules executed upon some form of processing core e.g. the CPU of a computer or otherwise implemented or realized upon or within a machine or computer readable medium. A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine e.g. a computer. For example a machine readable medium includes read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other form of propagated signals for example carrier waves infrared signals digital signals etc. or any other type of media suitable for storing or transmitting information.

Some embodiments of the disclosure have other aspects elements features and steps in addition to or in place of what is described above. These potential additions and replacements are described throughout the rest of the specification.

