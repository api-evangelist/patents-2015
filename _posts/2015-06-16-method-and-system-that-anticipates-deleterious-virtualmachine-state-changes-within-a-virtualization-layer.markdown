---

title: Method and system that anticipates deleterious virtual-machine state changes within a virtualization layer
abstract: The current document is directed to a machine-learning-based subsystem, included within a virtualization layer, that learns, over time, how to accurately predict operational characteristics for the virtual machines executing within the virtual execution environment provided by the virtualization layer that result from changes to the states of the virtual machines. When the virtualization layer receives requests that, if satisfied, would result in a change of the state of one or more virtual machines, the virtualization layer uses operational characteristics predicted by the machine-learning-based subsystem from virtual-machine resource-allocation states that would obtain by satisfying the requests. When the predicted operational characteristics are indicative of potential non-optimality, instability, or unpredictability of virtualized-computer-system operation, the virtualization layer anticipates a deleterious state change and undertakes preventative measures.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09378044&OS=09378044&RS=09378044
owner: VMware, Inc.
number: 09378044
owner_city: Palo Alto
owner_country: US
publication_date: 20150616
---
Benefit is claimed under 35 U.S.C. 119 a d to Foreign application Serial No. 1611 CHE 2015 filed in India entitled METHOD AND SYSTEM THAT ANTICIPATES DELETERIOUS VIRTUAL MACHINE STATE CHANGES WITHIN A VIRTUALIZATION LAYER on Mar. 28 2015 by VMware Inc. which is herein incorporated in its entirety by reference for all purposes.

The current document is directed to virtualization layers and methods and in particular to a machine learning based virtualization layer subsystem that anticipates deleterious changes to the resource allocation states of one or more virtual machines executing within a virtual execution environment provided by the virtualization layer.

Virtualization layers including hypervisors provide virtual execution environments to virtual machines. A virtualization layer essentially provides a virtual machine interface above the hardware layer of a computer system. Among many functionalities provided by a virtualization layer a virtualization layer allocates hardware resources to virtual machines. For example a virtualization layer associates processes and threads running within a virtual machine with one or more hardware CPUs and schedules execution of the threads and processes on the assigned hardware CPUs in order to provide instruction execution bandwidth to the virtual machine. Similarly the virtualization layer allocates memory data storage and networking bandwidth to the virtual machines by partitioning memory data storage and computational resources among the virtual machines. When the aggregate demand for one or more computational resources made by the virtual machines does not exceed a threshold percentage of the computational resources available from the computer system hardware the virtualization layer can provide optimal or near optimal resource allocation on behalf of the virtual machines and the virtualized computer system can provide optimal or near optimal computational throughput to virtual machines and processes and threads executing within virtual machines. However when the aggregate demand for one or more computational resources approaches a threshold percentage of available hardware resources the computational throughput for the executing virtual machines may become sub optimal the computational throughput for individual virtual machines may become unpredictable and sub optimal and virtualized computer system operational characteristics may become unstable. Non optimal unpredictable and unstable behavior can be to some extent avoided by careful system monitoring and administration but system administrators designers manufacturers and vendors of virtualization layers and designers manufacturers and vendors of computer systems in general continue to seek methods and systems that are less prone to non optimal unpredictable and unstable operation.

The current document is directed to a machine learning based subsystem included within a virtualization layer that learns over time how to accurately predict operational characteristics for the virtual machines executing within the virtual execution environment provided by the virtualization layer that result from changes to the states of the virtual machines. When the virtualization layer receives requests that if satisfied would result in a change of the state of one or more virtual machines the virtualization layer uses operational characteristics predicted by the machine learning based subsystem from virtual machine resource allocation states that would obtain by satisfying the requests. When the predicted operational characteristics are indicative of potential non optimality instability or unpredictability of virtualized computer system operation the virtualization layer anticipates a deleterious state change and undertakes preventative measures.

The current document is directed to a machine learning based virtualization layer subsystem that anticipates deleterious virtual machine state changes so that the virtualization layer can forestall non optimal unstable and unpredictable virtualized computer system operation. In a first subsection below a brief overview of virtualization technologies is provided with reference to . A second subsection discusses resource allocation by a virtualization layer and resource allocation associated virtual machine states with reference to . In a final subsection the virtualization layer subsystem to which the current document is directed is described in detail with reference to .

Of course there are many different types of computer system architectures that differ from one another in the number of different memories including different types of hierarchical cache memories the number of processors and the connectivity of the processors with other system components the number of internal communications busses and serial links and in many other ways. However computer systems generally execute stored programs by fetching instructions from memory and executing the instructions in one or more processors. Computer systems include general purpose computer systems such as personal computers PCs various types of servers and workstations and higher end mainframe computers but may also include a plethora of various types of special purpose computing devices including data storage systems communications routers network nodes tablet computers and mobile telephones.

Until recently computational services were generally provided by computer systems and data centers purchased configured managed and maintained by service provider organizations. For example an e commerce retailer generally purchased configured managed and maintained a data center including numerous web servers back end computer systems and data storage systems for serving web pages to remote customers receiving orders through the web page interface processing the orders tracking completed orders and other myriad different tasks associated with an e commerce enterprise.

Cloud computing facilities are intended to provide computational bandwidth and data storage services much as utility companies provide electrical power and water to consumers. Cloud computing provides enormous advantages to small organizations without the resources to purchase manage and maintain in house data centers. Such organizations can dynamically add and delete virtual computer systems from their virtual data centers within public clouds in order to track computational bandwidth and data storage needs rather than purchasing sufficient computer systems within a physical data center to handle peak computational bandwidth and data storage demands. Moreover small organizations can completely avoid the overhead of maintaining and managing physical computer systems including hiring and periodically retraining information technology specialists and continuously paying for operating system and database management system upgrades. Furthermore cloud computing interfaces allow for easy and straightforward configuration of virtual computing facilities flexibility in the types of applications and operating systems that can be configured and other functionalities that are useful even for owners and administrators of private cloud computing facilities used by a single organization.

While the execution environments provided by operating systems have proved to be an enormously successful level of abstraction within computer systems the operating system provided level of abstraction is nonetheless associated with difficulties and challenges for developers and users of application programs and other higher level computational entities. One difficulty arises from the fact that there are many different operating systems that run within various different types of computer hardware. In many cases popular application programs and computational systems are developed to run on only a subset of the available operating systems and can therefore be executed within only a subset of the various different types of computer systems on which the operating systems are designed to run. Often even when an application program or other computational system is ported to additional operating systems the application program or other computational system can nonetheless run more efficiently on the operating systems for which the application program or other computational system was originally targeted. Another difficulty arises from the increasingly distributed nature of computer systems. Although distributed operating systems are the subject of considerable research and development efforts many of the popular operating systems are designed primarily for execution on a single computer system. In many cases it is difficult to move application programs in real time between the different computer systems of a distributed computer system for high availability fault tolerance and load balancing purposes. The problems are even greater in heterogeneous distributed computer systems which include different types of hardware and devices running different types of operating systems. Operating systems continue to evolve as a result of which certain older application programs and other computational entities may be incompatible with more recent versions of operating systems for which they are targeted creating compatibility issues that are particularly difficult to manage in large distributed systems.

For all of these reasons a higher level of abstraction referred to as the virtual machine has been developed and evolved to further abstract computer hardware in order to address many difficulties and challenges associated with traditional computing systems including the compatibility issues discussed above. illustrate two types of virtual machine and virtual machine execution environments. use the same illustration conventions as used in . Figure SA shows a first type of virtualization. The computer system in includes the same hardware layer as the hardware layer shown in . However rather than providing an operating system layer directly above the hardware layer as in the virtualized computing environment illustrated in features a virtualization layer that interfaces through a virtualization layer hardware layer interface equivalent to interface in to the hardware. The virtualization layer provides a hardware like interface to a number of virtual machines such as virtual machine executing above the virtualization layer in a virtual machine layer . Each virtual machine includes one or more application programs or other higher level computational entities packaged together with an operating system referred to as a guest operating system such as application and guest operating system packaged together within virtual machine . Each virtual machine is thus equivalent to the operating system layer and application program layer in the general purpose computer system shown in . Each guest operating system within a virtual machine interfaces to the virtualization layer interface rather than to the actual hardware interface . The virtualization layer partitions hardware resources into abstract virtual hardware layers to which each guest operating system within a virtual machine interfaces. The guest operating systems within the virtual machines in general are unaware of the virtualization layer and operate as if they were directly accessing a true hardware interface. The virtualization layer ensures that each of the virtual machines currently executing within the virtual environment receive a fair allocation of underlying hardware resources and that all virtual machines receive sufficient resources to progress in execution. The virtualization layer interface may differ for different guest operating systems. For example the virtualization layer is generally able to provide virtual hardware interfaces for a variety of different types of computer hardware. This allows as one example a virtual machine that includes a guest operating system designed for a particular computer architecture to run on hardware of a different architecture. The number of virtual machines need not be equal to the number of physical processors or even a multiple of the number of processors.

The virtualization layer includes a virtual machine monitor module VMM also referred to as a hypervisor that virtualizes physical processors in the hardware layer to create virtual processors on which each of the virtual machines executes. For execution efficiency the virtualization layer attempts to allow virtual machines to directly execute non privileged instructions and to directly access non privileged registers and memory. However when the guest operating system within a virtual machine accesses virtual privileged instructions virtual privileged registers and virtual privileged memory through the virtualization layer interface the accesses result in execution of virtualization layer code to simulate or emulate the privileged resources. The virtualization layer additionally includes a kernel module that manages memory communications and data storage machine resources on behalf of executing virtual machines VM kernel . The VM kernel for example maintains shadow page tables on each virtual machine so that hardware level virtual memory facilities can be used to process memory accesses. The VM kernel additionally includes routines that implement virtual communications and data storage devices as well as device drivers that directly control the operation of underlying hardware communications and data storage devices. Similarly the VM kernel virtualizes various other types of I O devices including keyboards optical disk drives and other such devices. The virtualization layer essentially schedules execution of virtual machines much like an operating system schedules execution of application programs so that the virtual machines each execute within a complete and fully functional virtual hardware layer.

In the layers are somewhat simplified for clarity of illustration. For example portions of the virtualization layer may reside within the host operating system kernel such as a specialized driver incorporated into the host operating system to facilitate hardware access by the virtualization layer.

It should be noted that virtual hardware layers virtualization layers and guest operating systems are all physical entities that are implemented by computer instructions stored in physical data storage devices including electronic memories mass storage devices optical disks magnetic disks and other such devices. The term virtual does not in any way imply that virtual hardware layers virtualization layers and guest operating systems are abstract or intangible. Virtual hardware layers virtualization layers and guest operating systems execute on physical processors of physical computer systems and control operation of the physical computer systems including operations that alter the physical states of physical devices including electronic memories and mass storage devices. They are as physical and tangible as any other component of a computer since such as power supplies controllers processors busses and data storage devices.

A virtual machine or virtual application described below is encapsulated within a data package for transmission distribution and loading into a virtual execution environment. One public standard for virtual machine encapsulation is referred to as the open virtualization format OVF . The OVF standard specifies a format for digitally encoding a virtual machine within one or more data files. illustrates an OVF package. An OVF package includes an OVF descriptor an OVF manifest an OVF certificate one or more disk image files and one or more resource files . The OVF package can be encoded and stored as a single file or as a set of files. The OVF descriptor is an XML document that includes a hierarchical set of elements each demarcated by a beginning tag and an ending tag. The outermost or highest level element is the envelope element demarcated by tags and . The next level element includes a reference element that includes references to all files that are part of the OVF package a disk section that contains meta information about all of the virtual disks included in the OVF package a networks section that includes meta information about all of the logical networks included in the OVF package and a collection of virtual machine configurations which further includes hardware descriptions of each virtual machine . There are many additional hierarchical levels and elements within a typical OVF descriptor. The OVF descriptor is thus a self describing XML file that describes the contents of an OVF package. The OVF manifest is a list of cryptographic hash function generated digests of the entire OVF package and of the various components of the OVF package. The OVF certificate is an authentication certificate that includes a digest of the manifest and that is cryptographically signed. Disk image files such as disk image file are digital encodings of the contents of virtual disks and resource files are digitally encoded content such as operating system images. A virtual machine or a collection of virtual machines encapsulated together within a virtual application can thus be digitally encoded as one or more files within an OVF package that can be transmitted distributed and loaded using well known tools for transmitting distributing and loading files. A virtual appliance is a software service that is delivered as a complete software stack installed within one or more virtual machines that is encoded within an OVF package.

The advent of virtual machines and virtual environments has alleviated many of the difficulties and challenges associated with traditional general purpose computing. Machine and operating system dependencies can be significantly reduced or entirely eliminated by packaging applications and operating systems together as virtual machines and virtual appliances that execute within virtual environments provided by virtualization layers running on many different types of computer hardware. A next level of abstraction referred to as virtual data centers or virtual infrastructure provide a data center interface to virtual data centers computationally constructed within physical data centers. illustrates virtual data centers provided as an abstraction of underlying physical data center hardware components. In a physical data center is shown below a virtual interface plane . The physical data center consists of a virtual data center management server and any of various different computers such as PCs on which a virtual data center management interface may be displayed to system administrators and other users. The physical data center additionally includes generally large numbers of server computers such as server computer that are coupled together by local area networks such as local area network that directly interconnects server computer and and a mass storage array . The physical data center shown in includes three local area networks and that each directly interconnects a bank of eight servers and a mass storage array. The individual server computers such as server computer each includes a virtualization layer and runs multiple virtual machines. Different physical data centers may include many different types of computers networks data storage systems and devices connected according to many different types of connection topologies. The virtual data center abstraction layer a logical abstraction layer shown by a plane in abstracts the physical data center to a virtual data center comprising one or more resource pools such as resource pools one or more virtual data stores such as virtual data stores and one or more virtual networks. In certain implementations the resource pools abstract banks of physical servers directly interconnected by a local area network.

The virtual data center management interface allows provisioning and launching of virtual machines with respect to resource pools virtual data stores and virtual networks so that virtual data center administrators need not be concerned with the identities of physical data center components used to execute particular virtual machines. Furthermore the virtual data center management server includes functionality to migrate running virtual machines from one physical server to another in order to optimally or near optimally manage resource allocation provide fault tolerance and high availability by migrating virtual machines to most effectively utilize underlying physical hardware resources to replace virtual machines disabled by physical hardware problems and failures and to ensure that multiple virtual machines supporting a high availability virtual appliance are executing on multiple physical computer systems so that the services provided by the virtual appliance are continuously accessible even when one of the multiple virtual appliances becomes compute bound data access bound suspends execution or fails. Thus the virtual data center layer of abstraction provides a virtual data center abstraction of physical data centers to simplify provisioning launching and maintenance of virtual machines and virtual appliances as well as to provide high level distributed functionalities that involve pooling the resources of individual physical servers and migrating virtual machines among physical servers to achieve load balancing fault tolerance and high availability.

The distributed services include a distributed resource scheduler that assigns virtual machines to execute within particular physical servers and that migrates virtual machines in order to most effectively make use of computational bandwidths data storage capacities and network capacities of the physical data center. The distributed services further include a high availability service that replicates and migrates virtual machines in order to ensure that virtual machines continue to execute despite problems and failures experienced by physical hardware components. The distributed services also include a live virtual machine migration service that temporarily halts execution of a virtual machine encapsulates the virtual machine in an OVF package transmits the OVF package to a different physical server and restarts the virtual machine on the different physical server from a virtual machine state recorded when execution of the virtual machine was halted. The distributed services also include a distributed backup service that provides centralized virtual machine backup and restore.

The core services provided by the VDC management server include host configuration virtual machine configuration virtual machine provisioning generation of virtual data center alarms and events ongoing event logging and statistics collection a task scheduler and a resource management module. Each physical server also includes a host agent virtual machine through which the virtualization layer can be accessed via a virtual infrastructure application programming interface API . This interface allows a remote administrator or user to manage an individual server through the infrastructure API. The virtual data center agents access virtualization layer server information through the host agents. The virtual data center agents are primarily responsible for offloading certain of the virtual data center management server functions specific to a particular physical server to that physical server. The virtual data center agents relay and enforce resource allocations made by the VDC management server relay virtual machine provisioning and configuration change commands to host agents monitor and collect performance statistics alarms and events communicated to the virtual data center agents by the local host agents through the interface API and to carry out other similar virtual data management tasks.

The virtual data center abstraction provides a convenient and efficient level of abstraction for exposing the computational resources of a cloud computing facility to cloud computing infrastructure users. A cloud director management server exposes virtual resources of a cloud computing facility to cloud computing infrastructure users. In addition the cloud director introduces a multi tenancy layer of abstraction which partitions VDCs into tenant associated VDCs that can each be allocated to a particular individual tenant or tenant organization both referred to as a tenant. A given tenant can be provided one or more tenant associated VDCs by a cloud director managing the multi tenancy layer of abstraction within a cloud computing facility. The cloud services interface in exposes a virtual data center management interface that abstracts the physical data center.

Considering the VDC server and cloud director layers of abstraction can be seen as discussed above to facilitate employment of the virtual data center concept within private and public clouds. However this level of abstraction does not fully facilitate aggregation of single tenant and multi tenant virtual data centers into heterogeneous or homogeneous aggregations of cloud computing facilities.

At the top of the instruction execution bandwidth utilized by each of the four virtual machines is plotted in plot with respect to time. In this plot for example the curve labeled by a circled number 1 corresponds to the instruction execution bandwidth currently utilized by the first virtual machine VM. This curve is explained by considering the demand for instruction execution bandwidth made by the first virtual machine at each of the discrete time points t t. For example at the first time point t the first virtual machine demands 1 GHz of instruction execution bandwidth. This is reflected in the height of curve above the t axis of plot at time t. At time point t the demand for instruction execution throughput by the first virtual machine has increased to 3.0 GHz . The height of curve above the x axis reflects additional instruction execution bandwidth allocated to VM as a result of VM s increased demand for instruction execution bandwidth. A similar analysis explains the shapes of the other three curves corresponding to the other three virtual machines. In plot the unlabeled upper curve represents the total instruction execution bandwidth utilized by the hypervisor and four virtual machines. These curves are idealized and do not include the variability in the fine grained instruction execution bandwidth utilization that would be observed in an actual system.

The instruction execution bandwidth utilization curves are steady and predictable up until time point t when a large increase in the demand for instruction execution bandwidth by the virtual machine seen by comparing the demand at time point t to the demand at time point t has resulted in the four virtual machines demanding an aggregate instruction execution bandwidth that exceeds the available instruction execution bandwidth provided by the hardware layer . At this point as can be seen by the erratic behavior of the utilization curves between time points tand t and by the dip in the total instruction execution bandwidth utilization curve in this same time period system behavior has become non optimal and the instruction execution throughput experienced by the virtual machines is relatively unpredictable. This non optimal system behavior and unpredictability in the instruction execution throughput experienced by the virtual machines is resolved when at time point t the demand for instruction execution bandwidth by the first virtual machine is reduced back to 6 GHz . Thus the non optimal system behavior and unpredictability in instruction execution throughput for the virtual machines is precipitated by the increase in demand for instruction execution bandwidth by the first virtual machine in the time interval t t. Non optimal system performance is undesirable but even more undesirable are the many system alarms that may be generated due to operational instabilities and sub optimal performance. These alarms may trigger a variety of computationally expensive responses and may need to be dealt with by human system administrators and other personnel. Incorrect diagnosis of the problem can in turn lead to further problems.

Had the hypervisor been able to anticipate the non optimal system behavior and unpredictable instruction execution throughput that ensued and the hypervisor may have been able to ameliorate the situation and prevent the instability and decrease in overall processor utilization by refusing the increased demand for instruction execution bandwidth by the first virtual machine or by an alternative VM execution scheduling that temporarily decreased the instruction execution bandwidth provided to the other virtual machines in order to temporarily service the increased demand by the first virtual machine. Amelioration of the system instability would have also prevented triggering of system alarms and many potentially expensive downstream affects of the triggering of those alarms.

The example shown in and discussed above is as stated a simple example to illustrate occurrence of non optimal system behavior and unpredictability in the instruction execution throughput and why anticipation of such behavior is desirable. In this case the fact that the demand for instruction execution bandwidth was approaching the available instruction execution bandwidth provided by the hardware layer might be detected by relatively straightforward resource allocation monitoring. However in many more complicated and less forward cases the approach of a system to critical points in system operation where non optimal system behavior is precipitated may not be detectable by simple monitoring techniques. As one example there are often scenarios in which conflicts between concurrently executing processes can lead to non optimal system behavior even though the aggregate demand for system recourses does not approach total resource capacity within the system. For example particular patterns of memory access by two concurrently executing processes may end up in a high virtual memory page replacement rate even though for most common workloads the amount of virtual memory being used by the two concurrently executing processes would be more than adequate. Any change in the number of concurrently executing VMs in the operational and configuration parameters for one or more VM in the operational and configuration parameters for the system as a whole may lead to difficult to foresee non optimal system behavior. The number of configuration and parameter states that may lead to such behaviors far exceeds the abilities of system designers to develop specific monitoring and detection mechanisms for recognizing them in order to anticipate non optimal system behavior.

Returning to the example illustrated in when in the time period t t the first VM requests an increase in instruction processing bandwidth from 6 GHz to 10 GHz the hypervisor constructs according to the currently disclosed approach a set of VM resource allocation state vectors reflective of the states of the VMs following satisfaction of the request inputs them to the machine learned model and receives the computational resource utilizations for each of the executing VMs. From these predicted computer resource utilizations the hypervisor can determine whether or not the ratio of the demand for one or more computational resources to the utilizations of the one or more computational resources for any of the VMs exceeds a threshold value and when the ratio is exceeded attempts to forestall the instabilities and non optimal behavior that would result were the request to be satisfied without additional action. The request may be denied in certain cases. In other cases the hypervisor may be able to shift computational resources from underutilizing VMs to a VM requesting additional computational resources at least on a temporary basis in order to satisfy the request without risking the deleterious effects that would obtain without computational resource shifting. In certain cases a hypervisor may be able to acquire additional computational resources from remote computer systems when the hypervisor runs within and is integrated with a distributed computer system. In other cases underutilization of one type of resource may provide an opportunity for satisfying excessive demands for another computational resource. For example when the instruction execution bandwidth is underutilized and the demand for memory becomes excessive the hypervisor may undertake operating system like paging in order to provide a larger virtual memory that can satisfy the memory demands by using underutilized instruction execution bandwidth to carry out the paging operations. The machine learning based subsystem provides utilization predictions that allow the hypervisor to anticipate excessive demand to utilization ratios for computational resources prior to satisfying requests for the computational resources.

A na ve approach to attempting to solve the problem illustrated in would be to develop deterministic logic that examines incoming requests to detect requests that were they to be satisfied would lead to non optimal system behavior or unpredictability in computational resource utilizations. Virtualized computer systems are however extremely complicated systems that are not fiasibly modeled analytically. Furthermore each virtualized computer system is very likely unique due to the many different types and variations of hardware components and the many different configurations for the hardware virtualization layer operating system and other levels of the many tiered virtualized computer system. Another na ve approach might be to attempt to build thresholds limits and constraints with respect to computational resource allocation into the hypervisor in order to prevent the hypervisor from satisfying demands for computational resources that would lead to non optimal behavior unpredictability and instability. However again virtualized computer systems are extremely complex and their operational characteristics difficult to predict and anticipate. Use of predetermined thresholds limits and constraints would likely result in unnecessarily conservative computational resource allocation and a general less than optimal computational throughput. By contrast the machine learning based virtualization layer subsystem continuously monitors and learns how changes in VM state affect VM computational resource utilizations for the particular virtualized computer system in which it executes. As a result the machine learning based virtualization layer subsystem allows a hypervisor to continuously allocate close to the maximum level of allocatable computational resources while being provided advance notice of problems that would ensue were a given request for resources to be satisfied.

In step the hypervisor inputs the normalized VM states into the machine learned model in and receives as output from the machine learned model utilization vectors for each VM indicating the predicted normalized utilizations by the VM of each of the various different computational resources in step . In step the hypervisor sets a local variable alarm to 0. In the nested for loops of steps the hypervisor checks the demand utilization ratio for each computational resource for each VM using the predicted utilizations returned by the machine learned model in step . When the ratio exceeds a threshold value for a particular computational resource and VM as determined in step the hypervisor records an indication of the VM resource and demand utilization ratio and increments the local variable alarm in step . When following execution of the nested for loops local variable alarm stores a value greater than 0 as determined in step the hypervisor uses the information about the VMs resources and demand utilization ratios recorded in step to determine what ameliorative steps to take in order to prevent non optimal system behavior unpredictabilities and instabilities in step and then carries out the ameliorative steps in step . When the hypervisor in responding to the request changes the states of one or more VMs the hypervisor generates a new set of current VM states in step . When no problems with the input request are detected or following steps and when problems are detected the hypervisor calls an asynchronous feedback routine in step to provide feedback to the machine learned model with regard to the accuracy of the predictions made by the model in step .

There are many different types of machine learning systems that may be incorporated within a virtualization layer to provide computer resource utilization predictions. In one implementation a neural network is employed to learn the characteristics of the virtualized computer system in which the neural network is included as a subsystem and to provide predictions of computer resource utilizations based on input VM resource allocation state vectors. illustrates general characteristics of a neural network implementation of the machine learned model included within a virtualization layer. As discussed above input to the neural network comprises a set of VM resource allocation state vectors such as VM resource allocation state vector . For each input VM resource allocation state vector a corresponding computation resource utilization vector is output. In one implementation a set of VM resource allocation state vectors is concatenated together to form a single input vector that is input to the neural network which outputs a single computational resource utilization vector that includes computational resource utilization subvectors for each VM. Thus the ellipses in such as ellipsis indicate that only a portion of the inputs outputs and internal structures of the neural network are shown. In one implementation each element in each VM resource allocation state vector input to the neural network is submitted to a different neural network input level node. For example the first element in VM resource allocation state vector is input to neural network input level node . The layer of neural network nodes represented by column in to which elements of VM resource allocation state vectors are input form a first layer or first level of neural network nodes within the neural network. A neural network may have an arbitrary number of neural network node levels and an arbitrary pattern of inter node links as indicated in by the sets of ellipses between the input level and output level nodes such as sets of ellipses and . The neural network has a final set of neural network nodes represented in by column that each outputs a value to a single element of an output computational resource utilization vector. For example the output level node outputs element of computational resource utilization vector .

In an implementation subsequently described with reference to n VM resource allocation state vectors are concatenated together to form a single input vector to the neural network each element of which is directed to each input level node within the neural network. The neural network produces a final output vector comprising n corresponding computational resource utilization vectors. In the neural network instantiated in the example the neural network includes two layers of neural network nodes. The nodes of the input layer each receive as inputs the elements of the input vector. The nodes of the output layer each receive outputs from the nodes of the input layer and each produces an output that corresponds to one element of the output vector. However the implementation can be configured to have an arbitrary number of layers with arbitrary linkages between nodes and input and output vector elements. In the described implementation in order to accommodate a varying number of executing VMs within the execution environment provided by the virtualization layer a very large number n of VM resource allocation state vectors are concatenated together to produce a very large input vector for the neural network. In general only a portion of the subvectors within the input vector correspond to executing VMs. The remaining subvectors have zero valued elements. In alternative implementations a variety of neural network instantiations with different numbers of input level and output level nodes are maintained within the virtualization layer subsystem so that there is a separate learned model for each different number of executing VMs or for each different small range of numbers of executing VMs to provide greater precision of prediction based on the number of VMs currently executing in the execution environment provided by the virtualization layer. In yet alternative implementations connectivity between the input and output vectors and the neural network nodes may be changed to accommodate different input output vector sizes.

In a learning process differences are computed between the predicted utilization values and the actual observed utilization values following system stabilization and those differences are fed back into the neural network from output level nodes to input level nodes in reverse order from generation of output vectors from input vectors by the neural network. During the feedback process the weights associated with input links W Ware modified proportionally to the computed differences between the observed utilizations and predicted utilizations in order to adjust the function computed by the neural network. As mentioned above in certain implementations the pattern of linkages between neural network nodes and the number of node levels may also be altered in order to adjust the function computed by the neural network.

A first class declaration is provided for the class configuration. An instance of this class defines the neural network that is created and configured to implement the function . The configuration for a neural network is specified by a number of parameters input to a constructor for the class. These include 1 numIV the number of input VM resource allocation status vectors 2 iVSize the size of each VM resource allocation status vector 3 numOV the number of output computational resource utilization vectors 4 oVSize the size of each computational resource utilization vector 5 map a formatted character string that lays out the linkage pattern of the neutral net including inputs to each input node outputs from each node to nodes of successive layers and outputs of output nodes to elements of the computational resource utilization vector elements. illustrates creation of a map for an example neural network within a main routine. The inputs for each node are listed in order in substrings separated by the value 1. The descriptions of nodes for each layer of nodes are separated by the value 2. Of course there are many ways for specifying the size and configuration of a neural network.

An instance of the class configuration parses the configuration map to produce an accessible configuration description that can be used by subsequently discussed class instances to implement a neural network. An instance of the class configuration includes private data members that store the number of input VM resource allocation status vectors the VM status vector size the number of computational resource utilization output vectors the size of each output vector the number of node levels in the neural network the number of nodes in each level of the neural network offsets to a description of the nodes in the map for each level and a pointer to the configuration map . The member functions provide information about the configuration of the neural network. A pair of member functions provide by successive calls the inputs for each node at each level of the neural network. The number of inputs for a given node of a given level is returned by the function getNumInputs . The number of forward pointers emanating from a given node of a given level is returned by the function getNumberOfForwardPointersFrom .

There are of course many different possible ways to implement a neural network that is suitable for use as a machine learned model in a virtualization layer subsystem to which the current document is directed. The above described implementation is provided to simply illustrate how a neural network is constructed and how neural network nodes operate. More concise implementations can be obtained by using more complex language features including class inheritance iterators virtual functions and templates. The above described implementation omits destructors error detection and handling and the many other functionalities that would be included in a commercial implementation.

While neural networks represents one type of machine learning technology there are other types of machine learning technologies that can be used to implement a computational resource utilization prediction function for use in a virtualization layer subsystem. As discussed above a machine learning based model is used because deterministic logic based methods are impractical due to the complexity and uniqueness of virtualized computer systems and analytically derived attempts to include thresholds limits and constraints in the virtualization layer to prevent non optimal system behaviors unpredictabilities and instabilities would generally need to be far too conservative to provide for optimal or near optimal virtualized computer system operation. In fact it is likely to be as infeasible to design such constraints and limits into a virtualization layer as it would be to devise deterministic logic to predict when such non optimal behavior unpredictabilities and instabilities might occur during virtualization layer optimization. Furthermore a machine learning based subsystem can continuously monitor and change the function as the virtualized computer system changes dues to hardware additions and deletions reconfiguration and other changes in the computational environment of the virtualized computer system.

Although the present invention has been described in terms of particular embodiments it is not intended that the invention be limited to these embodiments. Modifications within the spirit of the invention will be apparent to those skilled in the art. For example as discussed above a virtualization layer subsystem that predicts computational resource utilizations for VMs executing within the execution environment provided by the virtualization layer can employ any of many different machine learning based prediction subsystems for each of which there are many alternative implementations that can be obtained by varying any of many different design and implementation parameters including programming language operating system modular organization data structures control structures and other such design and implementation parameters. Virtual machine resource allocation states can be expressed by many different types of input vectors with subvectors describing various different types of computational resources. In certain cases only one or a utilizations are predicted for one or a few different types of computational resources while in other implementations the number of predicted utilizations may be greater. While computational resource utilizations provide a basis for determining potential onset of non optimal system behavior unpredictabilities and instabilities other predicted values related to operational characteristics of a virtualized computer system may alternatively be used in alternate implementations of the virtualized layer subsystem. In the implementation discussed in the hypervisor continuously trains the machine learned model. In alternative implementations the virtualization layer may collect pairs of input vectors and observed utilizations over time and carry out discrete learning sessions based on the collected data. In the neural network implementation discussed above with reference to the neural network nodes are initially configured with small arbitrary weights. Alternatively the neural network employed within the virtualization layer may be initially configured with a set of reasonable weights derived for similarly deployed virtualization layers based on past observations.

It is appreciated that the previous description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the present disclosure. Various modifications to these embodiments will be readily apparent to those skilled in the art and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the disclosure. Thus the present disclosure is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.

