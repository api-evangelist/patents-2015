---

title: In-memory buffer service
abstract: A capture service running on an application server receives events from a client application running on an application server to be stored in a data store and stores the events in an in-memory bounded buffer on the application server, the in-memory bounded buffer comprising a plurality of single-threaded segments, the capture service to write events to each segment in parallel. The in-memory bounded buffer provides a notification to a buffer flush regulator when a number of events stored in the in-memory bounded buffer reaches a predefined limit. The in-memory bounded buffer receive a request to flush the events in the in-memory bounded buffer from a consumer executor service. The consumer executor service consumes the events in the in-memory bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel, wherein consuming the events comprises writing the events directly to the data store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09417840&OS=09417840&RS=09417840
owner: salesforce.com, inc.
number: 09417840
owner_city: San Francisco
owner_country: US
publication_date: 20150506
---
This application claims the benefit of U.S. Provisional Application No. 62 051 107 filed Sep. 16 2014 the entire contents of which are hereby incorporated by reference herein.

This disclosure relates to the field of multi tenant server operation and in particular to an in memory buffer service for a server.

A data buffer is a region of a physical memory storage used to temporarily store data while it is being moved from one place to another. In an application server implementing a data buffer data objects may be stored in a buffer as they are retrieved from a client device or application before they are processed or sent elsewhere for more permanent storage. Buffers can be implemented in a fixed memory location in hardware or by using a virtual data buffer in software pointing at a location in the physical memory. Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed or in the case where these rates are variable. A buffer can be used to adjust timing by implementing a queue algorithm in memory simultaneously writing data into the queue at one rate and reading it at another rate.

Embodiments are described for an in memory buffer service. In certain high volume event systems it may be beneficial to ingest and process events as quickly and efficient as possible i.e. in real time . Depending on the implementation this may include ingesting processing and persisting potentially millions of events over the span of an hour or billions of events over the span of a week. For instance a certain system may store up to a week s worth of details from sets of operations that are executed as a single unit e.g. Apex transactions in an open source non relational distributed database such as Apache HBase or other data store. This may be accomplished by pointing a debug log event handler that supplies limit usage information or any other program or component that generates a high volume of events or other data elements to the data store. In other embodiments some other data store may be used such as a NoSQL database a non opensource database a relational database a non distributed database or other type of data store.

In an implementation that averages 7.3 billion Apex executions per month or 243 million per day being stored in the data store storing one row per transaction limit with 8 types of limits would require storing 58.4 billion rows per month or about 1.8 billion rows per day across an entire service. Thus if only raw event data were kept around for a week that would require 13.1 billion rows at a time before being deleted. In other implementations there may be up to 15 types of limits which would result in even more rows being stored. This high volume situation could benefit significantly from a new way for handling event data at scale with high throughput.

In one embodiment an in memory buffer service running on a multi tenant application server provides a low latency application program interface API that writes objects such as event records to the data store. In other embodiments the application server may not server multiple clients but rather is utilized by a single client that generates significant a volume of event data. The in memory buffer service provides a store and forward based service for data objects where those objects e.g. events are temporarily stored in an in memory bounded buffer before being forward to a data store for longer term storage. A capture service can store events in a bounded buffer where they may be kept in memory until the number of objects reaches a predefined limit or the events have been in memory for a predetermined period of time e.g. 5 seconds 10 seconds 30 seconds 1 minute etc. . The in memory buffer provides a very low latency API to write objects and can be done very quickly. For instance in some examples writing the bounded buffer can be done in as little as 0.08 microseconds.

The in memory buffer may be responsible for supporting a concurrently writable API which enables the storing of events in memory and manages flushing of the buffer. In some embodiments the in memory buffer may include a plurality of buffer segments where each segment is single threaded. Each segment can support high read consistency by waiting until all or most write threads are complete before read threads are initiated. Thus each segment may only be read once. Additionally the concurrent bounded buffer comprised of segments may be used to store events concurrently from various threads. The bounded buffer may also maintain a notion of load factor and may support two types of overflow policies. For example a buffer flush may be initiated when the buffer load reaches some predefined limit e.g. 80 capacity . In some embodiments the bounded buffer keeps the latest object by replacing an oldest object with a recent object i.e. first in first out . In another embodiment the bounded buffer drops the latest object if the buffer is full. A buffer flush regulator may further be used to regulate the flushing of the buffer. The regulating may be based on size and time which will queue up the event for consumption and writing to the data store. For example the concurrent bounded buffer may provide a notification when the number of objects reaches a predefined limit that triggers buffer flushing.

Additionally a consumer executor service is responsible for consuming the in memory buffer and uses a dynamically sized thread pool to consume i.e. process the objects in parallel fashion in order to maximize throughput. The consumer executor service may include a service thread that initiates automatic restarts if a main thread is interrupted. The extension may also include an asynchronous API for starting and stopping a thread. The service thread further may use in one implementation Java s ThreadPool to get worker to run the consumer tasks concurrently and in a reliable manner. The service thread also may iteratively call blockedGetAndReset API of the buffer and may assign a set of data to the consumer task. The consumer task may be eventually run by the ThreadPool s worker thread.

A consumer factory of the consumer executor service allows a user to customize a consumer task. A consumer task may first try to write to the data store e.g. HBase Bigtable MongoDB etc. directly in a given time in order to reduce the load on a message queue MQ and to make data available instantaneously. If writing to the data store fails however the consumer task may enqueue objects in the MQ which eventually writes the objects to the data store via an MQ Handler. In some embodiments a shutdown hook is used to close the service properly when a shutdown of the application server is requested. A log of statistics may also be kept and the consumer executor service may be restarted if it was terminated for unknown reasons.

Each of client devices may be for example a personal computer PC workstation laptop computer tablet computer mobile phone smartphone personal digital assistant PDA or the like. Client devices may communicate with application server to access resources on application server such as client application . For example a user may access client application through a web browser or other HTTP client application on the client device.

In one embodiment application server may be any computing device such as computing system described below with respect to . In one embodiment application server may be a multi tenant application server designed to provide access to a number of client applications such as client application to one more client devices such as client devices . In another embodiment application server may be a single tenant application server design to service a single client. Client application and other resources provided by application server such as processing resources storage resources etc. may be maintained by application server and made available to the users of client devices as needed i.e. on demand . This application server can include various elements of hardware and software of a database system may be shared by one or more customers or tenants. For example application server may simultaneously process requests for a great number of customers. Application server may include an application platform including a framework that allows the applications to execute such as the hardware or software infrastructure of the system. In one embodiment the application platform enables the creation management and execution of one or more applications such as client application developed by the provider of the application server customers accessing the application server via client devices or third party application developers.

In one embodiment application server includes in memory buffer service . In memory buffer service can ingest and process events generated by client application buffer those events and eventually store the events in data store . In one embodiment data store provides an application programming interface API which can be called by the in memory buffer service in order to store the events in data store . In one embodiment data store may be an open source non relational distributed database such as Apache HBase Bigtable MongoDB or other data store. Examples of events generated by client application may include errors exceptions faults failures crashes incidents or other occurrences. For example client application may include a user interface layer that presents a user interface visible on one of client devices . Through selection of a user interface element the user may initiate some processing operation in a logical layer of the client application that hits some hard limit defined by the application server e.g. number of processing cycles consumed per day amount of storage resources consumed and page rendering is stopped. The reaching of this hard limit may trigger the creation of an event by client application which is recorded for possible future review. The volume at which such events are potentially generated and conventional means for recording and storing these events may result in an unacceptable level of latency. As such in one embodiment in memory buffer service can ingest and process the events buffer the events and eventually store the events in data store . The buffering of the events in memory before storage in data store can allow a high volume of events to be processed in near real time with minimal latency and without adversely affecting performance of the application server or client application . Additional details of the in memory buffer service are provided below.

Client application may be any type of computer application program that generates events. For example client application may be an entertainment application productivity application business application social networking application or other types of application. In one embodiment in memory buffer processes events for storage in data store . In other embodiments in memory buffer may process any other type of data object for storage in data store or elsewhere. In one embodiment a capture service running on application server receives events from client application that are to be stored in data store . Capture service temporarily stores the received events in bounded buffer . The bounded buffer may include a plurality of single threaded segments to which the capture service can write the events in parallel. In one embodiment bounded buffer may include 16 single threaded segments each of which can be written in parallel with a different event generated by client application . The size of bounded buffer is configurable according to the particular implementation. In one embodiment the buffer size may be approximately 10 megabytes MB to 20 MB. In other embodiments the buffer may have a different size such as 1 MB 50 100 MB 1 terabyte TB etc. .

In one embodiment in memory buffer service further includes a buffer flush regulator . Buffer flush regulator controls when bounded buffer is emptied i.e. flushed for consumption by consumer executor service and storage in data store . In one embodiment logic associated with bounded buffer monitors the load on bounded buffer and provides a notification to the buffer flush regulator when the number of events stored in the bounded buffer reaches a predefined limit e.g. 80 full or when a predefined amount of time has passed since a contents of the bounded buffer was written to data store e.g. 10 seconds . In one embodiment consumer executor service periodically sends a request for buffer flushing to buffer flush regulator . Buffer flush regulator determines whether a notification has been received from bounded buffer indicating that either the predefined size limit or the predefined time limit has been reached. If not buffer flush regulator denies the request. If the notification has been received buffer flush regulator grants the request and consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. By consuming the events consumer executor service reads the events from bounded buffer and writes the events to data store .

In some situations all of the segments of bounded buffer may be filled with events and new events are received by capture service before buffer flush regulator can empty the contents of bounded buffer . Bounded buffer may handle this situation in a number of different ways according to a defined overflow policy. In one embodiment bounded buffer may implement a keep latest overflow policy where the oldest event in bounded buffer is overwritten with the newly received event from client application . In another embodiment bounded buffer may implement a drop latest overflow policy where the newly received event is prevented from being stored in bounded buffer .

In one embodiment in memory buffer service further includes buffer flush regulator . Buffer flush regulator controls when bounded buffer is emptied i.e. flushed for consumption by consumer executor service and storage in data store . In one embodiment in memory buffer service monitors the load on the buffer segments and provides a notification to the buffer flush regulator when a certain portion or percentage of the buffer segments are full e.g. 80 full or when a predefined amount of time has passed since a contents of the buffer segments were flushed e.g. 10 seconds . In one embodiment a main service thread in consumer executor service may periodically send a request for buffer flushing to buffer flush regulator . Buffer flush regulator may determine whether a notification has been received from bounded buffer indicating that either the predefined size limit or the predefined time limit have been reached. If not buffer flush regulator denies the request. If the notification has been received buffer flush regulator grants the request and consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. Dynamically sized thread pool can add or remove consumer threads so that the number of consumer threads matches the number of buffer segments being consumed. For example if all 16 segments are being read dynamically sized thread pool can have 16 consumer threads . If however only 10 buffer segments contain events then thread pool need only include 10 threads . The consumer threads read the events from buffer segments in parallel and write the events to data store .

Under normal operation the threads of the dynamically sized thread pool in consumer executor service may write the events read from either bounded buffer or bounded buffer directly to data store . Depending on the implementation however the data store may be a distributed system and possibly take a significant period of time to be written. In such a case or if all or a portion of the data store is temporarily unavailable consumer executor service may enqueue the events from the bounded buffer or in a message queue for subsequent writing to data store after data store becomes available. In one embodiment consumer executor service may first try to write directly to data store but if data store does not respond within some period of time message queue may be utilized. Message queue may be any available in memory or out of memory data structure that can temporarily accommodate the events before they are stored in data store . In one embodiment message queue may be large enough to store the contents of one bounded buffer at a time. In another embodiment message queue may be large enough to store the contents of multiple buffers concurrently.

Referring to at block method receives events from client application . In one embodiment a capture service running on application server receives events from client application that are to be stored in data store . In another embodiment capture service may receive generic data objects from some other source for in memory buffering.

At block method determines whether in memory bounded buffer is full. In one embodiment bounded buffer may include single threaded segments each of which can be written in parallel with a different event generated by client application . In one embodiment in memory buffer service determines whether each of the buffer segments has been written with an event. If each segment contains an event then in memory buffer service determines that the bounded buffer is full. If there are one or more segments of the bounded buffer that do not contain events then in memory buffer service determines that the bounded buffer is not full.

If in memory bounded buffer is not full at block method stores the received events in the in memory bounded buffer . In one embodiment capture service writes the received events to one or more of the segments of in memory bounded buffer in parallel.

If in memory bounded buffer is full at block method applies a buffer overflow policy prior to storing the events. In one embodiment bounded buffer may implement a keep latest overflow policy where the oldest event in bounded buffer is overwritten with the newly received event from client application . In another embodiment bounded buffer may implement a drop latest overflow policy where the newly received event is prevented from being stored in bounded buffer .

At block method determines if a predefined limit has been reached. In one embodiment in memory buffer service monitors the load on bounded buffer and determines when the number of events stored in the bounded buffer reaches a predefined limit e.g. 80 full or when a predefined amount of time has passed since a contents of the bounded buffer was written to data store e.g. 10 seconds . If the predefined limit has been reached at block method provides a notification to buffer flush regulator . In one embodiment in memory buffer service provides the notification to buffer flush regulator .

At block method receives a buffer flush request from consumer executor service . In one embodiment consumer executor service may periodically send a request for buffer flushing to buffer flush regulator . The period with which the request is sent can be configurable depending on the particular implementation.

At block method determines whether the in memory bounded buffer is ready to be flushed. Buffer flush regulator may determine whether a notification has been received from bounded buffer at block indicating that either the predefined size limit or the predefined time limit have been reached. If not buffer flush regulator denies the request.

If the in memory bounded buffer is ready to be flushed at block method determines whether the data store is available. Depending on the implementation the data store may be a distributed system and possibly take a significant period of time to be written. In such a case all or a portion of the data store may be temporarily unavailable.

If the data store is available at block method consumes the events from the in memory bounded buffer by writing the events directly to the data store . In one embodiment consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. By consuming the events consumer executor service reads the events from bounded buffer and writes the events to data store .

If the data store is not available at block method enqueues the events from in memory bounded buffer in a message queue for subsequent writing to the data store after the data store becomes available. Message queue may be any available in memory or out of memory data structure that can temporarily accommodate the events before they are stored in data store . In one embodiment message queue may be large enough to store the contents of one bounded buffer at a time. In another embodiment message queue may be large enough to store the contents of multiple buffers concurrently.

The following description is of one example of a system in which the features described above may be implemented. The components of the system described below are merely one example and should not be construed as limiting. The features described above with respect to may be implemented in any other type of computing environment such as one with multiple servers one with a single server a multi tenant server environment a single tenant server environment or some combination of the above.

In some implementations the environment is an environment in which an on demand database service exists. An on demand database service such as that which can be implemented using the system is a service that is made available to users outside of the enterprise s that own maintain or provide access to the system . As described above such users generally do not need to be concerned with building or maintaining the system . Instead resources provided by the system may be available for such users use when the users need services provided by the system that is on the demand of the users. Some on demand database services can store information from one or more tenants into tables of a common database image to form a multi tenant database system MTS . The term multi tenant database system can refer to those systems in which various elements of hardware and software of a database system may be shared by one or more customers or tenants. For example a given application server may simultaneously process requests for a great number of customers and a given database table may store rows of data such as feed items for a potentially much greater number of customers. A database image can include one or more database objects. A relational database management system RDBMS or the equivalent can execute storage and retrieval of information against the database object s .

Application platform can be a framework that allows the applications of system to execute such as the hardware or software infrastructure of the system . In some implementations the application platform enables the creation management and execution of one or more applications developed by the provider of the on demand database service users accessing the on demand database service via user systems or third party application developers accessing the on demand database service via user systems .

In some implementations the system implements a web based customer relationship management CRM system. For example in some such implementations the system includes application servers configured to implement and execute CRM software applications as well as provide related data code forms renderable web pages and documents and other information to and from user systems and to store to and retrieve from a database system related data objects and Web page content. In some MTS implementations data for multiple tenants may be stored in the same physical database object in tenant database . In some such implementations tenant data is arranged in the storage medium s of tenant database so that data of one tenant is kept logically separate from that of other tenants so that one tenant does not have access to another tenant s data unless such data is expressly shared. The system also implements applications other than or in addition to a CRM application. For example the system can provide tenant access to multiple hosted standard and custom applications including a CRM application. User or third party developer applications which may or may not include CRM may be supported by the application platform . The application platform manages the creation and storage of the applications into one or more database objects and the execution of the applications in one or more virtual machines in the process space of the system .

According to some implementations each system is configured to provide web pages forms applications data and media content to user client systems to support the access by user systems as tenants of system . As such system provides security mechanisms to keep each tenant s data separate unless the data is shared. If more than one MTS is used they may be located in close proximity to one another for example in a server farm located in a single building or campus or they may be distributed at locations remote from one another for example one or more servers located in city A and one or more servers located in city B . As used herein each MTS could include one or more logically or physically connected servers distributed locally or across one or more geographic locations. Additionally the term server is meant to refer to a computing device or system including processing hardware and process space s an associated storage medium such as a memory device or database and in some instances a database application for example OODBMS or RDBMS as is well known in the art. It should also be understood that server system and server are often used interchangeably herein. Similarly the database objects described herein can be implemented as part of a single database a distributed database a collection of distributed databases a database with redundant online or offline backups or other redundancies etc. and can include a distributed database or storage network and associated processing intelligence.

The network can be or include any network or combination of networks of systems or devices that communicate with one another. For example the network can be or include any one or any combination of a LAN local area network WAN wide area network telephone network wireless network cellular network point to point network star network token ring network hub network or other appropriate configuration. The network can include a TCP IP Transfer Control Protocol and Internet Protocol network such as the global internetwork of networks often referred to as the Internet with a capital I . The Internet will be used in many of the examples herein. However it should be understood that the networks that the disclosed implementations can use are not so limited although TCP IP is a frequently implemented protocol.

The user systems can communicate with system using TCP IP and at a higher network level other common Internet protocols to communicate such as HTTP FTP AFS WAP etc. In an example where HTTP is used each user system can include an HTTP client commonly referred to as a web browser or simply a browser for sending and receiving HTTP signals to and from an HTTP server of the system . Such an HTTP server can be implemented as the sole network interface between the system and the network but other techniques can be used in addition to or instead of these techniques. In some implementations the network interface between the system and the network includes load sharing functionality such as round robin HTTP request distributors to balance loads and distribute incoming HTTP requests evenly over a number of servers. In MTS implementations each of the servers can have access to the MTS data however other alternative configurations may be used instead.

The user systems can be implemented as any computing device s or other data processing apparatus or systems usable by users to access the database system . For example any of user systems can be a desktop computer a work station a laptop computer a tablet computer a handheld computing device a mobile cellular phone for example a smartphone or any other Wi Fi enabled device wireless access protocol WAP enabled device or other computing device capable of interfacing directly or indirectly to the Internet or other network. The terms user system and computing device are used interchangeably herein with one another and with the term computer. As described above each user system typically executes an HTTP client for example a web browsing or simply browsing program such as a web browser based on the WebKit platform Microsoft s Internet Explorer browser Netscape s Navigator browser Opera s browser Mozilla s Firefox browser or a WAP enabled browser in the case of a cellular phone PDA or other wireless device or the like allowing a user for example a subscriber of on demand services provided by the system of the user system to access process and view information pages and applications available to it from the system over the network .

Each user system also typically includes one or more user input devices such as a keyboard a mouse a trackball a touch pad a touch screen a pen or stylus or the like for interacting with a graphical user interface GUI provided by the browser on a display for example a monitor screen liquid crystal display LCD light emitting diode LED display among other possibilities of the user system in conjunction with pages forms applications and other information provided by the system or other systems or servers. For example the user interface device can be used to access data and applications hosted by system and to perform searches on stored data and otherwise allow a user to interact with various GUI pages that may be presented to a user. As discussed above implementations are suitable for use with the Internet although other networks can be used instead of or in addition to the Internet such as an intranet an extranet a virtual private network VPN a non TCP IP based network any LAN or WAN or the like.

The users of user systems may differ in their respective capacities and the capacity of a particular user system can be entirely determined by permissions permission levels for the current user of such user system. For example where a salesperson is using a particular user system to interact with the system that user system can have the capacities allotted to the salesperson. However while an administrator is using that user system to interact with the system that user system can have the capacities allotted to that administrator. Where a hierarchical role model is used users at one permission level can have access to applications data and database information accessible by a lower permission level user but may not have access to certain applications database information and data accessible by a user at a higher permission level. Thus different users generally will have different capabilities with regard to accessing and modifying application and database information depending on the users respective security or permission levels also referred to as authorizations .

According to some implementations each user system and some or all of its components are operator configurable using applications such as a browser including computer code executed using a central processing unit CPU such as an Intel Pentium processor or the like. Similarly the system and additional instances of an MTS where more than one is present and all of its components can be operator configurable using application s including computer code to run using the processor system which may be implemented to include a CPU which may include an Intel Pentium processor or the like or multiple CPUs.

The system includes tangible computer readable media having non transitory instructions stored thereon in that are executable by or used to program a server or other computing system or collection of such servers or computing systems to perform some of the implementation of processes described herein. For example computer program code can implement instructions for operating and configuring the system to intercommunicate and to process web pages applications and other data and media content as described herein. In some implementations the computer code can be downloadable and stored on a hard disk but the entire program code or portions thereof also can be stored in any other volatile or non volatile memory medium or device as is well known such as a ROM or RAM or provided on any media capable of storing program code such as any type of rotating media including floppy disks optical discs digital versatile disks DVD compact disks CD microdrives and magneto optical disks and magnetic or optical cards nanosystems including molecular memory ICs or any other type of computer readable medium or device suitable for storing instructions or data. Additionally the entire program code or portions thereof may be transmitted and downloaded from a software source over a transmission medium for example over the Internet or from another server as is well known or transmitted over any other existing network connection as is well known for example extranet VPN LAN etc. using any communication medium and protocols for example TCP IP HTTP HTTPS Ethernet etc. as are well known. It will also be appreciated that computer code for the disclosed implementations can be realized in any programming language that can be executed on a server or other computing system such as for example C C HTML any other markup language Java JavaScript ActiveX any other scripting language such as VBScript and many other programming languages as are well known may be used. Java is a trademark of Sun Microsystems Inc. .

In the network interface is implemented as a set of HTTP application servers . Each application server also referred to herein as an app server is configured to communicate with tenant database and the tenant data therein as well as system database and the system data therein to serve requests received from the user systems . The tenant data can be divided into individual tenant storage spaces which can be physically or logically arranged or divided. Within each tenant storage space user storage and application metadata can similarly be allocated for each user. For example a copy of a user s most recently used MRU items can be stored to user storage . Similarly a copy of MRU items for an entire organization that is a tenant can be stored to tenant storage space .

The process space includes system process space individual tenant process spaces and a tenant management process space . The application platform includes an application setup mechanism that supports application developers creation and management of applications. Such applications and others can be saved as metadata into tenant database by save routines for execution by subscribers as one or more tenant process spaces managed by tenant management process for example. Invocations to such applications can be coded using PL SOQL which provides a programming language style interface extension to API . A detailed description of some PL SOQL language implementations is discussed in commonly assigned U.S. Pat. No. 7 730 478 titled METHOD AND SYSTEM FOR ALLOWING ACCESS TO DEVELOPED APPLICATIONS VIA A MULTI TENANT ON DEMAND DATABASE SERVICE by Craig Weissman issued on Jun. 1 2010 and hereby incorporated by reference in its entirety and for all purposes. Invocations to applications can be detected by one or more system processes which manage retrieving application metadata for the subscriber making the invocation and executing the metadata as an application in a virtual machine.

The system of also includes a user interface UI and an application programming interface API to system resident processes to users or developers at user systems . In some other implementations the environment may not have the same elements as those listed above or may have other elements instead of or in addition to those listed above.

Each application server can be communicably coupled with tenant database and system database for example having access to tenant data and system data respectively via a different network connection. For example one application server can be coupled via the network for example the Internet another application server can be coupled via a direct network link and another application server can be coupled by yet a different network connection. Transfer Control Protocol and Internet Protocol TCP IP are examples of typical protocols that can be used for communicating between application servers and the system . However it will be apparent to one skilled in the art that other transport protocols can be used to optimize the system depending on the network interconnections used.

In some implementations each application server is configured to handle requests for any user associated with any organization that is a tenant of the system . Because it can be desirable to be able to add and remove application servers from the server pool at any time and for various reasons in some implementations there is no server affinity for a user or organization to a specific application server . In some such implementations an interface system implementing a load balancing function for example an F5 Big IP load balancer is communicably coupled between the application servers and the user systems to distribute requests to the application servers . In one implementation the load balancer uses a least connections algorithm to route user requests to the application servers . Other examples of load balancing algorithms such as round robin and observed response time also can be used. For example in some instances three consecutive requests from the same user could hit three different application servers and three requests from different users could hit the same application server . In this manner by way of example system can be a multi tenant system in which system handles storage of and access to different objects data and applications across disparate users and organizations.

In one example storage use case one tenant can be a company that employs a sales force where each salesperson uses system to manage aspects of their sales. A user can maintain contact data leads data customer follow up data performance data goals and progress data etc. all applicable to that user s personal sales process for example in tenant database . In an example of a MTS arrangement because all of the data and the applications to access view modify report transmit calculate etc. can be maintained and accessed by a user system having little more than network access the user can manage his or her sales efforts and cycles from any of many different user systems. For example when a salesperson is visiting a customer and the customer has Internet access in their lobby the salesperson can obtain critical updates regarding that customer while waiting for the customer to arrive in the lobby.

While each user s data can be stored separately from other users data regardless of the employers of each user some data can be organization wide data shared or accessible by several users or all of the users for a given organization that is a tenant. Thus there can be some data structures managed by system that are allocated at the tenant level while other data structures can be managed at the user level. Because an MTS can support multiple tenants including possible competitors the MTS can have security protocols that keep data applications and application use separate. Also because many tenants may opt for access to an MTS rather than maintain their own system redundancy up time and backup are additional functions that can be implemented in the MTS. In addition to user specific data and tenant specific data the system also can maintain system level data usable by multiple tenants or other data. Such system level data can include industry reports news postings and the like that are sharable among tenants.

In some implementations the user systems which also can be client systems communicate with the application servers to request and update system level and tenant level data from the system . Such requests and updates can involve sending one or more queries to tenant database or system database . The system for example an application server in the system can automatically generate one or more SQL statements for example one or more SQL queries designed to access the desired information. System database can generate query plans to access the requested data from the database. The term query plan generally refers to one or more operations used to access information in a database system.

Each database can generally be viewed as a collection of objects such as a set of logical tables containing data fitted into predefined or customizable categories. A table is one representation of a data object and may be used herein to simplify the conceptual description of objects and custom objects according to some implementations. It should be understood that table and object may be used interchangeably herein. Each table generally contains one or more data categories logically arranged as columns or fields in a viewable schema. Each row or element of a table can contain an instance of data for each category defined by the fields. For example a CRM database can include a table that describes a customer with fields for basic contact information such as name address phone number fax number etc. Another table can describe a purchase order including fields for information such as customer product sale price date etc. In some MTS implementations standard entity tables can be provided for use by all tenants. For CRM database applications such standard entities can include tables for case account contact lead and opportunity data objects each containing pre defined fields. As used herein the term entity also may be used interchangeably with object and table. 

In some MTS implementations tenants are allowed to create and store custom objects or may be allowed to customize standard entities or objects for example by creating custom fields for standard objects including custom index fields. Commonly assigned U.S. Pat. No. 7 779 039 titled CUSTOM ENTITIES AND FIELDS IN A MULTI TENANT DATABASE SYSTEM by Weissman et al. issued on Aug. 17 2010 and hereby incorporated by reference in its entirety and for all purposes teaches systems and methods for creating custom objects as well as customizing standard objects in a multi tenant database system. In some implementations for example all custom entity data rows are stored in a single multi tenant physical table which may contain multiple logical tables per organization. It is transparent to customers that their multiple tables are in fact stored in one large table or that their data may be stored in the same table as the data of other customers.

As shown in accessing an on demand database service environment can involve communications transmitted among a variety of different hardware or software components. Further the on demand database service environment is a simplified representation of an actual on demand database service environment. For example while only one or two devices of each type are shown in some implementations of an on demand database service environment can include anywhere from one to several devices of each type. Also the on demand database service environment need not include each device shown in or can include additional devices not shown in .

Additionally it should be appreciated that one or more of the devices in the on demand database service environment can be implemented on the same physical device or on different hardware. Some devices can be implemented using hardware or a combination of hardware and software. Thus terms such as data processing apparatus machine server and device as used herein are not limited to a single hardware device rather references to these terms can include any suitable combination of hardware and software configured to provide the described functionality.

The cloud is intended to refer to a data network or multiple data networks often including the Internet. Client machines communicably connected with the cloud can communicate with other components of the on demand database service environment to access services provided by the on demand database service environment. For example client machines can access the on demand database service environment to retrieve store edit or process information. In some implementations the edge routers and route packets between the cloud and other components of the on demand database service environment . For example the edge routers and can employ the Border Gateway Protocol BGP . The BGP is the core routing protocol of the Internet. The edge routers and can maintain a table of IP networks or prefixes which designate network reachability among autonomous systems on the Internet.

In some implementations the firewall can protect the inner components of the on demand database service environment from Internet traffic. The firewall can block permit or deny access to the inner components of the on demand database service environment based upon a set of rules and other criteria. The firewall can act as one or more of a packet filter an application gateway a stateful filter a proxy server or any other type of firewall.

In some implementations the core switches and are high capacity switches that transfer packets within the on demand database service environment . The core switches and can be configured as network bridges that quickly route data between different components within the on demand database service environment. In some implementations the use of two or more core switches and can provide redundancy or reduced latency.

In some implementations the pods and perform the core data processing and service functions provided by the on demand database service environment. Each pod can include various types of hardware or software computing resources. An example of the pod architecture is discussed in greater detail with reference to . In some implementations communication between the pods and is conducted via the pod switches and . The pod switches and can facilitate communication between the pods and and client machines communicably connected with the cloud for example via core switches and . Also the pod switches and may facilitate communication between the pods and and the database storage . In some implementations the load balancer can distribute workload between the pods and . Balancing the on demand service requests between the pods can assist in improving the use of resources increasing throughput reducing response times or reducing overhead. The load balancer may include multilayer switches to analyze and forward traffic.

In some implementations access to the database storage is guarded by a database firewall . The database firewall can act as a computer application firewall operating at the database application layer of a protocol stack. The database firewall can protect the database storage from application attacks such as structure query language SQL injection database rootkits and unauthorized information disclosure. In some implementations the database firewall includes a host using one or more forms of reverse proxy services to proxy traffic before passing it to a gateway router. The database firewall can inspect the contents of database traffic and block certain content or database requests. The database firewall can work on the SQL application level atop the TCP IP stack managing applications connection to the database or SQL management interfaces as well as intercepting and enforcing packets traveling to or from a database network or application interface.

In some implementations communication with the database storage is conducted via the database switch . The multi tenant database storage can include more than one hardware or software components for handling database queries. Accordingly the database switch can direct database queries transmitted by other components of the on demand database service environment for example the pods and to the correct components within the database storage . In some implementations the database storage is an on demand database system shared by many different organizations as described above with reference to and .

In some implementations the app servers include a hardware or software framework dedicated to the execution of procedures for example programs routines scripts for supporting the construction of applications provided by the on demand database service environment via the pod . In some implementations the hardware or software framework of an app server is configured to execute operations of the services described herein including performance of the blocks of various methods or processes described herein. In some alternative implementations two or more app servers can be included and cooperate to perform such methods or one or more other servers described herein can be configured to perform the disclosed methods.

The content batch servers can handle requests internal to the pod. Some such requests can be long running or not tied to a particular customer. For example the content batch servers can handle requests related to log mining cleanup work and maintenance tasks. The content search servers can provide query and indexer functions. For example the functions provided by the content search servers can allow users to search through content stored in the on demand database service environment. The file force servers can manage requests for information stored in the File force storage . The File force storage can store information such as documents images and basic large objects BLOBs . By managing requests for information using the file force servers the image footprint on the database can be reduced. The query servers can be used to retrieve information from one or more file systems. For example the query system can receive requests for information from the app servers and transmit information queries to the NFS located outside the pod.

The pod can share a database instance configured as a multi tenant environment in which different organizations share access to the same database. Additionally services rendered by the pod may call upon various hardware or software resources. In some implementations the ACS servers control access to data hardware resources or software resources. In some implementations the batch servers process batch jobs which are used to run tasks at specified times. For example the batch servers can transmit instructions to other servers such as the app servers to trigger the batch jobs.

In some implementations the QFS is an open source file system available from Sun Microsystems of Santa Clara Calif. The QFS can serve as a rapid access file system for storing and accessing information available within the pod . The QFS can support some volume management capabilities allowing many disks to be grouped together into a file system. File system metadata can be kept on a separate set of disks which can be useful for streaming applications where long disk seeks cannot be tolerated. Thus the QFS system can communicate with one or more content search servers or indexers to identify retrieve move or update data stored in the network file systems or other storage systems.

In some implementations one or more query servers communicate with the NFS to retrieve or update information stored outside of the pod . The NFS can allow servers located in the pod to access information to access files over a network in a manner similar to how local storage is accessed. In some implementations queries from the query servers are transmitted to the NFS via the load balancer which can distribute resource requests over various resources available in the on demand database service environment. The NFS also can communicate with the QFS to update the information stored on the NFS or to provide information to the QFS for use by servers located within the pod .

In some implementations the pod includes one or more database instances . The database instance can transmit information to the QFS . When information is transmitted to the QFS it can be available for use by servers within the pod without using an additional database call. In some implementations database information is transmitted to the indexer . Indexer can provide an index of information available in the database or QFS . The index information can be provided to file force servers or the QFS .

The exemplary computer system includes a processing device processor a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM a static memory e.g. flash memory static random access memory SRAM and a data storage device which communicate with each other via a bus .

Processing device represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processing device may be a complex instruction set computing CISC microprocessor reduced instruction set computing RISC microprocessor very long instruction word VLIW microprocessor or a processor implementing other instruction sets or processors implementing a combination of instruction sets. The processing device may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a digital signal processor DSP network processor or the like. The processing device is configured to execute the notification manager for performing the operations and steps discussed herein.

The computer system may further include a network interface device . The computer system also may include a video display unit e.g. a liquid crystal display LCD or a cathode ray tube CRT an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. a speaker .

The data storage device may include a computer readable medium on which is stored one or more sets of instructions e.g. instructions of in memory buffer service embodying any one or more of the methodologies or functions described herein. The instructions may also reside completely or at least partially within the main memory and or within processing logic of the processing device during execution thereof by the computer system the main memory and the processing device also constituting computer readable media. The instructions may further be transmitted or received over a network via the network interface device .

While the computer readable storage medium is shown in an exemplary embodiment to be a single medium the term computer readable storage medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more sets of instructions. The term computer readable storage medium shall also be taken to include any medium that is capable of storing encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention. The term computer readable storage medium shall accordingly be taken to include but not be limited to solid state memories optical media and magnetic media.

The preceding description sets forth numerous specific details such as examples of specific systems components methods and so forth in order to provide a good understanding of several embodiments of the present invention. It will be apparent to one skilled in the art however that at least some embodiments of the present invention may be practiced without these specific details. In other instances well known components or methods are not described in detail or are presented in simple block diagram format in order to avoid unnecessarily obscuring the present invention. Thus the specific details set forth are merely exemplary. Particular implementations may vary from these exemplary details and still be contemplated to be within the scope of the present invention.

In the above description numerous details are set forth. It will be apparent however to one of ordinary skill in the art having the benefit of this disclosure that embodiments of the invention may be practiced without these specific details. In some instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the description.

Some portions of the detailed description are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion it is appreciated that throughout the description discussions utilizing terms such as determining identifying adding selecting or the like refer to the actions and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical e.g. electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

Embodiments of the invention also relate to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

It is to be understood that the above description is intended to be illustrative and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the invention should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

