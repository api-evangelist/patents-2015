---

title: Systems and methods for noise reduction using speech recognition and speech synthesis
abstract: The present disclosure describes a system () for reducing background noise from a speech audio signal generated by a user. The system () includes a user device () receiving the speech audio signal, a noise reduction device () in communication with a stored data repository (), where the noise reduction device is configured to convert the speech audio signal to text; generate synthetic speech based on the converted text; optionally determine the user as an actual subscriber based on a comparison between the speech audio signal with the synthetic speech; and selectively transmit the speech audio signal or the synthetic speech based on comparison between the predicted subjective quality of the recorded speech and the synthetic speech.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09390725&OS=09390725&RS=09390725
owner: ClearOne Inc.
number: 09390725
owner_city: Salt Lake City
owner_country: US
publication_date: 20150701
---
This application claims priority and the benefits of the earlier filed Provisional U.S. No. 62 042 024 filed 26. Aug. 2014 which is incorporated by reference for all purposes into this specification.

The present disclosure generally relates to noise reduction and more particularly to systems and methods for noise reduction using speech recognition and speech synthesis.

Various noise reduction techniques are currently available to enhance speech containing background noise in a diversity of applications including those related to communication and control. One such technique is called Spectral Subtraction See S. Boll Suppression of acoustic noise in speech using spectral subtraction. IEEE Transactions on Acoust. Speech and Signal Processing Vol. 27 1979 pp. 1109 1121. This technique involves estimating the power spectrum of the noise and subtracting the estimated noise power spectrum from the speech plus noise power spectrum. This technique suffers from a problem called musical artifacts. Another technique involves estimation of the clean speech spectral magnitude from a noisy speech spectrum using an optimal minimum mean squared estimator based on the Ephraim and Malah algorithm See Y. Ephraim and D. Malah Speech enhancement using optimal nonlinear spectral amplitude estimation in Proc. IEEE Int. Conf. Acoust. Speech Signal Processing Boston 1983 pp. 1118 1121. and Y. Ephraim and D. Malah Speech enhancement using a minimum means square error log spectral amplitude estimator IEEE Trans. Acoust. Speech Signal Processing vol. ASSP 33 no. 2 pp. 443 445 1985. . All of these techniques suffer from the problem that as the signal to noise ratio decreases i.e. the noise power increases relative to the speech power the enhanced speech sounds more unnatural and distorted. At some point a listener might actually prefer to simply listen to the noisy speech rather than the badly distorted enhanced speech.

Therefore there exists a need for improved systems and methods that reduce background noise for speech enhancement.

This disclosure describes systems and methods for noise reduction using speech recognition and speech synthesis. This disclosure provides a system using a user device in communication with a stored data repository that reduces the background noise from a speech audio signal generated by a user. The user device includes a processor and a memory and receives a speech audio signal. The system additionally includes a noise reduction device in communication with a stored data repository and in communication with the user device where the noise reduction device is configured to convert the received speech audio signal to text generate synthetic speech based on a speech data corpus or speech model data of the user stored in the stored data repository and the converted text determine the predicted subjective quality of the received speech audio signal if that signal were to be transmitted to a far end listener determine the predicted subjective quality of the synthetic speech and transmit selectively the speech audio signal or the synthetic speech whichever has higher predicted quality based on a comparison between the value of objective quality metrics computed for the speech audio signal and the synthetic speech signal.

Additionally this disclosure provides that the stored data repository is on the user device and or a server via a network.

Additionally this disclosure provides that the received speech audio signal is a live speech audio signal.

Further this disclosure provides that the user device is configured to pre process the speech audio signal based on using a predetermined noise reduction algorithm.

And this disclosure further provides that the noise reduction device is integrated with the user device.

Other and further aspects and features of the disclosure will be evident from reading the following detailed description of the embodiments which are intended to illustrate and not limit the present disclosure.

This disclosure describes a method for performing noise reduction using speech recognition and speech synthesis. This disclosure describes numerous specific details in order to provide a thorough understanding of the present invention. One skilled in the art will appreciate that one may practice the present invention without these specific details. Additionally this disclosure does not describe some well known items in detail in order not to obscure the present invention.

In one embodiment the first communication device may be a mobile phone receiving a speech audio signal from the user . In another embodiment the first communication device may be a headset worn by the pilot of an aircraft such as a helicopter which is used to communicate with other passengers in the same aircraft or personnel on the ground. The speech audio signal may include background noises from various sound sources e.g. another person transportation vehicles such as a car an animal such as a dog a television etc. In some embodiments the background noise may include non speech sounds e.g. humming finger clicks claps etc. being produced by the user or in the ambient surrounding. The speech audio signal may include a set of specific words in a predetermined language having predefined speech sounds called phonemes. In some embodiments the speech audio signal may be received live from the user . The communication devices and may include one or more processors and various types of memory and storage devices that are typically found in user communication devices and user computing devices.

In some embodiments a user device such as the first communication device and the second communication device may implement a variety of noise reduction techniques which are also synonymously called speech enhancement techniques known in the art related art or developed later including the Ephraim and Malah algorithm for speech enhancement. For example the first communication device may pre process the speech audio signal using such noise reduction techniques for sending a pre processed speech to the noise reduction device or a server implementing the noise reduction device . In some embodiments the pre processed speech may have relatively lesser noise compared to the speech audio signal.

The server may be implemented as any of a variety of computing devices including for example a general purpose computing device multiple networked servers arranged in clusters or as a server farm a mainframe or so forth. In one embodiment the server may be installed integrated or operatively associated with a noise reduction device configured to reduce noise from the audio signal for speech hereinafter also referred to as speech audio signal using speech recognition and speech synthesis. The server may include one or more processors and various types of memory and storage devices that are typically found in servers and other computing devices.

The noise reduction device may represent any of a wide variety of devices capable of providing noise reduction services for network devices. The noise reduction device may be implemented as a standalone and dedicated device including hardware and installed software where the hardware is closely matched to the requirements and or functionality of the software. Alternatively the noise reduction device may be implemented as a software application or a device driver. The noise reduction device may enhance or increase the functionality and or capacity of the network such as the network to which it is connected. In some embodiments the noise reduction device may be configured to expose its computing environment or operating code to a user and may include related art I O devices such as a keyboard or display. The noise reduction device of some embodiments may however include software firmware or other resources that support remote administration and or maintenance of the noise reduction device .

In further embodiments the noise reduction device either in communication with any of the networked devices such as the first communication device and the second communication device or independently may have video voice and data communication capabilities e.g. unified communication capabilities by being coupled to or including various imaging devices e.g. cameras printers scanners medical imaging systems etc. various audio devices e.g. microphones music players recorders audio input devices speakers audio output devices telephones speaker telephones etc. various video devices e.g. monitors projectors displays televisions video output devices video input devices camcorders etc. or any other type of hardware capable of facilitating video voice or data communications in any combination thereof. In some embodiments the noise reduction device may comprise or implement one or more real time protocols and non real time protocols known in the art related art or developed later to facilitate speech data transfer among the first communication device the second communication device the server the noise reduction device or any other network devices.

In some embodiments the noise reduction device may be configured to convert communications which may include instructions conversation queries data etc. from the first communication device into appropriate formats to make these communications compatible with the second communication device and vice versa. Consequently the noise reduction device may allow implementation of the first communication device or the server using different technologies or by different organizations e.g. a third party vendor managing the first communication device or the server or associated services using a proprietary technology.

In some embodiments as illustrated in the noise reduction device may be installed on or integrated with a network appliance not shown configured to establish the network between the first communication device and the second communication device . At least one of the noise reduction device and the network appliance may be capable of operating as or providing an interface to assist exchange of software instructions and data among the first communication device the second communication device and the noise reduction device . In some embodiments the network appliance may be preconfigured or dynamically configured to include the noise reduction device integrated with other devices. Examples of the network appliance include but are not limited to a DSL modem a wireless access point a router a base station and a gateway having a predetermined computing power and memory capacity sufficient for implementing the noise reduction device .

In another embodiment the noise reduction device may be integrated with the server as shown in or any other computing device not shown connected to the network . The server may include a module not shown which enables the server to provide a list of available services to the network appliance thereby enabling the network appliance to invoke the noise reduction device as a service.

In another embodiment as shown in the noise reduction device may be integrated with the communication devices and or .

And in another embodiment as shown in the noise reduction device may be integrated into any number of devices in a distributed fashion such as being integrated into communication devices and and in server .

As illustrated in the noise reduction device may be configured to reduce the background noise from the speech audio signal received from a user device such as the first communication device based on speech recognition and speech synthesis. The speech audio signal may include speech of the user and background noise comprising of any unwanted sound such as those mentioned above including a speech of another user. In some embodiments such noise reduction may be implemented as a service over the network for subscribed users.

The noise reduction device may be implemented by way of a single device e.g. a computing device a processor or an electronic storage device or a combination of multiple devices that are operatively connected or networked together. The noise reduction device may be implemented in hardware or a suitable combination of hardware and software. In some embodiments the noise reduction device may be a hardware device including processor s executing machine readable program instructions for analyzing data and interactions between the first communication device and the second communication device . The hardware may comprise a combination of discrete components an integrated circuit an application specific integrated circuit a field programmable gate array a digital signal processor or other suitable hardware. The software may comprise one or more objects agents threads lines of code subroutines separate software applications two or more lines of code or other suitable software structures operating in one or more software applications or on one or more processors. The processor s may include for example microprocessors microcomputers microcontrollers digital signal processors central processing units state machines logic circuits and or any devices that manipulate signals based on operational instructions. Among other capabilities the processor s may be configured to fetch and execute computer readable instructions in the memory associated with the noise reduction device for performing tasks such as signal coding data processing input output processing power control and or other functions.

In some embodiments the noise reduction device may include in whole or in part a software application working alone or in conjunction with one or more hardware resources. Such software applications may be executed by the processor s on different hardware platforms or emulated in a virtual environment. Aspects of the noise reduction device may leverage known related art or later developed off the shelf software. Other embodiments may comprise the noise reduction device being integrated or in communication with a mobile switching center network gateway system Internet access node application server IP Multimedia Core Network Subsystem IMS core service node or some other communication systems including any combination thereof. In some embodiments the noise reduction device may be integrated with or implemented as a wearable device including but not limited to a fashion accessory e.g. a wrist band a ring etc. a utility device a hand held baton a pen an umbrella a watch etc. a body clothing or any combination thereof.

The noise reduction device may include a variety of known related art or later developed interface s including software interfaces e.g. an application programming interface a graphical user interface etc. hardware interfaces e.g. cable connectors a keyboard a card reader a barcode reader a biometric scanner a microphone an interactive display screen etc. or both.

The noise reduction device may further include the memory for storing at least one of 1 a log of profiles of network devices device owners and associated communications including instructions queries conversations data and related metadata 2 one or more subscribers of a predefined service e.g. a noise reduction service etc. being provided by or implemented on the network 3 speech data corpus of the one or more users or subscribers and 4 predefined models equations algorithms etc. for speech recognition and speech synthesis.

The system memory may comprise of any computer readable medium known in the art related art or developed later including for example a processor or multiple processors operatively connected together volatile memory e.g. RAM non volatile memory e.g. flash etc. disk drive etc. or any combination thereof. The system memory may include one or more stored data repositories such as a database and or a file system which may be sub divided into further databases and or files for storing electronic files. The system memory may have one of many database schemas known in the art related art or developed later for storing speech data such as speech data corpus from the first communication device via the noise reduction device . For example the stored data repository may have a relational database schema involving a primary key attribute and one or more secondary attributes. In some embodiments the noise reduction device may perform one or more operations but not limited to reading writing indexing labeling updating and modifying the data and may communicate with various networked computing devices.

In one embodiment the system memory may include various modules such as a recording module a synthetic speech module a speaker verification module and a noise reduction module . The recording module may receive a speech audio signal including background noise from a user device such as the first communication device over the network . In some embodiments the speech audio signal may be pre processed at the first communication device for noise reduction using a variety of techniques known in the art related art or developed later. The speech audio signal may belong to a user such as the user capable of subscribing to a predefined service such as the noise reduction service provided by or implemented on the network .

The recording module may include a predefined threshold of the signal to noise ratio SNR hereinafter referred to as predefined SNR threshold for the received speech audio signal. In one embodiment the recording module may be configured to record the speech audio signal having an acceptable SNR which is above the predefined SNR threshold. Such speech audio signal may be recorded over time while the user device such as the first communication device is being used in some embodiments in a relatively quiet environment. The recorded speech audio signal may be stored in the stored data repository as such or after being converted into text or both. Alternatively the recorded speech may be analyzed by algorithms running on the processor in order to extract relevant features from the speech analyze those features and store appropriate limits for and statistical information about those features in the stored data repository represented as a file. The features stored in the file may be used to construct a vocal tract and excitation model to be used by an algorithmic speech synthesizer.

In some embodiments the user may record the speech audio signal at a user device such as the first communication device in a relatively quiet environment. Such recorded speech audio signal in one example may be converted into text for the purpose of collecting a speech data corpus at the user device such as the first communication device over time. Once a sufficiently large speech data corpus is collected the user device may send the collected speech data corpus to the recording module for being stored in the stored data repository .

In some embodiments the converted text may be tagged with a label e.g. based on inherent part of speech POS and noun phrases using any of a variety of natural language processing NLP techniques known in the art related art or developed later such as conditional random field models. Tagging may allow segments of recorded speech audio signal to be matched with the converted text so that sub word segments can be captured in the stored data repository . Such textual speech data may be accumulated over time to create a speech data corpus for the user in the stored data repository .

The synthetic speech module may be configured to generate synthetic speech using the speech data corpus stored in the stored data repository for various users subscribing to the noise reduction service hereinafter such users are referred to as service subscribers. In one embodiment the speech data corpus for various service subscribers may be stored as recorded speech plus transcribed text in the stored data repository .

The synthetic speech module then may determine how to pronounce a sequence of words of the converted text by determining what part of speech each word can be classified into and how the words are organized into logical groups. For example the correct pronunciation of the words record permit and present depends heavily on how the word is used in a specific sentence. At this point the output is a set of graphemes or letters of the alphabet plus information on how each word should be pronounced. If the original recorded speech is not excessively degraded by noise a pitch contour can be extracted from the speech and can be given as input to the speech synthesizer in order to improve the realism of the synthetic speech.

The graphemes or the stream of data that describes how a word should be pronounced may be taken and a set of phonemes may be selected from a recorded database of speech sounds that may be used to speak the word aloud. Phonemes are the set of speech sounds available for use in a particular language. Further the synthetic speech module may determine prosody information that describes elements like emphasis pauses and pitch for a set of phonemes.

In some embodiments the synthetic speech module may implement a variety of techniques known in the art related art or developed later for generating synthetic speech based on determined prosody information including the algorithmic synthesis method. In one instance the synthetic speech module may implement the concatenative synthesis method that uses a recorded database of speech sounds diphones or triphones and concatenates the correct pieces of speech sounds or phonemes to generate continuous speech. Pitch and timing modifications may be included to make the speech sound more natural. Additionally the synthetic speech module may generate synthetic speech using the converted text of the received speech audio signal stored in the stored data repository for the received speech audio signal. The generated synthetic speech may be sent to the noise reduction module for use or stored in the stored data repository .

In some embodiments the synthetic speech module may audio watermark the generated synthetic speech so that it can be verified by the noise reduction module or any other network module or device to be synthetic rather than the received speech audio signal.

In some embodiments the speaker verification module may be configured to automatically determine whether or not the user whose speech audio signal is received from the first communication device is the actual service subscriber. In one embodiment the speaker verification module may compare the speech audio signal as received by the recording module from the user device with the synthetic speech generated using the speech data corpus of the user stored in the stored data repository by the synthetic speech module for. A positive match based on such comparison may confirm the verification of the user who corresponds to the received speech audio signal who is the actual subscriber of the predefined service e.g. noise reduction service provided by or implemented on the network .

Additionally the speaker verification module may be configured to determine the identity of the user using a variety of speaker verification techniques known in the art related art or developed later. For example the speaker verification module may compute the Itakura Saito distance between the spectrum of the synthetic speech generated by the synthetic speech module for the target service subscriber stored in the stored data repository and the spectrum of the speech audio signal received from a user such as the user .

The textual speech data of the received speech audio signal for the user identified as the speaker may be stored in the collected speech data corpus for that user in the stored data repository .

The noise reduction module may receive the synthetic speech generated for the received speech audio signal from the synthetic speech module . In one embodiment the noise reduction module may be configured to objectively estimate the quality of the unprocessed received speech audio signal and the synthetic speech generated for this speech audio signal and choose which signal to send to the remote listener. In another embodiment the noise reduction module may be configured to estimate the quality of the unprocessed received speech audio signal and in addition estimate the quality of the speech audio signal processed by a traditional noise reduction or equivalently speech enhancement system and finally estimate the quality of the synthetic speech and choose the best out of the three options. The noise reduction module may perform such objective quality estimation by using the non intrusive quality measurement method standardized by the Telecommunication Standardization Sector of the International Telecommunications Union ITU T called ITU T standard P.563 Single ended method for objective speech quality assessment in narrow band telephony applications . This standard was developed as a way to monitor the quality of telecommunication links. After it was developed it was evaluated as a way to objectively measure the quality of synthetic speech See Ivan Kraljevski et. al. Synthesized Speech Quality Evaluation Using ITU T P.563 18. Telecommunications forum TELFOR 2010 p. 590 593 . As an alternative to ITU T P.563 the noise reduction module could use the Low Complexity Quality Assessment LCQA algorithm See Volodya Grancharov et. al. Low Complexity Nonintrusive Speech Quality Assessment IEEE Transactions on Audio Speech and Language Processing vol. 14 6 which gives results that correlate more closely with the Mean Opinion Scores given by human listeners than P.563. and also requires less computation. Based on the comparison of scores provided by the P.563. or LCQA algorithms one of the received speech audio signal and the synthetic speech that has a higher score may be determined as the output signal by the noise reduction module . The determined output signal may be sent as a noise reduced speech audio signal to the second communication device over the network provided the user is determined as the actual subscriber of the predefined service e.g. noise reduction service by the speaker verification module .

The order in which the method is described is not intended to be construed as a limitation and any number of the described method blocks may be combined or otherwise performed in any order to implement the method or an alternate method. Additionally individual blocks may be deleted from the method without departing from the spirit and scope of the present disclosure described herein. Furthermore the method may be implemented in any suitable hardware software firmware or combination thereof that exists in the related art or that is later developed.

The method describes without limitation implementation of the exemplary noise reduction device . Those having ordinary skill in the art would understand that the method may be modified appropriately for implementation in a various manners without departing from the scope and spirit of the disclosure.

At step a speech audio signal including background noise is received. The noise reduction module may receive the speech audio signal from a user device over a network . The speech audio signal may include background noise of different types from a variety of sound sources such as those discussed above. The speech audio signal may belong to the user and include a set of specific words in a predetermined language in the voice of the user . In one embodiment the speech audio signal may be received live from the user via the user device such as the first communication device aimed to be processed and sent to the second communication device . In another embodiment the speech audio signal may be pre processed by the user device using any of the variety of noise reduction techniques known in the art related art or developed later to reduce some portion of the background noise before the speech audio signal is received by the noise reduction device . In a further embodiment the user may record the speech audio signal at the user device such as the first communication device in a relatively quiet environment. Such recorded speech audio signal may be converted into text for the purpose of collecting a speech data corpus at the user device over time. Once a sufficiently large speech data corpus is collected the user device may send the collected speech data corpus e.g. textual speech data aligned with recorded speech audio signals to the recording module of the noise reduction device and stored in the stored data repository .

At step the received speech audio signal may be converted to text in response to the objective quality measurement of the received speech audio signal being above a predefined quality threshold. The received speech audio signal may be converted into text or textual speech data which may be stored in the stored data repository . In some embodiments similar textual speech data plus speech audio signals may be accumulated or retrieved from the user device if available over time to create a speech data corpus for the user . In some embodiments the user device such as the first communication device or the noise reduction device may allow the user to operate the user device e.g. the first communication device for controlling such conversion of the speech audio signal into text occurring at the noise reduction device .

In one embodiment the synthetic speech module may access the speech data corpus stored in the stored data repository for the user providing the speech audio signal. Such speech data corpus may include the textual speech data time aligned with recorded speech audio signals corresponding to a service subscriber for speech synthesis.

At step the user is determined as an actual service subscriber based on a comparison between the received speech audio signal and the synthetic speech. In one embodiment the speaker verification module may compare the received speech audio signal with the synthetic speech. As multiple speech audio signals belonging to one or more users may be received in a single session e.g. a communication session such comparison may allow the system to determine whether or not the user whose speech audio signal is received is the actual service subscriber. Based on a positive match between the synthetic speech and the received speech audio signal the speaker verification module may determine that the user is the actual service subscriber. This step is not required if the communication system requires a user to log in before using the system.

At step a second quality measurement of the generated second synthetic speech is determined. The noise reduction module may determine a quality metric of the synthetic speech generated using the converted text from the speech audio signal by the synthetic speech module .

At step at least one of the received speech audio signal and the synthetic speech whichever has relatively higher predicted subjective quality may be transmitted based on a comparison between the first quality measurement and the second quality measurement optionally provided the user is determined as the actual service subscriber.

The exemplary method may be described in the general context of computer executable instructions. Generally computer executable instructions may include routines programs objects components data structures procedures modules functions and the like that perform particular functions or implement particular abstract data types. The computer executable instructions may be stored on a computer readable medium and installed or embedded in an appropriate device for execution.

The order in which the method is described is not intended to be construed as a limitation and any number of the described method blocks may be combined or otherwise performed in any order to implement the method or an alternate method. Additionally individual blocks may be deleted from the method without departing from the spirit and scope of the present disclosure described herein. Furthermore the method may be implemented in any suitable hardware software firmware or combination thereof that exists in the related art or that is later developed.

The method describes without limitation implementation of the exemplary noise reduction device . One of skill in the art will understand that the method may be modified appropriately for implementation in various manners without departing from the scope and spirit of the disclosure.

At step a speech model for the target user may be retrieved from a database or file. In one embodiment the speaker verification module may retrieve a speech model for a target user stored in the stored data repository . The speech model may be created by the recording module using standard methods to extract relevant features from the speech recording along with a data clustering algorithm like the well known K means algorithm. The extracted features may include mel frequency cepstral coefficients MFCCs see Tomi Kinnunen et. al. An Overview of Text Independent Speaker Recognition from Features to Supervectors Speech Communication Vol. 52 1 January 2010 pp. 12 40 corresponding to a speech audio signal from the user or retrieved from the user device over a period of time. At step a likelihood ratio can be computed using a Gaussian Mixture Model GMM to determine the likelihood that the current talker is the service subscriber. Alternatively an artificial neural network ANN see generally S. Haykin Second Edition 1999 such as a multilayer perceptron could be used see J. M. Naik et. al. A hybrid HMM MLP speaker verification algorithm for telephone speech in Proc. IEEE Int. Conf. Acoustics Speech Signal Processing ICASSP 94 VOL. 1 PP. 153 156 Adelaide Australia April 1994. . At step a user or a service subscriber may be verified to be the target service subscriber based on the likelihood ratio being above a predetermined threshold or the Neural Network providing a positive classification. At step at least a portion of the received speech audio signal or relevant features extracted from the speech audio signal corresponding to the user or service subscriber identified as the speaker may be stored with the speech corpus for that user such as the user in the stored data repository.

To summarize this disclosure describes systems and methods for noise reduction using speech recognition and speech synthesis. This disclosure provides a system using a user device in communication with a stored data repository that reduces the background noise from a speech audio signal generated by a user. The user device includes a processor and a memory and receives a speech audio signal. The system additionally includes a noise reduction device in communication with a stored data repository and in communication with the user device where the noise reduction device is configured to convert the received speech audio signal to text generate synthetic speech based on a speech data corpus of the user stored in the stored data repository and the converted text determine the predicted subjective quality of the received speech audio signal if that signal were to be transmitted to a far end listener determine the predicted subjective quality of the synthetic speech and transmit selectively the speech audio signal or the synthetic speech whichever has higher predicted quality based on a comparison between the value of objective quality metrics computed for the speech audio signal and the synthetic speech signal.

Additionally this disclosure provides that the stored data repository is on the user device and or a server via a network. Additionally this disclosure provides that the received speech audio signal is a live speech audio signal. Further this disclosure provides that the user device is configured to pre process the speech audio signal based on using a predetermined noise reduction algorithm. And this disclosure further provides that the noise reduction device is integrated with the user device.

Other embodiments of the present invention will be apparent to those skilled in the art after considering this disclosure or practicing the disclosed invention. The specification and examples above are exemplary only with the true scope of the present invention being determined by the following claims.

