---

title: Reporting operational metrics in speech-based systems
abstract: A speech-based system is configured to use its audio-based user interface to present various types of device status information such as wireless signal strengths, communication parameters, battery levels, and so forth. In described embodiments, the system is configured to understand spoken user requests for device and system status. For example, the user may speak a request to obtain the current wireless signal strength of the speech-based system. The speech-based system may respond by determining the signal strength and by playing speech or other sound informing the user of the signal strength. Furthermore, the system may monitor operational parameters to detect conditions that may degrade the user experience, and may report such conditions using generated speech or other sounds.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09536527&OS=09536527&RS=09536527
owner: Amazon Technologies, Inc.
number: 09536527
owner_city: Seattle
owner_country: US
publication_date: 20150630
---
As the processing power available to devices and associated support services continues to increase it has become practical to interact with users in new ways. In particular it has become practical to interact with users through two way speech dialogs in which a user instructs a system by voice and the system responds by speech. However interacting without a graphical user interface presents challenges in how to present certain types of information to users.

A speech based system may be configured to interact with a user through speech to receive instructions from the user and to provide services for the user. In certain embodiments the system may comprise a speech interface device having a microphone and speaker for receiving user speech and playing responsive system speech. Certain functions and capabilities of the device may be implemented at least in part by network based services which the device may access through a data communications network such as the Internet. In particular the network based services may provide speech processing and interaction capabilities including automatic speech recognition ASR natural language understanding NLU dialog management and text to speech TTS functionality. The network based services may also provide status reporting regarding statuses of both the speech interface device and the network based services.

In operation the network based services perform ASR and NLU to determine and act upon requests by users. The system is configured to respond to user speech by performing actions providing services and or producing audio. In some cases the system may engage in a speech dialog with a user to determine the intent of the user. A speech dialog comprises two way exchange of speech by the user and the speech based system respectively.

The speech interface device is configured to report various types of statuses in response to spoken user queries and or in response to status conditions that threaten the quality of services provided by the system.

As an example the speech interface device may monitor the quality or strength of the wireless communications channel used by a Wi Fi interface of the speech interface device. The wireless communications channel is subject to interference by objects and devices such walls electronic components furniture sources of electromagnetic interference etc.

In certain situations the speech interface device may communicate information regarding the quality of the wireless communication channel with the user through generated speech or other types of sounds. For example the speech interface device may play the speech Wireless signal strength has dropped to an undesirable level. Furthermore the speech interface device may use its voice capabilities to guide the user through a sequence of steps to increase the quality of the wireless communication channel. For example the device may ask the user to move the speech interface device to a location that improves the quality of the wireless communication channel. As the device is moved it may play a tone or other sound that changes to indicate that a measured parameter such as signal strength is increasing or decreasing.

In some embodiments the speech interface device may indicate status information in response to a spoken user query. For example the user may ask How is your Wi Fi signal and the speech interface device may respond with the statement Wireless signal strength is currently 8 out of 10. 

More generally the audio capabilities of the speech interface device may be used to provide various types of device and system status information to the user either in response to detected events or in response to spoken user requests. For example the speech interface device may report statuses such as battery levels communication parameters accessories device configuration and so forth.

In certain embodiments the speech interface device may be configured to provide an audio signal representing a spoken user request to supporting network based services for ASR and NLU. The network based services may analyze the audio signal to determine the meaning of the spoken user request. In response to determining that the user request is for a status of the speech interface device the network based services may communicate with the speech interface device to obtain parameters corresponding to the requested status or from which the requested status can be determined. The network based services may then formulate a spoken response indicating the requested status and provide an audio signal to the speech interface device wherein the audio signal represents speech that describes or otherwise states the requested status. The speech interface device then produces the speech on its loudspeaker.

In some cases rather than communicating with the speech interface device to obtain status parameters for reporting the network based services may provide speech describing a partial answer to the user query or a phrase from which the actual requested value has been left out and may request the speech interface device to provide an actual parameter value. For example the speech provided by the network based service may comprise The signal strength is and the speech interface device may then insert or append the word eight corresponding to the parameter.

In some embodiments the speech interface device may periodically send updated status information to the network based services. In response to a user request for status information the network based services may provide speech or other sound that indicates the most recently received status information. In addition the network based services may cache and monitor the status information to detect changes or out of limits conditions of the status information and may audibly report the status information to the user.

Various types of sound in addition to speech may be used to indicate device status. For example distinctive sounds associated with certain statuses referred to as earcons may be used to indicate the statuses. As another example various types of tones tone patterns tone sequences and so forth may be used to indicate statuses. As a specific example a sound may be configured to increase in loudness or frequency as a function of a parameter value. Similarly different tone patterns or tunes may be used to indicate parameter values.

The speech interface device has one or more microphones that are used to capture user speech as well as one or more speakers that are used to play speech and content. In some embodiments the speech interface device may be designed to operate from a fixed location. In other embodiments the speech interface device may be portable. For example the speech interface device may comprise a handheld device.

The speech interface device has a network interface such as a Wi Fi communications interface or other communications interface that provides data communications with the network based services . The speech interface device may communicate wirelessly with the network based services through a Wi Fi access point . A communication channel between the speech interface device and the network based services may include a wireless RF radio frequency communication channel which may utilize a wireless communication standard and protocol such as Wi Fi which is defined by a specification known as the IEEE 802.11 specification. The Wi Fi access point may communicate with the network based services over a wide area data communications network such as the Internet using any of various types of networking technologies including both wired and wireless technologies.

The wireless communication channel may alternatively be implemented using different wireless standards and protocols. Bluetooth is an example of a different wireless protocol that may be used to implement the wireless communication channel . As another example the speech interface device may communicate with the network based services using cellular data communications.

Although not shown in the physical environment of the speech interface device may include various types of features that may obstruct or interfere with the wireless communication channel including walls furniture other devices various sources of electromagnetic radiation such as microwave ovens and so forth. The quality or performance of the wireless communication channel may therefore be dependent upon the location at which the speech interface device is placed within the environment.

The network based services may be part of one or more network accessible computing platforms that are maintained and accessible via the Internet such as are sometimes referred to as cloud services. Generally communications between the speech interface device and the network based services may be implemented through a combination of various types of data communications networks including local area networks wide area networks and or the public Internet which may include various types of wireless networks including Wi Fi networks Bluetooth networks and cellular communication networks. The network based services may serve large numbers of speech interface devices which may be located in the premises of many different users.

In operation the speech interface device monitors a microphone audio signal or other audio signal representing sound from the environment of the speech interface device to detect a user utterance of a wakeword which is referred to more generally as a trigger expression. The trigger expression may comprise a word a phrase or a sound. Utterance of the trigger expression indicates that subsequent speech is directed to the speech interface device and is intended to be understood and acted upon by the speech interface device . Upon detecting the trigger expression the speech interface device causes subsequent user speech to be analyzed to determine the meaning and intent of the speech. In some cases the speech interface device may conduct a speech dialog with the user in order to determine and act upon an intent that is being expressed by the user. A speech dialog comprises multiple dialog turns each of which may comprise one or more of a user utterance and a system generated speech reply.

In the described embodiments the network based services include speech services that receive audio from the speech interface device and that perform automatic speech recognition ASR and natural language understanding NLU in order to determine actions to perform in response to spoken user commands. The network based speech services may include speech dialog functionality which allows the system to interact with a user through two way speech dialogs in which the system may ask the user for additional information in order to fully define or determine the action that the user is requesting.

The network based services may also include other types of services that may be accessed and used by the speech interface device . For example the network based services may provide services for email and messaging for retail purchasing for providing various types of information such as news weather and traffic information for providing music and other audible content for calendaring and any number of other services. The speech interface device may be configured to access these services in response to spoken requests by the user and in some cases to perform actions using the services in response to user requests. For example using the speech interface device the user may compose mail and other messages to be sent using an email or Internet based messaging service instruct the speech interface device to read received email from an email service purchase items from an Internet based merchant request and receive weather news and traffic reports from corresponding network based services initiate playback of music from music services or repositories create to do lists or shopping lists set timers or alarms create appointments using a calendaring service and so forth.

In addition to being able to ask the speech interface device for services the user may speak commands or requests regarding system and device status. For example as illustrated in the user may ask for the current Wi Fi signal strength of the speech interface device . Similarly the speech interface device may respond to requests for information such as Bluetooth signal strength network configuration information such as internal and external IP addresses MAC addresses and Wi Fi access point names network performance information such as communication channel bandwidths communication speeds and latencies numbers of packets sent and received software information such as firmware build numbers and operating system versions device serial numbers battery levels remaining battery life device roles such as whether a device is acting as a left or right speaker in a stereo music system or the device role in relation to home automation components device metadata information regarding supporting network based services such as service server names and IP addresses status of supporting services etc. information relating to connected or controlled home automation devices and so forth.

In addition to providing device status in response to spoken user requests the speech interface device may at times provide status information in response to detecting certain events conditions or status changes. For example the speech interface device may monitor its Wi Fi signal strength to detect a decrease in the Wi Fi signal strength. In response to detecting the decrease in the Wi Fi signal strength the speech interface device may generate speech informing the user of the decrease in signal strength and describe the negative impact that this may have on the performance of the speech interface device . In some cases the speech interface device may instruct the user regarding steps that may be taken to increase the signal strength such as moving the speech interface device to a position nearer a Wi Fi access point removing nearby objects that may be obstructing the Wi Fi signal changing access points etc.

Specified device status parameters may also be indicated to the user at times such as device startup at periodic intervals in response to commands initiated by technicians and communicated from the network based services and so forth. In some cases the user may instruct the system to enter a monitoring mode in which parameters are audibly reported as they change.

In addition to current device status the system may be configured to audibly indicate past statuses. For example the system may be responsive to a user command or other instructions to audibly indicate a history of communications bandwidths. More generally the system may be responsive to a user command or other instructions to audibly indicate a history of device events device errors or status parameters that were outside of normal ranges.

The speech interface device may comprise a processing unit and associated memory . The processing unit may comprise one or more processors which may include general purpose processors specialized processors processing cores digital signal processors etc. Depending on the configuration of the speech interface device the memory may be a type of non transitory computer storage media and may include volatile and nonvolatile memory. The memory may include but is not limited to RAM ROM EEPROM flash memory or other memory technology. The memory may include removable or detachable memory and may also include network accessible memory. The memory may include portable storage media such as a flash memory drive.

The memory may be used to store any number of software components that are executable by the processing unit . Software components stored in the memory may include an operating system that is configured to manage hardware and services within and coupled to the speech interface device . In addition executable components stored by the memory may include audio processing components configured to produce an input audio signal using the microphone array . The audio processing component may include functionality for processing microphone audio signals generated by the microphone array and or output audio signals provided to the loudspeaker . As an example the audio processing components may include an acoustic echo cancellation or suppression component for reducing acoustic echo generated by acoustic coupling between the microphone array and the loudspeaker . The audio processing components may also include a noise reduction component for reducing noise in received audio signals such as elements of microphone audio signals other than user speech.

The audio processing components may include one or more audio beamformers or beamforming components configured to generate directional audio signals that are focused in different directions. More specifically the beamforming components may be responsive to audio signals from spatially separated microphone elements of the microphone array to produce directional audio signals that emphasize sounds originating from different areas of the environment of the speech interface device or from different directions relative to the speech interface device .

Executable components stored in the memory and executed by the processor may include a wake word detection component that monitors one or more of the directional audio signals to detect user utterances of the system of the trigger expression. In some embodiments the wake word detector may be implemented using keyword spotting technology as an example. A keyword spotter is a functional component or algorithm that evaluates an audio signal to detect the presence a predefined word or expression in the audio signal. Rather than producing a transcription of the words of the speech a keyword spotter generates a true false output to indicate whether or not the predefined word or expression was represented in the audio signal. For example a keyword spotter may use a Hidden Markov Model HMM recognizer that performs acoustic modeling of an audio signal and compares an HMM model of the audio signal to one or more reference HMM models that have been created by training for a specific wake word.

Executable software components stored in the memory and executed by the processor may also include a speech services interface . The speech services interface is responsible for communicating with speech services that are part of the network based services . For example the speech services interface may provide an audio stream to network based speech services and may receive responsive audio from the network based speech services. The speech services interface may also communicate with the speech services in order to exchange various types of control and status information.

The speech interface device may also implement a status monitor . The status monitor monitors and reports various information regarding the speech interface device and or any supporting network based services . For example the status monitor may monitor the quality of the communications channel between the speech interface device and the network based services . In some cases the status monitor may monitor the strength of the RF signal between the speech interface device and the Wi Fi access point . The status monitor may also monitor other status information such as battery level remaining battery life communication parameters status of accessories software firmware versions and build numbers role configuration in a multi speaker system communication latencies etc.

The status monitor may expose an API application programming interface through which the speech services interface or other software components of the speech interface device can request and receive status information regarding hardware and software components of the speech interface device .

In certain implementations the status monitor may cause the speech interface device to produce output speech indicating the status information. For example in response to determining that the RF signal quality or strength has decreased and or is below a quality strength threshold the status monitor may cause the speech interface device to produce output speech indicating that the quality or strength of the RF signal is low and may in some embodiments instruct the user how to increase the signal quality or strength.

The speech interface device may have a communications interface such as a wireless or Wi Fi network communications interface an Ethernet communications interface a cellular network communications interface a Bluetooth communications interface etc. for communications with the network based services over various types of networks including wide area network local area networks private networks public networks etc. In the case of a wireless communications interfaces such interfaces may include radio transceivers and associated control circuits and logic for implementing appropriate communication protocols.

The speech interface device also has various hardware components not shown such as communication components power components I O components signal processing components indicators control buttons amplifiers etc.

Software components stored in the memory may include drivers associated with hardware components such as the communications interface . The drivers may include communication drivers such as Bluetooth and Wi Fi communication stacks. Software drivers may also include power and battery management interfaces associated with power and battery components of the speech interface device . The status monitor may communicate with the software drivers to obtain status information regarding hardware aspects and other aspects of the speech interface device .

Generally the status monitor may have access to various types of status information relating to both hardware and software components of the speech interface device and to any services that are used to support the operation of the speech interface device . The status monitor for example may cause the speech interface device to produce output speech or other audible indicators relating to information such the following 

In a very basic configuration the example server may comprise a processing unit and associated memory . The processing unit may comprise one or more processors which may include general purpose processors specialized processors processing cores digital signal processors etc. Depending on the configuration of the server the memory may be a type of non transitory computer storage media and may include volatile and nonvolatile memory. The memory may include but is not limited to RAM ROM EEPROM flash memory or other memory technology. The memory may include removable or detachable memory and may also include network accessible memory. The memory may include portable storage media such as a flash memory drive.

The memory may be used to store any number of software components that are executable by the processing unit . Software components stored in the memory may include an operating system that is configured to manage hardware and services within and coupled to the server . In addition executable software components stored by the memory may include speech services that support the speech based operations of the speech interface device . The server may also have a communications interface such as an Ethernet communications adapter for communicating with other servers other networked components and with multiple speech interface devices which may be located in the homes or other premises of many different users.

The speech interface device is configured with the support of the speech services to receive and respond to spoken requests by the user . The components of the speech services receive one or more audio signals that have been processed by the audio processing components and perform various types of processing in order to understand the intent or meaning expressed by user speech. Generally the speech services are configured to a receive a signal representing user speech b analyze the signal to recognize the user speech c analyze the user speech to determine a meaning of the user speech and d generate output speech that is responsive to the meaning of the user speech. As an example the meaning of the user speech may correspond to a request for a report of a signal strength of the RF signal between the Wi Fi communications interface of the speech interface device and the Wi Fi access point and the output speech may be generated to indicate the signal strength of the RF signal.

The speech services may include an automatic speech recognition ASR component that recognizes human speech in the received audio signal. The ASR component creates a transcript of words represented in the directional audio signals. The speech services may also include a natural language understanding NLU component that is configured to determine user intent based on recognized speech of the user . The NLU component analyzes a word stream provided by the ASR component and produces a representation of a meaning of the word stream. For example the NLU component may use a parser and associated grammar rules to analyze a sentence and to produce a representation of a meaning of the sentence in a formally defined language that conveys concepts in a way that is easily processed by a computer. The meaning may be semantically represented as a hierarchical set or frame of slots and slot values where each slot corresponds to a semantically defined concept. NLU may also use statistical models and patterns generated from training data to leverage statistical dependencies between words in typical speech.

The speech services may be implemented in part by a text to speech or speech generation component that converts text to audio for generation at the loudspeaker .

The speech processing components may also include a dialog management component that is responsible for conducting speech dialogs with the user in response to meanings of user speech determined by the NLU component .

The speech interface device may have domain logic that is used by the NLU component and the dialog management component to analyze the meaning of user speech and to determine how to respond to the user speech. The domain logic may define rules and behaviors relating to different information or topic domains such as news traffic weather to do lists shopping lists music home automation retail services and so forth. The domain logic maps spoken user statements to respective domains and is responsible for determining dialog responses and or actions to perform in response to user utterances. Suppose for example that the user requests Play music. In such an example the domain logic may identify the request as belonging to the music domain and may specify that the speech interface device respond with the responsive speech Play music by which artist 

In addition to other domains the domain logic may define a status reporting domain that specifies how to handle spoken requests regarding various types of status of the speech interface device and supporting services. For example the status reporting domain may include logic and or rules for responding to questions such as What is the current signal strength What is your IP address What is the status of my email service etc.

In some embodiments the speech services may maintain a device status cache in the memory wherein the device status cache maintains and repeatedly updates current status of the speech interface device . For example the speech interface device may communicate periodically with the speech services and may enumerate multiple status parameters and state values for storage in the device status cache. Upon receiving a request for device status the speech services may access the device status cache to obtain the requested status for reporting to the user.

In certain embodiments the primary mode of user interaction with the speech interface device may be through speech. For example the speech interface device may receive spoken commands from the user and provide services in response to the commands. The user may speak a predefined trigger expression e.g. Awake which may be followed by instructions or directives e.g. I d like to go to a movie. Please tell me what s playing at the local cinema. . Provided services may include performing actions or activities rendering media obtaining and or providing information providing information via generated or synthesized speech via the speech interface device initiating Internet based services on behalf of the user and so forth.

Furthermore the speech interface device may lack typical types of graphical user interface elements. For example the speech interface device may have only limited visual elements such as a small number of discrete indicators used to indicate basic states of the device such whether the device is on. The speech interface device may lack any sort of indicator or display for displaying status information such as communication parameters or signal strengths.

In operation the speech interface device detects an utterance of the trigger expression and in response begins streaming an audio signal containing subsequent user speech to the network based speech services . The speech services may perform ASR NLU dialog management and speech generation as described above. Upon identifying an intent of the user and or an action that the user is requesting the network based speech services direct the speech interface device to perform an action and or may perform an action using other network based services . For example the network based speech services may determine that the user is requesting a taxi and may communicate with an appropriate network based service to summon a taxi to the location of the speech interface device . As another example the network based speech services may determine that the user is requesting status information and may generate speech for playback by the speech interface device indicating the requested status information.

The techniques described herein may be implemented in conjunction with various different types of devices such as telecommunications devices and components hands free communication devices entertainment devices media playback devices and other devices.

An action performed by the speech interface device comprises receiving or producing an input audio signal using one or more microphones of the speech interface device and the audio processing components . The input audio signal represents user speech such as user speech following a user utterance of a trigger expression.

An action comprises sending the input audio signal to the network based speech services for automatic speech recognition ASR and natural language understanding NLU in order to determine that the user speech comprises a request for a status such as a status of data communications with the network based service . The action may be performed by the speech services interface and the network communications interface of the speech interface device . An action performed by the speech services comprises receiving the input audio signal using the communications interface of the server .

An action comprises analyzing the input audio signal to determine the meaning and or intent of the user speech. This may include ASR in which the received audio signal is analyzed to recognize the words contained in the user speech. The action may also include NLU in which the words of the speech are analyzed to determine their meaning or intent. In the embodiments described herein the action may comprise determining that the meaning of the user speech corresponds to a request for status information such as a request for a quality metric regarding performance of the wireless communication channel between the speech interface device and the network based services . As an example the user speech may correspond to a request for the signal strength of the Wi Fi connection being used by the speech interface device . Similarly the requested quality metric may relate to communication speeds communication latencies data loss rates etc. Furthermore the requested status information may relate to other operational characteristics of the system such as device and network settings other performance indicators device and network status device and network configuration battery information status of peripheral devices such as Bluetooth devices that have been associated with the speech interface device firmware or software version information device or system diagnostic information status of the network based service system diagnostic information etc.

In some cases the user request may relate to a status of the speech interface device that is already known to the speech services . For example the user request may relate to a status of communications between the speech interface device and the server . This information may be available from the communications interface and or from drivers associated with the communications interface.

In some cases the user request may relate to a status of the speech interface device which has been stored in the device status cache and periodically updated in response to communications from the speech interface device . As described above the speech interface device may provide current status values parameters and other information to the speech services . The speech interface device may provide a full set of status parameters periodically or may notify the speech services in response to changes in certain status parameters.

An action comprises querying the speech interface device for data such as for one or more parameters that correspond to or are relevant to the requested status information. For example the action may comprise sending a query for a status of data communications by the speech interface device with the network based services . Parameters indicating the status of data communications may include signal strengths data latencies communication speeds addresses and so forth.

The action may comprise a network communication from the server to the speech services interface of the speech interface device . An action performed by the speech services interface comprises receiving the status query from the speech services .

In response to receiving the query from the speech services the speech interface device performs an action of obtaining the requested status parameters. For example this may comprise determining status of or parameters relating to data communications with the network based services .

In some cases the action may be performed by calling an API of the status monitor and or of one or more of the drivers . For example the status monitor may in some embodiments comprise one or more interface management APIs that are provided by the operating system to provide information regarding communication interfaces of the speech interface device such as Bluetooth interfaces and Wi Fi interfaces. Such interface management APIs may provide a received signal strength indicator RSSI regarding each interface indicating the signal strength of RF signals associated with the each interface. More generally APIs may be available for providing various different types of device information not limited to parameters relating to communications. For example information may be available for battery levels and power management.

After obtaining the requested parameters an action comprises sending data indicating the determined status or parameters to the server and to the speech services . An action performed by the speech services comprises receiving the requested status or parameters.

Returning to an action performed by the speech services comprises determining sound to be produced by the speech interface device in response to the user request. A subsequent action comprises specifying the sound to the speech interface device .

In some cases the actions and may be performed at least in part by the dialog management component and the speech generation component . For example the dialog management component may determine an appropriate speech response that states or otherwise describes the requested status information based on the one or more parameters received from the speech interface device . The speech generation component may be used to generate an audio signal representing the speech response which may be provided to the speech interface device .

In an action the speech interface device receives a sound specification from the speech services where the sound specification comprises an audio signal representing speech indicating the requested status. An action comprises producing the speech such as by playing the specified sound on the loudspeaker of the speech interface device.

In some embodiments the generated output speech may instruct the user regarding how to improve a reported performance parameter such as a parameter relating to wireless communications quality between the speech interface device and the network based services . For example the speech services may conduct a speech dialog with the user in which the user is stepped through a series of troubleshooting steps. The user may be asked to move the speech interface device as an example. As the user moves the speech interface device the device may generate a tone having a loudness or frequency that changes in accordance with the value of the parameter that the user is trying to improve. For example the device may generate beeps at a frequency that increases as the Wi Fi signal strength of the device increases.

In different embodiments the actions and may comprise specifying a sound in other ways such as by sending a sound identifier or sending an instruction for the speech interface device to play a certain sound without actually providing an audio signal representing the sound. For example the speech services may send an instruction for the speech interface device to play an earcon and may specify an identifier that has been previously associated with the earcon. The speech interface device may have data such as sound recordings corresponding to the earcon which the speech interface device may play on the loudspeaker in response to receiving the instruction from the speech services . The speech interface device may be configured to receive an instruction to play a sound to synthesize or obtain the sound and the produce the sound on the loudspeaker .

An earcon comprises any type of sound that is uniquely associated with an event or condition. An earcon may sound like a normally occurring sound such as a chime bell whistle etc. Alternatively an earcon may comprise a tone a sequence of tones a tune or melody and or any other combination of sounds that are recognizable to a user as being associated with a particular type of status or event.

The action may be omitted in some implementations. In such implementations the actions and may comprise generally instructing the speech interface device to play a certain type or category of sound corresponding to a specified device parameter where some characteristic of the sound is determined by the value of the device parameter. For example the action may comprise instructing the speech interface device to play a tone having a loudness that corresponds to the wireless signal strength of the device . In response the speech interface device may determine the signal strength and play the tone with a corresponding loudness.

As another example the action may comprise determining speech that introduces or describes a parameter without actually stating the parameter essentially leaving a blank space in the speech for the parameter. The speech interface device may provide additional speech corresponding to the parameter. For example the action may comprise providing a speech template such as the value of the requested parameter is along with an instruction for the speech interface device to provide and insert speech indicating a numeric value of the requested parameter.

An action comprises monitoring one or more status parameters over time. For example the action may comprise monitoring a wireless communications parameter relating to communications between the speech interface device and the Wi Fi access point . As a more specific example the action may comprise monitoring the RF signal strength between the speech interface device and the Wi Fi access point which may be reflected by an RSSI obtained by calling an interface management API of the speech interface device .

An action comprises detecting a condition of the speech interface device such as detecting a change in the status of the speech interface device . For example the action may comprise determining whether a monitored performance parameter is decreasing and or is currently below or outside a performance threshold. If not the action continues to monitor the quality metric. If the monitored performance parameter is decreasing and or is currently below or outside the quality threshold an action is performed of notifying the speech services of the change in the status. For example the speech services interface may communicate with the speech services to indicate one or more status parameters and to notify the speech services that one or more of the status parameters are out of limits.

As a specific example the actions and may comprise detecting a decrease in a performance parameter where the performance parameter indicates a quality of communications with the network based service . In some cases such a performance parameter may comprise a signal strength or RSSI of an RF signal used by a wireless communications interface. As another example the actions and may comprise detecting a nearly depleted battery level. In some cases the action may comprise comparing a performance parameter with a threshold to determine whether the performance parameter is out of limits.

An action performed by the speech services comprises receiving a notification from the speech interface device regarding the changed or changing status. In response the speech services perform an action of determining sound to be produced by the speech interface device in response to the changed status. A subsequent action comprises specifying the sound to the speech interface device .

The action may comprise determining appropriate speech that states or otherwise describes the changed status information and or a condition or state corresponding to the changed status information based on the one or more parameters received from the speech interface device . The speech generation component may be used to generate an audio signal representing the speech which may be provided to the speech interface device .

In an action the speech interface device receives a sound specification from the speech services where the sound specification comprises an audio signal representing speech indicating the requested status. An action comprises producing the speech such as by playing the specified sound on the loudspeaker of the speech interface device.

In different embodiments the actions and may comprise specifying a sound in other ways such as by sending a sound identifier or sending an instruction for the speech interface device to play a certain sound without actually providing an audio signal representing the sound. For example the speech services may send an instruction for the speech interface device to play an earcon and may specify an identifier that has been previously associated with the earcon. The speech interface device may have data such as sound recordings corresponding to the earcon which the speech interface device may play on the loudspeaker in response to receiving the instruction from the speech services . The speech interface device may be configured to receive an instruction to play a sound to synthesize or obtain the sound and the produce the sound on the loudspeaker .

In some embodiments the generated output speech may instruct the user regarding how to improve a reported performance parameter such as a parameter relating to wireless communications quality between the speech interface device and the network based services . For example the speech services may conduct a speech dialog with the user in which the user is stepped through a series of troubleshooting steps. The user may be asked to move the speech interface device as an example.

After the action the method repeats to continually monitor the quality metric over time. Note that the method may be performed with respect to multiple types of statuses including different performance parameters and quality metrics relating to the speech interface device the network based service and other components.

In implementation the method may be implemented so that a sound corresponding to a detected status is produced by the speech interface device an appropriate number of times and or at an appropriate time interval depending on the nature and importance of the status. For example some types of status may be reported only a single time even though a particular status may continue to exist over a long time period. Other types of status may be reported repeatedly at an appropriate time interval until the status is corrected and or until the user acknowledges hearing the status. The frequency of status reports may vary depending on the severity of the reported condition and or the level of interference with device operation that may result from the condition.

In some embodiments the actions and may be performed by the speech services or by a component of the speech services instead of being performed by the speech interface device . In particular in embodiments in which the speech services maintain and update a device status cache the action may comprise monitoring parameters stored and updated in the status cache in response to periodic or continuous updates of the status cache by the speech interface device . The actions and may not be necessary in these embodiments.

The method results in audible status notifications in response to a condition detected in the action . Generally the condition may relate to things other than status values or changes. For example the system may be configured to report status information when it has been instructed to operate in a monitoring or log mode. In this mode audible reports may be given in response to any system event such as a communications error a speech recognition error a low battery event etc. Similarly when in a monitor mode the speech interface device may repeatedly report a particular status or parameter so that the user can tell when the parameter increases or decreases.

Status notifications may relate to observed parameters and may also specify more complex information such as the results of system commands. As an example an audible system notification may comprise the results of a traceroute command which is a command that identifies servers through which communications pass between the speech interface device and the speech services .

Although the preceding describes several specific configurations in which a speech interface device might play speech indicating system status or configuration such speech may be similarly generated in other situations to report system status and configuration. For example the speech interface device may be responsive to an audible or inaudible tone to generate and play speech regarding one or more quality or performance metrics. As a specific use scenario a remote technician may use this capability by generating a tone over a telephone in order to instruct the speech interface device to generate speech that enumerates a number of system parameters and metrics. Similarly in some cases a remote technician may send instructions to the speech interface device using network communications instructing the speech interface device to generate speech that describes different types of parameters and metrics relating to device operation.

As another use scenario a speech interface device may be configured to report operational parameters metrics and quality measures upon startup of the device or to report any such parameters metrics or quality measures that may result in a degradation of user experience. Such parameters metrics and quality measures may be reported by speech as described above or by different types of sounds associated with different conditions.

Although the subject matter has been described in language specific to structural features it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features described. Rather the specific features are disclosed as illustrative forms of implementing the claims.

