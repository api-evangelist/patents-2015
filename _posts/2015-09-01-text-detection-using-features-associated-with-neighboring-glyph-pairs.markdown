---

title: Text detection using features associated with neighboring glyph pairs
abstract: A multi-orientation text detection method and associated system is disclosed that utilizes orientation-variant glyph features to determine a text line in an image regardless of an orientation of the text line. Glyph features are determined for each glyph in an image with respect to a neighboring glyph. The glyph features are provided to a learned classifier that outputs a glyph pair score for each neighboring glyph pair. Each glyph pair score indicates a likelihood that the corresponding pair of neighboring glyphs form part of a same text line. The glyph pair scores are used to identify candidate text lines, which are then ranked to select a final set of text lines in the image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09367736&OS=09367736&RS=09367736
owner: Amazon Technologies, Inc.
number: 09367736
owner_city: Seattle
owner_country: US
publication_date: 20150901
---
An image captured by a camera or a scanned image of a physical document may include text characters as well as other non text shapes or symbols. Various methods are known for detecting text in an image. These existing methods suffer from various drawbacks. Technical solutions that address at least some of these drawbacks are discussed herein.

This disclosure relates to among other things systems devices methods and computer readable media for detecting text in an image where the text may be oriented in different directions in the image. An image may include for example a still image captured by a camera a video frame in a video stream captured by a video camera a scanned image of a physical document or the like. An example image may include for example certain text that is oriented in a horizontal direction in the image and or certain text that is oriented in a vertical direction in the image. Horizontally oriented text and vertically oriented text may be rotated with respect to each other by 90 degrees. It should be appreciated that the terms horizontal and vertical or variations thereof are used herein merely to denote text having different e.g. orthogonal orientations and not to indicate an inherent characteristic of the text. In particular whether a particular line of text in an image is deemed to be horizontally or vertically oriented may depend on the perspective of an observer of the image e.g. an orientation of an observer with respect to the image . It should further be appreciated that text in an image may be oriented in any intermediate direction between a reference horizontal direction and a reference vertical direction e.g. diagonally oriented . In addition a line of text may be deemed to be horizontally oriented or vertically oriented even if each character in the line of text is not aligned along a reference horizontal axis or a reference vertical axis whichever the case may be. For example a particular character may be deemed to have the same orientation as another character even if one or both characters deviate from a reference line defining a reference orientation as long as the deviation is within a permissible tolerance.

An image may include one or more glyphs. Each glyph may correspond to a particular group of image pixels in the image. More specifically a glyph may be any symbol in an image that is represented by a group of connected image pixels. Each image pixel in the group may have a pixel value that differs from a pixel value of an image pixel forming part of a background portion of the image. The term connected may refer to each image pixel in the group being adjacent to at least one other image pixel in the group. For two dimensional images two image pixels may be adjacent if they share a common edge or corner. For three dimensional images two image pixels may be adjacent if they share a common edge corner or face. In certain example embodiments each image pixel in a group of image pixels corresponding to a same glyph may have a respective pixel value that deviates from a pixel value of a background image pixel by more than a first threshold value and that is within a second threshold value of a respective pixel value of each other image pixel in the group. The range of pixel values within which a pixel value of an image pixel may fall may depend on the type of image e.g. an 8 bit grayscale image may allow for 256 different pixel values while a 16 bit color image may allow for 2different pixel values .

A variety of text detection methods are known. For example one category of text detection methods involves segmenting an image into groups of image pixels e.g. glyphs and merging multiple groups of image pixels into lines of text. First learned or hard coded rules are typically used to group glyphs into pairs and then multiple pairs of glyphs are merged into text lines. These existing text detection methods suffer from various drawbacks. In particular these existing methods either utilize only orientation invariant glyph features or utilize orientation variant glyph features but assume a particular text line orientation e.g. a horizontal orientation .

Glyph features may include orientation variant or orientation invariant features. Example orientation invariant features may include for example glyph color e.g. pixel values of one or more image pixels representing the glyph glyph stroke width glyph convexity e.g. a measure of the curvature of one or more portions of the glyph glyph area e.g. an area of a portion of an image occupied by a glyph glyph perimeter e.g. a perimeter of a bounding box that encompasses a glyph and so forth. The values of orientation invariant glyph features may remain unchanged regardless of the orientation of a line of text that includes the glyph. On the other hand orientation variant glyph features may include for example glyph height glyph width and so forth. Glyph height and glyph width may be orientation variant features because the values of these glyph features may change depending on the orientation of a text line that includes the glyph. For example a glyph height of a glyph in a horizontally oriented line of text may become a glyph width of the glyph if the glyph forms part of vertically oriented line of text and vice versa. Similarly a glyph width of a glyph in a horizontally oriented line of text may become a glyph height of a glyph in a vertically oriented line of text.

Existing text detection methods that utilize only orientation invariant glyph features ignore orientation variant glyph features such as glyph height and glyph width that may prove more beneficial than orientation invariant features for accurately determining the glyph composition of text lines. Further as noted earlier existing text detection methods that utilize orientation invariant features necessarily assume a particular text orientation e.g. a horizontal orientation and thus may fail to identify text lines having a different orientation e.g. a vertical orientation than the assumed orientation.

Example embodiments of the disclosure relate to systems devices methods and computer readable media that utilize a multi orientation text detection algorithm that addresses the drawbacks noted above with respect to existing text detection methods. In particular a multi orientation text detection algorithmic process in accordance with example embodiments of the disclosure is capable of utilizing orientation variant glyph features to determine text lines in an image that may be orientated in any direction.

The user device may include a display on which the image may be rendered. The display may be for example an electrophoretic display an electrowetting display a liquid crystal display LCD an organic light emitting diode OLED display or the like. The display may be integrated with the user device or may be a peripheral device e.g. a display monitor operatively coupled to the user device . The user device may further include a touch sensor capable of detecting touch events. The touch sensor may be a resistive or a capacitive touch sensor. The user device may be configured to control the display to render the image in response to touch events detected by the touch sensor.

The image may include various glyphs. Each glyph may be a group of connected image pixels in the image . Each glyph may be a symbol in the image. The symbol may be a particular visual appearance of a text character or may be a non text symbol such as a shape. A text character may be a group of image pixels that corresponds to a grapheme or a grapheme like unit such as in an alphabet or syllabary in the written form of a natural language. Example text characters may include without limitation letters numerical digits punctuation marks special characters e.g. etc. or the like.

While the multi orientation text detection process may be described as being performed on the user device it should be appreciated that any of the depicted program modules may reside on a remote server with one or more program modules potentially distributed across multiple remote servers and or across one or more remote servers and the user device . Thus in certain example embodiments any output data generated by any of the program modules may be transmitted from a remote server to the user device or vice versa for further processing by the receiving device such as for example for providing the received output data as input data to another program module. Further in certain example embodiments all of the depicted program modules may reside on one or more remote servers and the final output of the multi orientation text detection process a final set of text lines in the image may be transmitted over one or more networks to the user device .

As an initial step in the process glyph data may be received by one or more neighboring glyph determination module s . The glyph data may include position coordinates for each glyph that identify a location of the group of image pixels that correspond to the glyph within the image . The glyph data may be generated using for example a Maximally Stable Extremal Regions algorithm.

Upon receipt of the glyph data the neighboring glyph determination module s may determine neighboring glyph pairs among the various glyphs in the image . Any of a variety of suitable approaches may be employed for determining a neighboring glyph pair. For example for a pair of candidate neighboring glyphs including a first glyph and a second glyph the neighboring glyph determination module s may determine a first radius associated with the first glyph and a second radius associated with the second glyph. More specifically the neighboring glyph determination module s may determine a first bounding box that encompasses the first glyph and a second bounding box that encompasses the second glyph. A bounding box may be a group of boundary image pixels that forms a rectangular boundary such that each image pixel in a group of image pixels corresponding to a glyph is contained within the boundary. A bounding box having the smallest perimeter that still contains all of the image pixels of a glyph may be chosen.

A height and a width of the first bounding box and a height and a width of the second bounding box may then be determined. The height and the width of a bounding box associated with a glyph may differ based on an orientation defined by the glyph and a neighboring glyph. For example the height value and the width value determined for the first boundary box may vary depending on whether the combination of the first glyph and the second glyph is horizontally oriented or vertically oriented. In certain example embodiments the height and width values of the first bounding box or the second bounding box may be reversed if the first glyph and the second glyph are vertically oriented instead of horizontally oriented or vice versa.

The neighboring glyph determination module s may then determine a first radius associated with the first glyph and a second radius associated with the second glyph. The first radius may be a value that is proportional to at least one of the height or the width of the first bounding box. Similarly the second radius may be a value that is proportional to at least one of the height or the width of the second bounding box. In certain example embodiments the radius associated with a glyph may be equal to the greater of the height or the width of a bounding box associated with the glyph multiplied by a proportionality constant. As a non limiting example the first radius of the first glyph may be proportional to the height of the first glyph. The height of the first glyph may be a distance between two pixels of the first glyph that are located farthest from each other when the first glyph is projected onto an axis that is perpendicular to an axis defining an orientation of the pair of the first glyph and the second glyph. As a non limiting example the second radius of the second glyph may be similarly determined.

The neighboring glyph determination module s may then determine a glyph distance between the first glyph and the second glyph. The glyph distance may be a distance between a center of the first glyph and a center of the second glyph. In certain example embodiments a first set of one or more image pixels representative of a center of the first glyph may be determined and a second set of one or more image pixels representative of a center of the second glyph may be determined. An average distance between the first set of pixel s and the second set of pixel s may then be determined as the glyph distance. In other example embodiments the distance between the first glyph and the second glyph may be a minimum distance between any pixel of the first glyph and any pixel of the second glyph. This minimum distance may be computed by projecting each of the first glyph and the second glyph onto the axis defining an orientation of the first glyph and the second glyph.

The neighboring glyph determination module s may then determine whether the glyph distance is within at least one of the first radius or the second radius. More specifically the neighboring glyph determination module s may determine whether the glyph distance is at least within the larger of the first radius or the second radius. If the neighboring glyph determination module s determine that the glyph distance between the first glyph and the second glyph is within at least one of the first radius or the second radius the first glyph and the second glyph may be determined to be a neighboring glyph pair.

Glyphs within a neighboring glyph pair may be oriented in any direction in the image . For example depicts an example neighboring glyph pair in which the constituent glyphs are oriented in a horizontal direction and an example neighboring glyph pair in which the constituent glyphs are oriented in a vertical direction. Further in certain example embodiments a glyph and a first neighboring glyph may be oriented in a first direction e.g. a horizontal direction while the glyph and a second neighboring glyph may be oriented in a second direction e.g. a vertical direction . For example the glyph pair that includes the glyph o and the glyph x may be a first neighboring glyph pair that includes the glyph o and the glyph pair may be a second glyph pair that may also include the glyph o but that is oriented in a different direction from the glyph pair . In addition in certain example embodiments multiple candidate neighboring glyphs each of which is oriented in a same direction with respect to a glyph may be located respective distances from the glyph that are each within the radius of the glyph. In such example embodiments a candidate neighboring glyph that is the closest distance to the glyph may be selected as a neighboring glyph for the glyph.

The set of neighboring glyph pairs identified by the neighboring glyph determination module s may be provided as input to one or more glyph pair feature value computation module s . The glyph pair feature value computation module s may determine values of one or more glyph pair features for each glyph in the image . More specifically the glyph pair feature value computation module s may determine one or more glyph pair feature values for each glyph with respect to each neighboring glyph that forms a glyph pair with the glyph. For example assume that glyph A is associated with neighboring glyphs B and C. The glyph pair feature value computation module s may determine a glyph height a glyph width a glyph color a glyph convexity a glyph distance etc. for glyph A with respect to neighboring glyph B and may independently determine values of these glyph pair features for glyph A with respect to neighboring glyph C. As previously noted a multi orientation text detection process in accordance with example embodiments of the disclosure may determine values for orientation variant glyph pair features such as glyph height and glyph width. If for example the neighboring glyph pair that includes glyph A and glyph B has a first orientation that differs from a second orientation of the neighboring glyph pair that includes glyph A and glyph C then the glyph height and glyph width determined for glyph A with respect to glyph B may differ e.g. may be reversed if the orientations are orthogonal to each other from the glyph height and glyph width determined for glyph A with respect to glyph C.

The glyph pair feature values determined for each glyph in the image with respect to each of its neighboring glyphs regardless of orientation may be provided as input to a learned classifier . The learned classifier may include one or more machine learning modules configured to generate a glyph pair score for each pair of neighboring glyphs based at least in part on the glyph pair feature values that were determined for each glyph in the neighboring glyph pair with respect to the other glyph in the neighboring glyph pair.

The learned classifier may be trained using a ground truth dataset in which neighboring glyph pairs are labeled as either belonging to the same text line or not. For example glyph pair feature values associated with each glyph in a neighboring glyph pair known to form part of the same text line in a ground truth image may be provided as a positive sample to train the learned classifier . Conversely glyph pair feature values associated with each glyph in a neighboring glyph pair known to not form part of the same text line in a ground truth image may be provided as a negative sample to train the learned classifier . A neighboring glyph pair from the ground truth image that is known to not form part of the same text line may include at least one non character symbol e.g. a background symbol in the ground truth image .

Based on the sample dataset used to train the learned classifier the learned classifier may determine using the corresponding glyph pair feature values a glyph pair score for each pair of neighboring glyphs . The glyph pair score for each neighboring glyph pair may be any suitable quantitative measure of the likelihood that the constituent glyphs of the neighboring glyph pair form part of a same text line in the image . For example the glyph pair score may be a probabilistic value or any other suitable normalized value.

One or more candidate text line determination module s may then receive the glyph pair score for each neighboring glyph pair as input. The candidate text line determination module s may be configured to determine a set of candidate text lines based at least in part on the received glyph pair scores . In certain example embodiments the candidate text line determination module s may generate a data structure that represents each glyph and its relationship with neighboring glyph s . For example the candidate text line determination module s may generate a graph that includes a plurality of nodes where each node is connected to at least one other node of the graph by a corresponding edge. Each node may represent a glyph in the image and each edge connecting two nodes may represent the glyph pair score associated with a neighboring glyph pair represented by the two connected nodes. The length of each edge for example may be indicative of the glyph pair score determined for the neighboring glyph pair represented by the two nodes connected by the edge.

For a given selected glyph the candidate text line determination module s may then determine a neighboring glyph that forms part of a neighboring glyph pair with the selected glyph having a highest glyph pair score among all neighboring glyph pairs that include the selected glyph. For example the candidate text line determination module s may locate a first node in the graph corresponding to a selected glyph. The candidate text line determination module s may then locate an edge in the graph that is connected to the first node and that represents the highest glyph pair score associated with the first node. The candidate text line determination module s may then determine a second node in the graph that is connected to the first node via the located edge. The first node and the second node may represent a first glyph and a second glyph respectively forming part of a neighboring glyph pair having the highest associated glyph pair score among all neighboring glyph pairs that include the first glyph.

The candidate text line determination module s may compare the glyph pair score associated with the neighboring glyph pair that includes the first glyph and the second glyph to one or more threshold values to determine whether the neighboring glyph pair is suitable for selection as a seed pair of glyphs for determining a corresponding candidate text line . For example the candidate text line determination module s may determine whether the glyph pair score satisfies a first threshold value and whether the glyph pair score satisfies a second threshold value greater than the first threshold value. The glyph pair score may be compared against the first threshold value to determine whether at least one of the first glyph or the second glyph is a background glyph in the image . If the glyph pair score satisfies the first threshold value the candidate text line determination module s may determine that neither the first glyph nor the second glyph is a background glyph.

Further the glyph pair score may be compared against the second threshold value to determine whether the first glyph and the second glyph form a suitable neighboring glyph pair for determining a candidate text line . For example the first glyph and the second glyph may constitute the first two glyphs in a text line in which case the first glyph may be a capitalized letter. In such a scenario the first glyph and the second glyph may not form a suitable glyph pair for determining a candidate text line . This may be reflected by the glyph pair score associated with the first glyph and the second glyph not satisfying the second threshold value. As another example the first glyph and the second glyph may constitute two neighboring glyphs neither of which is an end glyph within a text line. In such a scenario the first glyph and the second glyph may form a suitable glyph pair for determining a candidate text line and this may be reflected by the corresponding glyph pair score satisfying the second threshold value. It should be appreciated that a first value may satisfy a second value is the first value is greater than or equal to a second value.

If the candidate text line determination module s determine that the glyph pair score associated with the neighboring glyph pair that includes the first glyph and the second glyph satisfies one or more threshold values e.g. the first threshold value and the second threshold value described above the first glyph and the second glyph may be selected as a seed pair of glyphs for determining a corresponding candidate text line . The graph may then be traversed to identify each additional node that is representative of a corresponding glyph that is aligned in orientation with an orientation of the neighboring glyph pair that includes the first glyph and the second glyph. Each such additional node may be directly connected to the first node or the second node via a corresponding edge or may be indirectly connected to the first node or the second node via one or more intervening additional nodes and corresponding edges. The first glyph the second glyph and each additional glyph aligned in orientation with an orientation of the neighboring glyph pair that includes the first glyph and the second glyph may together be identified as a candidate text line.

The candidate text line determination module s may repeat the above process for each glyph in the image to obtain a set of candidate text lines . Each candidate text line may have any orientation within the image e.g. a horizontal orientation a vertical orientation a diagonal orientation etc. . Moreover a particular glyph may occur in more than one candidate text line including for example candidate text lines having different orientations. For example as shown in the glyph o occurs in candidate text line having a horizontal orientation and also occurs in candidate text line having a vertical orientation. In addition different seed pairs of neighboring glyphs may yield the same candidate text line and conversely the same seed pair of neighboring glyphs may occur in different candidate text lines. For example the same seed pair of neighboring glyphs may result in a first candidate text line that includes a particular glyph that is offset from one or more other glyphs in the first candidate text line in a first direction and may also result in a second candidate text line that does not include that particular glyph but instead includes a different glyph that is offset from one or more other glyphs in the second candidate text line in an opposing direction.

The set of candidate text lines determined by the candidate text line determination module s may be provided to one or more text line feature value computation modules . The text line feature value computation module s may determine value s of one or more text line features for each candidate text line. A text line feature value may include without limitation a number of glyphs included in a candidate text line e.g. a length of the candidate text line an average of a set of glyph pair scores where each glyph pair score corresponds to a particular pair of neighboring glyph pairs in the candidate text line a metric indicative of a curvature of a candidate text line a metric indicative of a variance in individual glyph feature values associated with each glyph in the candidate text line e.g. a variance in glyph height values for the constituent glyphs of the candidate text line where the glyph heights may be determined based on an orientation of the text line a variance in glyph color a variance in stroke width etc. and so forth.

The set of text line feature values determined for each candidate text line may then be provided as input to one or more candidate text line ranking modules . The candidate text line ranking module s may then rank the set of candidate text lines based at least in part on the set of text line feature values determined for each candidate text line. More specifically the candidate text line ranking module s may generate a score for each candidate text line e.g. a weighted combination of one or more text line feature values associated with the candidate text line that indicates a likelihood that the candidate text line represents an actual text line in the image . The candidate text line ranking module s may then rank the set of candidate text lines in accordance with their respective scores.

The ranked set of candidate text lines may then be provided to one or more conflict resolution module s . The conflict resolution module s may resolve any conflicts that may exist between the candidate text lines. A conflict may exist if the same glyph is present in more than one distinct candidate text line. For a particular glyph the conflict resolution module s may determine the highest ranked candidate text line in which the glyph appears and may then proceed to remove that glyph from each lower ranked candidate text line in which it also appears. After removing duplication of a glyph from one or more lower ranked candidate text lines the candidate text line ranking module s may determine an updated ranking for each candidate text line that was modified. This process may proceed iteratively for each glyph that appears in more than one candidate text line until a final set of candidate text lines are obtained each of which includes a unique combination of glyphs from the image . This final set of candidate text lines output by the multi orientation text detection algorithm may be assumed to be a final set of actual text lines in the image .

In addition in certain example embodiments a candidate text line may include a background glyph. For example the candidate text line may include the background glyph . In particular even if a neighboring glyph pair that includes the background glyph is not chosen as a seed pair because the corresponding glyph pair score fails to satisfy a corresponding threshold value the background glyph may nonetheless be included in a candidate text line that is identified using another seed pair of neighboring glyphs. In such example embodiments the candidate text line ranking module s may assign a lower ranking to the candidate text line than to a candidate text line that includes all glyphs of the candidate text line except for the background glyph in which case the candidate text line that excludes the background glyph may be identified as an actual text line in the image .

One or more illustrative embodiments of the disclosure have been described above. The above described embodiments are merely illustrative of the scope of this disclosure and are not intended to be limiting in any way. Accordingly variations modifications and equivalents of embodiments disclosed herein are also within the scope of this disclosure. The above described embodiments and additional and or alternative embodiments of the disclosure will be described in detail hereinafter through reference to the accompanying drawings.

At block a set of glyphs in an image may be determined. More specifically glyph data may be determined for each glyph in the set of glyphs. The glyph data may include for example position coordinates for each glyph that identify a location of the group of image pixels that correspond to the glyph within the image. The glyph data may be generated using for example a Maximally Stable Extremal Regions algorithm.

At block an identification of the set of glyphs and the corresponding glyph data may be received by the neighboring glyph determination module s which may proceed to determine neighboring glyph pairs among the various glyphs in the image. Any of the approaches previously described may be employed for determining a neighboring glyph pair. For example the neighboring glyph determination module s may determine a first radius associated with a first glyph and a second radius associated with a second glyph. As previously described the first radius may be a value that is proportional to at least one of a height or a width of a bounding box associated with the first glyph. Similarly the second radius may be value that is proportional to at least one of a height or a width of a bounding box associated with the second glyph.

The neighboring glyph determination module s may then determine a glyph distance between the first glyph and the second glyph and may further determine whether the glyph distance is within e.g. less than or equal to at least one of the first radius or the second radius. If the neighboring glyph determination module s determine that the glyph distance is within the first radius and or the second radius the first glyph and the second may be determined to be a neighboring pair of glyphs. The neighboring glyph determination module s may in this manner determine one or more neighboring glyphs for each glyph in the set of glyphs in the image.

Glyphs within a neighboring glyph pair may be oriented in any direction in the image. Further in certain example embodiments a glyph and a first neighboring glyph may be oriented in a first direction e.g. a horizontal direction while the glyph and a second neighboring glyph may be oriented in a second direction e.g. a vertical direction . In addition in certain example embodiments multiple candidate neighboring glyphs each of which is oriented in a same direction with respect to the glyph may be within a radius associated with a glyph. In such example embodiments the neighboring glyph determination module s may select a candidate neighboring glyph that is the closest distance to the glyph as a neighboring glyph for the glyph.

At block the glyph pair feature value computation module s may receive the set of neighboring glyph pairs identified by the neighboring glyph determination module s at block and may determine values of one or more glyph pair features for each pair of neighboring glyphs in the image. More specifically the glyph pair feature value computation module s may determine one or more glyph pair feature values for each glyph with respect to each neighboring glyph pair that contains that glyph.

At block the glyph pair feature values determined for each glyph in the image with respect to each of its neighboring glyphs regardless of orientation may be provided as input to a learned classifier . The learned classifier may include one or more machine learning modules configured to generate a glyph pair score for each pair of neighboring glyphs based at least in part on the glyph pair feature values that were determined for each glyph in the neighboring glyph pair with respect to the other glyph in the neighboring glyph pair. More specifically based on a sample dataset used to train the learned classifier the learned classifier may determine using the corresponding glyph pair feature values a glyph pair score for each pair of neighboring glyphs. The glyph pair score for each neighboring glyph pair may be any suitable quantitative measure of the likelihood that the constituent glyphs of the neighboring glyph pair form part of a same text line in the image.

At block the candidate text line determination module s may receive the glyph pair score for each neighboring glyph pair as input and may determine a set of candidate text lines based at least in part on the received glyph pair scores. In certain example embodiments the candidate text line determination module s may generate a data structure that represents each glyph and its relationship with neighboring glyph s . As previously noted in certain example embodiments the candidate text line determination module s may generate a graph that includes a plurality of nodes where each node is connected to at least one other node of the graph by a corresponding edge. Each node may represent a glyph in the image and each edge connecting two nodes may represent the glyph pair score corresponding to a neighboring glyph pair represented by the two connected nodes.

For a given selected glyph the candidate text line determination module s may locate a first node in the graph corresponding to a selected glyph. The candidate text line determination module s may then locate an edge in the graph that is connected to the first node and that represents the highest glyph pair score associated with the first node. The candidate text line determination module s may then determine a second node in the graph that is connected to the first node via the located edge. The first glyph and the second glyph may be selected as a seed pair of glyphs for determining a corresponding candidate text line. In certain example embodiments the candidate text line determination module s may first determine that the glyph pair score associated with the first glyph and the second glyph satisfies one or more threshold values prior to selecting the first glyph and the second glyph as a seed pair of glyphs.

The graph may then be traversed to identify each additional node that is representative of a corresponding glyph that is aligned in orientation with an orientation of the neighboring glyph pair that includes the first glyph pair and the second glyph pair. The first glyph the second glyph and each additional glyph aligned in orientation with an orientation of the neighboring glyph pair that includes the first glyph pair and the second glyph pair may together be identified as a candidate text line. The candidate text line determination module s may repeat the above process for each glyph in the image to obtain a set of candidate text lines.

At block the text line feature value computation module s may receive the set of candidate text lines as input and may determine value s of one or more text line features for each candidate text line. As previously noted a text line feature value may include without limitation a number of glyphs included in a candidate text line an average of a set of glyph pair scores where each glyph pair score corresponds to a particular pair of neighboring glyph pairs in the candidate text line a metric indicative of a curvature of a candidate text line a metric indicative of a variance in individual glyph feature values associated with each glyph in the candidate text line and so forth.

The set of text line feature values determined for each candidate text line may then be provided as input to the candidate text line ranking module s . The candidate text line ranking module s may then rank the set of candidate text lines based at least in part on the set of text line feature values determined for each candidate text line. More specifically at block the candidate text line ranking module s may generate a text line score for each candidate text line e.g. a weighted combination of one or more text line feature values associated with the candidate text line that indicates a likelihood that the candidate text line represents an actual text line in the image. Then at block the candidate text line ranking module s may rank the set of candidate text lines in accordance with their respective scores.

The ranked set of candidate text lines may then be provided to one or more conflict resolution module s . At block the conflict resolution module s may resolve any conflicts that may exist between the candidate text lines to obtain final set of text lines determined to correspond to actual text lines in the image. More specifically for a particular glyph the conflict resolution module s may determine the highest ranked candidate text line in which the glyph appears and may then proceed to remove that glyph from each lower ranked candidate text line in which it also appears. After removing duplication of a glyph from one or more lower ranked candidate text lines the candidate text line ranking module s may determine an updated ranking for each candidate text line that was modified. This process may proceed iteratively for each glyph that appears in more than one candidate text line until a final set of candidate text lines are obtained each of which includes a unique combination of glyphs from the image .

At block the neighboring glyph determination module s may determine a first glyph and a second glyph in an image. At block the neighboring glyph determination module s may determine a first bounding box that encompasses the first glyph. The first bounding box may be a group of boundary image pixels that forms a rectangular boundary such that each image pixel in the group of image pixels corresponding to the first glyph is contained within the boundary. A bounding box having the smallest perimeter that still contains all of the image pixels of the first glyph may be chosen as the first bounding box. Similarly the neighboring glyph determination module s may determine a second bounding box that encompasses the second glyph.

At block the neighboring glyph determination module s may determine a first radius associated with the first glyph. More specifically the neighboring glyph determination module s may determine a height and a width of the first bounding box. The height and the width of the first bounding box may be determined with respect to the pairing of the first glyph and the second glyph. The first radius may be a value that is proportional to at least one of the height or the width of the first glyph. Similarly the neighboring glyph determination module s may determine at block a second radius associated with the second glyph. More specifically the neighboring glyph determination module s may determine a height and a width of the second bounding box. The second radius may be a value that is proportional to at least one of the height or the width of the second glyph.

At block the neighboring glyph determination module s may determine a glyph distance between the first glyph and the second glyph. In certain example embodiments a first set of one or more image pixels representative of a center of the first glyph may be determined and a second set of one or more image pixels representative of a center of the second glyph may be determined. An average distance between the first set of pixel s and the second set of pixel s may then be determined as the glyph distance. At block the neighboring glyph determination module s may determine that the glyph distance is within at least one of the first radius or the second radius. More specifically the neighboring glyph determination module s may determine that the glyph distance is at least within the larger of the first radius or the second radius. Upon determining that the glyph distance between the first glyph and the second glyph is within at least one of the first radius or the second radius the neighboring glyph determination module s may determine that the first glyph and the second glyph are neighboring glyphs at block .

The method may be repeated with respect to any two glyphs in the image to determine if they glyphs form part of a pair of neighboring glyphs. It should be appreciated that a pair of neighboring glyphs may be oriented in any direction within the image. Further any given glyph may be oriented in a first direction e.g. a horizontal direction with respect to a first neighboring glyph and may be oriented in a second different direction e.g. a vertical direction with respect to a second neighboring glyph.

At block the candidate text line determination module s may generate a graph that includes multiple nodes and multiple edges where each edge may connect a pair of nodes representing a pair of neighboring glyphs and may represent a glyph pair score corresponding to the pair of neighboring glyphs. More specifically each node in the graph may be connected to at least one other node of the graph by a corresponding edge. Each node may represent a glyph in an image and each edge connecting two nodes may represent the glyph pair score corresponding to a neighboring glyph pair represented by the two connected nodes. The length of each edge for example may be indicative of the glyph pair score determined for the neighboring glyph pair represented by the two nodes connected by the edge.

At block the candidate text line determination module s may select a first glyph from a set of glyphs represented by corresponding nodes in the graph as a current glyph. At block the candidate text line determination module s may determine a neighboring glyph that together with the current glyph forms a glyph pair having the highest associated glyph pair score of any pair of neighboring glyphs that includes the current glyph. At block the candidate text line determination module s may determine that the glyph pair score associated with the glyph pair determined at block satisfies one or more threshold values. For example the candidate text line determination module s may determine whether the glyph pair score satisfies a first threshold value and whether the glyph pair score satisfies a second threshold value greater than the first threshold value. The glyph pair score may be compared against the first threshold value to ensure that neither glyph in the glyph pair determined at block is a background glyph in the image. The glyph pair score may be compared against the second threshold value to ensure that the glyph pair determined at block is a suitable neighboring glyph pair for determining a candidate text line.

Upon determining that the glyph pair score satisfies the one or more threshold values the candidate text line determination module s may select the glyph pair as a current seed pair of neighboring glyphs at block . Then at block the candidate text line determination module s may determine a node pair in the graph that corresponds to the current seed pair. More specifically the candidate text line determination module s may locate a first node in the graph corresponding to the current glyph. The candidate text line determination module s may then locate an edge in the graph that is connected to the first node and that represents the highest glyph pair score associated with the first node. The candidate text line determination module s may then determine a second node in the graph that is connected to the first node via the located edge. The first node and the second node may represent the current glyph and a neighboring glyph respectively forming part of a neighboring glyph pair having the highest associated glyph pair score among all neighboring glyph pairs that include the current glyph.

At block the candidate text line determination module s may traverse the graph to determine additional nodes corresponding to successive neighboring glyphs having the same orientation as the current seed pair of neighboring glyphs. More specifically the candidate text line determination module s may identify each additional node that is representative of a corresponding glyph that is aligned with an orientation of the current seed pair of neighboring glyphs. Each such additional node may be directly connected to a first node of the node pair or a second node of the node pair via a corresponding edge or may be indirectly connected to the first node or the second node via one or more intervening additional nodes and corresponding edges. At block the candidate text line determination module s may select the current seed pair of neighboring glyphs and the glyphs corresponding to the additional nodes as a candidate text line.

At block the candidate text line determination module s may determine whether all glyphs in the set of glyphs have been selected. In response to a positive determination at block the method may end. In response to a negative determination at block the candidate text line determination module s may select a next glyph from the set of glyphs as the current glyph. The method may then proceed iteratively from block until a positive determination is made at block and a complete set of candidate text lines is obtained.

At block the candidate text line ranking module s may rank a set of candidate text lines based at least in part on a set of text line feature values determined for each candidate text line. More specifically the candidate text line ranking module s may generate a text line score for each candidate text line e.g. a weighted combination of one or more text line feature values associated with the candidate text line that indicates a likelihood that the candidate text line represents an actual text line in an image. The candidate text line ranking module s may then rank the set of candidate text lines in accordance with their respective scores.

The operations at blocks may represent an iterative series of operations that the conflict resolution module s may perform to resolve any conflicts that may exist between the candidate text lines. As previously described a conflict may exist if the same glyph is present in more than one distinct candidate text line. At block the conflict resolution module s may select a highest ranked candidate text line as a current candidate text line. At block the conflict resolution module s may select a first glyph of the current candidate text line as a current glyph.

At block the conflict resolution module s may determine whether the current glyph is present in lower ranked candidate text lines. In response to a positive determination at block the conflict resolution module s may proceed to remove the current glyph from each lower ranked candidate text line at block . Then at block the conflict resolution module s may re rank each candidate text line from which the current glyph was removed. More specifically the candidate text line ranking module s may determine a new set of text line features values for each modified candidate text line and may further determine a new text line score for each modified candidate text line based at least in part on the new set of text line features. The candidate text link ranking module s may then update the ranking of each modified candidate text line based at least in part on the corresponding new text line score. It should be appreciated that set of candidate text lines having lower rankings than the current candidate text line may be iterated through to perform the operations at blocks .

From block the method may proceed to block . In addition in response to a negative determination at block the method may also proceed to block . At block the conflict resolution module s may determine whether all glyphs in the current candidate text line have been evaluated. In response to a negative determination at block the conflict resolution module s may select a next glyph in the current candidate text line as the current glyph at block and the method may proceed iteratively from block .

On the other hand in response to a positive determination at block the method may proceed to block where the conflict resolution module s may determine whether all candidate text lines have been evaluated. In response to a negative determination at block the conflict resolution module s may select a next highest ranked candidate text line as the current candidate text line and the method may proceed iteratively from block . On the other hand in response to a positive determination at block the method may end as all potential conflict in the set of candidate text lines have been resolved. At the completion of method a final set of candidate text lines are obtained each of which includes a unique combination of glyphs from the image. This final set of candidate text lines may be outputted by the multi orientation text detection algorithm as a final set of actual text lines in the image.

In an illustrative configuration the device may include one or more processors processor s one or more memory devices generically referred to herein as memory one or more input output I O interface s one or more network interfaces one or more sensors or sensor interfaces one or more transceivers and data storage . The device may further include one or more buses that functionally couple various components of the device . The device may further include one or more antennas not shown that may include without limitation a cellular antenna a Wi Fi antenna a Global Navigation Satellite System GNSS antenna a Bluetooth antenna an Near Field Communication NFC antenna and so forth. These various components will be described in more detail hereinafter.

The bus es may include at least one of a system bus a memory bus an address bus or a message bus and may permit exchange of information e.g. data including computer executable code signaling etc. between various components of the device . The bus es may include without limitation a memory bus or a memory controller a peripheral bus an accelerated graphics port and so forth. The bus es may be associated with any suitable bus architecture including without limitation an Industry Standard Architecture ISA a Micro Channel Architecture MCA an Enhanced ISA EISA a Video Electronics Standards Association VESA architecture an Accelerated Graphics Port AGP architecture a Peripheral Component Interconnects PCI architecture a PCI Express architecture a Personal Computer Memory Card International Association PCMCIA architecture a Universal Serial Bus USB architecture and so forth.

The memory of the device may include volatile memory memory that maintains its state when supplied with power such as random access memory RAM and or non volatile memory memory that maintains its state even when not supplied with power such as read only memory ROM flash memory ferroelectric RAM FRAM and so forth. In certain example embodiments volatile memory may enable faster read write access than non volatile memory. However in certain other example embodiments certain types of non volatile memory e.g. FRAM may enable faster read write access than certain types of volatile memory.

In various implementations the memory may include multiple different types of memory such as various types of static random access memory SRAM various types of dynamic random access memory DRAM various types of unalterable ROM and or writeable variants of ROM such as electrically erasable programmable read only memory EEPROM flash memory and so forth. The memory may include main memory as well as various forms of cache memory such as instruction cache s data cache s translation lookaside buffer s TLBs and so forth. Further cache memory such as a data cache may be a multi level cache organized as a hierarchy of one or more cache levels L1 L2 etc. .

The data storage may include removable storage and or non removable storage including but not limited to magnetic storage optical disk storage and or tape storage. The data storage may provide non volatile storage of computer executable instructions and other data. The memory and the data storage removable and or non removable are examples of computer readable storage media CRSM as that term is used herein.

The data storage may store computer executable code instructions or the like that may be loadable into the memory and executable by the processor s to cause the processor s to perform or initiate various operations. The data storage may additionally store data that may be copied to memory for use by the processor s during the execution of the computer executable instructions. Moreover output data generated as a result of execution of the computer executable instructions by the processor s may be stored initially in memory and may ultimately be copied to data storage for non volatile storage.

More specifically the data storage may store one or more operating systems O S one or more database management systems DBMS and one or more program modules applications or the like such as for example one or more neighboring glyph determination modules one or more glyph feature value computation modules a learned classifier one or more candidate text line determination modules one or more text line feature value computation modules one or more candidate text line ranking modules and one or more conflict resolution modules . Any of the modules depicted in may correspond in function to similarly named modules depicted in and may include computer executable code instructions or the like that may be loaded into the memory for execution by one or more of the processor s . Further any data stored in the data storage may be loaded into the memory for use by the processor s in executing computer executable code. In addition any data potentially stored in one or more datastores may be accessed via the DBMS and loaded in the memory for use by the processor s in executing computer executable code.

The processor s may be configured to access the memory and execute computer executable instructions loaded therein. For example the processor s may be configured to execute computer executable instructions of the various program modules of the user device to cause or facilitate various operations to be performed in accordance with one or more embodiments of the disclosure. The processor s may include any suitable processing unit capable of accepting data as input processing the input data in accordance with stored computer executable instructions and generating output data. The processor s may include any type of suitable processing unit including but not limited to a central processing unit a microprocessor a Reduced Instruction Set Computer RISC microprocessor a Complex Instruction Set Computer CISC microprocessor a microcontroller an Application Specific Integrated Circuit ASIC a Field Programmable Gate Array FPGA a System on a Chip SoC a digital signal processor DSP and so forth. Further the processor s may have any suitable microarchitecture design that includes any number of constituent components such as for example registers multiplexers arithmetic logic units cache controllers for controlling read write operations to cache memory branch predictors or the like. The microarchitecture design of the processor s may be capable of supporting any of a variety of instruction sets.

Referring now to other illustrative components depicted as being stored in the data storage the O S may be loaded from the data storage into the memory and may provide an interface between other application software executing on the device and hardware resources of the device . More specifically the O S may include a set of computer executable instructions for managing hardware resources of the device and for providing common services to other application programs e.g. managing memory allocation among various application programs . In certain example embodiments the O S may control execution of one or more of the program modules depicted as being stored in the data storage . The O S may include any operating system now known or which may be developed in the future including but not limited to any server operating system any mainframe operating system or any other proprietary or non proprietary operating system.

The DBMS may be loaded into the memory and may support functionality for accessing retrieving storing and or manipulating data stored in the memory and or data stored in the data storage . The DBMS may use any of a variety of database models e.g. relational model object model etc. and may support any of a variety of query languages. The DBMS may access data represented in one or more data schemas and stored in any suitable data repository. In those example embodiments in which the device is a mobile device the DBMS may be any suitable light weight DBMS optimized for performance on a mobile device. Datastore s stored in the data storage and or datastores external to the device may include but are not limited to databases e.g. relational object oriented etc. file systems flat files distributed datastores in which data is stored on more than one node of a computer network peer to peer network datastores or the like.

Referring now to other illustrative components of the device the input output I O interface s may facilitate the receipt of input information by the device from one or more I O devices as well as the output of information from the device to the one or more I O devices. The I O devices may include any of a variety of components such as a display or display screen having a touch surface or touchscreen an audio output device for producing sound such as a speaker an audio capture device such as a microphone an image and or video capture device such as a camera a haptic unit and so forth. Any of these components may be integrated into the device or may be separate. The I O devices may further include for example any number of peripheral devices such as data storage devices printing devices and so forth.

The I O interface s may also include an interface for an external peripheral device connection such as universal serial bus USB FireWire Thunderbolt Ethernet port or other connection protocol that may connect to one or more networks. The I O interface s may also include a connection to one or more antennas to connect to one or more networks via a wireless local area network WLAN such as Wi Fi radio Bluetooth and or a wireless network radio such as a radio capable of communication with a wireless communication network such as a Long Term Evolution LTE network WiMAX network 3G network etc.

The device may further include one or more network interfaces via which the device may communicate with any of a variety of other systems platforms networks devices and so forth. Such communication may occur via one or more networks including but are not limited to any one or more different types of communications networks such as for example cable networks public networks e.g. the Internet private networks e.g. frame relay networks wireless networks cellular networks telephone networks e.g. a public switched telephone network or any other suitable private or public packet switched or circuit switched networks. Further such network s may have any suitable communication range associated therewith and may include for example global networks e.g. the Internet metropolitan area networks MANs wide area networks WANs local area networks LANs or personal area networks PANs . In addition such network s may include communication links and associated networking devices e.g. link layer switches routers etc. for transmitting network traffic over any suitable type of medium including but not limited to coaxial cable twisted pair wire e.g. twisted pair copper wire optical fiber a hybrid fiber coaxial HFC medium a microwave medium a radio frequency communication medium a satellite communication medium or any combination thereof.

Antenna s of the device not shown may include any suitable type of antenna depending for example on the communications protocols used to transmit or receive signals via the antenna s . Non limiting examples of suitable antennas may include directional antennas non directional antennas dipole antennas folded dipole antennas patch antennas multiple input multiple output MIMO antennas or the like. The antenna s may be communicatively coupled to one or more transceivers or radio components to which or from which signals may be transmitted or received.

The transceiver s may include any suitable radio component s for in cooperation with the antenna s transmitting or receiving radio frequency RF signals in the bandwidth and or channels corresponding to the communications protocols utilized by the device to communicate with other devices. The transceiver s may include hardware software and or firmware for modulating transmitting or receiving potentially in cooperation with any of the antenna s communications signals according to any of the communications protocols discussed above including but not limited to one or more Wi Fi and or Wi Fi direct protocols as standardized by the IEEE 802.11 standards one or more non Wi Fi protocols or one or more cellular communications protocols or standards. The transceiver s may further include hardware firmware or software for receiving GNSS signals. The transceiver s may include any known receiver and baseband suitable for communicating via the communications protocols utilized by the device . The transceiver s may further include a low noise amplifier LNA additional signal amplifiers an analog to digital A D converter one or more buffers a digital baseband or the like.

The sensor s sensor interface s may include or may be capable of interfacing with any suitable type of sensing device such as for example inertial sensors force sensors thermal sensors and so forth. Example types of inertial sensors may include accelerometers e.g. MEMS based accelerometers gyroscopes and so forth.

It should be appreciated that the program modules applications computer executable instructions code or the like depicted in as being stored in the data storage are merely illustrative and not exhaustive and that processing described as being supported by any particular module may alternatively be distributed across multiple modules or performed by a different module. In addition various program module s script s plug in s Application Programming Interface s API s or any other suitable computer executable code hosted locally on the device and or hosted on other computing device s accessible via one or more networks may be provided to support functionality provided by the program modules applications or computer executable code depicted in and or additional or alternate functionality. Further functionality may be modularized differently such that processing described as being supported collectively by the collection of program modules depicted in may be performed by a fewer or greater number of modules or functionality described as being supported by any particular module may be supported at least in part by another module. In addition program modules that support the functionality described herein may form part of one or more applications executable across any number of systems or devices in accordance with any suitable computing model such as for example a client server model a peer to peer model and so forth. In addition any of the functionality described as being supported by any of the program modules depicted in may be implemented at least partially in hardware and or firmware across any number of devices.

It should further be appreciated that the device may include alternate and or additional hardware software or firmware components beyond those described or depicted without departing from the scope of the disclosure. More particularly it should be appreciated that software firmware or hardware components depicted as forming part of the device are merely illustrative and that some components may not be present or additional components may be provided in various embodiments. While various illustrative program modules have been depicted and described as software modules stored in data storage it should be appreciated that functionality described as being supported by the program modules may be enabled by any combination of hardware software and or firmware. It should further be appreciated that each of the above mentioned modules may in various embodiments represent a logical partitioning of supported functionality. This logical partitioning is depicted for ease of explanation of the functionality and may not be representative of the structure of software hardware and or firmware for implementing the functionality. Accordingly it should be appreciated that functionality described as being provided by a particular module may in various embodiments be provided at least in part by one or more other modules. Further one or more depicted modules may not be present in certain embodiments while in other embodiments additional modules not depicted may be present and may support at least a portion of the described functionality and or additional functionality. Moreover while certain modules may be depicted and described as sub modules of another module in certain embodiments such modules may be provided as independent modules or as sub modules of other modules.

One or more operations of the methods may have been described above as being performed by a device or more specifically by one or more engines program modules applications or the like executable on a device such as the device having the illustrative configuration shown in . It should be appreciated however that such operations may be implemented in connection with numerous other device configurations.

The operations described and depicted in the illustrative methods of may be carried out or performed in any suitable order as desired in various example embodiments of the disclosure. Additionally in certain example embodiments at least a portion of the operations may be carried out in parallel. Furthermore in certain example embodiments less more or different operations than those depicted in may be performed.

Although specific embodiments of the disclosure have been described one of ordinary skill in the art will recognize that numerous other modifications and alternative embodiments are within the scope of the disclosure. For example any of the functionality and or processing capabilities described with respect to a particular device or component may be performed by any other device or component. Further while various illustrative implementations and architectures have been described in accordance with embodiments of the disclosure one of ordinary skill in the art will appreciate that numerous other modifications to the illustrative implementations and architectures described herein are also within the scope of this disclosure.

Certain aspects of the disclosure are described above with reference to block and flow diagrams of systems methods apparatuses and or computer program products according to example embodiments. It will be understood that one or more blocks of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and the flow diagrams respectively may be implemented by execution of computer executable program instructions. Likewise some blocks of the block diagrams and flow diagrams may not necessarily need to be performed in the order presented or may not necessarily need to be performed at all according to some embodiments. Further additional components and or operations beyond those depicted in blocks of the block and or flow diagrams may be present in certain embodiments.

Accordingly blocks of the block diagrams and flow diagrams support combinations of means for performing the specified functions combinations of elements or steps for performing the specified functions and program instruction means for performing the specified functions. It will also be understood that each block of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and flow diagrams may be implemented by special purpose hardware based computer systems that perform the specified functions elements or steps or combinations of special purpose hardware and computer instructions.

Program modules applications or the like disclosed herein may include one or more software components including for example software objects methods data structures or the like. Each such software component may include computer executable instructions that responsive to execution cause at least a portion of the functionality described herein e.g. one or more operations of the illustrative methods described herein to be performed.

A software component may be coded in any of a variety of programming languages. An illustrative programming language may be a lower level programming language such as an assembly language associated with a particular hardware architecture and or operating system platform. A software component comprising assembly language instructions may require conversion into executable machine code by an assembler prior to execution by the hardware architecture and or platform.

Another example programming language may be a higher level programming language that may be portable across multiple architectures. A software component comprising higher level programming language instructions may require conversion to an intermediate representation by an interpreter or a compiler prior to execution.

Other examples of programming languages include but are not limited to a macro language a shell or command language a job control language a script language a database query or search language or a report writing language. In one or more example embodiments a software component comprising instructions in one of the foregoing examples of programming languages may be executed directly by an operating system or other software component without having to be first transformed into another form.

A software component may be stored as a file or other data storage construct. Software components of a similar type or functionally related may be stored together such as for example in a particular directory folder or library. Software components may be static e.g. pre established or fixed or dynamic e.g. created or modified at the time of execution .

Software components may invoke or be invoked by other software components through any of a wide variety of mechanisms. Invoked or invoking software components may comprise other custom developed application software operating system functionality e.g. device drivers data storage e.g. file management routines other common routines and services etc. or third party software components e.g. middleware encryption or other security software database management software file transfer or other network communication software mathematical or statistical software image processing software and format translation software .

Software components associated with a particular solution or system may reside and be executed on a single platform or may be distributed across multiple platforms. The multiple platforms may be associated with more than one hardware vendor underlying chip technology or operating system. Furthermore software components associated with a particular solution or system may be initially written in one or more programming languages but may invoke software components written in another programming language.

Computer executable program instructions may be loaded onto a special purpose computer or other particular machine a processor or other programmable data processing apparatus to produce a particular machine such that execution of the instructions on the computer processor or other programmable data processing apparatus causes one or more functions or operations specified in the flow diagrams to be performed. These computer program instructions may also be stored in a computer readable storage medium CRSM that upon execution may direct a computer or other programmable data processing apparatus to function in a particular manner such that the instructions stored in the computer readable storage medium produce an article of manufacture including instruction means that implement one or more functions or operations specified in the flow diagrams. The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational elements or steps to be performed on the computer or other programmable apparatus to produce a computer implemented process.

Additional types of CRSM that may be present in any of the devices described herein may include but are not limited to programmable random access memory PRAM SRAM DRAM RAM ROM electrically erasable programmable read only memory EEPROM flash memory or other memory technology compact disc read only memory CD ROM digital versatile disc DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the information and which can be accessed. Combinations of any of the above are also included within the scope of CRSM. Alternatively computer readable communication media CRCM may include computer readable instructions program modules or other data transmitted within a data signal such as a carrier wave or other transmission. However as used herein CRSM does not include CRCM.

Although embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the disclosure is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as illustrative forms of implementing the embodiments. Conditional language such as among others can could might or may unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments could include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without user input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment.

