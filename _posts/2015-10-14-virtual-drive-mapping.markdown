---

title: Virtual drive mapping
abstract: The automatic mapping of a set of physical drives to virtual drives is disclosed. Given a maximum set of n physical servers, S-S, and a maximum set of m physical drives, D-D, a mapping of a set of virtual drives, V-V, to the physical drives D-D, is created, assuming n and m are fixed and known, and one virtual drive is created per server. Physical drives of size Dsize are organized into a maximum of p “Stripe Sets” SS-SS, each Stripe Set containing an equal number of physical drives. Each virtual drive will have a size, Vsize=(m*Dsize)/n (rounded down to the nearest integer). Virtual drives are mapped sequentially to Stripe Sets, starting with Vmapped to SS. Successive virtual drives are mapped to Stripe Sets until all virtual drives have been mapped to a Stripe Set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09395932&OS=09395932&RS=09395932
owner: Avago Technologies General IP (Singapore) Pte. Ltd.
number: 09395932
owner_city: Singapore
owner_country: SG
publication_date: 20151014
---
This application is a continuation of application Ser. No. 11 636 108 filed Dec. 8 2006 which is hereby incorporated by reference in its entirety.

This invention relates to the mapping of virtual drives to servers and more particularly to the automated mapping of virtual drives to servers in a system that allows for additional servers and physical drives to be subsequently added to the system in a manner that does not require any change to the original mapping.

Conventional blade servers may be connected to redundant external switch fabrics through an A side Input Output I O switch and a B side I O switch which plug into the midplane from the back of the chassis . Typically the redundancy enables one switch to take over if the other fails. In addition the blade server midplane is typically plumbed to allow for multiple independent redundant fabrics or I O protocols such as Fibre Channel FC Serial Attached SCSI SAS SATA Ethernet or InfiniBand. In the case of a FC configuration each embedded switch and may be a FC Arbitrated Loop FC AL switch or a full fabric switch with a separate port to receive a FC link from each of the multiple server blades and output ports for connecting to each of the external switched fabrics .

To enable the server blades to communicate with the switch fabric typically a mezzanine I O card that performs a Host Bus Adapter HBA a.k.a. I O Controller IOC function is required in each server blade . These mezzanine I O cards are typically mounted to the server blades as daughter cards. Note that this may also be accomplished by embedding an IOC directly on the server blade. However this increases complexity for the Original Equipment Manufacturer OEM who must now make a different server blade for each type of I O that will be supported. For purposes of this specification mezzanine I O cards referred to herein include both daughter cards and IOCs mounted directly onto the server blade. The output of a mezzanine I O card is two I O links routed to each of the two embedded switches and . The mezzanine I O cards follow the standard device driver model so that when a server blade with a mezzanine I O card is plugged into the midplane and connected to an embedded switch or it appears to be a standalone server with a Peripheral Component Interconnect PCI card communicating with an external switch.

Each conventional server blade has traditionally included two disk drives for redundancy. However the compact nature of blade servers and the desired small size of the server blades means that the two disk drives normally contained in each server blade take up valuable space.

Modern disk drives contain more storage capacity that is typically needed by a server blade and thus diskless server blades have been developed in which the physical disk drives are located either in another board within the blade server an embedded implementation or even in an enclosure outside the blade server e.g. a storage array connected to the blade server . One company that makes diskless server blades for non FC applications is Engenera.

Diskless server blades boot off of virtual drives which are formed within the physical drives. The mapping of server blades and virtual drives has conventionally been a manual process involving adjusting Basic Input Output System BIOS settings and setting up the storage array with a World Wide Port Name WWPN that maps to the server blades and the blade server.

Heretofore in both blade server and non blade server applications there has been no way to automatically create virtual drives and map servers to the virtual drives. However if the maximum number of allowable servers and drives is known then a processor executing firmware either within one of the servers or external to the servers can automatically create virtual drives from existing physical drives map them to existing servers and allow for servers and drives to be subsequently added to the system up to the maximum allowable numbers without disrupting the mapping.

Therefore there is a need to automatically create virtual drives from existing physical drives and map existing servers to the virtual drives when the maximum number of allowable servers and drives is known and also to allow for additional servers and drives up to the maximum allowable numbers to be added and mapped without disrupting the original mapping.

Embodiments of the present invention are directed to automatically mapping a set of physical drives to a larger number of virtual drives for use by a set of computer servers. Users of this invention will save costs space and power by using fewer physical drives than the number of physical servers.

Given a maximum set of n physical servers denoted S S and a maximum set of m physical drives denoted D D embodiments of the present invention define a set of algorithms implemented in firmware to automatically create and maacute over p a set of virtual drives denoted V V to the physical drives D D given the following assumptions 1 the maximum number of supported servers n is fixed and known 2 the maximum number of supported physical drives m is fixed and known and 3 one virtual drive is created per server i.e. n total virtual drives are presented .

In the virtual drive mapping algorithm all virtual drives are the same size. Striping also known as a Redundant Array of Independent Disks 0 RAID 0 is used to map the virtual drives to the physical drives. Physical drives are organized into Stripe Sets with each Stripe Set containing an equal number of physical drives. There are a maximum of p Stripe Sets denoted SS SS. Because each Stripe Set has an equal number of drives the maximum number of physical drives m must be divisible by the maximum number of Stripe Sets p with mlp physical drives per Stripe Set.

To automatically configure a maximum set of m physical drives into a maximum set of n virtual drives the number of physical drives currently installed in the system NUMdrives and the size capacity in bytes of the installed physical drives is first discovered by querying each drive for its capacity. The smallest reported capacity of any of the physical drives Dsize is then assumed to be the capacity of all physical drives that are installed or will be installed in the system.

Because there are a maximum of n virtual drives supported by a maximum of in physical drives of size Dsize and all virtual drives are the same size each virtual drive will have a size Vsize equal to the maximum total size of all physical drives m times Dsize divided by the maximum number of virtual drives n rounded down to the nearest integer. In other words Vsize m Dsize n rounded down to the nearest integer .

Next the number of Stripe Sets must be selected. A default value for the number of Stripe Sets may be used to provide automatic configuration. The number of Stripe Sets p must be greater than or equal to 1 and less than or equal to the maximum number of physical drives m with m being divisible by p. In other words 1 p m where m is divisible by p.

By default embodiments of the present invention may select the number of Stripe Sets p to yield the smallest number of physical drives per Stripe Set greater than 1. Each Stripe Set has a size SSsize equal to the size of a single physical drive Dsize multiplied by the number of physical drives in a stripe set m p. In other words SSsize Dsize m p rounded down to the nearest integer .

Virtual drives are mapped sequentially to Stripe Sets starting with Vmapped to SS. Successive virtual drives are mapped to the Stripe Sets in order until all virtual drives have been mapped to a Stripe Set.

Next a validation step may be performed in which computations are made to determine if any of the configuration assumptions are being violated. To validate the configuration the number of drives present NUMdrives determined above must be checked to ensure that it maps into an integer number of Stripe Sets. In other words the number of physical drives present NUMdrives must be a multiple of the number of drives in a Stripe Set m p.

The actual number of servers present NUMservers must be discovered by querying the interconnect to the servers. Next to ensure that the number of servers present NUMservers can be supported by the number of physical drives present NUMdrives the virtual drives are mapped to the physical drives as described above.

If the configuration is not valid for any of the above reasons the user may be notified of the cause of the problem and provided with instructions to create a valid configuration. Typically a valid configuration can be reached by adding a number of physical drives until all requirements are satisfied.

In the following description of preferred embodiments reference is made to the accompanying drawings which form a part hereof and in which it is shown by way of illustration specific embodiments in which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the preferred embodiments of the present invention.

Although embodiments of the present invention are described herein in terms of blade servers and server blades it should be understood that the present invention is not limited to blade servers and server blades but is generally applicable to any multiple server system employing virtual drives. In addition the present invention is not limited to systems that support FC but includes InfiniBand Ethernet Serial Attached Small Computer System Interconnect SAS signaling and the like. Implementation of these protocols requires that the midplane or other connectivity support the protocols.

Embodiments of the present invention are directed to automatically mapping a set of physical drives to a larger number of virtual drives for use by a set of computer servers. Users of this invention will likely save costs by using fewer physical drives than the number of physical servers.

It should be noted that illustrate two exemplary systems capable of employing embodiments of the present invention. In general the functionality of the present invention may be implemented in firmware an API or any other type of computer program that may be executed by a processor or CPU or other instruction processing device or circuit located in any switching device storage concentrator or storage array in a system utilizing the concept of virtual drives or devices.

Embodiments of the present invention define a set of algorithms implemented in firmware to automatically create and map a set of virtual drives denoted V Vin given the following assumptions 1 the maximum number of supported servers n is fixed and known 2 the maximum number of supported physical drives m is fixed and known and 3 one virtual drive is created per server i.e. n total virtual drives are presented . The n and m values may be provided to the firmware of the present invention. These assumptions enable virtual drives to be created and mapped to servers using current quantities of servers and physical drives and allows for adding servers and physical drives up to the maximum numbers n and m without having to perform any re mappings of virtual drives to servers. In alternative embodiments there may be more than one virtual drive per server. The actual number of virtual drives present at any time is of course limited by the actual number of servers installed in the system.

In the virtual drive mapping algorithm all virtual drives are the same size. Alternative embodiments may support different size virtual drives. Size means the capacity in bytes of a drive virtual or physical . Any number of servers from 1 to n can be supported. In general a user would start with a smaller number of servers and add servers over time. When adding servers the size of existing virtual drives remains fixed. Virtual drive sizes are not reduced.

Striping also known as a Redundant Array of Independent Disks 0 RAID 0 is used to map the virtual drives to the physical drives. Striping is a technique to distribute data from a single virtual drive to multiple physical drives. Physical drives are organized into Stripe Sets with each Stripe Set containing an equal number of physical drives. There are a maximum of p Stripe Sets denoted SS SSin the example of . Because each Stripe Set has an equal number of drives the maximum number of physical drives m must be divisible by the maximum number of Stripe Sets p with m p physical drives per Stripe Set. Any actual number of Stripe Sets from 1 to p can be supported provided that enough actual Stripe Sets are present to support the number of servers present. It should be noted that shows two physical drives per Stripe Set as an example only other numbers of physical drives per Stripe Set are possible.

To automatically configure a maximum set of m physical drives into a maximum set of n virtual drives the number of physical drives currently installed in the system NUMdrives and the size capacity in bytes of the installed physical drives is first discovered by querying each drive for its capacity. Query methods depend on the specific protocol being used and the invention does not depend on any specific query method. As an example the Read Capacity command can be used in the SCSI protocol to determine the block size and total number of blocks on a drive. The smallest reported capacity of any of the physical drives Dsize is then assumed to be the capacity of all physical drives that are installed or will be installed in the system. Note that using the smallest size of a single drive as the capacity of all drives leaves unused capacity on drives larger than Dsize but simplifies the mapping algorithm and allows for expansion of the number of installed servers and physical drives up to the assumed maximums n and m without requiring re mapping. If less than m physical drives are present during the initial discovery then any new drives added must have a size greater than or equal to Dsize. If the new chive has a size smaller than Dsize it results in an unsupported configuration. In this case the user may be notified of the error and provided with instructions to replace the drive with a different drive of capacity greater than or equal to Dsize.

Because there are a maximum of n virtual drives supported by a maximum of in physical drives of size Dsize and all virtual drives are the same size each virtual drive will have a size Vsize equal to the maximum total size of all physical drives m times Dsize divided by the maximum number of virtual drives n rounded down to the nearest integer. In other words Vsize m Dsize n rounded down to the nearest integer .

Next the number of Stripe Sets must be selected. The use of Stripe Sets while optional allows the flexibility to upgrade the number of physical drives as long as entire Stripe Sets are added at a time. Because physical drives must be added in quantities equal to complete Stripe Sets the number of drives in a Stripe Set represents a cost granularity to the user. However having more drives in a Stripe Set improves performance because it is faster to access information from multiple physical drives at the same time so there is a trade off between cost granularity and performance. A default value for the number of Stripe Sets will be used to provide automatic configuration although in alternative embodiments users can specify a different value to optimize cost granularity vs. performance for a given application. The number of Stripe Sets p must be greater than or equal to 1 and less than or equal to the maximum number of physical drives m with m being divisible by p. In other words 1 p m where m is divisible by p.

By default embodiments of the present invention may select the number of Stripe Sets p to yield the smallest number of physical drives per Stripe Set greater than 1. Thus if there is only one physical drive then there will be one Stripe Set with one physical drive per Stripe Set. Note that if the maximum number of physical drives m is prime then by default there will be only one Stripe Set with m physical drives per Stripe Set resulting in the highest cost granularity. In alternative embodiments other methods may be used to select the default number of Stripe Sets.

Each Stripe Set has a size SSsize equal to the size of a single physical drive Dsize multiplied by the number of physical drives in a stripe set m p. In other words SSsize Dsize m p rounded down to the nearest integer .

The next step is to map the virtual drives to the physical drives. Physical drives are added to the system a Stripe Set at a time. Each Stripe Set can support a number of physical servers determined by the number of virtual drives that fit within a Stripe Set. Virtual drives are mapped sequentially to Stripe Sets starting with Vmapped to SS. Virtual drives continue to be mapped to SSuntil SSdoes not have enough capacity left to support another virtual drive. The number of whole virtual drives mapped to SSis equal to the size of a Stripe Set divided by the size of a virtual drive rounded down to the nearest integer. In other words the number of whole virtual drives mapped to SSis equal to SSsize Vsize Dsize m p m Dsize n m p m n n p rounded down to the nearest integer.

Unused capacity in SSis combined with enough capacity from the second Stripe Set SSto support the next sequential virtual drive. Virtual drives continue to be mapped to SSuntil it no longer has enough capacity to support the next virtual drive. This iterative process continues under control of firmware until all virtual drives have been mapped. During this process because the firmware knows the size of each virtual drive Vsize and the size of each Stripe Set SSsize it can track how much of each Stripe Set is consumed as each successive virtual drive is mapped to it and in this manner iteratively determine which successive whole and partial virtual drives are mapped to successive Stripe Sets using straightforward calculations easily implemented by those skilled in the art. One example of this process is as follows 1 map first virtual drive to first Stripe Set 2 compute remaining space in Stripe Set 3 as long as remaining space in Stripe Set Vsize map next virtual drive to Stripe Set compute new remaining space in Stripe Set and repeat step 3 4 when remaining space in Stripe Set

Users may need to know how many total servers can be supported by a given number of Stripe Sets. If the number of installed Stripe Sets is s the number of supported servers equals the total capacity of all installed Stripe Sets divided by the size of a virtual drive rounded down to the nearest integer. From the equation above the number of supported servers s n p rounded down to the nearest integer .

Next a validation step is performed in which computations are made to determine if any of the configuration assumptions are being violated. For example if only D was installed one physical drive installed in this would be an invalid configuration see Table 1 because each Stripe Set requires two physical drives.

To validate the configuration the number of drives present NUMdrives determined above must be checked to ensure that it maps into an integer number of Stripe Sets. The number of drives in each Stripe Set is equal to the maximum number of physical drives m divided by the number of Stripe Sets p. The number of physical drives present NUMdrives must be a multiple of the number of drives in a Stripe Set m p. The number of Stripe Sets s is equal to the number of drives present NUMdrives divided by the number of drives in a stripe set m p. In other words s NUMdrives m p .

The actual number of servers present NUMservers must be discovered by querying the interconnect to the servers. Specific query methods vary based on interconnect and protocol and the invention is not dependent on the specific methods. As an example in Fibre Channel a PLOGI command can be used to determine whether or not a server is present and obtain the WWN of the server if present. Next to ensure that the number of servers present NUMservers can be supported by the number of physical drives present NUMdrives the virtual drives are mapped to the physical drives as described above. Of course the number of servers present NUMservers must be less than or equal to the number of supported servers In other words NUMservers

If the configuration is not valid for any of the above reasons the user may be notified of the cause of the problem and provided with instructions to create a valid configuration. Typically a valid configuration can be reached by adding a number of physical drives until all requirements are satisfied.

The configuration may be re validated as described above when drives or servers are added or removed. In particular when drives are added embodiments of the present invention may first verify that the size of all new drives is greater than or equal to Dsize.

In alternative embodiments of the present invention illustrated symbolically in the example of automated mapping of virtual drives to servers as described above may be used in a configuration that uses RAID 1 mirroring on each server to provide high availability. In the example of two independent sets of physical drives D Dand D Dcan be mapped using this invention to create two independent sets of virtual drives V Vand V V. Each server is mapped to two virtual drives of equal size that in turn map to separate physical drives. RAID 1 on each server mirrors all writes to both virtual drives. Since all data is mirrored copied to both drives no single drive failure will cause the system to fail.

In a RAID application the redundant virtual drives seen by each server should be equal in size. To achieve equal size virtual drives each instance of the virtual drive mapping algorithm independently discovers the size of the lowest capacity physical drive present Dsize. Each instance then communicates the Dsize it discovered then both instances use the smaller of the two as a common Dsize. Additionally when validating the configuration both instances must communicate to ensure that the configuration present is supported.

Embodiments of the present invention can support more than one virtual drive per server given a known maximum number of virtual drives. Such a variation might be useful to have multiple operating system images per server. For example each server could have one virtual drive loaded with a Windows system image and another virtual drive loaded with a Linux system image. Users could choose which virtual drive to use at boot time.

In a blade server environment each physical port on an embedded storage concentrator is connected to a specific physical server slot. During the discovery process a unique name example WWNN in Fibre Channel is identified for each active server in each physical slot. A table can be created that saves the mapping of server names to physical slots. Each time a server is removed or inserted the invention can update the mapping table. If a server is removed from a physical slot and a new server is added with a different name in the same slot the invention can detect this situation by comparing the server name of the new server with server name saved in the mapping table for that physical slot. Several options are possible for this situation. A user may desire that the existing virtual drive image be mapped to the new physical server to enable rapid restoration of existing applications on a new server when an existing server fails. The invention can be configured to automatically map an existing virtual drive and all of its data to a new physical server replacing a failed server in a specific physical slot. Additionally if an existing server is moved from one physical slot to another physical slot the invention can detect this case by searching the mapping table to find the server name of the server that was just inserted into a different slot. Since that server name was previously recorded in the mapping table in a different slot the invention can detect that the server has been moved from one physical slot to another physical slot. In this case one option is to map the existing virtual drive and all of its data to the new physical slot.

Although the present invention has been fully described in connection with embodiments thereof with reference to the accompanying drawings it is to be noted that various changes and modifications will become apparent to those skilled in the art. Such changes and modifications are to be understood as being included within the scope of the present invention as defined by the appended claims.

