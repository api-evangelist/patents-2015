---

title: Modular block-allocator for data storage systems
abstract: A modular block allocator receives a cleaner message requesting dirty buffers associated with an inode be cleaned. The modular block allocator provides at least one bucket cache comprising a plurality of buckets, wherein each bucket represents a plurality of free data blocks. The dirty buffers are cleaned by allocating the data blocks of one of the buckets to the dirty buffers. The allocated data blocks are mapped to a stripe set and when the stripe set is full, the stripe set is sent to a storage system. In one embodiment of the invention, a modular block allocator includes a front end module and a back end module communicating with each other via an application programming interface (API). The front end module contains write allocation policies that define how blocks are laid out on disk. The back end module creates data structures for execution of the policies.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09612760&OS=09612760&RS=09612760
owner: NETAPP, INC.
number: 09612760
owner_city: Sunnyvale
owner_country: US
publication_date: 20150624
---
This invention relates to data storage systems and more specifically to a modular block allocator for a write anywhere file system.

The creation and storage of digitized data has proliferated in recent years. Accordingly techniques and mechanisms that facilitate efficient and cost effective storage of large amounts of digital data are common today. For example a cluster network environment of nodes may be implemented as a data storage system to facilitate the creation storage retrieval and or processing of digital data. Such a data storage system may be implemented using a variety of storage architectures such as a network attached storage NAS environment a storage area network SAN a direct attached storage environment and combinations thereof. The foregoing data storage systems may comprise one or more data storage devices configured to store digital data within data volumes.

A data storage system includes one or more storage devices. A storage device may be a disk drive organized as a disk array. Although the term disk often refers to a magnetic storage device in this context a disk may for example be a hard disk drive HDD or a solid state drive SSD .

In a data storage system information is stored on physical disks as volumes that define a logical arrangement of disk space. The disks in a volume may be operated as a Redundant Array of Independent Disks RAID . The RAID configuration enhances the reliability of data storage by the redundant writing of data stripes across a given number of physical disks in a RAID group and the storing of redundant information parity of the data stripes. The physical disks in a RAID group may include data disks and parity disks. The parity may be retrieved to recover data when a disk fails.

Information on disks is typically organized in a file system which is a hierarchical structure of directories files and data blocks. A file may be implemented as a set of data blocks configured to store the actual data. The data blocks are organized within a volume block number VBN space maintained by the file system. The file system may also assign each data block in the file a corresponding file block number FBN . The file system assigns sequences of FBNs on a per file basis while VBNs are assigned over a large volume address space. The file system generally comprises contiguous VBNs from zero to N 1 for a file system of size N blocks.

An example of a file system is a write anywhere file system that does not overwrite data on disks. Instead a data block is retrieved from a disk into a memory and is updated or modified i.e. dirtied with new data the data block is thereafter written to a new location on the disk. A write anywhere file system may initially assume an optimal layout such that the data is substantially contiguously arranged on disks which results in efficient read operation. When accessing a block of a file in response to a request the file system specifies a VBN that is translated into a disk block number DBN location on a particular disk within a RAID group. Since each block in the VBN space and in the DBN space is typically fixed e.g. 4 K bytes in size there is typically a one to one mapping between the information stored on the disks in the DBN space and the information organized by the file system in the VBN space. The requested block is then retrieved from the disk and stored in a buffer cache of the memory as part of a buffer tree of the file. The buffer tree is an internal representation of blocks for a file stored in the buffer cache and maintained by the file system.

As discussed before the requested data block is retrieved from the disk and stored in a buffer cache of the memory. If the data block is updated or modified by a CPU the dirty data remains in the buffer cache. Multiple modifying operations by the CPU are cached before the dirty data is stored on the disk i.e. the buffer is cleaned . The delayed sending of dirty data to the disk provides benefits such as amortized overhead of allocation and improved on disk layout by grouping related data blocks together. In the write anywhere file system the point in time when a collection of changes to the data blocks is sent to the disk is known as consistency point CP . A CP may conceptually be considered a point in time image of the updates to the file system since the previous CP. The process of emptying the buffer cache by sending the dirty data to the disk is accomplished by collecting a list of modes that have been modified since the last CP and then cleaning the inodes. It will be appreciated that cleaning dirty buffers involve assigning new locations on disk for the dirty buffers and then flushing the buffers to those locations on disk. An inode is a data structure used to store information such as metadata about a file whereas data blocks are data structures used to store the actual data for the file. The information in an inode may include ownership of the file access permission for the file size of the file and file type and references to locations on disk of the data blocks for the file. The references to the locations of the file data are provided by pointers which may reference the data blocks.

Initially a CPU issues a cleaner message indicating that the dirty buffers of one or more inodes need to be allocated on disk. In response a block allocator in the file system selects free blocks on disks to which to write the dirty data and then queues the dirty buffers to a RAID group for storage. The block allocator examines a block allocation bitmap to select free blocks within the VBN space of a logical volume. The selected blocks are generally at consecutive locations on the disks in a RAID group for a plurality of blocks belonging to a particular file. When allocating blocks the file system traverses a few blocks of each disk to lay down a plurality of stripes per RAID group. In particular the file system chooses VBNs that are on the same stripe per RAID group to avoid RAID parity reads from disk.

In a cluster network environment having a plurality of multi processors MPs multiple cleaner messages may be executing concurrently on MPs. The block allocator of the file system is required to respond to the multiple cleaner messages by selecting free blocks on disks on a RAID group and then queuing dirty buffers to the RAID group for writing. With new hardware platforms providing increasing number of CPUs it becomes difficult for existing block allocators to timely respond to the cleaner messages thus resulting in processing delay. Also for efficient utilization of storage resources depending on the particular type of data it is to store the data in a specific type of disk or a specific location on disk. For example if a particular data block is frequently accessed it is advantageous to store the data block in a SSD or the outer cylinder of an HDD for quick retrieval. If on the other hand the data is not frequently accessed it may be acceptable to store the data block in the inner cylinder of an HDD. Many existing block allocators do not allow a user to select the type of disk or a location on disk to write the dirty buffers

The present invention is directed to a modular block allocator having a plurality of modules at least one of which contains algorithms for write allocation policies and at least another of which creates data structures for execution of the policies and determination of a storage media type. In one embodiment of the invention the modular block allocator includes a front end module and a back end module communicating with each other via an application programming interface API . The front end module contains write allocation policies that define how cleaner messages are serviced. The back end module creates data structures for execution of the policies.

In one embodiment of the invention a method includes providing at least one bucket cache having a plurality of buckets. Each bucket represents a plurality of free data blocks. In one embodiment a free data block is a free volume block number VBN of a file system. The method according to the embodiment also includes receiving a cleaner message requesting dirty buffers associated with an inode be allocated on disks. The process of allocating dirty buffers on disks is also referred to in this document as cleaning dirty buffers. The dirty buffers are cleaned by allocating or assigning the free VBNs of one of the buckets to the dirty buffers. The free VBNs map to data block numbers DBNs on a storage media and are identified from a bitmap associated with the storage media. In one embodiment the storage media comprises one or more RAID groups. According to the embodiment the method includes mapping the allocated VBNs to a stripe set. When the stripe set is full the entire stripe set is sent to the RAID groups for storage.

In one embodiment the bucket cache includes buckets having attributes indicating that the associated VBNs map to a specific type of storage media or to a specific location of a storage media. In response to a cleaner message requesting that data in the dirty buffers be stored on a specific type of storage media or on a specific location of a storage media a bucket cache having the attribute is assigned to service that cleaner message. The bucket cache also includes default buckets which do not contain any attributes. The default buckets are assigned to service cleaner messages that do not contain special attribute requests.

In one embodiment the system includes a front end module configured to receive a cleaner message requesting dirty buffers associated with an inode be cleaned. The system according to the embodiment also includes a back end module for providing at least one bucket cache comprising a plurality of buckets wherein each bucket represents a set of free volume block numbers VBNs . The system according to the embodiment also includes an application programming interface operable to obtain the buckets from the back end module and to provide the buckets to the front end module. The dirty buffers are cleaned by allocating the VBNs of one of the buckets to the dirty buffers. The allocated VBNs are mapped to a stripe set. When the stripe set is full the stripe set is sent to the RAID groups for storage.

The foregoing has outlined rather broadly the features and technical advantages of the present invention in order that the detailed description of the invention that follows may be better understood. Additional features and advantages of the invention will be described hereinafter which form the subject of the claims of the invention. It should be appreciated by those skilled in the art that the conception and specific embodiment disclosed may be readily utilized as a basis for modifying or designing other structures for carrying out the same purposes of the present invention. It should also be realized by those skilled in the art that such equivalent constructions do not depart from the spirit and scope of the invention as set forth in the appended claims. The novel features which are believed to be characteristic of the invention both as to its organization and method of operation together with further objects and advantages will be better understood from the following description when considered in connection with the accompanying figures. It is to be expressly understood however that each of the figures is provided for the purpose of illustration and description only and is not intended as a definition of the limits of the present invention.

The modules components etc. of data storage systems and may comprise various configurations suitable for providing operation as described herein. For example nodes and may comprise processor based systems such as file server systems computer appliances computer workstations etc. Accordingly nodes and of embodiments comprise a processor e.g. central processing unit CPU application specific integrated circuit ASIC programmable gate array PGA etc. memory e.g. random access memory RAM read only memory ROM disk memory optical memory flash memory etc. and suitable input output circuitry e.g. network interface card NIC wireless network interface display keyboard data bus etc. . The foregoing processor based systems may operate under control of an instruction set e.g. software firmware applet code etc. providing operation as described herein.

Data store devices and may for example comprise disk memory flash memory optical memory and or other suitable computer readable media. It will be apparent to those skilled in the art that data store devices and may comprise one or more RAID groups.

In one embodiment modular block allocator A resides in data module and modular block allocator B resides in the data module . As will be explained later modular block allocators A and B responsive to a plurality of cleaner messages executing concurrently on multiple processors clean dirty buffers associated with inodes. Data modules and of nodes and may be adapted to communicate with data store devices and according to a storage area network SAN protocol e.g. small computer system interface SCSI fiber channel protocol FCP INFINIBAND etc. and thus data store devices and may appear a locally attached resources to the operating system. That is as seen from an operating system on nodes and data store devices and may appear as locally attached to the operating system. In this manner nodes and may access data blocks through the operating system rather than expressly requesting abstract files.

Network modules and may be configured to allow nodes and to connect with client systems such as clients and over network connections and to allow the clients to access data stored in data storage systems and . Moreover network modules and may provide connections with one or more other components of system such as through network . For example network module of node may access data store device via communication network and data module of node . The foregoing operation provides a distributed storage system configuration for system .

Clients and of embodiments comprise a processor e.g. CPU ASIC PGA etc. memory e.g. RAM ROM disk memory optical memory flash memory etc. and suitable input output circuitry e.g. NIC wireless network interface display keyboard data bus etc. . The foregoing processor based systems may operate under control of an instruction set e.g. software firmware applet code etc. providing operation as described herein.

Network may comprise various forms of communication infrastructure such as a SAN the Internet the public switched telephone network PSTN a local area network LAN a metropolitan area network MAN a wide area network WAN a wireless network e.g. a cellular communication network a wireless LAN etc. and or the like. Network or a portion thereof may provide infrastructure of network connections and or alternatively network connections and or may be provided by network infrastructure separate from network wherein such separate network infrastructure may itself comprise a SAN the Internet the PSTN a LAN a MAN a WAN a wireless network and or the like.

In one embodiment of the invention bucket caches and may include default bucket caches as well as bucket caches having special attributes. By way of example a bucket cache having special attributes contains buckets from a specific type of storage media e.g. SSD HDD DASD etc. buckets from a specific location on a storage media e.g. inner cylinder of HDD or outer cylinder of HDD etc. It will be understood by those skilled in the art that a bucket cache of embodiments may contain buckets from any other type of storage media. A default bucket cache contains buckets without special attributes. By way of example bucket cache may be a default bucket cache while bucket caches and may have special attributes. In response to a cleaner message indicating that data in dirty buffers needs to written to a specific type of storage media or a specific location on a storage media a bucket having the appropriate special attribute is provided to the front end to service the cleaner message. If the cleaner message does not request for any specific attribute a bucket from a default bucket cache is provided to the front end module .

In some embodiments of the invention back end module keeps a plurality of bucket caches readily available. Consequently back end module is able to promptly respond to requests for buckets from front end module .

In decision block front end module determines if a cleaner message has requested a bucket having a special attribute. If yes in step API obtains a bucket having the special attribute and provides the bucket to front end module . Otherwise API obtains a default bucket and provides the bucket to front end module .

In step front end module services the cleaner message by cleaning the associated dirty buffers by allocating the VBNs of the bucket to the dirty buffers. Thus the dirty buffers are tagged to the VBNs.

In step the allocated VBNs are mapped to a stripe set. In step a determination is made whether the stripe set is full. If yes in step a full stripe set is sent to the RAID groups by back end module for storage. In step back end module updates the meta data of the file system including the filesystem bitmaps to reflect that the VBNs in the bucket have been used. If in step it is determined that the stripe set is not full the flow moves to step .

In one embodiment of the invention if less than a predetermined percentage VBNs in the bucket are tagged the bucket is returned to the bucket cache for further use. Consider for example that after tagging dirty buffers associated with a particular cleaner message to VBNs of a bucket more than half of the available VBNs of the bucket are still available. In that case the bucket will be returned to the bucket cache so that it may be used to service another cleaner message. In one embodiment of the invention if at least one write allocation chunk or unit of VBNs are still available after a bucket has been used to service a cleaner message the bucket is returned to the bucket cache so that it may be used to service another cleaner message. The write allocation chunk is a predetermined number of VBNs and may vary depending on the configuration.

In one embodiment of the invention responsive to a cleaner message indicating that data in a dirty buffer needs to written to a specific type of storage media or a specific location on a storage media front end module may attach one or more attributes to the request for buckets. A cleaner message for example may indicate that the data in the dirty buffer needs to be written to an outer cylinder of an HDD. It will be understood by those skilled in the art that if data is frequently accessed the data should preferably be written to an outer cylinder of an HDD or to an SSD so that the data may subsequently read quickly. In response to the cleaner message front end module attaches an attribute to a bucket request specifying an outer cylinder of HDD. API then obtains a bucket having a special attribute and provides the bucket to front end module . API for example may provide bucket A from bucket cache because buckets A N contain special attributes. If a bucket request from the front end module does not contain any attributes a bucket from a default bucket cache is provided to the front end module . In that case bucket A may be provided to front end module because buckets in bucket cache are default buckets.

In one aspect of the invention a filesystem organizes the dirty buffers of an mode in a hierarchical buffer tree as illustrated in . In buffer tree buffers in level L0 comprise the ultimate data e.g. user data application data etc. and thus provide a data level. Levels L1 and L2 of buffer tree comprise buffers that provide information with respect to other buffers wherein buffers of level 2 provide information identifying buffers of level 1 and buffers of level 1 provide information identifying buffers of level 0. In accordance with some embodiments front end module first cleans buffers in L0 then L1s L2s and so on until the inode is reached. While allocating buffers in L0s back end module lays out write allocation chunk sized consecutive dirty FBNS of a file on consecutive DBNS of a disk thus ensuring good read performance on a subsequent read of these blocks. Thereafter back end module switches to another disk in order to allocates. While allocating buffers in L1s L2s etc. back end module may allocate multiple levels of buffers on a single disk or switch to a different disk for every buffer depending on policy. By switching to a different disk full stripes can be written thus eliminating the need to read blocks from the disk to compute parity.

Although the present invention and its advantages have been described in detail it should be understood that various changes substitutions and alterations can be made herein without departing from the spirit and scope of the invention as defined by the appended claims. Moreover the scope of the present application is not intended to be limited to the particular embodiments of the process machine manufacture composition of matter means methods and steps described in the specification. As one of ordinary skill in the art will readily appreciate from the disclosure of the present invention processes machines manufacture compositions of matter means methods or steps presently existing or later to be developed that perform substantially the same function or achieve substantially the same result as the corresponding embodiments described herein may be utilized according to the present invention. Accordingly the appended claims are intended to include within their scope such processes machines manufacture compositions of matter means methods or steps.

