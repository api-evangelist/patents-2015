---

title: Hardware simulation controller, system and method for functional verification
abstract: Systems and methods of using hardware to simulate software, specifically the semantic operations defined in HDL simulation languages. Traditional software HDL simulation kernel operations of advancing time, activating threads in response to notified events, and scheduling those threads of execution are handled via a simulation controller. The simulation controller is comprised of a timing wheel, an event-processor, a thread/process dispatch engine, a token processor, and a resource-allocator. These components work together with a control logic component to perform the semantic operations of an HDL software kernel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09195786&OS=09195786&RS=09195786
owner: MENTOR GRAPHICS CORP.
number: 09195786
owner_city: Wilsonville
owner_country: US
publication_date: 20150309
---
This is a divisional of application Ser. No. 13 842 174 filed Mar. 15 2013 which is incorporated by reference herein in its entirety.

The present application relates generally to microprocessor operations and architecture and more particularly to systems methods and apparatus for simulating hardware description language.

Hardware Description Language or HDL is a specialized computer language used to describe the structure design and operation of electronic circuits. In general Hardware Description Language enables precise formal descriptions of electronic circuits and is used to automate analysis simulation and simulated testing of an electronic circuit. For example Hardware Description Language is often used to simulate complex circuits such as microprocessors.

Hardware Description Language can be functionally simulated in software. Functional simulation is the use of a computer program to simulate the execution of a second computer program written in a language other than binary machine code. For example illustrates a model for functionally simulating HDL designs. According to the model of a programmer develops an HDL design to describe an electronic circuit. Using an HDL compiler the HDL design is compiled as a compiled design . An HDL simulator is used to simulate the compiled design . Simulation of the compiled design is necessary to verify that the HDL design actually performs as intended. Simulation is performed using various software that facilitates a testbench environment. During simulation a stimulus or input is provided to the compiled design and simulation results are obtained.

Hardware Description Language can also be emulated. While functional simulation relates to the simulating of non binary machine code software emulation relates to the simulation of execution of binary machine code. illustrates a synthesized emulation usage model for emulating HDL designs. According to the model of a programmer develops an HDL design to describe an electronic circuit. Using an HDL synthesizer the HDL design is synthesized as a synthesized design . An HDL emulator is used to emulate the synthesized design . As with the functional simulation model of a stimulus or input is provided to the synthesized design and simulation results are obtained.

The models of may be combined in a co simulation usage model as illustrated in which increases the efficiency of the overall simulation process. In this model an HDL design is converted into an HDL design that is suitable for emulation and an HDL testbench that is suitable for simulation. The HDL design is subjected to an HDL synthesizer to yield a synthesized design . The HDL testbench is subjected to an HDL compiler to yield a compiled testbench . The synthesized design is emulated by emulator while the compiled testbench is simulated using HDL simulator . The parallel processes of emulation and simulation are linked via a CoSim link which shares information between the two processes improving the speed of the combined processes. Simulation results are generated from the parallel processes.

Even the co simulation usage model however results in processing inefficiencies. Simulating Hardware Description Language can be problematic especially on modern PC hardware based on x86 server architectures. In such architectures Hardware Description Language simulation can be inefficient due to a significant amount of overhead in the representation of the semantic operations of an HDL simulation in the native language. Additionally inefficiencies arise from managing the processing of the HDL simulation kernel in software. As a result HDL simulation can be expensive in terms of processor time.

There are many specific reasons for why HDL simulation is slow especially in x86 server architectures. One reason is that in x86 server architectures the representation of HDL logical simulation semantics is large resulting in large bandwidth requirements. Another reason is that cache memory is underutilized due to an abundance of non repeated actions during for example a Verilog simulation. The inability to effectively utilize a memory cache results in slower performance. Another reason for slowness is poor bus effective utilization in an x86 architecture due to the fixed size of cache lines. Thus significant mismatches between the number of bytes used and the number of bytes read mean that buses are inefficiently utilized. Additionally software simulation kernel events and or scheduling operations are typically not cached well as the ratio of design size to kernel size exceeds 1 M to 1.

In the following detailed description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific embodiments that may be practiced. It should be understood that like reference numbers represent like elements throughout the drawings. Embodiments are described with sufficient detail to enable those skilled in the art to practice them. It is to be understood that other embodiments may be employed and that various structural logical and electrical changes may be made without departing from the spirit or scope of the invention.

As explained above the performance of software based simulation on modern hardware is hampered by various problems including the size of a compiled design representation in memory poor instruction and data cache performance poor memory bus utilization and a software based simulation kernel. One approach to improving application performance of simulating logic circuits and systems can be addressed by a simulation hardware system described in more detail below.

The simulation hardware system addresses the performance limitations of software simulation by replacing the general purpose instruction set encoding of a design with a specialized HDL optimized instruction set that runs on a custom logic processor. This logic processor operates on HDL simulation datatypes without additional overhead of having to map the HDL simulation semantics operations onto a general purpose processor instructions. The smaller HDL optimized instruction footprint reduces the amount of time necessary to read the instructions from memory and therefore reduces the amount of time necessary to perform the simulation.

The simulation hardware system addresses the poor bus utilization of modern CPU s by using multiple smaller memory channels in place of fewer wider channels typical in modern CPU architectures. HDL simulation requires accessing many small 1 byte to 8 byte chunks of data from around a large data address space. Modern CPUs attempt to optimize memory performance for typical CPU software by reading memory one cache line at a time. These cache lines are typically 64 or 128 bytes in size which means 1 bit of a Verilog 4 state design value in memory which theoretically takes up only 2 bits may require 1024 bits of memory to be read from memory. More narrower interfaces reduce the unused used data ratio significantly compared to modern CPU architecture.

The simulation hardware system also contains a plurality of memory types each of which is applied to different memory requirements of a running HDL simulation. HDL design is comprised of many small wire and registers data types often 1 8 bytes mixed with some very large data often many megabytes. HDL design instruction stream is typically comprised of long sequences of instructions that do very few loops. HDL simulation kernel requires less memory than the design data or instructions but must access the data quickly in order for the simulation to make forward progress. The simulation hardware addresses these conflicting requirements by splitting the memory into separate memory systems each of which has a custom datapath that is suited for the width of data that is best suited for the particular requirement. SRAM RLDRAM and DDR DRAM memories are used for the varying needs for fast access to small data streaming performance and massive capacity.

The simulation hardware system addresses the problem of running parallel processes concurrently within a system by memory mapping much of the interaction between HDL design and HDL simulation kernel to memory mapped registers. Memory mapped registers have no software overhead to martial access to physical resources because this is handled by the bus controller at no software cost and with very low latency. Attempting to have every core in a modern CPU attempt to push a value onto a shared software stack would require each core to lock the memory associated with the stack perform the operation and then unlock the memory. This would mean that only one core of execution could make forward progress at a time. Memory mapped queues allow the custom logic processors of the simulation hardware system to push values into memory mapped queues and continue without software level synchronization. This reduces the instructions necessary to perform simulation semantic actions and enables more parallel threads of execution to run concurrently.

The simulation hardware system speeds the performance during low activity of the HDL simulation by always keeping a portion of the next set of simulation time queues or event regions in on chip queues that are available immediately without going to off chip memory. Hardware overflow handling allows these queues to be virtually limitless only constrained by the amount of memory attached to the system.

Finally the simulation hardware system improves the performance during high activity of the HDL simulation by enabling the concurrent processing of the HDL design across many cores whose memory accesses go across memory interfaces designed for their particular memory needs while at the same time the simulation kernel is concurrently accumulating events that are triggered scheduling threads and processes and preparing for the next set of operations when simulation time advances.

The simulation hardware described herein is different than past attempts to accelerate using accelerators or emulators in co simulation with software based simulators. The simulation hardware described herein combines a dedicated low latency hardware controller that performs the operations of an event based software simulation kernel with custom logic processors to handle simulation data.

Event based software simulation is illustrated generally in . is a canonical Verilog event region diagram where Verilog is an example of an HDL. The diagram of illustrates that simulation considers how regions of the designed circuit react to events over time. For example in the current time slot is being considered. The previous time slot would have already been analyzed and analysis of the next time slot will follow. During current time slot various regions of the designed circuit are considered for active threads or processes. Events trigger actions in the form of threads that are scheduled to occur during different even regions. An active region is first considered. If actions exist in response to an event the actions are further simulated step . Once all actions in the active region are analyzed inactive regions are analyzed step . Identification of any actions within the inactive regions results in a reanalysis of the active and inactive regions . Once all actions in the inactive regions are analyzed a non blocking assignment or NBA region is analyzed step . Any actions within the NBA region requires a further analysis of the active inactive and NBA regions . When the NBA region becomes active the actions scheduled to occur during the new region may cause more events to be notified causing more actions to be scheduled again in the active region. After all previous regions have been executed the monitor region step is activated that is used to read the final values of the HDL design for signal tracing strobe or monitor value changes and then the time slot is advanced to the next analysis time step .

In the presently disclosed embodiments these functions as illustrated in are implemented in a simulation computer system. The disclosed simulation computer system embodies the functionality of a software simulator in hardware on a single chip. In the system the semantic operations defined in HDL simulation languages e.g. Verilog and SystemVerilog are handled by two different physical processing subsystems.

Traditional software HDL simulation kernel operations of advancing time activating threads in response to notified events and scheduling those threads of execution are handled in the presently disclosed embodiments on a custom datapath called a simulation controller. As explained in greater detail below the simulation controller is comprised of a timing wheel an event processor a thread process dispatch engine a token processor and a resource allocator. These components work together with a control logic component to perform the semantic operations of an HDL software kernel as defined by the stratified event queue model defined for Verilog or. SystemVerilog in or B respectively .

A set of logic processors runs compiled code generated by an HDL compiler. The system may contain a variety of different logic processor architectures utilizing different instruction set architectures that are more optimized for different portions of the Verilog data model processing. One of the logic processors is designed for fast HDL data manipulation using an HDL logic optimized processor pipeline capable of manipulating 2 state and 4 state data without additional instruction overhead.

The compiler compiles the design into a series of databases representing the operation semantics of the design. The databases are comprised of symbol table information design control data design instruction memory and design data memory. The symbol tables provide a mapping between the logical elements and the location in the hardware s memory. The design control data contains all the connectivity information stored in a series of tables full of simulation semantic tokens. Simulation tokens are used to represent simulation kernel semantic actions and are run on a custom datapath within the simulation controller. These tokens enable the custom simulation controller to process multiple events simultaneously allowing the latency to read data from memory to be run concurrently. The design instruction memory contains instructions for the logic processors to execute to manipulate the state of the HDL design elements in accordance with the HDL data semantics. The design data memory contains the starting values for the HDL design data before the simulation time has begun.

In order to run an HDL simulation using the disclosed embodiments a compilation is used to produce a design database and a simulator runs that design database and collects the output. The disclosed embodiments have the same semantic behavior as the software simulator but have a different operational model. In place of the software simulator a simulation hardware manager application is used to load the compiled design database into the hardware memory subsystems. The manager then starts the simulation and then waits either through polling or interrupt driver until the simulation requires servicing. Some example reasons hardware requires servicing from the manager include displaying output to the screen reading or writing a file calling foreign language function call on the PC that may want to read or write a file or make use of network resources enabling debuggers or finishing the simulation.

After the design has been loaded into the hardware the manager starts the simulation by notifying one event in the active event processor scoreboard. This event corresponds to the beginning of time i.e. initial construct in Verilog . Because no components are busy the event processor performs an iteration by swapping the mapping between the active scoreboard and the processing scoreboard and incrementing the event processor iteration counter. No significant movement of data is performed as part of this operation only the changing of the register value that is used to map the active and processing event scoreboards to the physical scoreboards in hardware is allowed. After the swap the processing scoreboard contains the event to be processed. The event processor begins reading out bit positions one at a time clearing the bits as it goes until no more events are present. At the beginning of the simulation this means that the value 0 is read from the scoreboard and the event processor translates this into a memory address of EventTable 0 . The event processor sends the address to the token datapath which will retrieve the value from memory and handle further processing. After clearing the one bit from the event processor processing event scoreboard the event processor is now idle since there are no more events that have been notified.

The token processor receives the address from the event processor. The token processor reads the address from the simulation memory subsystem which reads the data from either off chip memory or on chip memory depending on the address.

The token processor receives data from the simulation memory subsystem and routes it to the appropriate simulation controller block based on a token ID. Threads and process tokens are sent to the dispatch engine. Events are sent to the event processor. Slist tokens are converted to memory addresses and placed into memory address queues. This process is repeated until there are no events remaining in the current time step.

The dispatch engine receives the incoming thread token and determines which logic processor this token should be scheduled on. Thread tokens have affinity to a particular core so a given thread will always run on the same logic processor. Non blocking assignment NBA tokens which perform the memory copies and event notification during the NBA phase of the event loop do not have affinity to a particular processor and can be run on any available logic processor. The dispatch engine keeps track of what threads are running so that in case the same thread becomes active while another invocation of that same thread is still running the two threads do not run concurrently. This violates the simulation semantics of the HDL language and hardware control is used to prevent this from happening. For thread tokens that are found to be currently running the dispatch engine places these thread tokens in a cancellation queue which is used to cancel any further attempts to invoke the thread while it is still pending in the cancellation queue. Priority is given to rescheduling tokens out of the cancellation queue over processing new tokens. If the thread token does not match a current running thread token it is sent to the scheduler. The scheduler schedules the token with a logic processor by writing to the memory mapped program counter register in case of a thread or writing to an API register and setting the program counter to an entry from the handler table.

At the completion of the thread or other token processing the dispatch engine is notified that the logic processor slot is now idle. The scheduler marks the entry in the dispatch engine entry table as being invalid. This would enable the thread to be scheduled again out of the cancellation queue or make room for another new incoming thread token to takes it position. When all threads are completed the dispatch engine is considered to be idle. The dispatch engine outputs a busy idle single bit status back to the simulation controller control logic unit.

When all simulation controller sub blocks are idle the control logic moves to advance time. If the inactive queue is not empty this is swapped into the active queue and the time step register is incremented. Otherwise if any of the near time queues are not empty they are swapped into the active queue and the time register is incremented by the value of the delayed time queue. If none of the near time queues are empty the future pending register is shifted into the active queue and the future pending time overwrites the current time.

If all the time queues are empty and there is no future pending register set then the simulation is complete and the simulation controller changes state to stopped. The manager puts the hardware into an idle state and the program exits.

In an embodiment illustrates a block diagram of a simulation system in accordance with the above description. The system includes a host computer connected over a PCI Express link to a simulation hardware expansion board . The simulation hardware expansion board contains a simulation hardware FPGA or field programmable gate array and multiple external memory devices . Memory devices are external simulation memory devices. Memory devices are external instruction memory devices. Memory devices are external data memory devices. While only two of each type of external memory device is illustrated in system each type of external memory device may be expanded to n memory devices where n is a positive integer. The external memory devices may also have different speeds. For example external data memory device may be faster than external data memory device . Similarly external simulation memory device may be faster than external data memory device . External instruction memory device may be faster than external instruction memory device because of differences in bandwidth. The memory devices may also have different latencies.

The simulation hardware FPGA contains a simulation controller for performing the semantic operations of an event driven simulation. Multiple parallel logic processors perform all the logical operations of the simulation and also perform non latency critical kernel operations that do not impact performance. The system I O block is used as the bridge between the PC and the simulation hardware FPGA .

The simulation hardware FPGA contains multiple separate address subsystems . Instruction memory subsystem interfaces with the external instruction memory devices as well as internal instruction memory . Data memory subsystem interfaces with the external data memory devices as well as internal data memory . Simulation memory subsystem interfaces with the external simulation memory devices as well as internal simulation memory . Some of the data memory devices between different memory subsystem may use the same physical memory components provided they do not access the same memory addresses.

The instruction memory subsystem is designed to stream multiple long instruction sequences to logic processors from external instruction memory devices and internal instruction memory .

The data memory subsystem is designed to handle multiple outstanding read accesses to small amounts of memory. The data memory subsystem stores small design elements which are frequently accessed in internal data memory while placing larger frequently accessed objects in faster external data memory . Large infrequently accessed objects are stored in slow external data memory .

The organization of the simulation memory subsystem is optimized for different memory fetch behaviors of the simulation controller . The data structures of the simulation design are stored across the different external memory devices and internal memory based on compilation heuristics. As with the data memory subsystem the simulation memory subsystem stores data based on its frequency of access. Small frequently accessed data is stored in internal memory . Large frequently accessed data is stored off chip in for example external memory device which could be SRAM or DDR. Large simulation kernel tables that have predictive memory fetch patterns are stored in external memory device which could be a reduced latency DRAM RLDRAM .

The simulation controller includes elements that map to the event region diagram of an HDL such as Verilog as illustrated in or SystemVerilog as illustrated in as well as elements that map to a simulation time wheel such as that illustrated in . For example is a block diagram demonstrating how the components of the event region diagram of and the simulation time wheel of are memory mapped onto the simulation controller . The semantic queues included in the current time slot of the event region diagram include queues for the active region inactive region NBA region and monitor region and these map to the active events queue the inactive events queue the NBA queue and the monitor queue respectively. The semantic queues included in the software simulator time wheel include queues for the current simulation time the time 0 time 1 time 2 time 3 and future time and these map to the SimTime register the inactive event queue the queue the queue the queue and the next nearest future respectively. The mapping is performed via memory mapped I O .

The compiled HDL design of is illustrated with greater detail in . represents a block diagram of the components of the compiled HDL design . These components include a design symbol table design instruction memory design kernel tables and design data memory . The design symbol table represents an HDL design with each line of the table indicating a symbol for a component in the design. The design instruction memory stores the instructions for simulation of components in the design. The design kernel tables represents the simulation process used to simulate the design and the design data memory stores the input output and generated data used during simulation. Each of these is described in greater detail below in the context of an example illustrated by . However because an understanding of the example requires further explanation of various other components a description of the example and will occur after additional components of the disclosed embodiments have been described.

The translation unit of the time wheel is used to reduce the effort in moving between queues of the simulation event regions as described with reference to . The translation unit contains an array of queue indices which translate the memory mapped queues in to the physical queues in the time wheel . The queue indices also generate a series of empty or non empty status bits corresponding to the memory mapped queues for use by the control logic block .

In order to simulate the advancement of time an advance time control block is used to write to the array of queue indices and when issued a command to do so by the control logic . Time advancement is simulated by changing the physical queue to which a memory mapped queue is mapped.

The scoreboards can be implemented such that external memory is used to keep track of the bits set. The scoreboards can also be implemented such that some range of scoreboard entries are stored in on chip memory while other ranges of scoreboard entries are stored in external memory resources. The scoreboards can also be implemented such that they return an offset and an array of set bits effectively giving a set of bits instead of one bit at a time. This embodiment of the scoreboard would enable the tokenizer to request a larger block of data from the token datapath without requiring multiple cycles to determine memory proximity.

The event processor also implements clock suppression tables. Software HDL compilers in an attempt to improve performance have determined that significant amounts of logic that are sensitive to the edge of a clock may not need to be evaluated unless the inputs to that block have changed since it was last evaluated. See e.g. U.S. Pat. No. 8 311 781 entitled Selectively reducing the number of cell evaluations in a hardware simulation issued on Nov. 13 2012 the entirety of which is herein incorporated by reference. Scoreboards are an ideal storage for containing the information about which logic must be evaluated as a result of a clock edge.

The simulation controller may also be implemented to contain multiple event processors for converting scoreboards into token addresses or tokens. The event processors may also be implemented as having multiple data paths each capable of reading from a given grouping of scoreboards in parallel.

The dispatch engine uses entries to keep track of what token values are running on which logic processors . is a block diagram of an entry used in the dispatch engine . The entry includes a token value . The valid bit indicates whether the entry is valid. The compare bit indicates whether the token value should be compared when searching for a matching token. For example thread tokens as illustrated in require that the compare bit be set to 1. On the other hand NBA tokens as illustrated in require that the compare bit be set to 0.

A scheduler looks at the token enumeration to determine how to schedule the operation with the logic processors . Thread tokens only require that the program counter of the thread be written into the memory mapped control registers of the logic processor . NBA tokens in contrast require writing an application programming interface API register of the logic processor along with the program counter of a pre compiled kernel function that performs the simulation semantic operation. The handler table contains a mapping between the token values and the program counter values of the given functions to be called. The scheduler also keeps track of when the logic process has completed processing a token and clears the token value from the matching dispatch engine entry table or .

The Verilog avalbits and bvalbits data structure is illustrated in which includes a block diagram of the Verilog register format. The format requires 2 bits of data to represent 1 4 state bit of a Verilog register. The avalbits is used to encode the values 0 and 1 when the corresponding bit in bvalbits is 0. The avalbits is used to encode the values X and Z when the corresponding bit in bvalbits is 1. Arithmetic and logic operations of a 2 state data are equivalent to a 4 state data for the values composed only of 0 and 1. These operations only differ for values of X and Z. The processor is able to handle both types of data efficiently by using enhanced load and store instructions that are processed by the load store unit . When 2 state data is read from memory the data is placed in the avalbits and the bvalbits value is set to 0. When 4 state data is read from memory the data is placed in the avalbits and the bvalbits . No additional instructions or additional instruction encoding is necessary to process 2 state or 4 state data or to mix an operation with 1 or more 2 state operands with 1 or more 4 state operands.

Additional instructions to split up and recombine the avalbits and bvalbits data may be added to the instruction set architecture in order to have full control over constructing values.

The register file also contains condition code bits which are standard in most processors. However the condition code bits in the logic processor represent tri nary logic and encode the values true 1 false 0 and unknown x . The logic processor instruction set architecture also contains additional condition code comparison encodings for is unknown and is not unknown in addition to the more common is true and is false condition code comparisons.

The scoreboard provides a memory mappable device that can be used to manage sets of information. The event processor uses a scoreboard to track the notified events for a given event processor iteration. At the beginning of the iteration the scoreboard is empty signifying that no events have been notified. Events accumulate during the time the scoreboard is active. When the translation unit mapping are swapped the scoreboard is used for processing and the index of the bits set is read out. Each of these indices corresponds to an event action that is stored in the event table in memory. Using the linear algebra of y mx b where y represents a pointer to the notified event token m represents the size of the table element in this case an event table entry x represents an index coming from the scoreboard and b represents the table address base the scoreboard indices are able to be mapped to memory locations for event table semantic actions as is illustrated in .

Simulation tokens like NBA token as illustrated in described below provide a layer of indirection between the token and the memory that the token points to. This token indirection can be used for mapping of different scoreboard index ranges to different memory address ranges. Mathematically this is represented as 0

The scoreboards contained within the resource allocator are used in a different way than those used by the event processor . The resource allocator is configured to keep a set of available resources which will be encoded as bits set to 1 in the scoreboard. At the beginning of simulation time a given memory range is divided up into fixed size chunks the address of which is calculated using the y mx b. The software at the start of the simulation will set all the bits in the range to 1 indicating a given memory range resource is available. Software running on logic process or hardware overflow queue controller attempts to allocate a resource like a block of memory to use for future overflow buffers the scoreboard is read and the index of the bit that will be mapped to a memory location using y mx b math is returned. This bit being set to 0 in the scoreboard now indicates that a range of memory is allocated by device that reads the scoreboard could be a logic process or overflow queue controller . When the device or software is done using the resource the index for the value is stored back into the scoreboard making it available for use again by other resources. The scoreboard can return a special index value to indicate that no bits are available and the software or hardware reading this must be able to signal an out of resource error.

The token indirection when used with the resource allocator may allow for better resource utilization. For instance if the overflow buffer resource allocator would run out of memory it is foreseeable that software that handles the error could add more resources to the scoreboard if more resources were available but not mapped. Alternatively the error handle could change the mapping function and copy the old data to a newer larger segment of memory and provide for more bits of allocation in the scoreboard. Using tokens as indirection allows for greater flexibility at the runtime to manage resources.

Hardware resource allocators are a significant performance advantage when compared to software based memory allocation which on a multi threaded system requires locking shared memory. Hierarchical memory allocation with localized allocators trades off multi threaded locking for less resources available to each localized allocator. The hardware based allocator does not suffer either of these performance limitations.

An example of use of the described tokens and table is illustrated in . illustrates an exemplary Verilog design with 2 registers a and b and a wire c which is the combination of the registers a and b. Three initial blocks are present in this design. The first initial block sets the value of a to 0. The second initial block sets the value of b to 0. The third initial block has a delay and then sets the value of a to 1. The simulation of this design will terminate in one time slice after no more events or threads are running.

The next set of instructions starting at address 0x120 performs the same initialization and notification of the same event only this time for the value of the symbol b. The third set of instructions starting at 0x140 is an exemplary representation of the compiled code of the initial block in the exemplary Verilog design of that contains a delay control. The instructions load an immediate value thread token e.g. the token of that starts at the address 0x180 which contains the instructions for the continuation of the thread after the delay of 1 has occurred. This instruction stores the thread token to the memory mapped 1 Queue . Tokens and events are 2 state data and use store word instructions encoded as sw at addresses 0x110 0x130 0x144 and 0x190. After the simulation has advanced simulation time register to the value of 1 the thread token that contains the address of 0x180 will be in the executed.

The final set of instructions starting at address 0x200 perform the combinational logic evaluation for the signal c of exemplary design. The sequence of instructions loads the data values for a and b and performs an logical or operation on the two values and places the result in register 6. The instruction sequence then reads the old value for the symbol c from memory and loads it into register 7. The next instruction compares to see if there is any change to the value of the signal c and sets the condition code 1 if the value has changed. The next instruction stores out the 4 state data for signals c from register 6 into the data memory system if the condition code 1 is true indicating that the value has changed. The next instruction terminates the thread of execution.

The final simulation time increment operation illustrates how the advance time controller must rotate the indices of the time wheel in order to preserve the simulation kernel semantics. When simulation time register was at 0 the queue index pointed to Idx2 a queue that holds events for simulation time . In the next time slice after simulation time register was incremented to 1 the queue index pointed to Idx2 the queue holds events for simulation time .

Upon completing simulation time simulation step the control logic determines that the next nearest queue is the future pending queue and swaps in the index for this time queue with the empty active time queue. When this time queue becomes active the overflow pointer is used to read the data from memory and the time wheel datapath returns the allocated space to the resource allocator.

It should be noted the processors used and described above can include processors with both traditional RISC cores mixed with logic cores. Also DSP or floating point optimized cores to handle the analog portion of an ADMS Analog Digital Mixed Signal simulation would be a logical extension to the current hardware architecture.

The above description and drawings should only be considered illustrative of exemplary embodiments that achieve the features and advantages described herein. Modification and substitutions to specific process conditions and structures can be made. Accordingly the claimed invention is not to be considered as being limited by the foregoing description and drawings but is only limited by the scope of the appended claims.

