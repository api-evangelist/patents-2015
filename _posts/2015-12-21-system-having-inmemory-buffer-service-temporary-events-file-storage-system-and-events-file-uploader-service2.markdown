---

title: System having in-memory buffer service, temporary events file storage system and events file uploader service
abstract: Computer-implemented methods and systems are provided for writing events to a data store. An application server generates events, the data store that stores the events, and a temporary events file storage system (TEFSS) temporarily stores groups of events as events files. When events are unable to be written directly to the data store, an indirect events writer is invoked that includes event capture threads each being configured to generate a particular events file, and write it to the TEFSS. Each events file includes a plurality of events flushed from an in-memory buffer service. An events file uploader service reads the events file(s) from the TEFSS, and then writes the events from each of the events files to the data store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09632849&OS=09632849&RS=09632849
owner: salesforce.com, inc.
number: 09632849
owner_city: San Francisco
owner_country: US
publication_date: 20151221
---
This application claims the benefit of U.S. Provisional Application No. 62 218 871 filed Sep. 15 2015 the entire contents of which are hereby incorporated by reference herein.

This disclosure relates to the field of multi tenant server operation and in particular to an in memory buffer service for a server that provides improved reliability.

A data buffer is a region of a physical memory storage used to temporarily store data while it is being moved from one place to another. In an application server implementing a data buffer data objects may be stored in a buffer as they are retrieved from a client device or application before they are processed or sent elsewhere for more permanent storage. Buffers can be implemented in a fixed memory location in hardware or by using a virtual data buffer in software pointing at a location in the physical memory. Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed or in the case where these rates are variable. A buffer can be used to adjust timing by implementing a queue algorithm in memory simultaneously writing data into the queue at one rate and reading it at another rate.

High throughput scalable continuous events require transportation and queuing to a large data store such as a non relational distributed database like Hbase.

To address this issue and provide that high throughput an In Memory Buffer Service IMBS was recently developed as described for example in U.S. patent application Ser. No. 14 705 750 filed May 6 2015 entitled In Memory Buffer Service and assigned to the assignee of the present invention which is incorporated herein by reference in its entirety. The IMBS is a store and forward based service for objects. The IMBS is designed to provide a very low latency API to write objects to data store e.g. currently it takes 0.08 microseconds to write an object . The IMBS keeps events in memory until the number of objects reaches a configured limit and for a given time e.g. 10 seconds . In one implementation the IMBS can include a capture service running on an application server that receives events from a client application running on an application server to be stored in a data store. The IMBS stores the events in an in memory bounded buffer on the application server. The in memory bounded buffer is responsible to support a concurrently writable API which stores events in memory and includes a buffer flush regulator that manages flushing of this buffer. The in memory bounded buffer includes a plurality of single threaded segments and the capture service can write events to each segment in parallel. When a number of events stored in the in memory bounded buffer reaches a predefined limit the in memory bounded buffer provides a notification to the buffer flush regulator. The in memory bounded buffer receives a request to flush the events in the in memory bounded buffer from a consumer executor service. The consumer executor service is responsible for consuming the events in the in memory bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel to allow the events to be written directly to the data store. Events can be consumed in parallel fashion to allow for high throughput.

Embodiments are described for an in memory buffer service. In certain high volume event systems it may be beneficial to ingest and process events as quickly and efficient as possible i.e. in real time . As used herein the term event refers to a tuple or list of values or elements which represents something that happened. An event is immutable or irreversible and timestamped. The something that happened can be anything. In one context an event can be a tuple that characterizes an action taken by a user with respect to data such as action taken on data that describes an object. For instance an event can refer to data that characterizes an action performed by interaction with respect to a client application being executed at the application server. Events can be monitored and recorded or logged to capture user actions such as the use of applications windows opened system commands executed check boxes clicked text entered edited URLs visited and nearly every other on screen event.

Events can include standard events and custom events. Depending on the implementation processing of events may include ingesting processing and persisting potentially millions of events over the span of an hour or billions of events over the span of a week. For instance a certain system may store up to a week s worth of details from sets of operations that are executed as a single unit e.g. Apex transactions in an open source non relational distributed database such as Apache HBase or other data store. This may be accomplished by pointing a debug log event handler that supplies limit usage information or any other program or component that generates a high volume of events or other data elements to the data store. In other embodiments some other data store may be used such as a NoSQL database a non opensource database a relational database a non distributed database or other type of data store.

In an implementation that averages 7.3 billion Apex executions per month or 243 million per day being stored in the data store storing one row per transaction limit with 8 types of limits would require storing 58.4 billion rows per month or about 1.8 billion rows per day across an entire service. Thus if only raw event data were kept around for a week that would require 13.1 billion rows at a time before being deleted. In other implementations there may be up to 15 types of limits which would result in even more rows being stored. This high volume situation could benefit significantly from a new way for handling event data at scale with high throughput.

In one embodiment an in memory buffer service running on a multi tenant application server provides a low latency application program interface API that writes objects such as event records to the data store. In other embodiments the application server may not server multiple clients but rather is utilized by a single client that generates significant a volume of event data. The in memory buffer service provides a store and forward based service for data objects where those objects e.g. events are temporarily stored in an in memory bounded buffer before being forward to a data store for longer term storage. A capture service can store events in a bounded buffer where they may be kept in memory until the number of objects reaches a predefined limit or the events have been in memory for a predetermined period of time e.g. 5 seconds 10 seconds 30 seconds 1 minute etc. . The in memory buffer provides a very low latency API to write objects and can be done very quickly. For instance in some examples writing the bounded buffer can be done in as little as 0.08 microseconds.

The in memory buffer may be responsible for supporting a concurrently writable API which enables the storing of events in memory and manages flushing of the buffer. In some embodiments the in memory buffer may include a plurality of buffer segments where each segment is single threaded. Each segment can support high read consistency by waiting until all or most write threads are complete before read threads are initiated. Thus each segment may only be read once. Additionally the concurrent bounded buffer comprised of segments may be used to store events concurrently from various threads. The bounded buffer may also maintain a notion of load factor and may support two types of overflow policies. In some embodiments the bounded buffer keeps the latest object by replacing an oldest object with a recent object i.e. first in first out . In another embodiment the bounded buffer drops the latest object if the buffer is full. A buffer flush regulator may further be used to regulate the flushing of the buffer. The regulating may be based on size and time which will queue up the event for consumption and writing to the data store. For example a buffer flush may be initiated when the buffer load reaches some predefined limit e.g. 80 capacity . In one embodiment the concurrent bounded buffer may provide a notification when the number of objects reaches a predefined limit that triggers buffer flushing.

Additionally a consumer executor service is responsible for consuming the in memory buffer and uses a dynamically sized thread pool to consume i.e. process the objects in parallel fashion in order to maximize throughput. The consumer executor service may include a service thread that initiates automatic restarts if a main thread is interrupted. The extension may also include an asynchronous API for starting and stopping a thread. The service thread further may use in one implementation Java s ThreadPool to get worker to run the consumer tasks concurrently and in a reliable manner. The service thread also may iteratively call blockedGetAndReset API of the buffer and may assign a set of data to the consumer task. The consumer task may be eventually run by the ThreadPool s worker thread.

A consumer factory of the consumer executor service allows a user to customize a consumer task. A consumer task may first try to write to the data store e.g. HBase Bigtable MongoDB etc. directly in a given time in order to reduce the load on an asynchronous message delivery mechanism e.g. a message queue MQ and to make data available instantaneously. If writing to the data store fails however the consumer task may enqueue objects in the MQ which eventually writes the objects to the data store via an MQ Handler. In some embodiments a shutdown hook is used to close the service properly when a shutdown of the application server is requested. A log of statistics may also be kept and the consumer executor service may be restarted if it was terminated for unknown reasons.

Each of client devices may be for example a personal computer PC workstation laptop computer tablet computer mobile phone smartphone personal digital assistant PDA or the like. Client devices may communicate with application server to access resources on application server such as client application . For example a user may access client application through a web browser or other HTTP client application on the client device.

In one embodiment application server may be any computing device such as computing system described below with respect to . In one embodiment application server may be a multi tenant application server designed to provide access to a number of client applications such as client application to one more client devices such as client devices . In another embodiment application server may be a single tenant application server design to service a single client. Client application and other resources provided by application server such as processing resources storage resources etc. may be maintained by application server and made available to the users of client devices as needed i.e. on demand . This application server can include various elements of hardware and software of a database system may be shared by one or more customers or tenants. For example application server may simultaneously process requests for a great number of customers. Application server may include an application platform including a framework that allows the applications to execute such as the hardware or software infrastructure of the system. In one embodiment the application platform enables the creation management and execution of one or more applications such as client application developed by the provider of the application server customers accessing the application server via client devices or third party application developers.

In one embodiment application server includes in memory buffer service . In memory buffer service can ingest and process events generated by client application buffer those events and eventually store the events in data store . In one embodiment data store provides an application programming interface API which can be called by the in memory buffer service in order to store the events in data store . In one embodiment data store may be an open source non relational distributed database such as Apache HBase Bigtable MongoDB or other data store. Examples of events generated by client application may include errors exceptions faults failures crashes incidents or other occurrences. For example client application may include a user interface layer that presents a user interface visible on one of client devices . Through selection of a user interface element the user may initiate some processing operation in a logical layer of the client application that hits some hard limit defined by the application server e.g. number of processing cycles consumed per day amount of storage resources consumed and page rendering is stopped. The reaching of this hard limit may trigger the creation of an event by client application which is recorded for possible future review. The volume at which such events are potentially generated and conventional means for recording and storing these events may result in an unacceptable level of latency. As such in one embodiment in memory buffer service can ingest and process the events buffer the events and eventually store the events in data store . The buffering of the events in memory before storage in data store can allow a high volume of events to be processed in near real time with minimal latency and without adversely affecting performance of the application server or client application . Additional details of the in memory buffer service are provided below.

Client application may be any type of computer application program that generates events. For example client application may be an entertainment application productivity application business application social networking application or other types of application. In one embodiment in memory buffer processes events for storage in data store . In other embodiments in memory buffer may process any other type of data object for storage in data store or elsewhere. In one embodiment a capture service running on application server receives events from client application that are to be stored in data store . Capture service temporarily stores the received events in bounded buffer . The bounded buffer may include a plurality of single threaded segments to which the capture service can write the events in parallel. In one embodiment bounded buffer may include 16 single threaded segments each of which can be written in parallel with a different event generated by client application . The size of bounded buffer is configurable according to the particular implementation. In one embodiment the buffer size may be approximately 10 megabytes MB to 20 MB. In other embodiments the buffer may have a different size such as 1 MB 50 100 MB 1 terabyte TB etc. .

In one embodiment in memory buffer service further includes a buffer flush regulator . Buffer flush regulator controls when bounded buffer is emptied i.e. flushed for consumption by consumer executor service and storage in data store . In one embodiment logic associated with bounded buffer monitors the load on bounded buffer and provides a notification to the buffer flush regulator when the number of events stored in the bounded buffer reaches a predefined limit e.g. 80 full or when a predefined amount of time has passed since a contents of the bounded buffer was written to data store e.g. 10 seconds . In one embodiment consumer executor service periodically sends a request for buffer flushing to buffer flush regulator . Buffer flush regulator determines whether a notification has been received from bounded buffer indicating that either the predefined size limit or the predefined time limit has been reached. If not buffer flush regulator delays the request. This way if the buffer flush regulator has not received any notification from single threaded segments then buffer flush regulator make the request for buffer flushing from the consumer executor service to wait until it either gets notification or the time delay is over. If the notification has been received buffer flush regulator grants the request and consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. By consuming the events consumer executor service reads the events from bounded buffer and writes the events to data store .

In some situations all of the segments of bounded buffer may be filled with events and new events are received by capture service before buffer flush regulator can empty the contents of bounded buffer . Bounded buffer may handle this situation in a number of different ways according to a defined overflow policy. In one embodiment bounded buffer may implement a keep latest overflow policy where the oldest event in bounded buffer is overwritten with the newly received event from client application . In another embodiment bounded buffer may implement a drop latest overflow policy where the newly received event is prevented from being stored in bounded buffer .

In one embodiment in memory buffer service further includes buffer flush regulator . Buffer flush regulator controls when bounded buffer is emptied i.e. flushed for consumption by consumer executor service and storage in data store . In one embodiment in memory buffer service monitors the load on the buffer segments and provides a notification to the buffer flush regulator when a certain portion or percentage of the buffer segments are full e.g. 80 full or when a predefined amount of time has passed since a contents of the buffer segments were flushed e.g. 10 seconds . In one embodiment a main service thread in consumer executor service may periodically send a request for buffer flushing to buffer flush regulator . Buffer flush regulator may determine whether a notification has been received from bounded buffer indicating that either the predefined size limit or the predefined time limit have been reached. If not buffer flush regulator delays the request. If the notification has been received buffer flush regulator grants the request and consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. Dynamically sized thread pool can add or remove consumer threads so that the number of consumer threads matches the number of buffer segments being consumed. For example if all 16 segments are being read dynamically sized thread pool can have 16 consumer threads . If however only 8 buffer segments contain events then thread pool need only include 8 threads . The consumer threads read the events from buffer segments in parallel and write the events to data store .

Under normal operation the threads of the dynamically sized thread pool in consumer executor service may write the events read from either bounded buffer or bounded buffer directly to data store . Depending on the implementation however the data store may be a distributed system and possibly take a significant period of time to be written. In such a case or if all or a portion of the data store is temporarily unavailable consumer executor service may enqueue the events from the bounded buffer or in a message queue for subsequent writing to data store after data store becomes available. In one embodiment consumer executor service may first try to write directly to data store but if data store does not respond within some period of time message queue may be utilized. Message queue may be any available in memory or out of memory data structure that can temporarily accommodate the events before they are stored in data store . In one embodiment message queue may be large enough to store the contents of one bounded buffer at a time. In another embodiment message queue may be large enough to store the contents of multiple buffers concurrently.

Referring to at block method receives events from client application . In one embodiment a capture service running on application server receives events from client application that are to be stored in data store . In another embodiment capture service may receive generic data objects from some other source for in memory buffering.

At block method determines whether in memory bounded buffer is full. In one embodiment bounded buffer may include 16 single threaded segments each of which can be written in parallel with a different event generated by client application . In one embodiment in memory buffer service determines whether each of the buffer segments has been written with an event. If each segment contains an event then in memory buffer service determines that the bounded buffer is full. If there are one or more segments of the bounded buffer that do not contain events then in memory buffer service determines that the bounded buffer is not full.

If in memory bounded buffer is not full at block method stores the received events in the in memory bounded buffer . In one embodiment capture service writes the received events to one or more of the segments of in memory bounded buffer in parallel.

If in memory bounded buffer is full at block method applies a buffer overflow policy prior to storing the events. In one embodiment bounded buffer may implement a keep latest overflow policy where the oldest event in bounded buffer is overwritten with the newly received event from client application . In another embodiment bounded buffer may implement a drop latest overflow policy where the newly received event is prevented from being stored in bounded buffer .

At block method determines if a predefined limit has been reached. In one embodiment in memory buffer service monitors the load on bounded buffer and determines when the number of events stored in the bounded buffer reaches a predefined limit e.g. 80 full or when a predefined amount of time has passed since a contents of the bounded buffer was written to data store e.g. 10 seconds . If the predefined limit has been reached at block method provides a notification to buffer flush regulator . In one embodiment in memory buffer service provides the notification to buffer flush regulator .

At block method receives a buffer flush request from consumer executor service . In one embodiment consumer executor service may periodically send a request for buffer flushing to buffer flush regulator . The period with which the request is sent can be configurable depending on the particular implementation.

At block method determines whether the in memory bounded buffer is ready to be flushed. Buffer flush regulator may determine whether a notification has been received from bounded buffer at block indicating that either the predefined size limit or the predefined time limit have been reached. If not buffer flush regulator denies the request.

If the in memory bounded buffer is ready to be flushed at block method determines whether the data store is available. Depending on the implementation the data store may be a distributed system and possibly take a significant period of time to be written. In such a case all or a portion of the data store may be temporarily unavailable.

If the data store is available at block method consumes the events from the in memory bounded buffer by writing the events directly to the data store . In one embodiment consumer executor service may consume the events in the bounded buffer using a dynamically sized thread pool of consumer threads to read the segments of the bounded buffer in parallel. By consuming the events consumer executor service reads the events from bounded buffer and writes the events to data store .

If the data store is not available at block method enqueues the events from in memory bounded buffer in a message queue for subsequent writing to the data store after the data store becomes available. Message queue may be any available in memory or out of memory data structure that can temporarily accommodate the events before they are stored in data store . In one embodiment message queue may be large enough to store the contents of one bounded buffer at a time. In another embodiment message queue may be large enough to store the contents of multiple buffers concurrently.

Because the in memory buffer service is implemented in memory it is inherently lossy. For example if the application server crashes then objects events that the server is holding in memory and that have not been written to the data store can be lost. To help address this issue the IMBS can implement the message queue to improve reliability as described above.

However due to limits in scalability the reliability of the message queue can be somewhat limited. The MQ operates as a message queue backed by a large relational transactional data store with guaranteed message delivery. Enqueuing events in the MQ can have relatively high latency. This can be problematic when the number of events has a high volume e.g. on the order of 200 millions events per day . Because of high latency during high load time the buffer can starts to overflow since worker threads of consumer executor service are busy with events enqueuing. For instance when the consumer does not finish in a given time and the buffer starts to overflow.

Further in some situations the data store may not be available. For example the data store might undergo upgrades or other maintenance tasks that make it unavailable such that events cannot be written which reduces reliability of the system. According to one estimate when the large data store is unavailable IMBS could potentially drop up to 80 of events.

These issues can be problematic and unacceptable in certain use cases or environments for instance in compliance use cases where auditors want to know about access e.g. where it is necessary to track events such as who exported the customer list . Thus although IMBS has many benefits it would be desirable to improve reliability of the IMBS. To address these issues the in memory buffer service illustrated in can be modified as shown in .

When the consumer threads are unable to write events directly to the event table at the data store within a certain time the indirect events writer can be invoked. The indirect events writer includes a dynamically sized thread pool of event capture threads . Each event capture thread can create an events file that includes events from a corresponding consumer thread . Each event capture thread can temporarily write the events in batches as events files to the TEFSS . For example each event capture thread can serialize multiple events into events files that can then be temporarily stored at the TEFSS .

The events file uploader service is a separate daemon thread running in the application server . The events file uploader service can retrieve based on job detail information metadata stored in an events uploader job detail table not illustrated at the data store the events files from the TEFSS and then write upload the events from each of those retrieved events files to an event table not illustrated at the data store at a later time.

By adding a secondary storage option the TEFSS the event capture capability of the IMBS can be improved by significantly reducing loss of events without creating additional latency. For instance in one implementation it has been observed that the improved IMBS can reduce the 80 loss described above down to 0.02 loss without introducing additional latency. The temporary events file storage system TEFSS can help solve the scalability problem with MQ because the TEFSS is not backed by a large relational transactional data store and is not transactional in nature. Rather the TEFSS operates as a separate file storage system that provides much higher throughput and lower latency. To explain further the TEFSS is a data store that can store unstructured data as files e.g. that contain arbitrary and possibly unrelated data with no ordering or organizing structure required . In contrast to the MQ the TEFSS provides much higher throughput and has much lower latency. Moreover the TEFSS is available to write regardless of whether the tenant database is in read only mode which increases reliability of the system. To explain further the MQ relies on the tenant database to persist its metadata and data. If the tenant database is in read only mode e.g. during an upgrade events cannot be enqueued. By contrast the TEFSS does not go into a read only mode so events can be enqueued anytime.

As described above with reference to the capture service receive events from the client application running on the application server and provides the events to the in memory buffer service . The in memory buffer service temporarily holds the events in a bounded buffer that is implemented in physical memory at the application server. The bounded buffer includes a plurality of single threaded buffer segments that are each configured to temporarily hold some of the events received from the capture service until a flush operation is performed. The buffer flush regulator will perform a flush operation at regular intervals for example once every 10 seconds to flush the in memory buffer . The consumer executor service includes a dynamically sized thread pool of consumer threads that execute in parallel. Each of consumer threads corresponds to a particular single threaded buffer segment . When the flush operation occurs events stored in one of the buffer segments are then passed to a corresponding consumer thread .

Each consumer thread can include an instance of an events reader that reads events flushed from a corresponding one of the single threaded buffer segments assigns a unique identifier to each event that will be used at the data store adds that unique identifier to each event and then passes a result to the direct events writer . Each consumer thread can include an instance of a direct events writer is designed to write the events directly to the data store . In most scenarios the direct events writer can successfully write the events received from the events reader directly to the data store . However in some cases the direct events writer cannot write the events directly to the data store . For example the data store can have periods of lower responsiveness. For instance in some cases as the data gets written to the data store there are maintenance tasks e.g. such as splitting storage units regions as they get too large for a given storage unit region . Another example would be periodic re organization of data or compaction which takes care of things like deleted records.

To provide additional reliability in situations where the direct events writer is unable to successfully write events to the data store the indirect events writer provides a number of event capture threads corresponding to each of the consumer threads . Each event capture thread includes an instance of an invoker and an instance of an events file writer . Each invoker can determine if a corresponding instance of the direct events writer was able to successfully write events that it read from a particular single threaded buffer segment to an event table at the data store . Each invoker also receives the events from a particular single threaded buffer segment via the direct events writer . When an invoker determines that the corresponding instance of the direct events writer was unable to successfully write events directly to the data store e.g. invoker receives an indication that the direct events writer is unable or has failed to write events to the data store the invoker invokes an instance of the TEFSS events file writer at that event capture thread . The invoker will then communicate the events to the TEFSS events file writer which serializes events from the particular single threaded buffer segment into a single events file and then writes the events file to the TEFSS . Examples of events files stored at the TEFSS are illustrated in .

Each events file written to the TEFSS by the TEFSS events file writer can include a group identifier group ID that uniquely identifies a group of events files that were generated during a particular time window a file name not explicitly labeled in and file information not illustrated in . The file name can include an application server name of the application server that generated the events in the events file a creation date for each of the events in the events file where the creation date is specified as events for Mmddyyyy HHmm SSS where MM is the month dd is the day yyyy is the year HH is the hour mm is the minutes and SSS is the second when the events file was created and a thread identifier thread ID that specifies the name of the event capture thread writing the events file. The group ID identifies the group that the events file uploader service inspects to identify an events file to process. A new group identifier group ID for each events file can be generated at regular intervals for example once every 10 minutes in an implementation where separate events files are generated once every ten minutes. The application server name the creation date and the thread identifier thread ID make up the file name for the particular events file. The file information in each events file can include a file type e.g. Gzip File and events that are serialized using standard approaches for serializing objects or a collection of objects for example such as a JSON format Avro or protocol buffer in accordance with some exemplary implementations.

In the non limiting embodiment that is illustrated in an uploader job record for an events file includes various columns of metadata that include but are not limited to a cluster identifier that uniquely identifies a collection of instances that a grouped as a cluster of application servers an instance identifier that uniquely identifies a collection of application servers grouped as an instance an application server name of a particular application server a group identifier that uniquely identifies a group of events files that were generated during a particular time window a file name of the particular events file a job started date that specifies when the particular events file was created a number of events that specifies a number of events for this particular events file a number of events that specifies a number of events for this particular events file a last updated time that indicates when the particular events file was last updated a number of retry attempts that specifies how many times the events file uploader service has attempted to process the particular events file the job type that indicates either regular or backup and a status that indicates either running or completed. Although not illustrated it should be appreciated that the uploader job record for each events file can include other fields such as file size information regarding the file size of the particular events file a time to live TTL value etc.

An events file uploader service runs on each application server of a cloud computing service provider. A particular instance of the events file uploader service that runs on a particular application server of that cloud computing service provider can be identified by the combination of 

Each row of the events uploader job detail table includes a row key that is used by an events uploader manager to look up job detail information for a particular event file. A row key for a row of the events uploader job detail table is defined by the combination of the instance identifier the application server name the group identifier the file name and the job started date .

Referring again to at communication the events uploader manager receives or retrieves at least some of the job detail information from the events uploader job detail table that is stored at the data store . The events uploader manager is invoked with the application server name the group identifier and the job type e.g. either backup or regular .

At communication the events uploader manager reads all of the names of events files available for a particular application server from the TEFSS . At the events uploader manager then assigns each of the worker threads one of the events file names i.e. assigns a file name of specific events file to one of the worker threads .

Each worker thread includes events file reader that is responsible for reading an events file from the TEFSS and event loader that is responsible for uploading events from that events file to the data store .

Each events file reader retrieves an events file from the TEFSS that corresponds to particular events file name and adds a record in the events uploader job detail table with current time as job started time. Each events file reader then provides that events file to a corresponding instance of event loader that writes each event in the events file to the data store . Specifically event loader writes each event in the events file to the event table of the data store and then updates the record in the events uploader job detail table with a retry attempt.

Prior to describing it is noted that as described above with reference to capture service receives events that are to be stored in a data store from a client application running on the application server and temporarily stores the events in a bounded buffer that is part of the in memory buffer service . The bounded buffer is implemented in physical memory at the application server and comprises a plurality of single threaded buffer segments . The single threaded buffer segments are each configured to temporarily store some of the events until a flush operation is performed by the buffer flush regulator .

At the buffer flush regulator flushes the plurality of single threaded buffer segments of the bounded buffer and the consumer executor service instantiates a plurality of consumer threads that each corresponds to a particular single threaded buffer segment . As shown in each consumer thread includes an instance of an events reader and an instance of a direct events writer . the The buffer flush regulator can perform the flush operation at regular intervals for example once every 10 seconds to flush the in memory buffer and events from one of the buffer segments are then passed to the consumer thread .

At the events reader of each consumer thread reads the events flushed from the particular single threaded buffer segment that corresponds to that consumer thread and each direct events writer adds an identifier to each event and then passes a result to a direct events writer which is designed to write the events directly i.e. without any intermediate storage or processing steps to the data store .

At each direct events writer attempts to directly write each event it has received to the data store .

As shown in each of the event capture threads includes an instance of an invoker and an instance of a TEFSS events file writer .

At each invoker can determine if its corresponding direct events writer was able to successfully write events that were read from the particular single threaded buffer segment directly to the event table at the data store within constraints imposed. These constraints can be any combination of time based attempt based failure based error based measures that indicate that the direct events writer was unable to write events to the data store .

In many normal operational scenarios the direct events writer can successfully write an event directly to the event table at the data store . In this case the method loops to . However in some operational scenarios described above events cannot be written directly to the data store and additional mechanisms are invoked to provide additional reliability.

Whenever an instance of an invoker at one of the event capture threads determines that a corresponding instance of the direct events writer was unable to successfully directly write the events directly to an event table at the data store the invoker invokes an instance of the TEFSS events file writer at that event capture thread . Then at the invoker communicates the events that are received from that corresponding instance of the direct events writer to the TEFSS events file writer .

At the TEFSS events file writer of each event capture thread can generate a particular events file that includes a plurality of events received from an in memory buffer service and then write that particular events file to the TEFSS . The TEFSS is configured to temporarily store events files for subsequent writing to the data store when the data store becomes available. Each instance of the TEFSS events file writer can serialize the plurality of events received from the particular single threaded buffer segment into an events file. In addition at an uploader job record at the uploader job detail table .

At the events uploader manager can receive or retrieve job detail information from one or more particular uploader job records stored at the events uploader job detail table . Based on the job detail information retrieved the events uploader manager determines at least one events file for the application server that needs to retrieved from the TEFSS .

At the events uploader manager can read events file names for all of the events files that are available for a particular application server from the TEFSS and need to be retrieved from the TEFSS .

At the events uploader manager can then assign each worker thread a name of a particular events file. This way each events file name s retrieved from the TEFSS can be assigned to one instance of the worker thread . As described above each worker thread comprises a particular events file reader and a particular event loader .

At each of the events file readers can use the events file name to read retrieve an appropriate events file that corresponds to particular events file name from the TEFSS and then provide the retrieved events file to a corresponding instance of the event loader . In addition at the events uploader manager creates an uploader job record that points to the particular events file stored at the TEFSS and writes the uploader job record to the events uploader job detail table maintained at the data store . This uploader job record can include the information indicated above.

At each event loader can upload write each of the events from the particular events file to the event table of the data store . In addition at the events uploader manager updates the uploader job record at the events uploader job detail table with a retry attempt. Each event loader will attempt a certain number of retries in the event of a transport failure and if the event loader is unable to write events from the particular events file to the event table the event loader will wait for a time period before retrying to write events from the particular events file to the event table . In one non limiting implementation the period between retry attempts can be set using an exponential backoff algorithm e.g. where the period is set per a formula such as 2 60 1000 milliseconds .

The events file uploader service can operate in a regular mode or a backup mode. The regular events file uploader service runs at an application server to transfer events files created by that application server from the TEFSS to the data store . The regular events file uploader service runs continuously at the application server and does not terminate. For instance in one embodiment the regular events file uploader service is implemented using a continuously running dameon thread.

By contrast the backup events file uploader service can run periodically or according to a schedule. For instance in one embodiment the backup events file uploader service can be implemented as a time based job scheduler utility that allows tasks jobs to be automatically run at regular intervals e.g. periodically at fixed times dates or intervals by the backup daemon. The backup events file uploader service runs at an application server to transfer events files that were created by another application server from the TEFSS to the data store . This way when an application server that is part of the cluster is unavailable e.g. has crashed and is unable to transfer its own events files from the TEFSS to the data store another application server in that cluster that is available can run the backup events file uploader service to transfer events files that were created by the unavailable application server from the TEFSS to the data store .

Embodiments of the regular events file uploader service will be described below with reference to and embodiments of the backup events file uploader service will be described with reference to

At the events uploader manager reads the most recent uploader job record for the current application server from the events uploader job detail table .

At the regular events uploader manager searches the most recent uploader job record for the application server for a starting group identifier that uniquely identifies a group of events files generated by the application server during a particular time window. To explain further each group identifier is associated with a time window of a certain duration e.g. 10 minutes . In one embodiment the group identifier has a format Events MMddYYYYHHmm. The minute part mm represent a minute range of a certain duration. For example if the time window is set to 10 minutes then the group identifier can be 0 10 20 30 40 or 50. For example a group identifier of 0 would represent that the events file was generated during a time window that spans anywhere between the start 0 up to but not including the 10th minute whereas a group identifier of 20 would represent that the events file was generated during a time window that spans anywhere between the start of the 20th minute up to but not including the 30th minute whereas a group identifier of 50 would represent that the events file was generated during a time window that spans anywhere between the start of the 50th minute up to but not including the 60th minute. The significance of this is that if a group identifier has a minute part mm that is the same as a current time then that group identifier is the group identifier for the current time window. One exemplary implementation of will be described in greater detail below with reference to .

At the regular events uploader manager determines from the most recent uploader job record whether a status for the most recent uploader job record indicates running or completed. When the status of the most recent uploader job record indicates running this means that the job is in a running state e.g. the process which is consuming the events file has not reached the completed state and the method proceeds from to as will be described below.

When the status of the most recent uploader job record indicates running this means that the job is in a running state e.g. the process which is consuming the events file has not reached the completed state and the method proceeds from to where the regular events uploader manager upserts the most recent uploader job record for the application server at the events uploader job detail table with updated job detail information to indicate that the regular events uploader manager has started to process and read the events file. In this case the file name is already available in uploader job record . The method then proceeds to as described below.

When the status of the most recent uploader job record indicates completed this means the events file recorded in this uploader job record is processed successfully and itis time to search for and process next available events file. Therefore when the status of the most recent uploader job record indicates completed the method proceeds to where the regular events uploader manager searches the TFESS for an events file that includes the starting group identifier.

At the events uploader manager determines if an events file that is associated with the starting group identifier was able to be read from the TEFSS . When the events uploader manager determines at that an events file that is associated with the starting group identifier was not able to be read from the TEFSS the method proceeds to where the events uploader manager determines the next available group ID that uniquely identifies another group of events files generated by the application server during another particular time window. At the events uploader manager determines whether this next possible group identifier is for a current time window or corresponds to the current time window .

When the events uploader manager determines at that this next possible group ID is for a current time window then the method proceeds to where the events uploader manager waits for a time period e.g. 10 minutes before the method loops back to where the regular events uploader manager searches the TFESS for an events file that includes the next possible group identifier. When the events uploader manager determines at that this next possible group ID is not for the current time window then the method loops to where the regular events uploader manager searches the TFESS for an events file that includes the next possible group identifier.

When the events file that includes the starting group identifier was able to be read from the TEFSS at the regular events uploader manager assigns a worker thread for the particular events file that was read at . The worker thread includes a particular events file reader and a particular event loader .

At the events file reader upserts the most recent uploader job record for the application server at the events uploader job detail table with updated job detail information. As used herein the term upserting refers to a combination of updating i.e. refreshing an existing record that already exists and inserting i.e. inserting a new record if a match is not found . In other words one data set can be used to update existing records at the same time new records are inserted. The method then proceeds to where the events file reader reads the events file serializes the events from the events file and sends the events to the event loader .

At the event loader loads and saves each of the events from the events file to a row of the event table maintained at the data store . At the events uploader manager updates the status of the uploader job record that corresponds to the events file to indicate completed in the events uploader job detail table . At the events uploader manager deletes the events file from the TEFSS .

The method then loops to where the regular events uploader manager searches the TFESS for another events file that includes the group identifier. To explain further more than one events file can have the same group identifier so the regular events uploader manager searches the TFESS for more events files having the group identifier. If the regular events uploader manager determines that there is no events file available for a given application server for that group identifier and it is not for current time window then the regular events uploader manager will move to next possible group identifier based on next minute range window.

At the events uploader manager reads the most recent uploader job record for the current application server from the events uploader job detail table and determines whether the most recent uploader job record for the application server is null i.e. there is no uploader job record against this application server name in the events uploader job detail table .

When the events uploader manager determines at that the most recent uploader job record is not null i.e. that an uploader job record for the current application server was successfully read then method proceeds to where the events uploader manager reads the group identifier from the most recent uploader job record for the application server and the method then proceeds to where the regular events uploader manager searches the TFESS for an events file that includes the starting group identifier.

When the events uploader manager determines at that the most recent uploader job record is null the method proceeds to where the events uploader manager attempts to read a marker file for the application server from the TEFSS and then determines at whether the marker file for the application server was read from the TEFSS . In one embodiment the marker file is a simple text file which records the first group identifier when uploader service starts for the first time on an application server.

When the regular events uploader manager determines that the marker file for the application server was read from the TEFSS the method proceeds to where the regular events uploader manager reads a group identifier stored in the marker file. The method then proceeds to where the regular events uploader manager searches the TFESS for an events file that includes the starting group.

When the events uploader manager determines that a marker file for the application server was not able to be read from the TEFSS the method proceeds to where the regular events uploader manager reads the oldest group identifier stored in a cache at the application server that stores group identifier for that application server.

The method then proceeds to where the regular events uploader manager creates a marker file with the group identifier that was retrieved from the cache at the application server. The method then proceeds to where the regular events uploader manager searches the TFESS for an events file that includes the starting group identifier.

At the events uploader manager of the second application server attempts to find an application server in the cluster that has been inactive for a certain duration e.g. 30 minutes in one implementation . For example in one embodiment the events uploader manager of the second application server searches the events uploader job detail table for all inactive application servers i.e. all application servers that do not have an uploader job record that was started or updated within the certain duration and randomly selects one of the application servers.

At the events uploader manager determines whether an inactive application server in the cluster has been found. While this could be any application server in the cluster for purposes of the following example it will be assumed that the events uploader manager has determined that the first application server is inactive. However it is noted that if the events uploader manager of the second application server cannot find an inactive application server then method proceeds to where the backup events file uploader service terminates.

At the backup events uploader manager reads the most recent uploader job record for the first application server from the events uploader job detail table . At the backup events uploader manager searches the most recent uploader job record for the first application server for a starting group identifier that uniquely identifies a group of events files generated by the first application server during a particular time window. As explained above each group identifier is associated with a time window of a certain duration e.g. 10 minutes . If a group identifier has a minute part mm that is the same as a current time then that group identifier is the group identifier for the current time window.

At backup events uploader manager determines from the most recent uploader job record whether the status of the uploader job record indicates that it is running or completed.

When the status of the most recent uploader job record indicates running this means that the job is in a running state e.g. the process which is consuming the events file has not reached the completed state and the method proceeds from to as will be described below.

When the backup events uploader manager determines at that the status of the most recent uploader job record indicates that it has been completed this means the events file recorded in this uploader job record is processed successfully and it is time to search for and process next available events file. Therefore when the status of the most recent uploader job record indicates completed the method proceeds to where the backup events uploader manager of the second application server searches the TFESS for an events file that includes the starting group identifier.

At the backup events uploader manager determines whether an events file that is associated with the starting group identifier was able to be read from the TEFSS .

When the events uploader manager determines at that an events filethat is associated with the starting group identifier was not able to be read from the TEFSS the method proceeds to where the backup events uploader manager determines a next possible group identifier that uniquely identifies another group of events files generated by the first application server during another particular time window and the method proceeds to . At the backup events uploader manager determines whether the next possible group identifier is for a current time window or corresponds to the current time window . When the next possible group identifier is determined at not to be for the current time window the method proceeds to where the backup events uploader manager searches the TFESS for an events file that includes the next possible group identifier. By contrast when the next possible group identifier is determined at to be for the current time window the method proceeds to where the backup events uploader manager terminates the events file uploader service at the second application server.

When the events uploader manager determines at that an events file that includes the starting group identifier was able to be read from the TEFSS the method proceeds to . The backup events uploader manager assigns a worker thread for the particular events file that was read at . The worker thread includes a particular events file reader and a particular event loader . At where the backup events uploader manager upserts the most recent uploader job record for the first application server at the events uploader job detail table with updated job detail information. The method then proceeds to where the events file reader reads the events file serializes the events from the events file and sends the events to the event loader .

At the event loader loads and saves each of the events from the events file to a row of the event table maintained at the data store . At the backup events uploader manager updates the status of the uploader job record in the events uploader job detail table that corresponds to the events file to indicate completed. At the events uploader manager deletes the events file from the TEFSS .

Because more than one events file can have the same group identifier the method then loops to where the backup events uploader manager searches the TFESS for another events file that includes the group identifier.

When the status of the most recent uploader job record indicates running this means that the job is in a running state e.g. the process which is consuming the events file has not reached the completed state and the method proceeds from to . At the backup events uploader manager upserts the most recent uploader job record for the first application server at the events uploader job detail table with updated job detail information to indicate that the backup events uploader manager has started to process and read the events file. In this case the file name is already available in uploader job record . The method then proceeds to as described above.

The following description is of one example of a system in which the features described above may be implemented. The components of the system described below are merely one example and should not be construed as limiting. The features described above with respect to may be implemented in any other type of computing environment such as one with multiple servers one with a single server a multi tenant server environment a single tenant server environment or some combination of the above.

In some implementations the environment is an environment in which an on demand database service exists. An on demand database service such as that which can be implemented using the system is a service that is made available to users outside of the enterprise s that own maintain or provide access to the system . As described above such users generally do not need to be concerned with building or maintaining the system . Instead resources provided by the system may be available for such users use when the users need services provided by the system that is on the demand of the users. Some on demand database services can store information from one or more tenants into tables of a common database image to form a multi tenant database system MTS . The term multi tenant database system can refer to those systems in which various elements of hardware and software of a database system may be shared by one or more customers or tenants. For example a given application server may simultaneously process requests for a great number of customers and a given database table may store rows of data such as feed items for a potentially much greater number of customers. A database image can include one or more database objects. A relational database management system RDBMS or the equivalent can execute storage and retrieval of information against the database object s .

Application platform can be a framework that allows the applications of system to execute such as the hardware or software infrastructure of the system . In some implementations the application platform enables the creation management and execution of one or more applications developed by the provider of the on demand database service users accessing the on demand database service via user systems or third party application developers accessing the on demand database service via user systems .

In some implementations the system implements a web based customer relationship management CRM system. For example in some such implementations the system includes application servers configured to implement and execute CRM software applications as well as provide related data code forms renderable web pages and documents and other information to and from user systems and to store to and retrieve from a database system related data objects and Web page content. In some MTS implementations data for multiple tenants may be stored in the same physical database object in tenant database . In some such implementations tenant data is arranged in the storage medium s of tenant database so that data of one tenant is kept logically separate from that of other tenants so that one tenant does not have access to another tenant s data unless such data is expressly shared. The system also implements applications other than or in addition to a CRM application. For example the system can provide tenant access to multiple hosted standard and custom applications including a CRM application. User or third party developer applications which may or may not include CRM may be supported by the application platform . The application platform manages the creation and storage of the applications into one or more database objects and the execution of the applications in one or more virtual machines in the process space of the system .

According to some implementations each system is configured to provide web pages forms applications data and media content to user client systems to support the access by user systems as tenants of system . As such system provides security mechanisms to keep each tenant s data separate unless the data is shared. If more than one MTS is used they may be located in close proximity to one another for example in a server farm located in a single building or campus or they may be distributed at locations remote from one another for example one or more servers located in city A and one or more servers located in city B . As used herein each MTS could include one or more logically or physically connected servers distributed locally or across one or more geographic locations. Additionally the term server is meant to refer to a computing device or system including processing hardware and process space s an associated storage medium such as a memory device or database and in some instances a database application for example OODBMS or RDBMS as is well known in the art. It should also be understood that server system and server are often used interchangeably herein. Similarly the database objects described herein can be implemented as part of a single database a distributed database a collection of distributed databases a database with redundant online or offline backups or other redundancies etc. and can include a distributed database or storage network and associated processing intelligence.

The network can be or include any network or combination of networks of systems or devices that communicate with one another. For example the network can be or include any one or any combination of a LAN local area network WAN wide area network telephone network wireless network cellular network point to point network star network token ring network hub network or other appropriate configuration. The network can include a TCP IP Transfer Control Protocol and Internet Protocol network such as the global internetwork of networks often referred to as the Internet with a capital I . The Internet will be used in many of the examples herein. However it should be understood that the networks that the disclosed implementations can use are not so limited although TCP IP is a frequently implemented protocol.

The user systems can communicate with system using TCP IP and at a higher network level other common Internet protocols to communicate such as HTTP FTP AFS WAP etc. In an example where HTTP is used each user system can include an HTTP client commonly referred to as a web browser or simply a browser for sending and receiving HTTP signals to and from an HTTP server of the system . Such an HTTP server can be implemented as the sole network interface between the system and the network but other techniques can be used in addition to or instead of these techniques. In some implementations the network interface between the system and the network includes load sharing functionality such as round robin HTTP request distributors to balance loads and distribute incoming HTTP requests evenly over a number of servers. In MTS implementations each of the servers can have access to the MTS data however other alternative configurations may be used instead.

The user systems can be implemented as any computing device s or other data processing apparatus or systems usable by users to access the database system . For example any of user systems can be a desktop computer a work station a laptop computer a tablet computer a handheld computing device a mobile cellular phone for example a smartphone or any other Wi Fi enabled device wireless access protocol WAP enabled device or other computing device capable of interfacing directly or indirectly to the Internet or other network. The terms user system and computing device are used interchangeably herein with one another and with the term computer. As described above each user system typically executes an HTTP client for example a web browsing or simply browsing program such as a web browser based on the WebKit platform Microsoft s Internet Explorer browser Netscape s Navigator browser Opera s browser Mozilla s Firefox browser or a WAP enabled browser in the case of a cellular phone PDA or other wireless device or the like allowing a user for example a subscriber of on demand services provided by the system of the user system to access process and view information pages and applications available to it from the system over the network .

Each user system also typically includes one or more user input devices such as a keyboard a mouse a trackball a touch pad a touch screen a pen or stylus or the like for interacting with a graphical user interface GUI provided by the browser on a display for example a monitor screen liquid crystal display LCD light emitting diode LED display among other possibilities of the user system in conjunction with pages forms applications and other information provided by the system or other systems or servers. For example the user interface device can be used to access data and applications hosted by system and to perform searches on stored data and otherwise allow a user to interact with various GUI pages that may be presented to a user. As discussed above implementations are suitable for use with the Internet although other networks can be used instead of or in addition to the Internet such as an intranet an extranet a virtual private network VPN a non TCP IP based network any LAN or WAN or the like.

The users of user systems may differ in their respective capacities and the capacity of a particular user system can be entirely determined by permissions permission levels for the current user of such user system. For example where a salesperson is using a particular user system to interact with the system that user system can have the capacities allotted to the salesperson. However while an administrator is using that user system to interact with the system that user system can have the capacities allotted to that administrator. Where a hierarchical role model is used users at one permission level can have access to applications data and database information accessible by a lower permission level user but may not have access to certain applications database information and data accessible by a user at a higher permission level. Thus different users generally will have different capabilities with regard to accessing and modifying application and database information depending on the users respective security or permission levels also referred to as authorizations .

According to some implementations each user system and some or all of its components are operator configurable using applications such as a browser including computer code executed using a central processing unit CPU such as an Intel Pentium processor or the like. Similarly the system and additional instances of an MTS where more than one is present and all of its components can be operator configurable using application s including computer code to run using the processor system which may be implemented to include a CPU which may include an Intel Pentium processor or the like or multiple CPUs.

The system includes tangible computer readable media having non transitory instructions stored thereon in that are executable by or used to program a server or other computing system or collection of such servers or computing systems to perform some of the implementation of processes described herein. For example computer program code can implement instructions for operating and configuring the system to intercommunicate and to process web pages applications and other data and media content as described herein. In some implementations the computer code can be downloadable and stored on a hard disk but the entire program code or portions thereof also can be stored in any other volatile or non volatile memory medium or device as is well known such as a ROM or RAM or provided on any media capable of storing program code such as any type of rotating media including floppy disks optical discs digital versatile disks DVD compact disks CD microdrives and magneto optical disks and magnetic or optical cards nanosystems including molecular memory ICs or any other type of computer readable medium or device suitable for storing instructions or data. Additionally the entire program code or portions thereof may be transmitted and downloaded from a software source over a transmission medium for example over the Internet or from another server as is well known or transmitted over any other existing network connection as is well known for example extranet VPN LAN etc. using any communication medium and protocols for example TCP IP HTTP HTTPS Ethernet etc. as are well known. It will also be appreciated that computer code for the disclosed implementations can be realized in any programming language that can be executed on a server or other computing system such as for example C C HTML any other markup language Java JavaScript ActiveX any other scripting language such as VBScript and many other programming languages as are well known may be used. Java is a trademark of Sun Microsystems Inc. .

In the network interface of is implemented as a set of HTTP application servers . Each application server also referred to herein as an app server is configured to communicate with tenant database and the tenant data therein as well as system database and the system data therein to serve requests received from the user systems . The tenant data can be divided into individual tenant storage spaces which can be physically or logically arranged or divided. Within each tenant storage space tenant data and application metadata can similarly be allocated for each user. For example a copy of a user s most recently used MRU items can be stored to user storage . Similarly a copy of MRU items for an entire organization that is a tenant can be stored to tenant storage space .

The process space includes system process space individual tenant process spaces and a tenant management process space . The application platform includes an application setup mechanism that supports application developers creation and management of applications. Such applications and others can be saved as metadata into tenant database by save routines for execution by subscribers as one or more tenant process spaces managed by tenant management process for example. Invocations to such applications can be coded using PL SOQL which provides a programming language style interface extension to API . A detailed description of some PL SOQL language implementations is discussed in commonly assigned U.S. Pat. No. 7 730 478 titled METHOD AND SYSTEM FOR ALLOWING ACCESS TO DEVELOPED APPLICATIONS VIA A MULTI TENANT ON DEMAND DATABASE SERVICE by Craig Weissman issued on Jun. 1 2010 and hereby incorporated by reference in its entirety and for all purposes. Invocations to applications can be detected by one or more system processes which manage retrieving application metadata for the subscriber making the invocation and executing the metadata as an application in a virtual machine.

The system of also includes a user interface UI and an application programming interface API to system resident processes to users or developers at user systems . In some other implementations the environment may not have the same elements as those listed above or may have other elements instead of or in addition to those listed above.

Each application server can be communicably coupled with tenant database and system database for example having access to tenant data and system data respectively via a different network connection. For example one application server can be coupled via the network for example the Internet another application server can be coupled via a direct network link and another application server not illustrated can be coupled by yet a different network connection. Transfer Control Protocol and Internet Protocol TCP IP are examples of typical protocols that can be used for communicating between application servers and the system . However it will be apparent to one skilled in the art that other transport protocols can be used to optimize the system depending on the network interconnections used.

In some implementations each application server is configured to handle requests for any user associated with any organization that is a tenant of the system . Because it can be desirable to be able to add and remove application servers from the server pool at any time and for various reasons in some implementations there is no server affinity for a user or organization to a specific application server . In some such implementations an interface system implementing a load balancing function for example an F Big IP load balancer is communicably coupled between the application servers and the user systems to distribute requests to the application servers . In one implementation the load balancer uses a least connections algorithm to route user requests to the application servers . Other examples of load balancing algorithms such as round robin and observed response time also can be used. For example in some instances three consecutive requests from the same user could hit three different application servers and three requests from different users could hit the same application server . In this manner by way of example system can be a multi tenant system in which system handles storage of and access to different objects data and applications across disparate users and organizations.

In one example storage use case one tenant can be a company that employs a sales force where each salesperson uses system to manage aspects of their sales. A user can maintain contact data leads data customer follow up data performance data goals and progress data etc. all applicable to that user s personal sales process for example in tenant database . In an example of a MTS arrangement because all of the data and the applications to access view modify report transmit calculate etc. can be maintained and accessed by a user system having little more than network access the user can manage his or her sales efforts and cycles from any of many different user systems. For example when a salesperson is visiting a customer and the customer has Internet access in their lobby the salesperson can obtain critical updates regarding that customer while waiting for the customer to arrive in the lobby.

While each user s data can be stored separately from other users data regardless of the employers of each user some data can be organization wide data shared or accessible by several users or all of the users for a given organization that is a tenant. Thus there can be some data structures managed by system that are allocated at the tenant level while other data structures can be managed at the user level. Because an MTS can support multiple tenants including possible competitors the MTS can have security protocols that keep data applications and application use separate. Also because many tenants may opt for access to an MTS rather than maintain their own system redundancy up time and backup are additional functions that can be implemented in the MTS. In addition to user specific data and tenant specific data the system also can maintain system level data usable by multiple tenants or other data. Such system level data can include industry reports news postings and the like that are sharable among tenants.

In some implementations the user systems which also can be client systems communicate with the application servers to request and update system level and tenant level data from the system . Such requests and updates can involve sending one or more queries to tenant database or system database . The system for example an application server in the system can automatically generate one or more SQL statements for example one or more SQL queries designed to access the desired information. System database can generate query plans to access the requested data from the database. The term query plan generally refers to one or more operations used to access information in a database system.

Each database can generally be viewed as a collection of objects such as a set of logical tables containing data fitted into predefined or customizable categories. A table is one representation of a data object and may be used herein to simplify the conceptual description of objects and custom objects according to some implementations. It should be understood that table and object may be used interchangeably herein. Each table generally contains one or more data categories logically arranged as columns or fields in a viewable schema. Each row or element of a table can contain an instance of data for each category defined by the fields. For example a CRM database can include a table that describes a customer with fields for basic contact information such as name address phone number fax number etc. Another table can describe a purchase order including fields for information such as customer product sale price date etc. In some MTS implementations standard entity tables can be provided for use by all tenants. For CRM database applications such standard entities can include tables for case account contact lead and opportunity data objects each containing pre defined fields. As used herein the term entity also may be used interchangeably with object and table. 

In some MTS implementations tenants are allowed to create and store custom objects or may be allowed to customize standard entities or objects for example by creating custom fields for standard objects including custom index fields. Commonly assigned U.S. Pat. No. 7 779 039 titled CUSTOM ENTITIES AND FIELDS IN A MULTI TENANT DATABASE SYSTEM by Weissman et al. issued on Aug. 17 2010 and hereby incorporated by reference in its entirety and for all purposes teaches systems and methods for creating custom objects as well as customizing standard objects in a multi tenant database system. In some implementations for example all custom entity data rows are stored in a single multi tenant physical table which may contain multiple logical tables per organization. It is transparent to customers that their multiple tables are in fact stored in one large table or that their data may be stored in the same table as the data of other customers.

As shown in accessing an on demand database service environment can involve communications transmitted among a variety of different hardware or software components. Further the on demand database service environment is a simplified representation of an actual on demand database service environment. For example while only one or two devices of each type are shown in some implementations of an on demand database service environment can include anywhere from one to several devices of each type. Also the on demand database service environment need not include each device shown in or can include additional devices not shown in .

Additionally it should be appreciated that one or more of the devices in the on demand database service environment can be implemented on the same physical device or on different hardware. Some devices can be implemented using hardware or a combination of hardware and software. Thus terms such as data processing apparatus machine server and device as used herein are not limited to a single hardware device rather references to these terms can include any suitable combination of hardware and software configured to provide the described functionality.

The cloud is intended to refer to a data network or multiple data networks often including the Internet. Client machines communicably connected with the cloud can communicate with other components of the on demand database service environment to access services provided by the on demand database service environment. For example client machines can access the on demand database service environment to retrieve store edit or process information. In some implementations the edge routers and route packets between the cloud and other components of the on demand database service environment . For example the edge routers and can employ the Border Gateway Protocol BGP . The BGP is the core routing protocol of the Internet. The edge routers and can maintain a table of IP networks or prefixes which designate network reachability among autonomous systems on the Internet.

In some implementations the firewall can protect the inner components of the on demand database service environment from Internet traffic. The firewall can block permit or deny access to the inner components of the on demand database service environment based upon a set of rules and other criteria. The firewall can act as one or more of a packet filter an application gateway a stateful filter a proxy server or any other type of firewall.

In some implementations the core switches and are high capacity switches that transfer packets within the on demand database service environment . The core switches and can be configured as network bridges that quickly route data between different components within the on demand database service environment. In some implementations the use of two or more core switches and can provide redundancy or reduced latency.

In some implementations the pods and perform the core data processing and service functions provided by the on demand database service environment. Each pod can include various types of hardware or software computing resources. An example of the pod architecture is discussed in greater detail with reference to . In some implementations communication between the pods and is conducted via the pod switches and . The pod switches and can facilitate communication between the pods and and client machines communicably connected with the cloud for example via core switches and . Also the pod switches and may facilitate communication between the pods and and the database storage . In some implementations the load balancer can distribute workload between the pods and . Balancing the on demand service requests between the pods can assist in improving the use of resources increasing throughput reducing response times or reducing overhead. The load balancer may include multilayer switches to analyze and forward traffic.

In some implementations access to the database storage is guarded by a database firewall . The database firewall can act as a computer application firewall operating at the database application layer of a protocol stack. The database firewall can protect the database storage from application attacks such as structure query language SQL injection database rootkits and unauthorized information disclosure. In some implementations the database firewall includes a host using one or more forms of reverse proxy services to proxy traffic before passing it to a gateway router. The database firewall can inspect the contents of database traffic and block certain content or database requests. The database firewall can work on the SQL application level atop the TCP IP stack managing applications connection to the database or SQL management interfaces as well as intercepting and enforcing packets traveling to or from a database network or application interface.

In some implementations communication with the database storage is conducted via the database switch . The multi tenant database storage can include more than one hardware or software components for handling database queries. Accordingly the database switch can direct database queries transmitted by other components of the on demand database service environment for example the pods and to the correct components within the database storage . In some implementations the database storage is an on demand database system shared by many different organizations as described above with reference to and .

In some implementations the app servers include a hardware or software framework dedicated to the execution of procedures for example programs routines scripts for supporting the construction of applications provided by the on demand database service environment via the pod . In some implementations the hardware or software framework of an app server is configured to execute operations of the services described herein including performance of the blocks of various methods or processes described herein. In some alternative implementations two or more app servers can be included and cooperate to perform such methods or one or more other servers described herein can be configured to perform the disclosed methods.

The content batch servers can handle requests internal to the pod. Some such requests can be long running or not tied to a particular customer. For example the content batch servers can handle requests related to log mining cleanup work and maintenance tasks. The content search servers can provide query and indexer functions. For example the functions provided by the content search servers can allow users to search through content stored in the on demand database service environment. The file force servers can manage requests for information stored in the File force storage . The File force storage can store information such as documents images and basic large objects BLOBs . By managing requests for information using the file force servers the image footprint on the database can be reduced. The query servers can be used to retrieve information from one or more file storage systems. For example the query system can receive requests for information from the app servers and transmit information queries to the NFS located outside the pod.

The pod can share a database instance configured as a multi tenant environment in which different organizations share access to the same database. Additionally services rendered by the pod may call upon various hardware or software resources. In some implementations the ACS servers control access to data hardware resources or software resources. In some implementations the batch servers process batch jobs which are used to run tasks at specified times. For example the batch servers can transmit instructions to other servers such as the app servers to trigger the batch jobs.

In some implementations the QFS is an open source file storage system available from Sun Microsystems of Santa Clara Calif. The QFS can serve as a rapid access file storage system for storing and accessing information available within the pod . The QFS can support some volume management capabilities allowing many disks to be grouped together into a file storage system. File storage system metadata can be kept on a separate set of disks which can be useful for streaming applications where long disk seeks cannot be tolerated. Thus the QFS system can communicate with one or more content search servers or indexers to identify retrieve move or update data stored in the network file storage systems or other storage systems.

In some implementations one or more query servers communicate with the NFS to retrieve or update information stored outside of the pod . The NFS can allow servers located in the pod to access information to access files over a network in a manner similar to how local storage is accessed. In some implementations queries from the query servers are transmitted to the NFS via the load balancer which can distribute resource requests over various resources available in the on demand database service environment. The NFS also can communicate with the QFS to update the information stored on the NFS or to provide information to the QFS for use by servers located within the pod .

In some implementations the pod includes one or more database instances . The database instance can transmit information to the QFS . When information is transmitted to the QFS it can be available for use by servers within the pod without using an additional database call. In some implementations database information is transmitted to the indexer . Indexer can provide an index of information available in the database or QFS . The index information can be provided to file force servers or the QFS .

The exemplary computer system includes a processing device processor a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM a static memory e.g. flash memory static random access memory SRAM and a data storage device which communicate with each other via a bus .

Processing device represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processing device may be a complex instruction set computing CISC microprocessor reduced instruction set computing RISC microprocessor very long instruction word VLIW microprocessor or a processor implementing other instruction sets or processors implementing a combination of instruction sets. The processing device may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a digital signal processor DSP network processor or the like.

The computer system may further include a network interface device . The computer system also may include a video display unit e.g. a liquid crystal display LCD or a cathode ray tube CRT an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. a speaker .

The data storage device may include a computer readable medium on which is stored one or more sets of instructions e.g. instructions of in memory buffer service embodying any one or more of the methodologies or functions described herein. The instructions may also reside completely or at least partially within the main memory and or within processing logic of the processing device during execution thereof by the computer system the main memory and the processing device also constituting computer readable media. The instructions may further be transmitted or received over a network via the network interface device .

While the computer readable storage medium is shown in an exemplary embodiment to be a single medium the term computer readable storage medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more sets of instructions. The term computer readable storage medium shall also be taken to include any medium that is capable of storing encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention. The term computer readable storage medium shall accordingly be taken to include but not be limited to solid state memories optical media and magnetic media.

The preceding description sets forth numerous specific details such as examples of specific systems components methods and so forth in order to provide a good understanding of several embodiments of the present invention. It will be apparent to one skilled in the art however that at least some embodiments of the present invention may be practiced without these specific details. In other instances well known components or methods are not described in detail or are presented in simple block diagram format in order to avoid unnecessarily obscuring the present invention. Thus the specific details set forth are merely exemplary. Particular implementations may vary from these exemplary details and still be contemplated to be within the scope of the present invention.

In the above description numerous details are set forth. It will be apparent however to one of ordinary skill in the art having the benefit of this disclosure that embodiments of the invention may be practiced without these specific details. In some instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the description.

Some portions of the detailed description are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion it is appreciated that throughout the description discussions utilizing terms such as determining identifying adding selecting or the like refer to the actions and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical e.g. electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

Embodiments of the invention also relate to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

It is to be understood that the above description is intended to be illustrative and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the invention should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

