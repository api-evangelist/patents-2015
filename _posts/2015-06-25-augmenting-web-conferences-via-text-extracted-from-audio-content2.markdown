---

title: Augmenting web conferences via text extracted from audio content
abstract: Systems and methods for augmenting web conference sessions with multimedia content based on text extracted from audio content transmitted during the web conference. In one embodiment, a conference application or other application can receive audio content from at least one client participating in a web conference. The web conference can connect multiple clients for live sharing of audio and video. The conference application can also extract at least one text item from the audio content. The conference application can also generate augmented electronic content by combining electronic content received via the web conference with additional electronic content based on the at least one text item. The conference application can also provide the augmented electronic content via the web conference.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09621851&OS=09621851&RS=09621851
owner: Adobe Systems Incorporated
number: 09621851
owner_city: San Jose
owner_country: US
publication_date: 20150625
---
This application is a continuation application of U.S. patent application Ser. No. 13 742 449 filed on Jan. 16 2013 now allowed the contents of which are incorporated herein in their entirety.

This disclosure relates generally to computer implemented methods and systems and more particularly relates to augmenting web conference sessions with multimedia content.

Online services such as web conference applications can allow clients at remote locations to share electronic content such as multimedia content. Web conferences can be used to conduct meetings and training events and or present lectures or short presentations from any computer accessing a web conference. Web conference applications allow for online collaboration via webinars interactive conferences online workshops etc. Web conferences may also involve the exchange of data between various participants. Participants may communicate via text message video chat audio chat etc.

One embodiment involves receiving audio content from at least one client participating in a web conference. The web conference connects multiple clients for live sharing of audio and video. The embodiment further involves extracting at least one text item from the audio content. The embodiment further involves generating augmented electronic content by combining electronic content received via the web conference with additional electronic content based on the at least one text item. The embodiment further involves providing the augmented electronic content via the web conference.

These illustrative embodiments are mentioned not to limit or define the disclosure but to provide examples to aid understanding thereof. Additional embodiments are discussed in the Detailed Description and further description is provided there.

Computer implemented systems and methods are disclosed for augmenting a web conference with multimedia content based on text or other content extracted from audio content transmitted during the web conference. For example a web conference application such as Adobe Connect or another suitable application can be used to host a web conference. A web conference can be an online session in which multiple clients at remote locations can share multimedia content and other electronic content in real time. The web conference can communicatively connect multiple clients for live sharing of audio and video. Audio data can be received during the web conference. An example of such audio data is digital audio captured at different client devices when participants in the web conference speak to one another. A filter or other software module can be executed by the web conference application to filter the audio in real time. One or more keywords can be extracted from the filtered audio data. The keywords can be used to retrieve advertisements or other multimedia content. Video and or images transmitted during the web conference can be combined with the advertisements or other multimedia content to generate augmented content. A non limiting example of augmented video content can include video transmitted by a participant in the web conference that is combined with a banner advertisement selected by the conference application based on audio data transmitted by the participant. The web conference application provides the augmented video to one or more participants in the web conference.

In accordance with one embodiment a conference application or other application augments a web conference based on text or other content extracted from audio data during the web conference. The conference application can receive audio content from at least one client participating in a web conference such as but not limited to digital audio data representing words spoken by one of the participants of the web conference. The conference application can extract at least one text item from the audio content. For example the conference application can apply a software filter to the audio content and execute a speech recognition algorithm to identify one or more words in the audio content. The conference application can generate augmented electronic content by combining electronic content received via the web conference with additional electronic content based on the text item extracted from the audio content. For example the words or another sound pattern identified by the software filter may be compared to stored multimedia content such as but not limited to advertising content for one or more advertising campaigns stored in a database accessible by the conference application. The conference application may determine that one or more words extracted from the audio content match or otherwise correspond to keywords included in metadata for advertising content. The conference application may combine video content received from a participant in the conference with the advertising content corresponding to keywords extracted from the audio content. The conference application can provide the augmented electronic content via the web conference. In one non limiting example a conference application can provide augmented electronic content to a recipient computing device associated with a specific client or group of clients such as clients associated with a targeted demographic for an advertisement or a client from which the audio data originated. In another non limiting example a conference application can provide augmented electronic content to multiple participants in the web conference.

As used herein the term conference application is used to refer to a service or other application that can host a session for sharing electronic content in real time via a data network among multiple clients at remote locations. Non limiting examples of a web conference include webinars online workshops online meetings and the like. In some embodiments a conference application allows multicast communications from one sender client to many receiver clients. In other embodiments a conference application allows real time point to point communications. A conference application can include one or more additional features such as but not limited to text based chat features voice and video chat features sharing of desktops etc.

As used herein the term electronic content is used to refer to any type of media that can be rendered for display or use at a computing system or other electronic device. Electronic content can include text or multimedia files such as images video audio or any combination thereof.

As used herein the term client is used to refer to a logical entity used in accessing a server and can refer to an account device or software application associated with one or more particular persons. As examples a client may be an entity such as an account used by an application to access an online service or other application. Similarly as another example a client may be a device executing an application to access the online service or other application. An account for a client can also include one or more authentication credentials such as a password personal identification number a security question and an associated answer etc. In some embodiments a single client corresponding to a single client account can be associated with a single computing device. In other embodiments multiple clients corresponding to multiple respective accounts can be associated with a single computing device. In other embodiments a single client corresponding to a single client account can be associated with multiple computing devices.

As used herein the term metadata is used to refer to information associated with and generally but not necessarily stored with an electronic content item that describes a feature of the electronic content item. Metadata may describe a location or identification of electronic content. Non limiting examples of metadata for an electronic content item can include a title author keywords and the like. Metadata may also describe a relationship between a first electronic content item and a second electronic content item such as how the first and second electronic content items can be combined and sequenced for a multimedia presentation. Metadata can also describe when and how an electronic content item was created a file type and other technical information for the electronic content item and or access rights for the electronic content item. In some embodiments metadata includes data included in the electronic content item that is not displayed by a client application using the electronic content item.

In some embodiments the conference application can determine that keywords extracted from audio content match or otherwise correspond to multiple advertising campaigns. An advertising campaign can include one or more advertising content items that share common ideas themes and messages etc. The conference application can perform one or more operations to select a given advertising campaign or select an order in which the multiple advertising campaigns will be displayed during the web conference. For example the conference application can identify a weight for each advertising campaign. The weight of each advertising campaign can correspond to an amount of revenue provided by the advertisement provider. The conference application can select advertising campaigns with greater weights to augment the web conference or select the order in which the multiple advertising campaigns will be displayed during the web conference based on the relative weights of the various advertising campaigns.

The conference application can use the text content extracted from real time audio content to augment a web conference in any suitable manner. In some embodiments the conference application can identify or otherwise select a voice command based on the text extracted from the real time audio content. The conference application can augment the web conference by retrieving electronic content for sharing via the web conference and or by modifying electronic content shared via the web conference. For example the conference application can access a given file in response to a voice command or navigate within a multimedia presentation in response to a voice command.

In additional or alternative embodiments the conference application can apply one or more analytics to the text content extracted from real time audio content to provide feedback to the participant that provided the audio content. For example a participant in a web conference may be a presenter in an online meeting. The conference application can generate a transcription of a spoken presentation in real time as the presenter speaks. The conference application can perform analytics on the transcription to generate additional data describing one or more qualitative criteria of the presentation such as the frequency of words indicating uncertainty e.g. uh or um the speed at which the presenter is speaking the use of jargon by the presenter etc. The conference application can provide the additional data describing the quality of the presentation to the presenter or other clients in real time during the presentation. Such real time feedback can allow a presenter to make adjustments in order to improve the quality of the presentation.

In additional or alternative embodiments the conference application can analyze the text content extracted from real time audio content to determine the accuracy of the information included in the text content. For example the conference application can generate a transcript of the audio content in real time. The conference application can compare information in the transcription to reference data accessible by the conference application. The conference application can determine the accuracy of the information included in the transcription based on the reference data. The conference application can generate data describing the accuracy for the information in the transcription. The conference application can provide data describing the accuracy of the information to one or more recipients in the web conference.

Referring now to the drawings is a block diagram depicting exemplary computing systems for implementing certain embodiments. The exemplary computing systems include a host system and computing systems in communication via a network .

The host system includes a processor . The processor may include a microprocessor an application specific integrated circuit ASIC a state machine or other suitable processing device. The processor can include any number of computer processing devices including one. The processor can be communicatively coupled to a computer readable medium such as a memory . The processor can execute computer executable program instructions and or accesses information stored in the memory . The memory can store instructions that when executed by the processor cause the processor to perform operations described herein.

A computer readable medium may include but is not limited to an electronic optical magnetic or other storage device capable of providing a processor with computer readable instructions. Other examples comprise but are not limited to a floppy disk CD ROM DVD magnetic disk memory chip ROM RAM an ASIC a configured processor optical storage magnetic tape or other magnetic storage or any other medium from which a computer processor can read instructions. The instructions may comprise processor specific instructions generated by a compiler and or an interpreter from code written in any suitable computer programming language including for example C C C Visual Basic Java Python Perl JavaScript and ActionScript.

The host system may also include a number of external or internal devices such as input or output devices. For example the host system is shown with an input output I O interface . A bus can also be included in the host system . The bus can communicatively couple one or more components of the host system .

Each of the computing systems includes respective processors . Each of the processors may include a microprocessor an ASIC a state machine or other processor. Each of the processors can include any of a number of computer processing devices including one. Such a processor can include or may be in communication with a computer readable medium. As depicted in each of the processors is communicatively coupled to respective memories . Each of the processors respectively executes computer executable program instructions and or accesses information stored in the memories . The memories store instructions that when executed by the processor cause the processor to perform one or more operations described herein.

The computing systems may also comprise a number of external or internal devices such as a mouse a CD ROM DVD a keyboard a display audio speakers one or more microphones or any other input or output devices. For example each of the computing systems is respectively shown with I O interfaces display devices audio input devices and video input devices . A non limiting example of a display device is a computer monitor or computer screen. A non limiting example of an audio input device is a microphone. A non limiting example of a video input device is a camera. Although depicts the display devices audio input devices and video input devices as separate devices coupled to the computing systems some or all of the display devices audio input devices and video input devices can be respectively integrated into the computing systems 

Buses can be respectively included in the computing systems . Each of the buses can communicatively couple one or more components of the computing systems 

The client applications can access the conference application to establish a web conference or other communication session. A communication session for communicating via the conference application can be established by the client applications via the network between computing systems and the host system . Each of the client applications can include one or more software modules such as the audio modules and the video modules . The audio modules can respectively configure the processors to communicate audio data to the conference application and to process audio data received via the conference application for playback at the computing systems . Audio data can be generated based on sounds captured by the audio input devices . Audio data can also be generated by applications executed at the computing devices . The video modules can respectively configure the processors to communicate video data to the conference application and to process video data received via the conference application for playback at the computing systems via the display devices . Video data can be generated based on images captured by the video input devices . Video data can also be generated by applications executed at the computing devices such as the sharing of desktops via the conference application .

In some embodiments the client applications can be stand alone applications. In other embodiments the client applications can be embedded in another application such as an internet browser application. A non limiting example of a client application is Adobe Connect client software.

The host system can include any suitable computing system for hosting the conference application . In one embodiment the host system may be a single computing system such as a server system. In another embodiment the host system may be a virtual server implemented using a number of computing systems connected in a grid or cloud computing topology.

The computing systems can include any suitable computing device or system for communicating via a network and executing the client applications . Non limiting examples of a suitable computing device or system include a desktop computer a tablet computer a smart phone or any other computing device or system suitable for using electronic content.

The host system can provide access to electronic content . The electronic content may be resident in any suitable computer readable medium and execute on any suitable processor. In one embodiment the electronic content can reside in the memory at the host system . In another embodiment the electronic content can be accessed by the host system from a remote resource such as another computing system via the network and provided to the computing systems 

The conference application can include one or more modules for modifying providing or otherwise using the electronic content in a web conference between the client applications . The conference application can include an extraction module and an augmentation module . Although the extraction module and the augmentation module are depicted in and described herein as separate logical modules of a conference application for ease of reference other implementations are possible. In some embodiments the conference application extraction module and or the augmentation module can be separate applications that can be separately executed by the processor . In other embodiments the conference application extraction module and or the augmentation module can be a combined logical module executed by the processor .

The extraction module can include software such as but not limited to an audio filter for extracting keywords or other textual content from audio content provided by the audio modules and or video content provided by the video modules . The augmentation module can include software for selecting at least some of the electronic content based on the content extracted by the extraction module and combining the selected electronic content with other content communicated between the client applications via a web session.

Example processes for extracting content and selecting content are described in detail below with respect to .

The audio module can generate audio data from sounds captured at the computing system via the audio input device . For example the audio data generated by the audio module can include digital audio data representing speech spoken by a participant in a web conference and captured by the audio input device

The audio module can provide the audio data both to the audio module via the conference application and to the extraction module . The audio module can process the audio data for playback at the computing system . The extraction module can execute one or more filtering and or speech recognition operations to extract the extracted content from the audio data provided by the audio module . A non limiting example of extracted content is textual content that includes at least a partial transcription of words included in the spoken audio data. A non limiting example of an extraction module is the Java Speech Application Programming Interface JSAPI .

Non limiting examples of speech recognition operations can include grammar design signal processing phoneme recognition word recognition and or result generation. Grammar design can include defining or otherwise accessing words that may be spoken and one or more patterns in which the words may be spoken. Signal processing can include analyzing the spectrum i.e. the frequency characteristics of the audio data provided by the audio module . Phoneme recognition can include comparing spectrum patterns to patterns of phonemes of the language in which the audio is spoken. Word recognition can include comparing a sequence of likely phonemes against the words and patterns of words specified by the active grammars for the language in which the audio is spoken. Result generation can include providing the conference application with information about the words that has been detected in the audio data provided by the extraction module .

The extraction module provides the extracted content to the augmentation module . The augmentation module can access advertising content or other content included in the electronic content . The advertising content can include one or more predefined advertising campaigns. The advertising content can include metadata identifying one or more keywords associated with different campaigns. For example advertising content for automobiles can include keywords such as truck engine car etc. Advertising content for education software can include keywords such as school learning classroom etc.

The augmentation module determines whether any of the extracted content matches or otherwise corresponds to the advertising content as depicted by the decision block . In one non limiting example the extracted content may include one or more keywords matching or otherwise corresponding to either in whole or part keywords included in metadata for the advertising content . In another non limiting example the extracted content may include one or more words or phrases matching or otherwise corresponding to either in whole or part a brand or product for the advertising content .

If at least some of the extracted content matches or otherwise corresponds to the advertising content the augmentation module can augment video data provided by the video module to generate augmented video content to be provided to the video module . For example as depicted in the augmentation module can retrieve the selected content that matches or otherwise corresponds to the extracted content . The selected content can be for example an advertising campaign having keywords matching or otherwise corresponding to the extracted content . A combiner module of the augmentation module can combine the selected content with the video data provided by the video module to generate the augmented video content . The conference application provides the augmented video content to the video module for playback at the computing system . For example augmented video content can include selected content displayed as a banner advertisement along with video data provided by the video module . In additional or alternative embodiments the augmented video content can also be provided to the video module for playback at the computing system

In additional or alternative embodiments the augmentation module can identify one or more clients to receive the augmented video based on targeting criteria associated with the clients. Non limiting examples of targeting criteria include demographics e.g. age gender etc. income level geography and the like. The augmentation module can access client data associated with a client account for each client participating in the web conference. The augmentation module can compare the client data to targeting criteria for advertising content . The augmentation module can identify clients having client data with values within the targeting criteria as recipients for the augmented video content . The conference application can provide the augmented video content to the identified clients and provide non augmented video content to other clients.

If none of the extracted content matches or otherwise corresponds to the advertising content the augmentation module does not augment the video data provided by the video module . The video data provided by the video module is provided to the video module via the conference application without any of the advertising content or other electronic content being added.

In some embodiments the augmentation module can determine that keywords extracted from the audio content match or otherwise correspond to multiple advertising campaigns. The augmentation module can perform one or more operations to select a given advertising campaign or select an order in which the multiple advertising campaigns will be displayed during the web conference. For example the augmentation module can identify a weight for each advertising campaign. The weight of each advertising campaign can correspond to an amount of revenue provided by the advertisement provider. The augmentation module can select advertising campaigns with greater weights to augment the web conference or select the order in which the multiple advertising campaigns will be displayed during the web conference based on the relative weights of the various advertising campaigns.

In additional or alternative embodiments audio data received from the audio module can trigger one or more voice commands during a web conference. is a modeling diagram illustrating an example flow of communications for augmenting a web conference via voice commands based on content extracted from audio data.

As described above with respect to the audio module can generate audio data from sounds captured at the computing system via the audio input device and provide the audio data to the extraction module . The extraction module can execute one or more filtering and or speech recognition operations to extract the content from the audio data.

The extraction module provides the extracted content to the augmentation module . As depicted in the augmentation module can include or otherwise communicate with a voice command module . The voice command module can compare the extracted content with one or more pre defined voice commands. Non limiting examples of voice commands include commands accessing the electronic content modifying the electronic content such as by navigating within a presentation shared via the conference application and the like. For example a speaker may instruct the conference application to retrieve a certain file from the electronic content by speaking the phrase retrieve file X or open file X. The voice command module can identify the phrases retrieve file or open file as voice commands for providing the specified file. In another example a speaker may instruct the conference application to advance to a slide in a presentation by speaking the phrase next slide or previous slide. The voice command module can identify the phrases next slide or previous slide as voice commands for navigating within a presentation shared via the conference application .

The augmentation module determines whether any of the extracted content matches or otherwise corresponds to a voice command as depicted by the decision block .

If at least some of the extracted content matches or otherwise corresponds to a voice command the augmentation module can augment video data provided by the video module to generate augmented video content to be provided to the video module . For example as depicted in the augmentation module can retrieve the selected content based on the command matching or otherwise corresponding to the extracted content . The selected content can be for example a file or other data to be shared during the conference. The combiner module of the augmentation module can combine the selected content with video data provided by the video module to generate the augmented video . The conference application provides the augmented video to the video module for playback at the computing system . In additional or alternative embodiments the augmented video can also be provided to the video module for playback at the computing system

If none of the extracted content matches or otherwise corresponds to a voice command the augmentation module does not augment the video data provided by the video module

In additional or alternative embodiments the conference application can augment a web conference by providing feedback to one or more speakers participating in the web conference. is a modeling diagram illustrating an example flow of communications for augmenting a web conference via analytics based on content extracted from audio data.

For example the conference application may be used to host an online seminar. The conference application can analyze the content of an answer provided by a participant in response to a question to determine the accuracy of the answer or the speaking style of a participant. The conference application can provide data describing the accuracy of the information or qualitative feedback on a speaker s presentation style.

As described above with respect to the audio module can generate audio data from sounds captured at the computing system via the audio input device and provide the audio data to the extraction module . The extraction module can execute one or more filtering and or speech recognition operations to extract the extracted content from the audio data.

The extraction module provides the extracted content to the augmentation module . As depicted in the augmentation module can include or communicate with an analysis module . The analysis module can analyze the extracted content based on any number of criteria such as criteria included in the electronic content .

In some embodiments the analysis module can perform analytics on text content in the extracted content . Such analytics can include description s of statistics patterns or other characteristics of textual content. The electronic content can include data for evaluating the extracted content . The analysis module can generate feedback data based on criteria provided in the electronic content . For example the augmentation application can determine the frequency with which expressions of hesitancy or uncertainty e.g. the word uh are included in the extracted content the degree to which the vocabulary used by the speaker is appropriate to the audience e.g. the prevalence of technical jargon the speed at which speaker speaks etc. The augmentation module of the conference application can thereby allow one or more participants of a web conference to analyze the speaking style of a participant. For example the analysis module can recommend changes in wording for a speaking style as the feedback data based on text analytics performed on textual content in the extracted content .

In additional or alternative embodiments the analysis module can analyze the extracted content to determine the accuracy of information provided by a speaker such as a student in a seminar. For example electronic content can include data describing questions to be asked during a web seminar and data describing expected answers for the questions. The analysis module can analyze extracted content from a first set of audio data to determine that a facilitator of the seminar has asked one of the questions. The analysis module can compare one or more words in the extracted content to questions included in the electronic content to identify the question asked. The analysis module can analyze additional extracted content from a second set of audio data to determine that a participant in the seminar has answered the question. The analysis module can compare the additional extracted content to data included in the electronic content describing the expected answer for the question. The analysis module can generate feedback data based on how closely the information in the provided answer correlates with the answer included in the electronic content .

The augmentation module can augment video data provided by the video module with the feedback data to generate augmented video to be provided to the video module . For example as depicted in the augmentation module can combine feedback data with video provided by the video module to generate augmented video . The conference application provides the augmented video to the video module for playback at the computing system . In additional or alternative embodiments the augmented video can also be provided to the video module for playback at the computing system

In additional or alternative embodiments the conference application can augment a web conference in real time based on video transmitted via the web conference. For example is a modeling diagram illustrating an example flow of communications for augmenting a web conference based on content extracted from audio and or video data. As depicted in the audio module can generate audio data from sounds captured at the computing system via the audio input device and provide the audio data to the extraction module . The video module can generate video data from one or more images captured at the computing system via the video input device and or generated by an application executed at the computing system . The video module can provide the video data to the extraction module . The extraction module can execute one or more filtering and or speech recognition operations to extract textual content as the extracted content from the audio data provided by the audio module . The extraction module can additionally or alternatively perform one or more image capture operations to extract image content as extracted content from the video data provided by the video module . The extraction module provides the extracted content to the augmentation module . The augmentation module can determine whether any of the electronic content matches or otherwise corresponds to the extracted content as depicted by the decision block . If any of the electronic content matches or otherwise corresponds to the extracted content the augmentation module can select the matching or corresponding content. The augmentation module can combine the selected content with video content provided by the video module to generate augmented video . The conference application can provide the augmented video to the video module and or client application in communication with the conference application i.e. other participants of the web conference .

Although depict augmented video being provided from a video module to a single video module via the conference application other implementations are possible. Any number of video modules included in any number of client applications executed by any number of computing systems can receive video via a conference application . In additional or alternative embodiments augmented video can be provided to the computing system that originates the audio data or video from which content is extracted for augmentation purposes.

The method involves receiving audio content from at least one client participating in a web conference as shown in block . The web conference can connect multiple clients for live sharing of audio and video. The processor of the host system can execute the conference application to host the web conference and receive the audio content as described above with respect to .

The method further involves extracting at least one text item from the audio content as shown in block . The processor of the host system can execute the extraction module of the conference application to extract the text item s from the audio content as described above with respect to .

The method further involves generating augmented electronic content by combining electronic content received via the web conference with additional electronic content based on the at least one text item as shown in block . The processor of the host system can execute the augmentation module of the conference application to generate the augmented electronic content as described above with respect to .

The method further involves providing the augmented electronic content via the web conference as shown in block . The processor of the host system can execute the conference application to provide the augmented electronic content via the web conference as described above with respect to .

Numerous specific details are set forth herein to provide a thorough understanding of the claimed subject matter. However those skilled in the art will understand that the claimed subject matter may be practiced without these specific details. In other instances methods apparatuses or systems that would be known by one of ordinary skill have not been described in detail so as not to obscure claimed subject matter.

Unless specifically stated otherwise it is appreciated that throughout this specification discussions utilizing terms such as processing computing calculating determining and identifying or the like refer to actions or processes of a computing device such as one or more computers or a similar electronic computing device or devices that manipulate or transform data represented as physical electronic or magnetic quantities within memories registers or other information storage devices transmission devices or display devices of the computing platform.

The system or systems discussed herein are not limited to any particular hardware architecture or configuration. A computing device can include any suitable arrangement of components that provides a result conditioned on one or more inputs. Suitable computing devices include multipurpose microprocessor based computer systems accessing stored software that programs or configures the computing system from a general purpose computing apparatus to a specialized computing apparatus implementing one or more embodiments of the present subject matter. Any suitable programming scripting or other type of language or combinations of languages may be used to implement the teachings contained herein in software to be used in programming or configuring a computing device.

Embodiments of the methods disclosed herein may be performed in the operation of such computing devices. The order of the blocks presented in the examples above can be varied for example blocks can be re ordered combined and or broken into sub blocks. Certain blocks or processes can be performed in parallel.

The use of adapted to or configured to herein is meant as open and inclusive language that does not foreclose devices adapted to or configured to perform additional tasks or steps. Additionally the use of based on is meant to be open and inclusive in that a process step calculation or other action based on one or more recited conditions or values may in practice be based on additional conditions or values beyond those recited. Headings lists and numbering included herein are for ease of explanation only and are not meant to be limiting.

While the present subject matter has been described in detail with respect to specific embodiments thereof it will be appreciated that those skilled in the art upon attaining an understanding of the foregoing may readily produce alterations to variations of and equivalents to such embodiments. Accordingly it should be understood that the present disclosure has been presented for purposes of example rather than limitation and does not preclude inclusion of such modifications variations and or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.

