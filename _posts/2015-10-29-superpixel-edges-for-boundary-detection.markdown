---

title: Superpixel edges for boundary detection
abstract: Various embodiments presented herein relate to identifying one or more edges in a synthetic aperture radar (SAR) image comprising a plurality of superpixels. Superpixels sharing an edge (or boundary) can be identified and one or more properties of the shared superpixels can be compared to determine whether the superpixels form the same or two different features. Where the superpixels form the same feature the edge is identified as an internal edge. Where the superpixels form two different features, the edge is identified as an external edge. Based upon classification of the superpixels, the external edge can be further determined to form part of a roof, wall, etc. The superpixels can be formed from a speckle-reduced SAR image product formed from a registered stack of SAR images, which is further segmented into a plurality of superpixels. The edge identification process is applied to the SAR image comprising the superpixels and edges.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09389311&OS=09389311&RS=09389311
owner: Sandia Corporation
number: 09389311
owner_city: Albuquerque
owner_country: US
publication_date: 20151029
---
This application is a continuation in part of U.S. patent application Ser. No. 14 626 582 filed on Feb. 19 2015 and entitled SUPERPIXELS FOR IMPROVED STRUCTURE AND TERRAIN CLASSIFICATION USING MULTIPLE SYNTHETIC APERTURE RADAR IMAGE PRODUCTS which claims priority to U.S. Provisional Patent Application No. 61 942 532 filed on Feb. 20 2014 and entitled SUPERPIXELS FOR IMPROVED STRUCTURE AND TERRAIN CLASSIFICATION USING MULTIPLE SYNTHETIC APERTURE RADAR IMAGE PRODUCTS the entireties of which are incorporated herein by reference.

This invention was developed under contract DE AC04 94AL85000 between Sandia Corporation and the U.S. Department of Energy. The U.S. Government has certain rights in this invention.

Synthetic aperture radar SAR images provide a wealth of information about structures and activities in an imaged scene. During the production of high resolution single polarization SAR imagery much more data and or imagery is generated than available researchers and analysts can examine. Thus automating the recognition of objects and or features and their edges boundaries in SAR imagery is highly desired e.g. to augment manual visual analysis. Superpixel segmentation SPS algorithms can be utilized to divide an image into small regions of close proximity pixels having similar intensities. Applying these SPS algorithms to optical images can reduce image complexity enhance statistical characterization and improve segmentation and categorization of scene objects and features. SPS algorithms typically require high signal to noise ratio SNR images with low artifacts for accurate segmentation. SAR imagery however tends to include speckle a product of coherent combining and cancelling of multi path backscattered radar energy which can complicate the extraction of superpixel segments and even preclude SPS usage.

The following is a brief summary of subject matter that is described in greater detail herein. This summary is not intended to be limiting as to the scope of the claims.

Various embodiments presented herein relate to automating determination of superpixel boundaries edges and whether a superpixel boundary or portion thereof is an internal edge or an external edge. An internal edge identifies the boundary is shared between two superpixels which have similar radar reflecting properties that are consistent with originating from the same object or portion thereof . An external edge identifies the boundary is shared between two superpixels wherein the first superpixel and second superpixel have highly contrasting radar reflecting properties that are consistent with originating from the first superpixel originating from a whole or a portion of a first object and the second superpixel from a whole or a portion of a second object. In an embodiment the first object can be a man made structure e.g. a building while the second object can be a natural feature such as a region of grass that is adjacent to the first object.

In an embodiment each pixel in a superpixel can be tagged with an identifier ID for the superpixel. Thus pixels of a first superpixel are tagged with an ID of the first superpixel and pixels of a second superpixel are tagged with an ID of the second superpixel. The first superpixel can have at least one property assigned thereto wherein the at least one property can be based upon one or more values generated from one or more properties of pixels forming the first superpixel. The second superpixel can have at least one other property assigned thereto wherein the at least one other property can be based upon one or more values generated from one or more properties of pixels forming the second superpixel. The respective properties can be based upon one or more processes which are utilized to form the superpixels as further described.

In an embodiment edge pixels can be found by determining a first pixel has a different superpixel ID to a second adjacent pixel. Further once the edge pixels have been identified the first superpixel property of the first edge pixel and the second superpixel property of the second edge pixel can be compared to determine whether the first superpixel and the second superpixel are consistent with containing the same reflecting surface feature or a different reflecting surface feature. For example a first mean of the first superpixel can be compared with a second mean of the second superpixel using a ratio contrast measure. If the ratio contrast measure is less than a threshold the first superpixel and the second superpixel can be determined to be consistent with originating from the same object and the edge between them is determined to be an internal edge. If the ratio contrast measure is equal to or above the threshold the first superpixel can be determined to be consistent with originating from a first object and the second superpixel can be determined to be consistent with originating from a different second object and the edge between them is determined to be an external edge. For example the first object is a building and the edge of the first superpixel is determined to delineate a structural edge e.g. a wall a roof etc. of the building.

The various embodiments presented herein can be applied to a SAR image that has undergone speckle reduction. A SAR image can include speckle which is a deterministic artifact commonly found in SAR imagery. When a superpixel segmentation SPS algorithm is executed over the SAR image the speckle in the SAR image impacts segmentation of the SAR image. That is the speckle causes superpixels output by the SPS algorithm to be different from what the SPS algorithm would output if the SAR image were free of speckle. Accordingly speckle can negatively impact operation of the SPS algorithm.

Therefore the various embodiments presented herein relate to mitigating the deleterious effects of speckle during SPS to enable enhanced superpixel formation and according edge detection. Prior to executing an SPS algorithm over the SAR image e.g. in its original form a speckle reduction process can be undertaken over the SAR image resulting in a speckle reduced SAR image product. Exemplary speckle reduction processes include but are not limited to a sub aperture multilook SA ML process a mean coherent change detection MCCD process and a median radar cross section MRCS process. Other processes can also be executed such as an interferometric height IF H mapping process. One or more of these processes in addition to reducing speckle also reduces spatial resolution. Therefore the speckle reduced SAR image product can have a resolution that is lower than the resolution of the SAR image.

The SPS algorithm can then be executed over the speckle reduced image product resulting in oversegmentation of the speckle reduced image product into a plurality of segments wherein oversegmentation can result in one or more of the segments in the plurality of segments being smaller than an object which each respective segment forms a respective part. Each segment comprises at least one pixel and typically includes several pixels where pixels in a segment have been found by the SPS algorithm to be related to one another. It can be ascertained that since the speckle reduced image product has less speckle when compared to the original SAR image the oversegmentation performed by the SPS algorithm will be less influenced by speckle. The segmented reduced speckle image product can be referred to as a superpixel image product.

In an embodiment the superpixel image product can be formed from a speckle reduced product that is registered with the original SAR image accordingly the superpixel image product is likewise registered with the original SAR image. Registration of the superpixel image product with the original SAR image causes the segments of the superpixel image product to be applicable to the original SAR image. Effectively then the original SAR image and all other images registered with the superpixel image product can be oversegmented into segments that respectively correspond to the segments of the superpixel image product. The oversegmented original SAR image is referred to as the segmented image.

Segments in the segmented image can subsequently be assigned labels based upon values of pixels in respective segments. With more particularity a classifier can assign a label to a segment in the segmented image based upon values of pixels in the segment without regard to values of pixels in other segments . For example the classifier can be trained based upon labeled training data such as manually identified segments that correspond to an object or feature of interest. Thus for instance the classifier can be trained based upon segments of SAR images manually identified as including a particular type of surface e.g. a concrete building . The classifier when provided with a segment from the segmented image can output a value that is indicative of whether or not the segment includes a concrete building and the classifier can label the segment as including or not including the concrete building based upon the value. The value output by the classifier as noted above is based upon values of pixels in the segment.

As previously mentioned the one or more properties ascribed to the first superpixel and the second superpixel can be generated based upon the SA ML process the MCCD process the MRCS process the IF H mapping process a simple linear iterative clustering SLIC operation a QUICK SHIFT process and or any other process pertaining to the generation and or processing of superpixels in a SAR image.

The above summary presents a simplified summary in order to provide a basic understanding of some aspects of the systems and or methods discussed herein. This summary is not an extensive overview of the systems and or methods discussed herein. It is not intended to identify key critical elements or to delineate the scope of such systems and or methods. Its sole purpose is to present some concepts in a simplified form as a prelude to the more detailed description that is presented later.

Various technologies pertaining to identifying high and low contrast edges in a SAR image wherein the SAR image may include speckle are now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of one or more aspects. It may be evident however that such aspect s may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to facilitate describing one or more aspects.

Further the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from the context the phrase X employs A or B is intended to mean any of the natural inclusive permutations. That is the phrase X employs A or B is satisfied by any of the following instances X employs A X employs B or X employs both A and B. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from the context to be directed to a singular form. Additionally as used herein the term exemplary is intended to mean serving as an illustration or example of something and is not intended to indicate a preference.

As used herein the terms component device and system are intended to encompass computer readable data storage that is configured with computer executable instructions that cause certain functionality to be performed when executed by a processor. The computer executable instructions may include a routine a function or the like. It is also to be understood that a component or system may be localized on a single device or distributed across several devices. The terms component device and system are also intended to encompass hardware configured to cause certain functionality to be performed where such hardware can include but is not limited to including Field programmable Gate Arrays FPGAs Application specific Integrated Circuits ASICs Application specific Standard Products ASSPs System on a chip systems SOCs Complex Programmable Logic Devices CPLDs etc.

SAR imaging systems deliver complex phase history data which pass through Fourier transform processing to produce complex valued backscatter images. Because multi path backscattered energy can add and cancel coherently resulting SAR images can include speckle which can complicate application of standard image processing methods such as superpixel segmentation SPS to SAR images.

The aircraft has located thereon a radar system which includes an antenna . The antenna transmits radar signals and the antenna or another antenna receives radar echoes which have been generated by reflection of the radar signals from the scene . Transmission of the signals can be performed in conjunction with a controller not shown incorporated into the radar system wherein the controller can be a digital signal processor or other suitable circuit or processor.

For each pass of the aircraft over the scene data can be generated by the radar system e.g. during a first pass of the aircraft over the scene the radar system generates a first set of data during a second pass of the aircraft over the scene the radar system generates a second set of data during an npass of the aircraft over the scene the radar system generates a nset of data etc. where n is a positive integer. In an embodiment the sets of data and can be or include phase history data. Further the sets of data and can be in any suitable format such as Ground Based SAR Application Testbed File Format GFF .

The system comprises a classification device which can be any suitable computing device including but not limited to a desktop computing device a laptop computing device a mobile telephone a wearable computing device a server computing device etc. The classification device is in direct or indirect communication with the radar system such that data generated by the radar system or data based upon data generated by the radar system can be received at the classification device . For instance the classification device can be co located with the radar system on the aircraft. In another example the classification device can be located separately from the radar system . The classification device comprises a data store and the respective sets of data can optionally be stored in the data store for subsequent retrieval.

The system also includes a SAR image generator that is configured to generate complex SAR images and based upon at least one of the data e.g. where the data includes complex phase history data . The image generator can exploit different phenomena of the complex backscatter data to produce the SAR images and . While shown as being separate from the classification device and the radar system it is to be understood that the SAR image generator may be included in either of the classification device or the radar system . The respective SAR images can be stored in the data store for subsequent retrieval.

The classification device includes a processor and a memory . The memory includes components that are executable by the processor wherein functionalities of the process when executing the components are described below.

The memory includes a registration component that can be configured to register the SAR images . In an embodiment a SAR baseline image can be selected from any of the SAR images collected from the same scene . The registration component can be then be configured to register each of the remaining SAR images with the baseline SAR image thereby forming a mapping between the baseline SAR image and any of the SAR images and thereby producing registered SAR images and referred to collectively as a registered image stack . It is to be appreciated that while the registration component is shown as being separate from the radar system the registration component may be included in either of the classification device or the radar system . As shown the registered image stack can be stored in the data store for subsequent retrieval.

In a situation where any of the SAR images has a different resolution to any of the other SAR images the registration component can optionally be configured to resample any of the SAR images to enable the SAR images to have a common resolution. For example when the SAR image comprises x pixels and the SAR image comprises y pixels the registration component can resample the SAR image such that the SAR image comprises y pixels.

The memory can also include an artifact reduction component wherein the artifact reduction component is configured to generate an artifact reduced image product based upon at least one of the registered SAR images in the registered image stack . In a scenario where noise contamination may be an issue for processing of SAR images the artifact reduction component can also be configured to reduce noise in at least one of the registered SAR images . For purposes of explanation functionality of the components in the memory will be described with reference to the registered SAR image although it is to be understood that the functionality can be performed over other registered SAR images e.g. registered SAR images in the registered image stack . The artifact reduction component can be configured to generate the artifact reduced SAR image product based upon the registered SAR image such that an amount of artifact s in the artifact reduced SAR image product is less than the amount of artifact s in the registered SAR image . The artifact reduced SAR image product can be perceived as an image comprising a plurality of pixels wherein each pixel has a value or vector of values assigned thereto.

In a non limiting example the artifact reduction component can be configured to perform at least one speckle reduction operation over the registered SAR image such that the artifact reduced SAR image product is a speckle reduced image product. Accordingly an amount of speckle in the artifact reduced SAR image product can be less than an amount of speckle in the original registered SAR image . Exemplary operations that can be performed by the artifact reduction component include but are not limited to sub aperture multilook imaging SA ML mean over time of coherent change detection MCCD imaging and median over time of radar cross section MRCS imaging . The artifact reduction component can also be configured to perform other operations over the registered SAR image such as an operation that generates interferometric height IF H map data which can be indicative of local height variations in the scene and can augment available backscatter and coherent change information. In an embodiment the SA ML imaging can reduce spatial resolution to reduce speckle while MCCD imaging and MRCS imaging can average values over time rather than over space hence spatial resolution is preserved while speckle is reduced. In another embodiment MCCD imaging and MRCS imaging can have the same spatial resolution as an originally received image while SA ML imaging can have reduced spatial resolution from the originally received image . The exemplary speckle reduction operations are described in greater detail below.

It is to be appreciated that the artifact reduction component can generate the artifact reduced SAR image product using a single artifact reduction operation e.g. any of operations or a combination of artifact reduction operations e.g. a combination of operations . For example the artifact reduced SAR image product can be a plurality of image products that are registered to one another. For instance conceptually the artifact reduced SAR image product can have a plurality of pixels with each pixel in the artifact reduced SAR image product having a vector of values and each value in the vector corresponding to a respective artifact reduction operation. Thus a pixel in the artifact reduced SAR image product can have the vector of values A B C assigned thereto where A is based upon an output of a first artifact reduction operation relative to the registered SAR image B is based upon an output of a second artifact reduction operation relative to the registered SAR image and C is based upon an output of a third artifact reduction operation relative to the registered SAR image . Additionally each pixel in the artifact reduced product can have spatial values e.g. range and azimuth coordinates assigned thereto which represent location of the pixel in the artifact reduced SAR image product . It is to be appreciated that since the artifact reduced SAR image product was created from one or more registered images the artifact reduced image product is also registered to the baseline image as well as all other registered images in the stack .

The memory can further comprise a superpixel segmentation component that is configured to segment the artifact reduced SAR image product into a plurality of superpixels or segments based upon respective values of respective pixels of the artifact reduced SAR image product . For example the superpixel segmentation component can be configured to perform a pixel clustering operation on the artifact reduced SAR image product such that a plurality of superpixels pixel groupings are formed and hence the artifact reduced SAR image product is segmented into the plurality of superpixels . The superpixel segmentation component therefore divides oversegments the artifact reduced SAR image product into a plurality of superpixels thus producing a superpixel image product . The superpixel image product as noted above comprises a plurality of superpixels each comprising a respective boundary where each superpixel includes pixels of the artifact reduced SAR image product found to be correlated by the pixel clustering operation e.g. proximate pixels having a similar value performed by the superpixel segmentation component . Exemplary pixel clustering algorithms that can be utilized by the superpixel segmentation component when oversegmenting the artifact reduced product into a plurality of superpixels include but are not limited to a QUICK SHIFT algorithm and a simple linear iterative clustering SLIC algorithm. Because the SLIC operation performed by the superpixel segmentation component can be forced to select edges parsimoniously under such forced condition the SLIC operation is required to choose between higher contrast edges that correspond to scene structures and spurious and noisy edges that frequently have lower contrast. Hence in addition to detecting high contrast edges superpixels with their edges and edge statistics provide a number of useful advantages when applied to SAR imagery. For example parsimoniously selected superpixels can conform to the shape of structures in the scene . It is to be appreciated that since the superpixel image product was created from the artifact reduced SAR image product that it too is registered to all other registered images .

In an embodiment owing to the oversegmentation operation performed by the superpixel segmentation component e.g. SLIC QUICK SHIFT etc. each respective pixel in a superpixel has a similar value. For example a first group of pixels forming a first superpixel have a similar common parameter value e.g. a first statistical measure SM could be a first mean or median value of all pixels which form the first superpixel and the first superpixel is assigned the first statistical value for the first statistical measure. A second group of pixels in a second superpixel also have a similar common parameter value e.g. a second statistical measure SM could be a second mean or median value for all pixels which form the second superpixel and the second superpixel is assigned the second statistical value for the second statistical measure.

The superpixel segmentation component can be configured to assign the respective statistical values SM SM SMfor an nsuperpixel to the respective superpixels as further described below. It is to be appreciated that while only a first superpixel and a second superpixel are described herein with the respective statistical values assigned thereto any number of superpixels having respective statistical values can be included in the superpixel image product .

Furthermore superpixel segmentation component can be configured to apply a unique superpixel identifier ID to each superpixel in the superpixel image product . As further described below a shifting algorithm can find transitions from one superpixel ID to another wherein such transitions correspond to respective superpixel boundaries.

The memory further comprises a boundary detector component which can receive the segmented SAR image and based upon computing a contrast comparison between the respective statistical value s e.g. statistical values SM SM SM assigned to each superpixel the boundary detector component can identify whether a superpixel boundary or portion thereof represents a high contrast edge consistent with an external edge of an object represented by one or more superpixels or the superpixel boundary represents a low contrast edge consistent with an internal edge of an object represented by the one or more superpixels.

As further described below the boundary detector component can utilize the superpixel image product and a copy of the superpixel image product A to identify whether a pixel in the superpixel image product is included in the body of a superpixel e.g. the pixel is not of the edge of the superpixel or the pixel is located at the edge of the superpixel. The superpixel image product can include a first superpixel having a first superpixel ID and an adjacently located second superpixel having a second superpixel ID . Further the first superpixel can include a first pixel which is located at the edge of the first superpixel and the second superpixel can include a second pixel which is located at the edge of the second superpixel wherein the first pixel and the second pixel are adjacent to each other. Similarly the superpixel image product copy A can include a third superpixel a copy of the first superpixel and an adjacently located fourth superpixel a copy of the second superpixel . Further the third superpixel can include a third pixel a copy of the first pixel which is located at the edge of the third superpixel and the second superpixel can include a fourth pixel a copy of the second pixel which is located at the edge of the fourth superpixel wherein the third pixel and the fourth pixel are also adjacent to each other. The superpixel image product copy A can be overlaid co aligned on the superpixel image product such that the third pixel in the superpixel image product copy A is located directly over the first pixel in the superpixel image product and the fourth pixel is located over the second pixel. Subsequently the superpixel image product copy A can be shifted e.g. by the boundary detector component utilizing a shifting algorithm in relation to the underlying superpixel image product such that the fourth pixel is overlaid over the first pixel or the third pixel is overlaid over the second pixel . Owing to the first pixel having the first superpixel ID and the fourth pixel having the second superpixel ID the boundary detector component can determine that the first pixel and the fourth pixel are located in different superpixels and thus the first pixel and the fourth pixel are both edge pixels of their respective superpixels. The same determination can be made for the second pixel overlaid with the third pixel. A boundary detected image can be generated by the boundary detector component wherein the boundary detected image comprises superpixels and their respectively identified edge pixels. Further an index array can be generated from the shifting process to identify every superpixel edge location and to further store the superpixel statistics in the corresponding edges.

Turning to a superpixel image product comprising of a plurality of superpixels is illustrated in configuration . A first plurality of superpixels e.g. superpixels are shown wherein per the common shading the superpixels all have similar statistical measures e.g. a similar first mean radar reflectivity a first statistical measure SM. Further a second plurality of superpixels e.g. superpixels are shown wherein per the common shading the superpixels all have a similar statistical measure e.g. a similar second mean radar reflectivity a second statistical measure SM. Per the foregoing the identifiers and can act as the respective IDs utilized to identify superpixels associated with a particular superpixel boundary.

As previously described each superpixel and can be constrained by a respective superpixel boundary e.g. superpixel boundary . As shown in a first superpixel has a boundary while a second superpixel has a boundary . A boundary e.g. boundary or can comprise a plurality of pixels. As further shown in a portion of a superpixel boundary can separate a first superpixel from a second superpixel. For example a boundary portion separates superpixel and superpixel as indicated by the hashed line . In another example boundary portion separates superpixel and superpixel as indicated by the hashed line . Boundary portions and are internal edges between respective common superpixels e.g. boundary portion separates a pair of superpixels while boundary portion separates a pair of superpixels . A boundary portion can also separate superpixels of different groups e.g. boundary portion as indicated by the hashed line separates a first superpixel e.g. of a first group and a second superpixal e.g. of a second group . As shown the boundary portion forms a portion of an external edge between the group of superpixels and the surrounding group of superpixels .

As shown in zoomed portion a first portion of superpixels are depicted per the first common shading next to a second portion of superpixels per the second common shading wherein the first portion of superpixels e.g. and the second portion of superpixels e.g. form a part of the boundary portion . As further described herein superpixel boundaries can be found by comparing a pixel with its neighboring pixels a superpixel label image e.g. images and A can be shifted up down left and right with respect to itself with comparison of respective superpixel IDs. If it is determined that the pixels all have the same superpixel ID then the pixels are common to a superpixel. However if one of the pixels is determined to have a different superpixel ID to the superpixel ID of a neighboring superpixel the respective pixels can be identified as being edge pixels of the respective superpixels. After shifting all pixels and comparing IDs at each image shift it is possible to identify edge pixels for each superpixel. In an embodiment the superpixel label image only has to be shifted by one pixel width relative to itself in each of the up down left right directions for a dissimilarity between neighboring pixels to be determined.

Turning to zoomed portion a plurality of edge pixels are depicted from the respective superpixels which create the boundary portion . provides a schematic of respective edge pixels after edge pixel determination has been performed per the various embodiments presented herein. As illustrated a row line of pixels have been determined to be edge pixels of a first superpixel boundary or edge of the first superpixel e.g. wherein the first superpixel also includes the pixels . Further pixels are edge pixels of a second superpixel boundary of the second superpixel e.g. wherein the second superpixel also includes the pixels . Each section of the superpixel boundary that borders a different superpixel will receive a different ID that corresponds to its specific neighbor. Accordingly each pixel in the first superpixel boundary can be assigned an ID that matches the ID of the bordering superpixel each pixel in the second superpixel boundary can be assigned an ID that matches the ID of the bordering superpixel therein identifying the respective pixels in the first superpixel boundary and the second superpixel boundary. It is to be appreciated that while edge pixels and the pixels have different shadings in all of the pixels belong to the superpixel . And further while edge pixels and the pixels have different shadings in all of the pixels belong to the superpixel .

As mentioned the superpixel segmentation component can be configured to limit a number of superpixels generated and thereby force the available superpixel edges to favor high contrast intensity changes within a local region thus ensuring parsimonious placement of edges. As previously described the pixels of superpixel will have a first superpixel ID the pixels of superpixel will have a second superpixel ID the pixels of superpixel will have a third superpixel ID the pixels of superpixel will have a fourth superpixel ID. As further mentioned the superpixel label image e.g. images and A can be shifted up down left and right with respect to itself to enable extraction of locations where a first superpixel ID label s of a superpixel e.g. of an adjacent superpixel do not match with a second superpixel ID label s assigned to the superpixel in question. For those pixels e.g. at a first superpixel at which there is a label mismatch with an adjacent pixel e.g. at a second superpixel the pixels can be identified as corresponding to the edges of each superpixel that border another superpixel.

The edge pixels once identified can be further analyzed to determine whether they are external edge pixels or internal edge pixels. For example a first superpixel j e.g. superpixel has a different statistical value SM to a second superpixel k e.g. superpixel having a second statistical measure SM as determined by the computation of the contrast measure i.e. thresholding the contrast measure produces a ratio edge detector r per Eqn 1 

where contrast values close to 0 indicate that the superpixels have very similar statistics and contrast values close to 1 indicate that the superpixels have very different statistics. Utilization of Eqn. 1 is described further below in conjunction with Eqns. 2 5. Hence when determining the contrast of each edge the boundary classifier component can determine whether the pixels are of an external edge or an internal edge as further described below.

Applying ratio contrast boundary detection identifies high contrast binary edges which provide a convenient format for applying a Hough transform or a Radon transform to detect linear boundaries and other boundaries with specific mathematical shapes. Long and thin objects tend to create long thin superpixels for which it is possible to estimate a ratio of major axis length to minor axis length for detection. Thus superpixels and their edges provide a means of characterizing shapes of objects in an image and detecting objects with specific shape. Exploiting shape and orientation of these superpixels also enables detection of long thin superpixels which can find roads walls and other long thin structures.

As mentioned the boundary classifier component can identify whether an edge is an internal or external edge by comparing the contrast between respective values e.g. statistical values SM SM SM of superpixels that share a boundary. An internal edge can be formed by two superpixels which represent the same object. An external edge can be formed by a first superpixel that represents a first object and a second superpixel that represents a second object. For readability both man made features and natural features are referred to herein as objects wherein man made objects can include a building s a road s a track s a vehicle s etc. while a natural feature can include a grassy area e.g. a field other vegetation such as trees bushes a water feature e.g. a pond a lake a river etc. a desert region etc. Hence an internal edge may be determined between two superpixels which in combination represent an object or portion thereof forming a natural feature while an external edge may be determined between a first superpixel forming a part of a building and a second superpixel representing a grassed region.

Comparison of respective ratio contrast values can be based upon a threshold value T. For example respective edge pixels in boundary have been respectively assigned ID s wherein superpixels and have statistical values similar to each other and similar to SM. Hence computing the ratio contrast measure with similar statistical values yields a ratio contrast measure value close to 0. Accordingly both sets of edge pixels between first superpixel and second superpixel are assigned the corresponding ratio contrast measure. Owing to the statistical measures having the same value or similar value the contrast ratio does not exceed the threshold value T and the boundary is determined by the boundary classifier component to be an edge boundary that is consistent with being internal to an object which includes superpixels and . In another example respective edge pixels forming boundary has been respectively assigned ID s wherein superpixels and have statistical values similar to each other and similar to SM. Hence computing the ratio contrast measure with similar statistical values yields a ratio contrast measure value close to 0. Accordingly both sets of edge pixels between first superpixel and second superpixel are assigned the corresponding ratio contrast measure. Owing to the statistical measures being of similar value the ratio contrast threshold value T is not exceeded and the boundary is determined by the boundary classifier component to be an edge boundary that is consistent with being internal to an object which includes superpixels and .

In a further example boundary is formed from a first superpixel having a statistical value of SM. Boundary is further formed from a second superpixel having a statistical value of SM. Hence computing the ratio contrast measure with disparate statistical values yields a ratio contrast measure that is close to 1. Accordingly both sets of edge pixels between first superpixel and second superpixel are assigned the corresponding ratio contrast measure. Owing to the statistical measures SMand SMhaving different values the ratio contrast threshold value T is exceeded and the boundary is determined by the boundary classifier component to be an edge boundary that is consistent with being external to an object formed by either of superpixels or . While an approach of threshold comparison is presented to determine a contrast between a first superpixel and a second superpixel any other suitable method for making such a determination can be applied to the one or more embodiments presented herein.

Returning to per the foregoing a plurality of sub images can be generated to enable assignment of the various statistics relating to the respective edge pixels and further to enable determination of element by element ratios and final construction of the boundary detected image . For example respective superpixel statistics are stored in a first sub image and a second sub image . For every edge of every first superpixel within the first sub image the first statistic of the first superpixel is stored. For every edge of every first superpixel in the second image the second statistic of the second superpixel is stored. A third sub image is generated by computing the element by element ratio of the first sub image to the second sub image which corresponds to SM SM per Eqn. 1 above. A fourth sub image is generated by computing the element by element ratio of the second sub image to the first sub image which corresponds to SM SM per Eqn. 1. Accordingly the third sub image and the fourth sub image have valid values at the edge locations only any off edge locations contain invalid data. A fifth image e.g. another sub image not shown or an iteration of the boundary detected image is created by generating an element by element minimum between corresponding pixels of the third sub image and the fourth sub image which corresponds to

In an embodiment the boundary detected image can be utilized as an input into a segmentation component wherein the segmentation component can be utilized to segment divide a radar image into large regions that correspond to objects in the radar image wherein the large regions are typically larger than the superpixels which are generated by the superpixel segmentation component .

The memory further comprises a classifier component . Owing to each SAR image in the registered stack is segmented the classifier component can assign at least one label to the at least one superpixel based upon a vector of pixel values wherein a number of entries in the vector maps to a number of images in the stack . Pursuant to an example the classifier component can be configured to determine if a superpixel represents a particular type of vegetation based upon pixel values in the superpixel. When the classifier component determines that the superpixel represents the particular type of vegetation the classifier component can assign a label to the superpixel in the boundary detected image that indicates that the superpixel represents the particular type of vegetation. It can be ascertained that the classifier component can be configured to perform a classification based upon pixel values of a superpixel with respect to any suitable object feature or the like. For example the classifier component can be configured to determine whether a superpixel represents a body of water a particular type of road surface a ditch etc. Accordingly as a function of the classifier component operating in conjunction with the boundary detector component a classified image can be generated. In an embodiment superpixels included in the image which have a low coherence may be classified as a natural feature while superpixels having a high coherence may be classified as a man made object and further the respective internal e.g. edges and external edges e.g. edge of the man made structure or natural feature can be identified to facilitate automation of object recognition in a SAR image.

The classifier component can be trained to perform a classification based upon labeled training data. For example analyst s can manually identify superpixel segments of SAR images that represent an object feature or the like that is to be classified. Likewise negative training data can be considered where analyst s manually identify superpixels of SAR images that do not represent the object feature or the like that is to be classified. Features of a superpixel that can impact whether the superpixel represents an object include but are not limited to size of the superpixel shape of the superpixel average intensity values of pixels in the superpixel distribution of intensity values of pixels in the superpixel etc. These features can be inherently identified when training the classifier component and the classifier component can perform suitable computations with respect to pixel values in the superpixel when classifying the superpixel as representing an object or feature or not representing the object or feature.

When applied to image regions with little spatial variation such as roads and deserts SLIC can create superpixels that are fairly uniform and compact. When applied to image regions with coarse textures such as a tree canopy SLIC produces superpixels with higher spatial frequency variations. It is possible to exploit these superpixel shape characteristics by computing shape and texture statistics of superpixel edges to characterize coarse image textures. Computing the ratio of circumference to area for each superpixel can yield a compactness measure of the superpixels which is related to the texture of the underlying SAR image. Other possible measures of local texture include local variance of superpixel size local variance of superpixel circumference and local variance of edge contrasts. The classifier component can be configured to take into account such considerations when classifying one or more objects in a classified image .

It is to be appreciated that while the preceding has described oversegmenting an artifact reduced SAR image product to form a superpixel image product and subsequently determining internal external edges formed therein the superpixel image product can also be directly applied to any of the registered SAR images e.g. registered SAR images . For example the superpixel image product can be registered with the SAR images in the stack and the superpixel segmentation component can apply the boundaries of the superpixels of the superpixel image product to all registered SAR images and in the stack . In an example the superpixel segmentation component can apply the superpixels to the registered SAR image and thus to the original SAR image thereby creating a segmented registered SAR image . The segmented registered SAR image has a plurality of superpixels bounded by boundaries that respectively correspond to the segments and boundaries in the superpixel image product . Each segment in the segmented registered SAR image comprises a respective plurality of pixels which have values corresponding thereto. As noted above however as the superpixel image product is registered with SAR images in the stack the segments of the superpixel image product can be applied to others of the registered SAR images in the stack . Thus the registered SAR images in the stack can each be segmented in accordance with the boundaries of the superpixels.

As previously mentioned for each superpixel the member pixel locations of each superpixel can be indexed into a co registered image product such as MRCS or MCCD . Superpixel statistics can be computed from the respective intensities of the image products where such statistics can include mean median and or coefficient of variation. The superpixel segmentation component can generate one or more segmented SAR images utilizing the superpixel statistic s wherein each superpixel is filled with its corresponding estimated statistic. The superpixel segmentation component can utilize various algorithms to generate an oversegmented SAR image . In an embodiment per Eqns. 2 5 below the sample mean median m and coefficient of variation for a superpixel j can be respectively calculated for each superpixel. A set contains member pixels belonging to superpixel j where Nis the number of pixels in the set and each pixel i has intensity I. The set contains intensities of member pixels ordered by increasing intensity.

As previously mentioned edge pixels are found for each superpixel. The superpixel label image e.g. superpixel label image is shifted up down left and right with respect to itself locations where the labels of a first pixel overlaid with a second formerly adjacent pixel do not match are identified which correspond to the edges of each superpixel that border another superpixel.

An edge label image can then be created where each edge pixel contains the neighboring superpixel ID. From the edge label image an edge statistic image can be created wherein each edge pixel contains the neighboring superpixel statistic.

A plurality of approaches algorithms can be utilized by the boundary classifier component to generate contrast statistics for an edge. One approach entails the boundary classifier component computing three contrast statistics for each edge which are derived from the following edge detectors a ratio edge detector a cross correlation edge detector a fused edge detector . As previously mentioned an external edge and or an internal edge can be determined based upon a contrast between the edge pixel s of a first superpixel and the edge pixel s of a second superpixel located at a superpixel boundary.

A ratio edge detector takes a mean of superpixel j e.g. a first superpixel and the mean of a neighboring superpixel k e.g. a second superpixel and per Eqn. 1 above computes the ratio edge detector.

As previously mentioned the ratio edge detector r enables a contrast between neighboring superpixels to be determined. The ratio edge detector rcan discount multiplicative contamination which renders it useful for SAR images which contain speckle. For additive noise especially Gaussian noise a ratio edge detector based on Euclidean distance d can be utilized however it but lacks the property that it is constrained between 0 and 1.

A cross correlation edge detector can be utilized for each superpixel j and neighboring superpixel k and utilizes the number of pixels nand nin each respective superpixel respective means and and respective standard deviations and respective variation coefficients and a contrast estimate and computes per Eqn. 6 a cross correlation coefficient 

The cross correlation coefficient can account for mean contrast as well as homogeneity of each superpixel region.

A fused edge detector enables computation of an associative symmetrical sum of the ratio edge detector r and the cross correlation edge detector per Eqn. 7 

As previously mentioned the computed contrast value s can be compared against a threshold T. In response to the boundary classifier component determining that the computed contrast value s is less than the threshold T the boundary classifier component can determine that the respective contrasts for the first superpixel and the second superpixel are similar accordingly the first superpixel and the second superpixel represent part or all of the same structure and the edge is an internal edge. Alternatively in response to the boundary classifier component determining that the computed contrast value s matches or exceeds than the threshold T the boundary classifier component can determine that the respective contrasts for the first superpixel and the second superpixel are not similar the first superpixel represents part or all of a first object and the second superpixel represents part or all of a second object and the edge is an external edge. Thus for example owing to the difference in contrasts exceeding T the first object could be a man made structure while the second object is a natural feature captured in the SAR image.

In an alternative approach rather than the previously described threshold approach the boundary classifier component can utilize the ratio based contrast values to compute pairwise edge potentials for a conditional random field CRF . The CRF utilizes the contrast values to find spatial groupings of similar superpixels which form larger segments that correspond to scene relevant regions with similar backscatter or optical properties. The divisions between the segments become the detected edges e.g. external edges and internal edges.

Further alternate representations of superpixels and their edges can be utilized. To perform logical operations on superpixels and edges storing superpixel ID numbers neighboring ID numbers and neighbor statistics in image arrays maintains spatial relationships and can speed computation times. Alternatively storing superpixel data in Matlab cell arrays or arrays of linked lists facilitates application of graph based algorithms such as conditional random fields. Finally sparse arrays provide memory efficient indexing to access relationships between neighboring superpixels and their statistics.

Furthermore the boundary classifier component can utilize an alternative method for extracting boundaries of man made structures from superpixel segmentations dependent upon computing superpixels from a number of different speckle reduced image products such as MRCS MCCD and SA ML. The edges that correspond to solid structures in the image will be replicated in every set of superpixels. Combining the segmentations together can reinforce the persistent boundaries that correspond to man made structure boundaries.

It is to be understood that artifacts in the SAR image would impact oversegmentation of the registered SAR image if the superpixel segmentation component were configured to directly oversegment the SAR image . Thus the superpixels in the segmented SAR image are different from superpixels that would be generated from directly oversegmenting the SAR image . When the artifact reduction component generates the artifact reduced SAR image product based upon the registered SAR image however resolution of at least one dimension in the artifact reduced SAR image product may be less than resolution of the SAR image . Accordingly reducing artifacts in the registered SAR image prior to oversegmenting is non intuitive as it may be expected that oversegmenting a lower resolution SAR image product may negatively impact classification performed based upon the segmented image product. In addition the artifact reduced SAR image product utilized to generate the superpixels can be based on multiple SAR image products which can be derived from different SAR backscatter phenomena. The superpixel segmentation component facilitates the ability to generate the SAR image superpixels from a particular SAR backscatter phenomenon and apply those superpixels to images or image products that exhibit an alternate SAR backscatter phenomenon. For example an MCCD image product can capture a man made structure with a high degree of accuracy and accordingly superpixels generated based upon the MCCD image product e.g. MCCD can be applied to a radar cross section image product which includes characteristic distributions of pixel intensities for different surfaces but may include less well defined edges for man made structures.

Returning to the exemplary speckle reduction operations which can be performed by the artifact reduction component the following provides an overview of SA ML MCCD and MRCS techniques which can be utilized by the artifact reduction component when generating the artifact reduced SAR image product .

Forming a SA ML image product can require transforming a complex valued SAR image e.g. registered SAR image back to the two dimensional Fourier domain partitioning the spectrum into non overlapping pieces and non coherently averaging the images formed from each piece of the spectrum. As mentioned above a SA ML image product can have a coarser spatial resolution than an SAR backscatter magnitude image formed from the complete phase history but also has reduced speckle. presents an example of an SA ML image product which can be formed by application of the SA ML imaging algorithm to a SAR image e.g. registered SAR image . The SA ML image product can be calibrated and the log magnitude computed prior to the superpixel segmentation component segmenting the artifact reduced SAR image product which is based upon the SA ML image product . For example the SA ML image product can be a 20 log SA ML .

A MRCS image product can be formed by utilizing SAR images generated based upon multiple passes over the same scene e.g. scene . Thus the artifact reduction component receives multiple SAR images e.g. from the registered images that are based upon SAR data generated from different passes over the scene and utilizes the MRCS algorithm to estimate image statistics for speckle reduction. The MRCS algorithm can form a stack of co registered Radar Cross Section RCS images of the same scene and can compute a pixel by pixel median image product to form the MRCS image product which is a temporal multilook product. The artifact reduction component can compute the log magnitude of the MRCS image product prior to the superpixel segmentation component segmenting the artifact reduced SAR image product wherein the artifact reduced SAR image product can be based upon the MRCS image product. In an exemplary embodiment a MRCS image product can refer to 20 log MRCS . shows an example of an MRCS image product .

A complex valued radar backscatter BKS image can provide not only magnitude of the backscattered radar return but also a phase of the returned signal e.g. return signal which can be utilized for determining coherence between multiple passes and for forming interferometric height maps. CCD image products produced from co registered images e.g. registered SAR images of the same scene collected at different times e.g. formed from co registering SAR images can exploit the phase information in the backscatter signal to detect subtle changes such as tire tracks in a dirt road or breeze induced shifts in vegetation. Collecting a large number of passes e.g. 25 passes or more from the same scene enables characterization of patterns of change over time. The artifact reduction component can utilize the MCCD algorithm to generate CCD image products from pairs of images in the registered SAR images and further average a plurality of CCD image products together to create a MCCD image product. The MCCD image product represents the average change for different structures terrains. For example even a field of windblown grass can produce a smooth MCCD if the change from day to day is consistent.

In an embodiment the artifact reduction component can utilize one or more of the speckle reduction techniques SA ML MCCD MRCS and optionally other techniques to form the artifact reduced SAR image product . For example the artifact reduced SAR image product can be based upon the three techniques mentioned above such that each pixel in the artifact reduced SAR image product has a three dimensional vector assigned thereto where the artifact reduced SAR image product has a resolution of the SA ML image product. Thus as noted above a value of a first dimension for a pixel can be based upon an SA ML image product generated by the artifact reduction component through use of the SA ML technique a value of a second dimension for the pixel can be based upon an MRCS image product generated by the artifact reduction component through use of the MRCS technique and a value of a third dimension for the pixel can be based upon an MCCD image product generated by the artifact reduction component through use of the MCCD technique . The pixel can also have range and azimuth dimensions assigned thereto. Accordingly the artifact reduction component can generate the artifact reduced image product such that each pixel has values for an n dimensional vector assigned thereto where n is a positive integer.

As previously mentioned the superpixel segmentation component can oversegment the artifact reduced SAR image product based upon values of the n dimensional vector for each pixel in the artifact reduced SAR image product . For example the superpixel segmentation component can employ a distance based technique when segmenting the artifact reduced SAR image product such as the QUICK SHIFT algorithm. Execution of the QUICK SHIFT algorithm over the artifact reduced SAR image product causes the artifact reduced SAR image product to be segmented into superpixels where each superpixel in the superpixels represents a region of the artifact reduced SAR image product that comprises pixels having similar intensities in close spatial proximity.

The QUICK SHIFT algorithm forms a Parzen density estimate of spatial and intensity distance relationships between neighboring pixels in the artifact reduced SAR image product . The distance between pixels i and j as shown in Eqn. 8 accounts for both difference in intensity and difference in spatial proximity between the two pixels. Per Eqn. 8 ris the row index cis the column index and Iis the intensity of pixel i 8 

Eqn. 9 shows the local Parzen density estimate for a pixel i over a neighborhood N where is the Gaussian window width and W is the search window width. 9 

The Parzen density estimate produces larger values for pixels whose close neighbors have similar intensities. presents a conceptual representation of the Parzen density over the row and column grid space comprising a plurality of high intensity regions and lower intensity regions .

In contrast to gradient search algorithms which iteratively compute gradients in the direction of a local maximum a QUICK SHIFT technique constrains its search to pass through image pixels. For each pixel in the artifact reduced product QUICK SHIFT searches a local region to find a parent pixel one that has higher density than itself and closest distance within the search region. image illustrates Parzen density contours with dots that indicate the locations of image data pixels. The arrows respectively indicate the association between each pixel at the tail and its parent at the head. Some pixels are self parents with no tails because they represent local density maxima. Then each pixel follows parents of parents creating a chain of associations until it reaches a parent with largest local density. depicts an example of this second search step which finds two parent of parent pixels indicated by boldface x s . All pixels associated with each local maximum form the corresponding superpixel where pixels labeled with 1 correspond to one local maximum and pixels labeled with 2 correspond to the other local maximum. By searching for local parent pixels with higher density QUICK SHIFT avoids computationally expensive gradient calculations but still achieves a constrained locally optimal solution. Computational complexity of QUICK SHIFT is O N .

The SLIC algorithm implements a localized k means algorithm with a distance metric that depends on both spatial and intensity differences. The Euclidean spatial distance between pixels i and j is provided in Eqn. 10 square root over 10 

Euclidean intensity distance for 3 channel intensities with weighting factors is provided in Eqn. 11 square root over 11 

In an example w w w 1 although other values are possible and more or fewer dimensions are contemplated. In an embodiment per the foregoing any combination of SA ML image product the MCCD image product and or the MRCS image product can be selected by the superpixel segmentation component as one two or three input channels for SLIC segmentation. The input channels can be scaled to similar magnitude ranges with equal weightings. If a particular channel s e.g. any of the SA ML image product the MCCD image product and or the MRCS image product is deemed to be more important than another s the weightings can be adjusted accordingly. Further the channel inputs can be weighted to scale a parameter e.g. amplitude to a similar range s . When applying SLIC to either SA ML or MRCS products log magnitude can be first computed. Applying the Euclidean distance in the log magnitude domain is equivalent to a ratio intensity distance in the magnitude domain.

As previously mentioned an n dimensional vector can also be generated with one of the input channels utilizing IF H map data. To avoid IF H map data dominating a superpixel segmentation operation a weight can be assigned to the IF H input channel e.g. a weighting that is eight times smaller than applied to the other product input channels . MLIF indicates a combination of SA ML and IF H product inputs and MLMCIF indicates a combination of SA ML MCCD and IF H product inputs.

Eqn. 12 illustrates how a SLIC based technique combines spatial and intensity distances together to create its distance measure which depends on a compactness parameter m and an initial superpixel grid spacing parameter S where S square root over N k where N is a number of pixels in the artifact reduced product and k is an initial number of superpixels 

Because the k means algorithm can produce different cluster results with different cluster center initializations SLIC based technique deterministically initializes cluster centers to local minima of the intensity gradient. image presents a conceptual representation of intensity gradient contours . Dots represent the pixel data locations and boldface x s indicate the initial cluster centers located at two local gradient minima. After initialization the SLIC based technique ignores the intensity gradient contours . SLIC computes distances between every pixel and every cluster center within a local 2S 2S area. image illustrates that for each pixel SLIC finds the closest local cluster center and assigns the respective pixel to it. The SLIC algorithm iterates between assigning pixels to closest clusters and updating cluster means. The SLIC algorithm iterates until the change in cluster center means falls below a preset threshold. Initializing cluster centers to the local intensity gradient facilitates speedy convergence as does confining each search to a local area. Computational complexity of SLIC is O N .

Any suitable values can be utilized for the QUICK SHIFT techniques and the SLIC based techniques wherein selected values can be a compromise between fidelity in representing various features in the scene and sufficient size to provide accurate statistical estimates for later classification and reasonable computational complexity. For example values of 8 and w 10 can be utilized for QUICK SHIFT techniques. While for example values of S 50K 25K or 10K can be utilized along with m 10.

For understanding pertain to analysis of a scene comprising a drainage ditch located between a road and a field wherein per the MRCS image image the location of the drainage ditch has been outlined by a hand labelled ground truth . indicate respective segmentation generated by way of different operations. image illustrates superpixels obtained by applying a QUICK SHIFT based technique where 8 and w 10. image illustrates superpixels obtained by applying a SLIC based technique where S 25K and m 10. As shown in the SLIC based technique produces more compact superpixels that conform more readily to the shape of the drainage ditch than the superpixels which are generated via the QUICK SHIFT based technique referenced in . Further the superpixels of are also more uniformly sized which can be an advantage for making statistical comparisons.

To correctly map the roadside drainage ditch can be a challenge owing to the drainage ditch having low contrast compared to the background field . Accordingly superpixelation can be improved by including height information into the SPS segmentation. image illustrates the resulting superpixels achieved when the artifact reduced product is based upon both SA ML and IF H products where S 25K and m 10. As shown in adding the interferometric height information improves the ability of the superpixels to represent two of the three arms of the drainage ditch when compared with the superpixels and in respective images B and C.

The artifact reduction component and the superpixel segmentation component can operate in unison to select and utilize one or more of the imaging processes SA ML imaging MCCD imaging or MRCS imaging or other suitable data . For example a product of SA ML imaging can contain lower spatial frequencies which yield superpixels having smoother edges which can be advantageous when attempting to represent edges of a man made structure s that may be included in the scene . Further it is possible to utilize SA ML derived superpixels to process data from any of the other image products as long as they are co registered. For example if multiple images are not available from the same scene to compute a temporal multilook MRCS image products it is possible to create superpixels from an SA ML image and then apply them to a co registered MRCS image. In another example it is possible to compute superpixel histograms from higher resolution MRCS pixels located inside SA ML superpixels. Such histograms can be useful for classifying surfaces in a SAR image e.g. any of SAR images registered SAR images etc. .

Moreover the acts described herein may be computer executable instructions that can be implemented by one or more processors and or stored on a computer readable medium or media. The computer executable instructions can include a routine a sub routine programs a thread of execution and or the like. Still further results of acts of the methodology can be stored in a computer readable medium displayed on a display device and or the like.

At respective images in the plurality of received SAR images can be registered with the baseline image to form one or more registered SAR images.

At one or more SAR imaging processes are applied to the one or more registered SAR images to product an artifact reduced SAR image product. As previously described an originally received SAR image can include speckle wherein the speckle can impact oversegmentation of the original SAR image. Accordingly any of a SA ML technique a MCCD technique a MRCS technique or other suitable technique can be applied to the registered SAR image or images to generate an artifact reduced SAR image product. For example a SA ML product can be generated and comprises smooth superpixel edges and boundaries. A 20 logof SA ML can be utilized. The plurality of registered SAR images can be arranged to form a registered SAR image stack.

At a SPS process can be performed on the artifact reduced SAR image product to generate an oversegmented image product. The oversegmentation process can utilize any suitable SPS process such as SLIC QUICK SHIFT etc. Because SLIC can incorporate a Euclidean difference based similarity measure applying it to log magnitude data is equivalent to clustering magnitude data with a ratio based similarity measure. In an embodiment the SLIC parameters can be adjusted to limit a size of any respective superpixels such that for example four to six superpixels cover a medium sized object in a SAR image and provide sufficient size for estimating statistics for example 100 pixels per superpixel. Further the oversegmentation operation can be controlled to enforce single pixel are connected to at least one of 4 immediate neighbors in the up down left and right directions and excluding diagonal connections. As previously mentioned a unique identification ID label can be created for each superpixel.

At as previously described for each superpixel in a SAR image the pixels forming each superpixel can be tagged with an ID of the superpixel they form. For example each pixel included in a superpixel with an ID 1 is labeled with a superpixel ID 1 while each pixel included in a superpixel with an ID 2 is labeled with a superpixel ID 2.

At statistics superpixel statistics can be computed for each superpixel wherein such statistics can include mean median and or coefficient of variation of intensities of the image product s from pixels within the superpixel. One or more image s of superpixel statistic s can be created where each superpixel has associated therewith a corresponding estimated statistic for the superpixel. Such statistics can include sample mean median and coefficient of variation for each superpixel j respectively per Eqns. 1 5 .

At edge pixels for each superpixel are identified found. An image comprising the superpixels and their respective IDs a superpixel label image can be shifted up down left and right with respect to itself to enable extraction of locations where a superpixel ID label applied to a pixel does not match a superpixel ID label applied to an adjacent pixel. For those pixels e.g. included in a first superpixel at which there is an ID label mismatch with pixels included in an adjacent superpixel e.g. included in a second superpixel the respective pixels can be identified as corresponding to edge pixels of each superpixel that borders another superpixel. In an embodiment utilizing SLIC can enforce 4 connected superpixels to neighbor a first superpixel and accordingly the edges of the superpixel border 4 connected neighbors as well. In an embodiment the first edge pixel s can be included in a first superpixel identified in a first image and the second edge pixel s can be included in a second superpixel identified in a second image wherein the second image is a copy of the first image and further the first superpixel and the second superpixel are adjacent to each other e.g. respective edge pixels of the first superpixel and the second superpixel form a common boundary.

At each edge pixel forming a superpixel are further assigned a superpixel ID of the superpixel adjacent to the edge pixel. Continuing the previous example a first edge pixel has been identified wherein the first edge pixel has been previously assigned the superpixel ID 1. The first edge pixel is further assigned the superpixel ID of the adjacent superpixel which has the superpixel ID 2. Hence the first edge pixel is assigned the superpixel IDs 1 2. Similarly the second edge pixel which is included in the second superpixel having the superpixel ID 2 is further assigned the superpixel ID of the adjacent superpixel which has the superpixel ID 1. Hence the second edge pixel is assigned the superpixel IDs 2 1.

At the statistical measures determined for respective properties of each superpixel which were computed in are assigned to the superpixel edge pixels. For the first edge pixel having a superpixel ID pairing of 1 2 a first property for the first superpixel superpixel ID 1 is identified for the first edge pixel and further a second property for the second superpixel superpixel ID 2 is identified for the first edge pixel. Based upon the assigned statistical measures for each edge pixel in a superpixel edge segment a ratio contrast measure is calculated between a first statistical measure of a first property of the first superpixel and a second statistical measure of a second property of the second superpixel per Eqn. 1.

At a ratio contrast measure C determination can be made regarding how closely the first property of the first superpixel matches the second property of the second superpixel. The determination can be based upon comparing the first statistical measure of the first property with the second statistical measure of the second property where the comparison can be based upon the contrast measure C calculated for the first statistical measure and the second statistical measure wherein C can be below equal to or above a threshold value T.

At in response to determining that the first property and the second property have similar values e.g. the contrast measure C is less than T the first superpixel and the second superpixel can be considered to have similar radar reflecting properties and may be superpixels forming the same object.

At in response to determining that the first superpixel and the second superpixel form the same object the edge can be identified as an internal edge. Owing to the similarity between the first property and the second property the edge can be considered to be a low contrast edge.

At a next edge in the SAR image can be identified and the process returns to for determination of which superpixels the edge pixels form a boundary or portion of a boundary and a subsequent determination can be made regarding whether the edge is an internal edge or an external edge. Wherein a subsequent pair of found superpixels respectively become the first superpixel and the second superpixel.

Returning to in response to determining that the first property and the second property are not similar e.g. do not match wherein the contrast measure C is equal to or exceeds T the flow can proceed to where the first superpixel and the second superpixel can be considered to have contrasting different radar reflecting properties and may be superpixels forming different objects. E.g. the first superpixel may be a first object having a first radar reflecting property e.g. a road and the second superpixel may be a second object having a second radar reflecting property e.g. a field of grass that borders the road .

At in response to determining that the first superpixel and the second superpixel have contrasting radar reflecting properties the edge pixels can be identified as being an external edge. Hence the edge pixels can be considered to in part identify an outline of an object e.g. a man made object such as a building in the SAR image. Owing to the difference between the first property and the second property the edge can be considered to be a high contrast edge.

It is to be appreciated that various acts presented in can be carried out in parallel. For example while the various acts of selecting edges finding edge pixels labeling edge pixels computing edge contrasts thresholding contrasts and declaring internal external edges are presented in as single step by step iterations for each determined edge pixel the various acts can be applied across a whole image simultaneously for a plurality of superpixels and their respective edge pixels. Thus referring to a continuation of methodology at when the whole image is shifted as previously described all of the edges are identified simultaneously.

At as a function of the image shifting process an index array can be created to identify e.g. keep track of every superpixel edge location and to further store the superpixel statistics in the corresponding edges.

At a first sub image is generated comprising the superpixels and a second sub image is generated also comprising the superpixels wherein respective statistics are identified for edge pixels in the first sub image and the second sub image. For every edge pixel of every first superpixel within the first sub image the first statistic of the first superpixel is assigned thereto. For every edge pixel of every first superpixel in the second image the second statistic of the second superpixel is also assigned thereto.

At a third sub image is generated by computing the element by element ratio of the first sub image to the second sub image which corresponds to SM SM per Eqn 1.

At a fourth sub image is generated by computing the element by element ratio of the second sub image to the first sub image which corresponds to SM SM per Eqn 1. Accordingly the third sub image and the fourth sub image have valid values at the edge locations e.g. edge pixels only any off edge locations e.g. non edge pixels contain invalid data.

At a fifth sub image is created by generating an element by element minimum between corresponding pixels of the third sub image and the fourth sub image which corresponds to

Hence per the foregoing it is evident that each step of the algorithm presented in Eqn. 1. is completed for all acts for every pixel before proceeding to the next act. The foregoing process is amenable to parallel processing implementations and also amenable to array processing languages such as MATLAB. Because the edges in the image pairs remain aligned to one another and because the properties for each edge location are applied when the edges are first identified a computational overhead of keeping track of a long list of edges and associated superpixels and properties can be mitigated.

At a new image can undergo boundary detection wherein the methodology can return to or any suitable act therebetween based upon prior image processing.

Referring now to a high level illustration of an exemplary computing device that can be used in accordance with the systems and methodology disclosed herein is illustrated. For example the computing device may be utilized to generate any of an artifact reduced product an oversegmented image product an oversegmented image product copy A a boundary detected image a classified image etc. For example computing device can operate as the classification device or a controller associated with the radar system . The computing device includes at least one processor that executes instructions that are stored in a memory . The instructions may be for instance instructions for implementing functionality described as being carried out by one or more components discussed above or instructions for implementing one or more of the methods described above. The processor may access the memory by way of a system bus . In addition to storing executable instructions the memory may also store image products SAR data etc.

The computing device additionally includes a data store that is accessible by the processor by way of the system bus . The data store may include executable instructions image products SAR data etc. The computing device also includes an input interface that allows external devices to communicate with the computing device . For instance the input interface may be used to receive instructions from an external computer device from a user etc. The computing device also includes an output interface that interfaces the computing device with one or more external devices. For example the computing device may display text images etc. by way of the output interface .

Additionally while illustrated as a single system it is to be understood that the computing device may be a distributed system. Thus for instance several devices may be in communication by way of a network connection and may collectively perform tasks described as being performed by the computing device .

Various functions described herein can be implemented in hardware software or any combination thereof. If implemented in software the functions can be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes computer readable storage media. A computer readable storage media can be any available storage media that can be accessed by a computer. By way of example and not limitation such computer readable storage media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein include compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc BD where disks usually reproduce data magnetically and discs usually reproduce data optically with lasers. Further a propagated signal is not included within the scope of computer readable storage media. Computer readable media also includes communication media including any medium that facilitates transfer of a computer program from one place to another. A connection for instance can be a communication medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of communication medium. Combinations of the above should also be included within the scope of computer readable media.

What has been described above includes examples of one or more embodiments. It is of course not possible to describe every conceivable modification and alteration of the above structures or methodologies for purposes of describing the aforementioned aspects but one of ordinary skill in the art can recognize that many further modifications and permutations of various aspects are possible. Accordingly the described aspects are intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims. Furthermore to the extent that the term includes is used in either the details description or the claims such term is intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

