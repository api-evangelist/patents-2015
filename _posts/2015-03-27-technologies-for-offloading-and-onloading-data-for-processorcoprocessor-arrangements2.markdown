---

title: Technologies for offloading and on-loading data for processor/coprocessor arrangements
abstract: Technologies for transferring offloading or on-loading data or tasks between a processor and a coprocessor include a computing device having a processor and a sensor hub that includes a coprocessor. The coprocessor receives sensor data associated with one or more sensors and detects events associated with the sensor data. The coprocessor determines frequency, resource usage cost, and power state transition cost for the events. In response to an offloaded task request from the processor, the coprocessor determines an aggregate load value based on the frequency, resource usage cost, and power state transition cost, and determines whether to accept the offloaded task request based on the aggregate load value. The aggregate load value may be determined as an exponential moving average. The coprocessor may determine whether to accept the offloaded task request based on a principal component analysis of the events. Other embodiments are described and claimed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09626227&OS=09626227&RS=09626227
owner: Intel Corporation
number: 09626227
owner_city: Santa Clara
owner_country: US
publication_date: 20150327
---
As more sensors are added to nearly every electronic device including laptops smartphones tablets and wearables more power is needed to process sensor data and turn it into useful information. Data retrieved from multiple sensors such as accelerometers and gyroscopes is becoming much more complex to manage. Recently sensor hubs have been making their way into mobile devices and wearable electronics due to power hungry host processors also called application processors and battery power limitations. Sensor hubs are used to run sensor fusion algorithms to offload these tasks from the host processor enabling longer battery runtimes. However offloading technologies are often affected by factors such as power consumption size constraints battery lifetime and processing resources which may affect the ability and efficiency of host processor offloading.

While the concepts of the present disclosure are susceptible to various modifications and alternative forms specific embodiments thereof have been shown by way of example in the drawings and will be described herein in detail. It should be understood however that there is no intent to limit the concepts of the present disclosure to the particular forms disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives consistent with the present disclosure and the appended claims.

References in the specification to one embodiment an embodiment an illustrative embodiment etc. indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may or may not necessarily include that particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is submitted that it is within the knowledge of one skilled in the art to effect such feature structure or characteristic in connection with other embodiments whether or not explicitly described. Additionally it should be appreciated that items included in a list in the form of at least one of A B and C can mean A B C A and B A and C B and C or A B and C . Similarly items listed in the form of at least one of A B or C can mean A B C A and B A and C B and C or A B and C .

The disclosed embodiments may be implemented in some cases in hardware firmware software or any tangibly embodied combination thereof. The disclosed embodiments may also be implemented as instructions carried by or stored on one or more non transitory machine readable e.g. computer readable storage medium which may be read and executed by one or more processors. A machine readable storage medium may be embodied as any storage device mechanism or other physical structure for storing or transmitting information in a form readable by a machine e.g. a volatile or non volatile memory a media disc or other media device .

In the drawings some structural or method features may be shown in specific arrangements and or orderings. However it should be appreciated that such specific arrangements and or orderings may not be required. Rather in some embodiments such features may be arranged in a different manner and or order than shown in the illustrative figures. Additionally the inclusion of a structural or method feature in a particular figure is not meant to imply that such feature is required in all embodiments and in some embodiments may not be included or may be combined with other features.

Referring now to in an illustrative embodiment a system is shown for processor offloading e.g. moving tasks data from a host processor to a sensor hub on loading e.g. moving tasks data from a sensor hub to a host processor and sensor management. The illustrative system includes a computing device including a processor and a sensor hub . In use the computing device of the system is operative to dynamically learn device operation such as sensor batching and delivery in order to schedule and or control offloading operations from the processor to the sensor hub . Using a feedback based configuration a processor load time series may be computed using a moving average of sensor events in the sensor hub . If the processor load is estimated to be at or below a predetermined threshold an offload decision may be made to offload processing from a processor e.g. a processor to a coprocessor e.g. a sensor hub coprocessor . If a processor load for the sensor hub is subsequently estimated to be above the predetermined threshold the coprocessor e.g. sensor hub coprocessor may revert or on load offloaded tasks back to the processor e.g. processor . A bi directional application programming interface API may assist in supporting offload and or on load requests.

Using any of the illustrative techniques disclosed herein offloading from the processor to the sensor hub and vice versa may be accomplished without materially affecting sensor hub functionality such as detecting sensor events sensor event batching and delivery. The sensor management runtime engine may be configured to perform dynamic real time learning of the sensor hub batching and delivery to make an offloading decision i.e. from the processor to the sensor hub in a feedback based system. The learning may occur in an active sensor hub environment so as to allow offload at suitable times. In comparison to simple task migration e.g. load balancing scheduling the machine learning decisions are based on sensor data and usage and further allow for bi directional capabilities for on loading and offloading tasks. For example tasks may be offloaded from the processor to the sensor hub on loaded back to the processor from the sensor hub and subsequently offloaded back to the sensor hub again.

The disclosed technologies may be utilized to efficiently determine offloading and on loading decisions between a processing apparatus e.g. the processor and a co processing apparatus e.g. the sensor hub coprocessor . The offloading and on loading decisions may be performed on a stand alone processing apparatus e.g. the processor and co processing apparatus e.g. the sensor hub coprocessor or in a configuration where the processing apparatus e.g. the processor and co processing apparatus e.g. the sensor hub coprocessor are connected to a network. For example for some application services e.g. Google Play Services dynamic algorithm offloads may be provided remotely e.g. from a remote server where updated algorithms may be run directly on a sensor hub with minimal to no involvement from the host processor e.g. the processor . Accordingly data such as context fusion algorithms may be updated without requiring firmware updates. Thus if an application service algorithm is updated it may be marked or tagged e.g. by the remote server using code to signify that the algorithm must be dynamically loaded into a sensor hub when a computing device application accesses or uses the algorithm in the service. In an illustrative embodiment the application source may contain a main and an offload Java code where an application virtual machine e.g. a Dalvik class loader upon detecting the offload code may offload the data using any of the techniques described herein.

The computing device of may be embodied as any type of computation or computer device capable of performing the functions described herein. For example the computing device may be embodied as but is not limited to a desktop computer a laptop computing device a home automation gateway device a server computer a programmable logic controller a smart appliance a consumer electronic device a wireless access point a network switch a network router a mobile computing device a mobile phone a smart phone a tablet computing device a personal digital assistant a wearable computing device and or other type of computing device configured with offloading on loading capabilities as a stand alone device or via a computer network. In the illustrative embodiment of the computing device includes a processor a I O subsystem a memory a data storage device and communication circuitry . Of course the computing device may include other or additional components such as those commonly found in a laptop computer e.g. various input output devices in other embodiments. Additionally in some embodiments one or more of the illustrative components may be incorporated in or otherwise form a portion of another component. For example the memory or portions thereof may be incorporated in the processor in some embodiments.

The processor may be embodied as any type of processor capable of performing the functions described herein. For example the processor may be embodied as a single or multi core processor s digital signal processor microcontroller or other processor or processing controlling circuit. Similarly the memory may be embodied as any type or number of volatile or non volatile memory or data storage capable of performing the functions described herein. In operation the memory may store various data and software used during operation of the computing device such as operating systems applications programs libraries and drivers. In the illustrative embodiment the memory is communicatively coupled to the processor via the I O subsystem which may be embodied as circuitry and or components to facilitate input output operations with the processor the memory and other components of the computing device . For example the I O subsystem may be embodied as or otherwise include memory controller hubs input output control hubs firmware devices communication links i.e. point to point links bus links wires cables light guides printed circuit board traces etc. and or other components and systems to facilitate the input output operations. In some embodiments the I O subsystem may form a portion of a system on a chip SoC and be incorporated along with the processor the sensor hub the memory and other components of the computing device on a single integrated circuit chip.

The peripheral devices may also include a display along with associated graphics circuitry and in some embodiments may further include a keyboard a mouse audio processing circuitry including e.g. amplification circuitry and one or more speakers and or other input output devices interface devices and or peripheral devices. In some embodiments the memory and or the data storage has stored therein one or more application programs and the processor is operable to execute the one or more application programs and control a display screen to display corresponding graphical information thereon. Of course the computing device may include other or additional components such as those commonly found in a digital apparatus and or computer e.g. various input output devices in other embodiments.

The communication circuitry of the computing device may be embodied as any type of communication circuit device or collection thereof capable of enabling communications between the computing device and other computing devices via one or more communication networks e.g. local area networks personal area networks wide area networks cellular networks a global network such as the Internet etc. . The communication circuitry may be configured to use any one or more communication technologies e.g. wireless or wired communications and associated protocols e.g. Ethernet Wi Fi WiMAX etc. to effect such communication.

The computing device also includes a sensor hub that includes a sensor hub coprocessor and includes or is otherwise coupled to one or more sensors . The sensor hub coprocessor may be embodied as a microprocessor microcontroller unit coprocessor digital signal processor DSP etc. that helps to integrate and process data from one or a plurality of different sensors . The sensors may include but are not limited to gyroscopes accelerometers global positioning system GPS receivers barometer sensors temperature sensors magnetometers touch panel interfaces infra red IR detectors and the like. Using the sensor hub coprocessor for sensor processing helps to offload sensor related tasks from the processor thus reducing battery consumption and or providing a performance improvement. Also by using a low power coprocessor e.g. the sensor hub coprocessor hardware support the application processor may stay in a sleep state while the sensor hub coprocessor collects filters and processes sensor data from any of the sensors .

The computing device may be configured to give applications e.g. applications executed from the memory and or the data storage device access to the computing device s underlying physical sensors . In some illustrative embodiments data from the sensors may be configured as data providing virtual devices defined by the implementation of a sensor Hardware Abstraction Layer HAL e.g. as defined by sensors.h or a similar API definition . In some illustrative embodiments sensors may be coupled to each other and or the sensor hub coprocessor in the sensor hub via a transport mechanism e.g. Inter Integrated Circuit IC or Serial Peripheral Interface SPI which may allow low power monitoring and processing of the sensor data. To reduce power consumption the sensor hub may be hierarchical where some minimal processing is performed by each sensor in an application specific integrated circuit ASIC and further processing is performed in the sensor hub coprocessor . The sensor signals may further be batched to store sensor events in a hardware FIFO before reporting them through the HAL instead of reporting them immediately. Batching can enable significant power savings by preventing the processor from waking up to receive each event from the sensors. Instead the events can be grouped batched and processed together.

The sensor hub may be configured to combine sensor data e.g. from sensors or data derived from sensor data by the sensor hub to increase the accuracy dependability and or completeness of data received from the sensors via the sensor hub . The sensor hub may be configured for direct fusion which fuses sensor data from a set of heterogeneous or homogeneous sensors soft sensors and history values of sensor data. The sensor hub may also be configured for indirect fusion which uses information sources like a priori knowledge about the environment and human input.

Referring now to in the illustrative embodiment the computing device establishes an environment during operation. The illustrative environment includes modules established by the application processor or host processor and the sensor hub coprocessor . As shown the environment includes an application module a task schedule module a sensor management module a sensor profiling module and a machine learning module . The various modules of the environment may be embodied as hardware firmware software or a combination thereof. For example the various modules logic and other components of the environment may form a portion of or otherwise be established by the processor the coprocessor or other hardware components of the computing device . As such in some embodiments any one or more of the modules of the environment may be embodied as a circuit or collection of electrical devices e.g. a task schedule circuit a sensor management circuit etc. .

The application module is configured to execute an application virtual machine VM and one or more applications using the application processor . The application VM also known as a process VM or Managed Runtime Environment MRE may be configured to provide a platform independent programming environment that abstracts away details of the underlying hardware or operating system and allows a program e.g. from the applications to execute in the same way on any platform. The application VM that may be configured to run as a normal application inside the computing device operating system host OS and may support one or more processes. In some illustrative embodiments the application VM may provide a high level abstraction similar to a high level programming language and may be implemented using an interpreter. Just in time compilers may be used to increase performance. Illustrative application VMs include but are not limited to Dalvik and Android Runtime ART running Dex bytecode and their core Java application libraries. The applications may be embodied as software that may be executed e.g. launched processed initialized etc. within an application framework. The application module and or the application virtual machine may also include middleware. In some illustrative embodiments the middleware may include libraries that provide services such as inter application messaging services data storage screen display multimedia and web browsing. The middleware libraries may be compiled to machine language to allow services to execute quickly.

The application module may be configured to transmit one or more offloaded task requests to the sensor hub and to receive on load task requests from the sensor hub . The offloaded task request may include code data or other information that may be used to execute a processing task by the sensor hub . In some embodiments the application module may adapt its task offloading behavior based on feedback received from the sensor hub for example determining whether to submit additional offloaded task requests based on the availability of the sensor hub . The application module and or the application VM may provide an appropriate response that does not offload tasks or code to the sensor hub at the same time that the sensor hub is expecting potential sensor events and or sensor event triggers. The application VM may also detect the sensor hub availability and platform SOix state active idle power state transitions that may allow the application VM to schedule and even override the sensor hub tasks tasklets to ensure that sensor events are not missed.

The task schedule module established by the coprocessor is configured to receive offloaded task requests from the application processor . As described below if the offloaded task requests are accepted the task schedule module may be configured to execute the offloaded tasks using processing resources of the sensor hub e.g. the coprocessor . In some embodiments the task schedule module may be configured to transmit a task on load request to the application processor if the offloaded task request is not accepted.

The sensor management module established by the coprocessor is configured to receive sensor data associated with the sensors of the computing device . The sensor profiling module established by the coprocessor is configured to detect sensor events and or timer events associated with the sensor data. The sensor profiling module is configured to determine a resource usage cost value for the events which may be embodied as a coprocessor usage value for processing of one or more callback functions associated with the events. The sensor profiling module is further configured to determine a power state transition cost value associated with the events which may be embodied as a cost associated with bringing a functional block of the computing device from a low power state to an operational state to process the events.

The machine learning module established by the coprocessor is configured to determine an aggregate coprocessor load value associated with the plurality of events as a function of the frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events. The aggregate coprocessor load value may be determined for example as an exponential moving average. The machine learning module is configured to determine whether to accept the offloaded task request based on the aggregate coprocessor load value combined with a coprocessor load value associated with the offloaded task request. In some embodiments the machine learning module may be configured to perform a principal component analysis PCA of the events and based on the PCA computation determine whether a change in usage pattern of the computing device exists. The machine learning module may be configured to determine whether the offloaded task request is associated with a short term task or a long term task and to adjust the determination of whether to accept the offloaded task based on whether the offloaded task is short term or long term. Those functions may be performed by one or more sub modules such as a moving average module or a principal component analysis module .

Although illustrated as being established by coprocessor it should be understood that in certain embodiments part or all of each of the task schedule module the sensor management module sensor profiling module and or the machine learning module may be established by the application processor . For example in some embodiments task scheduling and event profiling may be performed by the coprocessor but machine learning calculations may be performed by the application processor .

Referring now to in use the computing device may execute a method for performing offloading operations to the sensor hub depending on an aggregated processor e.g. coprocessor workload. The method begins in block in which the sensor hub coprocessor of the computing device determines whether an offloaded task request has been received from the application processor . The offloaded task request identifies one or more tasks such as tasklets sensor fusion events or other tasks that the application processor has requested the sensor hub to execute. If an offloaded task request has not been received the method loops back to block and the coprocessor continues with normal operations. If an offload task request has been received or a task offload is otherwise required the method advances to block .

In block the coprocessor determines an aggregated workload value L based on the sensor hub processing capability current sensor processing workload and near future sensor processing workload. One method for calculating the aggregated workload value L is described below in connection with .

After determining the aggregated workload value L in block the method proceeds to block in which the coprocessor of the computing device determines if the aggregate workload value L of the processor is less than a residual sensor hub processing capacity or bandwidth. For example the aggregate workload value L combined with a workload value associated with the offloaded task request e.g. an estimated workload value for the offloaded task may be compared to a predefined threshold workload value. In an illustrative embodiment the predefined threshold workload value may be approximated or otherwise determined by the number of processing cores of the coprocessor . If the aggregated workload value L including the workload value associated with the offloaded task request is less than the residual sensor hub processing capacity the method proceeds to block in which the offloaded task request from the application host processor to the sensor hub is accepted and the offloaded task is subsequently executed. After offloading the task the method loops back to block to process additional offloaded task requests.

Referring back to block if the aggregate workload value L is not less than the residual sensor hub processing capacity the method proceeds to block in which the coprocessor requests to on load the task to the application processor . The application processor may execute the task in response to receiving the on load task request. In some embodiments the application processor may modify future offloaded task requests based on receiving the request to on load the task. For example a managed runtime executed by the application processor may learn or otherwise adapt to the availability of the sensor hub and may schedule offloaded tasks to make sure sensor events are not missed. After on loading the task the method loops back to block to process additional offloaded task requests.

Referring now to in use the computing device may execute a method for calculating and determining an aggregated processor workload of the sensor hub . The method may be executed for example in connection with block of the method illustrated in above or in connection with the method illustrated in below. The method begins in block in which the coprocessor of the computing device detects sensor and or timer events associated with sensor data received by the sensor hub . For example it may be assumed for the purposes of the illustrative method of that there are n types of sensor or timer events S . In some embodiments a composite sensor event e.g. an event produced from more than one sensor or derived from other sensor data may be treated as a new event type. In block the coprocessor determines the frequency of the sensor timer events. At any given unit time of time t the frequency of the sensor timer events is f.

In block the coprocessor determines the resource usage cost associated with processing each callback function associated with those events. For example the coprocessor may determine coprocessor cycles or other execution resources used by the callback functions. The resource usage cost associated with each event Smay be expressed as L. In block the coprocessor calculates a cost P associated with power state transitions to bring the functional block e.g. an IP block in the processor e.g. the processor and or the coprocessor from a low power state e.g. D0i3 to an operational state e.g. D0i0 at run time.

Referring now to in use the computing device may execute a method for performing offloading operations to the sensor hub depending on an aggregated processor e.g. coprocessor workload and a principal component analysis PCA computation. The method begins in block in which the sensor hub coprocessor of the computing device determines whether an offloaded task request has been received from the application processor . The offloaded task request identifies one or more tasks such as tasklets sensor fusion events or other tasks that the application processor has requested the sensor hub to execute. If an offloaded task request has not been received the method loops back to block and the coprocessor continues with normal operations. If an offload task request has been received or a task offload is otherwise required the method advances to block .

In block the coprocessor determines an aggregated workload value L based on the sensor hub processing capability current sensor processing and near future sensor processing workload. One method for calculating the aggregated workload value L is described above in connection with . After determining the aggregated workload value L in block the method proceeds to block in which the coprocessor performs a principal component analysis PCA on the sensor event data. Calculating PCA allows the coprocessor to detect phase shifts in sensor events that are typically associated with changes in the usage pattern of the computing device . For example as described further below calculating PCA may detect changes in eigenvalues that exceed one or more thresholds. Calculating PCA may provide robust data that is particularly suited for sensor data analysis. One embodiment of a method for calculating PCA is described below in connection with . Of course in some embodiments the coprocessor may use one or more other techniques to compute probabilistic models for sensor usage for the sensor hub and to make predictions or decisions on on loading and offloading tasks and or data between the processor and the sensor hub .

In block the coprocessor of the computing device determines whether the offloaded task request is associated with a short term request. The coprocessor may use any appropriate criteria for determining whether a requested task is a short term request. For example the coprocessor may determine whether the requested task is short term based on a predefined time scale e.g. minutes hours days etc. . If the request is not a short term request e.g. it is a long term request the method branches to block described below. If the request is a short term request the method branches to block .

In block the coprocessor determines whether to offload the requested task based on the aggregated workload value L or the results of the principal component analysis. The determination based on the aggregated workload value L may be similar to the determination described above in connection with block of . For example the coprocessor may determine to offload the task if the aggregated workload value L is below a predefined threshold or if the PCA analysis indicates that a change in the usage pattern is not likely. If the coprocessor determines to offload the requested task the method branches to block in which the offloaded task request from the application host processor to the sensor hub is accepted and the offloaded task is subsequently executed. After offloading the task the method loops back to block to process additional offloaded task requests.

Referring back to block if the coprocessor determines not to offload the task the method branches to block in which the coprocessor requests to on load the task to the application processor . The application processor may execute the task in response to receiving the on load task request. In some embodiments the application processor may modify future offloaded task requests based on receiving the request to on load the task. For example a managed runtime executed by the application processor may learn or otherwise adapt to the availability of the sensor hub and may schedule offloaded tasks to make sure sensor events are not missed. After on loading the task the method loops back to block to process additional offloaded task requests.

Referring back to block if the request is not a short term request e.g. it is a long term request the method branches to block . In block the coprocessor determines whether to offload the requested task based on the aggregated workload value L and the results of the principal component analysis. The determination based on the aggregated workload value L may be similar to the determination described above in connection with block of . For example the coprocessor may determine to offload the task if the aggregated workload value L is below a predefined threshold and if the PCA analysis indicates that a change in the usage pattern is not likely. If the coprocessor determines to offload the requested task the method branches to block in which the offloaded task request is accepted as described above. If the coprocessor determines not to offload the task the method branches to block in which the coprocessor requests to on load the task to the application processor as described above.

Referring now to in use the computing device may execute a method for determining whether to offload tasks using a principal component analysis PCA machine learning algorithm. PCA is a statistical technique that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables or principal components. In certain illustrative embodiments the number of principal components may be less than or equal to the number of original variables. In certain illustrative embodiments the orthogonal transformation may be defined in such a way that the first principal component has the largest possible variance i.e. accounts for as much of the variability in the data as possible and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to i.e. uncorrelated with the preceding components. The principal components may be considered orthogonal because they are the eigenvectors of the covariance matrix which is symmetric. In certain illustrative embodiments PCA may operate similarly to eigenvector based multivariate analyses in that the PCA processing may reveal the internal structure of the collected network data in a way that best explains the variance in the data. If a multivariate dataset is presented as a set of coordinates in a high dimensional data space e.g. 1 axis per variable PCA can supply the network with lower dimensional datasets which may provide more useful information.

The method may be performed in connection with block of as described above. The method begins in block in which the coprocessor extracts features of interest from sensor timer events and related data. In block the coprocessor forms vectors from the extracted features. The coprocessor may collect extracted feature data for a period of time and then perform feature aggregation on the extracted sensor features of interest. The coprocessor may then generate observation or feature vectors. During the forming of vectors in block processor loads associated with sensor timer events may be characterized as vectors of a given dimensionality.

The coprocessor creates eigenvalue average processor load key value pairs for sensor timer events in block . As mentioned above principal component analysis PCA is a statistical procedure for converting a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables principal components . Using PCA the coprocessor may compute principal components from observation vectors and characterize the variations of the vectors across the given dimensions. In some illustrative embodiments principal components of the average processor loads may be the eigenvectors of a resulting covariance matrix where offloading and on loading decision thresholds can be computed in this way from the principal components. The coprocessor may be configured to record and store each calculated eigenvalue as model entries for an eigenvalue average processor load key value pair in an internal table. As new processor load data is received it may be associated with new eigenvalues detected through table lookup. The coprocessor or other suitable component of the computing device may continue to detect sensor timer events in block and in block detect changes in eigenvalues that exceed one or more thresholds determined in block . After detecting any changes in eigenvalues the method is completed. The results of the PCA computation may be used to determine whether to accept an offloaded task request as described in connection with . If changes in eigenvalues exceed one or more thresholds the sensor hub may make an offload or on load decision to offload data and or tasks from processor to sensor hub .

Illustrative examples of the technologies disclosed herein are provided below. An embodiment of the technologies may include any one or more and any combination of the examples described below.

Example 1 includes a computing device for coprocessor task offloading the computing device comprising a sensor management module to receive by a coprocessor of the computing device sensor data associated with one or more sensors of the computing device a sensor profiling module to detect by the coprocessor a plurality of events associated with the sensor data and determine by the coprocessor a resource usage cost value and a power state transition cost value associated with the events a task schedule module to receive by the coprocessor an offloaded task request from an application processor of the computing device and a machine learning module to determine by the coprocessor an aggregate coprocessor load value associated with the plurality of events as a function of a frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events and determine by the coprocessor whether to accept the offloaded task request based on the aggregate coprocessor load value and a coprocessor load value associated with the offloaded task request.

Example 2 includes the subject matter of Example 1 and wherein the plurality of events comprises a sensor event or a timer event.

Example 3 includes the subject matter of any of Examples 1 and 2 and wherein to determine the resource usage cost value comprises to determine a coprocessor usage value for processing of one or more callback functions associated with the events.

Example 4 includes the subject matter of any of Examples 1 3 and wherein to determine the power state transition cost comprises to determine a cost associated with bringing a functional block of the computing device from a low power state to an operational state to process the events.

Example 5 includes the subject matter of any of Examples 1 4 and wherein to determine the aggregate coprocessor load value comprises to determine an exponential moving average as a function of the frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events.

Example 6 includes the subject matter of any of Examples 1 5 and wherein the task schedule module is further to transmit by the coprocessor a task on load request to the application processor in response to determining not to accept the offloaded task request.

Example 7 includes the subject matter of any of Examples 1 6 and further including an application module to determine by the application processor whether to transmit a second task offload request to the coprocessor based on receiving the task on load request from the coprocessor.

Example 8 includes the subject matter of any of Examples 1 7 and wherein to determine whether to accept the offloaded task request comprises to determine whether to accept the offloaded task request based on a residual processing capacity of the coprocessor.

Example 9 includes the subject matter of any of Examples 1 8 and wherein to determine whether to accept the offloaded task request comprises to compare the aggregate coprocessor load value and the coprocessor load value associated with the offloaded task request to a predefined threshold coprocessor load value.

Example 10 includes the subject matter of any of Examples 1 9 and wherein the predefined threshold coprocessor load value is based on a number of processor cores of the coprocessor.

Example 11 includes the subject matter of any of Examples 1 10 and wherein the machine learning module is further to perform a principal component analysis of the plurality of events and determine whether a change in usage pattern of the computing device exists based on the principal component analysis wherein to determine whether to accept the offloaded task request further comprises to determine whether to accept the offloaded task request as a function of a determination of whether the change in usage pattern of the computing device exists.

Example 12 includes the subject matter of any of Examples 1 11 and wherein the machine learning module is further to determine by the coprocessor whether the offloaded task request is associated with a short term task wherein to determine whether to accept the offloaded task request further comprises to determine whether to accept the offloaded task request as a function of a determination of whether the offloaded task request is associated with a short term task.

Example 13 includes the subject matter of any of Examples 1 12 and wherein in response to a determination that the offloaded task request is associated with a short term task to determine whether to accept the offloaded task comprises to determine whether to accept the task based on i a determination of the aggregate coprocessor load value or ii a determination of whether the change in usage pattern of the computing device exists and in response to a determination that the offloaded task request is not associated with a short term task to determine whether to accept the offloaded task comprises to determine whether to accept the task based on i a determination of the aggregate coprocessor load value and ii a determination of whether the change in usage pattern of the computing device exists.

Example 14 includes a method for coprocessor task offloading the method comprising receiving by a coprocessor of a computing device sensor data associated with one or more sensors of the computing device detecting by the coprocessor a plurality of events associated with the sensor data determining by the coprocessor a resource usage cost value and a power state transition cost value associated with the events receiving by the coprocessor an offloaded task request from an application processor of the computing device determining by the coprocessor an aggregate coprocessor load value associated with the plurality of events as a function of a frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events and determining by the coprocessor whether to accept the offloaded task request based on the aggregate coprocessor load value and a coprocessor load value associated with the offloaded task request.

Example 15 includes the subject matter of Example 14 and wherein detecting the plurality of events comprises detecting a sensor event or a timer event.

Example 16 includes the subject matter of any of Examples 14 and 15 and wherein determining the resource usage cost value comprises determining a coprocessor usage value for processing one or more callback functions associated with the events.

Example 17 includes the subject matter of any of Examples 14 16 and wherein determining the power state transition cost comprises determining a cost associated with bringing a functional block of the computing device from a low power state to an operational state to process the events.

Example 18 includes the subject matter of any of Examples 14 17 and wherein determining the aggregate coprocessor load value comprises determining an exponential moving average as a function of the frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events.

Example 19 includes the subject matter of any of Examples 14 18 and further including transmitting by the coprocessor a task on load request to the application processor in response to determining not to accept the offloaded task request.

Example 20 includes the subject matter of any of Examples 14 19 and further including determining by the application processor whether to transmit a second task offload request to the coprocessor based on receiving the task on load request from the coprocessor.

Example 21 includes the subject matter of any of Examples 14 20 and wherein determining whether to accept the offloaded task request comprises determining whether to accept the offloaded task request based on a residual processing capacity of the coprocessor.

Example 22 includes the subject matter of any of Examples 14 21 and wherein determining whether to accept the offloaded task request comprises comparing the aggregate coprocessor load value and the coprocessor load value associated with the offloaded task request to a predefined threshold coprocessor load value.

Example 23 includes the subject matter of any of Examples 14 22 and wherein the predefined threshold coprocessor load value is based on a number of processor cores of the coprocessor.

Example 24 includes the subject matter of any of Examples 14 23 and further including performing by the coprocessor a principal component analysis of the plurality of events and determining by the coprocessor whether a change in usage pattern of the computing device exists based on the principal component analysis wherein determining whether to accept the offloaded task request further comprises determining whether to accept the offloaded task request as a function of determining whether the change in usage pattern of the computing device exists.

Example 25 includes the subject matter of any of Examples 14 24 and further including determining by the coprocessor whether the offloaded task request is associated with a short term task wherein determining whether to accept the offloaded task request further comprises determining whether to accept the offloaded task request as a function of determining whether the offloaded task request is associated with a short term task.

Example 26 includes the subject matter of any of Examples 14 25 and wherein in response to determining that the offloaded task request is associated with a short term task determining whether to accept the offloaded task comprises determining whether to accept the task based on i determining the aggregate coprocessor load value or ii determining whether the change in usage pattern of the computing device exists and in response to determining that the offloaded task request is not associated with a short term task determining whether to accept the offloaded task comprises determining whether to accept the task based on i determining the aggregate coprocessor load value and ii determining whether the change in usage pattern of the computing device exists.

Example 27 includes a computing device comprising a processor and a memory having stored therein a plurality of instructions that when executed by the processor cause the computing device to perform the method of any of Examples 14 26.

Example 28 includes one or more machine readable storage media comprising a plurality of instructions stored thereon that in response to being executed result in a computing device performing the method of any of Examples 14 26.

Example 29 includes a computing device comprising means for performing the method of any of Examples 14 26.

Example 30 includes a computing device for coprocessor task offloading the computing device comprising means for receiving by a coprocessor of the computing device sensor data associated with one or more sensors of the computing device means for detecting by the coprocessor a plurality of events associated with the sensor data means for determining by the coprocessor a resource usage cost value and a power state transition cost value associated with the events means for receiving by the coprocessor an offloaded task request from an application processor of the computing device means for determining by the coprocessor an aggregate coprocessor load value associated with the plurality of events as a function of a frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events and means for determining by the coprocessor whether to accept the offloaded task request based on the aggregate coprocessor load value and a coprocessor load value associated with the offloaded task request.

Example 31 includes the subject matter of Example 30 and wherein the means for detecting the plurality of events comprises means for detecting a sensor event or a timer event.

Example 32 includes the subject matter of any of Examples 30 and 31 and wherein the means for determining the resource usage cost value comprises means for determining a coprocessor usage value for processing one or more callback functions associated with the events.

Example 33 includes the subject matter of any of Examples 30 32 and wherein the means for determining the power state transition cost comprises means for determining a cost associated with bringing a functional block of the computing device from a low power state to an operational state to process the events.

Example 34 includes the subject matter of any of Examples 30 33 and wherein the means for determining the aggregate coprocessor load value comprises means for determining an exponential moving average as a function of the frequency of the events the resource usage cost value associated with the events and the power state transition cost value associated with the events.

Example 35 includes the subject matter of any of Examples 30 34 and further including means for transmitting by the coprocessor a task on load request to the application processor in response to determining not to accept the offloaded task request.

Example 36 includes the subject matter of any of Examples 30 35 and further including means for determining by the application processor whether to transmit a second task offload request to the coprocessor based on receiving the task on load request from the coprocessor.

Example 37 includes the subject matter of any of Examples 30 36 and wherein the means for determining whether to accept the offloaded task request comprises means for determining whether to accept the offloaded task request based on a residual processing capacity of the coprocessor.

Example 38 includes the subject matter of any of Examples 30 37 and wherein the means for determining whether to accept the offloaded task request comprises means for comparing the aggregate coprocessor load value and the coprocessor load value associated with the offloaded task request to a predefined threshold coprocessor load value.

Example 39 includes the subject matter of any of Examples 30 38 and wherein the predefined threshold coprocessor load value is based on a number of processor cores of the coprocessor.

Example 40 includes the subject matter of any of Examples 30 39 and further including means for performing by the coprocessor a principal component analysis of the plurality of events and means for determining by the coprocessor whether a change in usage pattern of the computing device exists based on the principal component analysis wherein the means for determining whether to accept the offloaded task request further comprises means for determining whether to accept the offloaded task request as a function of determining whether the change in usage pattern of the computing device exists.

Example 41 includes the subject matter of any of Examples 30 40 and further including means for determining by the coprocessor whether the offloaded task request is associated with a short term task wherein the means for determining whether to accept the offloaded task request further comprises means for determining whether to accept the offloaded task request as a function of determining whether the offloaded task request is associated with a short term task.

Example 42 includes the subject matter of any of Examples 30 41 and wherein in response to determining that the offloaded task request is associated with a short term task the means for determining whether to accept the offloaded task comprises means for determining whether to accept the task based on i determining the aggregate coprocessor load value or ii determining whether the change in usage pattern of the computing device exists and in response to determining that the offloaded task request is not associated with a short term task the means for determining whether to accept the offloaded task comprises means for determining whether to accept the task based on i determining the aggregate coprocessor load value and ii determining whether the change in usage pattern of the computing device exists.

