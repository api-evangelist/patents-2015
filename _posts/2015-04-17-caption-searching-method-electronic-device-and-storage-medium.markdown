---

title: Caption searching method, electronic device, and storage medium
abstract: The present disclosure provides a caption searching method including: obtaining characteristic information of a video file to be played, and searching for a caption, for the video file to be played, in a caption database according to the characteristic information, so as to generate a search result; performing, according to the search result, a voice textualization process on the video file to be played; and updating the caption database according to a textualized caption generated by the voice textualization process, and using an updated caption in the caption database as a caption of the video file to be played. The present disclosure further provides an electronic device and storage medium for the caption searching. In this manner, a search for a caption is based on audio information recognition from the video file, to increase a hit rate and reduce an error rate of caption matching.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09456175&OS=09456175&RS=09456175
owner: TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED
number: 09456175
owner_city: Shenzhen
owner_country: CN
publication_date: 20150417
---
This application is a continuation of PCT Application No. PCT CN 2013 084263 filed on Sep. 26 2013 which claims priority to Chinese Patent Application No. CN 201210398027.1 filed on Oct. 18 2012 the entire contents of all of which are incorporated herein by reference.

The present disclosure generally relates to the field of Internet technologies and more particularly relates to a caption searching method electronic device and storage medium.

With the rapid development of multimedia technologies and Internet technologies video as a media type is becoming an important form for providing information in life education entertainment and other aspects of people. A caption is a very important part in a video file especially in a video file in a foreign language. Users often have difficulties in understanding the foreign language and often miss information in the video. Dubbing voice may be helpful but may hardly reproduce the effect of original sounds. As a result captioning may be the most effective and convenient method to solve this problem.

Current mainstream players all provide the function of matching a video file with captions in an online caption library but the matching has a low success rate or has a high error rate resulting in poor user experience when users view captions. A main cause of the problem is that the online caption library is not rich enough for a player on a client which leads to a low hit rate or a high error rate of caption matching of the player.

Therefore there is a need to solve technical problems in the Internet and multimedia technologies to provide methods devices and storage media for searching captions for a video in any possible languages.

An objective of the present disclosure is to provide a caption searching method electronic device and storage media that are based on audio information recognition which can increase a hit rate and reduce an error rate of caption matching so as to solve the technical problems that an existing video player has a low hit rate or a high error rate in caption matching.

In order to solve the problem the present disclosure provides the following technical solutions. One aspect or embodiment of the present disclosure provides a caption searching method by obtaining characteristic information of a video file to be played and searching for a caption for the video file to be played in a caption database according to the characteristic information so as to generate a search result performing according to the search result a voice textualization process on the video file to be played by extracting audio information of the video file to be played and converting the audio information into a textualized caption and updating the caption database according to the textualized caption generated by the voice textualization process and using an updated caption in the caption database as a caption of the video file to be played.

Another aspect or embodiment of the present disclosure further provides an electronic device for searching a caption. The electronic device includes one or more processors a memory and one or more programs stored in the memory and configured to be executed by the one or more processors to provide a caption searching method. The one or more programs are divided according to functions and include a searching module a voice textualization module and an update module. The searching module is configured to obtain characteristic information of a video file to be played and search for a caption for the video file to be played in a caption database according to the characteristic information so as to generate a search result. The voice textualization module is configured to perform according to the search result a voice textualization process on the video file to be played. The voice textualization module includes an extraction unit configured to extract audio information of the video file to be played and a conversion unit configured to convert the audio information into a textualized caption. The update module is configured to update the caption database according to the textualized caption generated by the voice textualization process and to use an updated caption updated in the caption database as a caption of the video file to be played.

The present disclosure further provides a non transitory computer readable storage medium having instructions stored thereon. When being executed the instructions cause the processor to implement a caption searching method. The method includes obtaining characteristic information of a video file to be played and searching for a caption for the video file to be played in a caption database according to the characteristic information so as to generate a search result performing a voice textualization process on the video file to be played according to the search result by extracting audio information of the video file to be played and converting the audio information into a textualized caption and updating the caption database according to the textualized caption generated by the voice textualization process and using an updated caption in the caption database as a caption of the video file to be played.

Compared with the existing technology in the disclosed caption searching method electronic device and storage media of the present disclosure a search for a caption is based on audio information recognition which can increase a hit rate and reduce an error rate of caption matching so as to solve the technical problems that an existing video player has a low hit rate or a high error rate in caption matching.

Other aspects or embodiments of the present disclosure can be understood by those skilled in the art in light of the description the claims and the drawings of the present disclosure.

Refer to the figures in which identical component symbols indicate identical components. The principle of the present disclosure is illustrated by using an example in which the present disclosure is implemented in a suitable computing environment. The following description is made based on exemplified specific embodiments of the present invention and shall not be construed as a limitation on other specific embodiments of the present invention that are not detailed here.

In the description that follows unless otherwise specified the specific embodiments of the present invention will be described with reference to steps and symbols of operations that are performed by one or more computers. Therefore it can be understood that execution of such steps and operations by a computer as mentioned several times includes manipulating by a computer processing unit electrical signals representing data in a structured form. This manipulation transforms the data or maintains it at locations in the memory system of the computer which reconfigures or otherwise alters the operation of the computer in a manner well known by a person skilled in the art. The data structure where data is maintained is a physical location of the memory that has particular properties defined by the format of the data. However while the principle of the present disclosure is described in the foregoing context the present disclosure is not limited thereto and a person skilled in the art will appreciate that various steps and operations described hereinafter may also be implemented in hardware.

The terms such as component module system and interface used in the present application are generally intended to refer to computer related entities hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to a process running on a processor a processor an object an executable application a thread in execution a program and or a computer. As illustrated in the figures both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread in execution and the component may be located on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method an apparatus or a product that uses standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term product used herein is intended to encompass a computer program accessible to any computer readable device carrier or medium. Certainly a person skilled in the art will realize that many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

An exemplary electronic device includes but is not limited to a personal computer a server computer a hand held or laptop device a mobile device such as a mobile phone a personal digital assistant PDA or a media player a multiprocessor system a consumer electronic device a mini computer a mainframe computer and or a distributed computing environment that includes any of the foregoing systems or devices and the like.

Although not required computer readable instructions may be executed by one or more exemplary electronic devices. The computer readable instructions may be distributed by using a computer readable medium e.g. a non transitory computer readable medium as discussed below . The computer readable instructions may be implemented as program modules such as functions objects application programming interfaces APIs or data structures that perform particular tasks or implement particular abstract data types. Typically functions of the computer readable instructions may be combined or distributed as desired in various environments.

For example the electronic device in may be used to implement caption searching methods according to various disclosed embodiments in the present disclosure. In one configuration the electronic device includes a configuration including at least one processing unit and a memory . Depending on the exact configuration and type of the electronic device the memory may be volatile such as a random access memory RAM non volatile such as a read only memory ROM or a flash memory or combination s thereof.

In various embodiments the electronic device may include additional features and or functions. For example the device may further include an additional storage device for example a removable and or non removable storage device which includes but is not limited to a magnetic storage device an optical storage device and the like. Such additional storage device is illustrated in as a storage device . In one embodiment computer readable instructions for implementing one or more embodiments of the present invention may be stored in the storage device . The storage device may also store other computer readable instructions for implementing an operating system an application program and the like. The computer readable instructions may be loaded in the memory and executed by for example the processing unit .

The term computer readable medium used herein includes a computer storage medium. The computer storage medium includes volatile and non volatile removable and non removable media implemented in any method or technology for storing information such as computer readable instructions or other data. The memory and the storage device are examples of the computer storage medium. The computer storage medium includes but is not limited to a RAM a ROM an electrically erasable programmable read only memory EEPROM a flash memory or other memory technologies a CD ROM a digital versatile disk DVD or other optical storage devices a magnetic cassette a magnetic tape a magnetic disk storage device or other magnetic storage devices or any other medium that can be used to store desired information and is accessible to the electronic device . Any such computer storage medium may be a part of the electronic device .

The electronic device may also include a communication connection that allows the electronic device to communicate with other devices or networks. The communication connection may include but be not limited to a modem a network interface card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a universal serial bus USB connection or other interfaces for connecting the electronic device to other electronic devices. The communication connection may include a wired connection or a wireless connection. The communication connection may transmit and or receive communication media.

The term computer readable medium may include any suitable communication medium. Typically the communication medium includes computer readable instructions or other data in a modulated data signal such as a carrier wave or other transmission mechanisms and includes any information delivery medium. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information into the signal.

The electronic device may include an input device such as a keyboard a mouse a stylus a voice input device a touch input device an infrared camera a video input device and or any other suitable input device. The device may also include an output device such as one or more displays speakers printers and or any other output device. The input device and the output device may be connected to the electronic device via a wired connection a wireless connection or any combination thereof. In one embodiment an input device or an output device from another electronic device may be used as the input device or the output device of the electronic device .

Components of the electronic device may be connected by various interconnects such as a bus . Such interconnects may include a peripheral component interconnect PCI such as PCI Express a universal serial bus USB a firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of the electronic device may be interconnected by a network. For example the memory may be formed by multiple physical memory units located in different physical locations interconnected by a network.

A person skilled in the art will realize that storage devices utilized for storing computer readable instructions may be distributed across networks. For example an electronic device accessible via a network may store computer readable instructions for implementing one or more embodiments of the present invention. The electronic device may access the electronic device and download a part or all of the computer readable instructions for execution. Alternatively the electronic device may download multiple computer readable instructions as needed or some instructions may be executed on the electronic device and some on the electronic device .

Various operations are provided herein. In one embodiment the one or more operations may constitute computer readable instructions stored on one or more computer readable media and when being executed by an electronic device the computer readable instructions will cause a computing device to perform the operations. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily related in such order. Alternative order of implementation having the benefit of this specification will be appreciated by a person skilled in the art. Further it should be understood that not all operations are necessary in each embodiment provided herein.

Moreover the word preferred is used herein to imply an example instance or illustration. Any aspect or design described herein as preferred is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word preferred is intended to present concepts in a concrete fashion. As used in the present application the term or is intended to imply an inclusive or rather than an exclusive or . Therefore unless specified otherwise or clarified in the context X uses A or B implies any of the natural inclusive permutations. That is if X uses A X uses B or X uses both A and B t X uses A or B is satisfied under any of the foregoing instances.

Although the present disclosure has been shown and described with respect to one or more implementations a person skilled in the art will conceive of equivalent alterations and modifications after reading and understanding this specification and the accompanying drawings. The present disclosure includes all such modifications and alterations and is only limited by the scope of the appended claims. In particular regard to the various functions performed by the above described components for example elements and resources the term used to describe such a component is intended to correspond to any component unless otherwise indicated that performs the specified function of the described component for example the component is functionally equivalent even if not structurally equivalent to the disclosed structure which performs the function in the exemplary implementations of the present disclosure illustrated herein. In addition while a particular feature of the present disclosure has been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of other implementations that may be desired by and beneficial to any given or particular application. Furthermore to the extent that the terms include have contain and variants thereof are used in either the embodiments or the claims these terms are intended imply inclusion similar to the term comprise .

The present disclosure provides an electronic device. As shown in is a schematic structural diagram of an exemplary embodiment of the electronic device in the present disclosure. The electronic device includes one or more processors a memory and one or more programs instructions stored in the memory and configured to be executed by the one or more processors to provide a caption searching method. The one or more programs are divided according to functions and include a searching module a voice textualization module and or an update module .

The searching module is configured to obtain characteristic information of a video file to be played and search for a caption for the video file to be played in a caption database according to the characteristic information so as to generate a search result. The voice textualization module is configured to perform according to the search result voice textualization on the video file to be played. The update module is configured to update the caption database according to a textualized caption generated by the voice textualization and use an updated caption in the caption database as a caption of the video file to be played.

The caption database includes a standard caption database and a voice textualization database. The standard caption database includes captions and hash codes of video files associated with the captions. The voice textualization database includes textualized captions and hash codes of video files associated with the textualized captions.

The searching module includes a first searching unit and a second searching unit . The first searching unit is configured to obtain the characteristic information of the video file to be played and search for a caption for the video file to be played in the standard caption database according to the characteristic information. Specifically the first searching unit returns if a hash code of the video file to be played exists in the standard caption database a caption associated with the hash code. The second searching unit is configured to search for a caption for the video file to be played in the voice textualization database if the caption of the video file to be played is not found in the standard caption database. Specifically the second searching unit returns if the hash code of the video file to be played exists in the voice textualization database a textualized caption associated with the hash code.

The voice textualization module includes an extraction unit and a conversion unit . The extraction unit is configured to extract audio information of the video file to be played. The conversion unit is configured to convert the audio information into the textualized caption.

The update module includes a first update unit a second update unit a first caption generation unit and a second caption generation unit . The first update unit is configured to update the voice textualization database according to the textualized caption generated by the voice textualization process. The second update unit is configured to compare the textualized caption generated by the voice textualization process with captions in the standard caption database and if a caption the same as the textualized caption generated by the voice textualization exists in the standard caption database update the standard caption database. Specifically the second update unit associates the video file corresponding to the textualized caption generated by the voice textualization process with the caption in the standard caption database. The first caption generation unit is configured to use an updated caption updated in the voice textualization database as the caption of the video file to be played. The second caption generation unit is configured to use an updated caption in the standard caption database as the caption of the video file to be played.

When the electronic device of the present disclosure is used first the standard caption database and the voice textualization database are created. Next the first searching unit of the searching module first queries a hash code of the video file to be played then searches for the hash code in the standard caption database and if the hash code of the video file to be played exists in the standard caption database returns a caption associated with the hash code to a user to complete the caption search. If the hash code of the video file to be played does not exist in the standard caption database the second searching unit of the searching module searches for in the voice textualization database the hash code of the video file to be played and if the hash code of the video file to be played exists in the voice textualization database returns a textualized caption associated with the hash code to the user to complete the caption search.

If the caption of the video file to be played is found in neither the standard caption database nor the voice textualization database the voice textualization module performs voice textualization on the video file to be played and the first update unit of the update module stores into the voice textualization database a textualized caption obtained by means of conversion for use in caption search thereby updating the voice textualization database. At this time the first caption generation unit may use an updated caption in the voice textualization database as the caption of the video file to be played.

Preferably the second update unit of the update module may compare the textualized caption generated by the voice textualization process with captions in the standard caption database and if a caption the same as the textualized caption generated by the voice textualization exists in the standard caption database the second update unit associates the caption with the video file corresponding to the textualized caption generated by the voice textualization process namely associates the caption with the hash code of the video file thereby updating the standard caption database which optimizes a matching hit rate of captions in the standard caption database. At this time the second caption generation unit may use an updated caption in the standard caption database as the caption of the video file to be played. Certainly the second update unit and the second caption generation unit here may be selected and set according to requirements of users.

The specific operating principle of the electronic device in the present disclosure is the same as or similar to that described in embodiments of a caption searching method below and for details refer to the detailed process of the preferred embodiment of the caption searching method below.

The electronic device according to this embodiment may be configured in a video player to search for a caption of a video file that is being played in the video player. Meanwhile the electronic device according to this embodiment may also be configured in a caption searching server that can provide users with a service of searching for a caption of a video file.

The present disclosure further provides a caption searching method. Referring to and is a flowchart of an exemplary embodiment of a caption searching method in the present disclosure. The caption searching method includes the following steps.

Step S includes obtaining characteristic information of a video file to be played and searching for a caption for the video file to be played in a caption database according to the characteristic information so as to generate a search result.

Step S includes performing according to the search result a voice textualization process on the video file to be played.

Step S includes updating the caption database according to a textualized caption generated by the voice textualization process and using an updated caption in the caption database as a caption of the video file to be played.

The caption searching method according to this preferred embodiment may conclude at step S. The voice textualization process includes for example extracting audio information of the video file to be played and converting the audio information into the textualized caption thereby textualizing the video file to be played.

In the caption searching method according to this exemplary embodiment voice textualization process is performed on a video file to be played whose caption cannot be found through matching and the caption database is updated according to a textualized caption obtained after the voice textualization process thereby ensuring caption matching and increasing the matching hit rate for caption search next time.

The detailed process of each step of the exemplary embodiment of the caption searching method in the present disclosure is described below in detail.

Before step S a standard caption database and a voice textualization database are created to form the caption database . The standard caption database is a database in a standard caption format and includes captions and hash codes of video files associated with the captions. The standard caption database may be created by manual input or standard captions on caption websites may be downloaded by using a caption web crawler and the standard caption database may be updated periodically by using the caption web crawler.

The voice textualization database is a database created based on textualized captions and includes textualized captions and hash codes of video files associated with the textualized captions. A textualized caption is a text formed by performing a voice recognition process on a video file and includes textual dialogues of the video file and corresponding timestamps. The voice textualization database may be small at the beginning but as the caption search proceeds the voice textualization database may be gradually expanded mainly by textualized captions of latest video files or textualized captions of some rare video files .

In step S first the first searching unit of the searching module obtains characteristic information of the video file to be played and searches for a caption for the video file to be played in the standard caption database according to the characteristic information. The characteristic information of the video file here refers to a characteristic value capable of identifying the video file for example a file name a file size a hash code of the entire file or part of the file or a combination thereof. The characteristic information is described as being a hash code of the video file in this embodiment. In this step the first searching unit of the searching module first queries a hash code of the video file to be played and then searches for the hash code in the standard caption database if the hash code of the video file to be played exists in the standard caption database the first searching unit returns a caption associated with the hash code to a user to complete the caption search or if the hash code of the video file to be played does not exist in the standard caption database the first searching unit determines that the standard caption database does not have the caption of the video file to be played.

If the caption of the video file to be played is not found in the standard caption database the second searching unit of the searching module searches for a caption for the video file to be played in the voice textualization database. In this step similarly the second searching unit searches for in the voice textualization database the hash code of the video file to be played if the hash code of the video file to be played exists in the voice textualization database the second searching unit returns a textualized caption associated with the hash code to the user to complete the caption search or if the hash code of the video file to be played does not exist in the voice textualization database the second searching unit determines that the voice textualization database does not have the caption of the video file to be played.

Then proceeding to step S and in step S if the caption of the video file to be played is found in neither the standard caption database nor the voice textualization database the voice textualization module performs a voice textualization process on the video file to be played. First the extraction unit of the voice textualization module extracts audio information of the video file to be played namely separates a voice signal in the video file to be played from video. No matter how many voices the video file to be played includes one main voice signal audio information can be output by using the voice recognition technology. Afterwards the conversion unit of the voice textualization module converts the audio information into a textualized caption namely converts the audio information into dialog texts and corresponding timestamps. The dialog texts may be in Chinese English or any other suitable language and the conversion should have a certain fault tolerance.

Then proceeding to step S and in step S the first update unit of the update module updates the voice textualization database according to the textualized caption generated by the voice textualization process and the first caption generation unit of the update module uses an updated caption in the voice textualization database as the caption of the video file to be played. The update of the voice textualization database here mainly includes storing into the voice textualization database the textualized caption generated by the voice textualization and a hash code of the video file associated with the textualized caption.

Furthermore in this step the second update unit of the update module may further compare the textualized caption generated by the voice textualization process with captions in the standard caption database and if a caption the same as the textualized caption generated by the voice textualization exists in the standard caption database the second update unit of the update module updates the standard caption database and the second caption generation unit of the update module uses an updated caption in the standard caption database as the caption of the video file to be played or if no caption the same as the textualized caption generated by the voice textualization exists in the standard caption database the first caption generation unit of the update module uses the updated caption in the voice textualization database as the caption of the video file to be played.

Because the standard caption database is a database in the standard caption format and captions in such database have high quality textualized captions in the voice textualization database may be associated with the captions in the standard caption database as much as possible in this step so that high quality captions in the standard caption database can be used directly for more video files.

Both a caption and a textualized caption include character strings dialogue texts and corresponding timestamps. Specifically during comparison a caption and a textualized caption whose total play times are approximately the same are selected to be compared character strings at n n is greater than or equal to 2 random time points for example at 5 minutes 10 minutes or 20 minutes of the textualized caption are selected to be compared with character strings at the corresponding time points of the caption the selection of time points here should allow a certain error tolerance for example the character string selected from the textualized caption is separately compared with 10 character strings before or after the time point in the caption and if each character string subject to comparison of the textualized caption has a corresponding character string matching therewith in the caption it is determined that a caption the same as the textualized caption generated by the voice textualization process exists in the standard caption database or otherwise it is determined that no caption the same as the textualized caption generated by the voice textualization exists in the standard caption database.

If a caption the same as the textualized caption generated by the voice textualization process exists in the standard caption database the second update unit associates the caption with the video file corresponding to the textualized caption generated by the voice textualization process namely associates the caption with a hash code of the video file and stores the hash code of the video file into the standard caption database thereby updating the standard caption database.

In this way the whole caption search process of the video file to be played and the corresponding update process of the caption database are completed.

It should be noted here that the step of comparing the textualized caption generated by the voice textualization process with a caption in the standard caption database and the step of updating the standard caption database in step S are intended to optimize the matching hit rate of captions in the standard caption database and the two exemplary steps may also be omitted according to requirements of users.

Meanwhile the order of the steps in this exemplary embodiment does not limit the protection scope of the present disclosure. For example for a latest video file the process may start from step S directly to update the voice textualization database without searching for a caption in the caption database . Therefore performing the above described steps of the present disclosure in any other order can also achieve the effect of optimizing the hit rate of caption matching and also falls within the protection scope of the present disclosure.

A person of ordinary skill in the art may understand that all or some of the processes in the method according to the foregoing embodiment may be implemented by a computer program instructing relevant hardware. The program may be stored in a computer readable storage medium. The program when being executed may include the process of the disclosed method. The storage medium may be a magnetic disk an optical disc a read only memory ROM a random access memory RAM or the like.

In the disclosed caption searching methods electronic devices and storage media of the present disclosure a search for a caption is based on audio information recognition which increases a hit rate and reduces an error rate of caption matching. Meanwhile a standard caption database and a voice textualization database are updated in time according to a textualized caption generated by voice textualization process which optimizes the matching hit rate of captions in the standard caption database and the voice textualization database.

To sum up although the present disclosure has been disclosed above through the exemplary embodiments these exemplary embodiments are not intended to limit the present disclosure. A person of ordinary skilled in the art can make various variations and modifications without departing from the spirit and scope of the present disclosure. Therefore the protection scope of the present disclosure is subject to the appended claims.

