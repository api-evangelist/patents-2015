---

title: Detecting malware based on reflection
abstract: According to one embodiment of the disclosure, a computerized method is described to detect a malicious object through its attempt to utilize reflection. The computerized method comprises receiving, by a network device, an object for analysis. Thereafter, the network device conducts a first analysis within a sandboxed environment. The first analysis determines whether the object is configured to utilize reflection. According to one embodiment, the first analysis involves analysis of the content of the object by a static analysis engine. Alternatively, or in addition to this analysis, the behavior of the object by an attempt to access a reflection API may determine that the object is utilizing reflection. Responsive to the network device determining that the object utilizes reflection, a second analysis is conducted to determine whether the object is malicious.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09594904&OS=09594904&RS=09594904
owner: FireEye, Inc.
number: 09594904
owner_city: Milpitas
owner_country: US
publication_date: 20150423
---
Embodiments of the disclosure relate to the field of cyber security. More specifically embodiments of the disclosure relate to a system and method for detecting malware utilizing reflection for obfuscation.

Malicious software generally referred to as malware has become a pervasive problem for corporations and individual users alike as the functionality of most networked resources is based on downloaded software. The presence of malware within downloaded software may compromise a networked resource and the network itself. A number of techniques have been used by malware authors to obfuscate the analysis of their malware within downloaded content.

Currently security appliances are not equipped to consistently detect malware when obfuscated by malware authors using advanced programmatic techniques.

Various embodiments of the disclosure relate to a platform that is implemented with logic configured to i analyze the content of an object to determine whether the object is configured to issue a function call that invokes reflection operations and or ii detect whether the object when processed issues a function call that invokes reflection operations. The functionality of this logic is directed to uncover malware that relies on reflection for obfuscation purposes.

In general reflection represents an ability to examine or modify run time behaviors of a particular object. As an example in object oriented programming languages such as JAVA reflection allows for inspection of software components such as interfaces as well as source code constructions e.g. classes at run time without knowing the names of these software components at compile time.

As an illustrative embodiment such detection may involve a determination as to whether an object under analysis sometimes referred to as a suspect object is configured to or is attempting to access one or more application programming interfaces APIs that invoke reflection operations hereinafter reflection APIs . In response to determining that the object is configured to or is attempting to access a reflection API an analysis of one or more features of the object may be conducted to determine whether the object may be associated with a malicious attack. This analysis may involve probabilistic modeling analysis and or machine learning analysis as described below.

More specifically a threat detection platform TDP may be deployed to conduct a first analysis of a suspect object to determine whether the suspect object is configured to issue a function call that invokes reflection operations such as an API call to a reflection API for example. According to one embodiment of the disclosure a static analysis engine of the TDP may be configured to conduct an operation e.g. de obfuscation such as decompiling and or disassembling incoming data or even emulation to recover content from the suspect object. The content may be part of a high level representation of the object such as at least a portion of source code pseudo code or another human readable format. Thereafter the content may be analyzed in efforts to detect the presence of one or more function calls that during run time would invoke reflection operations.

For example the static analysis engine may be configured to decompile an object such as an executable file for example to recover source code. Thereafter the static analysis engine analyzes the source code to determine if the source code includes a function call that invokes reflection operations. For instance the source code may include an API call to a predetermined reflection API. Upon completion of a scan of the source code e.g. an examination without execution and detection of a function call that invokes reflection operations e.g. an API call to a reflection API the object is determined to be suspicious. The object is deemed suspicious when there exists at least a first level of likelihood of the object being associated with a malicious attack.

Additionally or in the alternative reflection can be identified by implementing logic within a dynamic analysis engine of the TDP. During virtual processing of the suspect object the logic may be adapted to set interception points e.g. hooks breakpoints etc. that are used to detect the presence of one or more function calls that invoke reflection operations e.g. particular API or system calls etc. . Hence in response to detecting a function call that invokes reflection operations logic within the dynamic analysis engine determines that the object is suspicious .

After the object is deemed suspicious in response to determining that the content associated with the object includes a function call or determining that the object issues a function call that invokes reflection operations the static analysis engine and or the dynamic analysis engine provides the suspicious object and or particular features associated with the suspicious object to the classification system for a more in depth analysis. Deployed within the security appliance or in a remotely located resource the classification system is configured to determine whether the suspicious object is malicious namely the system determines whether there is a prescribed likelihood higher than the first level of likelihood of the object being associated with a malicious attack. In general it is contemplated that the classification system may not be accessed unless the suspect object i is configured to issue a function call that invokes reflection operations or ii has issued a function call that invokes reflection operations.

According to one embodiment of the disclosure the classification system determines whether the object is malicious by applying a probabilistic model analysis to one or more features herein feature s extracted from the suspicious object after analysis by the static analysis engine and or the dynamic analysis engine. These feature s may include but are not limited or restricted to metadata e.g. function names and or object size parameters passed or to be passed with an intended function call and or other information potentially indicative of malware such as suspicious data strings from content of the object if the object has been successfully de obfuscated. It is contemplated that the feature s may further include information associated with behaviors that constitute abnormalities such as a reflection API downloading a file or executing a file.

The classification system may in addition or in the alternative apply a machine learning analysis to the feature s associated with the suspicious object. Machine learning analysis includes an operation of comparing the feature s either individually or as a pattern of two or more features to data that is known to be malicious or non malicious e.g. benign . This comparison determines whether the suspicious object is malicious or non malicious.

The results of the probabilistic model analysis the machine learning analysis or a combination of these analyses produces a result that identifies whether the suspicious object is deemed to be malicious or non malicious.

In the following description certain terminology is used to describe aspects of the invention. For example in certain situations both terms logic and engine are representative of hardware firmware and or software that is configured to perform one or more functions. As hardware logic or engine may include circuitry having data processing or storage functionality. Examples of such processing or storage circuitry may include but is not limited or restricted to a hardware processor one or more processor cores a programmable gate array a microcontroller an application specific integrated circuit receiver transmitter and or transceiver circuitry storage medium including semiconductor memory or a drive or combinatorial logic or combinations of one or more of the above components.

Logic or engine may be in the form of one or more software modules such as executable code in the form of an executable application an application programming interface API a subroutine a function a procedure an applet a servlet a routine source code object code a shared library or dynamic link library dll or one or more instructions. These software modules may be stored in any type of a suitable non transitory storage medium or transitory storage medium e.g. electrical optical acoustical or other form of propagated signals such as carrier waves infrared signals or digital signals . Examples of a non transitory storage medium may include but are not limited or restricted to a programmable circuit non persistent storage such as volatile memory e.g. any type of random access memory RAM persistent storage such as non volatile memory e.g. read only memory ROM power backed RAM flash memory phase change memory etc. a solid state drive hard disk drive an optical disc drive or a portable memory device and or a semiconductor memory. As firmware the executable code is stored in persistent storage.

The term object generally refers to a collection of data whether in transit e.g. over a network or at rest e.g. stored often having a logical structure or organization that enables it to be classified for purposes of analysis. For instance the object may be a file e.g. Portable Document Format PDF document or Microsoft Word or other word processing document or HyperText Markup Language HTML based web page or the like. During analysis for example the object may exhibit or a program processing the object may exhibit one or more behaviors that are systematic of malicious activity and provide evidence that the object may be classified as malicious. One of these behaviors may include issuance of a function call that invokes one or more reflection operations.

One example of a function call that invokes reflection operations is an API call to access a reflection API e.g. an API call to Class.forName X that causes the class named X namely a programming construct with particular function to be dynamically loaded at run time . Another example of a function call that invokes reflection operations may be a system call normally based on an API call where the called system function invokes reflection operations.

A platform generally refers to an electronic device with connectivity to an external data source e.g. network other electronic device etc. that typically includes a housing that protects and sometimes encases circuitry with data processing and or data storage. Examples of a platform may include a server a dedicated security appliance or an endpoint device which may include but is not limited or restricted to a stationary or portable computer including a desktop computer laptop netbook or tablet a smartphone a video game console or wearable technology e.g. smart watch etc. .

The term transmission medium is a physical or logical communication path with an endpoint device. For instance the communication path may include wired and or wireless segments. Examples of wired and or wireless segments include electrical wiring optical fiber cable bus trace or a wireless channel using infrared radio frequency RF or any other wired wireless signaling mechanism.

The term computerized generally represents that any corresponding operations are conducted by hardware in combination with software and or firmware.

Lastly the terms or and and or as used herein are to be interpreted as inclusive or meaning any one or any combination. Therefore A B or C or A B and or C mean any of the following A B C A and B A and C B and C A B and C. An exception to this definition will occur only when a combination of elements functions or operations are in some way inherently mutually exclusive.

As this invention is susceptible to embodiments of many different forms it is intended that the present disclosure is to be considered as an example of the principles of the invention and is not intended to limit the invention to the specific embodiments shown and described.

Referring to an exemplary block diagram of a network deploying a plurality of threat detection platforms TDP N 1 where N 3 for this embodiment communicatively coupled to a management system via a network is shown. In general the management system is adapted to manage each TDP . For instance the management system may be configured to perform content updates within a processing engine operating as part of a communication interface a static analysis engine a dynamic analysis engine a classification engine and or a reporting engine with an optional user interface capability. For example the content update may include a software or firmware update that alters the functionality of the TDP . Alternatively the content update may include security content such as signatures or rules changes e.g. add delete modify signatures rules or parameters that are utilized by the rules etc. . The static analysis engine and or the dynamic analysis engine may use the signatures and or rules to detect whether reflection operations are invoked and whether the reflection operations are directed to malicious activities.

As shown in a first threat detection platform TDP is an electronic device that is adapted to analyze information associated with incoming data e.g. network traffic propagating over a communication network input data from another type of transmission medium including a dedicated transmission medium etc. . As this illustrative embodiment the first TDP is communicatively coupled with the communication network via an interface where the communication network may include a public network such as the Internet a private network e.g. a local area network LAN wireless LAN etc. or a combination thereof. The interface operates as a data capturing device that intercepts or alternatively duplicates at least a portion of the data associated with an object which may include metadata. Alternatively although not shown the interface may be configured to receive files or other objects that are not provided over a network. For instance as an example the interface may be a data capturing device that automatically or on command accessing data stored in a storage system or another type of interface such as a port for receiving objects manually provided via a suitable dedicated communication link or from storage media such as portable flash drives.

In some embodiments although not shown interface may be contained within the first TDP . In other embodiments the interface can be integrated into an intermediary device in the communication path e.g. an optional firewall router switch or other networked electronic device or can be a standalone component such as an appropriate commercially available network tap.

For this illustrative embodiment however the interface may be configured to capture data associated with an incoming object for analysis and perhaps its corresponding metadata or generate metadata based on the captured data . The metadata may be used at least in part to determine protocols application types and other information that may be used by logic e.g. scheduler or a virtual machine monitor not shown within the first TDP to determine particular software profile s used for virtual machine VM configuration and or VM operation scheduling. For instance the software profile s may be used for selecting and or configuring one or more virtual machines VMs M 1 within a virtual analysis environment of the dynamic analysis engine . These software profile s may be directed to different software or different versions of the same software application extracted from software image s fetched from a storage device . Additionally the metadata may be used at least in part as the feature s that are evaluated by a classification system within the classification engine in determining whether the object under analysis is malicious or not.

As further shown in the first TDP includes communication interface static analysis engine scheduler storage device dynamic analysis engine classification engine and or reporting engine . Herein according to this embodiment of the disclosure the communication interface receives an object and converts that object into a format as need or appropriate on which scanning may be conducted by the static analysis engine see operation . This conversion may involve decompression of the object for example. It is contemplated that the communication interface may conduct decompilation disassembly or other de obfuscation activities on the object and or extraction of specific data associated with the object however according to this embodiment as described below the de obfuscation and data extraction activities may be handled by logic within the static analysis engine .

As shown in the static analysis engine comprises de obfuscation logic reflection API analysis logic and or feature extraction logic and their collective operations are illustrated as operation . The de obfuscation logic is configured to de obfuscate at least a portion of an incoming object received from the communication interface . As an example the de obfuscation logic may be configured to de obfuscate such as decompile and or disassemble at least a portion of the incoming object e.g. an executable to recover a high level representation of the object. The high level representation may be in the form of source code pseudo code or another high level language.

After de obfuscation the reflection API analysis logic may analyze content that is part of the high level representation of the object for the presence of one or more API calls to any reflection API. In response to determining that the suspect object includes content that at run time would issue an API call to one of the reflection APIs the feature extraction logic may extract feature s from the high level representation e.g. source code or pseudo code or another high level language such as called function names data associated with the size of the object information associated with one or more post infection behaviors or the like. According to this embodiment of the disclosure the extracted feature s may be provided as static analysis SA based results to the classification system of the classification engine for subsequent analysis.

It is contemplated that the static analysis engine may further include processing circuitry that is responsible for extracting and or generating metadata contained within or otherwise associated with incoming data from the communication interface e.g. network traffic downloaded data . This metadata may be subsequently used for configuring one or more VMs within a virtual analysis environment for conducting a dynamic analysis of the object associated with that metadata.

Referring still to the reflection API analysis logic of the static analysis engine analyzes content within the object which may be a portion of network traffic or downloaded data according to this embodiment of the disclosure. Such analysis may involve the performance of one or more checks on content associated with the object namely content that is part of the high level representation of the object without execution of the object. Examples of the checks may include signature checks which may involve a comparison of content that is part of the high level representation of the object to one or more pre stored signatures which may include one or more reflection API function names.

After scanning the content of the suspect object the reflection API analysis logic determines whether or not this object is suspicious based on whether content within the high level representation includes an API call to a reflection API. As a result the static analysis engine may pass this suspicious object to the dynamic analysis engine for more in depth analysis in a VM based analysis environment see operation . Additionally or in the alternative the reflection API analysis logic may signal the feature extraction logic to obtain one or more features associated with the suspect object and provide such feature s to the classification engine as part of SA based results see operation .

Additionally after analysis of the object has been completed the static analysis engine may provide some or all of the incoming object as the suspicious object to the dynamic analysis engine for in depth dynamic analysis by one or more VMs of the virtual analysis environment . For instance according to one embodiment of the disclosure a first VM may be adapted to process the suspicious object . Logic within the dynamic analysis engine e.g. reflection hooking logic within the first VM may be configured to monitor for certain types of behaviors exhibited by the suspicious object during processing within the first VM . One type of behavior may include the object invoking reflection operations through one or more API calls to a reflection API. Another type of behavior may include detection of a system call or where a virtualization layer include a hypervisor is employed in an embodiment a hyper call that invokes reflection operations where the system call or hyper call may be issued or triggered by the suspicious object at run time and may be based on an API call.

Herein according to one embodiment the first VM is configured to process the suspicious object . The reflection hooking logic may be used to set one or more hooks at one or more reflection APIs or equivalent operating system e.g. guest or host OS functions that may perform or invoke reflection operations where the hooks redirect the operational flow such as redirecting operations via a JUMP instruction to the classification system as described below see operation . Examples of these reflection APIs may include but are not limited or restricted to getClass API or Class.forName which are responsible for finding a class associated with the object.

Upon determining that the object is issuing function calls to access an API or OS function that invokes reflection operations the object feature extraction logic may be activated to extract one or more features e.g. arguments etc. from the function call s . Similarly these feature s may include a name of the function identified in the function call and or other data within the arguments of the function call issued or triggered by the object during processing within the first VM . The feature s may be stored in data store and are subsequently provided to or accessible by the classification system as part of VM based results .

Referring still to the scheduler may be adapted to configure one or more VMs based on metadata associated with the suspicious object in order to conduct run time processing of the suspicious object within the configured VMs . For instance the first VM and a second VM may be configured to run concurrently i.e. overlapping at least in part in time where each VM and being configured with a different software profile corresponding to software images stored within storage device . As an alternative embodiment the first VM may be configured to run plural processes concurrently or sequentially each process configured according to a software configuration that may be used by different electronic devices connected to a particular enterprise network e.g. endpoint device s or a prevalent type of software configuration e.g. a particular version of Windows OS and or a particular version of a web browser with a particular application plug in . It is contemplated that the VM configuration described above may be handled by logic other than the scheduler .

According to one embodiment of the disclosure the dynamic analysis engine may be adapted to execute one or more VMs that each simulate processing of the suspicious object within a run time environment. For instance dynamic analysis engine may include processing logic to provide anticipated signaling to the VM s . . . and or during virtual processing of the suspicious object and as such emulate a source of and or destination for communications with the suspicious object while processed within the VM s . . . and or . As an example the processing logic may be adapted to operate by providing simulated key inputs from a keyboard keypad or touch screen as requested by the suspicious object during run time.

Referring still to the static analysis engine may be adapted to provide SA based results to the classification system while the dynamic analysis engine may be adapted to provide the VM based results to the classification system see operations . According to one embodiment of the disclosure the SA based results may include information obtained by analyzing the incoming object that is potentially indicative of malware e.g. function names object size suspicious strings within the object . Similarly the VM based results may include information associated with the object as well as the function calls that invoke reflection operations e.g. function names or other argument data associated with the functions calls .

According to one embodiment of the disclosure the classification engine includes the classification system that is configured to receive the SA based results and or the VM based result associated with the object under analysis. Based at least partially on the SA based results and or VM based results the classification system evaluates the feature s within the SA based results and or VM based results to determine whether the suspicious object should be classified as malicious see operation .

For instance as an illustrative embodiment the SA based results include one or more features that are provided to probabilistic modeling logic . The probabilistic modeling logic is configured as a decision tree analysis scheme which receives one or more features as input either individually or as a pattern of two or more features and produces a result that may be used to identify whether the object is associated with a malicious attack.

According to one embodiment the result may identify a risk level that indicates a likelihood of the object being associated with a malicious attack. For instance the risk level may be identified in a variety of manners. For instance the risk level may be conveyed by a two state result that simply represents the object as malicious or non malicious. Another risk level may be conveyed through a tri state result high medium low to identify various probabilities of the object being associated with the malicious attack and obfuscated by reflection. Yet another risk level may be conveyed using scores that provide a greater granularity as to the likelihood of the object being associated with a malicious attack and obfuscated by reflection.

As an illustrative example the result may include an overall score that is formed by an aggregation of scores e.g. prescribed values for some or all of the features undergoing analysis by the probabilistic modeling logic . Herein the name of a function call directed to a particular reflection API that is detected within the de obfuscated content of the object may be assigned a first score. Similarly the name of a system function that invokes reflection operations and is extracted from a system call detected during virtual processing of the object may be assigned a second score different than the first score. Again the size of the object may be assigned a third score which is different than the first and second scores. The aggregation of these scores may be used to compute an overall score which represents the likelihood of the object being malware that is obfuscated through reflection.

As an illustrative example suppose that the object under static analysis is a file having a filename entitled 2014 IRS TAX INQUIRY with a size of 15 megabytes and including content that represents a function call to a reflection API e.g. getClass . According to this probabilistic modeling analysis an aggregate value e.g. a score greater than or equal to 8 out of a maximum 10 denotes that the object is malicious. The probabilistic model logic may include a portion of the decision tree analysis that includes the following 

Based at least in part on the one or more features associated with the object a determination may be made by the probabilistic modeling logic of the classification system as to whether or not the object that invokes reflection is associated with a malicious attack. Upon determining that the object is associated with a malicious attack the classification system may provide information to identify the malicious object including the resultant score and or one or more of the features provided as part of the SA based results to the reporting engine .

As another illustrative embodiment if provided in lieu of or in addition to SA based results the VM based results may include one or more features that are provided to probabilistic modeling logic based on monitored behaviors during processing of the object within the first VM . According to this illustrative example the probabilistic model logic assigns a risk level to the object under dynamic analysis. For a file having a filename 2014 IRS TAX INQUIRY with a size of 15 megabytes and including content e.g. a code that initiates a function call to access the reflection API such as getClass the probabilistic modeling logic may assign a risk level e.g. aggregate score of at least 8 out of a maximum 10 that denotes that the object is malicious. For this example the probabilistic model logic may include a portion of the decision tree analysis that includes the following 

For this illustrated embodiment based at least in part on the feature s associated with the object a determination may be made by the probabilistic modeling logic of the classification engine as to whether or not the object is associated with a malicious attack. Upon determining that the object is associated with a malicious attack when Score 8 the classification engine may provide information to identify the malicious object including one or more of the features or the resultant score to the reporting engine .

As shown in the reporting engine is configured to receive information from the classification engine and generate alerts especially in response to the suspicious object being now classified as malicious see operation . The alerts may include various types of messages which may include text messages and or email messages video or audio stream or other types of information over a wired or wireless communication path. The reporting engine features an optional user interface e.g. touch pad keyed inputs etc. for customization as to the reporting configuration.

In addition or in the alternative to probabilistic modeling logic the classification engine may comprise machine learning logic . Machine learning logic performs an analysis of the one or more features that are part of the SA based results and or the one or more features that are part of the VM based results . These features are compared either individually or as a pattern of two or more features to data known to be malicious or non malicious e.g. benign . The comparison is conducted to determine whether the object under analysis is malicious. Upon determining that the object is malicious i.e. associated with a malicious attack the classification engine may provide information to identify the malicious object such as one or more of the features from the SA based results and or the VM based result and or resultant score to the reporting engine .

Referring now to according to another embodiment of the disclosure the static analysis engine and or dynamic analysis engine located within the first TDP may determine that the object is suspicious when the object is configured to invoke or invokes reflection operations as described above see operations . However located remotely from the first TDP such as part of a cloud computing service or within a different enterprise network for example a classification system is configured to receive an identifier for the object along with i the object and or one or more features ii object and or one or more features or any combination thereof see operations and . The identifier may include any value that is considered to be unique such as a hash result e.g. MD5 hash value for example.

Including the probabilistic modeling logic and or machine learning logic the classification system determines whether the object is malicious and returns a result of its probabilistic analysis or machine learning analysis described above along with the identifier to the classification engine see operation .

Upon determining that the object or is associated with a malicious attack the classification engine may provide information to identify the malicious object including one or more of the features or and or the result e.g. resultant score value to the reporting engine . Upon determining that the object or is benign the classification engine may provide information to identify the object and that the object is benign including the result to the reporting engine . In lieu of reporting benign objects the classification engine may merely report malicious objects to the reporting engine see operation .

As still shown in the reporting engine is configured to receive information from the classification engine and generate alerts especially in response to the suspicious objects that have now been classified as malicious see operation .

Referring now to an exemplary embodiment of a logical representation of the first TDP is shown. The first TDP includes a housing which is made entirely or partially of a rigid material e.g. hardened plastic metal glass composite or any combination thereof that protect circuitry within the housing namely one or more processors that are coupled to communication interface logic that is part of communication interface of via a first transmission medium . Communication interface logic enables communications with other TDP and management system of . According to one embodiment of the disclosure communication interface logic may be implemented as a physical interface including one or more ports for wired connectors. Additionally or in the alternative communication interface logic may be implemented with one or more radio units for supporting wireless communications with other electronic devices.

Processor s is further coupled to persistent storage via a second transmission medium . According to one embodiment of the disclosure persistent storage may include a static analysis engine including de obfuscation logic reflection API analysis logic and feature extraction logic b the dynamic analysis engine that includes the processing logic and the virtual analysis environment that includes VM s where at least some of the VM s include reflection hooking logic and object feature extraction logic c classification engine d reporting engine and or e one or more data stores that may be utilized by static analysis engine dynamic analysis engine classification engine and or reporting engine . One or more of these engines or logic units could be implemented externally from the first TDP .

Collective logic within the static analysis engine may be configured to de obfuscate e.g. decompile or disassemble an object and obtain a higher level representation of the object than machine code such as source code for example. Thereafter the content of the source code is analyzed to determine if reflection operations would be invoked by the object when processed. After detection that the object would invoke reflection operations the static analysis engine provides the object under analysis or particular feature s associated with the object to the classification system for more in depth analysis.

Additionally or in the alternative reflection can be identified by detecting function calls that invoke reflection operations where the function calls may be directed to reflection APIs and or system functions that invoke reflection operations. Hence during processing of the object within the VM and detecting at least one of the function calls that invoke reflection operations the dynamic analysis engine is able to determine that the object is suspicious.

Hereafter the classification engine is configured to determine whether an object which is previously determined as suspicious is further determined to be malicious or non malicious. The object is deemed suspicious based on a determination of the presence of API calls within content of the object or a detection during virtual processing of the object of the issuance of function calls e.g. API calls system calls etc. that invokes reflection operations. The classification engine may conduct probabilistic model analysis and or machine learning analysis on certain feature s extracted from the object after a prior analysis uncovered that the object is invoking reflection operations. The feature s may include but are not limited or restricted to function names file sizes and or other information potentially indicative of malware such as extract suspicious strings from the contents of the object if the object has been successfully decompiled.

When implemented as hardware circuitry the static analysis engine may be configured to be communicatively coupled to communication interface logic and or the classification engine . The dynamic analysis engine may further be communicatively coupled to the communication interface logic the static analysis engine and or the classification engine . The classification engine is communicatively coupled to the reporting engine .

Referring to a general exemplary flowchart is shown that illustrates operations conducted by one or more electronic devices such as a TDP or another type of platform for determining whether a suspect object which invokes reflection operations to obfuscate content or operability is malicious. Upon receiving an object an analysis is conducted to determine whether the suspect object is configured to access a reflection API block . This may be determined by analyzing the de obfuscated content associated with the object e.g. the decompiled source code for the presence of an API call that at run time would invoke a reflection API. If the object includes such an API call the object is deemed suspicious.

Additionally or in the alternative the behavior of the object may be monitored at run time to detect whether the object is invoking reflection operations block . For instance this may be accomplished by setting interception points e.g. hooks breakpoints with subsequent activity after code execution halts etc. to detect one or more function calls resulting from processing the object within the virtual machine. One type of function call being monitored includes an API call directed to reflection API. Additionally or in the alternative another function call being monitored includes a system call that invokes reflection operations where the system call may be based on an API call issued by the object.

In response to detecting that the object invokes reflection operations content from the suspect object is extracted for further analysis block . The content may include one or more features of the object under analysis suspicious string data or the like.

A classification analysis is conducted on the extracted content to determine the likelihood of the object which invokes reflection operations is associated with a malicious attack block . According to one embodiment of the disclosure the classification analysis may involve probabilistic model analysis and or machine learning analysis to produce a result e.g. a resultant score that may be used to classify whether the object is malicious or not as previously described. If the result is greater than a prescribed threshold the suspect object is determined to be malicious blocks and . Otherwise the suspect object is determined to be non malicious blocks and .

Referring now to a first exemplary flowchart is shown that illustrates operations conducted by the static analysis engine and the classification system collectively deployed within the TDP and or external resources e.g. cloud services . Upon receiving a suspect object an analysis is conducted to determine whether the object is configured to invoke reflection operations. This analysis may involve de obfuscating by decompiling and or disassembling or by emulation at least part of the object to recover a high level representation e.g. source code or pseudo code or another high level language and thereafter conducting an analysis of the content that is part of the high level representation e.g. at least a portion of the source code or pseudo code to determine whether the object would invoke reflection at run time blocks and . The object is considered to invoke reflection upon determining by static analysis of the source code or pseudo code or another high level language that the code includes an API call to a reflection API.

If the de obfuscated content of the suspect object fails to include an API call to a reflection API which is considered to be one of the triggering events for subsequent analysis the analysis ends as the suspect object may be further analyzed through other malware detection schemes. However in response to detecting that the suspect object is configured to access a reflection API for example content from the suspect object is extracted for further analysis blocks and . The content may include one or more features of the suspect object e.g. name of the reflection API size of the suspect object suspicious string data or the like . Optionally the static analysis engine may determine if the de obfuscated e.g. decompiled high level representation e.g. source code pseudo code or another high level language is further obfuscated and if so further operations are conducted to further de obfuscate the high level representation blocks and .

A classification analysis is conducted on the extracted content to determine the likelihood of the object being associated with a malicious attack block . According to one embodiment of the disclosure the classification analysis may involve probabilistic model analysis and or machine learning analysis to produce a result that represents a likelihood of the object which invokes reflection operations is associated with a malicious attack as previously described. If the result is greater than a prescribed threshold the suspect object is determined to be malicious blocks and . Otherwise the suspect object is determined to be non malicious blocks and .

Referring to a second exemplary flowchart is shown that illustrates operations conducted by the dynamic analysis engine and the classification system collectively deployed within the TDP and or external resources e.g. cloud services . Upon processing the suspect object within a configured virtual machine based on one or more behaviors of the object during processing within the virtual machine a determination is made whether the object is invoking reflection operations blocks and .

In response to detecting that the object is invoking reflection operations such as the object is attempting to access the reflection API for example content from the object under analysis is extracted for further analysis blocks and . The content may include one or more features of the object suspicious string data or the like.

A classification analysis is conducted on the extracted content to determine the likelihood of the object being associated with a malicious attack block . According to one embodiment of the disclosure the classification analysis may involve probabilistic model analysis and or machine learning analysis to produce a resultant score as previously described. If the resultant score is greater than a prescribed threshold the suspect object is determined to be malicious blocks and . Otherwise the suspect object is determined to be non malicious blocks and .

Referring now to an exemplary flowchart of the operations of the classification analysis described in as performed by the classification system of is shown. Herein the classification system performs a first classification analysis on the content of the object to determine a first classification result block . According to one embodiment of the disclosure the first classification analysis includes a probabilistic model analysis on contents of the object namely an analysis on features and other data associated with the object in accordance with a decision tree analysis as described above. Based on these features provided for analysis a result e.g. resultant score is produced which represents the likelihood of the object under analysis being associated with a malicious attack. According to another embodiment of the disclosure the first classification analysis may feature a machine learning analysis on content of the object namely comparing content associated with the object to content associated with known malware or known benign data. Based on these comparisons a result e.g. resultant score is produced which represents a likelihood that the object is associated with a malicious attack.

Next a determination is made whether additional classification analysis is to be performed block . If so the classification system performs a second classification analysis on the content of the object to determine a second classification result block . Where the first classification analysis is directed to a probabilistic model analysis of content associated with the object the second classification analysis may feature a more detailed probabilistic model analysis or a machine learning analysis. Similarly where the first classification analysis includes a machine learning analysis the second classification analysis may feature a more detailed machine learning analysis or a probabilistic model analysis.

In the foregoing description the invention is described with reference to specific exemplary embodiments thereof. For instance some or all of the functionality of the static analysis engine the dynamic analysis engine and the classification engine of may be implemented within another type of network device such as an endpoint device. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims.

