---

title: Beam tracing
abstract: An apparatus, computer readable medium, and method are disclosed for performing an intersection query between a query beam and a target bounding volume. The target bounding volume may comprise an axis-aligned bounding box (AABB) associated with a bounding volume hierarchy (BVH) tree. An intersection query comprising beam information associated with the query beam and slab boundary information for a first dimension of a target bounding volume is received. Intersection parameter values are calculated for the first dimension based on the beam information and the slab boundary information and a slab intersection case is determined for the first dimension based on the beam information. A parametric variable range for the first dimension is assigned based on the slab intersection case and the intersection parameter values and it is determined whether the query beam intersects the target bounding volume based on at least the parametric variable range for the first dimension.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09569559&OS=09569559&RS=09569559
owner: NVIDIA Corporation
number: 09569559
owner_city: Santa Clara
owner_country: US
publication_date: 20150318
---
This application claims the benefit of U.S. Provisional Application No. 62 046 093 titled Bounding Volume Hierarchy Representation and Traversal filed Sep. 4 2014 the entire contents of which is incorporated herein by reference.

The present invention relates to data structure queries and more particularly to beam tracing in bounding volume hierarchy data structures.

Computer graphics uses a variety of methods to generate two dimensional representations of a three dimensional scene. For example a three dimensional scene represented as a plurality of geometric primitives e.g. points lines triangles quads meshes etc. may be rasterized to project the geometric primitives to a projection plane and then shaded to calculate a color for one or more pixels of the projection plane based on the rasterization. Alternatively another technique for generating two dimensional representations of the three dimensional scenes is to perform ray tracing. As is known in the art ray tracing is a technique that includes the operation of sending out rays from a particular viewpoint and intersecting the rays with the geometry of the scene. When an intersection is detected lighting and shading operations may be performed to generate a color value for a pixel of the projection plane intersected by the ray. Additionally other rays may be generated based on the intersected primitives that contribute to the color of the intersected pixel or other pixels.

Because the number of geometric primitives in a scene may be quite large e.g. on the order of millions of triangles etc. and the number of rays generated to test for intersection against the primitives is also quite large e.g. on the order of millions to billions of rays intersection test efficiency typically defines overall rendering efficiency. Each test is typically performed as a query between a test object such as a ray or a beam and a target object such as a triangle.

In massively parallel architectures query efficiency can substantially determine overall system performance and inefficient query techniques may lead directly to degraded performance. Thus there is a need for addressing these issues and or other issues associated with the prior art.

An apparatus computer readable medium and method are disclosed for performing an intersection query between a query beam and a target bounding volume. An intersection query comprising beam information associated with the query beam and slab boundary information for a first dimension of a target bounding volume is received. Intersection parameter values are calculated for the first dimension based on the beam information and the slab boundary information and a slab intersection case is determined for the first dimension based on the beam information. A parametric variable range for the first dimension is assigned based on the slab intersection case and the intersection parameter values and it is determined whether the query beam intersects the target bounding volume based on at least the parametric variable range for the first dimension.

The apparatus may comprise circuitry within a processing unit such as a parallel processing unit which may further include circuitry to implement one or more tree traversal units that may be configured to generate the intersection query. Other embodiments include software hardware and systems configured to perform method steps for performing the intersection query.

Rendering techniques based on ray tracing may organize three dimensional 3D objects such as triangles occupying a 3D space using a bounding volume hierarchy BVH a data structure designed to efficiently encode spatial relationships among 3D objects. Each 3D object within the BVH may be represented as a bounding volume such as an axis aligned bounding box AABB defined by a pair of bounding planes in each of three dimensions. Rendering a two dimensional image that depicts a particular scene defined by the 3D objects and a particular view point involves ray tracing each sample e.g. pixel or sub pixel of an image plane associated with the view point and testing whether a given ray intersects with one or more of the bounding volumes corresponding to the 3D objects. An intersection with a bounding volume indicates there may be a true intersection with an associated 3D object and additional intersection analysis may be needed to establish a true intersection. A non intersection with a bounding volume definitively indicates there is no intersection with an associated 3D object. A positive test for an intersection between a ray and a bounding volume indicates that there may be a true intersection the determination of which is beyond the scope of the present disclosure but may be accomplished using any technically feasible technique.

Testing for an intersection between a ray and a target bounding volume may be performed using a Cartesian coordinate system whereby the ray is specified as a set of coordinate values and bounding planes of the bounding volume are also specified as a set of coordinate values providing a consistent comparison space over all three dimensions in a 3D space. Testing may be performed as a query where a given query ray is tested against bounding volumes within the BVH. An individual query may comprise testing whether the parametric variable associated with the query ray is within an appropriate range to fall between bounding planes for the x dimension y dimension and z dimension to intersect the bounding volume.

A beam intersection test is particularly useful in ray tracing and essentially tests whether a first bounding volume intersects a second bounding volume. A beam may be used as a conservative bounding volume for an arbitrary set of rays so that if any of the individual rays intersect a given 3D object the beam is also guaranteed to intersect the 3D object. The specification of the beam may comprise two rays and each of the two rays may be specified to have an origin and a direction. As with testing a query ray for intersections the query beam may be tested for intersections against bounding volumes within the BVH. A technique for performing an individual query of a query beam against a target bounding volume is discussed below.

Method begins at step where the intersection test engine receives an intersection query comprising beam information associated with a query beam q. In one embodiment the query beam comprises a first query ray and a second query ray and the beam information comprises a first query origin q.oA and a first query direction q.dA associated with the first query ray and a second query origin q.oB and a second query direction q.dB associated with the second query ray. Each query origin and each query direction may include a component in x a component in y and a component in z. For example the first query origin q.oA may include a component in x q.oA.x a component in y q.oA.y and a component in z q.oA.z and the second query origin q.oB may include a component in x q.oB.x a component in y q.oB.y and a component in z q.oB.z .

In one embodiment the beam information comprises a first AABB AABB0 and a second AABB AABB1 where AABB0 is associated with a particular value e.g. 0.0 for a parametric variable and AABB1 is associated with another value e.g. 1.0 for the parametric variable. Each AABB may be described according to x y and z coordinates at two diagonally opposite corners and a minimum and maximum coordinate may be determined for each dimension within a 3D space. For example a maximum x coordinate aabb0.xmax may represent a maximum x coordinate for all corners associated with AABB0. Similarly AABB0 may include a maximum y coordinate aabb0.ymax a maximum z coordinate aabb0.zmax a minimum x coordinate aabb0.xmin a minimum y coordinate aabb0.ymin and a minimum z coordinate aabb0.zmin . AABB1 may similarly include minimum and maximum values for each dimension.

Furthermore the first query origin q.oA may correspond to a maximum corner of AABB0 q.oA.x aabb0.xmax q.oA.y aabb0.ymax q.oA.z aabb0.zmax and the second query origin q.oB may correspond to a minimum corner of AABB0 q.oB.x aabb0.xmin q.oB.y aabb0.ymin q.oB.z aabb0.zmin . Similarly a direction for each query ray q.dA and q.dB may be determined as well as an inverse direction for each query ray q.idA and q.idB based on corresponding corners of AABB0 and AABB1. An inverse direction may be calculated as a reciprocal for each dimension e.g. component of a direction. A direction of zero may be treated as a special case and assigned an inverse direction of infinity. At this point the first query ray and the second query ray associated with the query beam are specified according to the parametric variable.

The beam information may also include a parametric variable range comprising a minimum value q.tmin and a maximum value q.tmax . The minimum and maximum values may be useful for defining the extent of the beam so that it may not necessarily extend all the way to AABB0 q.tmin 0 or that it may extend beyond AABB1 q.tmax 1 or not all the way to AABB1 q.tmax

In one embodiment certain beam configuration requirements may be satisfied in conjunction with execution of method wherein a given beam configuration is considered valid if the beam configuration requirements are satisfied. The beam configuration requirements may include without limitation q.tmin 0 q.tmax q.tmin q.oA.x q.oB.x q.dA.x q.dB.x and so on. In such an embodiment executing method in accordance with the beam configuration requirements may provide certain practical benefits such as reduced latency power and or area.

At step the intersection test engine receives slab boundary information for a first dimension e.g. an x dimension of a target bounding volume. In one embodiment the target bounding volume may comprise an AABB stored within a BVH and the slab boundary information comprises a minimum position of the target bounding volume along the first dimension aabb.xmin and a maximum position of the target bounding volume along the first dimension aabb.xmax .

In certain embodiments the slab boundary information further comprises a minimum position of the target bounding volume along a second dimension aabb.xmin and a maximum position of the target bounding volume along the second dimension aabb.ymax . The slab boundary information may further comprise a minimum position of the target bounding volume along a third dimension aabb.zmin and a maximum position of the target bounding volume along the third dimension aabb.zmax .

At step the intersection test engine calculates intersection parameter values for the first dimension based on the beam information and the slab boundary information. The value of an individual intersection parameter value may be calculated according to an intersection between a query ray and the target bounding volume within an associated dimension. For example an intersection by the first query ray at a minimum value along the first dimension is referred to herein as intersection parameter value Amin. Similarly an intersection at a maximum value is referred to herein as intersection parameter value Amax. Minimum and maximum intersection parameter values associated with the second query ray are referred to herein as Bmin and Bmax respectively. In one embodiment the intersection parameter values include one or more of Amin Amax Bmin and Bmax. In one embodiment the intersection test engine further calculates intersection parameter values for each dimension within a 3D space. For example the intersection parameter values may include a minimum and maximum value for each of x y and z dimensions.

At step the intersection test engine determines a slab intersection case for the first dimension based on the beam information and the intersection parameter values. In one embodiment determining the slab intersection case comprises comparing the direction of the first query ray in the first dimension to zero and comparing the direction of the second query ray in the first dimension to zero. Each comparison may yield a greater than less than or equal to relationship. In one embodiment the intersection engine further determines a slab intersection case for the second dimension and a slab intersection case for the third dimension. In such an embodiment each dimension of a 3D space may have an independent and distinct intersection case.

At step the intersection test engine assigns a parametric variable range for the first dimension based on the slab intersection case. In one embodiment the parametric variable range for the first dimension comprises a minimum value parametric variable x.tmin and a maximum value parametric variable x.tmax . The parametric variable range may be assigned according to at least one intersection parameter value. In one embodiment the intersection engine further assigns a parametric variable range for the second dimension and a parametric variable range for the third dimension. In such an embodiment each dimension of a 3D space may have an independent and distinct parametric variable range.

At step the intersection test engine determines whether the query beam intersects the target bounding volume based on at least the parametric variable range for the first dimension. In one embodiment for an intersection to occur between a query beam and a target bounding volume there must be at least one value of the parametric variable for which the beam and the target bounding volume overlap in each of the dimensions of the 3D space. In other words there must be at least one t value within the parametric variable range of the beam q.tmin q.tmax that is included in the parametric variable ranges associated with each of the dimensions e.g. x.tmin x.tmax . Such t values can be found by taking the max of mins and min of maxes as illustrated below in Table 1. Upon completing step method terminates. While the method is described in the context of an inverse direction the method may also be implemented using any direction representation including a direct representation and an inverse direction representation. Any representation of direction including inverse direction may be referred to herein generically as a direction vector whereby the direction vector may include one or more values.

More illustrative information will now be set forth regarding various optional architectures and features with which the foregoing framework may or may not be implemented per the desires of the user. It should be strongly noted that the following information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of the following features may be optionally incorporated with or without the exclusion of other features described.

The rectangular bounding volume is defined by a pair of infinite planes at minimum and maximum values in each dimension. In the x dimension the rectangular bounding volume is defined by a minimum value xmin and a maximum value xmax of x. In the y dimension the rectangular bounding volume is defined by a minimum value ymin and a maximum value ymax of y. In the z dimension the rectangular bounding volume is defined by a minimum value zmin and a maximum value zmax of z.

Each pair of minimum and maximum values for a given dimension defines a slab for the dimension. For example xmin and xmax define an x slab in the x dimension ymin and ymax define a y slab and zmin and zmax define a z slab. For an intersection test between the ray and the rectangular bounding volume to be true the ray must be located between slabs for all dimensions simultaneously for a given parametric variable value. As shown the ray intersects the x slab at t the y slab at t and the z slab at t. The ray exits the z slab when the parametric variable is at t. Therefore the ray intersection test for ray intersecting the bounding volume is true for t t t where t is the parametric variable.

As shown a maximum origin q.oA is defined by a maximum corner of AABB at t 0.0 and a minimum origin q.oB is defined by a minimum corner of AABB also at t 0.0. Similarly a maximum direction q.dA is defined as a vector from the maximum origin q.oA to the maximum corner of AABB at t 1.0 and a minimum direction q.dB is defined as a vector from the minimum origin q.oB to the minimum corner of AABB at t 1.0. Referring to step of method the maximum origin q.oA may be positioned at q.oA.x q.oA.y q.oA.z and the minimum origin q.oB may be positioned at q.oB.x q.oB.y q.oB.z . A first query ray follows a first direction q.dA while a second query ray follows second direction q.dB .

An intersection query between a query beam and an AABB may be performed according to the pseudo code of Table 1. In one embodiment a beam query function intersect beam aabb is implemented by the intersection test engine. As shown the function intersect beam aabb is configured to return a value of TRUE if a query beam q intersects the given AABB which may be associated in one embodiment with a BVH node. The function intersect beam aabb receives parameters for query beam object q that comprise a first origin q.oA a second origin q.oB a first direction q.dA and a first inverse direction q.idA a second direction q.dB and a second inverse direction q.idB and a parametric range minimum and maximum q.tmin q.tmax . The inverse direction involves computing a reciprocal of the direction per dimension which may be computed once and used for a plurality of intersection queries.

As shown the function bslab is called to calculate and return a minimum value and maximum value for the parametric variable according to a potential intersection for each dimension. An overall minimum value parametric variable tmin is selected as the maximum value from a first set of values that includes a minimum value of the parametric variable range for the intersection query q.tmin and minimum values of the parametric variable for at least one dimension xtmin ytmin ztmin . An overall maximum value parametric variable tmax is selected as the minimum value from a second set of values that includes a maximum value of the parametric variable range for the intersection query q.tmax and maximum values of the parametric variable for at least one dimension xtmax ytmax ztmax . The overall minimum and maximum values tmin and tmax define an overall range of the parametric variable where an intersection between the beam and the AABB occurs.

If the overall minimum value parametric variable is less than or equal to the overall maximum value parametric variable tmin

The function bslab of Table 1 may be advantageously performed in accordance with the pseudo code of Table 2. As shown in Table 2 the function bslab receives beam information for the query beam as parameters comprising the first query origin q.oA the first query inverse direction q.idA and the first query direction q.dA associated with the first query ray and the second query origin q.oB the second query inverse direction q.idB and the second query direction q.dB associated with the second query ray. In one embodiment receiving this beam information corresponds to step of the method . The function bslab also receives slab boundary information comprising parameters MIN and MAX for a given dimension. In one embodiment receiving the slab boundary information corresponds to step of the method .

Intersection parameter values comprising one or more of Amin Amax Bmin Bmax may be calculated for one or more slab intersection cases based on the beam information and the slab boundary information. In one embodiment calculating the intersection parameter values corresponds to step of the method . Determining a slab intersection case is performed by the if else selection structure which performs a series of comparison operations between ray direction information and zero. In one embodiment this determination process corresponds to step of the method . A parametric variable range tmin tmax is assigned based on the slab intersection case. This is shown in the pseudo code as assignment operations to tmin and tmax based on a slab intersection case. In one embodiment assigning the parametric variable range corresponds to step of method .

In one embodiment as illustrated by the pseudo code of Table 2 the beam query may be constrained as follows. The size of AABB0 is required to be non negative along each dimension oA oB AABB1 is required to be at least of equal the size to AABB0 dA dB and the minimum parametric value associated with the beam is required to be non negative q.tmin 0 . In case the beam specification fails to conform with these requirements the implementation may report an error as shown in Table 2. Imposing such requirements may reduce the number of different cases that need to be considered thereby simplifying the implementation and or providing other benefits.

The pseudo code of Table 2 illustrates an exemplary control flow that is sequential in nature. The control flow includes first determining the slab intersection case and then calculating one set of intersection parameter values based on the slab intersection case and subsequently assigning the parametric variable range based on the slab intersection case and the one set of intersection parameter values. While this sequential flow is illustrative certain embodiments may implement a concurrent calculation of two or more sets of intersection parameter values such an implementation may elect one of the two or more sets of intersection parameter values for assigning the parametric variable range. For example such embodiments may speculatively perform the calculation of the two or more sets of intersection parameter values prior to a specific slab intersection case determination while concurrently performing operations associated with determining the slab intersection case. Furthermore intersection parameter values may be calculated for each of three dimensions concurrently. Assigning the parametric variable range may then be performed as a selection process. Persons skilled in the art will understand that structuring certain operations defined by the pseudo code of Table 2 for concurrent execution produces equivalent assignment values for the parametric variable range as sequential execution. Furthermore structuring the operations for concurrent execution may have certain implementation advantages for pipelined hardware architectures. For example a concurrent execution implementation may provide for lower latency than a sequential implementation.

The function bslab of Table 2 may advantageously perform an assignment of a parametric variable range used to determine whether the query beam intersects the target bounding volume using only two multiplication operations allowing the function beam of Table 1 to perform an intersection test requiring only two multiplication operations per dimension. For example a first multiplication may be performed between a first inverse direction idA idB and a first distance between a first origin and a slab minimum MIN oA MIN oB and a second multiplication may be performed between a second inverse direction idB idA and a second distance between a second origin and a slab maximum distance MAX oB MAX oA .

The ability to perform the intersection test using only two multiplication operations is in contrast to the comparable function bslab naive which requires up to four division operations more expensive than multiplication operations per dimension. In certain prior art techniques not shown at least six multiplication operations are required per dimension.

Therefore the technique disclosed in Table 2 advantageously requires fewer and simpler arithmetic operations compared with prior art techniques such as the prior art technique illustrated in Table 3.

In one embodiment a ray intersection test is implemented as a beam intersection test whereby the query beam geometry is generated to envelope the ray with a non zero cross section along the path of the ray. The generated query beam may therefore be used for more conservative intersection testing. Conservative intersection testing may produce additional false positive intersection results with AABB targets but this approach substantially eliminates false negative intersection results that may potentially arise from numerical inaccuracies in the ray primitive intersection tests as well as in the ray beam intersection tests themselves. Additional false positive intersection tests in exchange for substantially eliminating false negative intersection tests an acceptable trade off because the false positive results typically represent a very small portion of overall intersection tests while a single false negative can easily produce visible artifacts in a resulting image. Each positive intersection test at the AABB query stage is further subjected to detailed intersection analysis and false positives are therefore substantially discarded producing no artifacts. In one embodiment the query beam may be generated using a dilation operator applied to the query ray. In one embodiment the beam may be generated according to a technique known in the art as Minkowski addition.

As shown in the PPU includes an Input Output I O unit a host interface unit a front end unit a compute scheduler unit CSU a compute work distribution unit CWDU a graphics primitive distribution unit GPDU a hub a crossbar Xbar one or more general processing clusters GPCs and one or more memory partition units . The PPU may be connected to a host processor or other peripheral devices via a system bus . The PPU may also be connected to a local memory comprising a number of memory devices . In one embodiment the local memory may comprise a number of dynamic random access memory DRAM devices.

The I O unit is configured to transmit and receive communications i.e. commands data etc. from a host processor not shown over the system bus . The I O unit may communicate with the host processor directly via the system bus or through one or more intermediate devices such as a memory bridge. In one embodiment the I O unit implements a Peripheral Component Interconnect Express PCIe interface for communications over a PCIe bus. In alternative embodiments the I O unit may implement other types of well known interfaces for communicating with external devices.

The I O unit is coupled to a host interface unit that decodes packets received via the system bus . In one embodiment the packets represent commands configured to cause the PPU to perform various operations. The host interface unit transmits the decoded commands to various other units of the PPU as the commands may specify. For example some commands may be transmitted to the front end unit . Other commands may be transmitted to the hub or other units of the PPU such as one or more copy engines a video encoder a video decoder a power management unit etc. not explicitly shown . In other words the host interface unit is configured to route communications between and among the various logical units of the PPU .

In one embodiment a program executed by the host processor encodes a command stream in a buffer that provides workloads to the PPU for processing. A workload may comprise a number of instructions and pointers to data to be processed by those instructions. The buffer is a region in a memory that is accessible i.e. read write by both the host processor and the PPU . For example the host interface unit may be configured to access the buffer in a system memory connected to the system bus via memory requests transmitted over the system bus by the I O unit . In one embodiment the host processor writes the command stream to the buffer and then transmits a pointer to the start of the command stream to the PPU . The host interface unit manages the scheduling of instructions from one or more command streams written by the host processor i.e. channels on the various sub units of the PPU .

The front end unit receives instructions from the host interface unit from one or more command streams and forwards those instructions to the correct sub unit of the PPU . Instructions associated with a compute pipeline may be received by the front end unit . These compute instructions are then forwarded to a compute scheduler unit . The compute scheduler unit is configured to track state information related to the various tasks managed by the compute scheduler unit . The state may indicate which GPC a task is assigned to whether the task is active or inactive a priority level associated with the task and so forth. The compute scheduler unit manages the execution of a plurality of tasks on the one or more GPCs .

The compute scheduler unit is coupled to a compute work distribution unit that is configured to dispatch tasks for execution on the GPCs . The compute work distribution unit may track a number of scheduled tasks received from the compute scheduler unit . In one embodiment the compute work distribution unit manages a pending task pool and an active task pool for each of the GPCs . The pending task pool may comprise a number of slots e.g. 16 slots that contain tasks assigned to be processed by a particular GPC . The active task pool may comprise a number of slots e.g. 4 slots for tasks that are actively being processed by the GPCs . As a GPC finishes the execution of a task that task is evicted from the active task pool for the GPC and one of the other tasks from the pending task pool is selected and scheduled for execution on the GPC . If an active task has been idle on the GPC such as while waiting for a data dependency to be resolved then the active task may be evicted from the GPC and returned to the pending task pool while another task in the pending task pool is selected and scheduled for execution on the GPC .

Returning to the front end unit instructions associated with a graphics pipeline may be received by the front end unit . These graphics instructions are then forwarded to a graphics primitive distribution unit . The graphics primitive distribution unit fetches vertex data from the memory or the system memory via the system bus for various graphics primitives. Graphics primitives may include points lines triangles quads triangle strips and the like. The graphics primitive distribution unit groups the vertices into batches of primitives and dispatches tasks to the GPCs for processing the batches of primitives. Processing may involve executing a shader i.e. a Vertex Shader Tesselation Shader Geometry Shader etc. on a programmable processing unit as well as performing fixed function operations on the vertices such as clipping culling and viewport transformation using a fixed function unit.

The compute work distribution unit and the graphics primitive distribution unit communicate with the one or more GPCs via a XBar . The XBar is an interconnect network that couples many of the units of the PPU to other units of the PPU . For example the XBar may be configured to couple the compute work distribution unit to a particular GPC . Although not shown explicitly one or more other units of the PPU are coupled to the host unit . The other units may also be connected to the XBar via a hub .

The tasks associated with the compute pipeline are managed by the compute scheduler unit and dispatched to a GPC by the compute work distribution unit . The tasks associated with the graphics pipeline are managed and distributed to a GPC by the graphics primitive distribution unit . The GPC is configured to process the tasks and generate results. The results may be consumed by other tasks within the GPC routed to a different GPC via the XBar or stored in the memory . The results can be written to the memory via the memory partition units which implement a memory interface for reading and writing data to from the memory . In one embodiment the PPU includes a number U of memory partition units that is equal to the number of separate and distinct memory devices coupled to the PPU . A memory partition unit will be described in more detail below in conjunction with .

In one embodiment a host processor executes a driver kernel that implements an application programming interface API that enables one or more applications executing on the host processor to schedule operations for execution on the PPU . An application may generate instructions i.e. API calls that cause the driver kernel to generate one or more tasks for execution by the PPU . The driver kernel outputs tasks to one or more streams being processed by the PPU . Each task may comprise one or more groups of related threads referred to herein as a warp. A thread block may refer to a plurality of groups of threads including instructions to perform the task. Threads in the same thread block may exchange data through shared memory. In one embodiment a warp comprises 32 related threads.

In one embodiment the operation of the GPC is controlled by the pipeline manager . The pipeline manager manages the configuration of the one or more TPCs for processing tasks allocated to the GPC . In one embodiment the pipeline manager may configure at least one of the one or more TPCs to implement at least a portion of a graphics rendering pipeline. For example a TPC may be configured to execute a vertex shader program on the programmable streaming multiprocessor SM . The pipeline manager may also be configured to route packets received from the Xbar to the appropriate logical units within the GPC . For example some packets may be routed to fixed function hardware units in the PROP and or raster engine while other packets may be routed to the TPCs for processing by the primitive engine or the SM .

The PROP unit is configured to route data generated by the raster engine and the TPCs to a Raster Operations ROP unit in the memory partition unit described in more detail below. The PROP unit may also be configured to perform optimizations for color blending organize pixel data perform address translations and the like.

The raster engine includes a number of fixed function hardware units configured to perform various raster operations. In one embodiment the raster engine includes a setup engine a coarse raster engine a culling engine a clipping engine a fine raster engine and a tile coalescing engine. Primitives lying outside a viewing frustum may be clipped by the clipping engine. The setup engine receives transformed vertices that lie within the viewing plane and generates edge equations associated with the geometric primitive defined by the vertices. The edge equations are transmitted to the coarse raster engine to determine the set of pixel tiles covered by the primitive. The output of the coarse raster engine may be transmitted to the culling engine where tiles associated with the primitive that fail a hierarchical z test are culled. Those fragments that survive culling may be passed to a fine raster engine to generate coverage information e.g. a coverage mask for each tile based on the edge equations generated by the setup engine. The output of the raster engine comprises fragments to be processed for example by a fragment shader implemented within a TPC .

Each TPC included in the GPC includes an M Pipe Controller MPC a primitive engine an SM and one or more texture units . The MPC controls the operation of the TPC routing packets received from the pipeline manager to the appropriate units in the TPC . For example packets associated with a vertex may be routed to the primitive engine which is configured to fetch vertex attributes associated with the vertex from the memory . In contrast packets associated with a shader program may be transmitted to the SM .

In one embodiment the texture units are configured to load texture maps e.g. a 2D array of texels from the memory and sample the texture maps to produce sampled texture values for use in shader programs executed by the SM . The texture units implement texture operations such as filtering operations using mip maps i.e. texture maps of varying levels of detail . In one embodiment each TPC includes two 2 texture units .

The SM comprises a programmable streaming processor that is configured to process tasks represented by a number of threads. Each SM is multi threaded and configured to execute a plurality of threads e.g. 32 threads from a particular group of threads concurrently. In one embodiment the SM implements a SIMD Single Instruction Multiple Data architecture where each thread in a group of threads i.e. a warp is configured to process a different set of data based on the same set of instructions. All threads in the group of threads execute the same instructions. In another embodiment the SM implements a SIMT Single Instruction Multiple Thread architecture where each thread in a group of threads is configured to process a different set of data based on the same set of instructions but where individual threads in the group of threads are allowed to diverge during execution. In other words when an instruction for the group of threads is dispatched for execution some threads in the group of threads may be active thereby executing the instruction while other threads in the group of threads may be inactive thereby performing a no operation NOP instead of executing the instruction. The SM may be described in more detail below in conjunction with .

The MMU provides an interface between the GPC and the memory partition unit . The MMU may provide translation of virtual addresses into physical addresses memory protection and arbitration of memory requests. In one embodiment the MMU provides one or more translation lookaside buffers TLBs for improving translation of virtual addresses into physical addresses in the memory .

In one embodiment the PPU implements a multi level memory hierarchy. The memory is located off chip in SDRAM coupled to the PPU . Data from the memory may be fetched and stored in the L2 cache which is located on chip and is shared between the various GPCs . As shown each memory partition unit includes a portion of the L2 cache associated with a corresponding memory device . Lower level caches may then be implemented in various units within the GPCs . For example each of the SMs may implement a level one L1 cache. The L1 cache is private memory that is dedicated to a particular SM . Data from the L2 cache may be fetched and stored in each of the L1 caches for processing in the functional units of the SMs . The L2 cache is coupled to the memory interface and the XBar .

The ROP unit includes a ROP Manager a Color ROP CROP unit and a Z ROP ZROP unit . The CROP unit performs raster operations related to pixel color such as color compression pixel blending and the like. The ZROP unit implements depth testing in conjunction with the raster engine . The ZROP unit receives a depth for a sample location associated with a pixel fragment from the culling engine of the raster engine . The ZROP unit tests the depth against a corresponding depth in a depth buffer for a sample location associated with the fragment. If the fragment passes the depth test for the sample location then the ZROP unit updates the depth buffer and transmits a result of the depth test to the raster engine . The ROP Manager controls the operation of the ROP unit . It will be appreciated that the number of memory partition units may be different than the number of GPCs and therefore each ROP unit may be coupled to each of the GPCs . Therefore the ROP Manager tracks packets received from the different GPCs and determines which GPC that a result generated by the ROP unit is routed to. The CROP unit and the ZROP unit are coupled to the L2 cache via an L2 XBar .

As described above the compute work distribution unit and the graphics primitive distribution unit dispatch tasks for execution on the GPCs of the PPU . The tasks are allocated to a particular TPC within a GPC and if the task is associated with a shader program the task may be allocated to an SM . A scheduler unit receives the tasks from the compute work distribution unit and the graphics primitive distribution unit and manages instruction scheduling for one or more groups of threads i.e. warps assigned to the SM . Each SM may include K scheduler units i.e. . . . K 1 . The scheduler unit schedules threads for execution in groups of parallel threads where each group is called a warp. In one embodiment each warp includes 32 threads. The scheduler unit may manage a plurality of different warps scheduling the warps for execution and then dispatching instructions from the plurality of different warps to the various functional units i.e. cores SFUs and LSUs during each clock cycle.

In one embodiment each scheduler unit includes one or more instruction dispatch units . Each dispatch unit is configured to transmit instructions to one or more of the functional units. In the embodiment shown in the scheduler unit includes two dispatch units that enable two different instructions from the same warp to be dispatched during each clock cycle. In alternative embodiments each scheduler unit may include a single dispatch unit or additional dispatch units .

Each SM includes a register file that provides a set of registers for the functional units of the SM . In one embodiment the register file is divided between subsets of the functional units such that each subset is allocated a dedicated portion of the register file . In another embodiment the register file is divided between the different warps being executed by the SM . The register file provides temporary storage for operands connected to the data paths of the functional units.

Each SM comprises L processing cores i.e. . . . L 1 . In one embodiment the SM includes a large number e.g. etc. of distinct processing cores . Each core may include a fully pipelined single precision processing unit that includes a floating point arithmetic logic unit and an integer arithmetic logic unit. The core may also include a double precision processing unit including a floating point arithmetic logic unit. In one embodiment the floating point arithmetic logic units implement the IEEE 754 2008 standard for floating point arithmetic. Each SM also comprises M SFUs i.e. . . . M 1 that perform special functions e.g. transcendental function evaluation attribute interpolation and the like and N LSUs i.e. . . . N 1 that implement load and store operations between the shared memory L1 cache and the register file . In one embodiment the SM includes 192 cores 32 SFUs and 32 LSUs .

Each SM includes an interconnect network that connects each of the functional units to the register file and the shared memory L1 cache . In one embodiment the interconnect network is a crossbar that can be configured to connect any of the functional units to any of the registers in the register file or the memory locations in shared memory L1 cache .

The shared memory L1 cache is an array of on chip memory that in one embodiment may be configured as either shared memory or an L1 cache or a combination of both as the application demands. For example the shared memory L1 cache may comprise 64 kB of storage capacity. The shared memory L1 cache may be configured as 64 kB of either shared memory or L1 cache or a combination of the two such as 16 kB of L1 cache and 48 kB of shared memory.

The PPU described above may be configured to perform highly parallel computations much faster than conventional CPUs. Parallel computing has advantages in graphics processing data compression biometrics stream processing algorithms and the like.

In one embodiment the PPU comprises a graphics processing unit GPU . The PPU is configured to receive commands that specify shader programs for processing graphics data. Graphics data may be defined as a set of primitives such as points lines triangles quads triangle strips and the like. Typically a primitive includes data that specifies a number of vertices for the primitive e.g. in a model space coordinate system as well as attributes associated with each vertex of the primitive. The PPU can be configured to process the graphics primitives to generate a frame buffer i.e. pixel data for each of the pixels of the display .

An application writes model data for a scene i.e. a collection of vertices and attributes to a memory such as a system memory or memory . The model data defines each of the objects that may be visible on a display. The application then makes an API call to the driver kernel that requests the model data to be rendered and displayed. The driver kernel reads the model data and writes commands to the one or more streams to perform operations to process the model data. The commands may reference different shader programs to be executed on the SMs of the PPU including one or more of a vertex shader hull shader domain shader geometry shader and a pixel shader. For example one or more of the SMs may be configured to execute a vertex shader program that processes a number of vertices defined by the model data. In one embodiment the different SMs may be configured to execute different shader programs concurrently. For example a first subset of SMs may be configured to execute a vertex shader program while a second subset of SMs may be configured to execute a pixel shader program. The first subset of SMs processes vertex data to produce processed vertex data and writes the processed vertex data to the L2 cache and or the memory . After the processed vertex data is rasterized i.e. transformed from three dimensional data into two dimensional data in screen space to produce fragment data the second subset of SMs executes a pixel shader to produce processed fragment data which is then blended with other processed fragment data and written to the frame buffer in memory . The vertex shader program and pixel shader program may execute concurrently processing different data from the same scene in a pipelined fashion until all of the model data for the scene has been rendered to the frame buffer. Then the contents of the frame buffer are transmitted to a display controller for display on a display device.

The PPU may be included in a desktop computer a laptop computer a tablet computer a smart phone e.g. a wireless hand held device personal digital assistant PDA a digital camera a hand held electronic device and the like. In one embodiment the PPU is embodied on a single semiconductor substrate. In another embodiment the PPU is included in a system on a chip SoC along with one or more other logic units such as a reduced instruction set computer RISC CPU a memory management unit MMU a digital to analog converter DAC and the like.

In one embodiment the PPU may be included on a graphics card that includes one or more memory devices such as GDDR5 SDRAM. The graphics card may be configured to interface with a PCIe slot on a motherboard of a desktop computer that includes e.g. a northbridge chipset and a southbridge chipset. In yet another embodiment the PPU may be an integrated graphics processing unit iGPU included in the chipset i.e. Northbridge of the motherboard.

In one embodiment each TPC included in the PPU may include one or more TTUs for performing tree traversal operations. The TTUs are coupled to the SM similar to the texture units . It will be appreciated that in alternate embodiments the TTUs may be included in the SM similar to the cores or the SFUs . Alternately one or more TTUs may be implemented within the PPU and shared by one or more GPCs or one or more SMs .

A tree traversal operation may include any operation performed by traversing the nodes of a tree data structure. A tree data structure may include but is not limited to a binary tree an octree a four ary tree a k d tree a binary space partitioning BSP tree and a bounding volume hierarchy BVH tree. In one embodiment the tree traversal operation includes a number of instructions for intersection a query shape with the tree. The query shapes may be e.g. rays bounding boxes frustums cones spheres and the like. In various embodiments a query shape may be specified by a query data structure. The query data structure may include any technically feasible technique for specifying the query shape to intersect with the tree. For example the query data structure may specify the starting and ending points of a ray using two three coordinate vectors. In another example the query data structure may specify the six planes of an axis aligned bounding box using six 32 bit floating point coordinates. The various query data structures may include any number of fields for specifying the attributes of the query shape.

For example one type of tree traversal operation for which the TTU may be optimized is to intersect a ray with a BVH data structure that represents each of the geometric primitives in a 3D scene or 3D model. The TTU may be particularly useful in ray tracing applications in which millions or even billions of rays are intersected with the geometric primitives of a 3D model represented by a BVH data structure.

The interface may receive instructions and or data for performing tree traversal operations from the SM . In one embodiment the SM may transmit the instructions and or data directly to the interface via a plurality of dedicated interconnects e.g. wires paths in a metal layer of a semiconductor etc. . In another embodiment the SM may write the instructions to one or more special registers associated with the TTU and the interface may monitor the registers for any updates from the SM .

The instructions may include instructions for configuring the TTU to perform a tree traversal operation. The instructions may include operands such as pointers that direct the TTU to a tree data structure and or a query data structure are located in the memory . The interface may cause at least a portion of the tree data structure and or the query data structure to be fetched into the L0 cache unit or the local storage .

The L0 cache unit is coupled to the MMU and provides a low level local access to the memory architecture hierarchy of the PPU . In one embodiment the L0 cache unit includes a number of entries where each entry is sized according to a size of a cache line in the memory architecture hierarchy. For example the L2 cache associated with the memory may implement a cache line having L bytes of information and the L0 cache unit may include M entries of L bytes to enable up to M cache lines to be stored in the L0 cache unit . In one embodiment the L0 cache unit may include eight entries for cache lines having 128 bytes of data. Of course the size and number of entries in the L0 cache unit may vary widely between different architectures and other cache line sizes and number of entries are contemplated as being within the scope of various embodiments. Furthermore the L0 cache unit may include logic in addition to the raw data storage for fetching cache lines from the memory and or the other hierarchical cache units. For example the logic may include hardware configured to select particular entries in the L0 cache unit to evict in order to enable other data to be fetched into the L0 cache unit . The logic may also include hardware for maintaining cache coherency. For example the logic may determine when write back operations need to be performed for dirty cache lines.

In one embodiment the query data structure associated with a particular tree traversal operation is stored in the local storage . The query data structure may specify a query shape to be intersected with a tree data structure. The interface may receive the data for the query data structure and store the data in an available memory location in the local storage . The interface may also initialize a stack data structure associated with the query data structure in the local storage . The stack data structure may include a portion of memory for creating a stack associated with the particular tree traversal operation. In one embodiment the stack data structure is initialized by allocating a portion of the local storage to a particular tree traversal operation and pushing a root node for a tree data structure onto the stack data structure. It will be appreciated that pushing a root node onto the stack data structure may be performed by storing a pointer to a data structure for the root node of the tree data structure in a memory location associated with the stack data structure.

The interface may notify the scheduler of an event when the interface receives an instruction that causes a tree traversal operation to be launched by the TTU . The event may indicate that the TTU has been tasked with performing a tree traversal operation for a particular tree data structure and a particular query data structure. The scheduler may receive notice of the event via a signal. The signal may be a token that is passed to the scheduler via a data communication channel. The token may include an identifier associated with a particular query data structure stored in the local storage .

The scheduler may include a queue e.g. first in first out or FIFO etc. that includes a number of slots that store identifiers for query data structures associated with tree traversal operations. Identifiers may be unique within the scope of the TTU . In other words each identifier uniquely identifies a particular query data structure stored in the local storage . In one embodiment identifiers are allocated to query data structures dynamically when the query data structures are stored in the local storage . The queue may be used such that a number of different tree traversal operations may be in flight in the TTU at any given time and the queue may be implemented at least in part to hide the latency associated with memory operations for fetching node data from the memory into the L0 cache unit . In one embodiment the queue includes e.g. 32 slots for storing a number of identifiers for query data structures to be intersected with the tree data structure. The total number of slots may be increased or decreased based on latency associated with memory operations which may be dependent at least in part on the details of the memory architecture hierarchy.

The scheduler may also maintain status entries for tracking the status of the tree traversal operations associated with each of the query data structures referenced by identifiers stored in the queue. The status entries may indicate for example a scheduling priority for a particular tree traversal operation whether data associated with the next node to be tested in the tree traversal operation is currently stored in the L0 cache unit whether the tree traversal operation associated with a particular query data structure is currently being processed by the one or more traversal units or whether results for a particular tree traversal operation are available in the memory . The scheduler may also notify the SM via the interface of certain events such as notifying the SM that the data for a particular tree traversal operation is available in the memory or in the register file of the SM or notifying the SM that the queue in the scheduler is full.

Once the scheduler has received an event notification from the interface indicating that the tree traversal operation should be launched the scheduler may begin to manage the execution of the tree traversal operation. In one embodiment the scheduler may pop the top element from the stack data structure in the local storage associated with the tree traversal operation. The top element may include a pointer to a location of a node of the tree data structure in the memory . The scheduler may issue one or more fetch commands to the L0 cache unit to fetch data associated with the node into the L0 cache unit . The fetch commands may include an address of the data to be fetched. For example the address may point to a root node for a block of the tree data structure. The L0 cache unit will determine if the requested data is in the L0 cache unit . If the data is not currently stored in the L0 cache unit then the fetch request results in a cache miss and the data will be fetched from the memory architecture hierarchy such as L2 cache unit or memory as required. Once the data has been returned from the memory architecture hierarchy the L0 cache unit will inform the scheduler that the data is available. If the data is currently stored in the L0 cache unit then the fetch request results in a cache hit and the L0 cache unit will inform the scheduler that the data is immediately available. It will be appreciated that the data associated with a particular node may be included in data associated with a plurality of nodes of the tree data structure that are stored in contiguous memory and comprise a single cache line. Therefore each fetch request may result in data for more than one node being loaded into the L0 cache unit .

Once the data has been fetched into the L0 cache unit the scheduler transmits a request to the setup unit to initiate the tree traversal operation for one or more nodes of the tree data structure. The setup unit may perform any number of operations for configuring the one or more traversal units to perform the tree traversal operation. For example in one embodiment the setup unit may fetch the data associated with the query data structure and the data associated with one or more nodes of the tree data structure from the local storage and the L0 cache unit respectively. In another embodiment the setup unit may transform coordinates associated with the query data structure from a global coordinate system into a local coordinate system. In another embodiment the setup unit may configure one or more traversal units to execute instructions for performing the tree traversal operation for one or more nodes of the tree data structure.

In one embodiment the TTU is configured to perform tree traversal operations on blocks of a tree data structure. As used herein a block may include one or more nodes of the tree data structure that fit within a particular cache line. The block may include a block root node having zero or more child nodes that are also included in the block. Each of the zero or more child nodes may also include corresponding child nodes those corresponding child nodes may include one or more additional child nodes and so forth. Some or all of the corresponding child nodes and or the additional child nodes may also be included in the block. A block may be defined as no larger than a cache line e.g. 128 bytes etc. and may contain a fixed or variable number of nodes. It will be appreciated that the tree data structure may include a plurality of blocks that together represent all of the nodes in the tree data structure.

The one or more traversal units may receive data for a particular query data structure to intersect with one or more nodes of the tree data structure. Each traversal unit may be configured to test each of the child nodes of a particular node for intersection with the query data structure. If the query data structure intersects the child node then the child node is added to a local stack data structure. Once all of the child nodes of the particular node have been tested then the traversal unit may be configured to check the local stack data structure. If the local stack data structure is empty then no nodes need to be tested for intersection with the query data structure and the traversal unit may notify the stack management unit that the tree traversal operation has been completed at least for the nodes in that particular block of the tree data structure. However if the local stack data structure is not empty then the top element is popped from the local stack data structure and the process is repeated for this new node.

If a particular node being tested by the traversal unit is a leaf node and is intersected by the query data structure then the elements associated with the leaf node may be added to a result queue. If the particular node being tested by the traversal unit is an internal node that is included in another block of the tree data structure then the node included in the other block may be added to a result queue.

In one embodiment the traversal units may implement a pipelined architecture in order to hide latency associated with a particular operation performed for each node. For example a pipelined architecture may be implemented for an intersection test that takes a number of cycles to complete such that a number of intersection tests for different nodes and different query data structures may be in flight at any given time within a traversal unit . In other words each traversal unit may be performing tree traversal operations for a number of different nodes and a number of different query data structures substantially simultaneously.

In one embodiment each traversal unit includes a local storage for storing a number of different blocks of the tree data structure. The local storage may be a temporary location comprising static RAM for storing one or more cache lines included in the L0 cache unit and needed for performing a tree traversal operation for a particular query data structure. For example the local storage may include 5 slots of 128 bytes for storing up to five cache lines from the L0 cache unit that include data for up to five different blocks of the tree data structure or different tree data structures . The data in up to four of the slots in the local storage may be accessed by the logic of the traversal unit during any given clock cycle and data for the remaining slot may be written to the local storage by the setup unit during the clock cycle. Each traversal unit may also include local storage for storing a number of query data structures. The number of query data structures stored locally in the traversal unit may be equal to the number of available slots for storing blocks of the tree data structure. Similarly each traversal unit may include local storage for storing a number of local stack data structures used for traversing the different blocks of the tree data structure.

The stack management unit receives the results of a tree traversal operation from the result queue. The result queue may include leaf data such as a geometric primitive to be tested for intersection with a query shape as well as nodes or rather pointers to nodes included in other blocks of the tree data structure. In one embodiment the stack management unit transmits leaf data such as the geometric primitives to the SM . As described herein the leaf data may represent those elements stored in the tree data structure that are potentially intersected by the query data structure. The SM may be configured to process the results of the tree traversal operation by any means necessary. For example if the results of the tree traversal operation include a set of geometric primitives the SM may be configured to test those particular geometric primitives for intersection with the query data structure. It will be appreciated that testing a geometric primitive included in a leaf node such as a triangle or quad for intersection with the query data structure is a different type of operation than testing a leaf node associated with a bounding volume for intersection with the query data structure. The SM may also be configured to launch one or more additional tree traversal operations for new query data structures based on the processing of the geometric primitives included in the results.

The stack management unit may also manage traversal stacks for each of the tree traversal operations currently being executed by the TTU . A traversal stack may refer to a data structure that temporarily stores particular nodes in the tree data structure that need to be tested against the query data structure during future iterations of the processing loop. A non empty traversal stack that includes one or more nodes of the tree data structure indicates that at least a portion of the tree traversal operation still needs to be scheduled for execution by the one or more traversal units .

When the stack management unit receives a pointer to a node for a new block of the tree data structure in the result queue the stack management unit adds the node to the traversal stack for a particular tree traversal operation. The stack management unit may be notified once the one or more traversal units have completed testing the nodes of a given block of the tree data structure. In one embodiment the one or more traversal units may notify the stack management unit of an event by including a signal and or data in the result queue that indicates the one or more traversal units have completed executing the tree traversal operation for a block of the tree data structure. Once the stack management unit receives the event the stack management unit may cause the scheduler to initiate the next portion of the tree traversal operation for a different block associated with a node included in the traversal stack. In other words the scheduler unit may retrieve the top element i.e. a new node from the traversal stack included in the local storage fetch any data required for performing the tree traversal operation for the new node into the L0 cache unit and or local storage and notify the setup unit to configure the one or more traversal units to perform the tree traversal operation for one or more nodes in the new block of the tree data structure.

Although the TTU described above has been described relative to a tree traversal operation for a general query data structure as applied to a general tree data structure the TTU in some embodiments may be configured to perform a tree traversal operation for a specific application such as ray tracing. In other words a tree traversal operation may be limited to intersecting a ray with a tree that represents a plurality of geometric primitives. The tree may be implemented as a bounding volume hierarchy BVH spatial subdivision tree and the like. The operation of the TTU as applied to a ray tracing application in association with a BVH will be described in more detail below.

In order to intersect a ray with the BVH the SM may transmit an instruction to the interface of the TTU . In response to the instruction the interface may load a ray data structure into the local storage and initialize a traversal stack data structure in the local storage . The interface may also push a root node for the BVH onto the traversal stack data structure. The interface may also assign a ray identifier to the ray data structure in the local storage for identifying the particular ray data structure associated with a particular tree traversal operation. In a typical ray tracing algorithm utilized to create a computer generated image hundreds thousands or even millions of rays may be cast and intersected with the tree data structure. Thus the ray identifier provides a useful way for tracking and identifying a tree traversal operation in flight in the TTU for a particular ray.

The ray data structure may be stored in the local storage such that the ray data structure may be quickly accessed during the tree traversal operation associated with the ray. A ray may be defined e.g. by a set of tuples specifying a starting coordinate and an ending coordinate or alternately a starting coordinate a direction and a magnitude. The ray data structure may include one or more coordinates for specifying the ray one or more attributes of the ray and so forth. In one embodiment the ray data structure includes two vectors for specifying the endpoints of the ray each vector comprising three 32 bit floating point values for specifying the coordinates of a point relative to a global coordinate system as well as one or more attributes such as flags that specify how particular types of graphics primitives encountered during the tree traversal operation are to be processed.

The interface may notify the scheduler of a ray event that indicates that the TTU received an instruction requesting a tree traversal operation to be performed for a given ray data structure. The interface may pass a ray identifier for the ray data structure stored in the local storage to the scheduler as part of the ray event.

As long as the queue includes at least one ray identifier that needs to be processed by the one or more traversal units the scheduler may choose a particular tree traversal operation from the queue to be launched on the one or more traversal units . The particular tree traversal operation may be selected by selecting one of the ray identifiers included in the queue of the scheduler . Any technically feasible means for selecting a particular ray identifier from the queue may be implemented by the scheduler such as a priority based algorithm a round robin algorithm and the like.

In one embodiment the scheduler searches the queue for ray identifiers that are ready to be launched. The scheduler may select a particular ray identifier ready to be launched and fetch the top element from the traversal stack data structure corresponding to the ray identifier. The top element may comprise a pointer to a node of the BVH. The scheduler may then issue a fetch request to the L0 cache unit to fetch the data corresponding to the pointer to the node. If the data is not currently stored in the L0 cache unit then the data is fetched from memory and the scheduler during the next clock cycle may select another ray identifier from the queue to try and launch. However if the data is currently stored in the L0 cache unit then the scheduler transmits a request to the setup unit to launch the tree traversal operation for that node.

In one embodiment the node represents the root node for a block of the BVH. The setup unit and one or more traversal units will be configured to traverse all of the nodes of the block intersecting each node of the block with the ray data structure corresponding to that particular tree traversal operation. In one embodiment the setup unit fetches the ray data structure associated with the tree traversal operation from the local storage . The setup unit may also fetch the data for the block including the node from the L0 cache unit . In one embodiment the setup unit performs one or more operations for preparing to execute the tree traversal operation. For example in one embodiment the setup unit transforms the coordinates associated with the ray data structure from a global coordinate system to a local coordinate system associated with a root node of the block. In another embodiment the setup unit may test the root node of the block for intersection with the ray data structure. If the root node of the block intersects the ray data structure then each of the child nodes of the root node may be passed to a particular traversal unit to continue traversing the BVH in parallel. In one embodiment the TTU may include four traversal units to test up to eight child nodes for intersection with the ray in parallel. The number of traversal units that are implemented in a given TTU may be optimized for the types of trees that are typically traversed. In yet another embodiment the setup unit may transmit the root node of the block to one of the available traversal units .

When a node is received at a tree traversal unit from the setup unit the node is inserted into a local stack data structure. The local stack data structure is similar to the traversal stack data structure except the depth of the local stack data structure may be limited due to the fixed size of a block of the tree data structure. The traversal unit then enters a loop where the traversal unit determines if the local stack data structure is empty. If the local stack data structure is empty then the traversal unit has completed the traversal of the block. However if the local stack data structure is not empty then the traversal unit pops the top entry from the local stack data structure. If the top entry is a leaf node and the lead node intersects the ray data structure then the data e.g. geometric primitives stored in the leaf node is added to a result queue. However if the top entry is an internal node i.e. a node that includes one or more child nodes etc. then the ray data structure is intersected with the node to determine if the ray intersects the node. If the ray data structure does not intersect the node then nothing is added to the local stack data structure and the loop is repeated if the local stack data structure is not empty. If the ray data structure intersects the node then each of the child nodes of the node included in the block are added to the local stack data structure and the loop is repeated. However if the child nodes of the intersected node are not included in the block i.e. the child nodes are included in a different block of the tree data structure etc. then the child nodes may be added to the result queue. Once the local stack data structure is empty the tree traversal operation for the block is complete and any data included in the result queue may be passed to the stack management unit .

The stack management unit may read the result queue and update the traversal stack data structure in the local storage by adding any child nodes included in the result queue to the top of the traversal stack data structure. The stack management unit may also transmit any geometric primitives included in the result queue to the SM . Again the geometric primitives included in the result queue were those primitives associated with nodes i.e. bounding volumes that intersected the ray and therefore are the results associated with a particular tree traversal operation intersecting the ray with the BVH. Once the traversal stack data structure in local storage has been updated and the one or more traversal units have indicated to the stack management unit that the tree traversal of the block of the tree data structure is complete the stack management unit may indicate to the scheduler that the tree traversal operation for the particular ray data structure is ready to be re launched if the traversal stack data structure is not empty.

The preceding description of the TTU in accordance with one embodiment utilizes an optimized block based tree traversal algorithm that is discussed in more detail below. It will be appreciated that the architecture of the TTU may be optimized for different types of tree traversal algorithms and that the architecture of the TTU may be changed for different algorithms utilized for different types of hardware architectures. The block based tree traversal algorithm is just one method for optimizing tree traversal operations on high latency memory architecture systems such as the PPU . In one embodiment the various units of the TTU e.g. the setup unit the traversal units etc. may be implemented as fixed function logic configured to implement the functionality of each of the units described above. In another embodiment one or more of the units of the TTU may be programmable logic devices that are configured to execute instructions transmitted to the TTU by the SM or read from the memory . The units may execute the instructions to implement the functionality of each of the units described above in a programmable manner. For example the traversal units may be programmable devices configured to execute a program stored in the memory to process one or more nodes of the tree data structure.

As shown in the tree data structure is a binary tree data structure. In one embodiment the binary tree data structure represents a BVH associated with a 3D scene or 3D model that includes a number of geometric primitives as shown in . It will be appreciated that the tree data structure is shown for illustration only and is quite small when compared to tree data structures generated from typical 3D models in for example computer graphics. Such tree data structures may contain thousands or millions of nodes.

As shown in a 3D model comprising a number of geometric primitives i.e. the shaded triangles may be associated with a BVH . In other words each geometric primitive may be associated with a bounding volume that fully encloses the geometric primitive and then multiple geometric primitives in close proximity may be bounded by a higher level bounding volume. The hierarchy is established through multiple levels of larger and larger bounding volumes until a single bounding volume encloses all of the lower level bounding volumes. The single bounding volume may be associated with the root node in the tree data structure .

It will be appreciated that the illustration of the BVH is shown in two dimensions rather than three dimensions and that the bounding volumes are illustrated as bounding rectangles. However the abstract concepts illustrated herein for a two dimensional system may be applied equally as well to higher dimensional system e.g. a three dimensional system etc. using for example axis aligned bounding boxes AABB . In addition the bounding volumes are not limited to AABBs. In other embodiments bounding volumes may be spheroid cylindrical or any other closed geometric surface.

As shown in the BVH includes bounding boxes and which correspond to nodes and of the tree data structure respectively. These bounding boxes contain one or more additional lower level bounding boxes. Similarly the BVH includes bounding boxes and which correspond to nodes and of the tree data structure respectively. These bounding boxes contain one or more geometric primitives and therefore are represented in the tree data structure by the leaf nodes.

While valid configurations are shown in other invalid configurations may also exist. For example configurations where oA

A given query beam includes a region between the first ray and the second ray starting at t 0 and projecting in the direction of the first and second rays for t 0. As shown the query beam includes a counter clockwise left to right region starting with ray A and rotating moving towards ray B. For example in the query beam is formed by the origins of rays A and B at t 0 and projects upwards in the direction of the rays A and B t 0 . The region between rays A and B below the intersection of rays A and B cannot be part of the query beam region by virtue of the requirements placed on valid beam configurations.

The top example of includes a minimum value parametric variable tmin at Amin and a maximum value parametric variable tmax at Bmax. The parametric variable range of tmin to tmax is indicated in brackets to the left of each example. In the top example the tmin to tmax parametric variable range is shown as Amin Bmax . The middle example of is labeled Bmin Bmax to indicate a tmin value of Bmin and a tmax value of Bmax. However both Amin and Bmin occur below the intersection of rays A and B and therefore in one embodiment both Amin and Bmin must correspond to negative parametric variable values. Because a negative parametric variable value indicates a point along a ray that is not included within a query beam Amin and Bmin are equivalent in this example for the purpose of an intersection test and in the middle example the parametric variable range Amin Bmax is equivalent to the indicated parametric variable range Bmin Bmax for the purpose of performing an intersection test. In the bottom example of Amin Bmin Amax and Bmax each correspond to a negative value oft and are equivalent to each other for the purpose of an intersection test and the indicated parametric variable range Bmin Amax is equivalent to the parametric variable range Amin Bmax for the purpose of performing an intersection test. The bottom example of is marked NULL to indicate no intersection between the slab and the query beam.

The equivalence of negative parametric variable values in performing a beam intersection test advantageously enables a simplification of different sets of query beam configurations into a single rule per slab intersection case. For example each of the different configurations illustrated in conform to a single slab intersection case identified in Table 2 as case 1 dA 0.0 dB 0.0 and consequently each different configuration illustrated in may be tested for intersection using a single rule to define a parametric variable range of Amin Bmax . Similarly each of the different configurations illustrated in conform to a single slab intersection case identified in Table 2 as case 2 dA 0.0 dB 0.0 and consequently each different configuration illustrated in may be tested for intersection using a single rule to define a parametric range of Amin Amax

The system also includes input devices a graphics processor and a display i.e. a conventional CRT cathode ray tube LCD liquid crystal display LED light emitting diode plasma display or the like. User input may be received from the input devices e.g. keyboard mouse touchpad microphone and the like. In one embodiment the graphics processor may include a plurality of shader modules a rasterization module etc. Each of the foregoing modules may even be situated on a single semiconductor platform to form a graphics processing unit GPU .

In the present description a single semiconductor platform may refer to a sole unitary semiconductor based integrated circuit or chip. It should be noted that the term single semiconductor platform may also refer to multi chip modules with increased connectivity which simulate on chip operation and make substantial improvements over utilizing a conventional central processing unit CPU and bus implementation. Of course the various modules may also be situated separately or in various combinations of semiconductor platforms per the desires of the user.

The system may also include a secondary storage . The secondary storage includes for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive a compact disk drive digital versatile disk DVD drive recording device universal serial bus USB flash memory. The removable storage drive reads from and or writes to a removable storage unit in a well known manner.

Computer programs or computer control logic algorithms may be stored in the main memory and or the secondary storage . Such computer programs when executed enable the system to perform various functions. The memory the storage and or any other storage are possible examples of non transitory computer readable media.

In one embodiment the architecture and or functionality of the various previous figures may be implemented in the context of the central processor the graphics processor an integrated circuit not shown that is capable of at least a portion of the capabilities of both the central processor and the graphics processor a chipset i.e. a group of integrated circuits designed to work and sold as a unit for performing related functions etc. and or any other integrated circuit for that matter.

Still yet the architecture and or functionality of the various previous figures may be implemented in the context of a general computer system a circuit board system a game console system dedicated for entertainment purposes an application specific system and or any other desired system. For example the system may take the form of a desktop computer laptop computer server workstation game consoles embedded system and or any other type of logic. Still yet the system may take the form of various other devices including but not limited to a personal digital assistant PDA device a mobile phone device a television etc.

Further while not shown the system may be coupled to a network e.g. a telecommunications network local area network LAN wireless network wide area network WAN such as the Internet peer to peer network cable network or the like for communication purposes.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

