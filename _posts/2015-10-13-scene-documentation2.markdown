---

title: Scene documentation
abstract: A plurality of images are captured by an image capturing device that is an integral part of the mobile data collection platform from at least two different perspectives that depict a point of interest in a scene. Coincident with capture of each of the plurality of images, orientation information is obtained via orientation sensors of the mobile data collection platform, a position fix of an antenna associated with the mobile data collection platform is determined, and a position of an entrance pupil of the image capturing device is calculated. Scale information associated with at least one of the images is captured. Scene data comprises the images, the orientation information and the entrance pupil positions. A three dimensional position of the point of interest at the scene is determined based on photogrammetric image processing of the scene data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639941&OS=09639941&RS=09639941
owner: Trimble Inc.
number: 09639941
owner_city: Sunnyvale
owner_country: US
publication_date: 20151013
---
This application claims priority to and is a continuation in part application of co pending U.S. patent application Ser. No. 14 035 884 filed on Sep. 24 2013 entitled EXTRACTING PSEUDORANGE INFORMATION USING A CELLULAR DEVICE by Rudow et al.

U.S. patent application Ser. No. 14 035 884 claimed priority to and benefit of then U.S. Provisional Patent Application No. 61 746 916 filed on Dec. 28 2012 entitled IMPROVED GPS GNSS ACCURACY FOR A CELL PHONE by Rudow et al. and assigned to the assignee of the present application the contents of U.S. Provisional Patent Application No. 61 746 916 were incorporated by reference into U.S. patent application Ser. No. 14 035 884.

Application Ser. No. 14 035 884 also claimed priority to and is a continuation in part to the co pending patent application Ser. No. 13 842 447 entitled OBTAINING PSEUDORANGE INFORMATION USING A CELLULAR DEVICE by Richard Rudow with filing date Mar. 15 2013 and assigned to the assignee of the present application the disclosure of which was incorporated by reference into application Ser. No. 14 035 884.

This application claims priority to and is a continuation in part application of co pending U.S. patent application Ser. No. 14 515 317 filed on Oct. 15 2014 entitled PERFORMING DATA COLLECTION BASED ON INTERNAL RAW OBSERVABLES USING A MOBILE DATA COLLECTION PLATFORM by Rudow et al.

This application claims priority to and is a continuation in part application of co pending U.S. patent application Ser. No. 14 516 157 filed on Oct. 16 2014 entitled EXTERNAL ELECTRONIC DISTANCE MEASUREMENT ACCESSORY FOR A MOBILE DATA COLLECTION PLATFORM by Rudow et al.

The Global Positioning System GPS and its extensions in the Global Navigation Satellite Systems GNSS have become thoroughly pervasive in all parts of human society worldwide. GPS and GNSS receivers in the form of chipsets have become widely incorporated into cell phones and other types of cellular devices with cellular based communications equipment.

Typically cellular devices include highly integrated GNSS chipsets that are designed to work with the E 911 service primarily and are not designed to provide anywhere near a full range of features and outputs. They do provide a position fix but are not designed to make available very many other parameters of interest. All GNSS receivers must acquire track and decode a data message that conveys information about the location of the satellites in space and time information. The principal additional parameter obtained is the pseudorange. However conventionally this set of data is not available as an output from the cellular device s GNSS chipsets for use by the cellular device itself. Conventionally in circumstances where it is available it is under access control by the vendor.

Reference will now be made in detail to various embodiments of the subject matter examples of which are illustrated in the accompanying drawings. While various embodiments are discussed herein it will be understood that they are not intended to limit to these embodiments. On the contrary the presented embodiments are intended to cover alternatives modifications and equivalents which may be included within the spirit and scope the various embodiments as defined by the appended claims. Furthermore in the following Description of Embodiments numerous specific details are set forth in order to provide a thorough understanding of embodiments of the present subject matter. However embodiments may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail as not to unnecessarily obscure aspects of the described embodiments.

Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the description of embodiments discussions utilizing terms such as accessing calculating extracting using providing applying correcting smoothing reconstructing modeling improving adjusting filtering discarding removing processing determining selecting locating positioning increasing differentiating integrating bridging displaying performing obtaining receiving storing notifying matching creating generating communicating transmitting requesting activating deactivating initiating terminating interpolating changing replacing causing transforming data modifying data to transform the state of a computer system or the like refer to the actions and processes of a computer system data storage system storage system controller microcontroller hardware processor or similar electronic computing device or combination of such electronic computing devices. The computer system or similar electronic computing device manipulates and transforms data represented as physical electronic quantities within the computer system s device s registers and memories into other data similarly represented as physical quantities within the computer system s device s memories or registers or other such information storage transmission or display devices.

Cellular devices such as cell phones and non voice enabled cellular devices possesses pseudorange information that can be used in surveying and other positioning operations. Conventionally however the pseudorange information from cellular device chipsets are only available under a limited set of conditions usually only when performing a E 911 service call and then only for use by the Assisted GPS service located in conjunction with the E 911 service facility. Therefore according to one embodiment an embedded GNSS chipset is employed with in a cellular device which a calculates pseudorange information for use by the GNSS chipset and b permits extraction of this pseudorange information by the cellular device in which it is embedded. As will be discussed the pseudorange information from the GNSS chipset is extracted for use elsewhere in the cellular device outside of the GNSS chipset.

As depicted in the cellular device includes a GNSS chipset a GNSS receiver a processor that is part of the GNSS receiver a chipset accessor logic a pseudorange information extractor logic an improved accuracy Secure User Platform Location SUPL client a pseudorange information bridger logic a pseudorange information processing logic an operating system a location manager logic a location displayer logic hardware that is outside of the GNSS receiver . According to one embodiment the chipset accessor logic the pseudorange information extractor logic the pseudorange information processing logic and the pseudorange information bridger logic are a part of the improved accuracy SUPL client .

According to one embodiment the hardware includes a hardware processor and memory . An example of a hardware processor is a central processing unit. An example of hardware memory is computer readable storage such as but not limited to a disk a compact disk CD a digital versatile device DVD random access memory RAM or read only memory ROM . The hardware memory is physical and therefore tangible according to one embodiment. The hardware memory according to another embodiment is non transitory.

According to one embodiment the processor and the GNSS receiver are a part of the GNSS chipset . According to one embodiment the chipset accessor logic pseudorange information extractor logic the pseudorange information bridger logic the improved accuracy SUPL client the operating system and the processor are located in a portion of the cellular device that is outside of the GNSS chipset . The location manager logic can be a part of the operating system and external to the GNSS chipset . According to one embodiment the location displayer logic is a part of the location manager logic . According to one embodiment the chipset accessor logic pseudorange information extractor logic the pseudorange information processing logic pseudorange information bridger logic and improved accuracy SUPL client are application programming interfaces API function applications that reside in memory of the cellular device and are executed by a processor of the cellular device .

According to one embodiment the GNSS receiver is capable of receiving signals from GPS satellites GLONASS satellites or from a combination of satellites from different constellations. The GNSS receiver can perform GPS measurements to derive raw measurement data for a position of the cellular device . The raw measurement data can provide an instant location of the cellular device . According to one embodiment the raw measurement data is the pseudorange information that is extracted also referred to as extracted pseudorange information . Examples of the extracted pseudorange information are uncorrected pseudorange information observed pseudorange information or unsmoothed pseudorange information or a combination thereof. Conventionally the raw measurement data is only for use by the GNSS chipset and the GNSS chipset calculates pseudorange information that is only for use by the GNSS chipset . Examples of pseudorange information are uncorrected pseudorange information smoothed pseudoranges and corrected pseudoranges. Examples of corrections used to improve accuracy of a position fix include differential GNSS corrections DGPS high precision GNSS satellite orbital data GNSS satellite broadcast ephemeris data and ionospheric and tropospheric error corrections and error projections based on location.

The GNSS chipset has a processor and therefore is capable of and or operates to process information such as pseudorange information itself to arrive at a position fix also known as a navigation solution . However according to various embodiments information such as pseudorange information that the GNSS chipset has can be extracted from the GNSS chipset and processed outside of the GNSS chipset . That is instead of relying on the position fix calculated by the GNSS chipset using its own processor the pseudorange information is extracted by and processed by a processor e.g. processor that is external to the GNSS chipset such as by a software defined GNSS receiver also often described in the art as a soft GNSS receiver implemented by the external processor in order to provide an improved accuracy position fix as compared to the position fix calculated internally by the GNSS chipset . In some embodiments pseudorange processor logic discussed below is an example of a software defined GNSS receiver and operates as logic instructions implemented by processor external to GNSS chipset . It should be appreciated that the position fix calculated by the external processor is in addition to a position fix calculated by the GNSS chipset on its own.

The chipset accessor logic is configured for accessing the GNSS chipset . The pseudorange information extractor logic is configured for extracting the pseudorange information from the accessed GNSS chipset . The extracted pseudorange information can be received and stored continuously. The pseudorange information bridger logic is configured for bridging the pseudorange information from the GNSS chipset to the location manager logic that resides in the operating system of the cellular device .

According to one embodiment the chipset accessor logic the pseudorange information extractor logic the pseudorange information processing logic and pseudorange information bridger logic are a part of an improved accuracy SUPL client . For example The SUPL client can interface between the GNSS chipset and the location manager logic which resides in the operating system .

The pseudorange information can be obtained from the processor of the GNSS receiver . The GNSS chipset may be designed for example by the manufacturer of the GNSS chipset to provide requested information such as pseudorange information in response to receiving the command. The pseudorange information may be extracted from the GNSS chipset using the command that the manufacturer has designed the GNSS chipset with. For example according to one embodiment the GNSS chipset is accessed using an operation that is a session started with a message that is an improved accuracy Secure User Platform Location SUPL start message or a high precision SUPL INIT message. According to one embodiment the message is a custom command that is specific to the GNSS chipset also referred to as a GNSS chipset custom command and by which the improved accuracy SUPL client can gain access to the raw measurements of the GNSS chipset . Access may be controlled by the chipset manufacturer and a suitable key made available for use in the SUPL for obtaining access to the pseudoranges. A suitable key is an example of a custom command. 

A worker thread associated with the SUPL client can monitor the raw measurements delivered by the GNSS chipset into the GNSS chipset s memory buffers cache the raw measurements and use the raw measurements to determine a position fix. The pseudorange information extractor logic and the pseudorange information processing logic can be associated with the worker thread. For example the pseudorange information extractor logic can cache the raw measurements and the pseudorange information processing logic can determine the location.

According to one embodiment a worker thread is a light weight process that executes a specific sequence of tasks in the background. The tasks can be of long term and or at times periodic in nature. The worker thread can assist in helping the main thread which may also be referred to as the main program or main task with specific functions. Worker threads can be started when these functions of the sequence of tasks are to be executed. A worker thread can remain in the active state as long as its respective functions are being executed. A worker thread may terminate itself when it completes its functions or when it reaches a point where it can no longer continue to function for example due to an irrecoverable error. A worker thread can post its status to the main thread when it ends. Examples of posted status are completion or termination. A worker thread may also post to the main thread the level of progress of its functions periodically. At a given point in time there may be many such worker threads in progress at the same time. Worker threads may maintain some sort of synchronization amongst themselves depending upon the tasks they are intended for. The main thread may terminate a worker thread for example when the functions of that worker thread are no longer needed or due to other execution changes in the system.

According to one embodiment the cellular device can improve the accuracy of the extracted pseudorange information. For example the pseudorange information processing logic can improve the accuracy of the extracted pseudorange information as will become more evident.

The output of the pseudorange information processing logic can be used for determining the location of the cellular device . For example a latitude longitude and altitude can be determined based on the output of the pseudorange information processing logic which can be displayed by the location displayer logic .

According to one embodiment the pseudorange information bridger logic communicates the output from the pseudorange information processing logic to the location manager logic in the operating system . According to one embodiment the output of the pseudorange information processing logic is a location that is defined in terms of latitude longitude and altitude. The methods are well known in the GPS arts. The pseudoranges are used to first determine a location the WGS 84 coordinate system of the Global Positioning System and then converted into latitude longitude and elevation.

The location displayer logic can display the location with respect to a digital representation of a map available for example from third parties via download to the cellular device.

Examples of satellite based augmentation system SBAS are Indian GPS aided Geo Augmented Navigation System GAGAN European Geostationary Navigation Overlay Service EGNOS Japanese Multi functional Satellite Augmentation System MSAS John Deere s StarFire WAAS and Trimble s OmniStar.

As depicted in the pseudorange information processing logic includes pseudorange correction logic pseudorange carrier phase smoothing logic position accuracy improvement determination logic B and determining position fix logic B. Examples of improving are smoothing or correcting or a combination thereof. The pseudorange correction logic includes WAAS logic A DGPS logic B Precise Point Positioning PPP logic C RTK logic D VRS Virtual Reference Station logic E and RTX logic F. The pseudorange carrier phase smoothing logic includes real carrier phase logic A and reconstructed carrier phase logic B. According to one embodiment the accessing logic B and the processing logic reside in the improved accuracy SUPL client .

Examples of pseudorange information are extracted pseudoranges corrected pseudoranges smoothed pseudoranges or a combination thereof among other things. Examples of pseudorange corrections include Wide Area Augmentation System WAAS corrections Differential Global Positioning System DGPS corrections Precise Point Positioning PPP corrections Real Time Kinematic RTK corrections and Virtual Reference Station VRS corrections. Examples of carrier phase information include real carrier phase and reconstructed carrier phase information.

The extracting logic B can extract various types of information from the GNSS chipset as discussed herein. For example the extracting logic B includes pseudorange information extracting logic WAAS extracting logic B Doppler extracting logic B and carrier phase measurement extracting logic B . According to one embodiment the extracting logic B can be used to extract these various types of information from the GNSS chipset in a similar manner that the pseudorange information extractor logic extracts pseudorange information from the GNSS chipset for example using an SUPL Client that employs a command designed or provided by the manufacturer of the GNSS chipset as described herein. More specifically the WAAS extracting logic B the Doppler extracting logic B and carrier phase measurement extracting logic B can employ commands designed or provided by the manufacturer of the GNSS chipset to extract respectively WAAS Doppler information and carrier phase measurements for real carrier phase information.

The receiving logic B receives other types of information that are not extracted from the GNSS chipset . The receiving logic B can receive the information in response to a request also commonly known as pulling or receive the information without the information being requested also commonly known as pushing . Obtaining and accessing can be used interchangeably according to various embodiments.

Table 1 depicts the types of information that are extracted from the GNSS chipset or received without extraction as discussed herein according to various embodiments.

The information depicted in the extracted column can be extracted from the GNSS chipset using the SUPL client in a manner similar to extracting pseudorange information as discussed herein. WAAS may be extracted or received for example over the Internet. When this Doppler shift information is available but real carrier phase information is not the extracted Doppler shift information can be integrated by processor for example to reconstruct carrier phase information. Techniques for reconstructing carrier phase information from Doppler shift information are well known in the art. Any one or more of the information depicted in Table 1 can be processed by the cellular device for example using the processor that is outside of the GNSS chipset .

The pseudorange carrier phase smoothing logic can smooth pseudorange information by applying carrier phase information to the pseudorange information.

The pseudorange carrier phase smoothing logic receives raw pseudorange information from the accessing logic B. The carrier phase information may be reconstructed carrier phase information or real carrier phase information.

The pseudorange correction logic can correct pseudorange information. For example the pseudorange correction logic can receive pseudorange information and apply pseudorange corrections to the pseudorange information. Examples of the pseudorange information received by the pseudorange correction logic include extracted pseudorange information DGPS corrected pseudoranges and smoothed pseudoranges that were smoothed for example using either real carrier phase information or reconstructed carrier phase information. Examples of pseudorange corrections that can be applied to the received pseudorange information are WAAS corrections DGPS corrections PPP corrections RTK corrections and VRS corrections. The PPP logic C performs Precise Point Positioning PPP processing on pseudorange information. According to one embodiment RTX is proprietary form of PPP developed by Trimble Navigation Limited. It should be appreciated that there are other forms of Precise Point Positioning which may operate using similar principles.

The pseudorange information processing logic may also include a determining position fix logic B that performs for example a least squares solution B can be performed after the extracted pseudorange information is improved by the pseudorange correction logic or the pseudorange carrier phase smoothing logic or a combination thereof and prior to transmitting the output to the pseudorange information bridger logic . According to one embodiment the determining position fix logic B resides in the processing logic . Least squares solution methods are well known in the position determination arts.

According to one embodiment extracted pseudorange information is passed from the extracting pseudorange information logic to the smoothing logic where it is smoothed at either real carrier phase logic A or reconstructed carrier phase logic B. According to one embodiment the smoothed pseudorange information is communicated from the smoothing logic to the correcting logic for further correction where one or more corrections may be performed. If a plurality of corrections is performed they can be performed in various combinations. If carrier phase smoothing is not possible the extracted pseudorange information can be communicated from extracting pseudorange information logic to correction logic . One or more of the logics A B A E F in the processing logic can communicate with any one or more of the logics A B A E F in various orders and combinations. Various embodiments are not limited to just the combinations and orders that are described herein. According to one embodiment extracted pseudorange information may not be smoothed or corrected. In this case unsmoothed uncorrected pseudorange information can be communicated from logic to logic B.

The cellular device may also include a position accuracy improvement determination logic B for determining whether to apply any improvements and if so the one or more position accuracy improvements to apply to the extracted pseudorange information. For example the cellular device may be preconfigured based on the signals that are available to the cellular device or a user of the cellular device may manually configure the cellular device . For example the cellular device can display the signals that are available to the user and the user can select which signals they desire from the displayed list of signals. The configuration information whether preconfigured or manually configured by the user can be stored for example in a look up table in the cellular device . Examples of position improvements that can be determined by the position accuracy improvement determination logic B are real carrier phase information reconstructed carrier phase information WAAS DGPS PPP RTX RTK and VRS. The position accuracy improvement determination logic B can be used to determine to reconstruct carrier phase information based on Doppler shift if real carrier phase information is not available for example. The position accuracy improvement determination logic B according to one embodiment is a part of the SUPL client .

Extracted pseudorange information without any additional improvements provides 4 5 meters of accuracy. Various combinations of position accuracy improvements can be applied to extracted pseudorange information EPI according to various embodiments where examples of position accuracy improvements include but are not limited to Wide Area Augmentation System WAAS pseudorange corrections Differential GPS DGPS pseudorange corrections Precise Point Positioning PPP processing RTX Real Time Kinematic RTK Virtual Reference Station VRS corrections real carrier phase information real CPI smoothing and reconstructed carrier phase information reconstructed CPI smoothing.

One or more of the logics B B B B B B A B Aj F B B can be executed for example by the processor of the cellular device that is located outside of the GNSS chipset .

Table 2 depicts combinations of information that result in a position fix B according to various embodiments. However various embodiments are not limited to the combinations depicted in Table 2.

According to one embodiment a first position is determined by an available means. For example the first position may be based on uncorrected unsmoothed extracted pseudorange information cellular tower triangulation WiFi triangulation or other means. A level of precision may be selected for example by a user or preconfigured into the cellular device where DGPS or one or more of SBAS WAAS RTX PPP would be used to achieve that level of precision. The decision logic H can access the level of precision and receive two or more reference station locations by sending a message to a database enquiring about nearby reference stations for DGPS. The decision logic H can determine the distance between the cellular device and the nearest reference station. If the distance is greater than some selected distance threshold the decision logic H can use PPP RTX SBAS or WAAS instead of DGPS. If the distance is less than the selected distance threshold the decision logic H can use DGPS instead of PPP RTX SBAS or WAAS. According to one embodiment a range for a distance threshold is approximately 20 to 60 miles. According to one embodiment the distance threshold is approximately 60 miles.

If the decision logic H determines to apply DGPS corrections at DGPS logic B resulting in DGPS corrected smoothed pseudoranges further corrections can be made using the orbit clock information contained in the PPP corrections. For example a position fix can be determined based on the DGPS corrected smoothed pseudoranges and the PPP corrections. The position fix can be determined external to the GNSS chipset for example at the processing logic .

The cellular device may be configured with the distance threshold for example by the manufacturer of the cellular device or by a user of the cellular device . The cellular device may be configured with the distance threshold through service that is remote with respect to the cellular device or may be configured locally. The distance threshold can be selected based on a degree of position accuracy that is desired.

As described herein various information can be extracted from the GNSS receiver such as pseudorange information Doppler Shift Information Real Carrier Phase Measurement WAAS and SBAS. Other types of processing information output by the GNSS receiver can be ignored.

A Cell device D s hardware architecture includes discreet physical layout and interconnection of multiple chipsets for processing and for special purposes such as a GNSS chipset . In addition newer architectures involve further integration of chipsets in the system on a chip SoC configuration. In this configuration the GNSS chipset can still be a complete element capable of delivering a PVT position velocity and time solution. However in an embodiment the pseudorange information carrier phase and or Doppler measurements along with WAAS corrections if available are extracted prior to further signal processing in the GNSS chipset and are processed using different algorithms and corrections data for developing an improved accuracy PVT solution. In so doing the deleterious effects of multipath and other error sources may be minimized. Further the GNSS chipset outputs are ignored and not displayed when the external processing is employed and the higher accuracy PVT data is available.

The cellular device includes a bus a satellite receiver a GNSS receiver an FM radio receiver a processor memory a cellular transceiver a display audio Wi Fi transceiver IMU image capturing device and operating system . Components and are all connected with the buss .

In a plurality of broadcast sources is used to convey data and media to a cellular device . As an example cellular device can receive broadcast signals from communication satellites e.g. two way radio satellite based cellular such as the Inmarsat or Iridium communication networks etc. global navigation satellites which provide radio navigation signals e.g. the GPS GNSS GLONASS GALILEO BeiDou Compass etc. and terrestrial radio broadcast e.g. FM radio AM radio shortwave radio etc. 

A cellular device can be configured with a satellite radio receiver coupled with a communication bus for receiving signals from communication satellites a GNSS receiver coupled with bus for receiving radio navigation signals from global navigation satellites and for deriving a position of cellular device based thereon. Cellular device further comprises an FM radio receiver coupled with bus for receiving broadcast signals from terrestrial radio broadcast . Other components of cellular device comprise a processor coupled with bus for processing information and instructions a memory coupled with bus for storing information and instructions for processor . It is noted that memory can comprise volatile memory and non volatile memory as well as removable data storage media in accordance with various embodiments. Cellular device further comprises a cellular transceiver coupled with bus for communicating via cellular network . Examples of cellular networks used by cellular device include but are not limited to GSM cellular networks GPRS cellular networks GDMA cellular networks and EDGE cellular networks. Cellular device further comprises a display coupled with bus . Examples of devices which can be used as display include but are not limited to liquid crystal displays LED based displays and the like. It is noted that display can be configured as a touch screen device e.g. a capacitive touch screen display for receiving inputs from a user as well as displaying data. Cellular device further comprises an audio output coupled with bus for conveying audio information to a user. Cellular device further comprises a Wi Fi transceiver and an inertial measurement unit IMU coupled with bus . Wi Fi transceiver may be configured to operate on any suitable wireless communication protocol including but not limited to WiFi WiMAX implementations of the IEEE 802.11 specification implementations of the IEEE 802.15.4 specification for personal area networks and a short range wireless connection operating in the Instrument Scientific and Medical ISM band of the radio frequency spectrum in the 2400 2484 MHz range e.g. implementations of the Bluetooth standard .

Improvements in GNSS GPS positioning may be obtained by using reference stations with a fixed receiver system to calculate corrections to the measured pseudoranges in a given geographical region. Since the reference station is located in a fixed environment and its location can be determined very precisely via ordinary survey methods a processor associated with the Reference Station GNSS GPS receivers can determine more precisely what the true pseudoranges should be to each satellite in view based on geometrical considerations. Knowing the orbital positions via the GPS almanac as a function of time enables this process first proposed in 1983 and widely adopted ever since. The difference between the observed pseudorange and the calculated pseudorange for a given Reference station is called the pseudorange correction. A set of corrections for all the global navigation satellites in view is created second by second and stored and made available as a service utilizing GPS GNSS reference stations and correction services . The pseudoranges at both the cellular device GPS receiver and those at the reference stations are time tagged so the corrections for each and every pseudorange measurement can be matched to the local cell phone pseudoranges. The overall service is often referred to as Differential GPS or DGPS. Without any corrections GNSS GPS receivers produce position fixes with absolute errors in position on the order of 4.5 to 5.5 m per the GPS SPS Performance Standard 4Ed. 2008. In one or more correction services convey these corrections via a cellular network or the Internet . Internet is in turn coupled with a local Wi Fi network which can convey the corrections to cellular device via Wi Fi transceiver . Alternatively cellular network can convey the corrections to cellular device via cellular transceiver . In some embodiments correction services are also coupled with a distribution service which conveys the corrections to an FM radio distributor . FM radio distributor can broadcast corrections as a terrestrial radio broadcast . It should be appreciated that an FM signal is being described as a subset of possible terrestrial radio broadcasts which may be in a variety of bands and modulated in a variety of manners. In some embodiments cellular device includes one or more integral terrestrial radio antennas associated with integrated terrestrial receivers FM radio receiver is one example of such a terrestrial receiver which would employ an integrated antenna designed to operate in the correct frequency band for receiving a terrestrial radio broadcast . In this manner in some embodiments cellular device can receive the corrections via FM radio receiver or other applicable type of integrated terrestrial radio receiver . In some embodiments correction services are also coupled with a distribution service which conveys the corrections to a satellite radio distributor . Satellite radio distributor can broadcast corrections as a broadcast from one or more communications satellites . In some embodiments cellular device includes one or more integral satellite radio antennas associated with integrated satellite radio receivers . Satellite radio receiver is one example of such a satellite receiver which would employ an integrated antenna designed to operate in the correct frequency band for receiving a corrections or other information broadcast from communication satellites . In this manner in some embodiments cellular device can receive the corrections via satellite radio receiver .

Examples of a correction source that provides pseudorange corrections are at least correction service FM radio distribution or satellite radio distributor or a combination thereof. According to one embodiment a correction source is located outside of the cellular device .

Examples of image capturing device are a camera a video camera a digital camera a digital video camera a digital camcorder a stereo digital camera a stereo video camera a motion picture camera and a television camera. The image capturing device may use a lens or be a pinhole type device.

The blocks that represent features in can be arranged differently than as illustrated and can implement additional or fewer features than what are described herein. Further the features represented by the blocks in can be combined in various ways. A cellular device can be implemented using software hardware hardware and software hardware and firmware or a combination thereof. Further unless specified otherwise various embodiments that are described as being a part of the cellular device whether depicted as a part of the cellular device or not can be implemented using software hardware hardware and software hardware and firmware software and firmware or a combination thereof. Various blocks in refer to features that are logic such as but not limited to B A B A G B which can be implemented using software hardware hardware and software hardware and firmware software and firmware or a combination thereof.

The cellular device according to one embodiment includes hardware such as the processor memory and the GNSS chipset . An example of hardware memory is a physically tangible computer readable storage medium such as but not limited to a disk a compact disk CD a digital versatile device DVD random access memory RAM or read only memory ROM for storing instructions. An example of a hardware processor for executing instructions is a central processing unit. Examples of instructions are computer readable instructions for implementing at least the SUPL Client that can be stored on a hardware memory and that can be executed for example by the hardware processor . The SUPL client may be implemented as computer readable instructions firmware or hardware such as circuitry or a combination thereof.

A GNSS receiver also referred to as a receiver according to various embodiments makes a basic measurement that is the apparent transit time of the signal from a satellite to the receiver which can be defined as the difference between signal reception time as determined by the receiver s clock and the transmission time at the satellite as marked in the signal. This basic measurement can be measured as the amount of time shift required to align the C A code replica generated at the receiver with the signal received from the satellite. This measurement may be biased due to a lack of synchronization between the satellite and receiver clock because each keeps time independently. Each satellite generates a respective signal in accordance using a clock on board. The receiver generates a replica of each signal using its own clock. The corresponding biased range also known as a pseudorange can be defined as the transit time so measured multiplied by the speed of light in a vacuum.

There are three time scales according to one embodiment. Two of the time scales are the times kept by the satellite and receiver clocks. A third time scale is a common time reference GPS Time GPST also known as a composite time scale that can be derived from the times kept by clocks at GPS monitor stations and aboard the satellites.

Let be the transit time associated with a specific code transition of the signal from a satellite received at time t per GPST. The measured apparent range r called pseudorange can be determined from the apparent transmit time using equation 1 as follows measured pseudorange at arrival time at emission time at . Eq. 1 Both t and are unknown and can be estimated. In this discussion of pseudoranges measurements from a GPS satellite are dealt with in a generic way to make the notation simple making no reference to the satellite ID or carrier frequency L or L .

Equations 2 and 3 depict how to relate the time scales of the receiver and the satellite clocks with GPST arrival time at receiver clock at Eq. 2 arrival time at satellite clock error at Eq. 3 

where receiver clock error represents the receiver s clock bias and satellite clock error represents the bias in the satellite s clock and both the receiver clock and the satellite clock are measured relative to GPST as shown in . Receiver clock error and satellite clock error represent the amounts by which the satellite and receiver clocks are advanced in relation to GPST. The satellite clock error is estimated by the Control Segment and specified in terms of the coefficients of a quadratic polynomial in time. The values of these coefficients can be broadcast in the navigation message.

Accounting for the clock biases the measured pseudorange Eq. 1 can be written as indicated in equation 4 receiver clock error at satellite clock error at miscellaneous errors at receiver clock errors at satellite clock error at miscellaneous errors at Eq. 4 where miscellaneous errors represent unmodeled effects modeling error and measurement error. The transmit time multiplied by the speed of light in a vacuum can be modeled as satellite position at t . Ionosphere error and troposphere error reflect the delays associated with the transmission of the signal respectively through the ionosphere and the troposphere. Both ionosphere error and troposphere error are positive.

For simplicity explicitly reference to the measurement epoch t has been dropped and the model has been rewritten for the measured pseudorange as indicated in equation 5. receiver clock error satellite clock error ionosphere error troposphere error miscellaneous errors Eq. 5 where PR is the measured pseudorange r is the true range from the receiver to the satellite receiver clock error is the difference between the receiver clock and the GPSTIME satellite clock error is the difference between the satellite clock and GPSTIME GPSTIME is ultimately determined at the receiver as part of the least squared solution determined by the least squares solution B so that all clock errors can be resolved to some level of accuracy as part of the position determination process and miscellaneous errors include receiver noise multipath and the like.

At least one source of error is associated with satellite positions in space. The navigation message in the GPS signal contains Keplerian parameters which define orbital mechanics mathematics and thus the positions of the satellites as a function of time. One component of WAAS and RTX contains adjustments to these parameters which form part of the constants used in solving for the position fix at a given time. Taking account of the corrections is well known in the GPS position determining arts.

Ideally the true range r to the satellite is measured. Instead what is available is PR the pseudorange which is a biased and noisy measurement of r. The accuracy of an estimated position velocity or time which is obtained from these measurements depends upon the ability to compensate for or eliminate the biases and errors.

The range to a satellite is approximately 20 000 kilometers km when the satellite is overhead and approximately 26 000 km when the satellite is rising or setting. The signal transit time varies between about 70 millisecond ms and 90 ms. The C A code repeats each millisecond and the code correlation process essentially provides a measurement of pseudo transmit time modulo 1 ms. The measurement can be ambiguous in whole milliseconds. This ambiguity however is easily resolved if the user has a rough idea of his location within hundreds of kilometers. The week long P Y code provides unambiguous pseudoranges.

The receiver clocks are generally basic quartz crystal oscillators and tend to drift. The receiver manufacturers attempt to limit the deviation of the receiver clock from GPST and schedule the typical once per second measurements at epochs that are within plus or minus 1 millisecond ms of the GPST seconds. One approach to maintaining the receiver clock within a certain range of GPST is to steer the receiver clock continuously. The steering can be implemented with software. The second approach is to let the clock drift until it reaches a certain threshold typically 1 ms and then reset it with a jump to return the bias to zero.

An example of pseudorange measurements with a receiver using the second approach shall now be described in more detail. Assume that there are pseudorange measurements from three satellites which rose about the same time but were in different orbits. Assume that one comes overhead and stays in view for almost seven hours. Assume that the other two stay lower in the sky and could be seen for shorter periods. There are discontinuities common to all three sets of measurements due to the resetting of the receiver clock. A determination can be made as to whether the receiver clock is running fast or slow and its frequency offset from the nominal value of 10.23 megahertz MHz can be estimated.

For more information on pseudorange information refer to Global Positioning Systems by Pratap Misra and Per Eng Ganga Jamuna Press 2001 ISBN 0 9709544 0 9.

The pseudorange information processing logic can include various types of logic for improving the position accuracy of the extracted pseudorange information as described herein. Table 2 as described herein depicts various combinations of position accuracy improvements for improving extracted pseudorange information according to various embodiments. Table 3 also depicts various combinations of position accuracy improvements for improving extracted pseudorange information according to various embodiments.

Table 3 includes columns for combination identifier operation description and accuracy. The combination identifier column indicates an identifier for each combination of improvements. The operation column specifies operations of various flowcharts in for the corresponding combination. The description column specifies various combinations of position accuracy improvements that can be applied to extracted pseudorange information EPI according to various embodiments where examples of position accuracy improvements include but are not limited to Wide Area Augmentation System WAAS pseudorange corrections real carrier phase smoothing real CPI information reconstructed carrier phase smoothing information reconstructed CPI Differential GPS DGPS pseudorange corrections and Precise Point Positioning PPP processing. The accuracy column specifies levels of accuracy provided by the corresponding combination.

Combination 1 is extracted pseudorange information without any additional improvements which provides 4 5 meters of accuracy. Combination 1 is described in Table 3 to provide a comparison with the other combinations 2 13.

According to one embodiment the SUPL client can also include a position accuracy improvement determination logic B for determining the one or more position accuracy improvements to apply to the extracted pseudorange information based on one or more factors such as cost quality of service and one or more characteristics of the cellular device. For example different costs are associated with different position accuracy improvements. More specifically extracted pseudorange information WAAS and Doppler information are typically free. There is a low cost typically associated with DGPS and real carrier phase information. There is typically a higher cost associated with PPP. Therefore referring to Table 3 according to one embodiment combinations 1 2 and 3 are typically free combinations 4 7 typically are low cost and combinations 8 12 are typically higher cost.

Various cellular devices have different characteristics that make them capable of providing different types of position accuracy improvements. For example one type of cellular device may be capable of providing WAAS but not be capable of providing Doppler information. In another example some types of cellular devices may be capable of providing DGPS but not capable of providing PPP. In yet another example different activities may require different levels of improvement. For example some activities and or people may be satisfied with 4 5 meters others may be satisfied with 1.7 meters. Yet others may be satisfied with less than 1 meter and still others may only be satisfied with 2 centimeters. Therefore different users may request different levels of accuracy.

Table 4 depicts sources of the various position accuracy improvements according to various embodiments.

The first column of Table 4 provides the name of the position accuracy improvement. The second column of Table 4 specifies the source for the corresponding position accuracy improvement.

According to various embodiments a cellular device can initially provide a position that is within 4 5 meters using for example unimproved extracted pseudorange information and the position can continually be improved using various position accuracy improvements as described herein as long as the antennae of the cellular device is clear of obstructions to receive various position accuracy improvements.

A Global Navigation Satellite System GNSS is a navigation system that makes use of a constellation of satellites orbiting the earth to provide signals to a receiver such as GNSS receiver which estimates its position relative to the earth from those signals. Examples of such satellite systems are the NAVSTAR Global Positioning System GPS deployed and maintained by the United States the GLObal NAvigation Satellite System GLONASS deployed by the Soviet Union and maintained by the Russian Federation and the GALILEO system currently being deployed by the European Union EU .

Each GPS satellite transmits continuously using two radio frequencies in the L band referred to as L and L at respective frequencies of 1575.41 MHz and 1227.60 MHz. Two signals are transmitted on L one for civil users and the other for users authorized by the Unites States Department of Defense DoD . One signal is transmitted on L intended only for DoD authorized users. Each GPS signal has a carrier at the L and L frequencies a pseudo random number PRN code and satellite navigation data.

Two different PRN codes are transmitted by each satellite A coarse acquisition C A code and a precision P Y code which is encrypted for use by authorized users. A receiver such as GNSS receiver designed for precision positioning contains multiple channels each of which can track the signals on both L and L frequencies from a GPS satellite in view above the horizon at the receiver antenna and from these computes the observables for that satellite comprising the L pseudorange possibly the L pseudorange and the coherent L and L carrier phases. Coherent phase tracking implies that the carrier phases from two channels assigned to the same satellite and frequency will differ only by an integer number of cycles.

Each GLONASS satellite transmits continuously using two radio frequency bands in the L band also referred to as L and L. Each satellite transmits on one of multiple frequencies within the L and L bands respectively centered at frequencies of 1602.0 MHz and 1246.0 MHz. The code and carrier signal structure is similar to that of NAVSTAR. A GNSS receiver designed for precision positioning contains multiple channels each of which can track the signals from both GPS and GLONASS satellites on their respective L and L frequencies and generate pseudorange and carrier phase observables from these. Future generations of GNSS receivers will include the ability to track signals from all deployed GNSSs.

Differential GPS DGPS utilizes a reference station which is located at a surveyed position to gather data and deduce corrections for the various error contributions which reduce the precision of determining a position fix. For example as the GPS signals pass through the ionosphere and troposphere propagation delays may occur. Other factors which may reduce the precision of determining a position fix may include satellite clock errors GPS receiver clock errors and satellite position errors ephemerides . The reference station receives essentially the same GPS signals as cellular devices which may also be operating in the area. However instead of using the timing signals from the GPS satellites to calculate its position it uses its known position to calculate timing. In other words the reference station determines what the timing signals from the GPS satellites should be in order to calculate the position at which the reference station is known to be. The difference in timing can be expressed in terms of pseudorange lengths in meters. The difference between the received GPS signals and what they optimally should be is used as an error correction factor for other GPS receivers in the area. Typically the reference station broadcasts the error correction to for example a cellular device which uses this data to determine its position more precisely. Alternatively the error corrections may be stored for later retrieval and correction via post processing techniques.

DGPS corrections cover errors caused by satellite clocks ephemeris and the atmosphere in the form of ionosphere errors and troposphere errors. The nearer a DGPS reference station is to the receiver the more useful the DGPS corrections from that reference station will be.

The system is called DGPS when GPS is the only constellation used for Differential GNSS. DGPS provides an accuracy on the order of 1 meter or 1 sigma for users in a range that is approximately in a few tens of kilometers kms from the reference station and growing at the rate of 1 m per 150 km of separation. DGPS is one type of Differential GNSS DGNSS technique. There are other types of DGNSS techniques such as RTK and Wide Area RTK WARTK that can be used by high precision applications for navigation or surveying that can be based on using carrier phase measurements. It should be appreciated that other DGNSS which may utilize signals from other constellations besides the GPS constellation or from combinations of constellations. Embodiments described herein may be employed with other DGNSS techniques besides DGPS.

A variety of different techniques may be used to deliver differential corrections that are used for DGNSS techniques. In one example DGNSS corrections are broadcast over an FM subcarrier. U.S. Pat. No. 5 477 228 by Tiwari et al. describes a system for delivering differential corrections via FM subcarrier broadcast method.

An improvement to DGPS methods is referred to as Real time Kinematic RTK . As in the DGPS method the RTK method utilizes a reference station located at determined or surveyed point. The reference station collects data from the same set of satellites in view by the cellular device in the area. Measurements of GPS signal errors taken at the reference station e.g. dual frequency code and carrier phase signal errors and broadcast to one or more cellular devices working in the area. The one or more cellular devices combine the reference station data with locally collected position measurements to estimate local carrier phase ambiguities thus allowing a more precise determination of the cellular device s position. The RTK method is different from DGPS methods in that the vector from a reference station to a cellular device is determined e.g. using the double differences method . In DGPS methods reference stations are used to calculate the changes needed in each pseudorange for a given satellite in view of the reference station and the cellular device to correct for the various error contributions. Thus DGPS systems broadcast pseudorange correction numbers second by second for each satellite in view or store the data for later retrieval as described above.

RTK allows surveyors to determine a true surveyed data point in real time while taking the data. However the range of useful corrections with a single reference station is typically limited to about 70 km because the variable in propagation delay increase in apparent path length from satellite to a receiver of the cellular device or pseudo range changes significantly for separation distances beyond 70 km. This is because the ionosphere is typically not homogeneous in its density of electrons and because the electron density may change based on for example the sun s position and therefore time of day.

Thus for surveying or other positioning systems which must work over larger regions the surveyor must either place additional base stations in the regions of interest or move his base stations from place to place. This range limitation has led to the development of more complex enhancements that have superseded the normal RTK operations described above and in some cases eliminated the need for a base station GPS receiver altogether. This enhancement is referred to as the Network RTK or Virtual Reference Station VRS system and method.

Network RTK typically uses three or more GPS reference stations to collect GPS data and extract information about the atmospheric and satellite ephemeris errors affecting signals within the network coverage region. Data from all the various reference stations is transmitted to a central processing facility or control center for Network RTK. Suitable software at the control center processes the reference station data to infer how atmospheric and or satellite ephemeris errors vary over the region covered by the network.

The control center computer processor then applies a process which interpolates the atmospheric and or satellite ephemeris errors at any given point within the network coverage area and generates a pseudo range correction comprising the actual pseudo ranges that can be used to create a virtual reference station. The control center then performs a series of calculations and creates a set of correction models that provide the cellular device with the means to estimate the ionospheric path delay from each satellite in view from the cellular device and to take account other error contributions for those same satellites at the current instant in time for the cellular device s location.

The cellular device is configured to couple a data capable cellular telephone to its internal signal processing system. The user operating the cellular device determines that he needs to activate the VRS process and initiates a call to the control center to make a connection with the processing computer.

The cellular device sends its approximate position based on raw GPS data from the satellites in view without any corrections to the control center. Typically this approximate position is accurate to approximately 4 7 meters. The user then requests a set of modeled observables for the specific location of the cellular device . The control center performs a series of calculations and creates a set of correction models that provide the cellular device with the means to estimate the ionospheric path delay from each satellite in view from the cellular device and to take into account other error contributions for those same satellites at the current instant in time for the cellular device s location. In other words the corrections for a specific cellular device at a specific location are determined on command by the central processor at the control center and a corrected data stream is sent from the control center to the cellular device . Alternatively the control center may instead send atmospheric and ephemeris corrections to the cellular device which then uses that information to determine its position more precisely.

These corrections are now sufficiently precise that the high performance position accuracy standard of 2 3 cm may be determined in real time for any arbitrary cellular device s position. Thus a GPS enabled cellular device s raw GPS data fix can be corrected to a degree that makes it behave as if it were a surveyed reference location hence the terminology virtual reference station. 

An example of a network RTK system in accordance with embodiments of the present invention is described in U.S. Pat. No. 5 899 957 entitled Carrier Phase Differential GPS Corrections Network by Peter Loomis assigned to the assignee of the present invention.

The Virtual Reference Station method extends the allowable distance from any reference station to the cellular devices . Reference stations may now be located hundreds of miles apart and corrections can be generated for any point within an area surrounded by reference stations. However there are many construction projects where cellular coverage is not available over the entire physical area under construction and survey.

To achieve very accurate positioning to several centimeters or less of a terrestrial mobile platform of a cellular device relative or differential positioning methods are commonly employed. These methods use a GNSS reference receiver located at a known position in addition to the data from a GNSS receiver on the mobile platform to compute the estimated position of the mobile platform relative to the reference receiver.

The most accurate known method uses relative GNSS carrier phase interferometry between the GNSS cellular device s receiver and GNSS reference receiver antennas plus resolution of integer wavelength ambiguities in the differential phases to achieve centimeter level positioning accuracies. These differential GNSS methods are predicated on the near exact correlation of several common errors in the cellular device and reference observables. They include ionosphere and troposphere signal delay errors satellite orbit and clock errors and receiver clock errors.

When the baseline length between the mobile platform and the reference receiver does not exceed 10 kilometers which is normally considered a short baseline condition the ionosphere and troposphere signal delay errors in the observables from the cellular device and reference receivers are almost exactly the same. These atmospheric delay errors therefore cancel in the cellular device s reference differential GNSS observables and the carrier phase ambiguity resolution process required for achieving centimeter level relative positioning accuracy is not perturbed by them. If the baseline length increases beyond 10 kilometers considered a long baseline condition these errors at the cellular device and reference receiver antennas become increasingly different so that their presence in the cellular device s reference differential GNSS observables and their influence on the ambiguity resolution process increases. Ambiguity resolution on single cellular device s reference receiver baselines beyond 10 kilometers becomes increasingly unreliable. This attribute limits the precise resolution of a mobile platform with respect to a single reference receiver and essentially makes it unusable on a mobile mapping platform that covers large distances as part of its mission such as an aircraft.

A network GNSS method computes the estimated position of a cellular device s receiver using reference observables from three or more reference receivers that approximately surround the cellular device s receiver trajectory. This implies that the cellular device s receiver trajectory is mostly contained by a closed polygon whose vertices are the reference receiver antennas. The cellular device s receiver can move a few kilometers outside this polygon without significant loss of positioning accuracy. A network GNSS algorithm calibrates the ionosphere and troposphere signal delays at each reference receiver position and then interpolates and possibly extrapolates these to the cellular device s position to achieve better signal delay cancellation on long baselines than could be had with a single reference receiver. Various methods of signal processing can be used however they all yield essentially the same performance improvement on long baselines.

Kinematic ambiguity resolution KAR satellite navigation is a technique used in numerous applications requiring high position accuracy. KAR is based on the use of carrier phase measurements of satellite positioning system signals where a single reference station provides the real time corrections with high accuracy. KAR combines the L and L carrier phases from the cellular device and reference receivers so as to establish a relative phase interferometry position of the cellular device s antenna with respect to the reference antenna. A coherent L or L carrier phase observable can be represented as a precise pseudorange scaled by the carrier wavelength and biased by an integer number of unknown cycles known as cycle ambiguities. Differential combinations of carrier phases from the cellular device and reference receivers result in the cancellation of all common mode range errors except the integer ambiguities. An ambiguity resolution algorithm uses redundant carrier phase observables from the cellular device and reference receivers and the known reference antenna position to estimate and thereby resolve these ambiguities.

Once the integer cycle ambiguities are known the cellular device s receiver can compute its antenna position with accuracies generally on the order of a few centimeters provided that the cellular device and reference antennas are not separated by more than 10 kilometers. This method of precise positioning performed in real time is commonly referred to as real time kinematic RTK positioning. The separation between a cellular device and reference antennas shall be referred to as cellular device reference separation. 

The reason for the cellular device reference separation constraint is that KAR positioning relies on near exact correlation of atmospheric signal delay errors between the cellular device and reference receiver observables so that they cancel in the cellular device s reference observables combinations for example differences between cellular device and reference observables per satellite . The largest error in carrier phase positioning solutions is introduced by the ionosphere a layer of charged gases surrounding the earth. When the signals radiated from the satellites penetrate the ionosphere on their way to the ground based receivers they experience delays in their signal travel times and shifts in their carrier phases. A second significant source of error is the troposphere delay. When the signals radiated from the satellites penetrate the troposphere on their way to the ground based receivers they experience delays in their signal travel times that are dependent on the temperature pressure and humidity of the atmosphere along the signal paths. Fast and reliable positioning requires good models of the spatio temporal correlations of the ionosphere and troposphere to correct for these non geometric influences.

When the cellular device reference separation exceeds 10 kilometers as maybe the case when the cellular device has a GNSS receiver that is a LEO satellite receiver the atmospheric delay errors become de correlated and do not cancel exactly. The residual errors can now interfere with the ambiguity resolution process and thereby make correct ambiguity resolution and precise positioning less reliable.

The cellular device s reference separation constraint has made KAR positioning with a single reference receiver unsuitable for certain mobile positioning applications where the mission of the mobile platform of the cellular device will typically exceed this constraint. One solution is to set up multiple reference receivers along the mobile platform s path so that at least one reference receiver falls within a 10 km radius of the mobile platform s estimated position.

Network GNSS methods using multiple reference stations of known location allow correction terms to be extracted from the signal measurements. Those corrections can be interpolated to all locations within the network. Network KAR is a technique that can achieve centimeter level positioning accuracy on large project areas using a network of reference GNSS receivers. This technique operated in real time is commonly referred to as network RTK. The network KAR algorithm combines the pseudorange and carrier phase observables from the reference receivers as well as their known positions to compute calibrated spatial and temporal models of the ionosphere and troposphere signal delays over the project area. These calibrated models provide corrections to the observables from the cellular device s receiver so that the cellular device s receiver can perform reliable ambiguity resolution on combinations of carrier phase observables from the cellular device and some or all reference receivers. The number of reference receivers required to instrument a large project area is significantly less than what would be required to compute reliable single baseline KAR solutions at any point in the project area. See for example U.S. Pat. No. 5 477 458 Network for Carrier Phase Differential GPS Corrections and U.S. Pat. No. 5 899 957 Carrier Phase Differential GPS Corrections Network . See also Liwen Dai et al. Comparison of Interpolation Algorithms in Network Based GPS Techniques Journal of the Institute of Navigation Vol. 50 No. 4 Winter 1003 1004 for a comparison of different network GNSS implementations and comparisons of their respective performances.

A virtual reference station VRS network method is a particular implementation of a network GNSS method that is characterized by the method by which it computes corrective data for the purpose of cellular device s position accuracy improvement. A VRS network method comprises a VRS corrections generator and a single baseline differential GNSS position generator such as a GNSS receiver with differential GNSS capability. The VRS corrections generator has as input data the pseudorange and carrier phase observables on two or more frequencies from N reference receivers each tracking signals from M GNSS satellites. The VRS corrections generator outputs a single set of M pseudorange and carrier phase observables that appear to originate from a virtual reference receiver at a specified position hereafter called the VRS position within the boundaries of the network defined by a polygon or projected polygon having all or some of the N reference receivers as vertices. The dominant observables errors comprising a receiver clock error satellite clock errors ionosphere and troposphere signal delay errors and noise all appear to be consistent with the VRS position. The single baseline differential GNSS position generator implements a single baseline differential GNSS position algorithm of which numerous examples have been described in the literature. B. Hofmann Wellenhof et al. Global Positioning System Theory and Practice 5th Edition 1001 hereinafter Hofmann Wellenhof 1001 gives comprehensive descriptions of different methods of differential GNSS position computation ranging in accuracies from one meter to a few centimeters. The single baseline differential GNSS position algorithm typically computes differences between the cellular device and reference receiver observables to cancel atmospheric delay errors and other common mode errors such as orbital and satellite clock errors. The VRS position is usually specified to be close to or the same as the roving receiver s estimated position so that the actual atmospheric errors in the cellular device receiver s observables approximately cancel the estimated atmospheric errors in the VRS observables in the cellular device s reference observables differences.

The VRS corrections generator computes the synthetic observables at each sampling epoch typically once per second from the geometric ranges between the VRS position and the M satellite positions as computed using well known algorithms such as those given in IS GPS 200G interface specification tilted Naystar GPS Space Segment Navigation User Interfaces and dated 5 Sep. 2012. It estimates the typical pseudorange and phase errors comprising receiver clock error satellite clock errors ionospheric and tropospheric signal delay errors and noise applicable at the VRS position from the N sets of M observables generated by the reference receivers and adds these to the synthetic observables.

A network RTK system operated in real time requires each GNSS reference receiver to transmit its observables to a network server computer that computes and transmits the corrections and other relevant data to the GNSS cellular device s receiver . The GNSS reference receivers plus hardware to assemble and broadcast observables are typically designed for this purpose and are installed specifically for the purpose of implementing the network. Consequently those receivers are called dedicated network reference receivers.

An example of a VRS network is designed and manufactured by Trimble Navigation Limited of Sunnyvale Calif. The VRS network as delivered by Trimble includes a number of dedicated reference stations a VRS server multiple server reference receiver bi directional communication channels and multiple server cellular device bi directional data communication channels. Each server cellular device bi directional communication channel serves one cellular device . The reference stations provide their observables to the VRS server via the server reference receiver bi directional communication channels. These channels can be implemented by a public network such as the Internet. The bi directional server cellular device communication channels can be radio modems or cellular telephone links depending on the location of the server with respect to the cellular device .

The VRS server combines the observables from the dedicated reference receivers to compute a set of synthetic observables at the VRS position and broadcasts these plus the VRS position in a standard differential GNSS DGNSS message format such as one of the RTCM Radio Technical Commission for Maritime Services formats an RTCA Radio Technical Commission for Aeronautics format or a proprietary format such as the CMR Compact Measurement Report or CMR format which are messaging system communication formats employed by Trimble Navigation Limited. Descriptions for numerous of such formats are widely available. For example RTCM Standard 10403.1 for DGNSS Services Version 3 published Oct. 26 2006 and Amendment 2 to the same published Aug. 31 2007 is available from the Radio Technical Commission for Maritime Services 1800 N. Kent St. Suite 1060 Arlington Va. 22209. The synthetic observables are the observables that a reference receiver located at the VRS position would measure. The VRS position is selected to be close to the cellular device s estimated position so that the cellular device s VRS separation is less than a maximum separation considered acceptable for the application. Consequently the cellular device receiver must periodically transmit its approximate position to the VRS server. The main reason for this particular implementation of a real time network RTK system is compatibility with RTK survey GNSS receivers that are designed to operate with a single reference receiver.

Descriptions of the VRS technique are provided in U.S. Pat. No. 6 324 473 of hereinafter Eschenbach see particularly col. 7 line 21 et seq. and U.S. Patent application publication no. 2005 0064878 of B. O Meagher hereinafter O Meagher which are assigned to Trimble Navigation Limited and in H. Landau et al. Virtual Reference Stations versus Broadcast Solutions in Network RTK GNSS 2003 Proceedings Graz Austria 2003 .

The term VRS as used henceforth in this document is used as shorthand to refer to any system or technique which has the characteristics and functionality of VRS described or referenced herein and is not necessarily limited to a system from Trimble Navigation Ltd. Hence the term VRS is used in this document merely to facilitate description and is used without derogation to any trademark rights of Trimble Navigation Ltd. or any subsidiary thereof or other related entity.

Descriptions of a Precise Point Positioning PPP technique are provided in U.S. Patent application publication 20110187590 of Leandro which is assigned to Trimble Navigation Limited. Trimble Navigation Limited has commercialized a version of PPP corrections which it calls RTX . PPP corrections can be any collection of data that provides corrections from a satellite in space clock errors ionosphere or troposphere or a combination thereof. According to one embodiment PPP corrections can be used in instead of WAAS or RTX .

The term Precise Point Positioning PPP as used henceforth in this document is used as shorthand to refer to any system or technique which has the characteristics and functionality of PPP described or referenced herein and is not necessarily limited to a system from Trimble Navigation Ltd. Hence the term PPP is used in this document merely to facilitate description and is used without derogation to any trademark rights of Trimble Navigation Ltd. or any subsidiary thereof or other related entity. Techniques for generating PPP corrections are well known in the art. In general a PPP system utilizes a network which may be global of GNSS reference receivers tracking navigation satellites such as GPS and GLONASS satellites and feeding data back to a centralized location for processing. At the centralized location the precise orbits and precise clocks of all of the tracked navigation satellites are generated and updated in real time. A correction stream is produced by the central location the correction stream contains the orbit and clock information. This correction stream is broadcast or otherwise provided to GNSS receivers such as a GNSS receiver in the field conventionally by satellite service or cellular link Corrections processors in the GNSS receivers utilize the corrections to produce centimeter level positions after a short convergence time e.g. less than 30 minutes . A main difference between PPP and VRS is that PPP networks of reference receivers are typically global while VRS networks may be regional or localized with shorter spacing between the reference stations in a VRS network.

Wide Area Augmentation System WAAS corrections are corrections of satellite position and their behavior. WAAS was developed by the Federal Aviation Administration FAA . WAAS includes a network of reference stations that are on the ground located in North America and Hawaii. The reference stations transmit their respective measurements to master stations which queue their respective received measurements. The master stations transmit WAAS corrections to geostationary WAAS satellites which in turn broadcast the WAAS corrections back to earth where cellular devices that include WAAS enabled GPS receivers can receive the broadcasted WAAS corrections. According to one embodiment the GNSS receiver is a WAAS enabled GPS receiver. The WAAS corrections can be used to improve the accuracy of the respective cellular devices positions for example by applying the WAAS corrections to extracted pseudoranges. WAAS operation and implementation is well known in the art.

According to one embodiment a GNSS chipset provides real carrier phase information also referred to as actual carrier phase information . The cellular device can extract real carrier phase information from the GNSS chipset in a manner similar to extracting pseudorange information from the GNSS chipset where the extracted carrier phase information is for use elsewhere in the cellular device outside of the GNSS chipset as described herein for example with flowchart of .

The filtering processing described herein lies in the family of errors in pseudorange processing that affect code and carrier measurements in the same way. In various embodiments the code phase pseudorange measurements are disciplined by subtracting out a more constant equivalent pseudorange like distance measurement derived from the carrier phase. Next a filtering on the net subtracted signal is performed which allows various embodiments to eliminate multipath induced errors in the raw and corrected pseudorange data. This method does not deal with ionospheric effects according to one embodiment.

In operation A of extracted pseudorange information and carrier phases for a first epoch are collected. In one embodiment these extracted pseudorange information and carrier phases are received at carrier phase smoothing logic from the GNSS receiver .

In operation A of pseudorange corrections are collected and applied to the first set of extracted pseudoranges collected in operation A. In one embodiment these corrections themselves may be smoothed at the reference receiver e.g. at GPS GNSS reference stations so that the delivered pseudorange corrections themselves are less noisy. Smoothing the pseudorange corrections derived at the GPS GNSS reference stations using the same carrier phase method of flowchart A can vastly improve the quality of the delivered pseudorange corrections delivered to cellular device for use by a position determination processor e.g. GNSS receiver or pseudorange information processing logic . Such corrected pseudoranges that are also smoothed may be used by the cellular device and fetched if available.

In operation A of delta carrier phase measurements for the same epoch are created using real carrier phase information. In accordance with various embodiments this replicates creating a second distance measurement similar to the reconstructed carrier phase information based on integrated Doppler Shift.

In operation A of the delta carrier phase measurements are subtracted from the corrected extracted pseudoranges. In accordance with various embodiments this provides a fairly constant signal for that epoch and is equivalent to the corrected extracted pseudorange at the start of the integration interval. In accordance with various embodiments this is referred to as a disciplining step that smoothes out the corrected extracted pseudorange signal and therefore reduces the instant errors in the later computed position fixes.

In operation A of the signal is filtered after the subtraction of operation A to reduce noise. In accordance with one embodiment this is performed by averaging the carrier phase yardsticks over a series of epochs.

In operation A of the delta carrier phase measurements from the real carrier phase processing operation is added back into the filtered signal of operation A.

In operation A of the new filtered and corrected extracted pseudorange signal is processed for example at the pseudorange information processing logic to derive a position fix B.

Carrier Phase Information can be reconstructed referred to herein as reconstructed carrier phase based on Doppler Shift. Doppler Shift is the change in frequency of a periodic event also known as a wave perceived by an observer that is moving relative to a source of the periodic event. For example Doppler shift refers to the change in apparent received satellite signal frequency caused by the relative motion of the satellites as they either approach the cellular device or recede from it. Thus any measurement of Doppler frequency change is similar to differentiating carrier phase. It is therefore possible to reconstruct the carrier phase by integrating the Doppler shift data. In an embodiment the GNSS chipset of GNSS receiver may provide Doppler information it determines through other means. This Doppler frequency shift information or Doppler may be collected at each GPS timing epoch e.g. one second and integrated over a sequence of the one second epochs to produce a model of carrier phase. This Doppler derived carrier phase model may be substituted for the real carrier phase data and used in the same manner as shown in the flow chart for carrier phase smoothing of . Doppler Shift signal processing is well known in the art.

In operation B of Doppler information from a GNSS receiver of a GNSS chipset is received by pseudorange carrier phase smoothing logic .

In operation B of a series of Doppler information is integrated. As described above Doppler frequency shift information may be collected at each GPS timing epoch e.g. one second and stored for use in producing a model of carrier phase.

In operation B of a model of carrier phase is created based on integrated Doppler information. As discussed above with reference to operation B a series of Doppler information for a plurality of timing epochs is integrated. In one embodiment this Doppler information is integrated over a sequence of the one second epochs to produce a model of carrier phase. The sequence may include 10 100 epochs or seconds. The model of carrier phase smoothing is used as the reconstructed carrier phase information.

In operation B of the modeled carrier phase which is also referred to as reconstructed carrier phase information is supplied to pseudorange carrier phase smoothing logic . As described above method of flowchart B can be implemented at GPS GNSS reference stations and the reconstructed carrier phase information can then be broadcast to cellular device .

At the cellular device accesses the GNSS chipset embedded within the cellular device where the GNSS chipset calculates pseudorange information for use by the GNSS chipset . For example the GNSS receiver can perform GPS measurements to derive raw measurement data for a position of the cellular device . The raw measurement data provides an instant location of the cellular device . The GNSS chipset calculates pseudorange information that is for use by the GNSS chipset . According to one embodiment the raw measurement data is the pseudorange information that will be extracted. Examples of pseudorange information are uncorrected pseudorange information differential GNSS corrections high precision GNSS satellite orbital data GNSS satellite broadcast ephemeris data and ionospheric projections.

A chipset accessor logic according to one embodiment is configured for accessing the GNSS chipset . According to one embodiment the chipset accessor logic is a part of an SUPL client .

The pseudorange information can be obtained from the processor of the GNSS receiver using a command. The GNSS chipset may be designed for example by the manufacturer of the GNSS chipset to provide requested information such as pseudorange information in response to receiving the command. The pseudorange information may be extracted from the GNSS chipset using the command that the manufacturer has designed the GNSS chipset with. For example according to one embodiment the GNSS chipset is accessed using an operation that is a session started with a message that is an improved accuracy Secure User Platform Location SUPL start message or a high precision SUPL INIT message. According to one embodiment the message is a custom command that is specific to the GNSS chipset also referred to as a GNSS chipset custom command and the improved accuracy SUPL client can access to the raw measurements of the GNSS chipset .

Examples of chipset manufacturers include Qualcomm Texas Instruments FastraX Marvel SIRF Trimble SONY Furuno Nemerix Phillips and XEMICS to name a few.

At the cellular device extracts the pseudorange information from the GNSS chipset for use elsewhere in the cellular device outside of the GNSS chipset . For example pseudorange information extractor logic may be associated with a worker thread of the SUPL client . The worker thread associated with the SUPL client can monitor the raw measurements delivered by the GNSS chipset into the GNSS chipset s memory buffers cache the raw measurements and use the raw measurements to determine a position fix. The pseudorange information extractor logic and the pseudorange information processing logic can be associated with the worker thread. For example the pseudorange information extractor logic can cache the raw measurements and the pseudorange information processing logic can determine the location.

According to one embodiment the raw measurement data is the pseudorange information that is extracted. According to one embodiment the raw measurement data is pseudorange information that is calculated by the GNSS chipset and is only for use by the GNSS chipset .

According to one embodiment a determining position fix logic B may perform a least squares solution B on the extracted pseudorange information prior to transmitting the output to the pseudorange information bridger logic . According to another embodiment the extracted pseudorange information is improved using various embodiments described in prior to performing a least squares solution B as will be described herein.

The extracted pseudorange information without further improvements can be used to provide an instant location as described herein. The extracted pseudorange information can be improved by applying position accuracy improvements that include but are not limited to those depicted in Tables 2 and 3. The instant location or the improved location can be communicated to location manager logic as discussed herein that displays the instant location or the improved location with respect to a map.

At A the pseudorange correction logic provides Wide Area Augmentation System WAAS corrected pseudoranges by applying WAAS corrections to the extracted pseudorange information. For example the pseudorange correction logic receives the extracted pseudorange information that was extracted from the GNSS chipset at of . The cellular device receives the WAAS corrections as described herein and provides the WAAS corrections to the pseudorange correction logic . The pseudorange correction logic provides Wide Area Augmentation System WAAS corrected pseudoranges by applying the received WAAS corrections to the extracted pseudorange information.

At B the pseudorange carrier phase smoothing logic provides smoothed pseudorange information by performing pseudorange smoothing on the extracted pseudorange information based on carrier phase information. For example if real carrier phase information is available the cellular device can extract it as discussed herein. Otherwise the cellular device can derive reconstructed carrier phase information as described herein and provide the reconstructed carrier phase information to the pseudorange carrier phase smoothing logic . The pseudorange carrier phase smoothing logic can receive the extracted pseudorange information that was extracted from the GNSS chipset at of . The pseudorange carrier phase smoothing logic can apply either the real carrier phase information or the real carrier phase information to the extracted pseudorange information to provide smoothed pseudorange information.

At B a position fix is determined based on the smoothed pseudorange information and WAAS pseudorange corrections. For example the pseudorange correction logic receives the smoothed pseudorange information and receives WAAS pseudorange corrections and determines a position fix based on the smoothed pseudorange information and the WAAS pseudorange corrections.

According to one embodiment a determining position fix logic B may perform a least squares solution B on the output of flowchart A and B prior to transmitting the output to the pseudorange information bridger logic .

At A the pseudorange correction logic provides Differential Global Positioning System DGPS corrected pseudoranges by applying DGPS corrections to the extracted pseudorange information.

For example the pseudorange correction logic receives the extracted pseudorange information that was extracted from the GNSS chipset at of . The cellular device receives the DGPS corrections as described herein and provides the DGPS corrections to the pseudorange correction logic . The pseudorange correction logic provides Differential Global Positioning System DGPS corrected pseudoranges by applying the received DGPS corrections to the extracted pseudorange information.

At A the pseudorange correction logic provides WAAS DGPS corrected pseudoranges by applying Wide Area Augmentation System WAAS to the DGPS corrected pseudoranges.

For example the pseudorange correction logic accesses the DGPS corrected pseudoranges determined at A of . The cellular device receives the WAAS corrections as described herein and provides the WAAS corrections to the pseudorange correction logic . The pseudorange correction logic provides WAAS DGPS corrected pseudoranges by applying Wide Area Augmentation System WAAS to the DGPS corrected pseudoranges.

At B a position determination decision is made as to whether to proceed to B or B. For example at operation B the position accuracy improvement determination logic B can determine whether to proceed to B or B as discussed herein.

At B DGPS corrected smoothed pseudoranges are provided by applying corrections to the smoothed pseudorange information. For example the pseudorange correction logic can provide DGPS corrected smoothed pseudoranges by applying DGPS corrections to the smoothed pseudoranges determined at either B or B.

At B WAAS DGPS corrected smoothed pseudoranges are provided by applying WAAS to the DGPS corrected smoothed pseudoranges. For example the pseudorange correction logic can provide WAAS DGPS corrected smoothed pseudoranges by applying WAAS corrections to the DGPS corrected smoothed pseudoranges.

According to one embodiment a determining position fix logic B may perform a least squares solution B on the output of flowcharts A or B prior to transmitting the output to the pseudorange information bridger logic .

At A DGPS corrected pseudoranges are determined by applying DGPS pseudorange corrections to extracted pseudorange information. For example the pseudorange correction logic receives extracted pseudorange information from the pseudorange information extractor logic and applies the DGPS pseudorange corrections to the extracted pseudorange information.

At A the pseudorange correction logic can determine a position fix based on the DGPS corrected pseudoranges and PPP corrections.

At B smoothed pseudorange information is provided by performing pseudorange smoothing on the extracted pseudorange information using carrier phase information. For example the pseudorange carrier phase smoothing logic provides smoothed pseudorange information by performing pseudorange smoothing on the extracted pseudorange information which can be obtained as discussed herein based on carrier phase information. If real carrier phase information is available the cellular device can extract the real carrier phase information as discussed herein. Otherwise the cellular device can derive reconstructed carrier phase information as described herein and provide the reconstructed carrier phase information to the pseudorange carrier phase smoothing logic .

At B DGPS corrected smoothed pseudoranges are provided by applying DGPS pseudorange corrections to the smoothed pseudorange information. For example the pseudorange correction logic can receive the smoothed pseudorange information from the pseudorange carrier phase smoothing logic . The pseudorange correction logic can determine the corrected smoothed pseudoranges by applying DGPS pseudorange corrections to the smoothed pseudorange information.

At B a position fix can be determined based on the DGPS corrected smoothed pseudoranges and PPP corrections. For example the pseudorange correction logic can determine a position fix based on the DGPS corrected smoothed pseudoranges and PPP corrections.

According to one embodiment a determining position fix logic B may perform a least squares solution B on the output of flowcharts A and B prior to transmitting the output to the pseudorange information bridger logic .

At the pseudorange carrier phase smoothing logic smoothes the extracted pseudorange information based on carrier phase smoothing. For example the pseudorange carrier phase smoothing logic receives extracted pseudorange information from the pseudorange information extractor logic and receives carrier phase information which may be either real carrier phase information or reconstructed carrier phase information as described herein. The pseudorange carrier phase smoothing logic smoothes the extracted pseudorange information based on carrier phase smoothing.

At the PPP logic C provides a smoothed improved accuracy position fix by performing Precise Point Positioning PPP processing on the smoothed extracted pseudorange information. For example the PPP logic C receives the smoothed extracted pseudorange information provided by the pseudorange carrier phase smoothing logic at . The PPP logic C provides a smoothed improved accuracy position fix by performing Precise Point Positioning PPP processing on the smoothed extracted pseudorange information

At the pseudorange correction logic can optionally correct the smoothed improved accuracy position fix by applying Differential Global Positioning System DGPS corrections to the smoothed improved accuracy position fix. For example pseudorange correction logic receives the smoothed improved accuracy position fix provided by the PPP logic C at . The pseudorange correction logic receives DGPS corrections as described herein. The pseudorange correction logic corrects the smoothed improved accuracy position fix by applying Differential Global Positioning System DGPS corrections to the smoothed improved accuracy position fix thus providing a corrected smoothed improved accuracy position fix. Operation is optional according to one embodiment.

According to one embodiment a determining position fix logic B may perform a least squares solution B on the output of flowchart prior to transmitting the output to the pseudorange information bridger logic .

At various types of information can be accessed. Examples of accessing are extracting information and receiving information. Unsmoothed uncorrected pseudorange information can be extracted at A WAAS corrections can be extracted at B SBAS corrections can be extracted at E Doppler shift can be extracted at C and carrier phase measurements can be extracted at D. Accessing and obtaining can be used interchangeably. Table 1 depicts types of information that can be extracted at operation from the GNSS chipset and types of information that are received at operation instead of being extracted. However various embodiments are not limited to the types of information that can be extracted or received depicted in Table 1.

What or whether to apply position accuracy improvements can be determined at for example by the position accuracy improvement determination logic B. Examples of position accuracy improvements are real carrier phase information reconstructed carrier phase information WAAS SBAS DGPS PPP RTK VRS and RTX corrections. The determination logic B can determine whether one or more and in what order logics A B A F are performed according to one embodiment. Tables 2 and 3 are examples of carrier phase information or corrections or a combination thereof that the position accuracy improvement determination logic B may determine as discussed herein.

The information can be smoothed at . Examples of smoothing are real carrier phase smoothing and reconstructed carrier phase smoothing .

Either unsmoothed information or smoothed information can be corrected at . For example unsmoothed information from or smoothed information from can be corrected at . Examples of correcting are SBAS correcting G WAAS correcting A DGPS correcting B PPP correcting C RTK correcting D VRS correcting E and RTX correcting F. The smoothed information or unsmoothed information can be corrected using one or more of operations A G. According to one embodiment WAAS correcting A is an example of SBAS correcting G.

Unsmoothed information from smoothed information from corrected unsmoothed information from or corrected smoothed information from can be used to determine a position fix B at for example by performing a least squares solution B at . The output of flowchart is a position fix B. Table 2 and Table 3 depict combinations of information that result in a position fix B according to various embodiments.

According to one embodiment accessing extracting extracting pseudorange information A extracting SBAS E extracting WAAS B extracting Doppler C extracting carrier phase measurement D receiving smoothing correcting determining a position fix and performing a least squares solution can be performed respectively by logic B B B B B B and B. Real carrier phase smoothing reconstructed carrier phase smoothing correcting A G can be performed respectively by logic A B A E F G.

Any one or more of A E A G can be performed. Further any one or more of A E B C E A G can be performed in various orders. Various embodiments are not limited to just the combinations that are described herein.

According to one embodiment a Global Navigation Satellite System GNSS chipset embedded within the cellular device is accessed at where the GNSS chipset calculates pseudorange information for use by the GNSS chipset. The pseudorange information is extracted at from the GNSS chipset for use elsewhere in the cellular device outside of the GNSS chipset. The accessing and the extracting A can be performed by the cellular device that includes hardware .

The extracted pseudorange information can be smoothed at . The smoothing can be based on reconstructed carrier phase information or real carrier phase information. The smoothed pseudorange information can be corrected at . Examples of the types of corrected pseudoranges are Wide Area Augmentation System WAAS Differential Global Positioning System DGPS Precise Point Positioning PPP and Real Time Kinematic RTK . Pseudorange corrections can be accessed . The corrected pseudorange information can be derived for example at by applying the pseudorange corrections to the extracted pseudorange information.

The operations depicted in transform data or modify data to transform the state of a cellular device . For example by extracting pseudorange information from a GNSS chipset for use elsewhere the state of the cellular device is transformed from a cellular device that is not capable of determining a position fix itself into a cellular device that is capable of determining a position fix itself. In another example operations depicted in flowcharts transform the state of a cellular device from not being capable of providing an improved accuracy position fix to be capable of providing an improved accuracy position fix.

The above illustration is only provided by way of example and not by way of limitation. There are other ways of performing the method described by flowcharts .

The operations depicted in can be implemented as computer readable instructions hardware or firmware. According to one embodiment hardware associated with a cellular device can perform one or more of the operations depicted in .

With reference now to a block diagram is shown of an embodiment of an example GNSS receiver which may be used in accordance with various embodiments described herein. In particular illustrates a block diagram of a GNSS receiver in the form of a general purpose GPS receiver capable of demodulation of the L and or L signal s received from one or more GPS satellites. A more detailed discussion of the function of a receiver such as GPS receiver can be found in U.S. Pat. No. 5 621 416 by Gary R. Lennen is titled Optimized processing of signals for enhanced cross correlation in a satellite positioning system receiver and includes a GPS receiver very similar to GPS receiver of .

In received L and L signals are generated by at least one GPS satellite. Each GPS satellite generates different signal L and L signals and they are processed by different digital channel processors which operate in the same way as one another. shows GPS signals L 1575.42 MHz L 1227.60 MHz entering GPS receiver through a dual frequency antenna . Antenna may be a magnetically mountable model commercially available from Trimble Navigation of Sunnyvale Calif. Master oscillator provides the reference oscillator which drives all other clocks in the system. Frequency synthesizer takes the output of master oscillator and generates important clock and local oscillator frequencies used throughout the system. For example in one embodiment frequency synthesizer generates several timing signals such as a 1st local oscillator signal LO at 1400 MHz a 2nd local oscillator signal LO at 175 MHz an SCLK sampling clock signal at 25 MHz and a MSEC millisecond signal used by the system as a measurement of local reference time.

A filter LNA Low Noise Amplifier performs filtering and low noise amplification of both L and L signals. The noise figure of GPS receiver is dictated by the performance of the filter LNA combination. The down convertor mixes both L and L signals in frequency down to approximately 175 MHz and outputs the analogue L and L signals into an IF intermediate frequency processor . IF processor takes the analog L and L signals at approximately 175 MHz and converts them into digitally sampled L and L inphase L I and L I and quadrature signals L Q and L Q at carrier frequencies 420 KHz for L and at 2.6 MHz for L signals respectively.

At least one digital channel processor inputs the digitally sampled L and L inphase and quadrature signals. All digital channel processors are typically are identical by design and typically operate on identical input samples. Each digital channel processor is designed to digitally track the L and L signals produced by one satellite by tracking code and carrier signals and to from code and carrier phase measurements in conjunction with the GNSS microprocessor system . One digital channel processor is capable of tracking one satellite in both L and L channels. Microprocessor system is a general purpose computing device such as computer system of which facilitates tracking and measurements processes providing pseudorange and carrier phase measurements for a determining position fix logic . In one embodiment microprocessor system provides signals to control the operation of one or more digital channel processors . According to one embodiment the GNSS microprocessor system provides one or more of pseudorange information Doppler Shift information and real Carrier Phase Information to the determining position fix logic . One or more of pseudorange information Doppler Shift information and real Carrier Phase Information can also be obtained from storage . One or more of the signals can be conveyed to the cellular device s processor such as processor that is external to the GNSS chipset . Determining position fix logic performs the higher level function of combining measurements in such a way as to produce position velocity and time information for the differential and surveying functions for example in the form of a position fix . Storage is coupled with determining position fix logic and microprocessor system . It is appreciated that storage may comprise a volatile or non volatile storage such as a RAM or ROM or some other computer readable memory device or media. In some embodiments determining position fix logic performs one or more of the methods of position correction described herein.

In some embodiments microprocessor and or determining position fix logic receive additional inputs for use in receiving corrections information. According to one embodiment an example of the corrections information is WAAS corrections. According to one embodiment examples of corrections information are differential GPS corrections RTK corrections signals used by the previously referenced Enge Talbot method and wide area augmentation system WAAS corrections among others.

Although depicts a GNSS receiver with navigation signals LI LQ LI LQ various embodiments are well suited different combinations of navigational signals. For example according to one embodiment the GNSS receiver may only have an LI navigational signal. According to one embodiment the GNSS receiver may only have LI LQ and LI.

Various embodiments are also well suited for future navigational signals. For example various embodiments are well suited for the navigational signal LC that is not currently generally available. However there are plans to make it available for non military receivers.

According to one embodiment either or both of the accessing logic B and the processing logic reside at either or both of the storage and GNSS microprocessor system .

According to one embodiment the GNSS receiver is an example of a GNSS receiver see e.g. and . According to one embodiment the determining position fix logic is an example of determining position fix logic B . According to one embodiment position fix is an example of a position fix B .

A basic Kalman filter implemented using Kalman filtering process typically has at least two major components states and covariances . States represent variables that are used to describe a system being modeled at a particular moment in time. Covariances are represented in a covariance matrix that describes uncertainty or lack of confidence of states with respect to each other at that same moment in time. Kalman filtering process also handles noise or unpredictable variability in the model. There are two principle types of noise observation noise and process noise . A Kalman filter may handle additional noise types in some embodiments. Process noise describes noise of the states as a function of time. Observation noise is noise that relates to the actual observation s e.g. observed measurements that are used as an input update to Kalman filtering process .

A prediction phase is the first phase of Kalman filtering process . Prediction phase uses predictive models to propagate states to the time of an actual observation s . Prediction phase also uses process noise and predictive models to propagate the covariances to time of the actual observation s as well. The propagated states are used to make predicted observation s for the time of actual observation s .

A correction phase is the second phase in the Kalman filtering process . During correction phase Kalman filtering process uses the difference between the predicted observation s and the actual observation s to create an observation measurement residual which may commonly be called the measurement residual. Observation noise can be noise in actual observation s and or noise that occurs in the process of taking the actual observation s . A Kalman gain is calculated using both the covariances and the observation noise . The states are then updated using the Kalman Gain multiplied by the observation measurement residual . The covariances are also updated using a function related to the Kalman gain for example in one embodiment where Kalman gain is limited to a value between 0 and 1 this function may be 1 minus the Kalman gain. This updating is sometimes referred to as the covariance update. In some embodiments if no actual observation is available Kalman filtering process can simply skip correction phase and update the states and covariances using only the information from prediction phase and then begin again. Using the new definitions of the states and covariances Kalman filtering process is ready to begin again and or to be iteratively accomplished.

Unless otherwise specified any one or more of the embodiments described herein can be implemented using non transitory computer readable storage medium and computer readable instructions which reside for example in computer readable storage medium of a computer system or like device. The non transitory computer readable storage medium can be any kind of physical memory that instructions can be stored on. Examples of the non transitory computer readable storage medium include but are not limited to a disk a compact disk CD a digital versatile device DVD read only memory ROM flash and so on. As described above certain processes and operations of various embodiments of the present invention are realized in one embodiment as a series of computer readable instructions e.g. software program that reside within non transitory computer readable storage memory of a cellular device and are executed by a hardware processor of the cellular device . When executed the instructions cause a computer system to implement the functionality of various embodiments of the present invention. For example the instructions can be executed by a central processing unit associated with the cellular device . According to one embodiment the non transitory computer readable storage medium is tangible.

Unless otherwise specified one or more of the various embodiments described herein can be implemented as hardware such as circuitry firmware or computer readable instructions that are stored on non transitory computer readable storage medium. The computer readable instructions of the various embodiments described herein can be executed by a hardware processor such as central processing unit to cause the cellular device to implement the functionality of various embodiments. For example according to one embodiment the SUPL client and the operations of the flowcharts depicted in are implemented with computer readable instructions that are stored on computer readable storage medium which can be tangible or non transitory or a combination thereof and can be executed by a hardware processor of a cellular device .

Reference will now be made in detail to various embodiments of the subject matter examples of which are illustrated in the accompanying drawings. While various embodiments are discussed herein it will be understood that they are not intended to be limited to these embodiments. On the contrary the presented embodiments are intended to cover alternatives modifications and equivalents which may be included within the spirit and scope the various embodiments as defined by the appended claims. Furthermore in the following Description of Embodiments numerous specific details are set forth in order to provide a thorough understanding of embodiments of the present subject matter. However embodiments may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail as not to unnecessarily obscure aspects of the described embodiments.

Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the description of embodiments discussions utilizing terms such as collecting capturing obtaining determining storing calculating calibrating receiving designating performing displaying positioning accessing transforming data modifying data to transform the state of a computer system or the like refer to the actions and processes of a computer system data storage system storage system controller microcontroller hardware processor such as a central processing unit CPU or similar electronic computing device or combination of such electronic computing devices. The computer system or similar electronic computing device manipulates and transforms data represented as physical electronic quantities within the computer system s device s registers and memories into other data similarly represented as physical quantities within the computer system s device s memories or registers or other such information storage transmission or display devices.

According to one embodiment a mobile data collection platform captures an image that depicts at least one point of interest. The location and orientation of the mobile data collection platform may be captured at the time the image is captured. The orientation of the mobile data collection platform is with respect to a local gravity vector that is local to the mobile data collection platform. The orientation according to one embodiment is given by a three axis tilt angle sensor and the direction of the tilt angle may be determined from the tilt angles for the x axis sensor and the y axis sensor as determined by aiming the measurement platform towards the point of interest. The tilt sensor measures degree of departure from local gravity vertical in 2 or 3 axes. The location and orientation can be associated with the image for example by the user holding the mobile data collection platform still during the period of time that the image is captured and the location and orientation of the mobile data collection platform are determined. In another example when a user of the mobile data collection platform presses a button the image the location and the orientation can all be obtained and stored in response to the user pressing the button. Therefore location and orientation can be associated with the image by determining the location and orientation and capturing the image in a time period that is short enough to avoid any significant user movement of the mobile data collection platform during the capture process.

Scale Information may be used as a part of determining a distance between the mobile data collection platform and the point of interest. The scale information may be the depiction of an object which has a known dimension in the captured image. A single measurement can be made if the plane of scale object is parallel to the plane of the image capture device. This is hard to achieve so two images are usually required. In another example a second image that depicts the point of interest captured with the image capturing device that is at a second location and orientation where the first location and the second location are separated by a known distance. Since the mobile data collection platform has a position determination system the distance between the first location and the second location can be easily determined as will become more evident. In this case scale information can include one or more of the first and second images the first and second locations and orientations that were used when the respective first and second images were captured and the known distance between the first and second locations.

The mobile data collection platform includes a cellular device processing logic an image capturing device an orientation system an inertial orientation system tilt sensor compass and hardware . The cellular device includes a display GNSS chipset and an antenna . The hardware includes the image capturing device the orientation system the inertial orientation system hardware memory and hardware processor . The antenna the display the processing logic the hardware are part of the mobile data collection platform and outside of the GNSS chipset .

According to one embodiment the orientation system includes a compass and an inertial orientation system . According to one embodiment the inertial orientation system includes a three axis tilt sensor . According to one embodiment the tilt sensor is a three axis inertial measurement unit IMU . According to one embodiment the tilt sensor is a three axis accelerometer. According to one embodiment the tilt sensor is a two axis accelerometer where the axes are for the x and y directions in the platform coordinate system.

The orientation system according to one embodiment determines orientation information that represents an orientation of the mobile data collection platform . The orientation information includes according to one embodiment inertial orientation information and azimuth angle. According to one embodiment the inertial orientation information includes a tilt angle from the tilt sensor .

Angles such as the azimuth angle are measured in 360 degrees as is well known in the art. However other metrics used by surveyors for describing angular displacement including what is known as grad that uses 400 degrees in a full circle can also be used.

The tilt sensor may be used to determine the tilt angle. The tilt angle indicates the mobile data collection platform s orientation with respect to a local gravity vector as measured from a vertical or zenith point. The overall tilt angle is composed of two angles tilt in the direction of the x axis and tilt in the direction of the y axis. The vector magnitude gives a tilt angle in the direction of the vector sum of the x axis and y axis components. It may be reported as a tilt angle in polar coordinates as well. Polar coordinates the tilt angle as measured from a vertical gravity reference direction along a compass angle as determined by the vector sum of the x and y components. Tilt sensors determine the tilt angle based on Euler angles. The inertial orientation information may include the Euler angles from the tilt sensor in addition to the tilt angle or instead of the tilt angle.

The compass may be used to determine the azimuth angle. The azimuth angle indicates the orientation for example with respect to a reference direction such as true north magnetic north or a reference target at a known location from which the direction vector can be determined.

The hardware memory stores the image that depicts the point of interest the position fix and the orientation information . The antenna has a three dimensional GNSS position fix Xpf Ypf Zpf that is stored in memory as position fix .

The hardware processor is for executing the capturing of the image with the image capturing device where the image includes at least one point of interest the determining of the position fix of the mobile data collection platform based on the raw observables where the position fix provides a location of the mobile data collection platform in a GNSS coordinate system the accessing of the orientation information from the inertial orientation system and the storing of the image the position fix and the orientation information in the hardware memory of the mobile data collection platform .

The mobile data collection platform is not required to be leveled as a part of capturing the image determining the position fix and determining the orientation information . The orientation information is associated directly and automatically with a three dimensional location such as the position fix Xpf Ypf Zpf stored as position fix or the three dimensional location X0 Y0 Z0 of an entrance pupil center of the mobile data collection platform when the image was captured. The mobile data collection platform is not required to be leveled at the time that the position fix Xpf Zpf Ypf and the orientation information are determined as is common with other optical measurement devices such as theodolites or total stations.

Any one or more of the entities such as hardware image capturing device inertial orientation system compass hardware memory hardware processor that are part of the mobile data collection platform and outside of the cellular device can instead be inside of the cellular device . According to one embodiment the mobile data collection platform is a cellular device. For example a tablet computer may contain all the recited hardware plus a separate cellphone module which itself can contain some of the hardware items including a GNSS chipset. Conversely the tablet may contain a GNSS chipset whose raw observables may be made available to any of the processors associated with the tablet.

Various types of information can be stored for example in an EXIF file associated with the image . Examples of information that can be written into the EXIF file are the GPS position fix orientation information the tilt angle the direction of an azimuth angle also referred to as an azimuth direction or tilt direction scale information and antenna to entrance pupil center geometric information. Any type of information that can be used for determining one or more of a three dimensional position of the entrance pupil center of the image capturing device a distance from the entrance pupil center to a point of interest and a location of a point of interest as will become more evident can be stored in the EXIF file. Alternatively any or more of the same information can be stored as reference information in a suitable reference file associated with the particular mobile data collection platform.

The mobile data collection platforms and depicted in and include a cellular device . According to one embodiment the cellular device can include cellular devices such as cellular device or any other cellular device described herein or any communications system capable of connecting with a cellular telephone system private or public for the purpose of transmitting and receiving voice data and messaging information.

An example of an image capturing device is a digital camera or portion thereof which includes an electronic image sensor e.g. a charge coupled device CCD image sensor an Active Pixel Sensor APS image sensor or other form of electronic image sensor . An example of hardware memory is memory . An example of hardware processor is hardware processor . An example of a GNSS chipset is GNSS chipset . According to one embodiment the mobile data collection platform includes a SUPL client as described herein. The SUPL client can be inside of the cellular device or can be in the mobile data collection platform and outside of the cellular device .

According to various embodiments the mobile data collection platform can include any one or more of features described herein. For example the mobile data collection platform can include at least any one or more features depicted in and can perform at least any one or more operations as depicted in .

For example the processing logic includes orientation information determination logic inertial orientation information determination logic store location of point of interest determination information logic and a true north declination angle application .

Orientation information can include one or more of tilt angle and azimuth angle. Orientation information determination logic includes the inertial orientation information determination logic according to one embodiment. However and can be separate. For example instructions for and may be part of the same procedure or function or may be part of separate procedures or functions.

The inertial orientation information determination logic that receives Euler angles from the inertial orientation system and processes the Euler angles to provide the tilt angle of the mobile data collection platform. The Euler angles may be stored in hardware memory .

The orientation information determination logic receives information from the compass and determines the tilt direction according to one embodiment.

The orientation information according to one embodiment includes information that provides a three dimensional position of the mobile data collection platform . The orientation information and the position fix can be used for determining the three dimensional position X0 Y0 Z0 of and or associated with the mobile data collection platform in a local three dimensional coordinate system.

Since the inertial orientation system provides information pertaining to the tilt angle of the mobile data collection platform the mobile data collection platform is not required to be leveled as a part of obtaining the location of point of interest determination information.

The store location of point of interest determination information logic according to one embodiment can store location of point of interest determination information such as the position fix the image and the orientation information into the hardware memory of the mobile data collection platform.

For example in an embodiment a mobile data collection platform captures an image that depicts a point of interest for the purpose of determining a distance between a three dimensional position of the mobile data collection platform such as the three dimensional position of the entrance pupil center and the point of interest. The mobile data collection platform collects various types of information that can be used for calculating the distance between the point of interest and the three dimensional position of the data collection platform . The collected information that can be used for determining the distance shall be referred to as location of point of interest determination information. 

According to one embodiment the location of point of interest determination information includes more than one image . The location of point of interest determination information can include any type of information that can be used for determining the location of the point of interest according to one embodiment. The location of point of interest determination information may include any type of information that can be used for determining the location of the point of interest in a three dimensional coordinate system according to one embodiment. According to one embodiment the three dimensional coordinate system that the point of interest can be located in is the well known latitude longitude and altitude or height system used in mapping. The GNSS receiver first locates itself in the WGS 84 World Geodetic System standard coordinate system widely accepted for use in cartography geodesy and navigation and used to describe the shape and coordinates of the earth. The WGS 84 datum includes the definition of a reference ellipsoid which approximates the earth s geoid. The WGS 84 datum is used for referencing GNSS derived positions to the earth. Models are available for relating WGS 84 derived heights to mean sea level geoid heights such as the Earth Gravitational Model 1996. According to one embodiment WGS 84 coordinate system includes WGS 84 datum. A conversion system within the GNSS receiver converts the GNSS determined WGS 84 data into latitude longitude and altitude information which are then used in the local coordinate system. Data on points of interest will be measured and transformed into the same local coordinate system. According to one embodiment the information includes any type of information that can be used for determining the location of the point of interest in a three dimensional coordinate system so that the mobile data collection platform is not required to be leveled as a part of determining the location of the point of interest.

According to one embodiment a true north declination angle application provides a declination angle for true north from the latitude and longitude associated with a position fix such as the position fix Xpf Ypf Zpf of an antenna . For example according to one embodiment the orientation of the mobile data collection platform at the time the image depicting the point of interest includes a tilt direction that is determined with respect to a reference direction. According to one embodiment the reference direction is true north.

Compasses provide the direction to magnetic north. True north can be determined by applying compensations to the direction of magnetic north provided by a compass.

One of the functions of the true north declination angle application that is used according to various embodiments is obtaining compensations that can be applied to the direction of magnetic north provided by a compass to obtain true north. For example the true north declination angle application can communicate with a database provided by the U.S. government that provides the declination angle for true north from the latitude and longitude associated with a position fix such as the position fix Xpf Ypf Zpf of an antenna . Therefore according to various embodiments the true north declination angle application can provide the position fix Xpf Ypf Zpf of the current location of the antenna to the U.S. governments database. The U.S. government s database can use the position fix Xpf Ypf Zpf to locate compensations such as declination angle for true north from the latitude and longitude associated with a position fix Xpf Ypf Zpf and return the compensations to the true north declination angle application . Magnetic north while the platform is at the same position Xpf Ypf Zpf can be obtained from the compass . True north can be derived for example by applying the compensations to the magnetic north.

The processing logic according to one embodiment provides instructions for communicating the position fix Xpf Ypf Zpf to the true north declination angle application and requesting compensations that correlate with the position fix Xpf Ypf Zpf receiving the compensations receiving magnetic north from the compass and determining true north by applying the compensations to magnetic north.

Data Collection Utilities Processing Logic according to one embodiment includes image outliner feature identification pattern recognition and image editor . The processing logic may include processing logic .

According to one embodiment a captured image can be displayed on the display . The user of the mobile data collection platform can outline a point of interest that is represented in image depicted on display . The user can specify that a point or feature is a point of interest for example by outlining it. The image outliner can receive information indicating the outline that the user drew around the point of interest. Therefore a point of interest that has been outlined is an example of a user specified point of interest. As will become more evident a user can also specify a point of interest using crosshairs shown in the display and aligned with the major axis of the image capturing device s lens also known as an entrance pupil . Feature identification can be performed for example by feature identification on a user specified point of interest. Pattern recognition can be performed on a user specified point of interest.

The user can use the image editor to annotate the image for example with audio or text or a combination thereof. The annotation can be a description of a point of interest. For example the user can indicate in the annotation that the point of interest is a standard survey target device consisting of concentric circles with alternating black and white sections or the upper right corner of a door or other point of interest or pseudo point of interest as described herein. These are just a couple of examples of annotations. Therefore a point of interest that a user specifies using an annotation is another example of a user specified point of interest. The annotation can include other information such as a description of the area or a job site where the image was taken.

For more information on cellular communications Bluetooth communications image outliner feature identification pattern recognition and image editor refer to U.S. 2012 0163656 filed on Jun. 28 2012 entitled Method Apparatus for image based positioning by Soubra et al and assigned to the assignee of the present application. Refer also to the contents of U.S. 2012 0330601 filed on Feb. 15 2012 entitled Determining Tilt Angle and Tilt Direction Using Image Processing by Soubra et al and assigned to the assignee of the present application.

Referring to the processing logic includes crosshairs processing logic bubble level processing logic and distance between two positions logic . The processing logic may include processing logic or processing logic or a combination thereof.

The crosshairs processing logic receives and processes information with respect to a crosshair display overlay as will become more evident.

The bubble level processing logic can receive information from the tilt sensor and use the received information to display a graphical visual representation of a bubble inside of the electronic bubble level overlay as will become more evident.

According to one embodiment the distance between two positions processing logic obtains the position fixes associated with two locations that a mobile data collection platform took images of a point of interest and determines a distance between the two locations based on the position fixes.

According to one embodiment one or more of the processing logics are executed by one or more hardware processors that are part of the mobile data collection platform and outside of the GNSS chipset .

Due to the orientation of mobile data collection platform the image plane that defines the orientation of an image captured with the image capturing device of mobile data collection platform would be defined by the x axis and z axis and the ground plane that is approximately parallel to the ground would be defined by the x axis and the y axis.

The body of mobile data collection platform is often tipped so that it is no longer in a vertical orientation. In this case the image capture device may view the nearby ground as well as objects in the foreground. No loss of functionality of position shift motion detection occurs for the LMM system.

Photogrammetry is the practice of determining the geometric properties of objects from photographic images. In the simplest example the distance between two points that lie on a plane parallel to the photographic image plane can be determined by measuring their distance on the image if the scale s of the image is known. This is done by multiplying the measured distance by a scale factor 1 S.

One way of finding points uses features to identify the desired object or point on a desired object. An example of an object is a door and an example of points on the object are the corners of the door. The points may be described by a feature description of the object. For example the door s corners may be represented by a small collection of closely associated details or image bits which form a distinct and recognizable image pattern. Modern image processing methods are available for identifying such grouping of image bits as feature points. 

According to one embodiment there are two types of calibration that enable satisfactory operation of an image capturing device with photogrammetric analyses. The first type of calibration is a determination of the angular displacement associated with each pixel or charge coupled device capture element. This may be done mathematically for example by determining the entire field of view of the image capturing device using external means and then dividing this angular field of view by the number of pixel elements in each dimension horizontally and vertically. This external mathematical means is well known in the art and includes measuring a distance from a reference plane such as a wall to the entrance pupil of the image capturing device and then marking the edges of the field of view horizontally and vertically for example on the image plane also known as a reference plane . The distance from each edge horizontally and vertically plus the distance from the entrance pupil to the image plane enable creation of a triangle whose angles for horizontal and vertical can be determined thus defining the field of view in horizontal and vertical planes relative to the image plane. An example of an image plane is illustrated in .

The second type of calibration deals with lens aberrations. Image capturing devices that are a part of cellular devices also referred to as internal image capturing devices typically have poor quality lenses where the image is distorted by a variety of lens aberrations so that what is a uniform distance metric in an image such as a checkerboard square pattern becomes less uniform particular near the edges of the field of view. Therefore according to one embodiment the image capturing device namely the camera and its lens must be calibrated.

Calibration can be done for a family of lenses associated with a particular image capturing device or may be done on an individual basis for each mobile data collection platform. The purpose of calibration is to 1 limit the useful area of the captured image data to only those pixels on the charge coupled device CCD that have a satisfactorily uniform image transform from the real world to the image capturing device s collection of CCD pixels or 2 to define the variation of transform information for the entire field of view in order to create a correction map for segments of pixels where distortion is greatest namely at the periphery of the field of view.

As stated poor quality lenses cause aberrations and or distortions. For example if an image of the pattern is captured using a poor quality lens the features such as the checkers in depicted in the image will not have the same proportions as the pattern . The distortion tends to increase toward the peripheries of the lens also known as stretch distortion . The kind and range of distortions in lenses are well known in the image processing arts. For example toward the center of the captured image the dimensions of the checkers will tend to be 1.00 by 1.00. However the dimensions of the checkers will increasingly be distorted the further the checkers are from the center. For example the checker at the center may have a height of 1.00 and a width of 1.00 and then as moved out the checker may have a height of 1.00 and a width of 1.05 and then as move still further toward the periphery the checker may have a height of 1.00 by width of 1.06. The pixel correction datum is a correction map for segments of pixels where distortion is greatest namely at the periphery of the field of view according to one embodiment. The pixel correction datum can be stored in the hardware memory .

There are other types of distortion effects besides a linear stretching such as pin cushion and barrel distortions for which alternate specifications for a distortion limit are available as is well known in the art.

According to one embodiment a quality threshold metric is used to determine the acceptable region within the boundary where the distortion is within an acceptable level. For example if the calibration image displaying the width of the squares as move toward the periphery do not differ by more than 5 percent from the width of a square closest to the pointing vector PV then the pixels for that square are included in the acceptable region . According to another embodiment if the width of the squares nearing the periphery do not differ by more than 2 percent from the width of the square closet to the pointing vector PV then the pixels for that square are included in the acceptable region . Thus a boundary can be determined for the CCD image capturing device such that image data in the acceptable region inside the boundary is used for photogrammetry analysis purposes and unacceptable region between the boundary and the periphery is ignored.

According to one embodiment calibrations are not performed for every single mobile data collection platform that is manufactured. According to one embodiment calibrations are performed for each type of mobile data collection platform. For example if there are two types of mobile data collection platforms that are manufactured and there are 1000 mobile data collection platforms for each of the two types two calibrations are performed instead of 2000. According to one embodiment calibrations are performed for each type of lens or are performed for each type of image capturing device.

A mobile data collection platform can be calibrated for example before it is purchased or after it is purchased. The mobile data collection platform can be calibrated for example at the manufacturing facility or by a user who bought the mobile data collection platform.

A mobile data collection platform accesses an internal GNSS chipset extracts raw observables from the internal GNSS chipset and determines a position fix Xpf Ypf Zpf based on the extracted raw observables according to various embodiments described herein. The extracted raw observables can include raw pseudoranges. Although various embodiments are described in the context of a GPS position fix since various position fixes are determined based on GNSS raw observables the term GNSS shall be understood as including GPS. 

 Raw observables shall be used to refer to the specific data comprising raw observables that are extracted from the internal GNSS chipset. The raw observables can include real carrier phase information or Doppler Shift Information. The raw pseudoranges may be smoothed based on real carrier phase information or reconstructed carrier phase information according to various embodiments described herein. The pseudoranges may be corrected for example based on external corrections obtained from correction sources that are external to a mobile data collection platform as described herein. A position fix may be smoothed based on locally measured movement information as described herein. The pseudoranges that are used for determining a position fix of the mobile data collection platform may be uncorrected unsmoothed pseudoranges corrected unsmoothed pseudoranges uncorrected smoothed pseudoranges or corrected smoothed pseudoranges as described herein. The position fixes may or may not be smoothed based on locally measured movement information as described herein.

A data collection platform captures an image that depicts a point of interest for the purpose of determining a distance between a three dimensional position of the data collection platform such as the three dimensional position of the entrance pupil center and the point of interest by photogrammetric methods. Other dimensions between other points in the image may also be determined.

According to one embodiment a point of interest is stationary. According to one embodiment a point of interest has a three dimensional coordinate. Examples of a point of interest are corners in an outdoor setting or indoor setting wall mounted fixture of various kinds such as lights switches window ledges window corners in an indoor setting a property boundary point a point of significance to a current or proposed construction project and or the like. A point of interest is also commonly referred to as target point or object point. A point of interest may be any point on an object that is of interest. It may be a topographic feature a manmade structure or component thereof such as a corner of a building the edge of a wall the point at which either of these contacts the ground. A single pixel or a group of pixels in an image can represent or be a point of interest.

Points of interest on moving objects may also be captured by the mobile data collection platform. With the mobile data collection platform time of data capture location of the platform and an image of the moving object can be obtained. Such mobile points of interest may include features on a vehicle including but not limited to door handles wheels logos emblems windows edges or corners.

According to one embodiment the pointing vector represents a line that points from the entrance pupil center to the point of interest. However embodiments are also well suited for using a point of interest that the pointing vector was not pointing directly at as long as the point of interest is in the image . For example if the pointing vector is not pointing at the real point of interest then the point that the pointing vector is pointing at can be used as a pseudo point of interest. The real point of interest that is also depicted in the image can be identified for example in relation to the pseudo point of interest. The pseudo point of interest can be represented by a single pixel or a group of pixels in an image where the single pixel or the group of pixels represents anything in the field of view captured with the image . For example a pseudo point of interest can be any type of point or feature that a point of interest can be. Further the pseudo point of interest may represent something that is not a real point of interest. For example the pseudo point of interest may be anywhere on a wall where there are no corners windows or doors or other features.

Photogrammetric techniques that are well known in the art can be used to determine the three dimensional location of the real point of interest for example based on the three dimensional relationship between the real point of interest and the pseudo point of interest and angles and scale factors determined during a data capture event.

A real point of interest and or a pseudo point of interest can be selected after or before the image has been captured.

A mobile data collection platform has an orientation when an image capturing device captures an image that depicts a point of interest. The orientation of the mobile data collection platform when the image is captured is stored as orientation information . Examples of orientation information includes one or more of tilt angle and tilt direction as determined by the azimuth angle given by the internal compass . Inertial orientation information includes tilt angle.

The tilt angle refers to an angle between a real world vertical axis e.g. local gravity vector and a vertical axis of the mobile data collection platform. The tilt direction refers to orientation typically relative to the local vertical axis in the x and y directions or may be represented in a polar coordinate system Azimuth angle or referred to as just azimuth refers to an angle between a reference direction and a line from the user of the mobile data collection platform to the point of interest as projected on the same plane as the reference direction typically a horizontal plane. Examples of a reference direction are true north magnetic north or a reference target at a known location from which the direction vector can be determined for example.

The local coordinate system includes the X local axis which represents east the Y local axis which represents north and the Z local axis which represents the local gravity vector .

The platform coordinate system of the mobile data collection platform includes the x platform axis the y platform axis and the z platform axis . According to one embodiment the y platform axis is parallel with the MDCP s length the z platform axis is parallel with the MDCP s depth and the x platform axis is parallel with the MDCP s width.

One end of the pointing vector PV is located at the entrance pupil center X0 Y0 Z0 of the image capturing device and the other end of the pointing vector PV is located at the point of interest or a pseudo point of interest. The pointing vector PV lies along the center line of the axis of the lens and its pupil.

The horizontal plane HP is about the three dimensional coordinates X0 Y0 Z0 of the entrance pupil s center. The horizontal line HL is in the horizontal plane HP. One end of the horizontal line HL is located at the entrance pupil center s coordinates X0 Y0 Z0. The horizontal line HL is directly below the pointing vector PV so that the horizontal line HL and the pointing vector PV are in the same vertical plane.

The tilt angle T is between the Z local axis and the y platform axis . The azimuth angle AZ is between the Y local axis north and the horizontal line HL. The elevation angle EL is between the horizontal line HL and the pointing vector PV. According to one embodiment the tilt angle T and the elevation angle EL measure have the same measurement by congruent triangles. Therefore the measurement of the tilt angle T can be used as the measurement of the elevation angle EL.

Point is located in the horizontal line HL and is directly below the point of interest . There is a distance between the point of interest and the point . The line that represents the distance is parallel with the local gravity vector .

The pointing vector PV is in the negative direction of the z platform axis . The x platform axis and the y platform axis are horizontal and vertical measurements of the image view. For example the y platform axis is the vertical dimension of an image and the x platform axis is the horizontal dimension of the image .

According to one embodiment the mobile data collection platform is or includes a tilt sensor that is 2 or 3 axis accelerometer. Typically modern smart phones and tablets include a 2 or 3 axis accelerometer. Therefore the mobile data collection platform is sensing the earth s gravity vector and as a result can automatically perform the same function that is manually performed for a typical optical total station that is known as leveling. Therefore a mobile data collection platform can determine the tilt angle T as measured from a local gravity vector which is vertical for any orientation of the mobile data collection platform .

The body of a mobile data collection platform and its principal axes are not the same axes that are represented in the local coordinates. As discussed herein the local gravity vector is used as the Z local axis true north is used as the Y local axis and east is used as the X local axis as depicted in . The axes of the platform coordinate system are the x platform axis the z platform axis and the y platform axis as depicted in and are the principal axes of the body of the mobile data collection platform .

According to one embodiment when a user points their mobile data collection platform at a point of interest the mobile data collection platform has a vector direction along the optical axis of the image capturing device which may be referred to as one of the principal axes of the mobile data collection platform . Herein it is referred to as the pointing vector PV but may also be referred to as a negative z platform axis . In this case the image displayed on the display represents an x and y pair of platform axes . According to the right hand rule x platform axis may represent the horizontal directions y platform axis may represent vertical directions which are parallel to the local gravity vector or the Z vector of the local coordinate system. Therefore z platform axis may represent negative direction towards the point of interest and the positive z platform axis direction in the platform coordinate system is toward the user of the mobile data collection platform not toward the point of interest .

Because of the capability of a tilt sensor that is 2 or 3 axis accelerometer the orientation of the mobile data collection platform relative to the local gravity vector in the local coordinate system is always available. The tilt angle T as measured from the local gravity vector to the z platform axis also known as the vector direction along the optical axis is independent of the orientation of the mobile data collection platform about the optical axis depicted as pointing vector PV in . Therefore any rotation of the mobile data collection platform about the optical axis PV does not affect the tilt angle . The tilt angle T may be displayed on the display . The tilt angle may be extracted from the tilt sensor for example using an API from a suite of API s that the tilt sensor provides.

Due to the independence between the tilt angle T and the orientation of the mobile data collection platform about the optical axis PV the handheld operation of the mobile data collection platform is foolproof with respect to measuring a vertical tilt angle T towards a point of interest as centered by appropriate manipulation of the mobile data collection platform towards the point of interest . The mobile data collection platform may be rotated about the optical axis PV and the determination of the tilt angle T determination and resulting determination of the elevation angle EL will always be the same for example as long as the photographic image of the point of interest is visible within the crosshair display overlay as depicted in . Therefore handheld operation of the mobile data collection platform is greatly simplified and no tripod or monopod is required.

According to one embodiment there are no intermediate operations required to determine the tilt angle . If the point of interest is in the center of the crosshairs display overlay then the tilt angle with respect to the point of interest is defined. If the point of interest is not in the center of the crosshairs display overlay also referred to as misalignment of the point of interest with respect to the crosshairs center the misalignment can be compensated for based on the number of pixels in the image from a pixel in the image that is represented by the center to a location of a pixel that represents the point of interest in the image and applying the angular correction appropriate for each pixels angular displacement.

Because the tilt angle T that is obtained from the tilt sensor is measured with respect to the local gravity vector by congruent triangles this tilt angle T is exactly the same as the elevation angle EL that is used for polar coordinate operations to convert the mobile data collection platform s data into the local coordinates.

The position fix of a mobile data collection platform is determined at the location of the antenna . However the position of an image is defined to be at the entrance pupil of the mobile data collection platform. The local gravity vector and the tilt angle are determined using the orientation system . Information relating the geometric relationship between the entrance pupil and the antenna also referred to as antenna to entrance pupil center geometric information or known spatial relationship can be used according to various embodiments.

The y platform axis is oriented along the length of the mobile data collection platform and the z platform axis is oriented along the depth of the mobile data collection platform . The horizontal line HL is horizontal with ground level and the entrance pupil center is one end of the horizontal line HL.

The pointing vector PV is from the entrance pupil center to the point of interest and the distance is between the entrance pupil center and the point of interest . The pointing vector PV is perpendicular to the front face of the mobile data capturing platform . For example the pointing vector PV is at a right angle with both the y platform axis and the x platform axis .

The line is an imaginary line that represents the local gravity vector . The tilt angle and the tilt direction are used to place the imaginary line that represents the local gravity vector through the center of the entrance pupil. The imaginary line that represents the local gravity vector could be drawn other places besides through the entrance pupil center based on the tilt angle and tilt direction.

The elevation angle E is the angle between the horizontal line HL and the pointing vector PV. The tilt angle is the angle between the local gravity vector and the y platform axis .

According to one embodiment z platform coordinate system is defined by x y z platform axes or also referred to as axes of the platform coordinate system associated respectively with the three sides of a mobile data collection platform . The mobile data collection platform can be tilted with respect to one or more of the x y and z platform axes and of the platform coordinate system. The tilt angle and tilt direction reflect the tilt of the mobile data collection platform with respect to the one or more x y and z platform axes of the platform coordinate system according to one embodiment.

According to one embodiment the image capturing device is in a known spatial relationship with the mobile data collection platform. For example one or more of the offsets depicted in and or the offsets and in can be used for defining the known spatial relationship between the image capturing device and the mobile data collection platform. According to one embodiment the known spatial relationship is also a known physical relationship or a known physical spatial relationship.

The antenna to entrance pupil center geometric information may be used to translate the GNSS position fix Xpf Ypf Zpf from the antenna to the position of the entrance pupil center or vice versa. Any combination of the GNSS position fix Xpf Ypf Zpf and the position X0 Y0 Z0 of the entrance pupil center can be related to each other using one or more of y axis offset x axis offset and z axis offset .

Referring to one or more of and the GPS position fix is a three dimensional position of and obtained from the antenna in the GNSS coordinate system. As depicted the GPS position fix is Xpf Ypf and Zpf respectively for latitude longitude and altitude. The local gravity vector true north and east are respectively the Z local axis the Y local axis and the X local axis of the local coordinate system. Note that the local coordinate frame and the definition just given are not the same as the coordinate frame for the mobile data collection platform. However data in one coordinate system may be translated into data in the other coordinate system for example using known spatial relationships as discussed herein. X0 Y0 Z0 is the three dimensional position of the entrance pupil center in the local coordinate system. The known spatial relationship between the antenna and the entrance pupil center and the orientation information which includes the tilt angle and tilt direction can be used to translate the GPS position fix Xpf Ypf Zpf into the three dimensional position X0 Y0 Z0 of the entrance pupil center in the local coordinate system. The known spatial relationship also known as antenna to entrance pupil center geometric information between the antenna and the entrance pupil center include one or more of the y axis offset the x axis offset and the z axis offset .

By way of clarification the side view of the mobile data collection platform in shows a reference coordinate system for the platform and for the local coordinate system. This is further exemplified in where the platform coordinates are shown and the world coordinates as defined by the local coordinate system are shown.

According to one embodiment the mobile data collection platform is not required to be level as a part of capturing an image determining a position fix and determining orientation information . The mobile data collection platform may be level if so desired. Leveling may be obtained by adjusting the mobile data collection platform s orientation using a support structure such as a tripod and using the tilt information to determine a 90 degree platform angle relative to the gravity vector. For example when both of the platform axes are 90 degrees relative to the local gravity vector then the mobile data collection platform is level.

However the mobile data collection platform is not required to be level to determine a tilt angle as is necessary in a more conventional total station. Further the tilt angle is obtained directly regardless of any rotation of the mobile data collection platform with respect to the pointing vector. When making measurements of objects on the ground or below the user it may be useful to actually level the platform. In this case both sides of the mobile data collection platform must be perpendicular to the local gravity vector then the mobile data collection platform is level. However since the mobile data collection platform provides orientation information via the 2 or 3 axis accelerometer and orientation system it is not required to be level.

Referring to scale information that may be used as a part of determining a distance between the mobile data collection platform and the point of interest can also be obtained. The scale information may be the depiction of an object which has a known dimension in the captured image. Examples of a known dimension are length width and diameter that are known. For example the dimensions of a ruler or a quarter are known e.g. a U.S. quarter is 24.3 mm in diameter. In another example a feature that appears in the image may be measured and the measurement may be used as the scale information. More specifically one side of a window a door or side of a building for example that appears in the image could be measured and used as scale information. To do this with a single image capture the camera must be on a pointing vector line that is perpendicular to the midpoint of the scale object. As this is hard to do a second image may be captured and processed photogrammetrically. In yet another example a second image that also depicts the point of interest is captured with the image capturing device at a second location where the first location and the second location are separated by a known distance. In this case the scale information can include one or more of the first and second images the first and second locations such as position fixes and orientations of the mobile data collection platform when the first and second images were captured and the known distance between the first and second locations where the two images were captured. The distance between the first and second locations may be determined from the position fixes obtained at those two locations.

According to one embodiment the scale information is any information that can be used in determining the distance between the point of interest and and the three dimensional location X0 Y0 Z0 of the entrance pupil center . Scale information can also be referred to as distance between point of interest and mobile data collection platform information. 

According to one embodiment scale information can be both the depiction of an object with at least one known dimension in an image and a distance between two positions P P that two images of a point of interest were captured from.

According to one embodiment a mobile data collection platform includes a user interface that can be displayed on the mobile data collection platform s display . depicts a user interface according to one embodiment.

The user interface includes a crosshair display overlay also referred to as crosshairs and a graphical bubble level overlay also referred to as graphical bubble level or bubble level .

The crosshair display overlay depicts a photographic image of the point of interest . As depicted in the photographic image is not in the center of the intersection of the two crosshairs but instead is slightly down and to the left of the center . If a photographic image of a point of interest is in the center of the crosshair display overlay then the optical axis from the entrance pupil center is in alignment with the point of interest . The pointing vector PV is coaxial with the optical axis according to one embodiment. According to one embodiment if the photographic image of a point of interest appears anywhere in the crosshair display overlay when the user presses the accept data button the point of interest is a user selected point of interest.

According to one embodiment a mobile data collection platform includes a bubble level processing logic and an image capturing device . The better the mobile data collection platform itself is aligned with a point of interest the better the accuracy of the determined position of the point of interest may be. In an embodiment mobile data collection platforms that are equipped with both an image capturing device and a tilt sensor may be used to aid in positioning the image capturing device more precisely over a target point of interest .

Referring now to mobile data collection platform may be held so it is looking downward over the point of interest as is shown in . The image captured depicts according to one embodiment the point of interest the object and the reference point . In accordance with one embodiment the bubble level processing logic provides an aiming pointing aide such as a graphical bubble level overlay with a set of concentric circles or concentric squares or other such visual aide around the center of the graphical bubble level overlay which can be displayed on the display of mobile data collection platform when the image capturing device is activated and displaying an image . According to one embodiment the crosshair display overlay overlays the image displayed on the display . Similarly the tilt sensor may have its output conditioned to display the degree of alignment of the display with a horizontal plane one that is perpendicular to a local gravity vector that represents vertical. That is tilt sensor may be used as an indicator of how level the body of mobile data collection platform is by indicating the tilt angles from vertical in two dimensions left right and up down relative to the view screen of mobile data collection platform when it is held horizontally with the screen of display face up. The coordinates are North South and East West in the coordinate space. Alternatively bubble level processing logic can display a graphical version of a bubble level such as the graphical bubble and the bubble level overlay in which a small circle representing a bubble is constrained to move within a pair of concentric circles emulating a mechanical bubble level. The graphical bubble position as depicted by the bubble within the pair of circles as depicted by the bubble level overlay is moved in proportion to the degree of tilt in the two orthogonal axes of the mobile data collection platform .

In an embodiment a single measurement of the degree of tilt from vertical given in degrees either from vertical or from a horizontal plane from the tilt sensor may be displayed. The direction of the tilt angle as projected on a horizontal plane may be determined from the compass heading when the tilt of the body of the mobile data collection platform is aligned with the major axis of the body of the mobile data collection platform.

In an embodiment better accuracy in locating a desired point of interest may be obtained by incorporating the offset distance e.g. offset of between the entrance pupil center of image capturing device and the location of the GNSS GPS antenna .

In the example depicted in the photographic image of the point of interest is not yet in the exact center of the aiming crosshairs of the crosshair display overlay . Embodiments are well suited to the photographic image of the point of interest being located in the center or not being located in the center as discussed herein. In bubble level processing logic has generated a graphical bubble level overlay to facilitate a user in aligning the mobile data collection platform relative to the local gravity vector.

In accordance with one embodiment bubble level processing logic can incorporate the offset distances and to more precisely determine the coordinates of the point of interest especially when the photographic image of the point of interest is in the center of the crosshair display overlay .

In one embodiment the position of reference point and of mobile data collection platform can be determined using photogrammetric processing of an image captured by mobile data collection platform . For example in accordance with one embodiment mobile data collection platform can access a remotely located database of geo tagged images wherein an image of the reference point is captured by the image capturing device and delivered to the database of geo tagged images for matching using photogrammetric processing. Therefore according to one embodiment the reference point is what is referred to as a georeference point of interest or a georeference feature. A position fix for a location of a georeference point of interest is referred to as a georeference position fix. For more information about georeference points of interest or georeference features and georeference position fix refer to U.S. 2011 0064312 filed on Sep. 14 2009 entitled Image Based Georeferencing by Janky et al and assigned to the assignee of the present application. Once the reference point has been identified in the database the coordinates of reference point can be delivered from the database to mobile data collection platform . The coordinates of the reference point may be three dimensional coordinates.

Object is an object of known width or dimensions that can be used for example as scale information. Since the object has a known width or dimension it can provide a scale that can be used for determining the distance between the point of interest and the mobile data collection platform .

Although has been described in the context of mobile data collection platform embodiments that pertain to are suitable for being used for other mobile data collection platforms such as as described herein.

According to one embodiment the entrance pupil center is one end of the pointing vector and the pseudo point of interest is located at the other end of the pointing vector . Therefore according to one embodiment the pixel or group of pixels that represents the pseudo point of interest would be located at the crosshair display overlay s center .

The crosshairs processing logic receives and processes information with respect to the crosshair display overlay . For example the crosshairs processing logic can receive information indicating that a photographic image of a point of interest is inside of the crosshair display overlay and use the received information to mark the point of interest as a user specified point of interest. In another example the crosshair display overlay can be used to measure how closely the axis with respect to being in alignment with the point of interest . For example if the photographic image is right in the center then the axis is in alignment with the point of interest . If the photographic image is inside of the crosshair display overlay but off center the crosshairs processing logic can measure how far the photographic image is from the center and in what direction. The measurement may be a two dimensional measurement since the crosshair display overlay is two dimensional.

The bubble level processing logic can receive information from the tilt sensor and use the received information to display a graphical visual representation of a bubble inside of the electronic bubble level overlay . According to one embodiment the bubble level that is used according to various embodiments is not a physical or mechanical bubble level that has a physical or mechanical bubble but instead is a bubble level that is displayed in a graphical display also referred to herein as a graphical bubble level .

As depicted in the mobile data collection platform s front is pointing downwards at the ground. However embodiments are well suited to using the mobile data collection platform when the mobile data collection platform s front is facing forward and or perpendicular to the ground for example as depicted in . According to various embodiments the bubble level can be used when the mobile data collection platform is facing downwards as depicted in or facing forward and or perpendicular to the ground as depicted in . For example a user can select between a downward facing mode or a forward facing mode using a graphical user interface displayed on the mobile data collection platform s display . If the downward facing mode is selected then the bubble level can be in a downward facing orientation as depicted in . If the forward facing mode is selected then the bubble level can be used in a forward facing orientation as would be the case for .

According to one embodiment the distance between two positions processing logic obtains the position fixes associated with two locations that a mobile data collection platform took images of a point of interest and determines a distance between the two locations based on the position fixes.

Referring to the image taken with a mobile data collection platform associated with the coordinates X0 Y0 Z0 according to one embodiment includes the point of interest and the object . The object is an object of a known dimension such as one or more of width diameter length that can be used for example as scale information as described herein. For example the object could be a yardstick. The object could be affixed to the wall by the operator of the Mobile Data Collection Platform .

Z0 is the point where the pointing vector PV and the local gravity vector which represents the Z local axis intersect. The tilt angle is the angle between the entrance pupil center and the local gravity vector represented by the Z local axis . The tilt direction indicates the direction the mobile data collection platform is tilted with respect to the local gravity vector . In this example the top of the mobile data collection platform is further back than the bottom of the mobile data collection platform .

The radial distance between distance D and the point of interest may be determined once observations are taken at two spaced apart locations P and P for the mobile data collection platform. The principles are well known in the photogrammetric arts. As depicted in a first image of the point of interest is taken at position P and a second image of the point of interest is taken at position P. The two positions P and P are separated by a distance D also referred to as the distance line D . According to one embodiment the distance between two positions processing logic obtains the position fixes associated with two locations P P that a mobile data collection platform took images of a point of interest and determines the distance D between the two locations P P based on the position fixes. Respective first and second orientation information of the mobile data collection platform is associated with the positions P and P. depicts respective pointing vectors PV and PV from the entrance pupil center to the point of interest for the respective positions P and P.

As depicted in there is a first line from P in the direction of true north also referred to as first true north line and a second line from P in the direction of true north also referred to as second true north line . The two lines and are parallel to each other since they are both in the direction of true north. Both of the lines and are perpendicular to the line that represents the distance D. These are examples for the sake of explanation. The directions may be arbitrarily chosen.

The three dimensional coordinates of the positions P and P are GPS positions and are known. The GPS three dimensional coordinates for P are X1 Y1 Z1. The GPS three dimensional coordinates for P are X2 Y2 Z2. P and P are three dimensional positions in the GNSS coordinate system. Distance D can be calculated by subtracting the GPS position fixes X1 Y1 Z1 for P and X2 Y2 Z2 for P using the vector equation D P P.

Referring to the scale information can include one or more of the first image taken from P and the second image taken from P the first coordinates X1 Y1 Z1 for the location P the second coordinates X2 Y2 Z2 for the location P the respective orientations of the mobile data collection platform when it captured images at P and P and the known distance D between the first location P and the second location P.

According to one embodiment scale information can be both the depiction of an object with at least one known dimension in an image and a distance D between two positions P P that two images of a point of interest were captured from.

The two images position fixes of the MDCP when at positions P and P orientation information of the MDCP at positions P and P and the distance D can be stored in the hardware memory .

At the display of the graphical bubble level overlay and graphical bubble on the display is activated.

At tilt and orientation information is obtained. For example the tilt angle and tilt direction can be obtained respectively from the tilt sensor and the compass .

At the display of the bubble on display is updated in real time as new Euler angles are obtained from the tilt sensor .

At a position determination mode is selected. In accordance with one embodiment if no position determination mode is selected the last operating position fix system is automatically selected.

At Euler angles from the tilt sensor are stored for example in hardware memory as the Euler angles become available.

At an image that includes at least one point of interest is captured where an image capturing device that is part of the mobile data collection platform captures the image .

At raw observables for the mobile data collection platform are obtained. For example a GNSS chipset of the mobile data collection platform is accessed and raw observables are extracted from the mobile data collection platform s GNSS chipset . In another example the raw observables are received by the mobile data collection platform from an optional external GNSS raw observable provider . A mobile data collection platform can use the raw observables received from the optional external GNSS raw observable provider even if the mobile data collection platform has an internal GNSS chipset .

The raw observables from either the internal GNSS chipset or the external GNSS raw observable provider are for use outside the GNSS chipset and elsewhere in the mobile data collection platform for example in a supl client as discussed herein. Other examples of outside the GNSS chipset and elsewhere in the mobile data collection platform include processing logic and . Examples of for use elsewhere include being executed by a hardware processor that is inside the mobile data collection platform and outside of the GNSS chipset . According to one embodiment the hardware processor executes the processing logic and .

At a position fix Xpf Ypf Zpf of the mobile data collection platform is determined based on the raw observables. For example the raw observables that are extracted from the GNSS chipset can be processed according to various embodiments described herein to determine a position fix Xpf Ypf Zpf. The position fix Xpf Ypf Zpf according to one embodiment provides a location of the mobile data collection platform in a GNSS coordinate system.

Various embodiments described herein can be used for smoothing pseudoranges correcting pseudoranges before determining the position fix Xpf Ypf Zpf as described herein. Various embodiments can be used for applying locally measured movement information to a position fix of the antenna to determine a locally measured movement smoothed position fix. In this case the position fix Xpf Ypf Zpf is a locally measured movement smoothed position fix. Examples of a locally measured movement smoothed position fix are B D and F.

For example the orientation information can be obtained from one or more sensors that are part of the mobile data collection platform . Orientation information can include tilt angle and azimuth angle AZ as discussed herein. According to one embodiment Euler angles are obtained from the tilt sensor and translated into the tilt angle . The azimuth angle AZ can be obtained based on information from the compass .

The tilt angle and the azimuth angle AZ can be determined based on data from an accelerometer type tilt sensor . An accelerometer type tilt sensor is able to determine the tilt angle of the sensor s X and Y axis relative to gravity in addition to determining the tilt angle . The tilt angle is often used to mean both of the sensor s X and Y axis. The magnetic sensor triad of the accelerometer type tilt sensor can then be used to determine the azimuth angle AZ. For more information refer to Tilt Measurement Using a Low g 3 axis Accelerometer published April 2010 document ID 17289 Rev 1 also known as AN3461 from Freescale .

The tilt angle is between the mobile data collection platform and a local gravity vector and the azimuth angle AZ is between true north and a pointing vector PV of the mobile data collection platform. The position fix Xpf Ypf Zpf and the orientation information are associated with a three dimensional location X0 Y0 Z0 of the mobile data collection platform when the image was captured. According to one embodiment the three dimensional location X0 Y0 Z0 is the three dimensional position of the entrance pupil center .

The position fix Xpf Ypf Zpf and the orientation can be associated with the image by the mobile data collection platform s user holding the mobile data collection platform in the same position during the capturing of the image the determining of the position fix Xpf Ypf Zpf and the determining of the orientation according to one embodiment. Examples of orientation are the tilt angle and the tilt direction also known as the azimuth angle . In another example the position fix and the orientation information can be associated with the image by simultaneously or nearly simultaneously capturing of the image determining of the position fix Xpf Ypf Zpf and determining of the orientation information . An example of nearly simultaneously is performing the capturing of the image determining of the position fix Xpf Ypf Zpf and determining of the orientation information in a short period of time where user movement is small to non existent. More specifically modern electronics are capable of performing the capturing of the image the determining of the position fix Xpf Ypf Zpf and the determining of the orientation information within 0.25 second for example in response to a button of the mobile data collection platform being pressed. Alternatively a timer can be used instead of the button to trigger performing the capturing of the image the determining of the position fix Xpf Ypf Zpf and the determining of the orientation information within 0.25 second for example.

One example of scale information is an object depicted in the image where the object has one or more known dimensions. The depiction of the scale information in the image is an example of capturing the scale information. Referring to another example of scale information is the known distance D between two positions P P where two respective images were captured where both images depict of the point of interest . For example the first image which depicts the point of interest may be captured with an image capturing device from position P and the second image which also depicts the point of interest may be captured with the mobile data collection platform from position P. Examples of capturing the known distance D are a person determining or measuring the distance D or determining the distance D by subtracting a first position fix of the mobile data collection platform for a the first position P from a second position fix of the MDCP for the second position P.

At the image the position fix Xpf Ypf Zpf the scale information and the orientation information are stored in hardware memory of the mobile data collection platform. The position fix Xpf Ypf Zpf is stored as position fix . The image the position fix and the orientation information can be used to determine a location of a point of interest in the image using for example photogrammetry. Photogrammetry is well known in the arts. According to one embodiment the image the position fix and the orientation information can be used to determine a three dimensional location Xpt Ypt Zpt of the point of interest . According to one embodiment the three dimensional location Xpt Ypt Zpt of the point of interest is determined in the local coordinate system.

According to one embodiment the method can be performed for example within a fraction of a second so that the mobile data collection platform is at the position fix Xpf Ypf Zpf and in the orientation described by orientation information at the time that the image is captured.

Various embodiments provide for capturing depiction an object with at least one known dimension wherein the image depicts the object with the at least one known dimension.

Various embodiments provide for capturing a first image and a second image that both depict the point of interest wherein the first image is captured from a first position P and the second image is captured from a second position P and for calculating a distance D between the first position P and the second position P.

Various embodiments provide for determining a first position P wherein the first position P is selected from a group consisting of a position of a georeference point of interest and a position fix Xpf Ypf Zpf of the mobile data collection platform where the point of interest is in a field of view of the image capturing device determining a second position P wherein the second position P is selected from the group consisting of the position of the georeference point of interest and the position fix Xpf Ypf Zpf of the mobile data collection platform where the point of interest in the field of view and determining a reference distance D between the first position P and the second position P.

An embodiment provides for determining the orientation information comprising the tilt angle and the azimuth angle wherein the tilt angle is between a y platform axis of the mobile data collection platform and a local gravity vector and the azimuth angle is between a reference direction and a pointing vector of the mobile data collection platform. For example the determined orientation information can include the tilt angle and the azimuth angle AZ wherein the tilt angle is between a y platform axis of the mobile data collection platform and a local gravity vector and the azimuth angle AZ is between a reference direction such as magnetic north or true north and a pointing vector PV of the mobile data collection platform .

According to one embodiment the pointing vector PV is in a known orientation relative to a compass heading such as magnetic north. According to one embodiment the pointing vector PV is aligned with the compass heading.

According to one embodiment the pointing vector PV is aligned with the compass heading. For example the user of the mobile data collection platform can hold the MDCP so that the pointing vector PV is aligned with the compass heading from the compass .

Various embodiments provide for capturing angular displacement from a first point on a scalar reference to a second point on the scalar reference visible in a field of view as given by a pixel count from the first point to the second point. For example the angular displacement from one end of a scalar reference to the other end of the scalar reference visible in the field of view of an image can be captured by counting the pixels from the one end to the other end of the scalar reference .

Various embodiments provide for calibrating the mobile data collection platform by determining a pixel calibration datum providing the angular displacement of each pixel in two dimensions depicted in a calibration image taken with the image capturing device. For example according to one embodiment the mobile data collection platform can be calibrated by determining a pixel calibration datum providing the angular displacement of each pixel in a calibration image in two dimensions where the calibration image is taken with an image capturing device of a pattern .

Various embodiments provide for calibrating the mobile data collection platform by determining an acceptable region in a calibration image taken with the image capturing device wherein the acceptable region includes a subset of pixels of the calibration image where the pixels do not exceed a specified level of distortion also known as an acceptable level of distortion . For example according to one embodiment the mobile data collection platform is calibrated by determining an acceptable region in a calibration image taken with the image capturing device that includes a subset of the calibration image s pixels that do not exceed an acceptable level of distortion. According to one embodiment the acceptable region includes a subset of the calibration image s pixels because the pixels in the unacceptable region that is between the boundary of the acceptable region and the periphery of the calibration image are not included in the subset.

Various embodiments provide for receiving outline information describing an outline of the point of interest and designating the point of interest as a user specified point of interest based on the outline information. For example according to one embodiment outline information describing an outline of the point of interest is received and the point of interest is designated as a user specified point of interest based on the outline information.

Various embodiments provide for designating the point of interest as a user specified point of interest based on orientation information from crosshairs processing logic associated with the mobile data collection platform when crosshairs are aligned with the point of interest and an image capture button is pressed. For example according to one embodiment designating the point of interest as a user specified point of interest based on orientation information from the orientation system associated with the mobile data collection platform when the crosshairs of the crosshair display overlay are aligned with the point of interest and an image capture button is pressed to capture the image .

Various embodiments provide for designating the point of interest as a user specified point of interest based on an annotation from an image editor associated with the mobile data collection platform. For example according to one embodiment the point of interest is designated as a user specified point of interest based on an annotation from an image editor associated with the mobile data collection platform .

Various embodiments provide for receiving annotation information and associating the annotation information with the image. For example according to one embodiment the annotation information is received and associated with the image . The annotation information can be associated with the image using an EXIF file. The annotation information can be associated with the file using other techniques that are well known in the art such as tables pointers identifiers.

Various embodiments provide for performing feature identification on at least a subset of the image. For example according to one embodiment feature identification is performed on at least a subset of the image .

Various embodiments provide for performing pattern recognition on at least a subset of the image. For example according to one embodiment pattern recognition is performed on at least a subset of the image .

Various embodiments provide for displaying crosshair display overlay on a display of the mobile data collection platform displaying a photographic image of the point of interest in relation to the crosshair display overlay and positioning the photographic image with respect to the crosshair display overlay based on an alignment of an entrance pupil of the mobile data collection platform with the point of interest. For example according to one embodiment crosshair display overlay is displayed on a display of the mobile data collection platform a photographic image of the point of interest positioned in relation to the crosshair display overlay and the photographic image is displayed with respect to the crosshair display overlay based on an alignment of an entrance pupil center of the mobile data collection platform with the point of interest .

Various embodiments provide for displaying a bubble level overlay on a display of the mobile data collection platform displaying a graphical bubble in relation to the bubble level overlay and positioning the graphical bubble with respect to the bubble level overlay based on a degree of tilt of the mobile data collection platform. For example according to one embodiment a bubble level overlay is displayed on a display of the mobile data collection platform a graphical bubble is displayed in relation to the bubble level overlay and the graphical bubble is positioned with respect to the bubble level overlay based on a degree of tilt for example of two orthogonal axes of the mobile data collection platform .

According to various embodiments determining a known spatial relationship between an entrance pupil of the image capturing device and an antenna of the mobile data collection platform based on one or more geometric offsets between the entrance pupil and the antenna. For example according to one embodiment a known spatial relationship between an entrance pupil center of the image capturing device and an antenna of the mobile data collection platform is determined based on one or more geometric offsets between the entrance pupil center and the antenna and .

According to one embodiment as described herein a mobile data collection platform is a cellular device.

At an image that depicts a point of interest is captured using a cellular device. For example the image that depicts the point of interest may be captured using the image capturing device .

At a three dimensional position associated with the cellular device is determined based on a local gravity vector and a position fix of the cellular device.

For example the local gravity vector can be determined using the information from the tilt sensor . The position fix Xpf Ypf Zpf which is the location of the antenna according to one embodiment can be determined and stored as position fix can be determined as described herein.

An example of a three dimensional position associated with the MDCP is the three dimensional position X0 Y0 Z0 of the entrance pupil center that is determined based on a local gravity vector and the position fix Xpf Ypf Zpf. The three dimensional position X0 Y0 Z0 is in the local coordinate system and the local gravity vector is one of the axes of the local coordinate system.

Referring to and the local gravity vector true north and east respectively are the Z local axis also known as the local gravity vector the Y local axis and the X local axis for the local coordinate system. The GPS position fix Xpf Ypf Zpf is a three dimensional position of the antenna in the GNSS coordinate system. The entrance pupil center has a three dimensional position X0 Y0 Z0 in the local coordinate system. One or more of the antenna to entrance pupil center geometric information the tilt angle the tilt direction and the local gravity vector can be used to translate the GPS position fix Xpf Ypf Zpf in the GNSS coordinate system into the entrance pupil center s three dimensional location X0 Y0 Z0 in the local coordinate system.

In another example a GPS position fix can be determined based on raw observables obtained from an optional external GNSS raw observable provider . Known spatial relationship as discussed herein between an antenna of the optional external GNSS raw observable provider and the entrance pupil center of the MDCP can be used to determine the three dimension location X0 Y0 Z0 of the entrance pupil center in the local coordinate system.

One example of scale information is an object depicted in the image where the object has one or more known dimensions. The depiction of the scale information in the image is an example of capturing the scale information. Referring to another example of scale information is the known distance D between two positions P P where two respective images were captured where both images depict of the point of interest . For example the first image which depicts the point of interest may be captured with an image capturing device from position P and the second image which also depicts the point of interest may be captured with the image capturing device from position P. Examples of capturing the known distance D are a person determining or measuring the distance D or determining the distance D by subtracting a first position fix of the MDCP for a the first position P from a second position fix of the MDCP for the second position P.

At the image the scale information and the three dimensional position are stored in hardware memory. For example the image the scale information and the three dimensional position X0 Y0 Z0 can be stored in hardware memory of the mobile data collection platform .

The MDCP is at the position fix when the image is captured. Therefore the entrance pupil center the antenna or the antenna are at the three dimensional position when the image is captured.

The MDCP is not required to be perpendicular to the local gravity vector at the time of collecting of data. For example none of the platform axis of cellular device z are required to be perpendicular to the local gravity vector at the time of the capturing of the image and the determining of the three dimensional position X0 Y0 Z0.

According to one embodiment the method can be performed for example within a fraction of a second so that the mobile data collection platform is at the position fix which would be of either antenna or antenna and in the orientation described by orientation information at the time that the image is captured.

According to various embodiments method is performed by a mobile data collection platform and outside of the internal GNSS chipset . Although many embodiments are described herein in the context of a mobile data collection platform various embodiments are also well suited for mobile data collection platform .

Either method or can be used with use cases depicted in . Either method or can be used for performing data collection at position P and position P as depicted in . For example method or could be used at position P to perform data collection and used at position P to perform data collection.

According to one embodiment capturing an item such as an image scale information distance angular displacement and so on includes storing the item for example in hardware memory such as hardware memory .

Referring to and according to one embodiment the tilt angle is between the mobile data collection platform and a local gravity vector and the azimuth angle AZ is between a reference direction such as true north and a pointing vector PV of the mobile data collection platform .

Various embodiments provide for obtaining a tilt angle and a tilt direction of the cellular device and determining the three dimensional position associated with the cellular device based at least in part on the tilt angle and the tilt direction in relation to the local gravity vector. For example according to one embodiment a tilt angle and a tilt direction of the MDCP are obtained and the three dimensional position X0 Y0 Z0 associated with the MDCP is determined based at least in part on the tilt angle and the tilt direction in relation to the local gravity vector .

Various embodiments provide for determining the three dimensional position associated with the cellular device based at least in part on geometric information relating an antenna of the cellular device with an entrance pupil center of the cellular device. For example according to one embodiment the three dimensional position X0 Y0 Z0 associated with the MDCP is determined based at least in part on geometric information such as relating an antenna of the MDCP with an entrance pupil center of the MDCP for example as depicted in and .

Various embodiments provide for designating the point of interest as a user specified point of interest based on information selected from a group consisting of annotation from an image editor an outline of the point of interest and a photographic image of the point of interest being visibly displayed within crosshair display overlay. For example according to one embodiment the point of interest is designated as a user specified point of interest based on information selected from a group consisting of annotation from an image editor an outline of the point of interest and a photographic image of the point of interest being visibly displayed within crosshair display overlay .

Various embodiments provide for displaying crosshair display overlay on a display of the cellular device displaying a photographic image of the point of interest in relation to the crosshair display overlay and positioning the photographic image with respect to the crosshair display overlay based on an alignment of an entrance pupil of the cellular device with the point of interest. For example according to one embodiment crosshair display overlay is displayed on a display of the MDCP a photographic image of the point of interest is positioned in relation to the crosshair display overlay and the photographic image is displayed with respect to the crosshair display overlay based on an alignment of an entrance pupil center of the MDCP with the point of interest .

Various embodiments provide for displaying a bubble level overlay on a display of the cellular device displaying a graphical bubble in relation to the bubble level overlay and positioning the graphical bubble with respect to the bubble level overlay based on a degree of tilt of the cellular device. For example according to one embodiment a bubble level overlay is displayed on a display of the mobile data collection platform a graphical bubble is displayed in relation to the bubble level overlay and the graphical bubble is positioned with respect to the bubble level overlay based on a degree of tilt for example of two orthogonal axes of the MDCP .

Various embodiments provide for determining a first position wherein the first position is selected from a group consisting of a position of a georeference point of interest and a position fix of the cellular device determining a second position wherein the second position fix is selected from the group consisting of the position of the georeference point of interest and the position fix of the cellular device and determining a distance between the first position and the second position. For example according to one embodiment a first position and a second position are determined where the first position and the second position are selected from a group consisting of a position of a georeference point of interest and a position fix Xpf Ypf Zpf of the mobile data collection platform and determining a distance between the first position and the second position.

Various embodiments provide for determining a known spatial relationship between an entrance pupil center of the cellular device and an antenna of the cellular device based on one or more geometric offsets between the entrance pupil center and the antenna. For example according to one embodiment a known spatial relationship between an entrance pupil of the image capturing device and an antenna of the cellular device is determined based on one or more geometric offsets between the entrance pupil center and the antenna and .

According to one embodiment the MDCP is not required to be perpendicular to the local gravity vector at the time of the capturing and the determining of the three dimensional position X0 Y0 Z0.

The mobile data collection platform includes a bus various types of software one or more hardware processors computer usable non volatile memory ROM computer usable volatile memory RAM hardware memory that includes data a display a graphical user interface GUI input output device platform orientation system cellular communications other communications receivers image capturing device bubble level system and short range communications .

The bus is connected with the one or more processors the ROM the RAM the memory the display the GUI the input output device the platform orientation system the cellular communications the other communications receivers the image capturing device the bubble level system and the short range communications . The MDCP can communicate with an optional external GNSS raw observable provider and a peripheral computer readable storage media .

Examples of software are an operating system applications and modules . Examples of an operating system applications modules include at least operating systems applications and modules as discussed herein.

The memory stores data . Examples of data include one or more images one or more position fixes orientation information and any other type of data that may be used by an MDCP or that is described herein or a combination thereof.

The ROM RAM and the memory is for storing information and instructions for the one or more processors .

The display may be a liquid crystal device cathode ray tube plasma display device or other display device suitable for creating graphic images and alphanumeric characters recognizable to a user.

The GUI includes the graphical user interface . The GUI may include other types of GUIs that may be used with an MDCP .

The input output device is for coupling the MDCP with external entities. For example in one embodiment I O device is a modem for enabling wired or wireless communications between an MDCP and an external network such as but not limited to the Internet.

Examples of other communications receivers are satellite radio terrestrial radio digital radio analog radio Wi Fi and Bluetooth protocol.

The peripheral computer readable storage media can be connected with the bus . Examples of peripheral computer readable storage media are a disk DVD or CD.

According to one embodiment an external GNSS raw observable provider provides higher quality reception of GNSS satellite signals than the GNSS chipset that is internal the cellular device of a mobile data collection platform . For example in typical GNSS antennae currently used in cellular devices the GNSS antennae are usually configured for linear polarization and not a circularly polarized design. This results in a significant loss of signal from orbiting GNSS satellites at least 3 dB. However according to one embodiment the external GNSS raw observable provider utilizes a circularly polarized GNSS antenna such as a patch antenna quadrifilier helix antenna and planar quadrifilier antenna. The circularly polarized GNSS antenna of the external GNSS raw observable provider has higher quality reception than linearly polarized antenna of an MDCP. Although many cellular devices antennas such as antenna are linearly polarized embodiments are well suited for cellular devices with high quality antennas such as antennas with a circularly polarized design.

The optional external GNSS raw observable provider can communicate with the MDCP via the short range communications . The external GNSS raw observable provider can receive raw observables communicate the raw observables to the MDCP and the MDCP can determine a position fix based on the raw observables from the external GNSS raw observable provider . The raw observables from the external GNSS satellite system are also referred to herein as external raw observables since they are received from a GNSS raw observable provider that is external to the MDCP . The raw observables obtained from the GNSS chipset that is internal to the MDCP shall be referred to as internal raw observables. 

The external raw observables from the external GNSS raw observable provider can include raw pseudoranges and one or more of real carrier phase information and Doppler Shift Information. The raw pseudoranges the real carrier phase information and the Doppler Shift Information from the external GNSS raw observable provider shall be called respectively external raw pseudoranges external Doppler Shift Information and external real carrier phase information. The MDCP can process the external raw observables according to various embodiments described herein to provide a position fix . The MDCP can use the external raw observables to determine a position fix for example instead of the internal raw observables from the GNSS chipset that is part of the MDCP . The external raw pseudoranges can be corrected or smoothed or a combination thereof as described herein. A position fix determined based on uncorrected unsmoothed external raw pseudoranges corrected unsmoothed external raw pseudoranges uncorrected smoothed external raw pseudoranges corrected smoothed external raw pseudoranges can be smoothed using locally measured movement information as described herein. The external raw pseudoranges can be smoothed using either the external Doppler Shift Information or the external real carrier phase information according to various embodiments described herein. A position fix that is determined based on external raw observables can be stored as position fix .

According to one embodiment the external GNSS raw observable provider has the type of GNSS chipset that is used in cellular devices. Therefore the GNSS chipset in the GNSS raw observable provider and the GNSS chipset in the mobile data collection platform may provide the same functionality. The GNSS chipset in the GNSS raw observable provider may provide more accuracy as is known in the GNSS receiver art than the GNSS chipset in the mobile data collection platform . An example of an optional external GNSS raw observable provider according to one embodiment is a GNSS receiver positioning system described in U.S. patent application Ser. No. 14 134 437 by Large et al. entitled GNSS Receiver Positioning System filed Dec. 19 2013.

The known spatial relationship can be one or more distances also known as offsets between an antenna of the GNSS raw observable provider and the entrance pupil center of the MDCP along respective x platform axis y platform axis and z platform axis . More specifically there may be a first distance between the GNSS raw observable provider and the entrance pupil center of the MDCP along the x platform axis a second distance between the GNSS raw observable provider and the entrance pupil center of the MDCP along the y platform axis and a third distance between the GNSS raw observable provider and the entrance pupil center of the MDCP along the z platform axis . One or more of these distances and can be used as a known spatial relationship between the GNSS raw observable provider and the MDCP . Therefore various embodiments provide for receiving external raw observables from an external GNSS raw observable provider that is external to the mobile data collection platform wherein an antenna of the external GNSS raw observable provider and an entrance pupil center of the mobile data collection platform are in a known spatial relationship and . A position fix that is determined based on external raw observables one or more of the distances the tilt angle and the tilt direction can be used to determine the three dimensional position X0 Y0 Z0 of the entrance pupil center in the local coordinate system according to various embodiments described herein.

Various embodiments provide a mobile data collection platform comprising a cellular device having a GNSS chipset that provides raw observables an antenna for receiving GNSS positioning signals and defining a location Xpf Ypf Zpf of the mobile data collection platform and a display an image capturing device that captures an image wherein the image capturing device has a known spatial relationship with a position determination system reference point provided for example by the antenna of the mobile data collection platform an orientation system that includes a tilt sensor and a compass and determines orientation information that includes tilt angle obtained from the tilt sensor and heading information AZ obtained from the compass wherein the tilt angle is between the mobile data collection platform and a local gravity vector and the heading information is an azimuth angle AZ between a pointing vector PV of the image capturing device and a reference direction hardware memory that stores the image the position fix and the orientation information and one or more hardware processors located outside of the GNSS chipset that accesses the GNSS chipset and extracts the raw observables from the GNSS chipset for use outside of the GNSS chipset elsewhere in the mobile data collection platform captures an image with the image capturing device wherein the image depicts a point of interest determines a position fix of the mobile data collection platform based on the raw observables wherein the position fix provides a location of the mobile data collection platform in a GNSS coordinate system accesses the orientation information from the orientation system wherein the orientation information and heading information AZ associated with a three dimensional location such as the entrance pupil center s location X0 Y0 Z0 or the position fix Xpf Ypf Zpf of the mobile data collection platform when the image z was captured and storing the image the position fix and the orientation information and heading information AZ in the hardware memory of the mobile data collection platform . Examples of a reference direction are true north magnetic north or a reference target at a known location from which the direction vector can be determined for example using vector algebra.

According to one embodiment the raw observables include raw pseudoranges and at least one of real carrier phase information and Doppler Shift Information. For example according to one embodiment the raw observables from the GNSS chipset include raw pseudoranges and at least one of real carrier phase information and Doppler Shift Information.

According to one embodiment the image capturing device is embedded in the cellular device as an integrated subsystem in a known location relative to a GNSS antenna of the cellular device. For example the image capturing device is embedded in the cellular device as an integrated subsystem in a known location relative to a GNSS antenna of the cellular device . For example offsets depicted in and can be used for determining the known location.

According to one embodiment the display emulates a pair of crosshairs indicative of an axial direction of an entrance pupil of the image capturing device when displaying the image. For example the display emulates a pair of crosshairs of the crosshair display overlay indicative of an axial direction of an entrance pupil center of the image capturing device when displaying the image .

According to one embodiment the mobile data collection platform includes a graphical user interface and wherein the mobile data collection platform further comprise a bubble level processing logic coupled with the orientation system that displays a virtual representation of a bubble level on the display. For example the mobile data collection platform includes a graphical user interface . The mobile data collection platform includes bubble level processing logic coupled with the orientation system that displays a virtual representation of a bubble level on the display .

According to one embodiment a position of a virtual representation of a bubble on the display is determined based on the orientation of the mobile data collection platform. For example a position of a virtual representation of a bubble on the display is determined based on the orientation of the mobile data collection platform . More specifically if the mobile data collect platform is level the virtual representation of the bubble will be in the center of the graphical bubble level overlay . However if the mobile data collect platform is tilting in one or more directions then the virtual representation of the bubble will move in a direction that corresponds with the one or more directions that the mobile data collection platform is tilting. For example the graphical user interface emulates a mechanical bubble level.

According to one embodiment the virtual representation of the bubble is visible when a tilt angle from the orientation system is less than a selected number in the range from 1 to 10 degrees from a horizontal reference. For example the virtual representation of the bubble is visible when a tilt angle from the inertial orientation system is less than a specified number in the range from 1 to 10 degrees from a horizontal reference. An example of a horizontal reference is a plane such as horizontal plane HP or a line such as second line HL that is perpendicular to the local gravity vector.

According to one embodiment the hardware processor executes instructions that provide smoothed pseudoranges by smoothing raw pseudoranges based on carrier phase information wherein the raw observables include the raw pseudoranges provide corrected smoothed pseudoranges by correcting the smoothed pseudoranges based on external corrections and determine the position fix Xpf Ypf Zpf based on the corrected smoothed pseudoranges.

According to one embodiment the hardware processor executes instructions that receive tilt angle information such as information about tilt angle from an at least one tilt sensor associated with the inertial orientation system receive azimuth angle information such as information about azimuth angle AZ from an azimuth sensor such as compass and determine a direction of a pointing vector PV emanating from an entrance pupil FIG. of the image capturing device . The tilt angle information and the azimuth angle information can be used to define the orientation of the mobile data collection platform relative to a local gravity vector .

According to one embodiment the image depicts an object with a known dimension. The object may be a coin a ruler or a yardstick for example which was placed in the field of view. The object may be a feature in the field of view that was not purposely placed there. For example the object may be the side of a window or a door where the length of the side is known and therefore be used as scale information.

According to one embodiment the hardware processor executes instructions for example in response to a user pressing a button of the MDCP to capture a first image and at a subsequent time a second image with the image capturing device where both the first image and the second image depict the point of interest determines a first position fix and a second position fix of the mobile data collection platform that correlate with respective first location P and second location P of the mobile data collection platform in the GNSS coordinate system accesses the first and second inertial orientation information from the inertial orientation system where the first inertial orientation information pertains to a first orientation of the mobile data collection platform for capturing the first image at the first location P and the second inertial orientation information pertains to a second orientation of the mobile data collection platform for capturing the second image at the second location P and stores the second image the second position fix and the second inertial orientation information in the hardware memory . The button that the user presses may be a button of the MDCP for capturing an image.

According to one embodiment the hardware processor executes instructions that calculates a distance D between the first location P and the second location P by calculating a difference between the first position fix for location P and the second position fix for location P wherein the distance D is scale information and stores the distance D in the hardware memory .

According to one embodiment the mobile data collection platform includes a tilt sensor and a compass the tilt sensor determines a tilt angle and the compass determines an azimuth angle AZ .

According to one embodiment the mobile data collection platform receives external raw observables from an external GNSS raw observable provider that is external to the mobile data collection platform wherein an antenna of the external GNSS raw observable provider and an entrance pupil center of the mobile data collection platform are in a known spatial relationship.

According to one embodiment the hardware processor further executes instructions that determine a location of the entrance pupil center based on the known spatial relationship such as one or more of distances between the antenna and the entrance pupil center .

Unless otherwise specified any one or more of the embodiments described herein can be implemented using non transitory computer readable storage medium and computer readable instructions which reside for example in computer readable storage medium of a computer system or like device. The non transitory computer readable storage medium can be any kind of physical memory that instructions can be stored on. Examples of the non transitory computer readable storage medium include but are not limited to a disk a compact disk CD a digital versatile device DVD read only memory ROM flash and so on. As described above certain processes and operations of various embodiments of the present invention are realized in one embodiment as a series of computer readable instructions e.g. software program that reside within non transitory computer readable storage memory of a computer system and are executed by the hardware processor of the computer system. When executed the instructions cause a computer system to implement the functionality of various embodiments of the present invention. For example the instructions can be executed by a central processing unit associated with the computer system. According to one embodiment the non transitory computer readable storage medium is tangible.

Unless otherwise specified one or more of the various embodiments described in the context of can be implemented as hardware such as circuitry firmware or computer readable instructions that are stored on non transitory computer readable storage medium. The computer readable instructions of the various embodiments described in the context of can be executed by a hardware processor such as central processing unit to cause a computer system to implement the functionality of various embodiments. For example according to one embodiment various embodiments described herein are implemented with computer readable instructions that are stored on computer readable storage medium that can be tangible or non transitory or a combination thereof.

The blocks that represent features in can be arranged differently than as illustrated and can implement additional or fewer features than what are described herein. Further the features represented by the blocks in can be combined in various ways. The mobile data collection platform and can be implemented using hardware hardware and software hardware and firmware or a combination thereof. Further unless specified otherwise various embodiments that are described as being a part of the mobile data collection platform whether depicted as a part of the mobile data collection platform or not can be implemented using hardware hardware and software hardware and firmware or a combination thereof.

The above illustration is only provided by way of example and not by way of limitation. There are other ways of performing the method described by the flowchart depicted herein.

Although specific operations are disclosed in various flowcharts depicted herein such operations are exemplary. That is embodiments of the present invention are well suited to performing various other operations or variations of the operations recited in the flowcharts. It is appreciated that the operations in the flowcharts may be performed in an order different than presented and that not all of the operations in the flowcharts may be performed.

The operations depicted in depicted in the flowcharts herein can be implemented as computer readable instructions hardware or firmware. According to one embodiment a mobile data collection platform and can perform one or more of the operations depicted in flowcharts herein.

The embodiments described herein transform data or modify data to transform the state of a mobile data collection platform for at least the reason that by extracting pseudorange information from a GNSS chipset for use elsewhere the state of the mobile data collection platform is transformed from an entity that is not capable of determining a position fix itself into a mobile data collection platform that is capable of determining a position fix itself. In another example embodiments described herein transform the state of a mobile data collection platform and from not being capable of providing an improved accuracy position fix to being capable of providing an improved accuracy position fix.

Reference will now be made in detail to various embodiments of the subject matter examples of which are illustrated in the accompanying drawings. While various embodiments are discussed herein it will be understood that they are not intended to limit to these embodiments. On the contrary the presented embodiments are intended to cover alternatives modifications and equivalents which may be included within the spirit and scope the various embodiments as defined by the appended claims. Furthermore in the following Description of Embodiments numerous specific details are set forth in order to provide a thorough understanding of embodiments of the present subject matter. However embodiments may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail as not to unnecessarily obscure aspects of the described embodiments.

Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the description of embodiments discussions utilizing terms such as providing collecting capturing obtaining accessing determining measuring receiving storing illuminating monitoring activating requesting coupling associating maintaining transmitting communicating altering detecting focusing integrating executing performing extracting using correcting smoothing reconstructing modeling improving adjusting filtering discarding removing selecting locating positioning increasing differentiating bridging displaying calculating notifying matching creating generating deactivating initiating terminating interpolating changing replacing causing transforming data modifying data to transform the state of a computer system or the like refer to the actions and processes of a computer system data storage system storage system controller microcontroller hardware processor or similar electronic computing device or combination of such electronic computing devices. The computer system or similar electronic computing device manipulates and transforms data represented as physical electronic quantities within the computer system s device s registers and memories into other data similarly represented as physical quantities within the computer system s device s memories or registers or other such information storage transmission or display devices.

An external accessory can be used in conjunction with a mobile data collection platform MDCP that provides additional information to the mobile data collection platform. Examples of an external accessory are an external GNSS raw observable provider an external electronic distance measurement EDM accessory and an external image capturing device ICD accessory. The external image capturing device accessory may or may not be an infrared image capturing device also known as an external infrared image capturing device accessory . The external accessory can provide the additional data to the mobile data collection platform for example using a communication method such as wireless communication or wired communication. The external accessory may be a legacy device.

Another type of external accessory provides an aid to improve the quality of the data collected by the mobile data collection platform. Examples of this second type of external accessory are a monopod a tripod a physical tape measurer what is commonly known as a surveyors rod and an external laser pointer accessory.

Examples of a mobile data collection platform are a cell phone a non voice enabled cellular device a tablet computer a phablet and a mobile hand held GNSS receiver. The mobile data collection platform may be used while moving or stationary since it may be operated in a hand held position or secured for example on a monopod or tripod or a mobile platform attached to a vehicle. Examples of a tablet computer are the Microsoft Surface Apple iPads Apple iPad mini iPad tablet Nexus 7 Samsung Galaxy Tab families and the Samsung Galaxy Note. According to one embodiment a mobile data collection platform is a mobile communication device MCD with cellular communications capabilities also referred to as a cellular communication enabled mobile communication device .

The mobile data collection platform includes a bus various types of software one or more hardware processors computer usable non volatile memory ROM computer usable volatile memory RAM hardware memory that includes data a display also referred to as a display screen or screen a graphical user interface GUI input output device platform orientation system cellular device other communications receivers image capturing device bubble level system and short range communication device .

The software is connected with the ROM RAM and the memory . The bus is connected with the one or more hardware processors the ROM the RAM the memory the display the GUI the input output device the platform orientation system the cellular device the other communications receivers the image capturing device the bubble level system and the short range communication device . The MDCP can communicate with an optional external GNSS raw observable provider and a peripheral computer readable storage media .

Examples of software are an operating system A applications B and modules C. Examples of an operating system A applications B modules C include at least operating systems applications and modules as discussed herein.

The memory stores data . Examples of data include one or more images one or more position fixes orientation information any one or more known spatial relationships discussed herein and any other type of data that may be used by an MDCP or that is described herein or a combination thereof.

The GNSS raw observable provider and external EDM accessory can communicate with the MDCP via the short range communication device . The external EDM accessory includes short range communication device and an EDM system . The MDCP and the external EDM accessory can communicate with each other with their respective short range communication devices and .

Various other features are depicted in that have already been discussed herein for example at least in the context of .

The software can include accessory activation logic and accessory accessing logic . The accessory activation logic and the accessory accessing logic can reside in either applications B or modules C for example. A mobile data collection platform can be coupled and used with an external accessory according to one embodiment. The accessory activation logic detects that an image capture button such as accept data button has been pressed and requests information in response to the button being pressed from an external accessory that is attached to the mobile data collection platform . Alternatively the accessory activation logic can detect that a timer expired and request information from an external accessory in response. The accessory accessing logic receives various types of external accessory data and stores various types of external accessory data. According to various embodiments the hardware processor executes the logics and .

Hardware memory includes internal image internal position fix external IR image external position fix EDM distance measurement any one or more known spatial relationships discussed herein and orientation information . The antenna the display the logic the hardware are part of the mobile data collection platform and outside of the GNSS chipset which is internal to the mobile data collection platform . Therefore the GNSS chipset is also referred to as an internal GNSS chipset. An external IR image the external position fix that is determined based on external raw observables an EDM distance measurement and optionally one or more known spatial relationships are stored in hardware memory .

The mobile data collection platform is not required to be leveled as a part of capturing the image determining the internal position fix determining the external position fix determining the orientation information or receiving external accessory data such as external raw observables that can be used for determining the external position fix external IR image EDM distance measurement or using an external laser pointer accessory refer to in in to illuminate a point of interest. The orientation information is associated directly and automatically with a three dimensional location such as the position fix Xpf Ypf Zpf stored as position fix or the three dimensional location X0 Y0 Z0 of an entrance pupil center of the mobile data collection platform when an image is captured. The mobile data collection platform is not required to be leveled at the time that the position fix Xpf Zpf Ypf and the orientation information are determined as is common with other optical measurement devices such as theodolites or total stations.

Any one or more of the entities such as hardware image capturing device inertial orientation system compass hardware memory hardware processor that are part of the mobile data collection platform and outside of the cellular device can instead be inside of the cellular device . According to one embodiment the mobile data collection platform is a cellular device. For example a tablet type MDCP may contain all the recited hardware plus a separate cellphone module which itself can contain some of the hardware items including a GNSS chipset. Conversely the tablet type MDCP may contain a GNSS chipset whose raw observables may be made available to any of the hard processors associated with the tablet.

Various types of information can be stored for example in an EXIF file associated with the image . Examples of information that can be written into the EXIF file are the GPS position fix orientation information the tilt angle the direction of an azimuth angle also referred to as an azimuth direction or tilt direction scale information EDM distance measurement and antenna to entrance pupil center geometric information one or more known spatial relationships. Any type of information that can be used for example for determining one or more of a three dimensional position of the MDCP s entrance pupil center a three dimensional position of the center of the IR entrance pupil B a distance from the entrance pupil center to a point of interest and a location of a point of interest as will become more evident can be stored in the EXIF file. Alternatively any or more of the same information can be stored as reference information in a suitable reference file associated with the particular mobile data collection platform.

According to one embodiment the mobile data collection platform includes a SUPL client as described herein. The SUPL client can be inside of the cellular device or can be in the mobile data collection platform and outside of the cellular device . According to various embodiments the mobile data collection platform can include any one or more of features described herein. For example the mobile data collection platform can include at least any one or more features or operations depicted in or described in the context of .

The entrance pupil and the flash are exposed on the portrait back view and landscape back view in and . The positions of the entrance pupil and the flash are marked in the portrait screen and landscape screen views however they are not exposed in the portrait screen and landscape screen views. The accept data button is exposed and accessible in the portrait screen and landscape screen views.

The external accessory as depicted in includes software computer usable non volatile memory ROM computer usable volatile memory RAM 4403 hardware memory one or more hardware processors a bus a laser transmitter subsystem a receiver subsystem a clock an EDM controller a signal processing and distance data short range communication device optional wired access optional infrared IR image capturing device ICD and flash optional visible laser pointer device and a rechargeable battery .

The software one or more hardware processors ROM RAM hardware memory laser transmitter subsystem receiver subsystem clock EDM controller signal processing and distance data short range communication device wired access optional IR image capturing device and flash optional peripheral computer readable storage media optional visible laser pointer device and battery which may be rechargeable or non rechargeable are connected with the bus .

The software includes an operating system A applications B and modules C. As will become more evident the time of flight distance calculator A interface to MDCP logic A and the data storage and data transfer logic A the requested information obtaining logic and the requested information providing logic can reside in software such as applications B or modules C.

Hardware memory includes data for example that the software uses or stores. The data may be input to the software an intermediate result of computations performed by the software or a final result of computations performed by the software or a combination thereof.

The external accessory can communicate with another entity using either wireless communications via short range communication device or wired communications using wired access . The signal processing and distance data can include for example input intermediate result or final result of calculating an estimated distance measurement. The external accessory may include an optional supplemental flash. The flash devices that are typically associated with a camera tend to be weak. Therefore a supplemental flash that has more photons can be used to provide a more powerful photo flash.

As discussed herein examples of an external accessory are an external electronic distance measurement EDM accessory an external image capturing device accessory an external laser pointer accessory and an external GNSS raw observable provider . As depicted in the external accessory is a combination accessory that includes an external electronic distance measurement EDM accessory with features an external image capturing device accessory with feature and an external laser pointer accessory with feature . According to various embodiments the external image capturing device accessory and the external laser pointer accessory are optional.

Electronic distance measurement EDM devices are well known in the art. EDM devices can be used to measure distances. An EDM device computes a distance measurement from the EDM device to a point of interest on an object. For example the EDM device can transmit light from an EDM transmitter. The transmitted light can bounce off of an object. The reflected light can then be received by the EDM receiver. The EDM device can determine the distance between the object and the MDCP for example based on a difference between the time that the light was transmitted and the time that the reflected light was received also known as time of flight . According to one embodiment an electronic distance measurement accessory is used to measure a distance between a mobile distance collection platform and a point of interest a pseudo point of interest or any point on an object of interest.

The distance measurement according to one embodiment provides scale information that can be used for locating the point of interest and for enabling photogrammetric methods also known as photogrammetric data processing for determination of other points of interest in the image captured by the image capturing device of the MDCP. The distance measured is a scalar quantity but the direction is based on the orientation of the EDM device. When an external EDM accessory is connected to the MDCP in a known spatial relationship the orientation of the MCDP provides the vector direction of the distance measurement. Using an EDM minimizes the need for a two position data capture process normally needed for photogrammetry when a distance measurement is not possible. One example of a two position data capture process is depicted in .

The external EDM accessory includes an EDM case A two lenses A and A a laser transmitter A a receiver detector A a receiver processor A a pulse generator A a clock start logic A stop logic A an EDM controller time of flight distance calculator A data storage and data transfer logic A interface to MDCP logic A and short range communication device . EDM The EDM case A has a front side A also referred to as a front surface and a back side A also referred to as a back surface . The electronic distance measurement accessory s lenses A and A are located on the front side A of the accessory .

Lens A is associated with the laser transmitter A. Lens A is associated with the receiver detector A. The laser transmitter A and the pulse generator A are coupled. The pulse generator A and the start logic A are coupled. The receiver detector A and the receiver processor A are coupled and the receiver processor A and stop logic A are coupled. Start logic A and stop logic A are both coupled with the clock . Start logic A and EDM controller are coupled. The EDM controller and the interface to MDCP logic A are coupled. The interface to MDCP logic A and the short range communication device are coupled. The clock and the time of flight distance calculator A are coupled. The time of flight distance calculator A and the interface to MDCP logic A are coupled. The time of flight distance calculator A and the data storage and data transfer logic A are coupled. The data storage and data transfer logic A and the short range communication device are coupled.

The EDM case A is depicted as being parallel to the case A of the MDCP . The MDCP s case A has a front side A also known as a front surface and a back side A also known as a back surface . The MDCP s back side A also known as a back surface is the display view side where a user can view the MDCP s display . The MDCP s lens A is located on the MDCP s front side A. The lens A defines the entrance pupil of the MDCP . The optical axis A is from the entrance pupil . The optical axis A is perpendicular to the MDCP s case A. The EDM case A does not cover the lens A of the MDCP .

The laser transmitter subsystem according to one embodiment includes one or more of the receiver detector A the receiver processor A and the stop logic A. The receiver subsystem according to one embodiment includes one or more of the laser transmitter A the pulse generator A and the start logic A.

The external EDM accessory can include a pulse generator A for use in triggering a laser A to emit a short burst of light A a laser A designed to emit light A in the infrared spectrum a clock that is started by the laser trigger event an optical receiver A that detects a return of the light pulse A from a distant object of interest A and upon detection stops the clock a time of flight distance calculator A for calculating the time from start to stop for determining a round trip time of flight of the pulse a communication device such as Bluetooth for interacting with the MDCP a battery that is rechargeable or non rechargeable applications software B for managing the entire process including sending of multiple pulses and averaging the results and formatting estimated distance measurement for use by the MDCP and a USB port for software downloading and power supply.

The external EDM accessory measures the time of flight for a laser pulse to travel to and be reflected from an object of interest A that a point of interest is on. Upon initiating a measurement epoch a pulse or a series of pulses are transmitted from a laser diode source and a clock is started. Upon receipt of the return reflection laser pulse a detector system is actuated which then in turn stops the clock. The distance A to the object of interest A is given by multiplying half the time interval measured by the clock by the speed of light.

As is well known in the art the pulse generator A generates a pulse that is communicated to the laser transmitter A causing the laser transmitter A to transmit a transmitted signal A that passes through the lens A. The start logic A is in communication with the pulse generator A and uses the clock to note the time that the pulse generator A generated the pulse. The transmitted signal A contacts the object of interest A such as a wall a door or a window that includes a point of interest as discussed herein. The transmitted signal A is reflected by the object of interest A resulting in a reflected signal A that passes through the lens A and is detected by the receiver detector A. The transmitted signal A and the reflected signal A are separated by a separation distance A. The external EDM accessory measures the distance A from the external EDM accessory to the object of interest A within a maximum separation distance A. The receiver processor A communicates with the stop logic A. The stop logic A obtains the time from the clock and notes the time that the reflected signal A was received. According to one embodiment the transmitted signal A and the reflected signal A travel along a light beam axis A that is parallel to the optical axis A of the entrance pupil of the mobile data collection platform .

The time of flight distance calculator A determines the difference between the start time and the stop time also commonly known as time of flight which can be used to measure the distance A also known as EDM distance measurement between the external EDM accessory and the object of interest A. The data storage and data transfer logic A can store various data associated with the processing of the time of flight distance calculator A such as the time of flight or the distance A or a combination thereof into memory. The EDM controller can communicate with the interface to MDCP logic A to transmit the time of flight or the distance A to the MDCP using the short range communication device of the external EDM accessory . In another embodiment the external EDM accessory can communicate with the MDCP using wired communications instead of short range communication device .

EDM devices are well known in the art. The DS00 Laser Range Finder by Lightware Optoelectronics Pty LTD of Midstream Estate South Africa is one non limiting example of an EDM.

The EDM receiver B receives the reflected light B. The mirror B reflects a subset of the reflected light B and the reflected subset is focused through the lens B. The cone B represents the shape of the path of the reflected subset B between the lens B and the light sensor B. The mirror B alters the path of the reflected light B into focused reflected subset B inside of the external EDM accessory B according to one embodiment. The focused reflected subset B passes through an optical filter B as it travels to the light sensor B. The light sensor B detects the focused reflected subset B coming from the lens B and sends a signal to the EDM logic B. The EDM logic B can measures the distance also referred to as EDM distance measurement between the external EDM accessory B and the object of interest based on the time that the light was transmitted by the EDM transmitter and the time that the light sensor B detects the focused reflected subset B.

According to one embodiment an external EDM accessory B has a form factor that integrates with a mobile data collection platform by redirecting the light path. For example the EDM accessory B that includes a mirror B that reflects light provides a compact EDM where the back side of the EDM accessory B can be adjacent to and oriented along the front side of the MDCP as depicted in according to one embodiment. Therefore largest faces of both the EDM accessory B and the MDCP are parallel with each other according to one embodiment. A mounting system can also be used as a part of integrating the EDM accessory B with the MDCP .

By design the EDM laser A is not coaxial with the ICD s optical axis. As one of ordinary skill in the art understands the EDM laser beam is transmitted along the light beam axis A as depicted for example at least in . By offsetting the EDM laser beam from the lens pupil parts weight can be saved and complexity reduced. The EDM laser beam according to one embodiment is in close proximity of the ICD s entrance pupil on the MDCP. Since different MDCP s have their internal ICD s in different positions a compromise can be made. This can be accomplished by arranging the EDM laser beam to be located between the two different positions and refer to and .

Of course an off the shelf EDM may be aimed upwards or downwards or in any direction as well. But the salient feature of the off the shelf EDM is that the beam pointing vector C lies in a plane parallel to the display plane of the display controls C. However in the case where the EDM accessory is integrated with an MDCP an EDM beam pointing vector such as light beam axis A now lies in a plane perpendicular to the display as shown in the second .

In an embodiment a legacy EDM C can be mounted to the MDCP so that the case of the conventional EDM is perpendicular to the MDCP case A as shown in and . display respective legacy EDMs C that are mounted perpendicularly with an MDCP so that the legacy EDM C s principal axis D and the MDCP s principal axis C are perpendicular to each other according to various embodiments.

In a clip D is used to couple the legacy EDM C to the MDCP s side that is closest to the MDCP s lens A forming an L shape where the MDCP represents the longer leg of the L and the legacy EDM C represents the shorter leg of the L shape. A user standing inside the 90 degree angle formed by the two legs of the L shape can see both the MDCP s display and the legacy EDM s display controls C while at the same time viewing an object of interest that the MDCP s optical axis A is directed toward.

In a top bottom bracket E is used to couple the legacy EDM C to approximately the center location of the MDCP forming a T shape. A user facing the top of the T shape can see the MDCP s display . A user facing one side of the perpendicular line of the T shape can see the legacy EDM C s display controls C.

In the EDM transmit receive beams C are aligned and parallel with the EDM s principal axis D. The EDM s principal axis C EDM transmit receive beams C are parallel with the MDCP s optical axis A.

In an embodiment a suitable frame case or mounting system can hold both the MDCP and the legacy EDM in the right angle orientation needed to meet the parallel beam requirement as can be seen in .

The display controls C G H of the respective EDM C G H depicted in are on the same side of the EDM C G H as the EDM s lenses A and A. The EDM s display controls C G H and the MDCP s display are on the opposite sides of the EDM MDCP combination as depicted in according to one embodiment.

Referring to the MDCP s principal axis D and the EDM C G H s principal axis C G H are parallel with each other. As will become evident the MDCP principal axis and the external EDM accessories principal axis are also parallel with each other as depicted at least in and . Therefore in various embodiments the EDM beam along a light beam axis A C can be configured to emanate perpendicular to the EDM case A thus allowing a closer integration of EDM case A and MDCP case A as shown in and .

In contrast in a conventional handheld EDM the receiver components are longer than the thickness of most cellphones or tablet computers making it less desirable to locate the EDM detector so that its components are coaxial and parallel to the optical axis of the camera lens as depicted in . In an embodiment the reflected beam may be reflected through a 90 degree angle and directed along the case of the EDM as shown in . A mirror B may be used to perform the right angle reflection. Referring to the laser transmitter beam A can be provided by a small laser diode and may be easily fitted so its beam along light beam axis A A is also parallel to the optical axis A from the lens A of the image capturing device .

According to various embodiments depict a fully integrated data capture system. To facilitate a fully integrated data capture system using the image capturing device a location system such as the internal GNSS chipset and or the external GNSS raw observable provider an orientation system and an electronic distance measurement system the EDM case A of the external EDM accessory is coupled in a known spatial relationship to the MDCP case A of the MDCP. The form factor for the MDCP case A is that of a rectangular body with a display showing both visual data and operational controls in a graphical user interface. The display also transforms into a visual display of the image captured by the image capturing device where the entrance pupil and the display are located on opposite sides of the MDCP . This image capturing device may be referred to as the forward looking camera as shown at least in . The user typically will hold the MDCP such that the forward looking camera is aimed at a scene containing an object of interest A. The scene may be located in any direction from the user horizontal vertical upward or vertical downward or any direction as chosen by the user and the user may or may not be able to see the display clearly.

The MDCP is able according to various embodiment to capture collect data as described herein by pressing accept data button usually displayed at one end of the display and often just above the home button at the bottom of the display . Expiration of a timer can be used for capturing or collecting data as described herein. To support timer expiration or single button push data capture activity two functions are performed according to various embodiments. The single button press or the expiration of a timer that actuates the image capturing device to capture an image is also used to activate the EDM accessory calculate the distance measurement of the distance A and return the distance measurement to the MDCP for compilation with the other data such as one or more images one or more position fixes and or orientation information taken by the MDCP itself as discussed herein. The second function is that of aligning the EDM beam which travels along light beam axis A with the direction of the optical axis A of the image capturing device which is usually in a center position of the display as depicted at least in and . For example the optical axis A pointing vector PV is incident on some object of interest A and an image of the object of interest A is displayed at the center of the display often at the center see of the crosshair display overlay see if crosshair display overlay is displayed. The MDCP s lens A and the external EDM accessory s lens A and A are on the respective front sides A A of the external EDM accessory and the MDCP .

According to one embodiment an external EDM accessory B integrates with a mobile data collection platform. all depict examples of EDM accessories that can be integrated with a mobile data collection platform for example by providing a light beam axis C that is parallel with the optical axis A of the mobile data collection platform. In another example the EDM accessory B that includes a mirror B that reflects received light provides a compact EDM where the back side of the EDM accessory B can be adjacent to and oriented along the front side of the MDCP as depicted in according to one embodiment. Therefore largest faces of both the EDM accessory B and the MDCP are parallel with each other according to one embodiment. In another example of the EDM accessory integrating with the mobile data collection platform the EDM accessory does not obscure or cover up the lens A and the entrance pupil of the MDCP. Further the mounting system and or fastener systems D E can also be used as a part of integrating the EDM accessory B with the MDCP . A legacy EDM accessory can integrate with an MDCP in an L shape as depicted in or a T shape as depicted in . An EDM accessory according to various embodiments can integrate with an MDCP where the principal axes are parallel as depicted in . Other examples of the EDM accessory integrating with a mobile data collection platform include the known spatial relationship between the EDM accessory and the mobile data collection platform the user s ability to clearly see the MDCP s display while operating the combination of the MDCP and the EDM accessory while viewing a scene the MDCP controlling the operation of the EDM accessory and the EDM accessory providing output such as the EDM distance measurement in response to the MDCP s controls. These are at least a few examples of the EDM accessory B integrating with a mobile data collection platform as discussed herein.

By design the EDM laser A is not coaxial with the ICD s optical axis A. The EDM laser beam travels along the light beam axis A. By offsetting the EDM laser beam from the lens pupil parts weight can be saved and complexity reduced. The EDM laser beam according to one embodiment is in close proximity of the ICD s entrance pupil on the MDCP. Since different MDCP s have their internal ICD s in different positions a compromise can be made. This can be accomplished by arranging the EDM laser beam to be located between the two different positions and and .

According to one embodiment an electronic distance measurement device used with an MDCP is fitted to the MDCP in a convenient way for the user. Off the shelf EDMs have a package aspect that is similar to that of a cellphone rectangular cross section with dimensions on the order of approximately 3 inches wide by 4 6 inches in length with a comparatively shallow depth on the order of less than 1 inch and with a display screen on the large face with user controls. Off the shelf EDMs have their laser transmitter and optical return reflection receiver located at one narrow end of the package parallel to the long axis of the package referred to as the top of the device as depicted in . This is convenient for hand held operation in which the user aims the EDM as if it were a flashlight towards the object of interest. While such a device could be joined to a cellphone or tablet phablet its use would be awkward as it would form a T shape as depicted in or an L shape as depicted in . A further consideration derives from the fact that the image capturing device is on the face opposite the user interface so the MDCP s user is used to seeing the image displayed on a large display such as for example the MDCP s display while holding the MDCP so its largest face front side A that includes the lens A is directed towards the object of interest. Thus a more useful package configuration for joining an EDM to a cellphone type MDCP or tablet type MDCP is to mimic or extend the current shape of the cellphone type MDCP or tablet type MDCP as if the depth of the MDCP were being increased to accommodate the EDM components.

Such an embodiment is shown at least in in which an EDM package is joined to the front side A of the MDCP. The laser transmitter A and receiver detector A are configured to emanate from the largest face such as the front side A of the EDM package. Thus the EDM transmitter and receiver functions are re oriented according to one embodiment from what is commonly available in off the shelf EDMs. According to various embodiments a laser transmitter is re packaged a mirror may be used and improved optics may be used to accommodate the laser receiver as discussed herein.

The following are a choice of technical parameters that would be suitable for using an external electronic distance measurement accessory with a mobile data collection platform.

The electronic distance measurement accessory is pulsed by a control circuit such as the EDM controller . The pulse width can be on the order of 2 to 4 nanoseconds.

According to one embodiment the wavelength is in the infrared region in the range of 870 to 930 nm. The pulse power is less than the specified limit for acceptable eye safety.

The working range for the electronic distance measurement accessory is up to 50 meters m according to one embodiment. The range may vary according to the available reflectivity of the objects of interest. If a suitable laser EDM target is placed in the scene and oriented so that it is perpendicular to the axis A of the laser beam the 50 m range is achievable.

The diameter of the beam of the exit lens A of the laser is approximately 5 mm according to one embodiment and the spot diameter at 50 meters is approximately 12 to 15 mm or less according to one embodiment.

An optical bandpass filter is inserted between the receiver detector A and the lens A to reduce the effects of noise due to ambient light. The filter bandwidth is the same as preferred range of wavelength 870 to 930 nm according to one embodiment.

Signal to noise improvements are accomplished by averaging the results from thousands of pulses. A typical pulse rate is on the order 20 000 pulses per second. The external electronic distance measurement accessory is operated at 300 to 3000 pulses for a measurement epoch.

The accuracy of the distance measurement via the averaging methods is on the order of 3 mm. The number of measurements that can be made is on the order 100 per minute so there is no limitation on the user s ability to capture data.

Data on each measurement epoch is stored and transmitted to the mobile data collection platform via the communication device and is stored and associated with the image captured at the same time in the EXIF file for the image or in another suitable file with a link to the image.

The laser transmitter A is offset from the image capturing device by less than 3 centimeters cm . The axis A of the EDM beam may be aligned to be parallel with the optical axis A of the image capturing device or may be positioned so that its EDM beam crosses the optical axis A at some distance in the range of 10 30 m.

The transmit laser A is positioned on the EDM case A so that it is approximately midway between the available locations on cellphone and tablet type MDCPs. For small cellphone type MDCPs that is approximately 0.75 1 in 2 2.5 cm from a top side of the electronic distance measurement accessory.

The electronic distance measurement accessory can have an infrared flash to aid in data capture when visible light is low or it is after sunset and dark. According to one embodiment it is basically regular visible light flash tube with an infrared bandpass filter in front of the output that filters out visible light.

The electronic distance measurement accessory is powered by a rechargeable battery and an external power converter well known n the cellphone arts. The power port may be part of a USB connector or may be a separate connector.

Image capturing devices ICDs that are a part of cellular devices also referred to as internal image capturing devices typically have poor quality lenses where the image is distorted by a variety of lens aberrations so that what is a uniform distance metric in an image such as a checkerboard square pattern becomes less uniform particular near the edges of the field of view as depicted in herein. Therefore according to one embodiment an external image capturing device accessory that provides higher quality images than the internal image capturing device can be used in conjunction with a mobile data collection platform MDCP . An image that is captured with the external image capturing device accessory shall be referred to as an external image and an image captured with the internal image capturing device that is part of the MDCP shall be referred to as an internal image. 

Many of the examples described herein refer to an external image capturing device accessory that is infrared also referred to as an external infrared image capturing device accessory . However various embodiments are well suited for an external image capturing device accessory that is not infrared also referred to as an external non infrared image capturing device accessory . An infrared image capturing device accessory permits operation in poor visible lighting conditions and at night.

Referring to an external IR image capturing accessory includes an IR flash device B and an IR image capturing device B with their respective IR flash B and entrance pupil B. The external image capturing device is not required to be infrared. According to one embodiment the optical axis of the external IR image capturing device accessory and the optical axis of the MDCP s image capturing device are aligned with each other. The external IR image capturing device accessory and the MDCP can communicate using wired or wireless communications. For example the external infrared image capturing device accessory and the MDCP can communicate for example using respective communication devices . The external infrared image capturing device accessory could capture an image that depicts for example a real point of interest or a pseudo point of interest or both and communicate the image to the MDCP using their respective communication devices . An image captured by an external capturing device accessory whether infrared or non infrared can be stored in hardware memory .

According to one embodiment reflective material may be placed on or near a point of interest. The reflective material does not need to be on or near a real point of interest but instead located anywhere in the field of view. If the reflective material is not on a point of interest the location that the reflective material is on can be treated as a pseudo point of interest. The infrared image captured with the external IR image capturing device accessory will depict the area covered by the reflective material more brightly than if the reflective material were not on that area.

As discussed herein the external image capturing device accessory is not required to be infrared. In the event that the external image capturing device is not an infrared device various features B B B would not be infrared.

A laser pointer also known as a laser pen can emit a narrow beam of light that illuminates a real point of interest or a pseudo point of interest with a bright spot according to one embodiment.

Referring to an external laser pointer accessory can include a laser pointer device and a laser pupil B according to one embodiment.

The laser pointer device can emit a narrow beam of light through the laser pupil B. According to one embodiment the laser pupil B is aligned with the optical axis A of the image capturing device that is part of the MDCP . According to one embodiment the laser pupil B is within 4 centimeters of the MDCP s entrance pupil . The user of the mobile data collection platform can illuminate a point of interest with the narrow beam of light for example prior to pressing a button of the MDCP to capture an image that depicts the point of interest. An example of a button that is pressed to capture the image is an accept data button as discussed herein.

Another example of an external accessory is an external GNSS raw observable provider. Referring to the external GNSS raw observable provider is located so that it will not obscure the MDCP s entrance pupil or the MDCP s antenna. For example as depicted in the external GNSS raw observable provider is located midway on the top of the secondary accessory so that when the combination accessory which includes the external EDM accessory and the external GNSS raw observable provider is coupled for example with a fastener with the MDCP the external GNSS raw observable provider will be on top of the MDCP and between the MDCP s entrance pupil and the MDCP s antenna as will be discussed in more detail hereinafter.

The external GNSS raw observable provider can receive raw observables communicate the raw observables to the MDCP and the MDCP can determine a position fix based on the raw observables from the external GNSS raw observable provider . The raw observables from the external GNSS satellite system are also referred to herein as external raw observables since they are received from a GNSS raw observable provider that is external to the MDCP . The raw observables obtained from the GNSS chipset that is internal to the MDCP shall be referred to as internal raw observables. 

The internal raw observables can include internal raw pseudoranges and one or more of internal real carrier phase information and internal Doppler Shift Information. As discussed herein the external raw observables from the external GNSS raw observable provider can include raw pseudoranges and one or more of real carrier phase information and Doppler Shift Information. The raw pseudoranges the real carrier phase information and the Doppler Shift Information from the external GNSS raw observable provider shall be called respectively external raw pseudoranges external Doppler Shift Information and external real carrier phase information. The MDCP can process the external raw observables according to various embodiments described herein to provide a position fix.

The MDCP can use the external raw observables to determine a position fix for example instead of the internal raw observables in a manner that the internal raw observables are used to determine a position fix. For example an uncorrected unsmoothed position fix can be determined based on the external raw pseudoranges a corrected unsmoothed position fix can be determined based on the external raw pseudoranges and external corrections obtained from correction sources that are external to a mobile data collection platform an uncorrected smoothed position fix can be determined based on external raw pseudoranges and external real carrier phase information or external Doppler Shift Information or a corrected smoothed position fix can be determined based on external raw pseudoranges external corrections obtained from correction sources that are external to a mobile data collection platform and external real carrier phase information or external Doppler Shift Information using various embodiments discussed herein.

According to various embodiments there are known spatial relationships between various entities discussed herein. For example there is a known spatial relationship between the respective entrance pupils of the mobile data collection platform MDCP and the external IR image capturing device ICD accessory. In a second example there is a known spatial relationship between the entrance pupil of the external IR image capturing device accessory and the antenna of the MDCP. In a third example there is a known spatial relationship between the MDCP s entrance pupil and the antenna of an external GNSS raw observable provider. In a fourth example there is a known spatial relationship between the laser pupil and the MDCP s antenna. In a fifth example there is a known spatial relationship between the laser pupil and the antenna of an external GNSS raw observable provider.

Therefore various embodiments are well suited for determining and using known spatial relationships and combinations of known spatial relationships between any two or more entities such as 1 antenna of an external GNSS raw observable provider 2 antenna of an internal GNSS chipset 3 entrance pupil of an internal image capturing device 4 entrance pupil of an external IR image capturing accessory 5 laser pupil of a laser pointer accessory 6 EDM receiver and 7 EDM transmitter. Referring to distances and are examples of known spatial relationships.

A known spatial relationship between two entities is a known fixed relationship for example because the known spatial relationship is maintained for example with a physical coupling. A known spatial relationship is a distance between two entities. A known spatial relationship is defined as a geometric offset also referred to as an offset from one entity to another entity according to one embodiment. Therefore according to one embodiment a mobile data collection platform is disposed in a known fixed relationship with a known geometric offset from the external accessory to the mobile data collection platform or vice versa. Examples of known spatial relationships known fixed relationships known geometric offsets known fixed offsets are . However embodiments are well suited for other known spatial relationships between other entities as discussed herein.

One or more known spatial relationships can be used for determining a three dimensional position of the center of the IR entrance pupil B or the entrance pupil of the image capturing device . The three dimensional position can be determined in the platform coordinate system or in the local coordinate system defined by the X local axis Y local axis and Z local axis as depicted at least in for example in a manner that the three dimensional position of the MDCP s entrance pupil center can be determined as discussed herein.

According to various embodiments one or more of the known spatial relationships may be one dimensional two dimensional or three dimensional.

The one or more known spatial relationships as described herein can also be stored in the hardware memory as discussed herein as known spatial relationships . A user interface can be used for entering known spatial relationships. For example a user of the MDCP can measure one or more spatial relationships or the one or more spatial relationships can be obtained from the MDCP s manufacturer specification. A list of types of external accessories and a list of types of MDCPs can be displayed. One of the types of accessories and one of the types of MDCPs can be selected. The one or more known spatial relationships can be determined based on the two selected types. In another example the external accessory can communicate its type to the MDCP and the MDCP can use its type in combination with the external accessory s type to determine the one or more spatial relationships.

The relationships are known for example because they are maintained in a fixed manner and because they can be obtained determined and or accessed as discussed herein.

Various monopods or tripods may be used to support the mobile data collection platform. A monopod or tripod can be used with the mobile data collection platform that is alone or with a mobile data collection platform that is coupled with an external accessory also referred to herein as an MDCP external accessory combination . Monopods and tripods are support mechanisms that allow the user to assure minimum camera movement during image capture. They may allow the user to use an image capturing device or an image capturing device accessory at a fixed distance above or in measurable relationship to a geographically known reference point that may be on the ground of the scene to be measured. Monopods and tripods are commercially available and well known to photographers and surveying professionals. The support mechanism can be coupled with a mounting system for example by means of a standard 20 screw mechanism that is built into the external accessory. There are numerous suitable monopods and tripods that are commercially available. By example a monopod such as Benro A35FBR1 may be used. It has a coupling mechanism that includes a ball head that enables the user to orient the MDCP to any angle that is appropriate to capturing the information in the scene. A suitable tripod is the Benro model BRA2970F.

According to various embodiments a mobile data collection platform and an accessory can be coupled with each other using various types of coupling mechanisms. One or more coupling mechanisms can be used to securely couple one or more accessories with the MDCP to maintain the known spatial relationship between the one or more accessories and the MDCP. Coupling mechanisms can also be used for coupling accessories with each other.

Examples of coupling mechanisms include hook and loop strips adhesive Velcro strap L shaped brackets U shaped brackets T shaped brackets mechanical fasteners snap fit receptacles screws clothing snaps such as common found on western style shirts rotate and lock systems that can be cinched tightly or the like. Examples of mechanical fasteners are mechanical clamps mechanical brackets or the like.

The coupling mechanism can be a screw mount that is inside of the accessory s case and is screwed into the back side of the accessory. The coupling mechanism can include a bracket that is either attached to the backside of the accessory for example using a screw mount or the bracket is a part of the accessory s case where the MDCP can slide into the bracket. The length of the bracket can be adjusted to accommodate a variety of shapes and sizes of MDCP cases. The adjustments may be done by joining two pieces of the bracket such as a top piece and a bottom piece held together by for example a screw. The same screw can also fasten the bracket pieces to the back of the accessory.

The mounting system includes an interface adapter and a fastener system . Examples of an MDCP include a smart phone mobile digital device e.g. iPhone among other things as discussed herein.

The mounting system can be used to join the mobile data collection platform such as a smart phone mobile digital device e.g. iPhone type mobile data collection platform with an external accessory . According to one embodiment the fastening system is a standard mounting or fastening system for the external accessory that accepts a variety of types shapes and sizes of interface adapters for the variety of cellphones such as smart phone mobile digital device e.g. iPhone that may be used as mobile data collection platforms according to various embodiments.

The interface adapter includes a case B and a knob A according to one embodiment. The fastener system according to one embodiment is a hole.

The MDCP and the external accessory can be snap fitted into or clicked into the case B of the mounting system .

The external accessory does not covered up does not obscure the area of the MDCP which includes the entrance pupil and flash as indicated by the lines . Further as can be seen in when an external GNSS raw observable positioning system is mounted on top of another external accessory the area is not covered up. As depicted in the line is a straight vertical line. However various embodiments are well suited for the line to form an L shape that provides a cut out portion of the accessory so that none of the accessory covers up the entrance pupil or flash. For example the lower portion of the accessory s side designed by line could extend below the entrance pupil and the flash while the upper portion of line remains to the side of the entrance pupil and or flash forming an L shape to provide the cut out portion. According to one embodiment the cut out portion is relatively small. For example the cut out portion is only big enough so that the entrance pupil and or the flash are not covered up. According to one embodiment the mounting system is a mechanical clamp that surrounds an external accessory and an MDCP without obscuring the area as discussed herein.

The mobile data collection platform has a case that an interface adapter A is a part of or coupled to. depicts a fastening system that that includes a case B also called a sleeve and a fastener A. The external accessory can be slide into the case B as depicted by the arrow. The mounting system includes the interface adapter A the case B and the fastener A. Location is the position where the interface adapter A and the fastener A couple.

In the accessory MDCP side view the tablet type MDCP depicts the entrance pupil and the flash in the center position . The tablet type MDCP has a case with an interface adapter A that is part of or coupled to the case . The fastening system includes a bracket B and a fastener A. The mounting system includes the interface adapter A the bracket B and the fastener A.

More specifically the smart phone mobile digital device e.g. iPhone type mobile data collection platform has a case that three interface adapters A are a part of or coupled to. depicts a fastening system that includes a case B also called a sleeve and three fasteners A. The external accessory can be slide into the case B as depicted by the arrow. The mounting system includes the interface adapters A the case B and the fasteners A. The three positions are the locations where the interface adapters A and the respective fasteners A couple with each other.

As can be seen in and the external GNSS raw observable provider is positioned approximately in the middle of the top of the secondary external accessory between the MDCP s entrance pupil and the MDCP s antenna to prevent obscuring the entrance pupil and the antenna . The respective back surfaces of the secondary external accessory and the external GNSS raw observable provider are flush as indicated respectively at positions of top views and positions and of top views and . Further as can be seen in the top views and the back surfaces of the external combination accessory is adjacent to the MDCP front surface as indicated respectively at positions and .

Referring to each of the one or more adapters A A couple with one of the respective fasteners A A. Various embodiments are well suited for one or more pairs of adapters A A and fasteners A A.

Referring back to a snap on mount fastener is used to couple an external EDM accessory with an external GNSS raw observable provider according to one embodiment.

According to various embodiments an external accessory may be a legacy device. For example the accessory may be a legacy GNSS raw observable provider a legacy IR image capturing device a legacy image capturing device that is not IR a legacy laser pointing device or a legacy electronic distance measurement device. The legacy external accessory may be coupled to the MDCP using Velcro or some other type of coupling mechanisms that is discussed herein or is well known in the art. depict examples of legacy EDM devices that are used as external electronic distance measurement accessories.

An external accessory can have various physical configurations with different shapes and sizes so long as the external accessory does not cover the entrance pupil of the mobile data collection platform. According to one embodiment the external accessory has a configuration that allows the flash and the entrance pupil of the MDCP s internal image capturing device to be exposed as depicted at least in . For example although many of the external accessories depicted in the figures and discussed herein have a rectangular shape embodiments can be practiced using other configurations. For example the configuration of the external accessory could wrap around a mobile data collection platform or allow a mobile data collection platform to slide into the external accessory or vice versa. In another example an L configuration that provides a cut out portion as discussed herein could be used for external accessories so that none of the entrance pupil and flash are covered up.

According to various embodiments various types of information are collected for determining the distance between a mobile data collection platform and a real point of interest or a pseudo point of interest as discussed herein. For example as discussed herein the tilt angle the azimuth angle a position fix and an image are collected in a manner that they are associated with each other. More specifically the tilt angle the azimuth angle the position fix and the image can all be collected during a period that the MDCP is held still. In another example in response to the user pressing a button on the MDCP the tilt angle the azimuth angle the position fix and the image are collected and associated with each other. The raw observables that are extracted from the internal GNSS chipset are referred to as internal raw observables. Raw observables that are received by the MDCP from an external GNSS raw observable provider are referred to as external raw observables. The image that is obtained with the image capturing device that is inside the MDCP is referred to as an internal image and an image that is obtained from an external IR image capturing device accessory is referred to as an external IR image or external IR image. 

The tilt angle the azimuth angle the position fix determined based on raw observables that are extracted from an internal GNSS chipset and the internal image are referred to herein as collected internal data. External raw observables a position fix that is determined based on external raw observables an external image and an EDM distance measurement are referred to as external accessory data or additional data. The external accessory data can be stored in the MDCP s hardware memory . The external accessory data that is stored in the hardware memory is referred to as collected external accessory data or collected additional data. 

According to various embodiments the additional data from an accessory is also collected and associated with one or more of the tilt angle the azimuth angle the internal position fix determined based on internal raw observables and the internal image. For example an external image be associated with the tilt angle the azimuth angle and an internal or external position fix instead of or in addition to the internal image. In yet another example external raw observables may be used to determine the position fix instead of or in addition to determining a position fix based on internal raw observables.

The techniques for associating tilt angle the azimuth angle the position fix and the internal image can be used for associating the external accessory data with the collected internal data. The external accessory data can be associated with the collected internal data so that the internal position fix and or the external position fix are the position also referred to as particular position of the MDCP at the time that one or more of the EDM distance measurement the tilt angle the azimuth angle and the internal image and or external image are captured. For example the MDCP can be held still while two or more of the tilt angle the azimuth angle internal position fix external position fix internal image external image EDM distance measurement and highlighting of a real or pseudo point of interest using the laser pointer accessory are collected. In another example one or more of the tilt angle the azimuth angle internal position fix external position fix internal image external image EDM distance measurement and highlighting of a real or pseudo point of interest using the laser pointer accessory can be collected automatically and instantaneously in response to a timer expiring or a user pressing a button associated with either the MDCP or a button associated respective accessory that the additional data is from. The button that is pressed may be the accept data button . An identifier can be associated with each of the pieces of external accessory data and collected internal data for a particular position of the MDCP.

The detect image capture button pressed logic detects that the user of the MDCP pressed a button such as the accept data button also referred to as image capture button to capture an image. For example the detect image capture button pressed logic can monitor that the accept data button was pressed and communicate for example with wireless communication device such as Bluetooth with the request information from accessory logic to activate the external accessory and to request external accessory data from the external accessory . The button that is pressed may be a mechanical button or a graphical button that is displayed on the display . Alternatively or in addition the external accessory can include a flash sensor that detects a flash from the MDCP s flash and . Flash sensors are well known in the art of photography. One or more timers can be used instead of the one or more buttons discussed herein. For example a timer can be used instead of the accept data button . Another timer can be used instead of the EDM distance button .

The accessory accessing logic receives external accessory data from the external accessory . For example if the external accessory is an external GNSS raw observable provider then the external raw observables receiving logic receives external GNSS observables from the external GNSS raw observable provider. The received external raw observables can be processed according to various embodiments described herein to determine a position fix. For example the external raw observables can include external raw pseudoranges. The external raw observables may also include either Doppler Shift Information or real carrier phase information. The external raw pseudoranges can be corrected based on external corrections or smoothed as discussed herein. The external Doppler shift information or the external real carrier phase information can be applied to the external raw pseudoranges as discussed herein. Therefore the external raw observables can be used to provide corrected unsmoothed pseudoranges uncorrected unsmoothed pseudoranges corrected smoothed pseudoranges or corrected unsmoothed pseudoranges. Then the corrected unsmoothed pseudoranges uncorrected unsmoothed pseudoranges corrected smoothed pseudoranges or corrected unsmoothed pseudoranges can be used to determine a position fix. The position fix can be smoothed based on locally measured movement information as discussed herein. The store external accessory data logic can store the position fix which results from processing the external raw observables as position fix .

If the external accessory is an external IR image capturing device accessory then the external IR image receiving logic receives an external IR image from the external IR image capturing device accessory. The store external accessory data logic can store the external IR image as the external IR image . If the external accessory is an external EDM accessory the external EDM distance receiving logic can receive the EDM distance measurement from the external EDM accessory. The store external accessory data logic can store the EDM distance measurement as EDM distance measurement . If the external accessory is an external combination accessory then the appropriate one or more logics and can receive one or more of external raw observables external IR image and EDM distance measurement depending on the capabilities of the external combination accessory. The store external accessory data logic can store one or more of external IR image EDM distance measurement and position fix that is determined based on the external raw observables depending which external accessory data the external combination accessory provides.

The processing logic is executed in response to principal control instructions as discussed herein received from a MDCP. For example the wireless communication device can receive the request for information from MDCP s request information from accessory logic and provide the request for information to the receive request for information logic . The request also known as a principal control instruction can be communicated to the requested information obtaining logic . The requested information obtaining logic can obtain depending on the type of external accessory that the external accessory is one or more of the external raw observables an external IR image and an EDM distance measurement. If the external accessory is a combination accessory the requested information obtaining logic can coordinate obtaining the various types of external accessory data that the combination accessory is capable of providing. For example the requested information obtaining logic can automatically and instantaneously obtain two or more of external raw observables EDM distance measurement and external IR image depending on what features are associated with the external combination accessory. The requested information providing logic can use the wireless communication device to communicate the one or more of the external raw observables an external IR image and an EDM distance measurement back to the MDCP s wireless communication device .

According to one embodiment the external accessory was not built in a manufacturing facility. For example the external accessory may be built by a user of the MDCP .

Operations are performed. The GNSS chipset in operation may be internal to the MDCP or external to the MDCP. For example raw observables can be obtained from an internal GNSS chipset or an external GNSS chipset that is part of an external GNSS raw observable provider . In operation the position fix can be determined based on either internal raw observables or external raw observables or both as discussed herein. The position fix defines a location of an antenna as discussed herein. The raw observables from either the internal GNSS chipset or the eternal GNSS raw observable provider can include raw pseudoranges and one of carrier phase information and Doppler Shift Information.

At external accessory data is received from an accessory that is external to the mobile data collection platform. The external accessory may be any one or more of an external EDM accessory an external image capturing device accessory which may be infrared or non infrared and an external GNSS raw observable provider accessory. The external accessory can be a combination accessory. The external accessory data may be one or more of external raw observables an EDM distance measurement and an external image . A position fix can be determined based on the external raw observables as discussed herein.

At the image the position fix Xpf Ypf Zpf the orientation information and external accessory data such as a position fix an external image and or an EDM distance measurement are stored in hardware memory of the mobile data collection platform. The position fix Xpf Ypf Zpf is stored as position fix . One or more of the image the position fix the orientation information the external image position fix and EDM distance measurement can be used to determine a location of a point of interest in the image using for example photogrammetry. Photogrammetry is well known in the arts. According to one embodiment the image the position fix the orientation information the external image position fix EDM distance measurement can be used to determine a three dimensional location Xpt Ypt Zpt of the point of interest. According to one embodiment the three dimensional location Xpt Ypt Zpt of the point of interest is determined in the local coordinate system.

Operations are performed. The GNSS chipset may be internal to the MDCP or external to the MDCP. For example raw observables that are used to determine the position fix of the cellular device can be obtained from an internal GNSS chipset or an external GNSS chipset of an external GNSS raw observable provider . The raw observables from either the internal GNSS chipset or the eternal GNSS raw observable provider can include raw pseudoranges and one of carrier phase information and Doppler Shift Information.

At external accessory data is received from an accessory that is external to the mobile data collection platform. The external accessory may be any one or more of an external EDM accessory an external image capturing device accessory and an external GNSS raw observable provider accessory. The external accessory can be a combination accessory. The external accessory data may be one or more of external raw observables an EDM distance measurement and an external image . A position fix can be determined based on the external raw observables as discussed herein.

The external accessory and the mobile data collection platform are physically coupled together according to one embodiment thus maintaining a known fixed relationship between the external accessory and the mobile data collection platform. The known fixed relationship provides one or more known geometric offsets between the external accessory and the mobile data collection platform. For example if the external accessory is a GNSS raw observables provider then the one or more known geometric offsets may be one or more distances . However embodiments are well suited for other geometric offsets for example for other types of external accessories.

At the image the three dimensional position and external accessory data are stored in hardware memory. For example the image the three dimensional position X0 Y0 Z0 and the external accessory data can be stored in hardware memory of the mobile data collection platform . The external accessory data can include one or more of the external image position fix and EDM distance measurement .

The local gravity vector is local with respect to the cellular device for example as discussed herein at the time that the one or more images is captured.

According to one embodiment the antenna is located at the position fix when the image is captured. For example if the position fix is determined based on raw observables obtained from an internal chipset then the position fix Xpf Ypf Zpf defines the location of the antenna . If the position fix is determined based on external raw observables from an external GNSS raw observables provider then the position fix defines the location of the antenna .

The three dimensional position X0 Y0 Z0 is associated with the cellular device when one or more images is captured. The three dimensional position X0 Y0 Z0 is the location of the MDCP s entrance pupil center at the time that the one or more images is captured. Instead or in addition the three dimensional position of the cellular device may be the three dimensional position of the entrance pupil center of the external image capturing device accessory or some other three dimensional position of the combination of the cellular device and the external accessory when the one or more images is captured.

The cellular device is not required to be perpendicular to the local gravity vector at the time of collecting of data as described herein. For example the cellular device z is not required to be perpendicular at the time of the capturing of the one or more the images and the determining of the three dimensional position X0 Y0 Z0.

The detect image capture button pressed logic detects that the user of the MDCP pressed a button such as the accept data button or a timer expired to capture one or more images as discussed herein. Alternatively or in addition the external accessory can include a flash sensor that detects a flash from the MDCP s flash and . The methods depicted in are initiated according to various embodiments in response to the detect image capture button pressed logic detecting that the user of the MDCP pressed a button or in response to the flash sensor detecting the flash.

At a determination is made as to what mode the mobile data collection platform is in. For example the mobile data collection platform can go into an image capture plus EDM mode A in response to the user selecting a camera icon from the home page displayed on the display and subsequently pressing the image capture button . Alternatively a timer can be used instead of pressing the image capture button . The mobile data collection platform can go into an EDM only mode B in response to the user pressing the EDM distance button also referred to as take a sample distance measurement button . Alternatively a timer can be used instead of pressing the EDM distance button .

If the mobile data collection platform is in an EDM only mode B processing proceeds to . If the mobile data collection platform is in an image capture plus EDM mode A processing proceeds to . According to one embodiment the EDM accessory operates at peak efficiency for example at 300 points per second while in image capture plus EDM mode A and performs in less than peak efficiency when in the EDM only mode B.

At the mobile data collection platform instructs the external EDM accessory to determine an EDM distance measurement. For example the request information from accessory logic can instruct the external EDM accessory to determine the EDM distance measurement for example by transmitting a principal control instruction via short range communication device or using wire access as discussed herein. The external EDM accessory can determine the EDM distance measurement as described herein. The measurement that is used as the EDM distance measurement can be to a point that is displayed nearby in and around the center of the crosshairs display overlay refer to in the image plane on the object of interest A. The EDM distance measurement is determined in response to the EDM accessory receiving the control instruction from the MDCP s request information from accessory logic .

At the mobile data collection platform receives the EDM distance measurement. For example the external EDM accessory can transmit the EDM distance measurement to the mobile data collection platform and the external EDM distance receiving logic can receive the EDM distance measurement. The EDM distance measurement is transmitted to the mobile data collection platform in response to the EDM accessory receiving the control instruction from the MDCP s request information from accessory logic . The EDM distance measurement can be displayed for example on the MDCP s display . Store external accessory data logic can optionally store the received EDM distance measurement in the hardware memory of the MDCP as EDM distance measurement . Processing proceeds to .

At an image is captured. and are examples of captured images. Images can be captured from a single location or from more than one location as discussed herein. A distance D can be determined between two positions P P that two respective images were captured that both depict a point of interest as depicted in .

At orientation information of the mobile data collection platform is captured. For example a tilt angle and tilt direction as provided by the compass heading can be captured. is an example of capturing orientation information.

At the location of the MDCP is captured and the time of that the location was captured also referred to as time of location capture is also captured. The MDCP location may be 1 a position fix as determined in 2 latitude longitude and altitude and or 3 a three dimensional position as determined in . The time may be a Greenwich Mean Time GMT or local time.

At the mobile data collection platform instructs the external EDM accessory to determine an EDM distance measurement. is performed in a similar manner to .

At the EDM distance measurement is received at the mobile data collection platform. Operation is performed in a similar manner to operation .

At the image the orientation information the MDCP location the time of capture and the EDM distance measurement are stored. For example store external accessory data logic can store the image captured at the orientation information captured at the MDCP location captured at the time of location capture captured at and the EDM distance measurement received at into a file. The file may be in hardware memory of the mobile data collection platform.

At a known fixed relationship between an external electronic distance measurement accessory in a first package and a mobile data collection platform in a second package is maintained where the first package and the second package are separate packages that are physically coupled together. For example the MDCP s case A and the external EDM accessory s case A are the respective separate packages. The first package and the second package are physically coupled together. For example the external electronic distance measurement accessory s case can include a fastening system that couples with an interface adapter that maintains a known fixed relationship between the respective cases A and A of the respective mobile data collection platform and the external electronic distance measurement accessory. One or more of distances and is an example of a known fixed relationship. The one or more distances and can be stored in known spatial relationship as discussed herein.

At control instructions are received at the external electronic distance measurement accessory from the mobile data collection platform. The EDM accessory s receive request for information logic receives a request for information from the MDCP s request information from accessory logic the requested information obtaining logic obtains the requested information in response to the received request for information and the requested information providing logic provides the requested information to the MDCP s external EDM distance receiving logic . In another example the MDCP activates the EDM accessory for example in response to detecting that a button has been pressed or a timer has expired.

The light beam axis of the external electronic distance measurement accessory is parallel with an optical axis from an entrance pupil of the mobile data collection platform according to various embodiments. depict examples of the light beam axis A and C that is parallel with an optical axis A from an entrance pupil of a mobile data collection platform.

The EDM accessory may be activated by the MDCP according to one embodiment. For example a user may push a button or slide a slide bar of the EDM accessory to turn the EDM accessory s communication device while putting the EDM accessory in a quiescent mode also known as a sleep mode that does not consume much power. The button or slide bar only turns the EDM accessory s communication device . Turning the EDM accessory s communication device on allows the MDCP to control the EDM accessory. The EDM only mode B or the image capture plus EDM mode A can be entered as discussed herein.

In another embodiment the EDM accessory may activate itself. For example the EDM accessory may be fully activated when the user pushes the button or slides the slide bar of the EDM accessory.

At a light beam A is transmitted from a transmit light source A where the transmit light source A is part of the external electronic distance measurement accessory and wherein an axis A C of the light beam A is parallel with an optical axis A of an entrance pupil of the mobile data collection platform . The optical axis A is pointing perpendicularly from the entrance pupil according to one embodiment.

At a reflected portion A B of the light beam A is received at a receiving aperture A A where the receiving aperture A A is part of the external electronic distance measurement accessory .

At a measurement of a distance e.g. distance measurement is determined based on a time that the light beam A that was transmitted at and a time that the reflected portion A B of the light beam was received at .

According to various embodiments the methods depicted in and can be performed automatically and almost instantaneously for example in approximately 0.25 second or less. For example approximately 0.25 second or less pass from the time of a data collection triggering event such as a button being pressed or a timer expiring until all of the external accessory data from one or more accessories and all of the collected internal data from a mobile data collection platform is stored in the hardware memory . Examples of the collected internal data are the tilt angle the azimuth angle the position fix determined based on raw observables that are extracted from an internal GNSS chipset and the internal image from the internal ICD and examples of external accessory data are a position fix that is determined based on external raw observables an external image from an external ICD accessory and an EDM distance measurement.

An embodiments provides for receiving the principal control instructions that include at least one of an instruction that controls an external electronic distance measurement accessory an instruction that controls an external image capturing device accessory an instruction that controls an external laser pointer accessory an instruction that controls an external Global Navigation Satellite Systems GNSS raw observable provider an instruction requesting that the external Global Navigation Satellite Systems GNSS raw observable provider transmit external raw observables to the mobile data collection platform and an instruction requesting that the external electronic distance measurement accessory transmit data to the mobile data collection platform. For example an external accessory such as an external electronic distance measurement accessory an external image capturing device accessory an external laser pointer accessory and an external Global Navigation Satellite Systems GNSS raw observable provider are not designed to be operated on their own. Instead they are designed to be controlled by a mobile data collection platform using one or more control instructions as described herein.

An example of a principal control instruction for any type of accessory is a control instruction that MDCP s request information from accessory logic transmits to the accessory s receive request for information logic or that causes the external accessory to perform some function. For an external electronic distance measurement accessory the principal control instruction may be a request for EDM distance measurement from the external EDM accessory. For an external image capturing device accessory the principal control instruction may be a request for an external image from the external image capturing device accessory. For an external laser pointer accessory the principal control instruction may be an instruction to transmit a beam of light from the external laser pointer accessory. For an external GNSS raw observable provider the principal control instruction may be a request for external raw observables. Examples of requested data include an EDM distance measurement from an external EDM accessory an external image from an external image capturing device accessory and external raw observables from an external GNSS raw observable provider that can be used to determine a position fix .

According to one embodiment turning an external accessory on or off are not examples of principal control instructions. For example an external accessory can be turned on or off by pressing a button or sliding a slide bar on the external accessory. According to one embodiment waking an external accessory up from a sleep mode is an example of a principal control instruction. For example the external accessory can be turned on or off by pressing a button on the external accessory. The external accessory can go into a sleep mode that saves power while at the same time enables it to communicate with the mobile data collection platform. Subsequently the external accessory can be woken up from the sleep mode by receiving a principal control instruction from a mobile data collection platform that instructs the external accessory to wake up.

An embodiment provides for altering the path of the reflected portion of the light beam inside of the external electronic distance measurement accessory with a mirror B that is part of the electronic distance measurement accessory B. For example referring to the path of the reflected portion is bent at a 90 degree angle for example by a mirror. Examples of reflected portion are B and A. Referring to the path of the reflected portion is not altered. The reflected portion includes a first reflected subset that travels the path prior to the reflecting with the mirror and a second reflected subset that travels the path after the reflecting with the mirror. Referring to an example of a first reflected subset is the portion of the reflected light B between an object of interest and the mirror B an example of a second reflected subset is the portion the reflected light B between the mirror B and the light sensor B.

An embodiment provides for providing a focused second reflected subset by focusing the second reflected subset with a lens of the external electronic distance measurement accessory and detecting the focused second reflected subset with a light sensor of the external electronic distance measurement accessory. An example of an external electronic distance measurement accessory is B. An example of reflected portion is reflected portion A B . An example of a lens is B. An example of a light sensor is B. An example of focused second reflected subset is B.

An embodiment provides for receiving at the external electronic distance measurement accessory a request from the mobile data collection platform for a distance measurement for example of a distance A between the object of interest A and the external electronic distance measurement accessory and communicating the distance measurement from the external electronic distance measurement accessory to the mobile data collection platform wherein the determining of the distance measurement and the communicating of the distance measurement are performed in response to the receiving of the request.

An embodiment provides for the receiving of the request and the communicating of the distance measurement of the distance A are performed by a communication device that is part of the external electronic distance measurement accessory wherein the communication device is selected from a group consisting of a wireless communication device and a wired access communication device .

An embodiments is provided for coupling the external electronic distance measurement accessory with the mobile data collection platform where the external electronic distance measurement accessory has a form factor that integrates with the mobile data collection platform where a light beam axis A of the external electronic distance measurement accessory is parallel with an optical axis A from an entrance pupil of the mobile data collection platform . For example a form factor can provide a size and shape of the EDM case A that integrates with the MDCP case A in a manner described herein.

Various embodiments provide for an external electronic distance measurement accessory B for providing data to a mobile data collection platform wherein the external electronic distance measurement accessory B comprises a front side A of the external electronic distance measurement accessory B includes a transmit light source A and a receiving aperture A A a back side A of the external electronic distance measurement accessory B is on an opposite side of the front side A and the back side A is parallel to the front side A of the external electronic distance measurement accessory B a fastener system that couples the back side of the external electronic distance measurement accessory B to a front side of the mobile data collection platform wherein the front side of the mobile data collection platform includes an entrance pupil and the fastener system maintains a known fixed relationship such as one or more of distances and between the external electronic distance measurement accessory B in a first package and the mobile data collection platform in a second package where the first and second package are separate packages that are physically coupled together using the fastener system receive request for information logic that receives a request from the mobile data collection platform for a distance measurement a transmit light source A that transmits a light beam such as A wherein an axis A of the light beam is parallel with an optical axis A of the entrance pupil of the mobile data collection platform the receiving aperture A A that receives a reflected portion such as A or B of the light beam a time of flight distance calculator A that determines the distance measurement of the distance A based on a time that the light beam such as A was transmitted by the transmit light source A and a time that the reflected portion such as A was received by the receiving aperture and requested information providing logic that communicates the distance measurement to the mobile data collection platform .

Various embodiments provide for the external electronic distance measurement accessory to further comprises a lens B that focuses the reflected portion and a light sensor B that detects the focused reflected portion.

Various embodiments provide for the external electronic distance measurement accessory B to further comprise a communication device that communicates with the mobile data collection platform wherein the communication device is selected from a group consisting of a wireless communication device and a wired access communication device.

Various embodiments provide for the electronic distance measurement accessory B to have that integrates with the mobile data collection platform by providing a light beam axis A that is parallel with the optical axis A. depict EDM accessories that have form factors that can be integrated with a mobile data collection platform by providing a light beam axis A that is parallel with the optical axis A. For example the EDM accessories can be integrated with a mobile data collection platform in an L shape a T shape where the principal axis of the EDM accessory and the MDCP are perpendicular to each other using mounting systems that include fastener systems such as D and E. In another example an EDM accessory can be integrated with a mobile data collection platform so that the respective principal axis of the EDM accessory and the mobile data collection platform are parallel with each other as depicted in using various mounting systems as discussed herein. Various embodiments provide for altering the path of the reflected portion with the mirror B. Various embodiments provide for a light beam axis A of the external electronic distance measurement accessory B is parallel with an optical axis A from the entrance pupil of the mobile data collection platform . Various embodiments provide for the back side A of the external electronic distance measurement accessory B to be a largest face of the external electronic distance measurement accessory B and the front side A of the mobile data collection platform to be a largest face of the mobile data collection platform . Various embodiments provide for a largest face such as B of the external electronic distance measurement accessory B is parallel with a largest face such as A of the mobile data collection platform . Various embodiments provide for a largest face such as A of the external electronic distance measurement accessory B to be smaller than a largest face such as A of the mobile data collection platform where the entrance pupil is located on the front side A of the mobile data collection platform.

Various embodiments provide for no portion of the external electronic distance measurement accessory B to cover any portion an entrance pupil of the mobile data collection platform when the external electronic distance measurement accessory B is coupled with the mobile data collection platform . depicts an area that includes an entrance pupil and a flash in either a center position or a side position that are not covered up by an external accessory that is coupled with the MDCP according to various embodiments.

According to one embodiment the external electronic distance measurement accessory has a cut out portion that exposes the entrance pupil of the mobile data collection platform when the external electronic distance measurement accessory and the mobile data collection platform are coupled with each other. For example as depicted in the line is a straight vertical line. However various embodiments are well suited for the line to be L shaped to provide a cut out portion of the accessory so that none of the accessory covers up the entrance pupil or flash. For example the lower portion of the accessory s side designed by line could extend below the entrance pupil and the flash in an L shape to provide the cut out portion.

According to one embodiment the external electronic distance measurement accessory includes a mirror B F G H that alters a path of the reflected portion such as A B . Various embodiments provide for the reflected portion to include a first reflected subset and a second reflected subset the first reflected subset travels the path prior to the reflected portion being reflected by the mirror B F G H and the second reflected subset travels the path after the reflected portion is reflected by the mirror B F G H and the first reflected subset is at a 90 degree angle with respect to the second reflected subset. Referring to an example of a first reflected subset is the portion of the reflected light B between an object of interest and the mirror B an example of a second reflected subset is the portion the reflected light B between the mirror B and the light sensor B.

Various embodiments provide for the first reflected subset as discussed herein being parallel to an optical axis A from the entrance pupil of the mobile data collection platform and the second reflected subset as discussed herein being parallel with the front side A of the external electronic distance measurement accessory B the back side A of the external electronic distance measurement accessory B and the front side A of the mobile data collection platform . Various embodiments provide for a light beam axis A of the external electronic distance measurement accessory B is parallel with an optical axis A from the entrance pupil of the mobile data collection platform .

Various embodiments provide for a principal axis of the mobile data collection platform is parallel with a principal axis of the external electronic distance measurement accessory B for example as depicted in .

Various embodiments provide for an external electronic distance measurement accessory B for providing data to a mobile data collection platform wherein the external electronic distance measurement accessory B comprises maintaining means that maintains a known fixed relationship such as one or more distances and between the external electronic distance measurement accessory B and the mobile data collection platform where the electronic distance measurement accessory and B and the mobile data collection platform are in separate packages that are physically coupled together as discussed herein integrating means that provides a light beam axis A of the external electronic distance measurement accessory B that is parallel with an optical axis A of an entrance pupil of the mobile data collection platform as depicted in controlling means such as that receives control instructions from the mobile data collection platform where the control instructions control the external electronic distance measurement accessory B for example by causing logics and to be performed transmitting means laser transmitter A that transmits a light beam such as transmitted light A from a transmit light source along the light beam axis A receiving means such as receiver detector A that receives a reflected portion such as A of the light beam and determining means such as time of flight distance calculator A that determines a distance measurement for example of a distance A based on a time that the light beam was transmitted by the transmitting means and a time that the reflected portion was received by the receiving means.

Various embodiments provide for the external electronic distance measurement accessory B comprises integrating means that integrates the external electronic distance measurement accessory B with the mobile data collection platform . Examples of an integrating means include at least one or more of a form factor as discussed herein shapes and sizes of the external electronic distance measurement accessory and the mobile data collection platform fastener system orientations of the external electronic distance measurement accessory and the mobile data collection platform when they are coupled together as depicted for example at least in not covering up area as discussed herein when the accessory and the MDCP are coupled together and providing a light beam axis A of the external electronic distance measurement accessory that is parallel with an optical axis A of an entrance pupil of the mobile data collection platform at least as depicted in .

Various embodiments provide for the external electronic distance measurement accessory B further comprising focusing means such as lens B that focuses the reflected portion and detecting means such as light sensor B that detects the focused reflected portion.

Various embodiments provide for the external electronic distance measurement accessory B further comprises receiving means such as receive request for information logic that receives at the external electronic distance measurement accessory B a request from the mobile data collection platform for the distance measurement for example of the distance A and communicating means such as communication device that communicates the distance A from the external electronic distance measurement accessory B to the mobile data collection platform .

Various embodiments provide for the receiving means and the communicating means being a part of the external electronic distance measurement accessory B wherein the receiving means and the communicating means are selected from a group consisting of a wireless communication means and a wired access communication means. Examples of a receiving means is receive request for information logic and communications device and examples of communicating means is requested information providing logic and communications device .

According to various embodiments the external electronic distance measurement accessory and B further comprises a positioning means that positions the external electronic distance measurement accessory with respect to the mobile data collection platform in a manner that the light beam axis of the external electronic distance measurement accessory is parallel with the optical axis from an entrance pupil of the mobile data collection platform. Examples of a positioning means include at least the mirror that bends the reflected portion the fastener system D E the orientation of the EDM accessory with respect to the MDCP which could be an L shape as depicted in a T shape as depicted in or parallel principal axis as depicted in not covering any portion of the MDCP s lens A the user s ability to clearly and easily see the MDCP s display as depicted in .

According to one embodiment the external electronic distance measurement accessory B further comprises altering means such as a mirror that alters a path of the reflected portion inside the external electronic distance measurement accessory by reflecting the reflected portion where the altering means is part of the external electronic distance measurement accessory. Examples of an altering means are mirrors B F G H. Examples of a reflected portion is reflected portion A B .

According to one embodiment the external electronic distance measurement accessory B further comprises coupling means that couples the external electronic distance measurement accessory with the mobile data collection platform. An example of a coupling means is fastener system . Other examples of a coupling means are a bracket a screw a screw hole a male portion or female portion of a snap on mounting system a hole or a knob that can be inserted into a hole and twisted.

An embodiment provides for receiving of the external accessory data as described herein from the accessory B that is external to the mobile data collection platform wherein there is a known spatial relationship as discussed herein between the mobile data collection platform and the external accessory B.

An embodiment provides for receiving the external accessory data from an external electronic distance measurement accessory B. An embodiment provides for receiving the external accessory data from an external image capturing device accessory that is selected from a group consisting of an external infrared IR image capturing device and an external non infrared image capturing device. An example of an external infrared IR image capturing device accessory includes features B B B B as depicted in . However embodiments are well are also well suited to an external non infrared image capturing device as discussed herein. An embodiment provides for receiving a distance measurement from an external electronic distance measurement accessory B. An example of a distance measurement is a measurement of the distance A. An embodiment provides for receiving the distance measurement that provides a scale factor used in photogrammetric data processing. For example the distance measurement can be used as a scale factor by photogrammetric data processing.

An embodiment provides for illuminating the point of interest with a beam of light from a laser pointer accessory. An example of a laser pointer accessory is an accessory that includes a laser pointer device and laser pupil B.

An embodiment provides for monitoring when a user of the mobile data collection platform presses a button such as accept data button capturing the image or activating the external accessory B in response to detecting that the button was pressed and requesting the external accessory data from the external accessory in response to the detecting that the button was pressed.

Various embodiments provide a mobile data collection system for collecting data the mobile data collection system comprising an external accessory B for providing external accessory data to a mobile data collection platform the mobile data collection platform comprising a cellular device an image capturing device an orientation system hardware memory and one or more hardware processors wherein the cellular device has a display and wherein the image capturing device includes an entrance pupil a GNSS raw observable provider that is located external to and physically coupled with the mobile data collection platform wherein the GNSS raw observable provider includes an antenna the antenna and the entrance pupil are in a known spatial relationship and or and the antenna receives GNSS positioning signals that defines a location of the antenna the image capturing device that captures an image wherein the image capturing device is an integral part of the mobile data collection platform and has a known spatial relationship with the antenna the orientation system includes a tilt sensor and a compass and determines orientation information that includes tilt angle obtained from the tilt sensor and tilt direction obtained from the compass the hardware memory that stores the image the position fix external accessory data and the orientation information wherein the one or more hardware processors receives external raw observables from a GNSS raw observable positioning provider that is outside of the mobile data collection platform captures an image with the image capturing device wherein the image depicts a point of interest determines the position fix of the mobile data collection platform based on the raw observables wherein the position fix defines a location of an antenna in a GNSS coordinate system accesses the orientation information from the orientation system wherein the orientation information which includes the tilt angle and the tilt direction is associated with a three dimensional location such as for example X0 Y0 Z0 of the mobile data collection platform when the image was captured and stores the image the position fix the orientation information and the external accessory data in the hardware memory of the mobile data collection platform.

According to one embodiment the antenna is a circularly polarized GNSS antenna. According to one embodiment the raw observables include raw pseudoranges and one of carrier phase information and Doppler Shift Information. According to various embodiments the mobile data collection platform is disposed in a known fixed relationship with a known geometric offset from the external accessory as discussed herein.

According to various embodiments the external accessory B is an external electronic distance measurement accessory such as B. According to various embodiments the external accessory is an external image capturing device accessory such as an accessory that includes one or more of B B B B . According to various embodiments the mobile data collection platform includes an internal GNSS chipset and the one or more hardware processors are located outside of the internal GNSS chipset .

According to one embodiment the mobile data collection platform further comprises detect image capture button pressed logic that monitors when a user of the mobile data collection platform presses a button that initiates capture of the image and request information from accessory logic that activates the external accessory and requests the external accessory data from the external accessory in response to detecting that the button was pressed wherein the one or more hardware processors executes the detect image capture button pressed logic and the request information from accessory logic .

Various embodiments provide for receiving the external accessory data from the external accessory receiving collected internal data from the mobile data collection platform wherein the position fix of the mobile data collection platform is the position of the mobile data collection platform at a time of the receiving of the external accessory data and the receiving of the collected internal data and storing the external accessory data with the collected internal data in the hardware memory. For example the receiving of the external accessory data the receiving of the collected internal data and the storing of the external accessory data and the collected internal data can be performed in 0.25 of a second or less.

In one embodiment a mounting system couples the external accessory and the mobile data collection platform together. According to one embodiment the mounting system is selected from a group consisting of a snap on mounting system and a screw mount .

Various embodiments provide for a method of performing data collection using a cellular device the method comprising capturing an image that depicts a point of interest using a cellular device obtaining raw observables from a GNSS raw observable positioning provider that is outside of the cellular device wherein the raw observables include raw pseudoranges and one of carrier phase information and Doppler Shift Information determining a position fix of an antenna of the GNSS raw observable positioning provider based on raw observables from the GNSS raw observable positioning provider wherein the GNSS raw observable positioning provider is outside of the cellular device and wherein the antenna is in a known spatial relationship with an entrance pupil center of the cellular device determining a three dimensional position such as X0 Y0 Z0 of the cellular device based on a local gravity vector and the position fix receiving external accessory data from an accessory B that is external to the cellular device and storing the image the three dimensional position and the external accessory data in hardware memory of the cellular device wherein the local gravity vector is local with respect to the cellular device wherein the antenna is at the position fix when the image is captured.

Unless otherwise specified any one or more of the embodiments described herein can be implemented using non transitory computer readable storage medium and computer readable instructions which reside for example in computer readable storage medium of a computer system or like device. The non transitory computer readable storage medium can be any kind of physical memory that instructions can be stored on. Examples of the non transitory computer readable storage medium include but are not limited to a disk a compact disk CD a digital versatile device DVD read only memory ROM flash and so on. As described above certain processes and operations of various embodiments of the present invention are realized in one embodiment as a series of computer readable instructions e.g. software program that reside within non transitory computer readable storage memory of a computer system and are executed by the hardware processor of the computer system. When executed the instructions cause a computer system to implement the functionality of various embodiments of the present invention. For example the instructions can be executed by a central processing unit associated with the computer system. According to one embodiment the non transitory computer readable storage medium is tangible.

Unless otherwise specified one or more of the various embodiments described in the context of can be implemented as hardware such as circuitry firmware or computer readable instructions that are stored on non transitory computer readable storage medium. The computer readable instructions of the various embodiments described in the context of can be executed by a hardware processor such as central processing unit to cause a computer system to implement the functionality of various embodiments. For example according to one embodiment various embodiments described herein are implemented with computer readable instructions that are stored on computer readable storage medium that can be tangible or non transitory or a combination thereof.

Although many embodiments have been descried with reference to mobile data collection platform embodiments are well suited for any of the other mobile data collection platforms described herein.

The embodiments described herein transform data or modify data to transform the state of a mobile data collection platform for at least the reason that by extracting pseudorange information from a GNSS chipset for use elsewhere the state of the mobile data collection platform is transformed from an entity that is not capable of determining a position fix itself into a mobile data collection platform that is capable of determining a position fix itself. In another example embodiments described herein transform the state of a mobile data collection platform from not being capable of providing an improved accuracy position fix to being capable of providing an improved accuracy position fix.

Reference will now be made in detail to various embodiments of the subject matter examples of which are illustrated in the accompanying drawings. While various embodiments are discussed herein it will be understood that they are not intended to limit to these embodiments. On the contrary the presented embodiments are intended to cover alternatives modifications and equivalents which may be included within the spirit and scope the various embodiments as defined by the appended claims. Furthermore in the following Description of Embodiments numerous specific details are set forth in order to provide a thorough understanding of embodiments of the present subject matter. However embodiments may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail as not to unnecessarily obscure aspects of the described embodiments.

Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the description of embodiments discussions utilizing terms such as capturing obtaining sensing determining calculating collecting receiving accessing storing executing performing processing annotating outputting depicting transmitting communicating identifying selecting causing transforming data modifying data to transform the state of a computer system or the like refer to the actions and processes of a computer system data storage system storage system controller microcontroller hardware processor or similar electronic computing device or combination of such electronic computing devices. The computer system or similar electronic computing device manipulates and transforms data represented as physical electronic quantities within the computer system s device s registers and memories into other data similarly represented as physical quantities within the computer system s device s memories or registers or other such information storage transmission or display devices.

According to various embodiments one or more images depicting a point of interest are captured that document a scene such as the scene of a car accident. Coincident with the capture of each of the one or more images orientation information of the mobile data collection platform is obtained a position fix is determined and a position of an entrance pupil is calculated in three dimensions. A three dimensional position of the point of interest is determined in a known coordinate system for example by performing photogrammetric image processing on the one or more images the one or more orientation information and the one or more entrance pupil positions. According to one embodiment a mobile data collection platform captures the one or more images obtains the one or more orientation information determines the one or more position fixes and calculates the one or more entrance pupil positions. The photogrammetric processing can be performed either at the mobile data collection platform or at a server that is located remotely with respect to the mobile data collection platform.

Various embodiments are well suited for scene documentation such as documenting the scene of a car accident. For example the points of interest may be positions on vehicles where they collided. The three dimensional positions of various points of interest can be used for determining how far apart the cars were and how far a car skidded among other things.

Although many embodiments are described in the context of a car accident various embodiments are well suited for documenting other types of scenes such as a construction site a historical site one or more buildings one or more buildings for the purpose of providing a bid for painting or other type of work and so on. These are just a few examples of how various embodiments may be used.

The target is manually positioned over a location of interest. The total station with its tri pod is placed at a first location and the total station is leveled. The total station takes an image of the target while at the first location. The total station with the tri pod is then moved to a second location where it is again leveled. After the total station has been leveled at the second location the total station takes another picture of the target . Information is communicated between the total station and the data collector controller .

As can be seen this conventional procedure is a very labor intensive process that involves expensive equipment. In contrast various embodiments provide for quickly taking images of a scene without requiring a mono pod tri pod and without requiring leveling. The images can quickly be collected on the fly. For example a police officer can begin to document a scene by capturing images along with the coincident information described herein as soon as they step out of their patrol car. Further this scene documentation can be done with equipment such as MDCP and with accessories and that is are much less expensive than the conventional equipment depicted in as will become more evident.

The mobile data collection platform includes a cellular device accessing logic processing logic an image capturing device an orientation system an inertial orientation system a tilt sensor a compass hardware and a transceiver . Although depicts a compass according to one embodiment the compass is a magnetometer. A magnetometer is just one type of compass that can be used with various embodiments. Various embodiments are well suited to various types of compasses. The cellular device includes a display GNSS chipset and an antenna . The hardware includes the image capturing device the orientation system the inertial orientation system hardware memory hardware processor and the transceiver . The antenna the display the processing logic the hardware are part of the mobile data collection platform and outside of the GNSS chipset .

According to one embodiment the orientation system includes a compass and an inertial orientation system . According to one embodiment the inertial orientation system includes a three axis tilt sensor . According to one embodiment the tilt sensor is a three axis inertial measurement unit IMU . According to one embodiment the tilt sensor is a three axis accelerometer. According to one embodiment the tilt sensor is a two axis accelerometer where the axes are for the x and y directions in a platform coordinate system such as 220 2230 2240 .

The orientation system according to one embodiment determines orientation information that represents an orientation of the mobile data collection platform . The orientation information includes according to one embodiment inertial orientation information and azimuth angle. According to one embodiment the inertial orientation information includes a tilt angle from the tilt sensor .

Angles such as the azimuth angle are measured in 360 degrees as is well known in the art. However other metrics used by surveyors for describing angular displacement including what is known as grad that uses 400 degrees in a full circle can also be used.

The tilt sensor may be used to determine the tilt angle. The tilt angle indicates the mobile data collection platform s orientation with respect to a local gravity vector as measured from a vertical or zenith point. The overall tilt angle is composed of two angles tilt in the direction of the x axis and tilt in the direction of the y axis. The vector magnitude gives a tilt angle in the direction of the vector sum of the x axis and y axis components. It may be reported as a tilt angle in polar coordinates as well. Polar coordinates capture the tilt angle as measured from a vertical gravity reference direction along a compass angle as determined by the vector sum of the x and y components. Tilt sensors determine the tilt angle based on Euler angles. The inertial orientation information may include the Euler angles from the tilt sensor in addition to the tilt angle or instead of the tilt angle.

The compass may be used to determine the azimuth angle. The azimuth angle indicates the orientation for example with respect to a reference direction such as true north magnetic north or a reference target at a known location from which the direction vector can be determined.

Examples of a transceiver are a cellular radio transceiver the Bluetooth or other Near Field communications transceiver a Wi Fi transceiver that is typically compliant with some IEEE 802.11 standard and a serial transceiver for communicating over a serial cable when the cellphone is plugged into a computer. A transceiver can be any type of hardware that is used for sending or receiving data or a combination thereof.

The hardware memory stores the image that depicts the point of interest the position fix the orientation information entrance pupil position and scale information . The antenna has a three dimensional GNSS position fix Xpf Ypf Zpf that is stored in memory as position fix . The hardware memory may store a plurality of images that depict a point of interest a plurality of position fixes a plurality of orientation information a plurality of entrance pupil positions a plurality of scale information a plurality of known spatial relationships a plurality of time stamps or a combination thereof.

The hardware processor is for executing one or more operations such as processing logic the capturing of the image with the image capturing device where the image includes at least one point of interest the determining of the position fix of the mobile data collection platform based on the raw observables where the position fix provides a location of the mobile data collection platform in a GNSS coordinate system the accessing of the orientation information from the inertial orientation system accessing entrance pupil position accessing scale information accessing known spatial relationship and the storing of the image the position fix the orientation information the entrance pupil position scale information and known spatial relationship in the hardware memory of the mobile data collection platform .

Although the image capturing device captures one or more images since according to various embodiments the one or more hardware processors also captures the one or more images because the one or more hardware processors interact with the image capturing device to at least perform the operation of storing the one or more images. Although the orientation system obtains orientation information as discussed herein since according to various embodiments the one or more hardware processors interact with the orientation system for example by at least performing the operation of storing the orientation information the one or more hardware processors according to an embodiment obtain orientation information. Although according to various embodiments an EDM or an image capturing device captures scale information since the one or more hardware processors interacts with the EDM or the image capturing device by at least performing the operation of storing the scale information in hardware memory according to one embodiment the one or more hardware processors capture the scale information. These are just a few examples of operations that the hardware processor s perform in conjunction with other entities. For similar reasons the one or more hardware processors can be considered to perform various operations because they interact with other entities that perform those operations and in so doing initiate control or complete those operations or a combination thereof. In so doing the hardware processor s perform operations in conjunction with the other entities.

The mobile data collection platform is not required to be leveled as a part of at least capturing the image determining the position fix and determining the orientation information . For similar reasons the mobile data collection platform is not required to be leveled as a part of providing an electronic distance measurement capturing scale information determining a time stamp capturing images with a depth camera array or determining receiving or accessing any type of information from any type of external accessory that can be coupled with a mobile data collection platform as discussed herein or a combination thereof. This list is not intended to be an exhaustive list of operations that a mobile data collection platform can perform without being required to be leveled.

The orientation information is associated directly and automatically with a three dimensional location such as the position fix Xpf Ypf Zpf stored as position fix or the three dimensional location X0 Y0 Z0 of an entrance pupil center of the mobile data collection platform when the image was captured. The mobile data collection platform is not required to be leveled at the time that the position fix Xpf Zpf Ypf or any other position fix associated with the MDCP as discussed herein and the orientation information are determined as is common with other optical measurement devices such as theodolites or total stations. The position fix may be of an internal antenna or of an external antenna associated with an external accessory as discussed herein.

Any one or more of the entities such as hardware image capturing device inertial orientation system compass hardware memory hardware processor that are part of the mobile data collection platform and outside of the cellular device can instead be inside of the cellular device . According to one embodiment the mobile data collection platform is a cellular device. For example a tablet computer may contain all the recited hardware plus a separate cellphone module. Conversely the tablet may contain a GNSS chipset whose raw observables may be made available to any of the processors associated with the tablet.

Various types of information can be stored for example in an EXIF file associated with the image . Examples of information that can be written into the EXIF file are the GPS position fix orientation information the tilt angle the direction of an azimuth angle also referred to as an azimuth direction or tilt direction scale information entrance pupil position and known spatial relationship s . Any type of information that can be used for determining one or more of a three dimensional position of the entrance pupil center of the image capturing device a distance from the entrance pupil center to a point of interest and a location of a point of interest as will become more evident can be stored in the EXIF file. Any type of information that may be useful to providing output such as a three dimensional position of a point of interest a map or a top down view of a scene as discussed herein can be stored in the EXIF file. Alternatively any or more of the same information can be stored as reference information in a suitable reference file associated with the particular mobile data collection platform.

According to various embodiments the accessing logic E can include accessing logic B accessing logic for extracting pseudorange information logic and receiving information as described herein.

According to various embodiments processing logic can include one or more of photogrammetric image processing logic optional processing logic processing logic processing logic processing logic and processing logic distance between two positions processing logic cross hairs processing logic and bubble level processing logic . The MDCP can perform any embodiments with respect to smoothing and correcting described herein.

MDCP may be capable of interoperating with any type of external accessory as described herein. An MDCP may include at least any of the features described in and interoperate with an external accessory as described herein.

The MDCP may include any of the features or perform any of the operations described herein with respect MDCPs.

MDCP includes a GNSS system an orientation system Bluetooth communications one or more microprocessors a camera an internal EDM device communications and a graphical user interface according to one embodiment. An example of GNSS system is cellular device . An example of an orientation system is orientation system . An example of Bluetooth Communications is Bluetooth Communications . An example of microprocessor is hardware processor . An example of a camera is image capturing device . An example of communications are cellular communications and other communications receiver . An example of the graphical user interface is graphical user interface .

MDCP includes GNSS system camera EDM interface Bluetooth Communications orientation system and one or more microprocessors according to one embodiment. MDCP is coupled with an external GNSS positioning system and an external EDM accessory .

An example of a GNSS system is cellular device . An example of a camera is image capturing device . An example of Bluetooth Communications is Bluetooth Communications . An example of an orientation system is orientation system . An example of microprocessor is hardware processor . An example of EDM interface is one or more of the external EDM distance receiving logic and store external accessory data logic . EDM interface may include any type of logic that is used for interacting with an external GNSS positioning system or processing information obtained from an external GNSS positioning system at least as discussed herein.

The external GNSS positioning system includes GNSS system and orientation system . The external EDM accessory includes Bluetooth Communications . The respective Bluetooth Communications and provide communications between the external EDM accessory and the MDCP . The external GNSS positioning system and the external EDM accessory can be implemented according to various embodiments described herein with regards to external GNSS positioning systems and external EDM accessories.

The MDCP includes GNSS system camera Bluetooth Communications orientation system and one or more microprocessors according to one embodiment.

An example of GNSS system is cellular device . An example of a camera is image capturing device . An example of Bluetooth Communications is Bluetooth Communications . An example of an orientation system is orientation system . An example of microprocessor is hardware processor .

Although various MDCPs and have been illustrated with a certain set of features the MDCPs may include fewer or more features. Further each of the MDCPs may include one or more features that have been illustrated in or described in the context of one or more other MDCPs as discussed herein.

According to various embodiments the MDCP can be used to capture various types of information such as one or more images of a scene that depict a point of interest in a scene orientation information position fix of an antenna and an entrance pupil position. The MDCP can capture time stamps or scale information or both for each capture of images. The obtaining of the orientation information the determining of the antenna s position fix and the calculation of the entrance pupil s position according to various embodiments are performed coincident with the capturing of each of the images as discussed herein. The capturing of scale information or a time stamp or both may also be coincident with capture of an image.

The remote server includes hardware and photogrammetric image processing logic . The hardware includes one or more hardware processors A and one or more hardware memories B. The hardware processor s A can perform any type of processing that the remote server performs as described herein. The hardware memory B can store any type of information that the remote server receives or intermediate information that is a part of processing that the remote server performs as discussed herein. The hardware memory B can include instructions for performing operations of the remote server as described herein according to various embodiments. The photogrammetric image processing logic can be stored in the hardware memory B and executed by the hardware processor A.

The one or more images one or more orientation information one or more position fixes or the one or more entrance pupil positions or a combination thereof can be transmitted to the remote server over the internet. Scale information s or time stamp s or both may be transmitted to the remote server over the internet . The remote server can process the information to determine a three dimensional position of the point of interest. The remote server can use photogrammetric image processing as described herein to determine the three dimensional position of the point of interest. The remote server can communicate the three dimensional position of the point of interest to the MDCP . The MDCP can also be used to capture any type of scale information described herein.

Various embodiments provide output. For example the three dimensional position of a point of interest A or B can be output. An image that has been annotated can be output. An image with a point of interest that has been identified can be output. According to one embodiment a top down view as depicted in any of could be output. According to one embodiment a large number of points of interest can be determined and output. Therefore a detailed layout of a scene can be created with as much or as few points of interest flagged in the created scene. Photogrammetric software as discussed herein can be programmed to limit the number of points of interest to a user specified number such as 1 2 5 10 50 100 500 or 1000 or any number chosen specified by the user or automatically specified by the software. The output can depict one or more time stamps that coincide with the capture of one or more images that were used for creating the output.

The photogrammetric software such as PIPL or can select points of interest arbitrarily in an image and identify them for example with a mark. Any of the points of interest discussed herein may be selected by a user or automatically by photogrammetric software. The photogrammetric software can be used to perform the photogrammetric location of all the arbitrarily selected points of interest. Once these points of interest have been located in a coordinate system they may be transferred to a top down view which is also commonly referred to as a plan view to make a map of the scene properly located in a coordinate system of choice. An MDCP or a remote server can output such a map or plan view.

The conventionally known Harris affine detection method can be used to automatically select points of interest. The Harris affine detection software can be part of the processing logic or processing logic or both.

It should be appreciated that techniques for applying and utilizing photogrammetry are generally well known by those of skill in the art and that numerous descriptions of these techniques are readily available in books articles and on the Internet.

The obtaining of the orientation information the determining of the antenna s position fix and the calculation of the entrance pupil s position according to various embodiments are performed coincident with the capturing of each of the images. For example each time an image is captured the orientation information is obtained the antenna s position fix is determined and the entrance pupil s position is calculated according to one embodiment. Therefore according to one embodiment each capture of orientation information is coincident with a different one of the one or more images. Therefore according to one embodiment one orientation information one antenna position fix one entrance pupil position and one image are coincident with each other. Capture of a time stamp or capture of scale information may also coincide with capture of an image. For example each time an image is captured a time stamp or scale information or both may also be captured.

 Coincident or coincidence refers to occurring together in space or time. An example of coincidence in time is performing the capturing of an image the obtaining of the orientation information the determining of the position fix and the calculating of the entrance pupil position in response to a single event that actuates the image capturing device such as a single button press also referred to herein as single button push data capture activity or the expiration of a timer also referred to herein as timer expiration as described herein. If a time stamp is captured it is coincident in time with the capture of the image according to one embodiment. For example approximately 0.25 second or less passes from the time of a data collection triggering event such as a button being pressed or a timer expiring until all the one or more images are captured the one or more orientation information is obtained the one or more position fixes are determined and the one or more entrance pupil positions are calculated using an MDCP with or without an external accessory a time stamp is captured scale information is captured or other operations that are performed in response to the single triggering event and storing the information that coincides with each other for example in hardware memory of the MDCP.

An example of coincidence in space is when the capturing of an image the obtaining of the orientation information the determining of the position fix and the calculating of the entrance pupil position are all performed while the MDCP which performs these operations is in the same position.

In embodiments relating to a single image a position fix is determined based on information obtained coincident with the capture of the image the orientation information is obtained and the entrance pupil position is calculated coincident with the capture of the image . Capture of a time stamp or scale information can also be coincident with the capture of the image . Various embodiments are also well suited to a plurality of images a plurality of position fixes a plurality of entrance pupil positions and plurality of orientation information . In this case each of the position fixes is determined each of the orientation information is obtained and each of the entrance pupil positions is calculated coincident with capture of one of the images . For example a first image that is captured while the MDCP is at one position is coincident with the determination of a first position fix for an associated antenna while the MDCP is at that position first orientation information of the MDCP while capturing that image and a first entrance pupil position derived based on that first position fix shall be referred to as being coincident with each other. Capture of scale information and or a time stamp as discussed herein may also be coincident with capturing of an image orientation information determining a position fix or calculating an entrance pupil position or a combination thereof.

Scale information can also be captured. Scale information is a distance associated with the scene in view of the image capture device. It is necessary for performing photogrammetric processes. It may be determined directly or indirectly as will be shown. As described herein scale information may be the depiction of an object which has a known dimension in one or more captured images. In another embodiment the scale information can include two captured images the locations such as position fixes and orientations of the mobile data collection platform when the two images were captured and the known distance between the two locations where the two images were captured. The distance between the two locations may be determined from the position fixes obtained at those two locations. Another example of scale information is a distance between two entities such as between an MDCP and a point of interest obtained for example from an electronic distance measurement device or EDM. The EDM may be an internal EDM or an external accessory as discussed herein.

According to one embodiment scale information can be provided using a second camera having an array or image capture sensors while taking at least one image with main image capture device in the cellphone as discussed herein. The second camera shall be referred to herein as a multiple sensor or as a depth camera array.

According to one embodiment the capture of scale information is coincident with the capture of at least one image. For example the scale information may be depicted in an image. In another example the scale information may be a measured distance provided by an EDM where the capture of the measured distance is coincident with the capture of an image. In yet another example scale information is provided by a set of images captured in response to a single event such as a press of a button or the expiration of a timer using a depth camera array .

According to one embodiment scale information is associated with at least one image. In one example if the scale information is coincident with an image it is associated with that image. According to one embodiment scale information is a distance between a first position from which a first image is captured and a second position from which a second image is captured. Since each of the position fixes are determined for the respective positions that the images were captured from the distance between the two positions is considered to be associated with both of the images and therefore is associated with at least one of the images.

The scale information can be any type of scale information described herein or that is well understood in the art.

According to one embodiment scale information can be provided using a second camera having an array or image capture sensors while taking at least one image with main image capture device in the cellphone. The second camera shall be referred to herein as a multiple sensor or as a depth camera array. depicts a depth camera array by itself and a depth camera array physically coupled with an MDCP according to one embodiment. As an example the depth camera array shown consists of 9 image sensors. The number of sensors can be any number from 2 upwards. Alternatively a single element for the additional imager may be used in conjunction with the built in image capture device of the MDCP. All that is needed is two image capture devices capturing a pair of images at the same time. The external depth camera array may be located anywhere on the body of the MDCP in a known spatial relationship to the built in image capture device of the MDCP. The physical coupling is maintained while the depth camera array captures a set of images that the MDCP will use. The MDCP and the depth camera array communicate with each other according to one embodiment. For example the set of images captured by the depth camera array can be communicated from the depth camera array to the MDCP .

Depth camera arrays are known in the art for example Pelican Imaging of Santa Clara Calif. makes and sells a depth camera array called the PiCam. The depth camera array can be physically coupled with an MDCP by surrounding the entrance pupil with the depth camera array as depicted in . A three dimensional position of a point of interest can be determined based on photogrammetric processing of a single image captured with the built in image capturing device or with multiple images that depict the point of interest where one or more of the multiple images that were captured using the depth camera array when physically coupled with the MDCP as depicted in .

According to one embodiment if the distance between the MDCP and the point of interest is less than a threshold then the scale information provided by the depth camera array can be used. If the distance between the MDCP and the point of interest is greater than the threshold then the scale information provided by the depth camera array is not used. An example of a threshold for current technology is 10 feet. However as the technology for depth camera arrays improves the threshold can increase accordingly. For example the scale information provided by the depth camera array will become useful with technological advancements in depth camera arrays when the MDCP is further than 10 feet away from the point of interest.

The depth camera array can be used according to one embodiment to find a distance that forms a part of a triangle. For example a depth camera array can be used to find a distance that forms a part of one of the triangles depicted in .

According to one embodiment a point of interest s three dimensional position may be determined based on the set of images captured by a depth camera array in a similar manner that a point of interest s three dimensional position can be determined based on one or more images captured by the integral image capture device . In this case the point of interest s three dimensional position determined based on the depth camera array s set of images can be used instead of the point of interest s three dimensional position determined based on the one or more images captured by the integral image capturing device .

According to various embodiments an entrance pupil position can be calculated on the basis of a position fix . According to one embodiment the entrance pupil position is the center of the entrance pupil. The entrance pupil position can be calculated based on a position fix and a known spatial relationship as discussed herein. For example the known spatial relationship can include one or more offsets and in the event that the position fix is for the antenna also known as an internal antenna of an MDCP . In another example the known spatial relationship can include one or more offsets and in the event that the position fix is for an antenna also known as an external antenna of the GNSS raw observable provider also known as an external GNSS positioning system as discussed herein.

A position fix for an antenna is determined coincident with capturing an image and the capturing of orientation information . The entrance pupil position that is calculated based on that position fix shall also be referred to as coincident with the position fix the image and the orientation information . For similar reasons an entrance pupil position can be coincident with scale information for example when the coincident image depicts the scale information or an EDM is used to determine scale information in the form of a measured distance coincident with the capture of the image determination of the coincident position fix and so on as discussed herein.

For example depict a scene with vehicles VA VB and VC that were involved in an accident. The vehicles depicted in the images of the scene collided with each other resulting in damage to the vehicles. The positions of damages are examples of points of interest POI POI POI POI and POI.

The images depicted in were captured from one side of the road and the image depicted in was captured from the other side of the road. More specifically depicts the right side of vehicles VA and VC where vehicles VA and VC are pointing in the same direction. Vehicle VA s right front fender at point of interest POI collided with vehicle VB s left rear fender at point of interest POI. The image depicted in was taken while the front face of the MDCP approximately forms a 40 degree angle with the right sides of the vehicles VA and VC and part of the right rear bumper of vehicle VA is depicted in . Vehicle VC is parked on the right side of the road and vehicle VB s appears to be headed toward the left front side of vehicle VC.

Known distances between various depicted items can be used as scale information. For example the length of the text EMS depicted on the emergency vehicle the distance between centers of hubcaps and so on could be used as scale information as discussed herein. Dimensions of various items could be obtained from manufacturers or measured if they are not already known. In another example an object with a known dimension such as a yard stick could quickly be placed in the scene prior to capturing an image of it.

The radial distance between distance D and the point of interest A may be determined once observations are taken at two spaced apart locations P P and P P for the mobile data collection platform. The principles are well known in the photogrammetric arts. As depicted in a first image of the point of interest A is taken at position P P and a second image of the point of interest A is taken at position P P . The two positions P P and P P are separated by a distance D also referred to as the distance line D . According to one embodiment the distance between two positions processing logic obtains the position fixes associated with two locations P P P P from which a mobile data collection platform took images of a point of interest A and determines the distance D between the two locations P P P P based on the position fixes. First orientation information of the mobile data collection platform is coincident with the first image depicting the point of interest A captured with the same mobile data collection platform from location P P . Second orientation information of the mobile data collection platform is coincident with the second image depicting the point of interest A captured with the same mobile data collection platform from location P P . depicts respective pointing vectors PV and PV from the entrance pupil center to the point of interest A for the respective positions P P and P P .

There is a first line from P P in the direction of true north also referred to as first true north line and a second line from P P in the direction of true north also referred to as second true north line . The two lines and are parallel to each other since they are both in the direction of true north. These are examples for the sake of explanation. The directions may be arbitrarily chosen.

BL represents the angle between the baseline direction and north and also represents the angle between the baseline direction and north . BL represents the angle between the baseline direction and north . B represents the angle between the baseline direction and the pointing vector PV . B represents the angle between the baseline direction and the pointing vector PV . P POI represents the distance between position P P and the point of interest A. P POI represents the distance between position P P and the point of interest A.

The three dimensional coordinates of the positions P P and P P are GPS positions and can be calculated as discussed herein. The GPS three dimensional coordinates for P P are X1 Y1 Z1. The GPS three dimensional coordinates for P P are X2 Y2 Z2. P P and P P are three dimensional positions in the GNSS coordinate system. Distance D can be calculated by subtracting the GPS position fixes X1 Y1 Z1 for P P and X2 Y2 Z2 for P P using the vector equation D P P. The line extending in both directions from distance D is known as the baseline direction BLD .

The calculation of angle BL is discussed in the context of . Angle 1 180 1 2 Angle 2 1 2 Angle 3 180 2

The law of sines can be used find P POI and P POI as follows sin 3 1 sin 1 2 POI sin 2 1 POI so that 1 POI sin 2 sin 3 1 and 2 POI sin 1 sin 3 1.

Referring to the three dimensional coordinates for P P are X1 Y1 Z1 and the three dimensional coordinates for P P are X2 Y2 Z2 in the north east coordinate system latitude and longitude . 1 2 1 2 1 2

Assuming for the sake of simplifying the illustration that z is approximately 0 then angle BL arctan x y or BL arcsin x D . Various embodiments are also well suited for a z that does not approximate 0.

Referring to B represents the angle between east B and pointing vector PV . In the north east coordinate system depicted in let P with coordinates X1 Y1 Z1 be the origin for the sake of illustration. Xpt Ypt Zpt represent the coordinates of the point of interest POI A.

The following are equations that can be used for calculating various angles coordinates distances and so on. POI 1 1 POI 1 1 

Therefore according to an embodiment the coordinates for the position of the point of interest A are P x y . More specifically Xpt X1 x and Ypt Y1 y according to an embodiment. If z is not approximately 0 then the equation Zpt Z1 z can be used to determine Zpt.

Referring to the scale information can include one or more of the first image taken from P P and the second image taken from P P the first coordinates X1 Y1 Z1 for the location P P the second coordinates X2 Y2 Z2 for the location P P the respective orientations of the mobile data collection platform when it captured images at P P and P P and the known distance D between the first location P P and the second location P P .

According to one embodiment scale information can be both the depiction of an object with at least one known dimension in an image as described herein and a distance D between two positions P P P P that two images of a point of interest A were captured from.

The two images position fixes of the MDCP when at positions P P and P P orientation information of the MDCP at positions P P and P P entrance pupil positions that coincide with the positions P P and P P and the distance D can be stored in the hardware memory .

The points of interest A and B can represent any point of interest discussed herein. Examples of points of interest A and B are the points of interest depicted in . However the points of interest depicted in are not intended to be an exhaustive list of the points of interest that may be represented by points of interest A or B or a combination thereof.

Operations and are performed by hardware processor at the MDCP according to one embodiment. Operations are performed by the hardware processor A at the remote server according to one embodiment.

At images of a scene are captured by an image capturing device that is an integral part of the mobile data collection platform. For example images as depicted in are captured by the image capturing device that is an integral part of the MDCP . The images depict one or more points of interest POI POI. These images can be stored in hardware memory at . The images can be captured while a depth camera array is coupled with the MDCP . Operation can be performed in a similar manner to .

At orientation information is captured. For example the orientation information can be obtained from one or more sensors that are part of the mobile data collection platform . Orientation information can include tilt angle and azimuth angle as discussed herein. According to one embodiment Euler angles are obtained from the tilt sensor and translated into the tilt angle . The azimuth angle can be obtained based on information from the compass . According to one embodiment processing as described in operation can be used to capture orientation information that is coincident with the capture of each of the images that are captured in operation . The one or more orientation information can be stored at orientation information as described herein.

At position fix of an antenna associated with the MDCP is determined. The position fix may be of the MDCP s antenna or an antenna of an external GNSS position system as discussed herein. According to one embodiment processing as described with respect to operation can be used in the event that the position fix is for the MDCP s antenna .

Various embodiments provide for receiving external raw observables from an external GNSS raw observable provider that is external to the mobile data collection platform wherein an antenna of the external GNSS raw observable provider and an entrance pupil center of the mobile data collection platform are in a known spatial relationship and . A position fix that is determined based on the external raw observables one or more of the distances the tilt angle and the tilt direction can be used to determine the three dimensional position X0 Y0 Z0 of the entrance pupil center in the local coordinate system according to various embodiments described herein.

At the position of an entrance pupil is calculated. For example according to various embodiments an entrance pupil position can be calculated on the basis of a position fix . According to one embodiment the entrance pupil position is the center of the entrance pupil . The entrance pupil position can be calculated based on a position fix and a known spatial relationship as discussed herein. The known spatial relationship can include one or more offsets and in the event that the position fix is for the antenna of an MDCP . In another example the known spatial relationship can include one or more offsets and in the event that the position fix is for an antenna of the GNSS raw observable provider also known as an external GNSS positioning system as discussed herein. According to one embodiment a position of the entrance pupil is calculated for each image that is captured since the MDCP may be in different positions each time it is used to capture an image. The one or more entrance pupil positions can be stored at entrance pupil position as described herein.

Therefore according to one embodiment the first image that is captured the first orientation information that is obtained the first position fix that is determined and the first position of the entrance pupil that is calculated using the mobile data collection platform at position P P are coincident with each other. Further according to one embodiment the second image that is captured the second orientation information that is obtained the second position fix that is determined and the second position of the entrance pupil that is calculated using the mobile data collection platform at position P P are coincident with each other.

At scale information is captured as discussed herein. According to one embodiment scale information is captured as described in operation . According to one embodiment an example of scale information is a distance measured by an EDM which may be an internal EDM or an external EDM accessory . Various embodiments as described at least in the context of may be used for obtaining EDM type scale information.

At scene data is sent from the MDCP to the remote server. For example the one or more images the one or more orientation information and the one or more entrance pupil positions are transmitted from the MDCP to the remote server . As discussed herein for each captured image there is coincident orientation information and a coincident entrance pupil position. An entrance pupil position is treated as coincident with an image for at least the reason that it was derived from a position fix that coincides with that captured image.

At the scene data is received by the remote server. The remote server can store the scene data in its hardware memory B.

At a three dimensional position of point of interest in the scene is determined based on photogrammetric image processing. For example various geometric relationships and equations described in the context of can be used by a photogrammetric image processing logic located at the remote server to determine a three dimensional position such as Xpt Ypt Zpt of a point of interest A in a scene. At the three dimensional position of the point of interest is sent from the remote server to the MDCP. For example the three dimensional position Xpt Ypt Zpt of the point of interest A can be transmitted from the remote server to the MDCP .

At a plurality of images are captured by an image capturing device that is an integral part of the mobile data collection platform. According to various embodiments processing as described in operation can be used for operation .

At orientation information is obtained. The orientation information comprises a tilt angle and an azimuth angle provided by orientation sensors of the mobile data collection platform. According to various embodiments processing as described in operation can be used for operation .

At a position fix of an antenna associated with the mobile data collection platform is determined in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna. According to various embodiments processing as described in operation can be used for operation .

At a position of an entrance pupil of the image capturing device is calculated in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna. According to various embodiments processing as described in operation can be used for operation .

At scale information associated with the plurality of images is captured. According to various embodiments processing as described in operation can be used for operation .

At based on photogrammetric image processing of the scene data a three dimensional position of the point of interest at the scene is determined. The photogrammetric image processing is performed based on the scene data as part of the determining of the three dimensional position of the point of interest at the scene. According to various embodiments processing similar to operation can be used for operation except that operation is performed by photogrammetric image processing logic at the MDCP instead of at the remote server .

At an image is captured from a perspective that depicts a point of interest in the scene. The image capturing device is an integral part of the mobile data collection platform that is used to capture the image. Operation is similar to operation except that captures a single image instead of multiple images.

At orientation information is obtained. The orientation information comprises a tilt angle and an azimuth angle provided by orientation sensors of the mobile data collection platform. Operation is similar to operation except that obtains orientation information that is coincident with capturing the single image in instead of multiple orientation information that each coincide with the capture of one of the multiple images.

At a position fix of an antenna is determined. Operation is similar to operation except that in operation one position fix is coincident with the single image captured in instead of multiple position fixes each coincides with one of a plurality of images.

At a position of an entrance pupil of the image capturing device is calculated. Operation is similar to operation except that in operation one entrance pupil position coincides with the capture of the single image in operation .

At scale information is captured. The scale information may be obtained using various embodiments discussed herein. For example according to one embodiment scale information is captured as described in operation . The scale information may be depicted in the captured image as discussed herein or may be a measured distance obtained from an EDM which may be an internal EDM or an external EDM accessory as discussed herein. Various embodiments as described at least in the context of may be used for obtaining EDM type scale information. Various embodiments described herein or as understood in the art could be used for scale information.

At based on photogrammetric image processing of the scene data a three dimensional position of the point of interest at the scene is determined. For example the photogrammetric image processing logic located at the mobile data collection platform can use geometric relationships that are described in the context of as a part of determining the three dimensional position of the point of interest.

As discussed herein the methods depicted in can be used for determining a three dimensional position of a first point of interest A. According to various embodiments a second three dimensional position of a second point of interest B also known as an additional point of interest at the scene can also be determined. The determination of the second three dimensional position can be performed by a hardware processor at an MDCP or at a remote server as discussed herein. The determination of the second three dimensional position can be determined by photogrammetric image processing logic or .

According to various embodiments a vector is calculated between the first point of interest A and the second point of interest B. The vector is defined by the distance between the first point of interest A and the second point of interest B and by the direction as indicated by the arrow in from the first point of interest A to the second point of interest B. According to various embodiments a three dimensional position of the second point of interest B is determined using various embodiments as described herein that were used in determining the three dimensional position of the first point of interest A. For example the vector can be determined based on the respective three dimensional positions of the points of interest A and B.

According to various embodiments information associated with the vector the first point of interest A and the second point of interest A can be annotated onto at least one of the captured images to create an annotated image. The annotation can be performed by a hardware processor at an MDCP or a hardware processor at a remote server as discussed herein. An image editor as described herein can perform the annotation as discussed herein. The annotation can be received by photogrammetric image processing logic or . Any other point of interest can also be annotated according to various embodiments.

According to one embodiment an identification of a point of interest can be received for example by a remote server or by a feature associated with the MDCP. For example the point of interest can be identified in an image based on user input. The user input maybe an annotation as discussed herein. A photogrammetric image processing logic or could receive the identification of the point of interest or logic that is designed to output the identification could receive the identification. The identification could be for the first point of interest A or the second point of interest B. Both the first point of interest A and the second point of interest B could have respective identifications. The receiving of an identification could be performed by a hardware processor at an MDCP or a hardware processor at a remote server as discussed herein. The identification could be received for example by photogrammetric image processing logic or or by output logic that is part of either the MDCP or the remote server or both.

Various embodiments provide output. For example the three dimensional position of a point of interest A or B can be output. An image that has been annotated can be output. An image with a point of interest that has been identified can be output. According to one embodiment a top down view as depicted in any of could be output. According to one embodiment a large number of points of interest can be determined and output. Therefore a detailed layout of a scene can be created with as much or as few points of interest flagged in the created scene. Photogrammetric software as discussed herein can be programmed to limit the number of points of interest to a user specified number such as 1 2 5 10 50 100 500 or 1000 or any number chosen specified by the user or automatically specified by the software.

The photogrammetric software such as PIPL or can select points of interest arbitrarily in an image and identify them for example with a mark. Any of the points of interest discussed herein may be selected by a user or automatically by photogrammetric software. The photogrammetric software can be used to perform the photogrammetric location of all the arbitrarily selected points of interest. Once these points of interest have been located in a coordinate system they may be transferred to a top down view which is also commonly referred to as a plan view to make a map of the scene properly located in a coordinate system of choice. An MDCP or a remote server can output such a map or plan view.

At one or more images one or more orientation information and one or more entrance pupil positions to photogrammetric software. As discussed herein each image has associated orientation information and entrance pupil position that are coincident with capture of that image. Processing logic or can provide the more images one or more orientation information and one or more entrance pupil positions to the photogrammetric software such as PIPL or . Scale information as discussed herein may also be received at .

At optionally one or more user selected points of interest is received by the photogrammetric software. Processing logic or can provide the one or more user selected points of interest to the photogrammetric software such as PIPL or . The photogrammetric software can determine three dimensional positions for the user selected points of interest. The photogrammetric software can determine three dimensional positions for points of interest that the photogrammetric software arbitrarily selected as discussed herein. The photogrammetric software can determine three dimensional positions for user selected points of interest or for points of interest that were arbitrarily selected by the photogrammetric software or a combination thereof.

A three dimensional positions of the points of interest are received from the photogrammetric software. For example the processing logic or can receive the three dimensional positions that the photogrammetric software determined of the user selected points of interest or the arbitrarily selected points of interest or both.

At output is created based on the three dimensional positions. For example the processing logic or can create output based on the three dimensional positions that the processing logic or received at . The output can be any type of output as discussed herein. The output can be any type of output that could be created using one or more three dimensional positions of one or more respective points of interest.

Plan view output may include distances between objects of interest as calculated and described herein. Further any fixed point on a reference object such as a street sign or fire hydrant may be used as a point of reference in plan view output. For example the GNSS locations may be transformed into a local map on the plan view with one or more reference points from which distances to various features may be shown. The GNSS data itself may or may not be shown on the output. In the example discussed in the context of the location of arbitrarily selected points on the vehicles may be depicted in the output with distance data from the selected fixed or anchor points in the environment of the scene.

There are various ways that the output can be provided. For example the output may be electronically on an electronic device such as the MDCP and or a different electronic device or printed out.

Various embodiments are well suited for capturing scale information associated with at least one of the plurality of images that document a scene or for capturing scale information associated with a single image that documents a scene as discussed herein.

According to various embodiments three dimensional coordinates of points of interests may be determined using any one or more of the embodiments described herein. For example points of interest POI and POI are found in both of the images depicted in . Therefore embodiments such as that described in that use two or more images could be used according to various embodiments. In another example points of interest POI POI and POI are found in the single image as depicted in . Therefore embodiments that use a single image such as that is described in the context of may be used to determine the three dimensional positions of points of interest POI POI and POI. Scale information depicted in such as the length of a vehicle door the length of a door handle and so on could be used as scale information. Scale information in the form of an object such as a ruler could be placed into the scene so that the single image depicts the object. Scale information in the form of a measured distance from an internal EDM or an external GNSS positioning system could be used in conjunction with the single image. Therefore images of a scene may have a subset that is processed using embodiments involving multiple image processing such as described in the context of while another subset of images of the same scene may be processed using embodiments involving single image processing as described in the context of .

At one or more images of a scene are received where the one or more images depict a point of interest in the scene.

At one or more orientation information are received where each orientation information is coincident with each of the one or more images. Therefore according tone embodiment each capture of orientation information is coincident with a different one of the one or more images.

At one or more position fixes are received where there is one position fix that is coincident with each of the one or more images according to one embodiment. At according to one embodiment one or more entrance pupil positions are received where there is one entrance pupil position coincident with each of the one or more images. Therefore according to one embodiment the capture of one orientation information the calculation of one antenna position fix the calculation of one entrance pupil position and the capture of one image are coincident with each other.

At an identification of the point of interest is received. The identification according to one embodiment is based on at least one selected pixel in the one or more images. According to one embodiment the identification of the point of interest is an annotation as discussed herein.

According to one embodiment the information that are received as a part of operations can all be received as parameters in a single call instruction to logic such as photogrammetric image processing logic .

At GNSS coordinates of the point of interest are determined. For example photogrammetric image processing logic can determine a three dimensional position of a point of interest based on the information received in according to one embodiment.

According to various embodiments a method of scene documentation is provided where the method comprises with a mobile data collection platform capturing by an image capturing device that is an integral part of the mobile data collection platform a plurality of images from at least two different perspectives that depict a point of interest HA in the scene and coincident with capture of each of the plurality of images obtaining orientation information comprising a tilt angle and an azimuth angle AZ AZ via orientation sensors of the mobile data collection platform determining a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna and calculating a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein each of the images is associated with one of a plurality of entrance pupil positions wherein the determining and the calculating are performed by one or more hardware processors that are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform and capturing scale information associated with at least one of the images and with a server located remote from mobile data collection platform receiving from the mobile data collection platform via a communication network scene data comprising the images the orientation information and the entrance pupil positions and determining by one or more hardware processors A of the server based on photogrammetric image processing of the scene data a three dimensional position Xpt Ypt Zpt of the point of interest at the scene.

An embodiment provides for determining by the server based on photogrammetric image processing of the scene data a second three dimensional position of an additional point of interest B at the scene. The photogrammetric image processing can be performed by logic .

According to an embodiment the point of interest A is a first point of interest and provides for calculating by the server a vector between the first point of interest A and the additional point of interest B.

An embodiment provides for annotating performed by the server information associated with the vector the point of interest A the additional point of interest B onto at least one of the images to create an annotated image.

An embodiment provides for receiving performed by the server an identification of the additional point of interest B.

An embodiment provides for capturing at least one set of images with a depth camera array that is coupled with the mobile data collection platform capturing at least one set of images and generating a depth based scale factor based on the at least one set of images. For example scale information can be generated based on the set of images captured by the depth camera array . The scale information generated based on the set of images is also referred to herein as depth based scale factor. The generating of the depth based scale factor can be performed by processing logic as discussed herein.

Various embodiments provide for a system comprising a mobile data collection platform configured to capture by an image capturing device that is an integral part of the mobile data collection platform a plurality of images from at least two different perspectives that depict a point of interest HA in an scene and coincident with capture of each of the plurality of images obtain orientation information comprising a tilt angle and an azimuth angle AZ AZ via orientation sensors of the mobile data collection platform determine a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna and calculate a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein each of the images is associated with one of a plurality of entrance pupil positions wherein one or more hardware processors that are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform determine the position fix of the antenna and calculate the entrance pupil position and capture scale information associated with at least one of the plurality of images and a server located remote from mobile data collection platform and configured to receive from the mobile data collection platform via a communication network scene data comprising the images the orientation information and the entrance pupil positions and determine by one or more hardware processors A of the server based on photogrammetric image processing of the scene data a three dimensional position Xpt Ypt Zpt of the point of interest at the scene.

An embodiment provides for a server further configured to determine based on photogrammetric image processing of the scene data a second three dimensional position of an additional point of interest B at the scene. The photogrammetric image processing can be performed by logic .

An embodiment provides for the point of interest being a first point of interest A and the server being further configured to calculate a vector between the first point of interest A and the additional point of interest B.

An embodiment provides for the server being further configured to annotate information associated with the vector the point of interest A the additional point of interest B onto at least one of the images to create an annotated image.

An embodiment provides for the server being further configured to receive an identification of the additional point of interest B.

According to various embodiments the system further comprises a depth camera array coupled with the mobile collection platform with the depth camera array coupled with the mobile data collection platform capturing at least one set of images and wherein the server is further configured to generate a depth based scale factor based on the at least one set of images. For example a set of images captured with a depth camera array can be transmitted along with other information to the server . Scale information can be generated based on the set of images captured by the depth camera array . The scale information generated based on the set of images is also referred to herein as depth based scale factor. The generating of the depth based scale factor can be performed by processing logic as discussed herein.

Various embodiments provide for a mobile data collection platform MDCP comprising an image capturing device that is an integral part of the mobile data collection platform and is configured to capture a plurality of images from at least two different perspectives that depict a point of interest A in an scene one or more MDCP hardware processors configured to obtain coincident with capture of each of the plurality of images orientation information comprising a tilt angle and an azimuth angle AZ AZ via orientation sensors of the mobile data collection platform determine coincident with capture of each of the plurality of images a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna and calculate coincident with capture of each of the plurality of images coincident with capture of each of the plurality of images a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein each of the images is associated with one of a plurality of entrance pupil positions wherein the one or more MDCP hardware processors are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform and capture scale information associated with at least one of the plurality of images and a transceiver configured to send scene data via a communication network to a server located remote from mobile data collection platform the scene data comprising the images the orientation information and the entrance pupil positions and receive a three dimensional position Xpt Ypt Zpt of the point of interest at the scene which has been determined by one or more hardware processors A of the server based on photogrammetric image processing of the scene data.

Various embodiments provide for a method of scene documentation the method comprising with a mobile data collection platform capturing by an image capturing device that is an integral part of the mobile data collection platform a plurality of images from at least two different perspectives that depict a point of interest in the scene and coincident with capture of each of the plurality of images obtaining orientation information comprising a tilt angle and an azimuth angle AZ AZ provided orientation sensors of the mobile data collection platform determining a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna calculating a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein each of the images is associated with one of a plurality of entrance pupil positions and wherein scene data comprises the images the orientation information and the entrance pupil positions and capturing scale information associated with at least one of the plurality of images and determining based on photogrammetric image processing of the scene data a three dimensional position of the point of interest at the scene wherein one or more hardware processors that are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform perform the determining of the position fix of the antenna the calculating of the entrance pupil position the capturing of the scale information and the determining of the three dimensional position.

An embodiment provides for determining by the one or more hardware processors based on photogrammetric image processing of the scene data a second three dimensional position of an additional point of interest B at the scene. The photogrammetric image processing can be performed by logic .

An embodiment provides for the point of interest being a first point of interest A and provides for calculating by the one or more hardware processors a vector between the first point of interest A and the additional point of interest B.

An embodiment provides for annotating by the one or more hardware processors information associated with the vector the point of interest A the additional point of interest B onto at least one of the images to create an annotated image.

An embodiment provides for receiving by the one or more hardware processors an identification of the additional point of interest B.

An embodiment provides for capturing at least one set of images with a depth camera array coupled with the mobile data collection platform and generating a depth based scale factor based on the at least one set of images. For example scale information can be generated based on the set of images captured by the depth camera array . The generating of the depth based scale factor can be performed by processing logic . The scale information generated based on the set of images is also referred to herein as depth based scale factor. 

Various embodiments provide for a mobile data collection platform comprising an image capturing device that is an integral part of the mobile data collection platform and is configured to capture a plurality of images from at least two different perspectives that depict a point of interest A in an scene one or more hardware processors configured to obtain coincident with capture of each of the plurality of images orientation information comprising a tilt angle and an azimuth angle AZ AZ provided by orientation sensors of the mobile data collection platform determine coincident with capture of each of the plurality of images a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna calculate coincident with capture of each of the plurality of images a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein each of the images is associated with one of a plurality of entrance pupil positions and wherein scene data comprises the images the orientation information and the entrance pupil positions capture coincident with capture of at least one of the plurality of images scale information and determine based on photogrammetric image processing of the scene data a three dimensional position of the point of interest at the scene wherein the one or more hardware processors are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform.

Various embodiments provide for a method of scene documentation the method comprising with a mobile data collection platform capturing by an image capturing device that is an integral part of the mobile data collection platform an image from a perspective that depicts a point of interest A in the scene and coincident with capture of the image obtaining orientation information comprising a tilt angle and an azimuth angle AZ AZ provided by orientation sensors of the mobile data collection platform determining a position fix of an antenna associated with the mobile data collection platform in three dimensions based on raw Global Navigation Satellite System GNSS observables captured by the antenna and calculating a position of an entrance pupil of the image capturing device in three dimensions based on the orientation information and a known offset between the entrance pupil and the antenna wherein the determining and the calculating are performed by one or more hardware processors that are part of the mobile data collection platform and outside of an internal GNSS chipset of the mobile data collection platform and wherein scene data comprises the image the orientation information and the position of the entrance pupil capturing scale information depicted in the image and determining or based on photogrammetric image processing of the scene data a three dimensional position Xpt Ypt Zpt of the point of interest at the scene.

An embodiments provides for with the one or more hardware processors performing the obtaining of the orientation information the determining of the position fix the calculating of the position of the entrance pupil the capturing of the scale information and the determining of the three dimensional position.

An embodiment provides for with a server located remotely from the mobile data collection platform performing the determining of the three dimensional position.

An embodiment provides for the capturing of the scale information to further comprise receiving an electronic measured distance between a location where the image was captured and a point of interest captured in the image. According to one embodiment the electronic measured distance may be provided by an EDM which may be an internal EDM or an external EDM accessory .

An embodiment provides for the antenna to be selected from a group consisting of an internal antenna that is part of the mobile data collection platform and an external antenna that is located outside of the mobile data collection platform wherein the external antenna is maintained in a known spatial relationship and with the entrance pupil .

Unless otherwise specified any one or more of the embodiments described herein can be implemented using non transitory computer readable storage medium and computer readable instructions which reside for example in computer readable storage medium of a computer system or like device. The non transitory computer readable storage medium can be any kind of physical memory that instructions can be stored on. Examples of the non transitory computer readable storage medium include but are not limited to a disk a compact disk CD a digital versatile device DVD read only memory ROM flash and so on. As described above certain processes and operations of various embodiments of the present invention are realized in one embodiment as a series of computer readable instructions e.g. software program that reside within non transitory computer readable storage memory of a computer system and are executed by the hardware processor such as or A or a combination thereof of the computer system. When executed the instructions cause a computer system to implement the functionality of various embodiments of the present invention. For example the instructions can be executed by a central processing unit associated with the computer system. According to one embodiment the non transitory computer readable storage medium is tangible.

Unless otherwise specified one or more of the various embodiments described in the context of can be implemented as hardware such as circuitry firmware or computer readable instructions that are stored on non transitory computer readable storage medium. The computer readable instructions of the various embodiments described in the context of can be executed by a hardware processor such as central processing unit to cause a computer system to implement the functionality of various embodiments. Examples of a hardware processor for executing various embodiments as described herein are or A or a combination thereof. For example according to one embodiment various embodiments described herein are implemented with computer readable instructions that are stored on computer readable storage medium that can be tangible or non transitory or a combination thereof.

Although many embodiments have been descried with reference to mobile data collection platform embodiments are well suited for any of the other mobile data collection platforms described herein.

The blocks that represent features in can be arranged differently than as illustrated and can implement additional or fewer features than what are described herein. Further the features represented by the blocks in can be combined in various ways. A mobile data collection platform can be implemented using hardware hardware and software hardware and firmware or a combination thereof. Further unless specified otherwise various embodiments that are described as being a part of the mobile data collection platform whether depicted as a part of the mobile data collection platform or not can be implemented using hardware hardware and software hardware and firmware or a combination thereof.

The above illustration is only provided by way of example and not by way of limitation. There are other ways of performing the method described by the flowchart depicted herein.

Although specific operations are disclosed in various flowcharts depicted herein such operations are exemplary. That is embodiments of the present invention are well suited to performing various other operations or variations of the operations recited in the flowcharts. It is appreciated that the operations in the flowcharts may be performed in an order different than presented and that not all of the operations in the flowcharts may be performed.

The operations depicted in depicted in the flowcharts herein can be implemented as computer readable instructions hardware or firmware. According to one embodiment a mobile data collection platform can perform one or more of the operations depicted in flowcharts herein.

The embodiments described herein transform data or modify data to transform the state of a mobile data collection platform for at least the reason that by extracting pseudorange information from a GNSS chipset for use elsewhere the state of the mobile data collection platform is transformed from an entity that is not capable of determining a position fix itself into a mobile data collection platform that is capable of determining a position fix itself. In another example embodiments described herein transform the state of a mobile data collection platform MDCP from not being capable of providing an improved accuracy position fix to being capable of providing an improved accuracy position fix. In yet another example embodiments described herein transform the state of an MDCP from not being capable of to an MDCP that is capable of capturing one or more images of a scene and coincident with capture of each of the one or more images obtaining orientation information determining a position fix of an antenna and calculating a position of an entrance pupil and determining based on photogrammetric image processing a three dimensional position of the point of interest depicted in the one or more images. The one or more images the extracted pseudorange information the one or more position fixes the one or more orientation information and the one or more entrance pupil positions are transformed into a three dimensional position of a point of interest depicted in the one or more images according to various embodiments.

Example embodiments of the subject matter are thus described. Although the subject matter has been described in a language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

Various embodiments have been described in various combinations and illustrations. However any two or more embodiments or features may be combined. Further any embodiment or feature may be used separately from any other embodiment or feature. Phrases such as an embodiment one embodiment among others used herein are not necessarily referring to the same embodiment. Features structures or characteristics of any embodiment may be combined or separated in any suitable manner with one or more other features structures or characteristics.

