---

title: Multiple-object tracking and team identification for game strategy analysis
abstract: A method for automatically tracking multiple objects from a sequence of video images that may extract raw data about participating elements in a sporting, or other event, in a way that does not interfere with the actual participating elements in the event. The raw data may include the position and velocity of the players, the referees, and the puck, as well as the team affiliation of the players. These data may be collected in real time and may include accounting for players moving fast and unpredictably, colliding with and occluding each other, and getting in and out of the playing field. The video sequence, captured by a suitable sensor, may be processed by a suitably programmed general purpose computing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09437012&OS=09437012&RS=09437012
owner: DISNEY ENTERPRISES, INC.
number: 09437012
owner_city: Burbank
owner_country: US
publication_date: 20150414
---
This application is related to and claims priority from U.S. Provisional Patent application No. 61 079 203 filed on Aug. 22 2008 by S. Gefen et al. entitled Multi Object Tracking and Team Identification for Game Strategy Analysis the contents of which are hereby incorporated by reference.

The present invention relates to the field of computer vision and image processing and more specifically to the real time recognition and tracking of objects moving within a field of view and captured by one or more video cameras.

Increasing viewership of major league sports by enhancing game viewing experience has the potential to increase advertisement based revenues. This applies to all major league sports including but not limited to hockey NHL basketball NBA and soccer MLS . A good example of such a game enhancing method is the existing First Down Line FDL . The FDL is a fluorescent yellow or orange line that appears on TV broadcast of football games. The FDL allows viewers at home to observe when a player gains a first down. This FDL graphic is added to the broadcast video in real time using a video insertion technology introduced by PVI in 1998 and is described in detail in for instance U.S. Pat. No. 5 264 933 the contents of which are hereby incorporated by reference and by SportVision and is described in detail in for instance U.S. Pat. No. 6 266 100 the contents of which are hereby incorporated by reference. The FDL has since become an integral part of NFL game broadcasts.

Similarly statistical information about players and team performance as well as ongoing analyses of game progress may be a significant factor in improving game coverage and in doing so increasing viewership. For example analyzing team strategy and visualizing the teams relative formation and advances in a playback during breaks could add useful insights into game dynamics. Another example of improving game coverage is using information that could be derived in real time from puck shots in hockey.

The utility of such tracking data generated throughout a sporting event may not be limited to during the game statistics presentation for viewing reporting enhancement. The tracking data collected in real time during the sports event may for instance be archived into a database and used later to for instance index a library of games. Much information could be derived from such a database including but not limited to learning about the performance history of certain players or certain teams doing comparative analyses between for instance players or teams and generally computing statistics about any event of interest. It could also be used as a tool for training or demonstrating remarkable player and team maneuvers and tactics.

There are many types of applications that could be derived based on the positional data of the players and their team affiliation the raw data including various statistical analyses graphical illustrations and game dynamic visualizations. However obtaining the raw data to produce such real time tracking statistics presents many significant challenges. For instance the large amount of video information that has to be analyzed from each frame of video which may be high definition video. Accomplishing this using current technology requires the development of innovative methods.

Briefly described the present invention is a system and method for automatically tracking multiple objects from a sequence of video images of those objects. In a preferred embodiment the system and method of this invention hereinafter referred to as either the tracking method or the tracking process are such that the objects to be recognized may be moving rapidly and may be undergoing occlusion.

The tracking method of this invention may for instance extract raw data about participating elements in a sporting or other event in a non obtrusive manner i.e. in a way that does not interfere with the actual participants in the event. The raw data may for instance include the position and velocity of the players the referees and the puck as well as the team affiliation of the players. These data may be collected in real time and may include accounting for players moving fast and unpredictably colliding with and occluding each other and getting in and out of the playing field. Adding to this internal complexity the tracking method may also take into account the vibrations of the cameras the varying light conditions in the arena and camera flashes. This invention may deliver a unified solution for continuous real time multiple object and multiple view tracking in these and similar challenging conditions and may do so with a flexibility that allows deployment at different field layout conditions.

In a preferred embodiment of the tracking method a video sequence is processed by a suitably programmed general purpose computing device. The video sequence may be captured by a suitable sensor such as but not limited to a high definition digital camera. The sensor may be positioned at any viewpoint in the scene including but not limited to side view and overhead view. In an alternative embodiment of the invention several cameras may be used to provide full coverage of the field. For instance each such sensor may generate the video input for one tracking process. Camera views may overlap to allow the computation of off ground objects trajectories or to provide system redundancy. The tracking data provided by all tracking processes may then be fused together to form a coherent representation of the whereabouts of all the elements on the field and their team affiliation.

The tracking method may first stabilize the input video and then detect moving foreground regions by for instance utilizing a background subtraction method. The background subtraction method separates the foreground regions from the scene background for each frame using a background model. The background model which may be a reference image may be generated through a training process prior to the game and may be adapted throughout the game to meet changing light conditions as well as physical changes on the field. The detected moving foreground regions may represent desired elements such as but not limited to the players the referees the puck or the ball or some combination thereof. The detected moving foreground regions may also or instead include undesired noise elements. Prior information regarding the expected characteristics of the desired elements pre selected objects may be used to filter out this noise.

Following foreground detection the tracking method may characterize a foreground as a measurement that for instance represents a single player observation a multi player observation or a non player observation such as but not limited to a puck or a ball. Foreground related information such as feet position and environs may also be calculated and stored into the measurement s data structure. Tracking an object that is associated with a single player measurement isolated object is relatively simple. On the other hand tracking an object that is associated with a multi player measurement typically represents two or more possibly occluding players requires a further analysis. To this end a particle filtering technique utilizing color and players formation may be used for tracking in order to maintain the separate tracks of closely engaging players. The tracking method in the present invention uses cues such as but not limited to uniform and skin color players figure size and surrounding players formation to maintain consistent and lengthy tracks of elements in the field. In addition it may use the color characteristic of the tracked objects to classify them into teams such as a home group a guest group and a referee group or some combination thereof.

These and other features of the invention will be more fully understood by references to the following drawings.

The present invention uses and integrates state of the art techniques from computer vision and image processing to track players referees and puck ball that are moving fast and unpredictably while engaging and occluding each other. Moreover athletes playing in a team sport change their pose rapidly and frequently which makes tracking their silhouettes especially difficult relative to for example tracking pedestrians. Adding to the complexity of the tracking problem is the need to account for vibrations of the camera s platform changing light conditions and frequent flashes in the arena. This invention provides a vision based tracking solution that may be used in real time and may be transparent to game proceeding tracking solution.

The tracking method of the present invention is described below in the context of tracking hockey players referees and the puck during a hockey match. A person of ordinary skill in the art will appreciate that the tracking method of this invention may be applied to a wide range of events including but not limited to sports games and events such as football soccer field hockey rugby cricket tennis track and field swimming gymnastics as well as for non sporting applications such as but not limited to pedagogical security and traffic management systems by for instance tracking children in a playground or play area tracking people on surveillance cameras in a train station or airport environment and tracking cars and trucks on traffic cameras.

A preferred embodiment of the invention will now be described in detail by reference to the accompanying drawings in which as far as possible like elements are designated by like numbers.

Although every reasonable attempt is made in the accompanying drawings to represent the various elements of the embodiments in relative scale it is not always possible to do so with the limitations of two dimensional paper. Accordingly in order to properly represent the relationships of various features among each other in the depicted embodiments and to properly demonstrate the invention in a reasonably simplified fashion it is necessary at times to deviate from absolute scale in the attached drawings. However one of ordinary skill in the art would fully appreciate and acknowledge any such scale deviations as not limiting the enablement of the disclosed embodiments.

In an exemplary embodiment of the present invention shown in cameras are positioned at various locations at the arena to allow a full coverage of the scene in this case the game field . When off ground positioning of objects such as the puck is required an overlapping coverage of at least two views should be provided. Otherwise there are typically no constraints on the locations of the cameras. Each video signal may be captured in one of the Player Track computing units and may be fed into the tracking algorithm one frame at a time. At each iteration the tracking algorithm typically analyzes the current video frame to first detect and then track moving objects. At the end of each iteration Player Track may broadcast information about active tracks currently tracked objects over for instance an Ethernet . This information about active tracks may for instance include but is not limited to the real world position of an object the velocity of the object and the team to which the object belongs or some combination thereof. The Track Manager may receive the messages broadcasted from each Player Track in the system and may compile all the received information into one coherent representation. Then the Track Manager may broadcast back on the Ethernet the fused tracking data to be received by a third party for game enhancement or to be stored in a database for off line processing.

A top level flow diagram of the tracking method is shown in . The first two steps of the algorithm consist of obtaining the current image and locating the foreground regions . The latter may includes stabilizing the video normalizing the color detecting the foreground regions using the reference images and extracting their outlines. Next each foreground is characterized based on features such as shape and color metrics as representative of one or more of the pre selected objects. Due to occlusion often a foreground may represent more than one object. Hence next each tracked object is assigned to be represented by one foreground region or alternatively each foreground is associated with one or more tracked objects . This process referred to as measurement to track association is critical to resolving multi object tracking where occlusion is frequent and complex.

The current position of each tracked object is then predicted utilizing a motion model and the characteristic of the object associated measurement. Following prediction the object position is further refined . This stage is especially important when several objects share the same representative foreground. Refining each object position then is done with respect to the representative foreground and with respect to the formation of neighboring objects. In the probabilistic approach suggested by this invention the likelihood of an object being located at a certain position is a function of the similarity between the object s color characteristic and the color characteristic of its representative foreground as well as the relative position of the object to its neighboring objects. Note that in steps and tracks are processed independently and therefore implementation can be parallelized taking advantage of a multiprocessing environment.

Next in step measurements without object association are examined. A measurement that is characterized as a single object measurement will be considered as a new observation indicative of a new object entering the scene. In this case a new track data structure is initiated including the new object s characteristic such as position color and object s ROI. Finally the tracked objects are clustered into groups in this case the home team guest team and referees. Detail description of the above tracking method steps will be presented below.

Prior to employing tracking knowledge of the cameras model is required to compute the position of tracks in real world coordinates and to characterize the foregrounds in real world space. The relation between a real world point at the scene and its projective point in image space is determined by a calibration procedure as illustrated in . Calibration may be carried out during system setting once the cameras are positioned in place. A representation of the scene in this case the rink in real world coordinates is compared with the scene s projective image supported by image space coordinates . Correspondence is established by pairing landmark points such as the pair and the pair . This correspondence information allows for the computation of camera parameters including the camera s gimbal position pan tilt roll and image distance from the lens. These camera parameters define the mapping between a point in real world space denoted hereafter as x x y z and its projective point in image space denoted hereafter as u u v .

The first step when automatically tracking objects is detection of the dynamic elements imaged by the system s sensors locating foreground regions . Typically locating the foreground regions is achieved by background subtraction. The static scene the background is statistically represented by reference images. Comparing the reference images against the current image allows demarcation of the foreground regions from the background region. In the present invention the background is modeled by three reference images created via training on a video sequence captured prior to the tracking operation. The reference images then are accessed by the background subtraction process in and are also updated to account for lighting changes in the scene during tracking.

The algorithm for calculating the reference images starts with initializing the above background model records to zero. Going through the pixels of the first image in the training video sequence each pixel is compared first with its corresponding most probable background color . If this pixel color value is within a predefined range of this most probable background color then this pixel color value is used to update the value of the most probable background color and its frequency counter is increased by one . Otherwise this pixel is compared with its corresponding second most probable background color . Similarly at this point if this pixel color value is within a predefined range of the second most probable background color then this pixel color value is used to update the value of this second most probable background color and its frequency counter is increased by one . This comparison may go all the way through to comparing the current pixel value against the Nth most probable background . However if the current pixel value was not found to be within range of any of the N background color values the Nth most probable background is set to the current pixel value and its frequency counter is set to one .

Once the matching background color has been updated and its counter incremented the N current background colors are sorted with respect to their frequency counters . This way the order of the probable background colors from most probable to least probable is maintained so that accessing them is more efficient all through the process. Completing processing of all pixels through all training video sequence the reference image is established as the one composed of all most probable background colors . Next three representative reference images are created. The first one is a minimum reference image the output of a 3 3 minimum filtering of the reference image . The second one is a maximum reference image the output of a 3 3 maximum filtering of the reference image . And the third one is an average reference image the output of a 3 3 average filtering of the reference image . These three reference images represent the scene background and as such are used to locate the foreground regions as will be explained next.

The current image optionally after employing the stabilization procedure is compared with the reference images . First each current image pixel is compared against the corresponding pixel in the average reference image if within a predefined range it is determined to be a background pixel and the corresponding pixel in a mask binary image is set to zero. Otherwise if the pixel is not within a predefined range a second test takes place the value of the current image pixel is checked to verify if it is between the values of corresponding pixels from minimum and maximum reference images . If it is within this range the current image pixel is determined to be a background pixel otherwise an out of range counter is incremented by one . The purpose of the out of range counter is to detect an occasional flash that disables proper further analysis of the current image. Thus if the out of range counter is above a pre defined threshold a flash is detected and processing stops for the current image . Otherwise the current pixel is determined to be a foreground pixel and the corresponding pixel in the mask image is set to one. Processing of all pixels accordingly leads to completion of the mask image that constitutes a binary representation of the foreground regions in the current image . The last step includes delineating the outline of each foreground region and storing it in a vector . An outline vector consists of the coordinate points of pixels on the foreground s boundary. A foreground s outline embodies shape information and so is instrumental for its characterization.

Camera vibrations and instantaneous changes in illumination are a common reality in the field and should be accounted for when relating one video frame to another. The background subtraction technique as described in steps through assumes a fixed camera position or alternatively that the current image was compensated for any spatial deviation relative to the average reference image.

It is common practice in image processing to analyze patterns at different resolutions. A multi resolution approach in general reduces algorithm complexity and prevents optimization algorithms from being trapped at local extremum. Thus in the reference and current frames are sub sampled into an L level pyramid representation. Next a set of feature points S u v i 1 . . . N from the average reference image is compiled . These feature points represent high curvature points from the field plane . Similarly a set of points S u v i 1 . . . N is defined and initialized as S Sin step . Having corresponding sets Sand S it is straightforward to calculate T using a weighted least squared error WLSE estimator for instance. The challenge is in obtaining a set S that corresponds to the set S. To this end first a set that is merely matching S not corresponding necessarily is found and then using for instant the RANSAC method the transformation parameters ttttdd are estimated together with the corresponding set S . This feature based image registration method will be explained in detail next.

The registration algorithm computes the transformation T in a coarse to fine order. At each level of resolution a matching feature set S to Sis pursued . First the points u v Sand u v S are scaled down to fit the current resolution level. Then a block matching technique may be used wherein a block centered at a feature point u v Sis compared with blocks from a neighborhood centered at the current feature point u v S. Thus the pair of blocks with the highest correlation will result in a match. Note that this pair of points has a matching texture but does not necessarily represent correspondence. Therefore only a subset of Sand S that better represents correspondence should be used to estimate the transformation parameters in 1 .

In step the RANSAC Random Sample Consensus method may be utilized to estimate the transformation parameters in 1 from Sand the current matching set S. The RANSAC method is known to be a robust scheme to fit a mathematical model to given data in the presence of outliers and it may successfully be used in step to recover the transformation T and to update the points in set S as follows u T u. The updated points in set S are in better correspondence with the points in Sfor the current resolution level. To obtain a refinement for T and S processing proceeds to the next higher resolution level . Completing processing at all resolution levels the last and most refined estimate for the transformation T is used to map the current image onto the average reference image .

Once spatial vibrations have been accounted for through image registration in step the image stabilizer performs color normalization in step . Variation in image illumination may occur due to a change in the angle between a light source and the camera or alternatively a jitter in camera aperture and shutter speed. Here the color values of the current frame are altered through polynomial transformations to globally match the average reference image. In the case where YUV color model is used for example the Y value may be mapped independently while the mapping operator for the color components U and V may be coupled since their values are highly correlated.

Back to the realization of video stabilization in step is optional and its inclusion depends on the conditions in the field. For example in outdoor deployment the camera may be exposed to vibration due to wind load or any non stationary camera platform while in indoor deployment only small sub pixel vibrations may occur. Step sufficiently addresses sub pixel displacements but in the case of larger displacements image registration and possibly color normalization should be employed first before proceeding to background subtraction.

Following the foreground regions locating algorithm in step the measurements characterization step is carried out as illustrated in . A measurement including a foreground region and its outline contains color and shape information that can be analyzed using various pattern recognition methods in order to learn about the nature of the object or objects it represent. In the context of a hockey game the objects of interest are the players the referees the hockey sticks and the puck. Therefore in our exemplary embodiment each detected foreground is characterized and analyzed to determine which one or more of these pre defined objects they may represent. The tracking method later uses this information to carry out tracking of these pre defined objects specifically to associate detected measurements to tracked objects.

In the hockey game case first the outline length vector size is examined to determine if a measurement is likely to represent a puck . If the outline length is smaller than a preset threshold then a candidate for a puck measurement is detected. Otherwise the foreground s area and bounding ROI are examined to determine if it is likely to represent a human or a group of connected and or occluding humans . For example the foreground s area may be compared with the area of the ROI of a player hypothetically positioned at the measurement vicinity. Or the height of a foreground s ROI may be compared with the height of the ROI of a player hypothetically positioned at the measurement vicinity. If the foreground s characteristics are found to be those of a human humans then processing proceeds to step otherwise processing proceeds to the next foreground .

Although there is only one puck on the ice during the game typically more than one measurement will be considered as a puck candidate. Therefore in the puck detector various features are fused together to determine the most likely puck measurement. There may be two groups of features computed in step . The first group of features is designed to capture the elliptic signature of the puck at various extents. The left part of illustrates the puck signature . Note that the puck s image is smeared due to motion blur. The contours and shows two possible Hough transform integration paths C that may be used to detect the puck s elliptic shape. These features may be employed on the puck image Y may be the gray scale part of the image as follows 

The second group of features is designed to detect a hockey stick. In the search for the puck measuring the likelihood that a measurement originates from a hockey stick helps eliminate it from mistakenly being detected as a puck. Often the tip of the hockey stick resembles the puck image due to the high reflectivity of the part connecting the stick to its tip. The right part of illustrates the stick s signature . The hockey stick s short axis C and long axis C may be projected at different orientations defined by the angle and the angle respectively.

Foreground regions found to be representative of a human or a group of humans are further characterized in step . Real world measures are estimated out of the foreground s outline in order to obtained two metrics. The first metric is the foreground s point of contact with the ground or the center of players feet on the ground . The second metric is a scalar value termed environs which is indicative of the area of projection on the ground of a foreground region . The environs is used by the tracking method to assess the number of players projected by a foreground Next the computation of these two metrics is described.

The environs is a scalar value proportional to the area enclosed by the quadrilateral and is defined by the points X X X and X. The environs is a real world metric that can suggest for example if a foreground encloses on one player single player measurement or rather encloses on a group of connected occluding players multi player measurement . It may also be used to compare between foreground regions meaning if a foreground region representative of five players in a previous frame is split into two foreground regions in the current frame then comparing the two foregrounds environs values can suggest a likely distribution of the five players between the two foreground regions. The usage of the environs metric for resolving tracking under occlusion will be explained below.

The second metric the foreground s point of contact with the ground or the center of feet position is estimated as follows. The centroid P u v of the outline is in the vicinity of a players body center and therefore its real world position xcan also be calculated x x h 2 z . The points x x and xmay be used to estimate the center of feet location considering their projections on the ground as follows 3 0 3 7 shows the feet position for a foreground encloses on one player and a foreground encloses on a group of connected occluding players. Note that these estimates for the environs and the center of feet location metrics are real world measures that are valid for any camera position relative to the scene.

The last step in the measurement characterization procedure includes compiling a list of measurements and their associated parameters such as the foreground and its outline the environs the center of feet position the ROI etc. This measurement list is passed to the object tracking algorithm for further processing.

During a game players collide with and occlude each other rapidly and unpredictably. In addition each player s pose and position may change considerably from one frame to the other. This dynamic translates into foreground regions that frequently merge and split through successive frames. This behavior complicates the tracking task especially in sports such as hockey and basketball where players constantly and closely interact with each other. In the measurement to track association part of the algorithm the tracker starts with linking measurements from the previous frame iteration to measurements in the current frame iteration by employing a Merge Split Detector. The measurement to track association procedure will be explained through the four frame foreground transition analysis in .

Next in the third frame the one foreground from previous frame is split into two foregrounds and . In this split transition the algorithm needs to distribute the four objects from the second frame between the two foregrounds in the third frame . Hence based on the environs value of each foreground and three objects are assigned to the foreground with the larger environs and one object is assigned to the foreground with the smaller environs . The decision as to which object out of the four A B C and D to assign to which foreground out of the two and is based on spatial distance and on color similarity between each object and each foreground. In the fourth frame both a split and a merge are occurred. In this case the four objects associated with foregrounds and in the third frame will be distributed evenly between the two foregrounds and in the forth frame since theirs environs values are comparable.

Using the environs metric to decide how to distribute a plurality of objects among a plurality of foregrounds after a split transition is essential for resolving the measurement to track association problem especially when tracking highly dynamic groups of objects such as players. The distribution of a plurality of objects among a plurality of foregrounds is selected as follows. First for each possible distribution the ratios between each foreground s environs and the number of objects assigned to it are calculated. Then the distribution that resulted in ratios with minimum variance is selected. For example in frame there are three possible distributions a one object assigned to foreground and three objects assigned to foreground b two objects assigned to foreground and two objects assigned to foreground c three objects assigned to foreground and one object assigned to foreground . Therefore the corresponding ratios are a foreground s environs divided by one and foreground s environs divided by three b foreground s environs divided by two and foreground s environs divided by two and c foreground s environs divided by three and foreground s environs divided by one. Given that the environs value is proportional to the area of a foreground region s projection on the ground it can be seen that the distribution in case c resulted in ratios with minimum variance.

Back to completing the measurement to track association procedure the following group of steps updates the state of each track independently and therefore may be employed in parallel. First if a track is not represented by a measurement the track is deleted assuming that the object moved out of the scene. Otherwise the track s current position is predicted in step . The prediction of a track s current position x k is computed based on a motion model constant velocity model for instance as x k and based on the position of the associated measurement x k as follows 1 8 where a is a scalar proportional to the measurement environs. Hence for a small environs single player measurement a is close to zero and therefore x k is close to the associated measurement feet s position estimate x k . While for a large environs multi player measurement a is close to one and therefore x k is closely set to x k .

Next the object s current position is further corrected refined based on color analysis and the relative position of the object and its neighboring objects. This position refining is especially important when several tracks are associated with one measurement as illustrated for instance in frames . In this case knowledge of the objects color characteristic and their previous relative positions is instrumental in determining their most likely current position within the foreground region.

Color is an important characterizing feature of objects. It is invariant to pose orientation and resolution and it is relatively simple to model using for instance a discrete three dimensional histogram. The tracker builds a color histogram for each track at initiation and continues adding samples into this histogram as long as the environs of the track s assigned measurement is small enough indicative of a single player . This way pixels drawn from the player s foreground region are most likely to belong to this player only and not to other players thereby allowing for accurate color representation of the tracked player. A track s color model may be three dimensional YUV color histogram with for instance an 8 cube bin size.

Each track s histogram gives a probabilistic representation of its player. This probabilistic representation may be used to determine the probability f I u v of any pixel I u v to belong to a certain tracked player. Particularly the tracker considers a player s ROI r roi x w h defined by the projection of a hypothetical player at position x and with w width and h height. Note that this rectangular region is defined in image space and is computed as a function of a real world player s position width 2 ft and height 6 ft . As a result regardless of the player s position relative to the camera this ROI will always be tightly enclosing on its figure.

Having a player s ROI r the similarity of the region it encloses to a specific player s track color model is determined by

The tracker may use a particle filtering technique in order to get the most likely player s position in the vicinity of x k in step . Particle filtering is a Monte Carlo technique to approximate the posterior probability p x k z k by a set of samples and their weights . Each particle i has its own hypothesis regarding the current track state where a track state may be defined by x y z w h. Specifically each particle hypothesizes that the track s position is at location x x y z and that the player s width and height are wand h respectively. Next each particle s hypothesis is weighed by 

Thus in the particle filtering method each particle 1 is influenced by the experience of the overall population of particles and 2 impacts the overall particles population by its own experience . Specifically the following steps are carried out 

Employing particle filtering is computationally expensive because the similarity metric in 10 needs to be computed for each particle. In addition enough particles should be included in the analysis to accurately approximate the posterior probability p x z . To facilitate real time tracking an integral image method may be used. An integral image method is a technique that can be used to speed up computation carried out over a rectangular support. In our case this is the similarity metric that is computed for all the ROIs of all the particles that are confined within a window termed here the canonical window. Pre calculating the integral image of f I u v within the canonical window and then extracting

At the end of each tracking iteration the tracking algorithm automatically identifies the team affiliation of all active tracks . This is done by comparing the color model histogram of each player s track to the color models histograms of home guest and referee teams. The histograms representing the teams color models may be built at the very beginning of the tracking operation before the game starts with the help of a human operator as demonstrated in . An operator may manually select several tracks of players from the home team the tracker then compiles the color models of these players resulting in a home team s color model . Similarly the operator may select tracks of several guest players and several referees for the tracker to compile the guest team s and the referee team s color models. Once the team s color models are built the tracker is ready to cluster actively tracked objects into teams through comparison of each track s color model say histogram with each of the teams color models say histograms .

There are many ways to measure the similarity or distance between two color histograms using measures such as normalized correlation histogram intersection Kullback Leibler divergence and Bhattacharyya coefficient. For example the Bhattacharyya coefficient is defined as square root over 13 where an entry in a player s histogram p m is compared with the corresponding entry in a home guest or referee s histogram p m .

Adding the team identification information to a player s positional data makes the tracking system a powerful indexing engine. It extends its game analysis capacity from merely analyzing player based performance to analyzing team based performance and team based strategy. For example knowing the team affiliation of a group of players it will be possible to visualize their relative propagation and formation during critical parts of the game.

Another embodiment for this invention may be as a component of a broadcast enhancement system. illustrates a system that receives a feed from the broadcast camera . This can be a dedicated feed from a camera covering the game play an isolated point of view camera or a program feed which cuts between video from multiple cameras. The Video Tracker analyzes the incoming video for landmarks and produces a representation of the PTZ of the video which is combined with camera position information to produce a camera model similar to the calibration process. The Tracker updates the position over time through frame to frame analysis of features in the video such as texture analysis performed by the stabilization routine in this tracking method invention . These video camera tracking techniques are well known in the field U.S. Pat. Nos. 5 808 695 and 6 529 613 . Alternately the Video tracker can rely on PTZ sensors on the camera or a combination of sensors and image stabilization which is also known in the field U.S. Pat. No. 6 100 925 . The resulting camera model may be sent over the Ethernet connection to the Player Tracker Video Render and Operator controller .

The Player Tracker receives the camera information from Video Tracker and updates the camera model for the particular frame replacing the functionality of the calibration and the stabilization procedures. In this embodiment the background subtraction in step is replaced with a color chromakey step based on the dominant background colors. Chromakeying techniques to handle occluding foreground objects are well known by those familiar with the art U.S. Pat. No. 7 015 978 . The object tracking steps generate tracks consistent with the camera model received from the Video Tracker. The resulting information may be sent over the Ethernet connection to the Render module and Operator Controller .

The Render is responsible for generating and mixing graphics into the video feed. It analyzes the input video to find the dominant colors of the background if chromakeying of foreground objects is desired. The Render receives camera orientation information from the Video Tracker and players location from the Player Tracker. It uses this data to warp artwork related to the objects that is realistically rendered into the video scene. Alternately it can be used to relay data statistics in a burn in graphic. In the typical scenario a mixed output is sent out for broadcast.

The operator controller enables a human operator to monitor and control the broadcast enhancement process. It provides feedback on the state of the Video Tracker module with diagnostics overlaid on a video window. It allows the monitoring of Player Tracker data output with the option to select information from a player of interest. It enables the selection of graphics and monitoring of results within the video render . Control of the Video Tracker Player Tracker and Video Render may be achieved through Ethernet communications .

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed invention. Modifications may readily be devised by those ordinarily skilled in the art without departing from the spirit or scope of the present invention.

This section contains a glossary of terms including commonly used terms of art and specific terms coined in this document to help describe this invention.

A BACKGROUND the regions in a video frame that belong to the static part of the scene. For example in a video of a hockey game the ice boards creases may be part of the background.

BACKGROUND SUBTRACTION is typically the process of separating a video frame into background and foreground regions. This separation may be with respect to the reference image and may be represented by the mask.

CAMERA CALIBRATION the process of producing the camera s parameters including but not limited to the gimbal real world position pan tilt roll and image distance from the lens. Camera parameters are typically used to relate a point in the image space to its correspondence in real world space and vise versa.

AN ENVIRONS a scalar value indicative of the area of projection on the ground of the foreground region.

A FOREGROUND the regions in a video frame that belong to the dynamic part of the scene or alternatively regions that are not part of the background. For example in a video of a hockey game the players referees and puck may be part of the foreground.

AN IMAGE SPACE a two dimensional space of the scene s image as projected by the camera. Image space coordinates denote the column and row number of a pixel s location in the image.

A MASK is a binary image with pixel values set to 1 where the corresponding video frame s pixels are part of the foreground and set to 0 where the corresponding video frame s pixels are part of the background.

A MEASUREMENT a data structure containing information about a foreground such as foreground s outline foreground s point of contact with the ground and foreground s environs.

AN OUTLINE an array of image pixel coordinates that delineates a foreground element is typically referred to as an outline. The array s coordinates point to the boundary pixels of the foreground.

REAL WORLD SPACE a three dimensional space of the scene s physical space. Real world coordinates are in physical units such as meters or feet.

A REGION OF INTEREST ROI sub region in an image specified by the left right top and bottom sides of a bounding rectangle.

A REFERENCE IMAGE is an image that models a complete camera view of the static scene without occlusion by moving objects.

A TRACK a data structure containing information about a tracked object such as object s position velocity and ROI.

A VIDEO FRAME a single framed image in a sequence of images that captures a snapshot of a dynamic scene.

