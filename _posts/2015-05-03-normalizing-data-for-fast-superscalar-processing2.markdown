---

title: Normalizing data for fast superscalar processing
abstract: A data normalization system is described herein that represents multiple data types that are common within database systems in a normalized form that can be processed uniformly to achieve faster processing of data on superscalar CPU architectures. The data normalization system includes changes to internal data representations of a database system as well as functional processing changes that leverage normalized internal data representations for a high density of independently executable CPU instructions. Because most data in a database is small, a majority of data can be represented by the normalized format. Thus, the data normalization system allows for fast superscalar processing in a database system in a variety of common cases, while maintaining compatibility with existing data sets.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09582467&OS=09582467&RS=09582467
owner: Microsoft Technology Licensing, LLC
number: 09582467
owner_city: Redmond
owner_country: US
publication_date: 20150503
---
Superscalar central processing units CPUs that can execute more than one instruction per clock cycle are becoming more and more common for computing systems. Unlike pipelined architectures superscalar architectures include multiple redundant functional units that can operate on many instructions in parallel. Superscalar architecture and pipelining can be used together to provide even more CPU efficiency. Superscalar processing depends in part on the processor being provided with or detecting on its own instruction streams that are intrinsically parallel meaning that the stream contains operations that operate on independent sets of data or in a way that order of execution between the operations will not lead to different results. This allows the processor to perform multiple operations at the same time.

Most database systems were implemented before superscalar CPUs started to dominate the market. Superscalar CPUs process data faster provided there are enough independent instructions inside small instruction windows e.g. on the order of up to 100 instructions . In such cases superscalar processors can detect enough independent operations to utilize multiple available CPU execution units. Independent operations are those with no data or control flow dependencies between them. Database systems often rely on optimizations that are no longer efficient for superscalar architectures. For example a database implementation may include long functions with many conditional branches.

To take advantage of superscalar CPUs databases need to improve data warehouse processing to achieve higher efficiency in processing for a majority of data warehouse specific data values. Current internal data representations do not lend themselves to efficient scalar processing. Database systems provide many data types such as integers strings floats binary blobs and so forth that may each include a different type of internal data structure or other representation. Some of these are more appropriate for superscalar processing than others. Code paths have to be constructed with care to ensure very efficient processing and high density of independent CPU instructions which often is not the case for database systems being used on superscalar processors. Various specialized data warehouse engines have been built to take advantage of superscalar CPUs such as Monet DB X100 and Microsoft Analysis Services. However these engines are not generic relational database management system RDBMS engines and provide advantages only in limited situations that do not address superscalar issues with the database system core.

A data normalization system is described herein that represents multiple data types that are common within database systems in a normalized form that can be processed uniformly to achieve faster processing of data on superscalar CPU architectures. The data normalization system includes changes to internal data representations of a database system as well as functional processing changes that leverage normalized internal data representations for a high density of independently executable CPU instructions. Because most data in a database is small a majority of data can be represented by the normalized format. The system includes functions that optimistically attempt to handle all data in a batch as normalized and to do so compactly with few control flow dependencies. During fast processing the algorithm identifies data that is not normalized and sets that data aside for later processing by a traditional slower algorithm that may not be as superscalar efficient. Thus the data normalization system allows for fast superscalar processing in a database system in a variety of common cases while maintaining compatibility with existing data sets.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A data normalization system is described herein that represents multiple data types that are common within database systems in a normalized form that can be processed uniformly to achieve faster processing of data on superscalar CPU architectures. The data normalization system includes changes to internal data representations of a database system as well as functional processing changes that leverage normalized internal data representations for a high density of independently executable CPU instructions. In some embodiments the system stores data using a 64 bit binary value that can either represent a normalized data type or act as a pointer to a non normalized data type for those data types that do not fit the normalization scheme. For example 64 bits may be insufficient for storing some types of data like a long string or a long binary blob. In some embodiments a bit of the 64 bit binary value is reserved to indicate whether the value represents a normalized data type or not e.g. the significant bit can be used for this purpose so that a simple CPU shift instruction can be used to extract data from the remaining 63 bits . Once all data is represented in a common format it is easier to provide functional processing that operates on such data in a superscalar efficient manner. Because most data in a database is smaller than the size of the 64 bit data value e.g. a street number phone number amount of sales in a region and so forth a majority of data can be represented by the normalized format.

The system includes functions that optimistically attempt to handle all data in a batch as normalized and to do so in compact ways e.g. a tight loop with few control flow dependencies. For example for a batch of column data having a column each from two sources to be added together the system may optimistically assume that all of the data in the columns fits into the normalized scheme described herein and process the data using a fast algorithm that allows each row value in the columns to be added independently within the CPU. For hundreds of rows of data this can result in a dramatic execution speed improvement. During fast processing the algorithm identifies data that is not normalized e.g. using the bit described above and sets that data aside e.g. by ignoring it or placing it on a separate list for later processing by a traditional slower algorithm that may not be as superscalar efficient. For example the system can make two passes through a set of column data one to perform operations for those rows that contain normalized data that can be handled quickly and another to perform operations for those rows that contain non normalized data that is processed in a traditional manner. Thus the data normalization system allows for fast superscalar processing in a database system in a variety of common cases while maintaining compatibility with existing data sets.

In some embodiments the data normalization system establishes a convention for representing NULL data values in the data set. For database systems a NULL value is a different value than a numeric zero and thus may not be able to be represented in the normalized format in the same way that zero is. Because the normalized format contains a bit for indicating non normalized data the system can use setting the non normalized bit in combination with a null value for the portion that would normally point to the non normalized data as an indication of NULL. This allows the system to cover a much broader set of common values NULL within the normalized format.

In some embodiments the data normalization system includes hash join and hash aggregation algorithms that reduce a number of CPU instructions needed to perform their task. These algorithms may also minimize data and control flow dependencies for a majority of data processing to efficiently utilize superscalar CPU resources. These processing techniques are described further herein.

Superscalar CPUs are able to execute multiple instructions in single CPU cycle provided a each instruction performs a simple scalar calculation and b there are no data dependencies in a set of operations processed by the CPU in a cycle. The data representation described herein satisfies the first condition for a majority of data values so that processing can occur using as few CPU instructions as possible. Most modern CPUs can perform a variety of native operations on 64 bit values. The data normalization system satisfies the second condition by improving data processing algorithms so that the CPU has sufficient number of independent operations to perform in close proximity in a particular code path. In data warehouse scenarios if an array of data is to be processed then usually each array element s processing is independent from other elements. The system overlaps processing of one array element with processing of one or many other array elements to provide multiple independent instructions for the superscalar CPU to execute. The system overlaps processing in part by making array processing loops very short so that the CPU can easily recognize the parallelism. In these cases a set of CPU instructions processed in a CPU cycle will include instructions from individual loop iterations. Alternatively the system overlaps processing by merging data processing tasks of two or more separate loop iterations into a single instruction stream.

In some embodiments described herein the data normalization system uses a 64 bit or 8 byte value to represent common data types. A 64 bit value is currently a good choice because most data types will fit in 64 bits e.g. integers dates floats short strings Booleans and so forth . Widely available processors also are natively able to process 64 bit values from registers or memory in a single instruction. However those of ordinary skill in the art will recognize that it has been the nature of computing to utilize more space over time and the system herein could be easily extended to use a value that includes more than 64 bits e.g. 128 bits . Conversely there may also be situations where using smaller values would be useful such as mobile or embedded scenarios where memory is constrained and the system can be adapted to use a smaller number of bits e.g. 32 bit . The 64 bit value is used herein as an example but is not intended to limit the system described to any particular bit or byte size implementation.

In the 64 bit example the data normalization system provides a data representation for NULL and common integer numeric and string data type values in a RDBMS. This particular representation uses eight bytes where the least significant bit LSB is zero to indicate that the value is of a common type i.e. frequently used and can be processed using the fast techniques described herein. Another bit could also be used e.g. the most significant bit and those of ordinary skill in the art will recognize that endian ness of the system and other considerations can affect the bit chosen. In addition the system can also use values that do not encode an indication of whether the value is a normalized type within the value itself. In the present example the remaining 63 bits represent the value itself e.g. a number for a numeric value or several characters for a short string value . Such common values can be processed very efficiently to meet the first condition descried in the previous paragraph. If the least significant bit is one and the rest of bits are zero then it indicates a relational NULL value. If the least significant bit is one and any other bit is non zero then the remaining 63 bits represent a pointer or other reference e.g. an index to an uncommon data type domain value. The system processes non normalized data outside of tight processing loops so as not to interfere with superscalar CPU specific optimizations. Note that in many cases such as sum and comparison operations the system can ignore the least significant bit and perform the operation without shifting the normalized value to remove the bit. Rather the system may only need to shift the value at the end of processing to convert data back from normalized into native representation.

One example of a common database data type that can be represented using this format is the big integer bigint provided by Microsoft SQL Server. The bigint data type in Microsoft SQL Server covers range of integer values 2 64 . . . 2 64 1 . The system can represent all but the extreme values within the 63 bits available in the normalized data representation. A majority of user data fits into this range. For other values the system uses a conventional representation for bigint values i.e. for very large positive and very small negative values . Another example is a column containing a varchar 10 data type which is a string value having a limit of 10 characters. Where string column data is likely to only hold a small set of values e.g. two letter abbreviations or full names of U.S. states databases often use a dictionary approach where the database stores a dictionary of all of the string values and stores an index in the column data that points to the appropriate location to find the string in the dictionary. The data normalization system uses the normalized data representation whenever strings reside in the column store dictionary and can be identified using a 63 bit integer index. The system may reserve several bits in the normalized value to identify a dictionary there may be more than one and then the rest of the bits identify a string within the dictionary. Otherwise the system uses a conventional representation with a pointer pointing to the actual string value. The system can also include string data directly in the 63 bits when the string data is sufficiently short e.g. less than four or eight characters depending on whether ANSI or UNICODE encoding is used .

In these two examples data value comparisons for the normalized representation for aggregation purposes can be performed using just one CPU instruction and can fit into a small instruction window that leverages superscalar CPU processing. Whether the data type is varchar or bigint the same function can compare the data by directly comparing the 64 bit integer value. However if involved values are conventional non normalized then comparison can be performed using slower conventional processing. The data normalization system assembles data into arrays called batches and processes batches using either small loops or merged loop iterations. This leverages abilities of superscalar CPUs and increases data processing performance. At the same time the system detects any small subset of data that has conventional representation or involves complex data processing like arithmetic error handling . The system performs this more complex data processing as a separate post processing step outside of the main processing loop. This processing step may be slower and may not fully leverage abilities of the superscalar CPU. However slow processing of a small subset of data will not affect overall performance significantly.

One example is a hash join. In a hash join whenever a join is performed on a normalized key value and a hash table bucket has the only one potential match the system can use a tight CPU instruction loop to perform the join. If one of these conditions is not met then the system does not perform more complex handling immediately as that might interfere with superscalar CPU optimizations. Rather the system identifies rows that do not meet fast processing conditions and processes that data later using a post processing step. Similarly during hash aggregation in a first pass the system computes results if all involved values have normalized representation. If at least one aggregation key or intermediate result is not in normalized representation or if the system identifies other problematic conditions such as a potential for arithmetic overflow in calculations then the system postpones row processing for a slower second processing step. However a majority of data is processed very quickly using the first processing step that is able to leverage the strengths of the superscalar CPU.

Common operations in data warehouse processing include operations such as copy column for example from user table into hash table compare column value for group by or join purposes hash column value compute sum of column values. These operations work much faster if performed over a single fixed size data type e.g. 64 bit integers . Most database systems support many scalar data types and each data type has its own implementation of comparison sum and copy operations. Sometimes these type specific implementations are complex e.g. adding 2 high precision numeric values may take 100 CPU instructions . Adding 64 bit integers takes just one CPU instruction on modern CPUs. The system treats all normalized values described herein as integers for copying sum and comparison purposes.

The extra bit check imposed by the implementation described is low overhead because a database system includes similar checks for NULL values already. In addition in most cases values will be represented as normalized so the extra bit check has a predictable outcome improving CPU pipeline utilization . Some functional processing of the data normalization system can avoid the bit check at runtime if all values processed in given a part of a query plan are known to be normalized.

As an example suppose a column data type is numeric 20 2 total 20 digits precision 2 digits after decimal point . The value 10.01 can be represented as 1001 normalized integer value. Value 999999999999999999.99 however cannot be represented using normalized form because it does not fit into a 64 bit integer and for those values the system can fall back to a slow code path to process those values. Fortunately such large values are very rare. If the system receives a request to add two numeric 20 2 columns then the type of the result is numeric 21 2 . The system can add two normalized values using one instruction or potentially slightly more to check for overflow and the result is still normalized. The system can also multiply integer values and the result will be still normalized without any need to perform division because type derivation adjusts the decimal point location to numeric 38 4 . Other types can be handled similarly such as strings described previously integers int financial values e.g. smallmoney dates e.g. datetime and certain ranges of floating point numbers e.g. float . Unlike previous in memory database techniques that normalize based on storage format the data normalization system normalizes based on type derivation i.e. making all types or many types fit within a common representation .

The data storage component stores database data persistently between sessions of use of the system . The data storage component may include one or more files file systems hard drives storage area networks SANs cloud based storage services or any other facility for persisting data. The system may be implemented within a previously existing database core such as Microsoft SQL Server or as an add on or new type of data processing facility.

The data normalization component retrieves data stored by the data storage component and loads the retrieved data into memory in a normalized data representation that allows fast superscalar processing. The normalized data representation includes a common format such as a fixed size value for storing multiple data types so that processing of normalized data can be handled in a unified manner for a variety of data types. The uniformity of data also increases potential parallelism when executing on massively parallel or superscalar CPUs. The data normalization component also provides an in memory representation of data that is not normalized by providing a normalized value that includes a pointer to a data structure for storing non normalized values. Although this may incur a slightly higher use of memory the system benefits from the unified processing of data of various types. The data normalization component may select an appropriate normalized representation for each data type based on a type of the data a number of values of the data that fall within a normalizable range a level of precision of the data a length of string data and so forth.

The operation manager manages requests to perform database operations on stored database data. For example the operation manager may include a query engine that receives queries from users or applications develops a query plan executes the query against an in memory or loaded data set and provides results back to the requestor. The operation manager invokes the other components of the system to perform queries and other operations in a manner that leverages available hardware such as superscalar CPUs efficiently.

The batch assembly component identifies batches of data that have control flow and data independence such that the batch includes multiple instances of parallelizable operations. For example the batch assembly component may scan an array of data values and identify whether the data values include a majority or other threshold of values represented in the normalized data representation described herein. The batch assembly component may also separate data into groups such that each group can minimize control flow interruptions e.g. branches or excessive conditional checking and perform multiple operations efficiently on a superscalar CPU or set of CPUs.

The outlier identification component identifies data values in a batch of data that cannot be performed by a fast processing path that performs efficient superscalar processing. The outlier identification component can be implemented in a variety of ways from managing a second pass through the batch of data after a first fast pass has completed to separating outlying data into a separate data structure such as a list of remaining data to be post processed. The outlier identification component may traverse an array of data and identify values in the array that are not represented in the normalized data representation. The component may place those values on a queue for post processing or flag the values in place for later processing. In some embodiments the outlier identification component and fast operation component are merged into a single component that performs a fast first pass and detects outlying data at the same time. In such cases the component sets the non normalized data aside for slower post processing.

The fast operation component provides instructions to a superscalar processor in a manner that allows parallel execution of the instructions by multiple functional units of the superscalar processor. For example the fast operation component may include functions for adding comparing or performing other operations on data in a tight loop or with multiple independent loop operations executable in each loop iteration or a combination of these . The fast operation component may include separate functions or a conditional branch within a function that take the fast processing path for data that is represented in the normalized data format. Because the majority of data types and values are represented in the normalized data format the system achieves faster execution of common database operations by using the fast operation component in a majority of operation processing.

The slow operation component performs database operations on data within a batch that is not stored in the normalized data representation. The slow operation component is less concerned with fast superscalar execution and performs the additional processing for handling data types that are not handled in a unified manner. For example the component may process data that is expected to include arithmetic overflow data that is large or of a nonstandard type and so forth. The slow operation component implements the type of processing of traditional database engines that did not leverage superscalar processing techniques like those described herein.

The result processing component gathers results from the fast operation component and slow operation component and returns the results to an operation requestor. The results processing component handles any merging of data from fast and slow paths and any cleanup or other management needed after execution of the fast or slow path. The component packages the results into an appropriate response format e.g. a query response or other format and sends the response to the requestor. Where iterators are used within the database engine fast and slow operation results may be merged many times in each iterator. The next iterator next operation receives uniform merged data and splits the data again if applicable into slow and fast processing and then merges results at the end so that data is ready to be consumed by users servers or a subsequent operation. The requestor may include servers applications or users interacting with the system over a network or from the same machine on which the system executes. The result processing component provides result responses using an application programming interface API or protocol through which the system received the request.

The computing device on which the data normalization system is implemented may include a central processing unit memory input devices e.g. keyboard and pointing devices output devices e.g. display devices and storage devices e.g. disk drives or other non volatile storage media . The memory and storage devices are computer readable storage media that may be encoded with computer executable instructions e.g. software that implement or enable the system. In addition the data structures and message structures may be stored or transmitted via a data transmission medium such as a signal on a communication link. Various communication links may be used such as the Internet a local area network a wide area network a point to point dial up connection a cell phone network and so on.

Embodiments of the system may be implemented in various operating environments that include personal computers server computers handheld or laptop devices multiprocessor systems microprocessor based systems programmable consumer electronics digital cameras network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and so on. The computer systems may be cell phones personal digital assistants smart phones personal computers programmable consumer electronics digital cameras and so on.

The system may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures and so on that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

Continuing in block the system determines a data type of the selected column. For example the stored data may include column metadata that identifies a type of the column data declared by a database designer e.g. bigint varchar 20 and so forth . The system identifies the column type and any other information that may affect whether the column s row data can be stored in the normalized format e.g. level of precision limits on data length and so forth . Continuing in decision block if the system can normalize the determined column data type then the system continues at block else the system continues at block . The system may store a list of types that the system can normalize or other criteria such as a length limit for particular types that can be normalized. In some embodiments the system may receive configuration information that determines whether the normalized format is used for storing data in memory including conditions for determining when the format is used. For example the system may only use the normalized format if more than half of a column s data values can be normalized.

Continuing in block the system converts row data associated with the selected column into a normalized data representation. For example the normalized data representation may include a fixed size numeric value into which the system stores multiple different native data types. For example the system may store floats dates integers Booleans and other data types as a 64 bit integer in memory. The normalized format allows the system to perform unified processing that is suited to superscalar processors on a variety of types of data.

If execution reaches block the system identifies a non normalized data structure for storing row data associated with the selected column. The system may store some rows as normalized and others as non normalized such as where some values fall outside of a range that the normalized format can contain. The non normalized structure may include a traditional data structure used before the normalized format was introduced or any other suitable data structure for describing the column row data value. Continuing in block the system stores a pointer to an instance of the identified non normalized data structure in a normalized data value. For example the system may set the normalized data value to the pointer value and set an unused bit of the pointer value to indicate that the normalized value points to another data structure. In this way when examining data values the system can initially treat each value similarly.

Continuing in decision block if the system determines that there are more columns in the accessed data then the system loops to block to select the next column else the system completes. Although shown serially the system can also be implemented to process all columns or multiple columns at the same time while making fewer passes through the rows of data. After block these steps conclude.

Continuing in block the system identifies zero or more non normalized rows of data associated with the batch of operations. The non normalized rows may involve additional processing that is less suitable for parallel execution. The system may flag the identified rows add them to a separate list or ignore them in a first pass and process the identified rows in a post processing step or second pass. Continuing in block the system submits the identified batch of operations that involve normalized rows of data to the superscalar processor for parallel processing. The superscalar processor recognizes data with few or no data and control flow dependencies and sends the data to separate execution units for parallel processing. For example where the data includes elements of an array the processor may perform an operation in parallel on multiple elements of the array at a time. In some embodiments the system performs the actions of blocks and at the same time to avoid reading the same data twice. Once data is read from memory into a CPU register it is a relatively cheap operation to perform the actual operation and the normalization check.

Continuing in block the system submits the identified batch of operations that involve identified non normalized rows of data for processing. The processing of the non normalized data may involve instructions that are less suitable for parallel processing such as one or more conditional checks for correct handling of complex data types. By handling these rows in a separate way the system allows those rows that can be processed quickly to benefit from the capabilities of the superscalar processor. Continuing in block the system reports results of performing the batch of operations to a requestor of the operations. For example the system may merge results from processing of the normalized data rows and the non normalized data rows and provide the results in a data structure back to a caller or next operation to be executed such as an application that requested a database query. After block these steps conclude.

The data normalization system described herein can process many types of data very fast leveraging superscalar processors. Many types of common data fit within the normalized data representation described herein e.g. zip codes two letter state codes license plate numbers and so forth . As one example consider a database that stores a person s purchases. If an operation totals all purchases made by a person in a month then the majority of the person s purchases e.g. groceries gas fit within the normalized data types. Only very big ticket items e.g. a car purchase might not fit in the normalized representation. For such an operation the system can use the fast processing path for all of the data but the big ticket items then follow up with a post processing step using a potentially slower path to apply the operation to the outlying data that is not normalized.

In some embodiments the data normalization system normalizes short strings by placing characters directly in the normalized data representation. For example where each character of a string uses a byte and the normalized data structure includes seven full bytes and almost an eighth byte one byte is used for indicating the normalized type then the system can potentially store eight characters of a string in the normalized data representation. For longer strings the system can include a pointer to the string or a pointer to another data structure that includes the string.

In some embodiments the data normalization system determines a size of the normalized data structure separately for each type of data so that smaller data types or ranges can be represented using less memory. For example if an integer column in a table only contains values that will fit within a single byte then the system may use a byte sized data structure for the normalized representation of data in that column so that less memory is allocated for storing the data of that column. For large numbers of rows of data the saved memory may add up to be substantial.

From the foregoing it will be appreciated that specific embodiments of the data normalization system have been described herein for purposes of illustration but that various modifications may be made without deviating from the spirit and scope of the invention. Accordingly the invention is not limited except as by the appended claims.

