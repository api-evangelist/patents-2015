---

title: Video system with fovea tracking and methods for use therewith
abstract: A viewer fovea tracking generator is configured to analyze image data corresponding to a viewing of the video program via an A/V player by at least one viewer, and to generate fovea tracking data corresponding to the at least one viewer. A network interface configured to transmit the fovea tracking data to the video source via a network. The video program is fovea encoded by the video source in accordance with the fovea tracking data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09530450&OS=09530450&RS=09530450
owner: VIXS SYSTEMS, INC.
number: 09530450
owner_city: Toronto
owner_country: CA
publication_date: 20150424
---
The present U.S. Utility Patent Application claims priority pursuant to 35 U.S.C. 120 as a continuation in part of U.S. Utility application Ser. No. 14 590 303 entitled AUDIO VIDEO SYSTEM WITH INTEREST BASED AD SELECTION AND METHODS FOR USE THEREWITH filed Jan. 6 2015 which is a continuation in part of U.S. Utility application Ser. No. 14 217 867 entitled AUDIO VIDEO SYSTEM WITH USER ANALYSIS AND METHODS FOR USE THEREWITH filed Mar. 18 2014 and claims priority pursuant to 35 U.S.C. 120 as a continuation in part of U.S. Utility application Ser. No. 14 477 064 entitled VIDEO SYSTEM FOR EMBEDDING EXCITEMENT DATA AND METHODS FOR USE THEREWITH filed Sep. 4 2014 all of which are hereby incorporated herein by reference in their entirety and made part of the present U.S. Utility Patent Application for all purposes.

The present disclosure relates to audio video systems that process and present audio and or display video signals.

Modern users have many options to view audio video programming. Home media systems can include a television a home theater audio system a set top box and digital audio and or A V player. The user typically is provided one or more remote control devices that respond to direct user interactions such as buttons keys or a touch screen to control the functions and features of the device. Audio video content is also available via a personal computer smartphone or other device. Such devices are typically controlled via a buttons keys a mouse or other pointing device or a touch screen.

Video encoding has become an important issue for modern video processing devices. Robust encoding algorithms allow video signals to be transmitted with reduced bandwidth and stored in less memory. However the accuracy of these encoding methods face the scrutiny of users that are becoming accustomed to greater resolution and higher picture quality. Standards have been promulgated for many encoding methods including the H.264 standard that is also referred to as MPEG 4 part 10 or Advanced Video Coding AVC . While this standard sets forth many powerful techniques further improvements are possible to improve the performance and speed of implementation of such methods. Further encoding algorithms have been developed primarily to address particular issues associated with broadcast video and video program distribution.

The devices and each represent examples of electronic devices that incorporate one or more elements of a system that includes features or functions of the present disclosure. While these particular devices are illustrated system includes any device or combination of devices that is capable of performing one or more of the functions and features described in conjunction with and the appended claims.

The received signal is received from a video source such as a streaming video server a video on demand server or other video source. The received signal can be a compressed video signal such as a unicast video signal streaming video signal or other video signal that has been transmitted over a wireless medium either directly or through one or more satellites or other relay stations or through a cable network optical network or other transmission network without or without an accompanying audio signal. In addition received signal can be generated from a stored video file played back from a recording medium such as a magnetic tape magnetic disk or optical disk and can include a streaming video signal or other unicast signal that is transmitted over a public or private network such as a local area network wide area network metropolitan area network or the Internet.

Received signal can include a compressed digital video signal complying with a digital video codec standard such as H.264 MPEG 4 Part 10 Advanced Video Coding AVC VC 1 H.265 or another digital format such as a Motion Picture Experts Group MPEG format such as MPEG1 MPEG2 or MPEG4 QuickTime format Real Media format Windows Media Video WMV or Audio Video Interleave AVI etc. When the received signal includes a compressed digital video signal a decoding module or other video codec decompresses the audio video signal to produce a decoded audio video signal suitable for display by a video display device of audio video player that creates an optical image stream either directly or indirectly such as by projection.

When the received signal includes a compressed digital audio signal the decoding module can decompress the audio video signal and otherwise process the audio video signal to produce a decoded audio signal suitable for presentation by an audio player included in audio video player . The decoded audio video signal can include a high definition media interface HDMI signal digital video interface DVI signal a composite video signal a component video signal an S video signal and or one or more analog or digital audio signals.

When A V signal is received and the decoded video signal is produced in a digital video format the digital video signal may be optionally scrambled or encrypted may include corresponding audio and may be formatted for transport via one or more container formats. Examples of such container formats are encrypted Internet Protocol IP packets such as used in IP TV Digital Transmission Content Protection DTCP etc. In this case the payload of IP packets contain several transport stream TS packets and the entire payload of the IP packet is encrypted. Other examples of container formats include encrypted TS streams used in Satellite Cable Broadcast etc. In these cases the payload of TS packets contain packetized elementary stream PES packets. Further digital video discs DVDs and Blu Ray Discs BDs utilize PES streams where the payload of each PES packet is encrypted. When the received signal is scrambled or encrypted the decoding module further operates to descramble and or decrypt the received signal to produce the decoded audio video signal .

The viewer fovea tracking generator is configured to analyze image data generated by one or more viewer sensors corresponding to a viewing of the video program via the A V player by at least one viewer. For example a viewer sensor generates image data in a presentation area of the A V player . The viewer sensor can include a digital camera such as a still or video camera that is either a stand alone device or is incorporated in any one of the devices or or other device that generates the image data . In addition or in the alternative the viewer sensor can include an infrared sensor thermal imager background temperature sensor or other thermal imaging sensor an ultrasonic imaging sensor or other sonar based sensor and or other sensors for generating image data that can be used by the viewer fovea tracking generator for determining the presence of viewers for optionally identifying particular viewers and or for determining the portions of the display screen that the one or more viewers are currently watching. In addition or in the alternative image data can be generated by cameras associated with one or more portable devices associated with the viewer s .

Consider an example where a family is watching TV. One or more video cameras are stand alone devices or are built into the TV a set top Blu Ray player or portable devices associated with the viewers. The camera or cameras capture video of the presentation environment and viewers. The viewer fovea tracking generator processes the video and detects if there are viewers present how many viewers are present the identities of each of the viewers and further to determine the focus of interest by each of the viewers to generate fovea tracking data corresponding to the viewer s .

In an embodiment the viewer fovea tracking generator tracks that viewers eyes and or head to determine the region of the screen that is being watched by the viewer an area of viewer focus of the viewer of viewers. As used herein the area of viewer focus is a prediction of estimation of the region of the display screen corresponding to the viewer s visual fovea i.e. the portion of the display that is subject to viewer s central vision as opposed to the viewer s peripheral vision. The fovea tracking data is generated to indicate the region of viewer focus in the video program corresponding to the viewer s . The network interface configured to transmit the fovea tracking data to the video source via a network. The video program is fovea encoded at the video source in accordance with the fovea tracking data for transmission as received signal . In particular the video program can be fovea encoded in accordance with the fovea tracking data to greater accuracy within the region of viewer focus compared with an encoding accuracy outside the region of viewer focus. In this fashion the received signal includes a video stream that is encoded to provide maximum resolution color depth and encoding accuracy for the region or regions of viewer focus of any and all of the viewers. As the viewers change what they are looking at on the screen the region or regions of accurate encoding can move around.

The operation of system can be further described in conjunction with the following examples that include several optional functions and features. A viewers eyes and or head movements can be tracked and used to determine if there is a stable fovea on the screen based on the analysis of eye or head movements over time. If it is determined that the viewer or viewers central vision is consistently or predominately focused on a particular region of display device then fovea tracking data can be generated to indicate this stable region and indicating that a fovea encoding mode can be enabled.

In a further example a user of the A V player can interact with the a user interface of the A V player to enter this fovea encoding mode in order to save on network charges to reduce the cost of a streaming or video on demand selection and or to increase the quality of experience of the video by enhancing the resolution of one or more regions of interest in the video program while adapting to available transmission bandwidth. The user can opt into this mode via interaction with the user interface associated with A V player and generation of A V control data that indicates this fovea tracking encoding mode of operation.

The decoding module A V player and the viewer fovea tracking generator can each be implemented using a single processing device or a plurality of processing devices. Such a processing device may be a microprocessor co processors a micro controller digital signal processor microcomputer central processing unit field programmable gate array programmable logic device state machine logic circuitry analog circuitry digital circuitry and or any device that manipulates signals analog and or digital based on operational instructions that are stored in a memory. These memories may each be a single memory device or a plurality of memory devices. Such a memory device can include a hard disk drive or other disk drive read only memory random access memory volatile memory non volatile memory static memory dynamic memory flash memory cache memory and or any device that stores digital information. Note that when decoding module A V player and the viewer fovea tracking generator implement one or more of their functions via a state machine analog circuitry digital circuitry and or logic circuitry the memory storing the corresponding operational instructions may be embedded within or external to the circuitry comprising the state machine analog circuitry digital circuitry and or logic circuitry.

While system is shown as an integrated system it should be noted that the system can be implemented as a single device or as a plurality of individual components that communicate with one another wirelessly and or via one or more wired connections. As described in conjunction with system can be implemented entirely via a mobile communication device such as a laptop tablet or smartphone with a back facing camera. Downstream bandwidth can be saved by using full resolution on only on part of the screen. In this fashion a user on the go can enjoy a video program on a smaller screen that a traditional television or home theatre environment while reducing program cost using less bandwidth and or otherwise achieving greater resolution in regions of visual interest.

The further operation of system including illustrative examples and several optional functions and features is described in greater detail in conjunction with that follow.

In an embodiment the video encoding module monitors transmission bandwidth data that indicates a transmission bandwidth. The video encoding module generates a fovea encoded video signal in accordance with the fovea tracking data to a first accuracy within the region s of viewer focus and to a second encoding accuracy outside the region s of viewer focus such that the ratio between the first encoding accuracy and the second encoding accuracy is adjusted according to the transmission bandwidth. In this fashion the compression difference between the fovea and peripheral regions can be adapted dependent on available bandwidth. In off hours there can be only a slight difference between encoding accuracy in these two regions. As available transmission bandwidth decreases encoding of the peripheral regions can be sacrificed to generate a higher ratio of compression difference between the fovea and peripheral regions.

Consider an example where a family of viewers are viewing a video program. In this case the fovea tracking data can indicate one or more different regions of viewer focus in the video program for the plurality of viewers. Mom and Dad may be watching the hero but their son may have his attention focused on a female character in the same scene that he feels is particularly good looking. In an embodiment the video encoding module generates the fovea encoded video signal in accordance with the fovea tracking data to greater encoding accuracy within each of these two regions of viewer focus compared with an encoding accuracy outside the regions of viewer focus.

In the alternative the video encoding module may only support encoding for a single region of viewer focus. When multiple viewers are present fovea encoding can be supported if the viewers have the same or similar regions of viewer focus. In particular a single common region of viewer focus can be determined based on the union of the regions of viewer focus for all viewers. In another example a single common region of viewer focus can be determined based on a single region of viewer focus that best approximates the region of viewer focus for all viewers. In this embodiment the video encoding module can compare different regions of viewer focus for different viewers to determine an area of intersection and the single common area of viewer focus can be centered on the centroid of the area of intersection. The fovea encoded video signal can be generated in accordance with the fovea tracking data to disable fovea encoding when an area of intersection between the regions of viewer focus is smaller than a predetermined threshold meaning that there may not be a large enough area of common viewer focus to warrant fovea encoding.

In addition to real time fovea encoding transcoding consider an HLS DASH implementation where segments of a video program are re encoded and stored as multiple fovea modes corresponding to a plurality of possible fovea positions. In this case the fovea encoded video signal is generated in accordance with the fovea tracking data to select a stored segment encoded with greater accuracy within the region of viewer focus compared with an encoding accuracy outside the region of viewer focus as the closest match to the fovea position of one of the prestored segments. Non fovea encoded segments of the video program can likewise be stored and selected in circumstances where the fovea tracking data indicates that fovea tracking is disabled or is otherwise not possible due to a lack of fovea stability or an impermissible lack of fovea consensus over a plurality of viewers. When the A V player player selects the next video segment it the video encoding module selects a segment to retrieve as a fovea encoded video signal to match the viewers current fovea profile.

In this example during a scene of a video program depicted in screen display the viewer fovea tracking generator tracks the eye and or head movements of the viewer to determine a region of viewer interest . The video source generates the received signal to enhance the encoding accuracy in region of viewer interest and to reduce the encoding accuracy regions of the video outside of the region . In the example shown the viewer s eyes are focusing on the face of Stephen Lang. The video source responds to this region of viewer focus to encode the region of Stephen Lang s face with greater accuracy than the remaining portions of the scene.

In an embodiment the viewer fovea tracking generator generates the fovea tracking data based on facial modelling recognition and tracking of the point of focus on the display device of the viewer s eyes. In an embodiment the viewer fovea tracking generator analyzes the video image to determine a number of users that are present the locations of the users the viewing angle for each of the users and a corresponding region of focus on the display device for each viewer. In the example shown a single viewer is present.

In one mode of operation the viewer fovea tracking generator analyzes video image together with a skin color model used to roughly partition face candidates. The viewer fovea tracking generator identifies and tracks candidate facial regions over a plurality of images such as a sequence of images of the image data and detects a face in the image based on the one or more of these images. For example viewer fovea tracking generator can operate via detection of colors in the image data. The viewer fovea tracking generator generates a color bias corrected image from the video image and a color transformed image from the color bias corrected image. The viewer fovea tracking generator then operates to detect colors in the color transformed image that correspond to skin tones. In particular viewer fovea tracking generator can operate using an elliptic skin model in the transformed space such as a CCsubspace of a transformed YCCspace. In particular a parametric ellipse corresponding to contours of constant Mahalanobis distance can be constructed under the assumption of Gaussian skin tone distribution to identify a facial region based on a two dimension projection in the CCsubspace. As exemplars the 853 571 pixels corresponding to skin patches from the Heinrich Hertz Institute image database can be used for this purpose however other exemplars can likewise be used in broader scope of the present disclosure.

In an embodiment the viewer fovea tracking generator tracks candidate facial regions over a sequence of images and detects a facial region based on an identification of facial motion and or facial features in the candidate facial region over the sequence of images. This technique is based on 3D human face model that looks like a mesh that is overlaid on the video image . For example face candidates can be validated for face detection based on the further recognition by viewer fovea tracking generator of facial features such as the shape size motion and relative position of face eyebrows eyes nose mouth cheekbones and jaw. Any of these facial features extracted from the image data can be used by viewer fovea tracking generator to detect each viewer that is present.

Further the viewer fovea tracking generator can employ temporal recognition to extract three dimensional features based on different facial perspectives included in the plurality of images to improve the accuracy of the detection and recognition of the face of each viewer. Using temporal information the problems of face detection including poor lighting partially covering size and posture sensitivity can be partly solved based on such facial tracking. Furthermore based on profile view from a range of viewing angles more accurate and 3D features such as contour of eye sockets nose and chin can be extracted. Based on the number facial regions that are detected the number of users present can be identified. In addition the viewer fovea tracking generator can identify the viewing angle of the users that are present and the region of viewer interest in the displayed video program based on the position of the detected faces in the field of view of the image data and their head and or eye orientations.

In this example a viewer sensor generates image data in a presentation area of the A V player . The A V player includes a flat screen television and speakers and . The viewer sensor can include a digital camera such as a still or video camera that is either a stand alone device or is incorporated in the flat screen television and that generates image data . The viewer fovea tracking generator analyzes the image data to detect and recognize the viewers and of the A V player and their particular viewing vectors and in three dimensions in order to derive the corresponding regions of viewer interest in the display by the flat screen television . The intersection of each viewing vector can be equated to the centroid of a region of viewer focus of fixed size e.g. a fixed percentage of the screen size and shape e.g. square rectangle or other shape .

In a further embodiment the viewer fovea tracking generator is configured to estimate the distance from each of the viewers and to the television . For example the viewer sensor can includes two or more imaging sensors and the viewer fovea tracking generator can triangulate the image results to determine the distance to each viewer. In another embodiment the sizes of the heads of the viewers can be compared to standard head sizes or profile data for each viewer in order to estimate the distance of each viewer to the television or other display screen. In operation the viewer fovea tracking generator can use the distance prediction to adjust the size of the region of viewer focus for each viewer. In particular as the distance to the viewer decreases the amount of the display screen in the central vision of the viewer also decreases. Similarly as the distance to the viewer increases the amount of the display screen in the central vision of the viewer also increases. In this fashion the viewer fovea tracking generator can use distance to determine a proper size of each estimated region of viewer focus to generate a more accurate estimate of each actual region of viewer focus.

In this example a father and son are viewing a video program. In this case the fovea tracking data can indicate two different regions of viewer focus and in the video program for these two viewers. Dad is watching the hero and focusing his attention on region of viewer focus but his son has his attention focused on a female character in region of viewer focus in the same scene that he feels is particularly good looking.

In an embodiment the video encoding module generates the fovea encoded video signal in accordance with the fovea tracking data to greater encoding accuracy within each of these two regions of viewer focus and compared with an encoding accuracy outside the regions of viewer focus. In the alternative the video encoding module can compare different regions of viewer focus and to determine an area of intersection in this case the null set. The fovea encoded video signal can be generated in accordance with the fovea tracking data to disable fovea encoding because the area of intersection between the regions of viewer focus is smaller than a predetermined threshold meaning that there is not a large enough area of common viewer focus to warrant fovea encoding.

Consider an example where a husband and wife are viewing a video program. In this case the fovea tracking data can indicate two different regions of viewer focus and in the video program for these two viewers. Mom and Dad are both watching the hero Stephen Lang. In an embodiment the video encoding module generates the fovea encoded video signal in accordance with the fovea tracking data to greater encoding accuracy within the union of these two regions of viewer focus compared with an encoding accuracy outside the union of these two regions of viewer focus. In the alternative the video encoding module can compare the two different regions of viewer focus and to determine an area of intersection. The fovea encoded video signal can be generated in accordance with the fovea tracking data to enable fovea encoding because the area of intersection between the regions of viewer focus and is greater than a predetermined threshold meaning that there is a large enough area of common viewer focus to warrant fovea encoding.

In an embodiment the fovea tracking data indicates a region of viewer focus in the video program corresponding to the at least one viewer and the video program is fovea encoded in accordance with the fovea tracking data to greater accuracy within the region of viewer focus compared with an encoding accuracy outside the region of viewer focus. The video source can monitor a transmission bandwidth and the video program can be fovea encoded in accordance with the fovea tracking data to a first accuracy within the region of viewer focus and to a second encoding accuracy outside the region of viewer focus such that the ratio between the first encoding accuracy and the second encoding accuracy is adjusted according to the transmission bandwidth.

In an embodiment the fovea tracking data indicates a region of viewer focus in the video program corresponding to the at least one viewer and the video program is fovea encoded in accordance with the fovea tracking data to select a stored segment encoded with greater accuracy within the region of viewer focus compared with an encoding accuracy outside the region of viewer focus. A plurality of viewers can be present and the fovea tracking data can indicate a region of viewer focus in the video program for each of the plurality of viewers. The video program can fovea encoded in accordance with the fovea tracking data to greater encoding accuracy within each of the regions of viewer focus compared with an encoding accuracy outside the regions of viewer focus. The video program can be fovea encoded in accordance with the fovea tracking data to disable fovea encoding when an area of intersection between the regions of viewer focus is smaller than a predetermined threshold. In addition the fovea tracking data can be generated based on a facial modelling of the at least one viewer.

As may also be used herein the term s configured to operably coupled to coupled to and or coupling includes direct coupling between items and or indirect coupling between items via an intervening item e.g. an item includes but is not limited to a component an element a circuit and or a module where for an example of indirect coupling the intervening item does not modify the information of a signal but may adjust its current level voltage level and or power level. As may further be used herein inferred coupling i.e. where one element is coupled to another element by inference includes direct and indirect coupling between two items in the same manner as coupled to . As may even further be used herein the term configured to operable to coupled to or operably coupled to indicates that an item includes one or more of power connections input s output s etc. to perform when activated one or more its corresponding functions and may further include inferred coupling to one or more other items. As may still further be used herein the term associated with includes direct and or indirect coupling of separate items and or one item being embedded within another item.

As may also be used herein the terms processing module processing circuit processor and or processing unit may be a single processing device or a plurality of processing devices. Such a processing device may be a microprocessor micro controller digital signal processor microcomputer central processing unit field programmable gate array programmable logic device state machine logic circuitry analog circuitry digital circuitry and or any device that manipulates signals analog and or digital based on hard coding of the circuitry and or operational instructions. The processing module module processing circuit and or processing unit may be or further include memory and or an integrated memory element which may be a single memory device a plurality of memory devices and or embedded circuitry of another processing module module processing circuit and or processing unit. Such a memory device may be a read only memory random access memory volatile memory non volatile memory static memory dynamic memory flash memory cache memory and or any device that stores digital information. Note that if the processing module module processing circuit and or processing unit includes more than one processing device the processing devices may be centrally located e.g. directly coupled together via a wired and or wireless bus structure or may be distributedly located e.g. cloud computing via indirect coupling via a local area network and or a wide area network . Further note that if the processing module module processing circuit and or processing unit implements one or more of its functions via a state machine analog circuitry digital circuitry and or logic circuitry the memory and or memory element storing the corresponding operational instructions may be embedded within or external to the circuitry comprising the state machine analog circuitry digital circuitry and or logic circuitry. Still further note that the memory element may store and the processing module module processing circuit and or processing unit executes hard coded and or operational instructions corresponding to at least some of the steps and or functions illustrated in one or more of the Figures. Such a memory device or memory element can be included in an article of manufacture.

One or more embodiments have been described above with the aid of method steps illustrating the performance of specified functions and relationships thereof. The boundaries and sequence of these functional building blocks and method steps have been arbitrarily defined herein for convenience of description. Alternate boundaries and sequences can be defined so long as the specified functions and relationships are appropriately performed. Any such alternate boundaries or sequences are thus within the scope and spirit of the claims. Further the boundaries of these functional building blocks have been arbitrarily defined for convenience of description. Alternate boundaries could be defined as long as the certain significant functions are appropriately performed. Similarly flow diagram blocks may also have been arbitrarily defined herein to illustrate certain significant functionality.

To the extent used the flow diagram block boundaries and sequence could have been defined otherwise and still perform the certain significant functionality. Such alternate definitions of both functional building blocks and flow diagram blocks and sequences are thus within the scope and spirit of the claims. One of average skill in the art will also recognize that the functional building blocks and other illustrative blocks modules and components herein can be implemented as illustrated or by discrete components application specific integrated circuits processors executing appropriate software and the like or any combination thereof.

In addition a flow diagram may include a start and or continue indication. The start and continue indications reflect that the steps presented can optionally be incorporated in or otherwise used in conjunction with other routines. In this context start indicates the beginning of the first step presented and may be preceded by other activities not specifically shown. Further the continue indication reflects that the steps presented may be performed multiple times and or may be succeeded by other by other activities not specifically shown. Further while a flow diagram indicates a particular ordering of steps other orderings are likewise possible provided that the principles of causality are maintained.

The one or more embodiments are used herein to illustrate one or more aspects one or more features one or more concepts and or one or more examples. A physical embodiment of an apparatus an article of manufacture a machine and or of a process may include one or more of the aspects features concepts examples etc. described with reference to one or more of the embodiments discussed herein. Further from figure to figure the embodiments may incorporate the same or similarly named functions steps modules etc. that may use the same or different reference numbers and as such the functions steps modules etc. may be the same or similar functions steps modules etc. or different ones.

Unless specifically stated to the contra signals to from and or between elements in a figure of any of the figures presented herein may be analog or digital continuous time or discrete time and single ended or differential. For instance if a signal path is shown as a single ended path it also represents a differential signal path. Similarly if a signal path is shown as a differential path it also represents a single ended signal path. While one or more particular architectures are described herein other architectures can likewise be implemented that use one or more data buses not expressly shown direct connectivity between elements and or indirect coupling between other elements as recognized by one of average skill in the art.

The term module is used in the description of one or more of the embodiments. A module implements one or more functions via a device such as a processor or other processing device or other hardware that may include or operate in association with a memory that stores operational instructions. A module may operate independently and or in conjunction with software and or firmware. As also used herein a module may contain one or more sub modules each of which may be one or more modules.

While particular combinations of various functions and features of the one or more embodiments have been expressly described herein other combinations of these features and functions are likewise possible. The present disclosure is not limited by the particular examples disclosed herein and expressly incorporates these other combinations.

