---

title: Computer vision as a service
abstract: A computer vision service includes technologies to, among other things, analyze computer vision or learning tasks requested by computer applications, select computer vision or learning algorithms to execute the requested tasks based on one or more performance capabilities of the computer vision or learning algorithms, perform the computer vision or learning tasks for the computer applications using the selected algorithms, and expose the results of performing the computer vision or learning tasks for use by the computer applications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09466013&OS=09466013&RS=09466013
owner: SRI INTERNATIONAL
number: 09466013
owner_city: Menlo Park
owner_country: US
publication_date: 20150909
---
This application is a continuation of U.S. patent application Ser. No. 14 212 237 filed Mar. 14 2014 which application claims the benefit of and priority to U.S. Provisional Patent Application Ser. No. 61 787 254 filed Mar. 15 2013 each of which are incorporated herein by this reference in their entirety.

This invention was made in part with government support under contract number FA8750 12 C 0103 awarded by the Air Force Research Laboratory. The United States Government has certain rights in this invention.

In computer vision mathematical techniques are used to detect the presence of and recognize various elements of the visual scenes that are depicted in digital images. Localized portions of an image known as features may be used to analyze and classify an image. Low level features such as interest points and edges may be computed from an image and used to detect for example people objects and landmarks that are depicted in the image. Machine learning algorithms are often used for image recognition.

Computer vision capabilities can be provided by self contained e.g. vertical or shrink wrapped software applications such as Goggles by GOOGLE Inc. Image Search by GOOGLE Inc. Bing Image Search by Microsoft Corp. and Kooaba s Image Recognition. Some computer vision applications utilize open source computer vision algorithm libraries such as OpenCV.

While the concepts of the present disclosure are susceptible to various modifications and alternative forms specific embodiments thereof are shown by way of example in the drawings and are described in detail below. It should be understood that there is no intent to limit the concepts of the present disclosure to the particular forms disclosed. On the contrary the intent is to cover all modifications equivalents and alternatives consistent with the present disclosure and the appended claims.

Existing computer vision tools and applications are not generally accessible to address a broad range of computer application needs and performance requirements. Visual processing of and visual learning from large repositories of digital content e.g. images video and associated metadata is increasingly needed. Unprecedented quantities of visual data are available online through Internet services such as YOUTUBE FACEBOOK news sites and blogs and the proliferation of such data is facilitated by mobile device cameras. This visual data can be a valuable tool for many different types of computer applications including for example entertainment travel education security and disaster recovery applications. However in order to expose the richness embedded in this visual data to computer applications at large many types of computer vision algorithms machine learning algorithms indexing algorithms big data handling algorithms and associated architectures need to be organized and optimized for various different computer vision and learning tasks. This task is large and complex and thus extremely difficult for the traditional self contained applications to handle.

Referring now to an embodiment of a vision and learning algorithm services platform is embodied in a computing system . The illustrative platform exposes the features and capabilities of a wide variety of computer vision machine learning and big data processing algorithms for use by many different types of computer applications at different levels of sophistication depending on the needs of the particular application . Embodiments of the platform can intelligently provide the needed vision and learning algorithm services to for example back end middleware and or customer oriented computer applications. The inventors have further described some embodiments of the illustrative platform in Sawhney Harpreet S. Tools for Democratizing Computer Vision and Performance Characterization of Detection Algorithms Enabling Parameter Selection Probabilistic and Content specific Reasoning Presented at the IEEE Conference on Computer Vision and Pattern Recognition CVPR 2013 Vision Industry Entrepreneurship Workshop dated Jun. 24 2013 and in Sawhney et. al. Image Content Based Algorithm Performance Characterization and Recommendation draft dated Feb. 7 2014 both of which are incorporated herein by reference.

As used herein user oriented application may refer to among other things any of these types of computer applications whether back end middleware and or customer oriented computer applications that has a need for computer vision machine learning big data processing or similar tasks but whose main focus or objective may be something other than performing computer vision machine learning or big data processing tasks. Such applications may include for example online travel and tourism services photo recommenders home furnishing recommenders data driven image and or video content recommenders e.g. for focused advertising text recognition applications e.g. for reading text in images and videos and or others. As used here application or computer application may refer to among other things any type of computer program or group of computer programs whether implemented in software hardware or a combination thereof and includes self contained vertical and or shrink wrapped software applications distributed and cloud based applications and or others. Portions of a computer application or application may be embodied as firmware as one or more components of an operating system a runtime library an application programming interface API as a self contained software application or as a component of another software application for example.

In operation the computer application interfaces with a person such as an end user or application developer e.g. by a user interface subsystem shown in described below of the computing system . From time to time the computer application receives or accesses user content which is stored electronically e.g. as digital files stored in a memory or a data storage device . The user content may include for example structured e.g. meta tags or unstructured e.g. natural language text audio e.g. sounds and or spoken dialog video and or images e.g. a single image or a group or sequence of images . The computer application may determine e.g. by executing computer logic to identify the user content or a characteristic thereof that a computer vision or learning task needs to be performed. If the computer application determines that a computer vision or learning task is to be performed the computer application formulates and submits the vision or learning task to the platform . As used herein a task may refer to among other things an activity such as a vision or learning operation to be performed by the computing system on specified content . As such a task can have parameters that relate to among other things the specific content to be processed by the computing system in performing the task . In some embodiments the task involves executing one or more vision or learning algorithms on the user content and returning a result of the algorithm execution to the requesting application . Alternatively or in addition the task may include a request to select an appropriate algorithm for use in processing particular content and or a request to determine an appropriate set of parameters to use with a particular algorithm in processing certain content . For example portions of the platform may function mainly as a developer s tool while other portions may operate as an online service directly accessible by applications in operation e.g. at load time or runtime .

Based on the task and or one or more parameters relating to the task which may be supplied to the platform by the application as part of the task or separately from the task the platform selects one or more of the vision and learning algorithms to perform the task . As described in more detail below the platform may access reference data in order to inform its algorithm selection process and or to perform the requested task . For instance the platform may utilize reference data to characterize and predict the capabilities of one or more of the algorithms in relation to the particular task . The platform executes or initiates the execution of the selected algorithm s to perform the task with the requisite algorithm parameters receives algorithm results e.g. the output of the execution of the selected algorithm and exposes platform output e.g. the algorithm results and or an application friendly version of the algorithm results for use by the computer application .

In turn the application may process the platform output according to the needs of the application and as a result present application output . For example if the task requested by the application is recognize all of the faces in all of these images the platform may select an algorithm based on parameters where the parameters may include the number of images to which the task relates the quality and or content of the images the processing power of the available computing resources e.g. mobile device or server and or the task type e.g. face object scene or activity recognition . The selected algorithm performs the task by for instance algorithmically extracting useful information from the images and comparing the useful information for each of the images to a portion of the reference data . The platform may supply the matching images or information relating to the matching images such as the name of each person recognized in each of the images or a computer storage location at which the matching images can be accessed to the application as platform output . The application may formulate the platform output for presentation to an end user of the application . For instance the application may place the recognized persons names on or adjacent to each image and display the image and recognized name on a display device of the computing system e.g. a display of the user interface subsystem shown in and described below or the application may invoke a text to speech processor to output the recognized persons names as machine generated speech audio. Alternatively or in addition the application may use the name information for a subsequent task such as to perform a background check or to query other information relating to the person. The manner in which the application ultimately utilizes the platform output can vary depending on the requirements or design of the particular application .

Embodiments of the platform ensure that the requested task is completed within the requisite accuracy quality efficiency and or other parameters that may be specified by the application as part of the task and or the parameters . As described in more detail below any application that has a need for vision or learning algorithm services can benefit from the use of the platform . In some implementations revenue may be generated in response to the use of the platform and or the underlying algorithms by various applications . For example vendors of different vision and learning algorithms may compete to have their algorithm selected by the platform or by applications and the selection of an algorithm may trigger a revenue event.

Referring now to an embodiment of the vision and learning algorithm services platform is shown in more detail in the context of an environment that may be created during the operation of the computing system e.g. an execution or runtime environment . The illustrative platform and portions thereof are embodied as a number of computer executable modules components and or data structures including application algorithm interfaces and vision and learning services . The interfaces can individually or collectively communicate with the application at an application level and can communicate with one or more of the services at an algorithm level where the application level is typically a higher level of abstraction than the algorithm level . Some embodiments of the platform may be implemented as an application programming interface API or as a collection of APIs which is made available to applications or application developers as an Internet based service e.g. a web service . The illustrative interfaces include an algorithm capabilities interface a task performance interface a computational performance interface and a database interface . The illustrative services include a hardware optimization service an algorithm organization service and a data organization service . The interfaces and services are described in more detail below.

The computer vision and learning algorithms can have tens or sometimes hundreds of internal parameters that control the flow and performance of the algorithms . Input and output data types for the algorithms are often complex and heterogeneous. Such complex interfaces burden the algorithm user by requiring knowledge of the meaning and appropriate use of the algorithm parameters . The illustrative interface layer functions as an intermediary between the applications and the services . The interfaces are designed to support the applications in terms of intelligently selecting one or more of the available algorithms that is capable of performing a particular task given the parameters based on for example the algorithms capabilities task performance computational performance and or applicable databases. The algorithm capabilities interface provides the applications with access to one or a combination of the algorithms the functional capabilities of each of the algorithms and or a means by which to control the algorithms via parameters that are meaningful in terms of real world characteristics where such parameters may be referred to herein as physical parameters or application parameters e.g. the parameters rather than algorithm centric parameters e.g. the algorithm parameters . As an example the use of Ground Sampling Distance may be considered a physical parameter application parameter while pixel resolution may be considered an algorithm parameter which corresponds to the Ground Sampling Distance application parameter . In some cases algorithm parameters may be used to calculate application parameters or vice versa.

The algorithm capabilities interface enables these application algorithm interactions through computerized abstractions that are designed to remain consistent or change minimally over the algorithm development cycles and across the algorithm implementations of different applications . To do this the capabilities interface utilizes APIs that have templated algorithms and abstract input and output data types. The APIs for the algorithms may be developed using for example polymorphism inheritance and template representations that allow a container type to hold multiple object types and enable algorithm implementations to be independent of the container and object type with a fixed API. Additionally as described in connection with an algorithms parameter mapping module automatically associates the real world data characteristics of the application parameters with the algorithm parameters so that the algorithms can be executed with the algorithm parameters to produce algorithm results for the requested task and parameters .

The published performance characteristics of many existing vision algorithms are limited in that they are the result of the algorithms having been run against certain specific public datasets. These datasets are often not tactically relevant for a wide variety of applications . Further existing performance evaluations rarely characterize the algorithms against fuzzy compressed and or low quality data which is common on the Internet and is likely to be a common type of content in many applications . The illustrative task performance interface exposes the performance characteristics of an algorithm in terms of the accuracy precision confidence uncertainty etc. of the algorithm results for a specific task and parameters . The platform can customize the performance characteristics for a particular type of algorithm . The algorithm type may be defined by the functionality performed by the algorithm such as object detection face detection scene detection activity detection event detection vehicle detection facial recognition etc. The algorithm type may alternatively or in addition refer to a level of abstraction associated with the algorithm e.g. pixel level feature level semantic level etc. . As an example the performance of object detection algorithms can be characterized by metrics such as the probability of detection the probability of false alarm and the receiver operating characteristic ROC curves resulting from the distribution of scores with respect to positive and negative instances . Similarly the performance of localization algorithms can be characterized by uni or multi modal distributions of their output parameters such as location and orientation of the camera. A computer vision algorithmic service as disclosed herein incorporates programming interfaces for these and all other types of algorithmic performance characterizations.

As described below with reference to embodiments of the task performance interface can provide performance estimates at multiple levels of performance characterization including 1 a projected performance characterization that quantifies the algorithm s performance against known datasets 2 a probe which rapidly analyzes input without running the full algorithm e.g. to determine the algorithm s suitability for a particular task and 3 a diagnostic characterization that characterizes the uncertainty of specific point solutions obtained by executing the algorithm . In this way the task performance interface can provide both coarse and fine performance measures on algorithms to among other things aid in dynamic workflow optimization. The interface may expose one or more of the estimates for use by the platform or the application . The computational performance interface exposes information about the time taken and computing resources needed e.g. hardware processors cloud clusters etc. to execute an algorithm . Such information may be obtained from for example the hardware optimization service described below. The database interface enables applications to access the indexed content that is applicable to a given task and parameters in a rapid and efficient manner Additional details of the interfaces are described below.

Referring now to the vision and learning algorithm services the algorithm organization service is embodied as a computerized framework e.g. as middleware for the layered representation of vision and learning algorithms . The illustrative framework of algorithm layers organizes the algorithms into a pixel level class of algorithms a feature level class of algorithms and a semantic level class of algorithms where the feature level algorithms are implemented at a higher level of abstraction than the pixel level algorithms and the semantic level algorithms are implemented at a higher level of abstraction than the feature level algorithms and the pixel level algorithms . For example the illustrative pixel level vision algorithms may produce enhanced versions of input images and may extract camera characteristics whereas the feature level algorithms may process images to combine feature aggregates and geometry for recognition and the semantic level algorithms may ingest feature and pixel data to produce decisions labels or tags and semantic output. Additional examples of the layered framework are shown in TABLE 1 below.

As shown in TABLE 1 each of the algorithm layers is further organized by algorithm type. As such the platform or the application can access any of the algorithms by its level of abstraction and or its type. Current open source libraries like OpenCV and VXL are organized around textbook level core image libraries and tend to be very project specific. Among other things the layered architecture can handle content diversity can abstract computations and data structures for algorithm families rather than per atomic module and can handle new versions of the algorithms without changing the interfaces .

The illustrative integration service integrates the algorithms into the layered architecture . The illustrative capability analysis evaluates the functional capabilities of new algorithms or new versions of algorithms and the illustrative evolving algorithms service maps the new or new versions of algorithms to an appropriate level in the layered architecture

The reference data may include a wide variety of different content including the user content which may be stored in databases files and or other electronic data stores which may be referred to herein simply as data or databases for ease of discussion . The reference data may include private or protected data and or public or unprotected data . Referring now to the database interface and the data organization service the illustrative database interface exposes information regarding the content databases of the reference data that are available what type of data each of the databases includes e.g. area sensors biometric data and the functional characteristics of each of the databases. Some other examples of reference data include 1 LIDAR light detection and ranging data aerial and ground level imagery with and without any associated metadata 2 polygonal and point cloud models of objects 3 biometric and object databases and 4 architectural botanical geological and meteorological databases. In general the reference data is stored in any suitable computer readable media such as the data storage device shown in and described below.

The illustrative data organization service is embodied as an extensible framework e.g. middleware for indexing algorithms to comprehensively and efficiently handle the diversity of databases and data stores of the reference data that may be applicable to different applications . To do this the data organization service creates the reference data by for example ingesting data from a large variety of databases and data stores e.g. Internet sources such as YOUTUBE FLICKR FACEBOOK etc. where the ingesting may be performed by the computing system as an automated e.g. background process or by interfacing with an end user for example. The data organization service automatically indexes this data and provides database access interfaces for the applications. For example the database indexing module of the data organization service may create a reference data index to index a collection of invariant two dimensional and or three dimensional features as having been demonstrated for accuracy and efficiency. The database access module may specify and or verify appropriate permissions and or access levels for the applications to access the reference data e.g. the private data . The reference data index automatically indexes visual data and metadata from structured semi structured and unstructured data stores. In this way the data organization service can expose a large number of heterogeneous databases and or data stores for use by the platform or the application .

Some embodiments of the database interface provide multiple types of abstracted APIs that allow unified access to different categories of indexed data such as i imagery data e.g. Electro Optic EO Multi Hyper spectral Imagery MSI HSI etc. ii three dimensional data e.g. Light Detection and Ranging LIDAR Digital Elevation Maps DEM iii attributes e.g. color class type scene type and iv features e.g. Histogram of Oriented Gradients HoG spin image iv object location scene action event and other such database entity for instance faces from a biometric imagery database locations from a geo organized imagery database and actions from an ingested and indexed action database from imagery. For each specific database the database interface exposes certain database information e.g. as a summary table that contains among other fields data type spatial coverage time interval if available and the number of elements in the database . Some embodiments of the database interface include an interface to an index of high dimensional visual and metadata features that enable rapid typically logarithmic sublinear access to the categories of data types described above. The summary table can be used e.g. by the platform or an application to quickly poll for types of data that are available within a given subject area in order to create a workflow that is suitable for a particular task . An example of a database interface is shown in TABLE 2 below.

In addition to high level information about the indexed data the database APIs allow applications or the platform to poll the database to retrieve stored data according to one or more criteria such as i spatial or volumetric e.g. return all the images or skylines within a region of interest ii attribute based e.g. return all the locations containing a desert scene iii feature similarity e.g. return all the skylines being similar to a query input iv temporal access. More complex queries can be formed by creating combinations of the different query types.

In some implementations the APIs for image data use templated image classes to handle different pixel data types e.g. color gray scale etc. . For three dimensional 3D data abstracted 3D point interfaces similar to the open source Point Cloud Library PCL from Willow Garage may be used. For accessing derived attributes and features the interface may be based on a templated class that comprises several fields such as feature identifier 2D 3D feature location origin identifier and or descriptor vector. More complex feature types can be constructed using e.g. inheritance and polymorphism mechanisms to allow APIs to remain fixed.

Referring now to the hardware optimization service the service maps and optimizes vision and learning algorithms for a variety of computing platforms which range from smartphones personal computers digital signal processors and floating point graphics accelerators to server cloud and multi core graphics processing unit GPU central processing unit CPU architectures. As such the service contains implementations of the algorithms that are optimized for the different hardware platforms e.g. GPU cores e.g. CUDA the Compute Unified Device Architecture multi threading CPU cores and parallel distributed cloud architectures.

Referring now to an embodiment of the algorithm capabilities interface is shown in more detail. The interface includes a number of application parameters APIs and performance parameters APIs . The APIs translate physical or user oriented parameters e.g. the parameters to algorithm centric parameters e.g. the algorithm parameters . Additionally the APIs can be used to automatically determine a set of optimal algorithm parameters for a particular task and parameters . The physical or user oriented parameters may be computed by the application or by the platform from the task e.g. a query string or may be specified by a user of the application e.g. an end user or a user of the platform e.g. an application developer . As used herein optimal may refer to among other things a combination of algorithm parameters that is algorithmically determined to have a high probability of performing the task according to the specified parameters accuracy criteria performance criteria and or other criteria.

The illustrative algorithm capabilities interface is embodied as one or more APIs that encode i the parameters e.g. physical input parameters for the task such as parameters with real world meaning rather than algorithm specific meaning e.g. Ground Sampling Distance GSD focal length and blur level and ii input and output parameters that specify a desired performance level for the algorithms executing the task or implementing the application . These APIs are abstracted and thus do not require the applications to provide algorithm parameters . For example an application may provide only query image properties and desired performance parameters and the platform can automatically select an algorithm determine the algorithm parameters and produce the platform output in response to those parameters without requiring any additional information from the application .

To do this the algorithms parameter mapping module translates the parameters e.g. physical input parameters and input output I O performance parameters into a set of I O APIs for interacting directly with the semantic feature and pixel level algorithms . This mapping process utilizes the task performance interface to map the parameters to algorithm performance parameters . In doing this the module identifies a set of input parameters that are mathematically determined to be likely to achieve a specific level of performance as determined through systematic testing and evaluation of the algorithm s output over time. As an illustration consider an interface for vehicle recognition. An application needs a vehicle recognition service e.g. the task may be a query such as find all vehicles in these images . The platform or the application uses a combination of algorithms to compute or otherwise determine the physical parameters of the task . The physical parameters can be provided by the application e.g. distance to an object or computed by a vision or learning algorithm based on one or more of the algorithm parameters . The platform or the application invokes the capabilities interface with these parameters . The algorithms parameters mapping module maps these parameters to a complete set of i semantic level parameters e.g. classifier type classifier parameters and ii feature level parameters e.g. feature type . The platform selects and executes a semantic level algorithm which produces results using the semantic level parameters and the platform passes the results to the application as platform output . Additionally the platform may select and execute a feature level algorithm which produces results using the feature level parameters and the platform passes the results to the application as platform output . Some illustrative examples of algorithm parameter mappings that may be performed by the algorithm capabilities interface are shown in TABLE 3 below.

Referring now to an embodiment of the task performance interface is shown in more detail. The illustrative task performance interface provides algorithm performance estimates that enable the platform or the application to obtain an optimal result in response to a task and parameters e.g. an answer to a query . To do this the platform constructs a workflow for accomplishing the task according to applicable task performance constraints e.g. the image quality and or computational constraints which may be supplied by the task performance interface . The interface determines performance estimates based on characteristics of the known datasets and the operating range of the parameters that are specific to the task e.g. an image query . Furthermore the interface enables the platform or the application to perform a quick triage of task or the associated content to assess the landscape of potential solutions for the task . As a result of the triage the platform or the application can select one or more algorithms for full execution that output confidences in the specific solution produced. In other words once an algorithm is picked and the solution is obtained the quality of the solution is characterized as performance characterization and provided to the platform or the application as needed.

Some embodiments of the task performance interface describe performance characteristics as functions of properties of the content e.g. image and scene properties such as ground sample distance GSD image blur and contrast that are associated with a task . To do this the content properties e.g. scene and image properties are extracted from the content e.g. query images . One or more of the extracted content properties are used to characterize the algorithm s performance and to recommend parameters for improved performance. To do this the algorithm s performance is learned over a data cluster that is based on the extracted image feature content and attributes. Based on the learning a set of parameters is recommended for performing the algorithm on a new image e.g. an image that is not already represented in the cluster based on the parameters performance in the cluster. Local image features are computed for the image to capture the image content and then all of the images in a dataset of images are clustered using the feature similarity. A ratings matrix may be computed to estimate the algorithm s performance over the clusters for each combination of parameters where a combination of parameters may be referred to as an operating point . In this way a new image can be related to a cluster having a similar feature distribution and the predicted best operating point of the matching cluster can be used as the algorithm parameters . To perform the clustering the images in the dataset are clustered according to similar content and attributes using for example a k means clustering algorithm.

As shown in the illustrative task performance interface gives the platform or the application multiple ways to estimate the performance of an algorithm and thereby helps the platform or an application in selecting candidate algorithms for the task . A projected performance measure gives a global estimate in response to parameters and the algorithm type which may be determined by the capabilities interface as described above where the parameters may include the application parameters the algorithm parameters or a combination of the parameters and the algorithm type may be determined according to the algorithm layers framework . The projected measure does not use any inputs from the given content e.g. a query image . As such the projected measure quantifies performance against known datasets and the resulting estimate is not particular to the content .

A probe performance measure uses the actual content e.g. an image to predict uncertainty relating to the algorithm s performance of the task using coarse feature computations . The probe measure can rapidly assess the space of possible solutions e.g. a set of candidate algorithms . A diagnostic performance measure assesses the final results of executing the algorithm selected based on the algorithm type on the content e.g. an image to perform the task using the parameters . In this way the task performance interface enables multiple level data driven performance characterization of algorithms for a specific task submitted by an application . As a result applications or the platform can obtain both coarse and fine performance measures to dynamically optimize their processing pipelines by evaluating multiple algorithms e.g. a set of candidate algorithms .

As an example for a given skyline matching algorithm the projected measure provides the ranges of achievable location uncertainty with respect to parameters computed from images in the existing datasets. The projected measures are pre computed for the respective algorithms as part of training and testing stages of the algorithms . For a task involving a where query given skyline and building outlines without performing detailed matching the probe measure informs the platform or the application as to whether the achievable geo location uncertainty is e.g. 10000 sq. kms or 100 sq. kms. The probe measure produces estimates using global properties of the content e.g. a query image such as scene type e.g. desert shoreline rural resolution contrast blur and also coarse level properties of features related to the specific task or the particular application . For example the jaggedness of a skyline is a good indication of how well a skyline based where algorithm is likely to work. Similarly the number of distinctive corners available in an urban image will determine the expected uncertainties in its location. The probe measure mimics human like abilities by training the system to make high level estimates from global and application specific features of the task e.g. query .

An embodiment of the probe measure can be implemented in multiple stages including i an offline technique for learning the mapping between the image properties and the estimates obtained by running the respective algorithms on labeled examples and ii an incremental technique that can refine its mapping by adding a new image its properties and its results. The probe measure can dynamically update its predictions by incorporating the results for images previously analyzed by the platform or by an application . Given the learned mapping the probe module computes the global and application specific features of a test image and applies the mapping to generate estimates of the expected accuracy and confidence.

The estimates produced by the diagnostic measure are computed from the complete configuration of matching features in module and determined by combining their confidences and accuracies into summary estimates in module . The diagnostic measure analyzes the results of component algorithms to estimate a confidence and accuracy for the whole task . This analysis is different for each task or for each application . For example when a semantic fingerprint is used to answer a where task e.g. query with respect to an image the diagnostic prediction method combines the confidences and accuracies associated with each semantic feature detected in the image such as a building road and mountain and forms a confidence and accuracy for the whole image . When a face detection algorithm is used for example to answer a who task e.g. query the diagnostic measure reports the expected recall precision and confidence of the selected algorithm for the database used. TABLE 4 below summarizes typical inputs used and output interfaces for the task performance measures .

Referring back to an embodiment of the computational performance interface provides estimates of the computational resources required by each algorithm to help construct a pipeline to meet the resource constraints specified by the application or the application developer . For instance the interface can provide estimates of the computational requirements for the algorithms when they are executed on different processing configurations such as cloud computers with GPUs or enable profiling techniques to recognize when two or more algorithms perform the same computations so that an analysis can be performed once and shared in order to save time or for other reasons.

Traditionally computational complexity is characterized in terms of algorithmic complexity. While useful this characterization is not sufficient for the platform or the application to make an informed decision about resource allocation because it does not lead to an accurate estimate of processing time in a cloud architecture which has diverse computational resources including different types of CPUs and GPUs. The computational performance interface provides a variety of computation specific information for each algorithm as shown by the example in TABLE 5 below.

The illustrative interface lists the processing e.g. CPU GPU and memory requirements to execute an algorithm at different levels. For example a projected level may characterize the algorithm s processing time with respect to known datasets and a diagnostic level may characterize the computational resources used by the executed algorithm. In some embodiments components of the interface are implemented using a framework for managing processing flows such as a Hadoop UIMA based infrastructure or any of the standard cloud based distributed parallel processing infrastructures. The interface can use the UIMA Unstructured Information Management Architecture to define processing pipelines for an algorithm each of which may involve multiple types of computing resources e.g. hardware . The interface can use Hadoop to replicate these function blocks and to distribute data to them. With this framework when it is time to execute an algorithm the platform or the application can specify resources and or a processing graph using XML Extensible Markup Language based configurations. The interface can for example choose among multiple processing options replicate function blocks and distribute computation across the cloud at runtime.

As an example consider a feature extraction algorithm that uses the Harris corner detector and Histogram of Oriented Gradients HoG feature descriptor. Through the interface the platform can determine that the algorithm can be executed using single core CPU multi core CPU or GPU hardware and can analyze the time taken for each. Since both Harris corners and HoG compute first order gradients this computation only needs to be done once for the feature extraction algorithm. The benefit of this optimization compared to independently using Harris detectors and HoG descriptors is exposed through the computational performance interface .

Referring now to an illustrative method by which the computing system may perform vision or learning algorithm services for an application on content is shown. The method may be embodied as computerized programs routines logic and or instructions executed by the computing system for example by the platform . At block the system receives a computer vision or machine learning task from a requesting application . To do this the requesting application may submit the task using one or more of the application algorithm interfaces e.g. the capabilities interface or may use one or more of the APIs depending on the needs and or level of sophistication of the application . At block the computing system determines whether the task requires the use of one of the algorithms . If the requested task does not require the use of an algorithm as may be the case if for example the task cannot be handled by any of the available algorithms the system returns to block and monitors for another task which may be received from the same application or a different application depending on the design or implementation of the platform . If the task requires the use of an algorithm the system determines the application parameters for the requested task at block . To do this the system may for example extract the parameters from a query string of the requested task . At block the system identifies one or more candidate algorithms to perform the requested task based on the application parameters determined at block where the candidate algorithms comprise a subset of the library of algorithms . To do this the computing system may analyze the parameters to determine an appropriate level of algorithm abstraction using the algorithm organization service . In some embodiments the system may simply return a list of the candidate algorithms depending on the needs of the requesting application . In other embodiments the system proceeds to intelligently analyze the capabilities of the candidate algorithms vis a vis the requested task as described below.

The algorithm and performance capabilities of the candidate algorithms identified at block are evaluated for the requested task at block . To do this the computing system may utilize the capabilities interface at block the task performance interface at block the computational performance interface at block and or one or more of the services as described above. At block the computing system compares the results of the evaluating of the algorithm and performance capabilities of the candidate algorithms and selects one or more of the algorithms to perform e.g. fully execute the task on the content . In some embodiments the system may simply return the selected algorithm s or a list of the selected algorithm s depending on the needs of the requesting application . In other embodiments the system proceeds to intelligently determine a set of parameters for the selected algorithm s in view of the requested task as described below.

At block the system determines the optimal algorithm parameters to execute the algorithm s selected at block on the particular content that is the subject of the task . For example the system may perform content based performance characterization wherein attributes of the content may be extracted and clustered with a dataset of previously analyzed content to identify the algorithm parameters . In some embodiments the system may simply return the algorithm parameters depending on the needs of the requesting application . In other embodiments the system proceeds to execute the selected algorithm s using the parameters as described below.

At block the system executes the task using the selected algorithms and the algorithm parameters determined at block and obtains the algorithm results . To do this the system may initiate the executing of the algorithms through an API such as one or more of the APIs . At block the system communicates the results of performing the task with the selected algorithms as output to the requesting application . To do this the system may expose the results as output through one or more of the interfaces or through one or more of the APIs for use by the application . As used herein expose may refer to the action of making information or computer functionality available for use by other applications by some computerized mechanism e.g. through an API or through a message communication mechanism .

Among other things the platform can be used to combine existing vision and or learning techniques in new ways to adapt to evolving algorithmic and software needs. For example the platform can combine shadow detection object recognition and an ephemeris module to create a technique for estimating the time at which a picture was taken by using detected objects as sundials. The platform also has a number of military intelligence and commercial applications.

Alternatively or in addition the platform can be used to provide performance characteristics of algorithms for ranges of operating parameters that cover image quality scene complexity and clutter and object and scene oriented parameters. Accordingly the platform can help developers and practitioners to create objective assessments of algorithms and operating ranges for the algorithms to be used in real time by mainstream applications.

Referring now to a simplified block diagram of an embodiment of the computing system is shown. While the illustrative computing system is shown as involving multiple components and devices it should be understood that in some embodiments the computing system may constitute a single computing device alone or in combination with other devices. The computing system includes a user computing device which may be in communication with one or more other computing systems or devices via one or more networks . The vision and learning services platform or portions thereof may be distributed across multiple computing that are connected to the network s as shown. In other embodiments however the platform may be located entirely on the computing device . In some embodiments portions of the platform may be incorporated into other systems or computer applications. Such applications or systems may include for example operating systems middleware or framework software and or applications software. For example portions of the platform may be incorporated into or accessed by search engines or intelligent assistance applications.

The illustrative computing device includes at least one processor e.g. a microprocessor microcontroller digital signal processor etc. memory and an input output I O subsystem . The computing device may be embodied as any type of computing device capable of performing the functions described herein such as a personal computer e.g. desktop laptop tablet smart phone body mounted device etc. a server an enterprise computer system a network of computers a combination of computers and other electronic devices or other electronic devices. Although not specifically shown it should be understood that the I O subsystem typically includes among other things an I O controller a memory controller and one or more I O ports. The processor and the I O subsystem are communicatively coupled to the memory . The memory may be embodied as any type of suitable computer memory device e.g. volatile memory such as various forms of random access memory .

The I O subsystem is communicatively coupled to a number of hardware components and or other computing systems including the computer application s the platform and the user interface subsystem which includes one or more user input devices e.g. a touchscreen keyboard virtual keypad microphone etc. and one or more output devices e.g. speakers displays LEDs etc. . The I O subsystem is also communicatively coupled to one or more storage media one or more one or more video and or still image capture devices e.g. cameras and a communication subsystem . It should be understood that each of the foregoing components and or systems may be integrated with the computing device or may be a separate component or system that is in communication with the I O subsystem e.g. over a network or a serial bus connection .

The storage media may include one or more hard drives or other suitable data storage devices e.g. flash memory memory cards memory sticks and or others . In some embodiments portions of the application s the platform the user content the application output the task the platform output and or other data reside at least temporarily in the storage media . Portions of the application s the platform the user content the application output the task the platform output and or other data may be copied to the memory during operation of the computing device for faster processing or other reasons.

The communication subsystem may communicatively couple the computing device to one or more communication networks e.g. a local area network wide area network personal cloud enterprise cloud public cloud and or the Internet for example. Accordingly the network interfaces may include one or more wired or wireless network interface software firmware or hardware for example as may be needed pursuant to the specifications and or design of the particular computing system .

The server computing device s may be embodied as any suitable type of computing device capable of performing the functions described herein such as any of the aforementioned types of devices or other electronic devices. For example in some embodiments the server computing device s may include one or more server computers including storage media which may be used to store portions of the vision and learning algorithms the reference data the application s the platform the user content the application output the task the platform output and or other data. The illustrative server computing device also includes a user interface subsystem and a communication subsystem which may be embodied similarly to the components respectively described above. The computing system may include other components sub components and devices not illustrated in for clarity of the description. In general the components of the computing system are communicatively coupled as shown in by signal paths which may be embodied as any type of wired or wireless signal paths capable of facilitating communication between the respective devices and components.

Illustrative examples of the technologies disclosed herein are provided below. An embodiment of the technologies may include any one or more and any combination of the examples described below.

In an Example 1 a platform for providing computer vision algorithm services is embodied in one or more machine accessible storage media and includes an application algorithm interface to receive a computer vision task from a computer application the computer vision task to be performed on one or more digital images accessed by the computer application determine one or more parameters relating to the performing of the computer vision task on the one or more digital images select one or more computer vision algorithms from a library of computer vision algorithms based on capabilities of the computer vision algorithms that have a high level of performance in comparison to the capabilities of the other computer vision algorithms in the library of computer vision algorithms to perform the computer vision task on the one or more digital images with the one or more parameters and expose for use by the computer application output of the selected computer vision algorithm performing the computer vision task on the one or more digital images using the one or more parameters.

An Example 2 includes the platform of Example 1 wherein the platform is to execute one or more algorithm performance characterization techniques to determine the one or more parameters relating to the performing of the computer vision task. An Example 3 includes the platform of Example 2 wherein the platform is to map one or more application parameters supplied by the computer application to one or more algorithm parameters of the selected computer vision algorithms based on the executing of the one or more algorithm performance characterization techniques. An Example 4 includes the platform of any of Examples 1 3 wherein the platform is to determine a content characteristic or an application defined parameter of the one or more digital images wherein the application defined parameter is defined by the computer application and select the computer vision algorithm based on the content characteristic or the application defined parameter of the one or more digital images. An Example 5 includes the platform of Example 4 wherein the platform is to analyze the performance of the selected computer vision algorithm on the computer vision task based on the content characteristic or the application defined parameter of the one or more digital images and determine a set of algorithm parameters for the selected computer vision algorithm based on analyzing the performance of the selected computer vision algorithm. An Example 6 includes the platform of any of Examples 1 5 wherein the platform is to organize the library of computer vision algorithms according to a plurality of different levels of abstraction and determine a level of abstraction at which to select the computer vision algorithm based on a characteristic of the computer vision task or a characteristic of the computer application. An Example 7 includes the platform of any of Examples 1 6 wherein the platform is to select a combination of different computer vision algorithms to perform the computer vision task execute the combination of different computer vision algorithms on the one or more digital images using the parameter and expose for use by the computer application output of the combination of computer vision algorithms executing the computer vision task. An Example 8 includes the platform of any of Examples 1 7 wherein the platform is to determine a hardware computing resource available to perform the computer vision task estimate the computational performance of the selected computer vision algorithm on the hardware computing resource and determine an algorithm parameter for use with the selected computer vision algorithm based on the computational performance of the selected computer vision algorithm on the computing resource. An Example 9 includes the platform of any of Examples 1 8 wherein the platform is to select a data store of a plurality of available data stores for use in performing the computer vision task wherein each of the data stores includes reference data usable to perform the computer vision task and the platform selects the selected data store based on a content characteristic or an application defined parameter of the one or more digital images wherein the application defined parameter is defined by the computer application. An Example 10 includes the platform of any of Examples 1 9 wherein the platform is to compute a plurality of different performance measures for the selected computer vision algorithm and determine an algorithm parameter for use with the selected computer vision algorithm based on the plurality of different performance measures. An Example 11 includes the platform of any of Examples 1 10 wherein the platform is to determine an algorithm type of the selected computer vision algorithm and customize the performance measures for the selected computer vision algorithm based on the algorithm type. An Example 12 includes the platform of any of Examples 1 11 wherein the platform is to predictively characterize the performance of the selected one or more computer vision algorithms without executing the algorithm. An Example 13 includes the platform of any of Example 12 wherein the platform is to predictively characterize the performance of the selected one or more computer vision algorithms based on one or more content characteristics of the one or more digital images and or one or more application defined parameters supplied by the computer application. An Example 14 includes the platform of any of Examples 1 13 wherein the platform is to characterize the performance of the selected one or more computer vision algorithms by executing the selected one or more computer vision algorithms on the one or more digital images and analyzing the output of the selected one or more computer vision algorithms.

In an Example 15 a platform for providing computer vision and learning algorithm services to user oriented computer applications includes embodied in one or more machine accessible storage media an application algorithm interface to determine application parameters to perform a computer vision or learning task on digital content the computer vision or learning task received from a computer application at least one of the application parameters indicating a characteristic of the digital content an algorithm capabilities interface to based on the application parameters identify candidate computer vision or learning algorithms to perform the computer vision or learning task on the digital content based on the application parameters and a performance interface to evaluate a capability of each of the candidate computer vision or learning algorithms to perform the computer vision or learning task on the digital content the performance capability determined at least in part by the characteristic of the digital content. An Example 16 includes the platform of Example 15 wherein the platform is to select a computer vision or learning algorithm of the candidate computer vision or learning algorithms based on the evaluating of the capability of the selected computer vision or learning algorithm to perform the computer vision or learning task on the digital content. An Example 17 includes the platform of Example 16 including an algorithms parameter mapping module to map the application parameters to one or more algorithm parameters to use with the selected computer vision or learning algorithm to perform the computer vision or learning task on the digital content. An Example 18 includes the platform of Example 17 wherein the platform is to perform the computer vision or learning task on the digital content by executing the selected computer vision or learning algorithm using the one or more algorithm parameters. An Example 19 includes the platform of Example 18 wherein the platform is to communicate a result of executing the selected computer vision or learning algorithm to the computer application. An Example 20 includes the platform of any of Examples 15 19 including an algorithm organization framework to organize the candidate computer vision or learning algorithms according to a plurality of different levels of abstraction and wherein the platform is to select a level of abstraction based on the computer vision or learning task. An Example 21 includes the platform of any of Examples 15 20 including a computational performance interface to determine a hardware computing resource available to perform the computer vision or learning task and estimate the computational performance of each of the candidate computer vision or learning algorithms on the hardware computing resource. An Example 22 includes the platform of any of Examples 15 21 including a task performance interface to compute a plurality of different performance measures for each of the candidate computer vision or learning algorithms and select the computer vision or learning algorithm based on the plurality of different performance measures. An Example 23 includes the platform of any of Examples 15 22 including a data organization service to index a plurality of reference data for use by the platform in executing the computer vision or learning algorithms. An Example 24 includes the platform of any of Examples 15 23 including a plurality of application programming interfaces to expose computer vision or learning algorithms for use at a plurality of different levels of abstraction.

In an Example 25 a method for providing machine learning algorithm services to computer applications includes with at least one computing device determining a parameter relating to a machine learning task of a computer application evaluating a capability of a plurality of machine learning algorithms to perform the machine learning task with the parameter selecting a machine learning algorithm of the plurality of machine learning algorithms based on the evaluating of the capability of the machine learning algorithms to perform the machine learning task with the parameter performing the machine learning task by executing the selected machine learning algorithm with the parameter and communicating a result of the executing of the machine learning algorithm to the computer application.

An Example 26 includes the method of Example 25 wherein the machine learning task includes analyzing digital content and the method includes determining the parameter based on an attribute of the digital content. An Example 27 includes the method of Example 26 including using the attribute of the digital content to determine a performance characteristic of the machine learning algorithm. An Example 28 includes the method of Example 27 including determining the performance characteristic of the machine learning algorithm by executing a content clustering technique based on the attribute of the digital content. An Example 29 includes the method of any of Examples 25 28 wherein the machine learning task includes analyzing one or more digital images and the method includes algorithmically extracting a content characteristic from a digital image computing distances between the digital image and each of a plurality of clusters of stored digital images wherein the distances are computed based on the extracted content characteristic selecting a cluster having a shortest computed distance to the digital image and executing the selected machine learning algorithm on the digital image using a parameter associated with the selected cluster. An Example 30 includes the method of any of Examples 25 29 wherein the machine learning algorithms are organized according to a plurality of different levels of abstraction and the method includes selecting a level of abstraction based on the machine learning task and or the parameter. An Example 31 includes an Internet based service including instructions embodied in one or more machine accessible storage media the instructions executable by one or more processors to perform the method of any of Examples 25 30. An Example 32 includes one or more machine accessible storage media having embodied therein a plurality of instructions executable by a processor to perform the method of any of Examples 25 30.

In the foregoing description numerous specific details examples and scenarios are set forth in order to provide a more thorough understanding of the present disclosure. It will be appreciated however that embodiments of the disclosure may be practiced without such specific details. Further such examples and scenarios are provided for illustration and are not intended to limit the disclosure in any way. Those of ordinary skill in the art with the included descriptions should be able to implement appropriate functionality without undue experimentation.

References in the specification to an embodiment etc. indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic. Such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is believed to be within the knowledge of one skilled in the art to affect such feature structure or characteristic in connection with other embodiments whether or not explicitly indicated.

Embodiments in accordance with the disclosure may be implemented in hardware firmware software or any combination thereof. Embodiments may also be implemented as instructions stored using one or more machine readable media which may be read and executed by one or more processors. A machine readable medium may include any mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device or a virtual machine running on one or more computing devices . For example a machine readable medium may include any suitable form of volatile or non volatile memory.

Modules data structures blocks and the like are referred to as such for ease of discussion and are not intended to imply that any specific implementation details are required. For example any of the described modules and or data structures may be combined or divided into sub modules sub processes or other units of computer code or data as may be required by a particular design or implementation. In the drawings specific arrangements or orderings of schematic elements may be shown for ease of description. However the specific ordering or arrangement of such elements is not meant to imply that a particular order or sequence of processing or separation of processes is required in all embodiments. In general schematic elements used to represent instruction blocks or modules may be implemented using any suitable form of machine readable instruction and each such instruction may be implemented using any suitable programming language library application programming interface API and or other software development tools or frameworks. Similarly schematic elements used to represent data or information may be implemented using any suitable electronic arrangement or data structure. Further some connections relationships or associations between elements may be simplified or not shown in the drawings so as not to obscure the disclosure. This disclosure is to be considered as exemplary and not restrictive in character and all changes and modifications that come within the spirit of the disclosure are desired to be protected.

