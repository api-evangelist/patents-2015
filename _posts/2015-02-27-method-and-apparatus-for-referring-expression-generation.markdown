---

title: Method and apparatus for referring expression generation
abstract: Methods, apparatuses, and computer program products are described herein that are configured to perform referring expression generation. In some example embodiments, a method is provided that comprises identifying an intended referent to be referred to in a textual output. The method of this embodiment may also include determining that a salient ancestor of the intended referent is lower in a part-of hierarchy than a lowest common ancestor. The method of this embodiment may also include causing the salient ancestor to be set as a current target referent and a new salient ancestor to be determined for the current target referent. In some example embodiments, the default descriptor of each current target referent is added to the referring noun phrase and the part-of hierarchy is traversed via salient ancestor links until the new salient ancestor of the current target referent is higher than or equal to the lowest common ancestor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09355093&OS=09355093&RS=09355093
owner: ARRIA DATA2TEXT LIMITED
number: 09355093
owner_city: Aberdeen
owner_country: GB
publication_date: 20150227
---
This application is a continuation of International Application No. PCT US2012 053183 filed Aug. 30 2012 which is hereby incorporated herein in its entirety by reference.

Embodiments of the present invention relate generally to natural language generation technologies and more particularly relate to a method apparatus and computer program product for referring expression generation.

In some examples a natural language generation NLG system is configured to transform raw input data that is expressed in a non linguistic format into a format that can be expressed linguistically such as through the use of natural language. For example raw input data may take the form of a value of a stock market index over time and as such the raw input data may include data that is suggestive of a time a duration a value and or the like. Therefore an NLG system may be configured to input the raw input data and output text that linguistically describes the value of the stock market index for example Securities markets rose steadily through most of the morning before sliding downhill late in the day. 

Data that is input into a NLG system may be provided in for example a recurrent formal structure. The recurrent formal structure may comprise a plurality of individual fields and defined relationships between the plurality of individual fields. For example the input data may be contained in a spreadsheet or database presented in a tabulated log message or other defined structure encoded in a knowledge representation such as the resource description framework RDF triples that make up the Semantic Web and or the like. In some examples the data may include numerical content symbolic content or the like. Symbolic content may include but is not limited to alphanumeric and other non numeric character sequences in any character encoding used to represent arbitrary elements of information. In some examples the output of the NLG system is text in a natural language e.g. English Japanese or Swahili but may also be in the form of synthesized speech.

Methods apparatuses and computer program products are described herein that are configured to perform referring expression generation. In some example embodiments a method is provided that comprises identifying an intended referent to be referred to in a textual output. The method of this embodiment may also include determining a lowest common ancestor for the intended referent and a previously referred to entity within a part of hierarchy. The method of this embodiment may also include determining that a salient ancestor of the intended referent is lower in the part of hierarchy than the lowest common ancestor in an instance in which the intended referent is marked as not salient. The method of this embodiment may also include causing the salient ancestor to be set as a current target referent and a new salient ancestor to be determined for the current target referent. In some example embodiments the default descriptor of each current target referent is added to the referring noun phrase and the part of hierarchy is traversed via salient ancestor links until the new salient ancestor of the current target referent is higher than or equal to the lowest common ancestor.

Example embodiments will now be described more fully hereinafter with reference to the accompanying drawings in which some but not all embodiments are shown. Indeed the embodiments may take many different forms and should not be construed as limited to the embodiments set forth herein rather these embodiments are provided so that this disclosure will satisfy applicable legal requirements. Like reference numerals refer to like elements throughout. The terms data content information and similar terms may be used interchangeably according to some example embodiments to refer to data capable of being transmitted received operated on and or stored. Moreover the term exemplary as may be used herein is not provided to convey any qualitative assessment but instead merely to convey an illustration of an example. Thus use of any such terms should not be taken to limit the spirit and scope of embodiments of the present invention.

Natural language texts that describe one or more entities such as those entities that have a complex internal structure e.g. machine parts geographic locations equipment or the like include a number of assets e.g. listing of vehicles or the like use referring expressions to identify particular intended referents e.g. components and sub components . In some examples a referring expression is any noun phrase or surrogate for a noun phrase whose function in a text is to identify an individual person place object or a set of persons places objects or the like. Referring expressions are generated based on the discourse context e.g. the previously generated text and the genre of the text e.g. engineering maintenance manuals often use different referring expressions from operational manuals .

However in order to generate referring expressions that describe an entity a decision must be made about how much information to include in each referring expression. For example a referring expression that has limited information may cause a reader to become confused whereas an expression with too much information may reduce readability and effectiveness of a text. By way of further example in a complex system one or more of the following referring expressions that describe a blade component may be generated based on a hierarchy see e.g. the blades the turbine blades the right engine s turbine blades the turbine blades of the power system s right engine the turbine blades of the right engine of the Super Puma s power system and or the turbine blades of the Super Puma s right engine .

In order to generate or otherwise select a referring expression to be included in a textual output methods apparatuses and computer program products are described herein that are configured to generate a referring expression in the form of a referring noun phrase using a part of hierarchy a reference model and or a discourse model. In particular a microplanner having a referring expression generation system may be configured to generate the referring expression based on a default descriptor for a particular entity to be referred to the intended referent and one or more salient ancestors of the intended referent. Further the referring expression generation system may also be configured to determine a previously referred to entity and as such may then identify a lowest common ancestor in the hierarchy of the intended referent and the previously referred to entity. A salient ancestor e.g. a prominent or important parent in the hierarchy may also be determined for the intended referent. In an instance in which the salient ancestor is higher than or equal to the lowest common ancestor then the default descriptor of the intended referent may become the referring expression. However in an instance in which the salient ancestor of the intended referent is lower in the hierarchy than the lowest common ancestor the default descriptors of one or more salient ancestors e.g. via one or more salient links of an intended referent may be formed together with a default descriptor of the intended referent to generate a referring expression.

A message store or knowledge pool is configured to store one or more messages that are accessible by the natural language generation system . Messages are language independent data structures that correspond to informational elements in a text and or collect together underlying data referred to as slots arguments or features which can be presented within a fragment of natural language such as a phrase or sentence. Messages may be represented in various ways for example each slot may consist of a named attribute and its corresponding value these values may recursively consist of sets of named attributes and their values and each message may belong to one of a set of predefined types. The concepts and relationships that make up messages may be drawn from an ontology e.g. a domain model that formally represents knowledge about the application scenario. In some examples the domain model is a representation of information about a particular domain. For example a domain model may contain an ontology that specifies the kinds of objects instances concepts and or the like that may exist in the domain in concrete or abstract form properties that may be predicated of the objects concepts and the like relationships that may hold between the objects concepts and the like and representations of any specific knowledge that is required to function in the particular domain.

In some examples messages are created based on a requirements analysis as to what is to be communicated for a particular scenario e.g. for a particular domain or genre . A message typically corresponds to a fact about the underlying data for example the existence of some observed event that could be expressed via a simple sentence although it may ultimately be realized by some other linguistic means . For example to linguistically describe an object such as an engine a user may want to know which engine is being referred to a status of the engine a condition of the engine and or the like. In some cases the user may not want to know an engine temperature but instead want to be warned in an instance in which the engine temperature is at a dangerous level. For example the right engine is too hot. In other examples the engine being too hot may be linked to a resultant condition for example after investigating the crash it appears the right engine was too hot. 

In some examples a message is created in an instance in which the raw input data warrants the construction of such a message. For example a wind message would only be constructed in an instance in which wind data was present in the raw input data. Alternatively or additionally while messages may correspond directly to observations taken from a raw data input others however may be derived from the observations by means of a process of inference or based on one or more detected events. For example the presence of rain may be indicative of other conditions such as the potential for snow at some temperatures.

Messages may be instantiated based on many variations of source data such as but not limited to time series data time and space data data from multiple data channels an ontology sentence or phrase extraction from one or more texts a text survey responses structured data unstructured data and or the like. For example in some cases messages may be generated based on text related to multiple news articles focused on the same or similar news story in order to generate a news story. Whereas in other examples messages may be built based on survey responses and or event data.

Messages may be annotated with an indication of their relative importance this information can be used in subsequent processing steps or by the natural language generation system to make decisions about which information may be conveyed and which information may be suppressed. Alternatively or additionally messages may include information on relationships between the one or more messages.

In some example embodiments a natural language generation system such as natural language generation system is configured to generate phrases sentences text or the like which may take the form of a natural language text. The natural language generation system comprises a document planner a microplanner and or a realizer . The natural language generation system may also be in data communication with the message store the domain model and or the linguistic resources . In some examples the linguistic resources include but are not limited to text schemas aggregation rules reference rules lexicalization rules and or grammar rules that may be used by one or more of the document planner the microplanner and or the realizer . Other natural language generation systems may be used in some example embodiments such as a natural language generation system as described in Building Natural Language Generation Systems by Ehud Reiter and Robert Dale Cambridge University Press 2000 which is incorporated by reference in its entirety herein.

The document planner is configured to input the one or more messages from the message store . The document planner is further configured to determine how to arrange those messages in order to describe the patterns in the one or more data channels derived from the raw input data. The document planner may comprise a content determination process that is configured to select the messages such as the messages that contain a representation of the data that is to be output via a natural language text.

The document planner may also comprise a structuring process that determines the order of messages to be included in a text. In some example embodiments the document planner may access one or more text schemas for the purposes of content determination and document structuring. A text schema is a rule set that defines the order in which a number of messages are to be presented in a document. For example a medication injection message may be described prior to a heart rate spike message. In other examples a steady respiration rate message may be described after but in relation to the heart rate spike message.

The output of the document planner may be a tree structured object or other data structure that is referred to as a document plan. In an instance in which a tree structured object is chosen for the document plan the leaf nodes of the tree may contain the messages and the intermediate nodes of the tree structure object may be configured to indicate how the subordinate nodes are related e.g. elaboration consequence contrast sequence and or the like to each other.

The microplanner is configured to construct a text specification based on the document plan from the document planner such that the document plan may be expressed in natural language. In some example embodiments the microplanner may perform aggregation lexicalization and referring expression generation. In some examples aggregation includes but is not limited to determining whether two or more messages can be combined together linguistically to produce a more complex phrase specification. For example one or more messages may be aggregated so that both of the messages can be described by a single sentence. In some examples lexicalization includes but is not limited to choosing particular words for the expression of concepts and relations. In some examples referring expression generation includes but is not limited to choosing how to refer to an entity so that it can be unambiguously identified by the reader. Referring expression generation is further described with respect to at least . The output of the microplanner in some example embodiments is a tree structured realization specification whose leaf nodes are phrase specifications and whose internal nodes express rhetorical relations between the leaf nodes.

A realizer is configured to traverse a text specification output by the microplanner to express the text specification in natural language. The realization process that is applied to each phrase specification makes use of a grammar e.g. the grammar of the linguistic resources which specifies the valid syntactic structures in the language and further provides a way of mapping from phrase specifications into the corresponding natural language sentences. The output of the process is in some example embodiments a natural language text. In some examples the natural language text may include embedded mark up.

In some example embodiments and in order to generate the referring expression the referring expression generation system is configured to access or otherwise be in data communication with a data model that may additionally comprise or otherwise embodies at least a hierarchy e.g. a part of hierarchy such as the hierarchy shown in or the like a reference model and or the like. The reference model specifies additional information about the components in the hierarchy . For example the reference model may provide a default descriptor for an entity and may further identify a salient ancestor for that entity. In some examples a default descriptor is the name used for a particular entity in a text in an instance in which no additional information about higher level entities in the hierarchy is provided. For example the default descriptor of Eurocopter AS332 Super Puma Helicopter shown in may be Super Puma . Super Puma may provide enough information for a reader in a helicopter or aircraft genre or domain to identify that the intended referent of Super Puma is a Eurocopter AS332. As such the default descriptor typically used for a given entity in a genre may not be as rich or as complicated as the full name or nomenclature used in an underlying hierarchy.

In some examples a salient ancestor is an ancestor of an intended referent in the hierarchy that may be added to a referring expression in an instance in which it is insufficient to use the default descriptor of the intended referent alone. In some examples the salient ancestor is the intended referent s parent in the hierarchy however in other examples one or more levels within the hierarchy may be skipped or marked as to be ignored. For example and with reference to the reference model may indicate in the helicopter genre that the salient ancestor of the left engine is the Super Puma and not its parent the power system. Such a rule may be present because the genre may specify that an engine is to be referred to as the Super Puma s left engine not the power system s left engine or the Super Puma s power system s left engine . Alternatively or additionally the reference model may be configured to include multiple Boolean flags for each entity such that the Boolean flags are configured to indicate whether an entity is always salient or if an entity should be skipped when looking for salient ancestors.

In an instance in which the salient ancestor is null or the intended referent is otherwise indicated as always salient then the intended referent may be described without reference to a salient ancestor. For example in a geographic ontology or hierarchy Chicago and Springfield would both be beneath the state of Illinois however Chicago would likely be marked as always salient because in most contexts Chicago by itself is sufficient . On the other hand Springfield would not be marked as always salient and would have Illinois as a salient ancestor because Springfield without Illinois would not be meaningful. Further in a sports ontology a player such as David Beckham or Ronaldo may be marked as always salient whereas Freddi Montero may require a salient ancestor of Seattle Sounders FC in a textual output. In some examples Seattle Sounders may need a further salient ancestor of Major League Soccer in other example textual outputs.

In some example embodiments a discourse model is embodied by or may be accessed by the microplanner . The discourse model is configured to record the entities previously referred to in the present text e.g. entities mentioned in previous phrase specifications along with the referring expressions that were used to refer to them. For example and with reference to if a previous referring expression referred to right engine casings the next referring expression may only need to refer to the turbine since the right engine is already salient. As such the referring expression generation system may access the discourse model in order to determine the previous entities referred to.

In some example embodiments the referring expression generation system may determine the lowest common ancestor in the hierarchy between an intended referent and the previous referent. Using the lowest common ancestor the intended referent and the salient ancestors a referring expression for example in the form of a referring noun phrase is generated by the referring expression generation system by including the default descriptors of the intended referent and its ancestors e.g. by following the salient ancestor links until the lowest common ancestor or one of its ancestors that is salient is reached. The generation of the referring expression is further described with reference to .

In block the referring expression generation system may access the discourse model to obtain the previous entity referred to. The previous entity referred to is the last or prior entity that was the intended referent in the generation of a referring expression. The previous entity referred to may then be identified or otherwise located in the hierarchy by the referring expression generation system . Using the previous entity referred to the referring expression generation system may be configured to set a lowest common ancestor to be the lowest entity within the hierarchy that is an ancestor of both the intended referent and the previous entity referred to in block . In an instance in which the previous entity referred to is null then the lowest common ancestor may be set to a root entity of the hierarchy e.g. Super Puma in .

In block the default descriptor of the intended referent in the reference model is added to a descriptor queue. In some example embodiments the descriptor queue is initialized as an empty queue prior to the first instance of block . Alternatively or additionally the process shown in may be configured to end in an instance in which the intended referent is identified such as by the reference model a flag or the like as always salient. In such cases the referring expression e.g. referring noun phrase may then take the form of the default descriptor of the intended referent. As is shown in block the target referent is set to be the intended referent.

As shown in block a salient ancestor of the intended referent in the reference model may be identified such as via the reference model . At decision block the referring expression generation system is configured to determine whether the salient ancestor is lower in the hierarchy than the lowest common ancestor. If so then at block the current salient ancestor is set as a new target referent. In block the default descriptor for the new target referent is added to the descriptor queue and a new salient ancestor for the new target referent is determined in block The process of blocks continues until at decision block the salient ancestor of the current target referent is higher than or equal to the lowest common ancestor. As noted during each iteration through blocks the default descriptor for the target referent is added to the descriptor queue. As such the hierarchy is traversed using salient ancestor links. For example salient ancestor links may be represented as 

Alternatively or additionally in some examples other methods of traversal may be used such as but not limited to traversing each hierarchy and skipping those entities marked as to be ignored traversing the hierarchy and including parent entities and or the like.

At block the first element of the descriptor queue is removed and designated as the head noun of a referring noun phrase. In some example embodiments the head noun may be assigned a determiner of the . For example if the intended referent was Super Puma the default descriptor may be stored in the referring noun phrase as the Super Puma .

At decision block in an instance in which the descriptor queue is not empty it is determined whether a predetermined premodifier count as been reached. In some examples a premodifier count is predetermined and indicates the maximum number of premodifiers that may be placed before the head noun in the referring noun phrase. In an instance in which the premodifier count has not been reach or satisfied then at block the default descriptor of the first element of the descriptor queue is set as a premodifier to the head noun in the referring noun phrase. For example in an instance in which a blade is the intended referent turbine may be added as a premodifier resulting in a referring expression the turbine blades . The premodifier count is also incremented in block . Such a process continues until the premodifier count is reached or the descriptor queue is empty.

In an instance in which the maximum premodifier count is reached or the descriptor queue is empty then at decision block it is determined whether the descriptor queue is empty. If the descriptor queue is not empty then at block the first element of the descriptor queue is set as a postmodifier to the head noun in the referring noun phrase. In some examples the first element is added to a prepositional phrase having the proposition of and is then added to the referring noun phrase. For example in an instance in which a blade is the intended referent and turbine is the premodifier right engine may be added as the postmodifier resulting in a referring expression the turbine blade of the right engine . Such a process continues until the descriptor queue is empty.

At block the referring noun phrase is returned as the referring expression for use in a phrase specification and eventually the textual output of the natural language generation system . Alternatively or additionally the discourse model is updated to reflect the most recently identified intended referent.

Alternatively or additionally one or more entities may not have a default descriptor in a reference model. For example in the hierarchy of Gear through to Gear may not be assigned individual default descriptors and in such example cases the entities may be referred to by the name of a class a type or the like e.g. gear .

By way of example in order to generate a referring expression for an entity that does not have a default descriptor the referring expression generation system may in some example embodiments determine whether the intended referent has been previously referred to. In an instance in which the intended referent has not been previously referred to then the referring noun phrase may include a and the class or type of the intended referent e.g. a gear . In an instance in which the intended referent has been previously referred to then the referring expression generation system may determine the previous references in the one or more phrase specifications to a same class or type via the discourse model. In an instance in which the intended referent is the most recently referred to entity in the previously referred to entities then the referring noun phrase may include the determiner the and the intended referent class or type name. Otherwise the referring noun phrase is generated to include one of the and the entity is set to plural e.g. one of the gears . Alternatively or additionally sets may be referred to in a same or similar manner. For example if referring to multiple unnamed entities of the same type and in the same hierarchy position e.g. the gears phrases such as four of the gears or all of the gears may be returned.

Text was taken from Section 1.12.2 of an official air accident report http www.aaib.gov.uk cms resources 2 2011 20G REDL.pdf .

For example in order to describe the blades the referring expression generation system is configured to determine a previous entity referred to in the text such as via the discourse model . In this example the previous entity referred to in the text was the free turbine case . Therefore in this example the lowest common ancestor in the hierarchy between the free turbine case and the blades is the right engine . A reference model such as reference model may indicate that the turbine is the salient ancestor of the blades . As such the blades are designated to be referred to by the head noun of a referring noun phrase. Because the turbine is located beneath the lowest common ancestor in the hierarchy the turbine is then set as the target referent and its salient ancestor the right engine is determined. In this example the right engine is the salient ancestor of the turbine and is also the lowest common ancestor and therefore the process ends. The referring noun phrase may be then generated by the referring expression generation system having blades as the head noun and having turbine as a premodifier or postmodifier. For example the referring noun phrase may be the turbine blades or the blades of the turbine .

In the example embodiment shown computing system comprises a computer memory memory a display one or more processors input output devices e.g. keyboard mouse CRT or LCD display touch screen gesture sensing device and or the like other computer readable media and communications interface . The processor may for example be embodied as various means including one or more microprocessors with accompanying digital signal processor s one or more processor s without an accompanying digital signal processor one or more coprocessors one or more multi core processors one or more controllers processing circuitry one or more computers various other processing elements including integrated circuits such as for example an application specific integrated circuit ASIC or field programmable gate array FPGA or some combination thereof. Accordingly although illustrated in as a single processor in some embodiments the processor comprises a plurality of processors. The plurality of processors may be in operative communication with each other and may be collectively configured to perform one or more functionalities of the reference system as described herein.

The natural language generation system is shown residing in memory . The memory may comprise for example transitory and or non transitory memory such as volatile memory non volatile memory or some combination thereof. Although illustrated in as a single memory the memory may comprise a plurality of memories. The plurality of memories may be embodied on a single computing device or may be distributed across a plurality of computing devices collectively configured to function as the natural language system the microplanner and or the reference system. In various example embodiments the memory may comprise for example a hard disk random access memory cache memory flash memory a compact disc read only memory CD ROM digital versatile disc read only memory DVD ROM an optical disc circuitry configured to store information or some combination thereof.

In other embodiments some portion of the contents some or all of the components of the natural language generation system may be stored on and or transmitted over the other computer readable media . The components of the natural language generation system preferably execute on one or more processors and are configured to enable operation of a configurable microplanner as described herein.

Alternatively or additionally other code or programs e.g. an administrative interface a Web server and the like and potentially other data repositories such as other data sources also reside in the memory and preferably execute on one or more processors . Of note one or more of the components in may not be present in any specific implementation. For example some embodiments may not provide other computer readable media or a display .

The natural language generation system is further configured to provide functions such as those described with reference to . The natural language generation system may interact with the network via the communications interface with remote data sources e.g. remote reference data remote performance data remote aggregation data remote knowledge pools and or the like third party content providers and or client devices . The network may be any combination of media e.g. twisted pair coaxial fiber optic radio frequency hardware e.g. routers switches repeaters transceivers and protocols e.g. TCP IP UDP Ethernet Wi Fi WiMAX Bluetooth that facilitate communication between remotely situated humans and or devices. In some instance the network may take the form of the internet or may be embodied by a cellular network such as an LTE based network. In this regard the communications interface may be capable of operating with one or more air interface standards communication protocols modulation types access types and or the like. The client devices include desktop computing systems notebook computers mobile phones smart phones personal digital assistants tablets and or the like.

In an example embodiment components modules of the natural language generation system are implemented using standard programming techniques. For example the natural language generation system may be implemented as a native executable running on the processor along with one or more static or dynamic libraries. In other embodiments the natural language generation system may be implemented as instructions processed by a virtual machine that executes as one of the other programs . In general a range of programming languages known in the art may be employed for implementing such example embodiments including representative implementations of various programming language paradigms including but not limited to object oriented e.g. Java C C Visual Basic.NET Smalltalk and the like functional e.g. ML Lisp Scheme and the like procedural e.g. C Pascal Ada Modula and the like scripting e.g. Perl Ruby Python JavaScript VBScript and the like and declarative e.g. SQL Prolog and the like .

The embodiments described above may also use synchronous or asynchronous client server computing techniques. Also the various components may be implemented using more monolithic programming techniques for example as an executable running on a single processor computer system or alternatively decomposed using a variety of structuring techniques including but not limited to multiprogramming multithreading client server or peer to peer running on one or more computer systems each having one or more processors. Some embodiments may execute concurrently and asynchronously and communicate using message passing techniques. Equivalent synchronous embodiments are also supported. Also other functions could be implemented and or performed by each component module and in different orders and by different components modules yet still achieve the described functions.

In addition programming interfaces to the data stored as part of the natural language generation system such as by using one or more application programming interfaces can be made available by mechanisms such as through application programming interfaces API e.g. C C C and Java libraries for accessing files databases or other data repositories through scripting languages such as XML or through Web servers FTP servers or other types of servers providing access to stored data. The message store the domain model and or the linguistic resources may be implemented as one or more database systems file systems or any other technique for storing such information or any combination of the above including implementations using distributed computing techniques. Alternatively or additionally the message store the domain model and or the linguistic resources may be local data stores but may also be configured to access data from the remote data sources .

Different configurations and locations of programs and data are contemplated for use with techniques described herein. A variety of distributed computing techniques are appropriate for implementing the components of the illustrated embodiments in a distributed manner including but not limited to TCP IP sockets RPC RMI HTTP Web Services XML RPC JAX RPC SOAP and the like . Other variations are possible. Also other functionality could be provided by each component module or existing functionality could be distributed amongst the components modules in different ways yet still achieve the functions described herein.

Furthermore in some embodiments some or all of the components of the natural language generation system may be implemented or provided in other manners such as at least partially in firmware and or hardware including but not limited to one or more ASICs standard integrated circuits controllers executing appropriate instructions and including microcontrollers and or embedded controllers FPGAs complex programmable logic devices CPLDs and the like. Some or all of the system components and or data structures may also be stored as contents e.g. as executable or other machine readable software instructions or structured data on a computer readable medium so as to enable or configure the computer readable medium and or one or more associated computing systems or devices to execute or otherwise use or provide the contents to perform at least some of the described techniques. Some or all of the system components and data structures may also be stored as data signals e.g. by being encoded as part of a carrier wave or included as part of an analog or digital propagated signal on a variety of computer readable transmission mediums which are then transmitted including across wireless based and wired cable based mediums and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly embodiments of this disclosure may be practiced with other computer system configurations.

As is shown in operation an apparatus may include means such as the microplanner the hierarchy the discourse model the reference system the processor or the like for determining a lowest common ancestor for the intended referent and a previously referred to entity within a part of hierarchy such as an equipment part of hierarchy. As is shown in operation an apparatus may include means such as the microplanner the hierarchy the discourse model the referring expression generation system the processor or the like for determining the previously referred to entity based on a last entity mentioned in a discourse model. In some example embodiments the previously referred to entity is set to a root component of the part of hierarchy in an instance in which the previous reference is set to null.

As is shown in operation an apparatus may include means such as the microplanner the hierarchy the referring expression generation system the processor or the like for determining that a salient ancestor of the intended referent is higher than or equal to the lowest common ancestor in the part of hierarchy such that the referring noun phrase comprises the default descriptor of the intended referent. As is shown in operation an apparatus may include means such as the microplanner the hierarchy the referring expression generation system the processor or the like for determining that a salient ancestor of the intended referent is lower in the part of hierarchy than a lowest common ancestor in an instance in which the intended referent is marked as not salient.

As is shown in operation an apparatus may include means such as the microplanner the hierarchy the reference model the referring expression generation system the processor or the like for causing the salient ancestor to be set as a current target referent and a new salient ancestor to be determined for the current target referent wherein the default descriptor of each current target referent is added to the referring noun phrase and the part of hierarchy is traversed via salient ancestor links until the new salient ancestor of the current target referent is higher than or equal to the lowest common ancestor.

In some example embodiments the referring noun phrase comprises a predetermined maximum number of premodifiers of the default descriptor of the intended referent wherein the premodifiers comprise one or more default descriptors of the one or more parts of the part of hierarchy traversed. In additional example embodiments the referring noun phrase comprises a number of postmodifiers of the default descriptor of the intended referent wherein the postmodifiers comprise the remaining one or more default descriptors of the one or more parts of the part of hierarchy traversed not included as premodifiers.

Accordingly blocks of the flowchart support combinations of means for performing the specified functions and combinations of operations for performing the specified functions. It will also be understood that one or more blocks of the flowcharts and combinations of blocks in the flowchart can be implemented by special purpose hardware based computer systems which perform the specified functions or combinations of special purpose hardware and computer instructions.

In some example embodiments certain ones of the operations herein may be modified or further amplified as described below. Moreover in some embodiments additional optional operations may also be included some examples of which are shown in dashed lines in . It should be appreciated that each of the modifications optional additions or amplifications described herein may be included with the operations herein either alone or in combination with any others among the features described herein.

Many modifications and other embodiments of the inventions set forth herein will come to mind to one skilled in the art to which these inventions pertain having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore it is to be understood that the inventions are not to be limited to the specific embodiments disclosed and that modifications and other embodiments are intended to be included within the scope of the appended claims. Moreover although the foregoing descriptions and the associated drawings describe example embodiments in the context of certain example combinations of elements and or functions it should be appreciated that different combinations of elements and or functions may be provided by alternative embodiments without departing from the scope of the appended claims. In this regard for example different combinations of elements and or functions than those explicitly described above are also contemplated as may be set forth in some of the appended claims. Although specific terms are employed herein they are used in a generic and descriptive sense only and not for purposes of limitation.

