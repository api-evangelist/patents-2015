---

title: Dynamic rule-based automatic crash dump analyzer
abstract: A method and system for dynamic rule-based automatic crash dump analysis are described. In an example, a dynamic rule-based crash dump analysis system retrieves debug symbol data, rules, and commands from a server over a network. The actions are executed based on the retrieved rules in order to automatically analyze a crash dump using a debugger and the debug symbol data. During the process of analyzing the crash dump, the system parses output from the debugger for further rule processing and creates a human-readable analysis file from the parsed output.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09529662&OS=09529662&RS=09529662
owner: NETAPP, INC.
number: 09529662
owner_city: Sunnyvale
owner_country: US
publication_date: 20150731
---
Examples described herein relate to computer troubleshooting and more specifically to a system and method for dynamically analyzing crash dumps.

A crash dump also known as a core dump memory dump or a system dump contains the memory state of a computer system at a given time which is written to storage by the system usually in the case of a system crash or fatal error. Crash dumps can be used with or without manual intervention to aid in debugging certain problem scenarios such as the cause of the crash or error. Normally analysis of crash dump files through a debugging program requires an engineer to run through certain decisions making processes to arrive at a conclusive result. These decision paths are typically taken based on command outputs from the debugger and can range from outputting a single variable to long running and lengthy output macros. Often these decision paths are repetitive and based on certain familiar or popular command outputs.

With cheaper dynamic static random access memory DRAM SRAM systems with large amounts of RAM are becoming commonplace. Several high end systems like enterprise storage controllers benefit greatly from more RAM in providing high end solutions. Correspondingly the crash dumps generated from such systems are no longer small and continue increasing in the range of their system memory. Uploading these large crash dumps to remote support sites introduces several issues in regards to bandwidth limitations and unsuccessful or corrupted file transfers. Compression can be used to reduce the crash dump file size to some extent but running compression algorithms on extremely large files can take hours or even days to compress and decompress.

In addition analysis of crash dumps is greatly aided by symbol files containing debug symbol tables which are data structures used by debuggers compilers and interpreters to store information about the occurrence of various entities such as variable names function names objects classes interfaces etc. in program code. Since these symbol files can be used in reverse engineering programs they are important company assets and any compromise with these assets is not acceptable.

The proposed system aims to provide a single full fledged solution to eliminate the need to upload huge crash dump files while also providing the debugger with the required symbol lookups with enough security to protect the symbol files from both the customer site as well as the internet. The system offloads all the manual work done by an engineer to an automated system through the use of decision trees.

With the increasing size of crash dumps it is becoming more difficult for customers to upload the dumps from local servers to remote hosts for debugging by qualified engineers with access to the proper tools. At worst it can take from hours to even days to transfer the crash dump files with no guarantee of a successful transfer. There are various existing solutions involving analysis programs such as back trace analyzers and bug signature analyzers which can be run without transferring the entire crash dump. However these solutions are mainly targeted at frequently occurring bugs and require constant maintenance involving writing bug signatures for each bug. As a result these are poor long term solutions and not applicable in all cases. The proposed system is targeted to extracting the useful information from crash dumps and creating a small analysis file without requiring uploading the entire crash dump to a remote support site. Unlike previous solutions a single well crafted decision tree is enough to catch multiple bugs which can greatly decrease the manual maintenance work.

Ideally a well crafted decision tree should produce a small self sufficient analysis file that contains all the useful information from the crash dump. The analysis file can then be uploaded and examined by an engineer or technical support specialist to pinpoint an existing bug discover a new bug or find the underlying root cause of the crash. Even in a worst case scenario where the crash dump is uploaded for further examination analyzing the crash dump using the decision trees can reduce the complexity of manual analysis. In addition the decision tree analysis can at least identify the subsystem s in which the problem was observed so that further analysis can be better focused or assigned to someone with the correct expertise.

In an example a dynamic rule based crash dump analysis system retrieves debug symbol data rules and commands from a server over a network. The actions are executed based on the retrieved rules in order to automatically analyze a crash dump using a debugger and the debug symbol data. During the process of analyzing the crash dump the system parses output from the debugger for further rule processing and creates a human readable analysis file from the parsed output.

In some aspects the actions are generic and designed to not be specific to the debugger. Instead adapters can be created that adapt the generic actions to formats compatible with multiple different debuggers depending on the environment. In addition the retrieved rules and actions can be contained in a decision tree or trees which may be in XML format.

According to some examples dynamic rule based crash dump analysis also includes parsing the rules and actions from the decision tree and retrieving objects associated with those rules and commands from a database or knowledge base. The output from the parser can be used in further rule processing through a forward chaining approach until all matching rules have been exhausted.

In one aspect the debug symbol data retrieved from the remote server over the network is sufficient to create a symbol table to be used by a debugger along with the parsed rules and actions. In another aspect the initial debug symbol data is insufficient and the debugger can request further debug symbol data from the server as needed during the crash dump analysis.

This approach for solving the problem of sending large crash dumps over a network uses expert system to provide a simple solution for a complex problem. It provides a neat solution which is scalable and extendable. The adapter interface provides enough extendibility for the infrastructure to interact with other systems i.e. not limited to a specific debugging program and hence serves as the base and infrastructure to solve various other problems.

Besides the bandwidth savings from remotely analysing crash dumps in some circumstances customers in secure sites require crash dumps to be analyzed only by authorized personnel which can mean the analysis has to be performed at a remote site. An automatic crash dump analyzer can help avoid the need to send engineers to remote sites for performing such analyses.

One or more aspects described herein provide that methods techniques and actions performed by a computing device are performed programmatically or as a computer implemented method. Programmatically means through the use of code or computer executable instructions. A programmatically performed step may or may not be automatic.

One or more aspects described herein may be implemented using programmatic modules or components. A programmatic module or component may include a program a subroutine a portion of a program a software component or a hardware component capable of performing one or more stated tasks or functions. In addition a module or component can exist on a hardware component independently of other modules or components. Alternatively a module or component can be a shared element or process of other modules programs or machines.

Furthermore one or more aspects described herein may be implemented through the use of instructions that are executable by one or more processors. These instructions may be carried on a computer readable medium. Machines shown or described with figures below provide examples of processing resources and computer readable media on which instructions for implementing some aspects can be carried and or executed. In particular the numerous machines shown in some examples include processor s and various forms of memory for holding data and instructions. Examples of computer readable media include permanent memory storage devices such as hard drives on personal computers or servers. Other examples of computer storage media include portable storage units such as CD or DVD units flash or solid state memory such as carried on many cell phones and consumer electronic devices and magnetic memory. Computers terminals network enabled devices e.g. mobile devices such as cell phones are all examples of machines and devices that utilize processors memory and instructions stored on computer readable media.

Alternatively one or more examples described herein may be implemented through the use of dedicated hardware logic circuits that are comprised of an interconnection of logic gates. Such circuits are typically designed using a hardware description language HDL such as Verilog and VHDL. These languages contain instructions that ultimately define the layout of the circuit. However once the circuit is fabricated there are no instructions. All the processing is performed by interconnected gates.

In order to bring scalability reliability and extendibility to the system the infrastructure is designed with the knowledge of expert systems. A rule engine backend proves flexibility to create modify and remove rules and hence cleanly change a decision tree without involving any programmatic changes. Various concepts are introduced which allow the infrastructure to understand and run commands on any system any entity which can take a command and provide a corresponding output provided that a corresponding adapter is added. Output from these commands can then be converted to useful information for decision making through the parser modules and a logger can present these outputs in plain text HTML or other formats with highlighting and other emphasis present to help identify the most pertinent data.

Decision tree is a machine representation of an engineer s crash dump analyzing technique which can be contained in one or more XML files or other formats suitable for being parsed. Decision tree consists of pairs of rules and commands that mimic the process and decision making an engineer might perform for analyzing a crash dump with a debugger. Storing decision tree in a format such as XML allows changes to be made to decision tree without programming language specific changes to code run by other elements of the crash dump analysis system . In a remote deployment the system can pull decision tree from a remote web server before initiating a crash dump analysis. Hence any changes to decision tree made remotely do not impact a currently running crash dump analysis at a client site although updates to decision tree can be made on a central server and retrieved by clients to keep them up to date. In other aspects decision tree can be manually acquired or retrieved from other sources.

Once pulled from the remote web server the decision tree is loaded into the automatic core analyzer and can be parsed by decision tree parser . In aspects where the decision tree is an XML file decision tree parser reads and separates the individual tags in the XML into their component commands rules actions logs and conditions which make up parsed tree data . These parsed tags correspond to objects or snippets of code stored in knowledge base . Decision trees in other formats can be similarly parsed into component tags that correspond to objects in the knowledge base .

The parsed tree data is then sent to the main rule solving engine when requested by the rule solving engine which sends object requests to pull objects identified in the parsed tree data from the knowledge base a repository for these objects. Any lookups concerning rules commands etc. are performed on the knowledge base by the rule solving engine . Objects stored in the knowledge base take numerous forms depending on their functions. Rules conditions actions logs commands and questions are illustrated although more categories and subcategories of objects can be stored in the knowledge base depending on the complexity of the decision tree and features of external debugging programs . Furthermore although distinctions between object types are described some types can be combined for simplicity. For example commands and actions can both be considered actions in terms of objects.

A decision tree can have multiple rules in the parsed tree data . A rule can consist of multiple conditions actions and logs . Rules trigger the set of actions when the conditions are satisfied. Commands define how a command can be executed by the external debugging programs . In some aspects commands are run before rules are used to determine the rule conditions or its actions . A macro used by a debugger such as GDB is an example of a command . In addition the knowledge base can also include questions that require manual responses from users of the system .

Log tags in rules specify how a command could be logged e.g. print commands and highlight critical points . The modules interpret these tags and dump the corresponding output format either in text or HTML format. While analyzing the crash dump certain levels of logging are provided one of which is keyword logging. In some aspects these keywords can serve the foundation of a bug prediction system.

This example decision tree depicts 2 macros memstat and leakdetector. The rules instruct the rule solving engine to run leakdetector if kma takes up more than 20 of total memory. The COLUMN symbol and column number are used to extract the kma value from memstat output in this example. However in other examples regular expressions can be used to match and extract the proper values from program outputs. In addition decision trees can span multiple XML files. For example command tags can be placed in a separate XML file from the rules and actions.

Rule solving engine can be regarded as the core which powers and connects all the components of the automatic core analyzer . In some aspects forward chaining is used as the logic for solving the rules read from the parsed tree data . Forward chaining starts with the available data from executed commands and uses inference rules to extract more data from the external debugging programs and the crash dump until all rules are solved or otherwise exhausted. An inference engine using forward chaining searches the inference rules until it finds one where the antecedent If clause is known to be true. When such a rule is found the engine can conclude or infer the consequent Then clause resulting in the addition of new information to its data. In this case the rule solving engine runs until all the command and condition attributes are resolved or there is not enough data remaining in the crash dump to resolve the attributes.

Commands and actions retrieved from the knowledge base are processed by the rule solving engine as generic commands . However these generic commands must first be converted to be compatible with one of the external debugging programs available to the system . In some aspects debugging adapters are modules programmed to convert the generic commands into converted commands and interface with a specific debugger local or remote to invoke a command on it. The debugger executes the converted commands on the crash dump and returns a corresponding output. The debugging adapters can also perform an authentication if required. This is the only part of the infrastructure which is non generic. For example an adapter for a storage controller may be able to perform certain tasks like automatic management gathering statistical data or performing certain workflows based on the objects retrieved from the knowledge base .

Depending on the system one or more external debugging programs may be available. For example debugger 1 may be the GNU Debugger GDB debugger 2 may be WinDbg and debugger n may be the Microsoft Visual Studio Debugger. Each of these debuggers has an associated debugging adapter that was programmed for it. Once the external debugging program receives the converted commands it executes the commands on the crash dump and returns raw output to the rule solving engine .

In some aspects this raw output can be difficult or impossible to read either by users or the rule solving engine itself. In order to convert the raw output it is sent through an output parser and turned into useful output . Output parser is special parser which takes in raw outputs from the debugging adapters through the rule solving engine and extracts useful information for further rule processing. Generally the rules can contain certain symbols like ROW COLUMN REGX etc. which carries these symbols on to the attribute value. The work of this module is to interpret these symbols extract a value from the corresponding command output and substitute the new value to the expression. Attributes can be complex expressions and can also contain other attribute dependencies. Resolution of the dependencies is performed by the rule solving engine .

Rule solving engine can then use the useful output as further data in the forward chaining engine to solve more rules and execute more actions . In addition the rule solving engine can send outputs either or both of raw output and useful output to a logging module which can generate human readable analysis files and logs. In one aspect outputs consist of raw output modified by the log tags which contain symbols for text highlighting and other features to facilitate human analysis if needed. These files and logs can then be used by engineers to locate bugs and determine the root cause of a crash which produced the crash dump .

There are multiple approaches to make this solution work at a customer site. The first approach is to ship the symbol files to the customer site and run a debugger locally. The other approach involves establishing a secure connection between a web server with the symbol files and the customer site to fetch the symbols for the debugger running locally on the customer site. The detailed explanations of these approaches are given below.

In this approach a machine or virtual machine performs an NFS mount on another system e.g. storage controller after a crash and accesses the crash dump . In some aspects this can be performed automatically after the storage controller reboots. In other examples the storage controller can be mounted using other file systems and mounting applications.

Once the crash dump has been loaded into the debugger the machine VM runs the infrastructure by fetching symbol files and the decision tree from a web server . In some aspects these files can be retrieved over a network such as the Internet by using HTTP FTP or a similar protocol. In this setup it is assumed that the customer can have access to the symbol files and security is only at the session level.

While operations of the methods and are described below as being performed by specific components modules or systems of the computer system it will be appreciated that these operations need not necessarily be performed by the specific components identified and could be performed by a variety of components and modules potentially distributed over a number of machines. Accordingly references may be made to elements of system for the purpose of illustrating suitable components or elements for performing a step or sub step being described. Alternatively at least certain ones of the variety of components and modules described in system can be arranged within a single hardware software or firmware component. It will also be appreciated that some of the steps of this method may be performed in parallel or in a different order than illustrated.

With reference to an example of a computing device crashes and reboots for example the storage controller as described with . A machine virtual machine running the automatic core analyzer and a debugger mounts the storage controller in order to access the crash dump . Next the machine virtual machine fetches symbol files and a decision tree from web server over a network . With the symbol files the debugger constructs a symbol table that can be used to help the automatic core analyzer debug the cause of the crash . The machine virtual machine then executes the automatic core analyzer using the decision tree in a manner as described with respect to .

Normally debuggers such as GDB read from the symbol files and construct a symbol table locally to look up various entities such as variable names function names objects classes interfaces etc. in program code. Since these symbol files can be used in reverse engineering programs they are important company assets and any compromise with these assets is not acceptable. The example illustrated in decouples the symbol table logic from the debugger in the local network machine virtual machine . In place of this normal logic the debugger instead requests individual symbols from a symbol lookup module running remotely on web server with access to the symbol files . This allows the debugger to construct partial symbol tables at a client site securely. Any time the debugger at the client site requires a symbol lookup it sends a request across the network to the symbol lookup module .

A single symbol file may contain millions of entries in a symbol table. What the client machine virtual machine receives in this implementation is a very small subset of these entries which drastically reduces the risk factor of exposing symbol files outside of a company. Apart from the session level security provided by SSL additional security like signature authentication through the REST API and encryption of the symbol cache of certain fields at the client end can be provided.

In addition for performance and network latency reasons the debugger can request batches of symbol data from the symbol lookup module at a time instead of individually. In one example the debugger sends multiple lookup calls through a single JSON object.

In an embodiment computer system includes processor memory including non transitory memory storage device and communication interface . Computer system includes at least one processor for processing information. Computer system also includes the main memory such as a random access memory RAM or other dynamic storage device for storing information and instructions to be executed by processor . Main memory also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor . Computer system may also include a read only memory ROM or other static storage device for storing static information and instructions for processor . The storage device such as a magnetic disk or optical disk is provided for storing information and instructions. The communication interface may enable the computer system to communicate with one or more networks through use of the network link and any one of a number of well known transfer protocols e.g. Hypertext Transfer Protocol HTTP . Examples of networks include a local area network LAN a wide area network WAN the Internet mobile telephone networks Plain Old Telephone Service POTS networks and wireless data networks e.g. WiFi and WiMax networks . Computer system can also include an automatic core analyzer and debugger for the analysis and debugging of crash dumps in accordance with some aspects.

Examples described herein are related to the use of computer system for implementing the techniques described herein. According to one embodiment those techniques are performed by computer system in response to processor executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory from another machine readable medium such as storage device . Execution of the sequences of instructions contained in main memory causes processor to perform the process steps described herein. In alternative aspects hard wired circuitry may be used in place of or in combination with software instructions to implement aspects described herein. Thus aspects described are not limited to any specific combination of hardware circuitry and software.

Although illustrative aspects have been described in detail herein with reference to the accompanying drawings variations to specific examples and details are encompassed by this disclosure. It is intended that the scope of examples described herein be defined by claims and their equivalents. Furthermore it is contemplated that a particular feature described either individually or as part of an embodiment can be combined with other individually described features or parts of other aspects. Thus absence of describing combinations should not preclude the inventor s from claiming rights to such combinations.

