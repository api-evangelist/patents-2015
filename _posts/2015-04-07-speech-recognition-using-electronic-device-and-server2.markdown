---

title: Speech recognition using electronic device and server
abstract: An electronic device is provided. The electronic device includes a processor configured to perform automatic speech recognition (ASR) on a speech input by using a speech recognition model that is stored in a memory and a communication module configured to provide the speech input to a server and receive a speech instruction, which corresponds to the speech input, from the server. The electronic device may perform different operations according to a confidence score of a result of the ASR. Besides, it may be permissible to prepare other various embodiments speculated through the specification.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09640183&OS=09640183&RS=09640183
owner: Samsung Electronics Co., Ltd.
number: 09640183
owner_city: Suwon-si
owner_country: KR
publication_date: 20150407
---
This application claims the benefit under 35 U.S.C. 119 e of a U.S. Provisional application filed on Apr. 7 2014 in the U.S. Patent and Trademark Office and assigned Ser. No. 61 976 142 and under 35 U.S.C. 119 a of a Korean patent application filed on Mar. 20 2015 in the Korean Intellectual Property Office and assigned Serial Number 10 2015 0038857 the entire disclosure of each of which is hereby incorporated by reference.

The present disclosure relates to a technology for executing speech instructions to speech inputs of users by using a speech recognition model which is equipped in an electronic device and a speech recognition model available in a server.

In addition to traditional input methods of using a keyboard or a mouse recent electronic devices may support input operations using speech. For example electronic devices such as smart phones or tablet computers may perform an operation of analyzing a user s speech that is input during a specific function e.g. S Voice or Siri converting the speech into text or executing a function corresponding to the speech. Some electronic devices may normally remain in an always on state for speech recognition such that they may awake or be unlocked upon detection of speech and perform functions of Internet surfing telephone conversations SMS e mail readings etc.

Although many technologies have been proposed for speech recognition it is inevitable to encounter limitations to speech recognition in electronic devices. For example electronic devices may use speech recognition models which are embedded therein for quick response to speech recognition. However the capacities of electronic devices are limited which may cause a restriction in the number or kinds of recognizable speech inputs.

To obtain more accurate and reliable results for speech recognition electronic devices may transmit speech inputs to a server to request the server to recognize the speech inputs provide results which are fed back from the server or perform specific operations with reference to the fed back results. However that manner could increase an amount of communication traffic through the electronic devices and cause relatively slow response rates.

The above information is presented as background information only to assist with an understanding of the present disclosure. No determination has been made and no assertion is made as to whether any of the above might be applicable as prior art with regard to the present disclosure.

Aspects of the present disclosure are to address at least the above mentioned problems and or disadvantages and to provide at least the advantages described below. Accordingly an aspect of the present disclosure is to provide a speech recognition method capable of utilizing two or more different speech recognition capabilities or models to diminish inefficiency that may be encountered during the aforementioned diverse situations.

In accordance with an aspect of the present disclosure an electronic device is provided. The electronic device includes a processor configured to perform an automatic speech recognition ASR on a speech input by using a speech recognition model that is stored in a memory and a communication module configured to provide the speech input to a server and receive a speech instruction which corresponds to the speech input from the server. The processor may further perform an operation corresponding to a result of the ASR if a confidence score of the ASR result is higher than a first threshold and provide a feedback if a confidence score of the ASR result is lower than a second threshold.

In accordance with another aspect of the present disclosure a method of executing speech recognition in an electronic device is provided. The method includes obtaining a speech input from a user generating a speech signal corresponding to the obtained speech performing first speech recognition on at least a part of the speech signal acquiring first operation information and a first confidence score transmitting at least a part of the speech signal to a server for second speech recognition receiving second operation information which corresponds to the transmitted signal from the server performing a function corresponding to the first operation information if the first confidence score is higher than a first threshold value providing a feedback if the first confidence score is lower than a second threshold value and performing a function corresponding to the second operation information if the first confidence score is between the first threshold value and second threshold value.

In accordance with an aspect of the present disclosure it may be advantageous to increase a response rate and accuracy by executing speech recognition by using a speech recognition model which is prepared for an electronic device in itself and using a result of speech recognition supplementary from a server which refers to a result of the speech recognition by the speech recognition model.

Additionally it may be permissible to compare results of speech recognition between an electronic device and a server and reflect a result of the comparison to a speech recognition model or algorithm. Then it may be possible to continuously improve accuracy and response rate to permit repetitive speech recognition.

Other aspects advantages and salient features of the disclosure will become apparent to those skilled in the art from the following detailed description which taken in conjunction with the annexed drawings discloses various embodiments of the present disclosure.

Throughout the drawings it should be noted that like reference numbers are used to depict the same or similar elements features and structures.

The following description with reference to the accompanying drawings is provided to assist in a comprehensive understanding of various embodiments of the present disclosure as defined by the claims and their equivalents. It includes various specific details to assist in that understanding but these are to be regarded as merely exemplary. Accordingly those of ordinary skill in the art will recognize that various changes and modifications of the various embodiments described herein can be made without departing from the scope and spirit of the present disclosure. In addition descriptions of well known functions and constructions may be omitted for clarity and conciseness.

The terms and words used in the following description and claims are not limited to the bibliographical meanings but are merely used by the inventor to enable a clear and consistent understanding of the present disclosure. Accordingly it should be apparent to those skilled in the art that the following description of various embodiments of the present disclosure is provided for illustration purpose only and not for the purpose of limiting the present disclosure as defined by the appended claims and their equivalents.

It is to be understood that the singular forms a an and the include plural referents unless the context clearly dictates otherwise. Thus for example reference to a component surface includes reference to one or more of such surfaces.

As used herein the terms have may have include comprise or may include comprise indicate the existence of a corresponding feature e.g. numerical values functions operations or components elements but do not exclude the existence of other features.

As used herein the terms A or B at least one of A or and B or one or more of A or and B may include all allowable combinations. For instance the terms at least one of A and B or at least one of A or B may indicate 1 to include at least one A 2 to include at least one B or 3 to include both at least one A and at least one B.

As used herein the terms such as 1st 2nd first second and the like used herein may refer to modifying various different elements of various embodiments but do not limit the elements. For instance such terms do not limit the order and or priority of the elements. Furthermore such terms may be used to distinguish one element from another element. For instance both a first user device and a second user device indicate a user device but indicate different user devices from each other. For example a first component may be referred to as a second component and vice versa without departing from the scope of the present disclosure.

As used herein when one element e.g. a first element is referred to as being operatively or communicatively connected with to or connected with to another element e.g. a second element it should be understood that the former may be directly coupled with the latter or connected with the latter via an intervening element e.g. a third element . But it will be understood that when one element is referred to as being directly coupled or directly connected with another element it means that there any intervening element is not existed between them.

In the description or claims the term configured to or set to may be changeable with other implicative meanings such as suitable for having the capacity of designed to adapted to made to or capable of and may not simply indicate specifically designed to. Alternatively in some circumstances a term such as a device configured to may indicate that the device may do something together with other devices or components. For instance the term a processor configured to or set to perform A B and C may indicate a generic purpose processor e.g. CPU or application processor capable of performing its relevant operations by executing one or more software or programs stored in an exclusive processor e.g. embedded processor which is prepared for the operations or in a memory.

The terms in this specification are used to describe embodiments of the present disclosure and are not intended to limit the scope of the present disclosure. The terms of a singular form may include plural forms unless otherwise specified. Unless otherwise defined all the terms used herein which include technical or scientific terms may have the same meaning that is generally understood by a person skilled in the art. It will be further understood that terms which are defined in a dictionary and commonly used should also be interpreted as is customary in the relevantly related art and not in an idealized or overly formal sense unless expressly so defined herein in various embodiments of the present disclosure. In some cases terms even defined in the specification may not be understood as excluding embodiments of the present disclosure.

Hereinafter an electronic device according to various embodiments of the present disclosure will be described in more detail with reference to the accompanied drawings. In the following description the term user in various embodiments may refer to a person using an electronic device or a device using an electronic device for example an artificial intelligent electronic device .

Referring to the electronic device may include a configuration such as a user equipment UE . For example the UE may include a microphone microphone a controller an Automatic Speech Recognition ASR module an ASR model a transceiver a speaker and a display . The configuration of the UE shown in is provided as an example. Thus it may be modified by way of various alternative embodiments of the present disclosure. For instance the electronic device may include a configuration such as a UE shown in an electronic device shown in or an electronic device shown in or may be properly modified with those configurations. Hereinafter various embodiments of the present disclosure will be described with reference to the UE .

The UE may obtain a speech input through the microphone from a user. For instance if a user executes an application which is relevant to speech recognition or if an operation of speech recognition is in activation the user s speech may be obtained by the microphone . The microphone may include an analog digital converter ADC to convert an analog signal into a digital signal. In some embodiments an ADC a digital analog converter DAC a circuit processing diverse signals or a pre processing circuit may be included in the controller .

The controller may provide a speech input which is obtained by the microphone and an audio signal or speech signal which is generated from a speech input to the ASR module and the transceiver . An audio signal provided to the ASR module by the controller may be a signal which is pre processed for speech recognition. For instance an audio signal may be a signal which is noise filtered or processed to be pertinent to human voice by an equalizer. Otherwise a signal provided to the transceiver by the controller may be a speech input itself. Different from the ASR module the controller may transmit original speech data to the transceiver to control a server to work with a pertinent or more functional audio signal processing operation.

The controller may control general operations of the UE . For instance the controller may control an operation for a speech input from a user an operation of speech recognition and execution of functions according to speech recognition.

The ASR module may perform speech recognition on an audio signal which is provided from the controller . The ASR module may perform functions of isolated word recognition connected word recognition and large vocabulary recognition. The ASR performed by the ASR module may be implemented in a speaker independent or speaker dependent type. The ASR module may not be limited to a single speech recognition engine and may be formed of two or more speech recognition engines. Additionally if the ASR module includes a plurality of speech recognition engines each speech recognition engine may be different one another in direction of recognition. For instance one speech recognition engine may recognize wakeup speech e.g. Hi. Galaxy for activating an ASR function while the other speech recognition engine may recognize command speech e.g. Read a recent e mail. The ASR module may perform speech recognition with reference to the ASR model . Therefore it may be permissible to determine a range e.g. kind or number of speech input which is recognizable by the ASR model . The aforementioned description about the ASR module may be applicable even to an ASR module belonging to the server which will be described later.

The ASR module may convert a speech input into a text. The ASR module may determine an operation or function which is to be performed by the electronic device in response to a speech input. Additionally the ASR module may determine a confidence score or score of a result of ASR.

The ASR model may include grammar. Here grammar may include various types of grammar which is statistically generated through a user s input or on the World Wide Web in addition to linguistic grammar. In various embodiments of the present disclosure the ASR model may include an acoustic model and a language model. Otherwise the ASR model may be a speech recognition model which is used for isolated word recognition. In various embodiments of the present disclosure the ASR model may include a recognition model for performing speech recognition in a pertinent level in consideration of arithmetic and storage capacities of the UE . For instance the grammar may regardless of linguistic grammar include grammar for a designated instruction structure. For example call user name corresponds to grammar for sending a call to a user of user name and may be included in the ASR model .

The transceiver may transmit a speech signal which is provided from the controller to the server by way of a network . Additionally the transceiver may receive a result of speech recognition which corresponds to the transmitted speech signal from the server .

The speaker and the display may be used for interacting with a user s input. For instance if a speech input is provided from a user through the microphone a result of speech recognition may be expressed in the display and output through the speaker . Needless to say the speaker and the display may also perform general functions of outputting sound and a screen in the UE .

The server may include a configuration for performing speech recognition with a speech input which is provided from the UE by way of the network . Then partial elements of the server may correspond to the UE . For instance the server may include a transceiver a controller the ASR module and an ASR model . Additionally the server may further include an ASR model converter or a natural language processing NLP unit .

The controller may control functional modules for performing speech recognition in the server . For instance the controller may be coupled with the ASR module and or the NLP . Additionally the controller may cooperate with the UE to perform a function relevant to recognition model update. Additionally the controller may perform a pre processing operation with a speech signal which is transmitted by way of the network and provide a pre processed speech signal to the ASR module . This pre processing operation may be different from the pre processing operation which is performed in the UE in type or effect. In some embodiments the controller of the server may be referred to as an orchestrator.

The ASR module may perform speech recognition with a speech signal which is provided from the controller . The above description regarding the ASR module may be at least partially applied to the ASR module . While the ASR module for the server and the ASR module for the UE are described as performing partially similar functions they may be different each other in functional boundary or algorithm. The ASR module may perform speech recognition with reference to the ASR model and then generate a result that is different from a speech recognition result of the ASR module of the UE . In more detail the server may generate a recognition result through the ASR module and the NLP by means of speech recognition natural language understanding NLU Dialog Management DM or a combination thereof while the UE may generate a recognition result through the ASR module . For instance first operation information and a first confidence score may be determined after an ASR operation of the ASR module and second operation information and a second confidence score may be determined after an ASR operation of the ASR module . In some embodiments results from the ASR modules and may be identical to each other or may be different in at least one part. For instance the first operation information corresponds to the second operation information but the first confidence score may be higher than the second confidence score. In various embodiments of the present disclosure an ASR operation performed by the ASR module of the UE may be referred to as first speech recognition while an ASR operation performed by the ASR module of the server may be referred to as second speech recognition. 

In various embodiments of the present disclosure if the first speech recognition performed by the ASR module is different from the second speech recognition performed by the ASR module in algorithm or in usage model the ASR model converter may be included in the server to change a model type between them.

Additionally the server may include the NLP for sensing a user s intention and determining a function which is to be performed with reference to a recognition result of the ASR module . The NLP may perform natural word understanding which mechanically analyzes an effect of words spoken by humans and then makes the words into computer recognizable words or reversely a natural word processing that expresses human understandable words from the computer recognizable words.

Referring to an electronic device is exemplified in a configuration different from that of . However a speech recognition method disclosed in this specification may also be performed by an electronic device user equipment shown in or some of which will be described below by another device which can be modifiable or variable from the electronic device user equipment.

Referring to a UE may include a processor and a memory . The processor may include an ASR engine for performing speech recognition. The memory may store an ASR model which is used by the ASR engine to perform speech recognition. For instance considering functions performed by elements of the configuration it can be seen that the processor the ASR engine and the ASR model or the memory of may correspond respectively with the controller the ASR model and the ASR model of . Thus a duplicative description will not be further offered hereinafter.

The UE may obtain a speech input from a user by using a speech recognition i.e. acquisition module e.g. the microphone . The processor may perform an ASR operation to the obtained speech input by means of the ASR model which is stored in the memory . Additionally the UE may provide a speech input to the server by way of a communication module and receive a speech instruction e.g. a second operation information which corresponds to an speech input from the server . The UE may output a speech recognition result which is acquisitive by the ASR engine and the server through a display or speaker .

Referring to the UE may obtain a user s speech input by using a speech acquisition module such as microphone in operation . This operation may be performed in the state that the user executes a specific function or application which is relevant to speech recognition. But in some embodiments speech recognition of the UE may be conditioned in an always on state e.g. the microphone is normally turned on for which operation may be normally active to a user s speech. Otherwise an ASR operation may be conditioned to be an active state by different speech recognition engines in response to a specific speech input e.g. Hi Galaxy as aforementioned and then performed with subsequently input speech recognition information.

In operation the UE may transmit a speech signal or at least a part of a speech signal to the server . In an internal view for the device a speech signal e.g. an audio signal made by a speech input is converted into a digital speech signal and by pre processing the speech signal may be provided to the ASR module by a processor e.g. the controller . In other words in operation the UE may provide a speech signal which is regarded as a target of recognition to an ASR module which is placed in and out of a device capable of performing speech recognition. The UE may utilize all of speech recognition capabilities that are prepared in itself and the server .

In operation the UE may perform speech recognition by itself. This speech recognition may be referred to as ASR. For instance the ASR module may perform speech recognition with a speech input by using the ASR model . For instance the ASR model may perform ASR with at least a part of a speech signal. After performing ASR a result of speech recognition may be obtained. For instance if a user provides a speech input such as tomorrow weather the UE may determine operation information such as weather application tomorrow weather output by using a function of speech recognition to the speech input. Additionally a result of speech recognition may include a confidence score of operation information. For instance although the ASR module may determine a confidence score of 95 if a user s speech is analyzed as clearly indicating tomorrow weather the ASR module may also give a confidence score of 60 to a determined operation information even if a user s speech is analyzed as being vague to indicate everyday weather or tomorrow weather. 

In operation a processor may determine whether a confidence score is higher than a threshold. For instance if a confidence score of operation information determined by the ASR module is higher than a predetermined level e.g. 80 the UE may perform ASR i.e. an operation corresponding to a speech instruction recognized by a speech recognition function of the UE in itself in operation . This operation may be performed with at least one function that is practicable by the processor at least one application or at least one of inputs based on an execution result of ASR operation.

Operation may be performed before a speech recognition result is received from the server e.g. before operation . In other words if speech recognition self performed by the UE results in a sufficient confidence score to recognize a speech instruction the UE may directly perform a corresponding operation without waiting for an additional result of speech recognition which is received from the server to provide a quick response time to a user s speech input.

If a confidence score is less than the threshold in operation the UE may be maintained in a standby state until a speech recognition result is received from the server . During the standby state the UE may display a suitable message icon or image to inform a user that speech recognition is operating to the speech input.

In operation speech recognition by the server may be performed with a speech signal which is transmitted to the server in operation . This speech recognition may be referred to as ASR. Additionally an NLP may be performed in operation . For instance an NLP may be performed with a speech input or a recognition result of ASR by using the NLP . In some embodiments this operation may be performed by selection of the user.

In operation if speech recognition results e.g. a second operation information and a second confidence score of ASR ASR or NLP are received from the server operation may include an operation corresponding to a speech instruction e.g. second operation information by way of ASR. Since operation needs to allow an additional time for transmitting a speech signal at operation and acquiring a speech recognition result at operation it takes a longer time than operation . However it may be possible to perform a speech recognition operation with higher confidence score and accuracy even in comparison with a case of speech recognition that operation is incapable of self processing or capable of self processing but resulting in a low confidence score.

Referring to as speech recognition operation speech signal transmit operation ASR operation ASR operation and NLP operation correspond respectively to the aforementioned operations and those operations will not be further described below.

A speech recognition method described in conjunction with may be performed by referring to two thresholds. Based on a first threshold and a second threshold that is lower than the first threshold in confidence score different operations e.g. operations and respectively may be performed respectively for the cases that a confidence score of ASR result from operation is 1 higher than the second threshold 2 lower than the second threshold and 3 between the first and second thresholds.

If a confidence score is determined as being higher than the first threshold in operation the UE may perform an operation corresponding to an ASR result in operation . If a confidence score is determined as being lower than the first threshold in operation the process may go to determine whether the confidence score is lower than the second threshold in operation .

In operation if a confidence score is lower than the second threshold the UE may provide a feedback for the confidence score. This feedback may include a message or an audio output which indicates that a user s speech input was abnormally recognized or normally recognized but in lack of confidence. For instance the UE may display or output a guide message such as Your speech is not recognized Please speak again through a screen or a speaker. Otherwise the UE may confirm accuracy of a low confident recognition result by guiding a user to a relatively easy recognizable speech input e.g. Yes Not No Impossible Never and so on by way of a feedback such as Did you speak XXX 

Once a feedback is provided in operation operation may not be performed even if a speech recognition result is obtained in operation along a lapse of time later. This is because a feedback may cause a new speech input from a user and then it may be unreasonable to perform an operation with the previous speech input. But in some embodiments operation may be performed after operation if there is no additional input from a user for a predetermined time despite a feedback of operation and if a speech recognition result e.g. a second operation information and a second confidence score which is received from the server in operation satisfies a predetermined condition e.g. the second confidence score is higher than the first threshold or a certain third threshold .

In operation if a confidence score obtained from operation is higher than the second threshold i.e. the confidence score ranks between the first and second thresholds the UE may receive a speech recognition result from the server in operation . In operation the UE may perform an operation which corresponds to a speech instruction second operation information by way of ASR.

In the embodiment shown in it may be permissible to differentiate a confidence score which results from speech recognition by the UE into a usable level with reference to usable and unusable levels and an ASR result of the server and then enable an operation that is pertinent to the differentiated confidence score. Especially if a confidence score is excessively low the UE may provide a feedback regardless of reception of a result from the server to guide a user to a speech re input and may thereby prevent a message such as not recognized from being provided to a user after a long time from a response standby time.

Referring to as speech acquisition operation speech signal transmit operation ASR operation ASR operation and NLP operation correspond respectively to the aforementioned operations and those operations will not be further described below.

If a confidence score of a result from ASR is determined to be larger than a threshold e.g. a first threshold in operation the process may go to operation to perform an operation corresponding to a speech instruction e.g. first operation information by way of ASR. If a confidence score of an ASR result is determined as being lower than the threshold an operation subsequent to operation of or operation of may be performed.

In the embodiment of even after operation the process may not be terminated but may continue to perform operations through . In operation the UE may receive a speech recognition result from the server . For instance the UE may obtain second operation information and a second confidence score which result from ASR to a speech signal transmitted during operation .

In operation the UE may compare ASR with ASR in recognition result. For instance the UE may determine whether recognition results from ASR and ASR are identical to or different from each other. For instance if ASR recognizes speech as Tomorrow weather and ASR recognizes speech as Tomorrow weather both may include operation information such as Output weather application Output tomorrow weather. In this case it can be understood that such recognition results of ASR and ASR may correspond each other. Otherwise if different operations are performed after speech recognition the two or more speech recognition results may be determined as none corresponding each other.

In operation the UE may change a threshold by comparing a result of ASR self operation of speech recognition in the UE with a speech instruction which is received from the server . For instance the UE may decrease the first threshold if the first operation information and the second operation information are identical each other or include a speech instruction corresponding thereto. For instance for a certain speech input a general method is designed to control a speech recognition result by itself from the UE not to be adopted without waiting for a response from the server until a confidence score reaches 80 whereas this method may be designed to control a confidence score higher even than 70 to enable a speech recognition result by itself from the UE to be adopted by way of threshold update. Threshold update may be resumed whenever a user plays the speech recognition function and thus it may shorten a response time because speech recognition frequently operating by a user is set to have a lower threshold.

In the meantime if ASR is different from ASR in result the threshold may increase. In some embodiments an operating of updating a threshold may occur after a predetermined condition is accumulated as many as the predetermined number of times. For instance for a certain speech input if results from ASR and ASR agree with each other in more than five times a threshold may be updated lower.

Referring to as speech recognition operation speech signal transmit operation ASR operation ASR operation and NLP operation correspond respectively to the aforementioned operations and those operations will not be further described below.

In operation if a confidence score of a result of ASR is determined as being greater than a threshold e.g. a first threshold an operation subsequent to operation of operation of and operation of may be performed.

If a confidence score of a result of ASR is determined as being lower than the threshold in operation the UE may receive a speech recognition result from the server in operation and in operation perform an operation corresponding to a speech instruction by way of ASR. Operations and may correspond to operations and of or operations and of .

In operation the UE may compare ASR with ASR in speech recognition result. Operation may correspond to operation of .

In operation the UE may update its own speech recognition model e.g. the ASR model with reference to a comparison result from operation . For instance the UE may add a speech recognition result e.g. second operation information or the second operation information and a second confidence score of ASR which is generated in response to a speech input to the speech recognition model. For instance if the first operation information does not correspond to the second operation information the UE may add the second operation information and the second confidence score to a speech recognition model which is used for the first speech recognition with reference to the first and second confidence scores e.g. if the second confidence score is higher than the first confidence score . Similar to the embodiment shown in an operation of updating a speech recognition model may occur after a predetermined condition is accumulated a predetermined number of times.

Referring to an electronic device may be situated in a network environment in accordance with various embodiments. The electronic device may include a bus a processor a memory an input output I O interface a display and a communication interface . In some embodiments the electronic device may be organized without at least one of the elements or comprised of another additional element.

The bus may include for example a circuit to interconnect the elements and help communication e.g. control messages and or data between the elements.

The processor may include one or more of central processing unit CPU application processor AP or communication processor CP . The processor may perform for example an arithmetic operation or data processing to control and or communicate at least one of other elements.

The memory may include a volatile and or nonvolatile memory. The memory may store for example instructions or data that are involved in at least one of other elements. According to an embodiment the memory may store a software and or program . The program may include for example a kernel a middleware an application programming interface API and or application programs or application . At least one of the kernel the middleware or the API may be called Operating System OS . 

The kernel may control or manage for example system resources e.g. the bus the processor or the memory which are used for executing an operation or function implemented embodied in other programs e.g. the middleware the API or the application programs . Additionally the kernel may provide an interface capable of controlling or managing system resources by approaching individual elements of the electronic device in the middleware the API or the application programs .

The middleware may intermediate for example to manage the API or the application programs to communicate data with the kernel .

Additionally the middleware may process one or more work requests which are received from the application programs in priority. For instance the middleware may allow at least one of the application programs to have priority capable of using a system resource e.g. the bus the processor or the memory of the electronic device . For instance the middleware may perform scheduling or load balancing to the at least one or more work requests by processing the at least one or more work requests in accordance with the priority allowed for the at least one of the application programs .

The API as an interface necessary for the application to control a function that is provided from the kernel or the middleware may be include foe example at least one interface or function e.g. instruction for file control window control or character control.

The I O interface may act for example as an interface capable of transmitting instructions or data which are input from a user or another external system to another element or other elements of the electronic device . Additionally the I O interface may output instructions or data which are received from another element or other elements of the electronic device to a user or another external system.

The display may include for example a Liquid Crystal Display LCD a light emission diode LED an organic light emission Diode OLED display or a micron electro mechanical system MEMS display or an electronic paper display. The display may express for example diverse contents e.g. text image video icon or symbol to a user. The display may include a touch screen and for example receive an input by touch gesture approach or hovering which is made with a part of a user s body or an electronic pen.

The communication interface may set for example communication between the electronic device and an external device e.g. a first external electronic device a second external electronic device or a server . For instance the communication interface may communicate with the external device e.g. the second external electronic device or the server in connection with a network through wireless or wired communication.

Wireless communication may adopt at least one of LTE LTE A CDMA WCDMA UMTS WiBro and GSM for cellular communication protocol. Additionally wireless may include for example a local area communication . The local area communication may include for example at least one of Wi Fi Bluetooth near field communication NFC or global positioning system GPS . Wired communication may include for example at least one of universal serial bus USB high definition multimedia Interface HDMI recommended standard 832 RS 232 and plain old telephone server POTS . The network may include a communication network for example at least one of a computer network e.g. LAN or WAN the Internet and a telephone network.

The first and second external electronic devices and may be same with or different from the electronic device . According to an embodiment the server may include one or more groups of servers. In various embodiments of the present disclosure all or a part of operations performed in the electronic device may be also performed in another one or a plurality of electronic devices e.g. the electronic devices and or the server . According to an embodiment if there is a need to perform some function or service by automation or request the electronic device may request another device e.g. the electronic device or or the server to perform such function or service instead of executing the function or service in itself or request such other devices to perform the function or service to perform in addition to its self execution. Such another electronic device e.g. the electronic device or or the server may perform the requested function or service and then transmit a result thereof to the electronic device . The electronic device may process the received result directly or additionally to provide the requested function or service. For this operation for example it may be allowable to employ cloud computing dispersion computing or client server computing technology.

Referring to an electronic device may include for example all or a part of elements of the electronic device shown in . Referring to the electronic device may include at least one of one or more Application Processors AP a communication module a subscriber identification module e.g. SIM card a memory a sensor module an input unit a display an interface an audio module a camera module a power management module a battery an indicator or a motor .

The processor AP may drive an OS or an application to control a plurality of hardware or software elements connected to the processor and may process and compute a variety of data including multimedia data. The processor may be implemented with a system on chip SoC for example. According to an embodiment the AP may further include a graphic processing unit GPU and or an image signal processor. The processor may even include at least a part of the elements shown in . The processor may process instructions or data which are received from at least one of other elements e.g. a nonvolatile memory and then store diverse data into such a nonvolatile memory.

The communication module may have a configuration same with or similar to the communication interface of . The communication module may include a cellular module a WiFi module a Bluetooth BT module a GPS module an NFC module and a radio frequency RF module .

The cellular module may provide voice call video call a character service or an Internet service through a communication network. According to an embodiment the cellular module may perform discrimination and authentication of an electronic device within a communication network using a subscriber identification module e.g. a SIM card . According to an embodiment the cellular module may perform at least a portion of functions that the AP provides. According to an embodiment the cellular module may include a CP.

Each of the WiFi module the Bluetooth module the GPS module and the NFC module may include a processor for processing data exchanged through a corresponding module for example. In some embodiments at least a part e.g. two or more elements of the cellular module the WiFi module the Bluetooth module the GPS module and the NFC module may be included within one integrated circuit IC or an IC package.

The RF module may transmit and receive for example communication signals e.g. RF signals . The RF module may include a transceiver a power amplifier module PAM a frequency filter a low noise amplifier LNA or an antenna. According to another embodiment at least one of the cellular module the WiFi module the Bluetooth module the GPS module and the NFC module may transmit and receive an RF signal through a separate RF module.

The SIM card may include for example a card which has a subscriber identification module and or an embedded SIM and include unique identifying information e.g. Integrated Circuit Card Identifier ICCID or subscriber information e.g. Integrated Mobile Subscriber Identify IMSI .

The memory e.g. the memory may include for example an embedded memory or an external memory . For example the embedded memory may include at least one of a volatile memory e.g. a dynamic RAM DRAM a static RAM SRAM a synchronous dynamic RAM SDRAM etc. a nonvolatile memory e.g. a one time programmable ROM OTPROM a programmable ROM PROM an erasable and programmable ROM EPROM an electrically erasable and programmable ROM EEPROM a mask ROM a flash ROM a NAND flash memory a NOR flash memory etc. a hard drive or solid state drive SSD .

The external memory may further include a flash drive for example a compact flash CF a secure digital SD a micro secure Digital SD a mini SD an extreme Digital xD or a memory stick. The external memory may be functionally connected with the electronic device through various interfaces.

The sensor module may measure for example a physical quantity or detect an operation state of the electronic device to convert the measured or detected information to an electric signal. The sensor module may include at least one of a gesture sensor A a gyro sensor B a pressure sensor C a magnetic sensor D an acceleration sensor E a grip sensor F a proximity sensor G a color sensor H e.g. RGB sensor a living body sensor I a temperature humidity sensor J an illuminance sensor K or an UV sensor M. Additionally or generally though not shown the sensor module may further include an E nose sensor an electromyography sensor EMG sensor an electroencephalogram EEG sensor an ElectroCardioGram ECG sensor a photoplethysmography PPG sensor an infrared IR sensor an iris sensor or a fingerprint sensor for example. The sensor module may further include a control circuit for controlling at least one or more sensors included therein. In some embodiments the electronic device may further include a processor which is configured to control the sensor module as a part or additional element thus enabling to control the sensor module while the processor is in a sleep state.

The input unit may include for example a touch panel a digital pen sensor a key or an ultrasonic input unit . The touch panel may recognize for example a touch input using at least one of a capacitive type a resistive type an infrared type or an ultrasonic wave type. Additionally the touch panel may further include a control circuit. The touch panel may further include a tactile layer to provide a tactile reaction for a user.

The digital pen sensor may be a part of the touch panel or a separate sheet for recognition. The key for example may include a physical button an optical key or a keypad. The ultrasonic input unit may allow the electronic device to detect a sound wave using a microphone e.g. a microphone and determine data through an input tool generating an ultrasonic signal.

The display e.g. the display may include a panel a hologram device or a projector . The panel may include the same or similar configuration with the display of . The panel for example may be implemented to be flexible transparent or wearable. The panel and the touch panel may be implemented with one module. The hologram device may show a three dimensional image in a space using interference of light. The projector may project light onto a screen to display an image. The screen for example may be positioned in the inside or outside of the electronic device . According to an embodiment the display may further include a control circuit for controlling the panel the hologram device or the projector .

The interface for example may include a high definition Multimedia interface HDMI a USB an optical interface or a D sub D subminiature . The interface may include for example the communication interface shown in . The interface for example may include a mobile high definition Link MHL interface an SD card multi media cared MMC interface or an Infrared Data Association IrDA standard interface.

The audio module may convert a sound and an electric signal in dual directions. At least one element of the audio module may include for example the I O interface shown in . The audio module for example may process sound information that is input or output through a speaker a receiver an earphone or the microphone .

The camera module may be a unit which is capable of taking a still picture and a moving picture. According to an embodiment the camera module may include one or more image sensors e.g. a front sensor or a rear sensor a lens an image signal processor ISP or a flash e.g. an LED or a xenon lamp .

The power management module may manage for example power of the electronic device . The power management module may include for example a power management integrated Circuit PMIC a charger IC or a battery or fuel gauge. The PMIC may operate in wired and or wireless charging mode. A wireless charging mode may include for example diverse types of magnetic resonance magnetic induction or electromagnetic wave. For the wireless charging an additional circuit such as a coil loop circuit a resonance circuit or a rectifier may be further included therein. The battery gauge for example may measure a remnant of the battery a voltage a current or a temperature for example during charging. The battery may measure for example a residual capacity a voltage on charge a current or temperature thereof. The battery may include for example a rechargeable battery and or a solar battery.

The indicator may display the following specific state of the electronic device or a part e.g. the AP thereof a booting state a message state or a charging state. The motor may convert an electric signal into mechanical vibration and generate a vibration or haptic effect. Although not shown the electronic device may include a processing unit e.g. a GPU for supporting a mobile TV. The processing unit for supporting the mobile TV for example may process media data that is based on the standard of digital multimedia broadcasting DMB digital video broadcasting DVB or media flow MediaFlo .

Each of the above components or elements of the electronic device according to an embodiment of the present disclosure may be implemented using one or more components and a name of a relevant component may vary with on the kind of the electronic device. The electronic device according to various embodiments of the present disclosure may include at least one of the above components. Also a part of the components may be omitted or additional other components may be further included. Also some of the components of the electronic device according to the present disclosure may be combined to form one entity thereby making it possible to perform the functions of the relevant components substantially the same as before the combination.

The term module used for the present disclosure for example may mean a unit including one of hardware software and firmware or a combination of two or more thereof. A module for example may be interchangeably used with terminologies such as a unit logic a logical block a component a circuit etc. The module may be a minimum unit of a component integrally configured or a part thereof. The module may be a minimum unit performing one or more functions or a portion thereof. The module may be implemented mechanically or electronically. For example the module according to the present disclosure may include at least one of an application specific integrated circuit ASIC chip performing certain operations a field programmable gate arrays FPGAs or a programmable logic device known or to be developed in the future.

At least a part of an apparatus e.g. modules or functions thereof or method e.g. operations or operations according to various embodiments of the present disclosure for example may be implemented by instructions stored in a computer readable storage medium in the form of programmable module.

For example the storage medium may store instructions enabling during execution an operation or operation of allowing a processor of an electronic device to obtain a speech input and then generate a speech signal an operation of performing first speech recognition to at least a part of the speech signal to obtain first operation information and a first confidence score an operation of transmitting at least a part of the speech signal to a server for the second speech recognition and an operation of receiving second operation information to the signal transmitted from the server and functions of 1 corresponding to the first operation information if the first confidence score is higher than a first threshold 2 providing a feedback to the first confidence score if the first confidence score is lower than a second threshold and 3 corresponding to the second operation information if the first confidence score is between the first and second thresholds.

A module or programming module according to various embodiments of the present disclosure may include at least one of the above elements or a part of the above elements may be omitted or additional other elements may be further included. Operations performed by a module a programming module or other elements according to an embodiment of the present disclosure may be performed sequentially in parallel repeatedly or in a heuristic method. Also a portion of operations may be performed in different sequences omitted or other operations may be added.

While the present disclosure has been shown and described with reference to various embodiments thereof it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present disclosure as defined by the appended claims and their equivalents.

