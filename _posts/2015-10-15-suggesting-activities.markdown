---

title: Suggesting activities
abstract: A method includes receiving inputs indicative of a user state of a user. The received inputs include: 1) sensor inputs from one or more sensors; 2) application inputs received from one or more software applications; and/or 3) user inputs received from a graphical user interface. The method includes determining a collective user state of the user based on the received inputs and obtaining user data of other users that includes a collective user state of each corresponding other user. The method includes displaying, on a screen, other user glyphs representing the other users. Each other user glyph: 1) at least partially indicates the collective user state of the corresponding other user; and/or 2) is associated with a link to a displayable view indicating the collective user state of the corresponding other user and/or the inputs used to determine the collective user state of the corresponding other user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09460394&OS=09460394&RS=09460394
owner: Blackwerks LLC
number: 09460394
owner_city: Glen Ellyn
owner_country: US
publication_date: 20151015
---
This U.S. patent application claims priority under 35 U.S.C. 119 e to U.S. Provisional Application 62 064 053 filed Oct. 15 2014 which is hereby incorporated by reference in its entirety.

This disclosure relates to suggesting information and or activities to a user based on an assessment of the user s current state of being.

The use of mobile devices such as smartphones tablet PCs cellular telephones or portable digital assistants has become widespread. At their inception mobile devices were mainly used for voice communication but recently they have become a reliable source for performing a range of business and personal tasks. Mobile devices are useful to obtain information by using a data connection to access the World Wide Web. The user may input a search query on a search engine website using the mobile device to obtain requested information. The information may relate to a location of a restaurant hotel shopping center or other information. Users may use mobile devices for social media which allows the users to create share or exchange information and ideas in virtual communities or networks. Social media depends on mobile and web based technologies to allow people to share co create collaborate on discuss and modify user generated content.

One aspect of the disclosure provides a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The received inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface. The method includes determining by the data processing hardware possible activities for the user to perform based on the received inputs determining by the data processing hardware one or more predicted outcomes for each possible activity based on the received inputs and executing by the data processing hardware behaviors having corresponding objectives. Each behavior is configured to evaluate a possible activity based on whether the possible activity and the corresponding one or more predicted outcomes of the possible activity achieves the corresponding objective. The method further includes selecting by the data processing hardware one or more possible activities based on evaluations of one or more behaviors and outputting results including the selected one or more possible activities.

Another aspect includes a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The received inputs include one or more of sensor inputs from one or more sensors in communication with the data processing hardware application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or user inputs received from a graphical user interface. The method includes determining by the data processing hardware possible information for the user based on the received inputs and executing by the data processing hardware behaviors having corresponding objectives. Each behavior is configured to evaluate the possible information based on whether the possible information is related to the corresponding objective. The method includes selecting by the data processing hardware suggested information from the possible information based on evaluations of one or more behaviors for presentation to the user.

Implementations of the disclosure may include one or more of the following optional features. The received inputs may include biometric data of the user environmental data regarding a surrounding of the user and or application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware. In some implementations one or more behaviors elect to participate or not participate in evaluating the possible activities based on the received inputs. The method may include for each behavior determining whether any input of the received inputs is of an input type associated with the behavior and when an input of the received inputs is of an input type associated with the behavior incrementing an influence value associated with the behavior. When the influence value of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activities and when the influence value of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activities.

The method may include for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value of the behavior when the decrement criterion is satisfied. In some examples the decrement criterion is satisfied when a threshold period of time has passed since lasting incrementing the influence value. The evaluation of at least one behavior may be weighted based on the corresponding influence value of the at least one behavior.

In some implementations the method includes determining using the data processing hardware the possible activities based on one or more preferences of the user. At least one behavior may evaluate a possible activity based on at least one of a history of selected activities for the user or one or more preferences of the user. In some examples a first behavior evaluates a possible activity based on an evaluation by a second behavior of the possible activity.

Another aspect of the disclosure provides a system that includes data processing hardware and memory hardware in communication with the data processing hardware. The memory hardware stores instructions that when executed by the data processing hardware cause the data processing hardware to perform operations including receiving inputs indicative of a user state of a user. The received inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface. The operations include determining possible activities for the user to perform based on the received inputs determining one or more predicted outcomes for each possible activity based on the received inputs and executing behaviors having corresponding objectives. Each behavior is configured to evaluate a possible activity based on whether the possible activity and the corresponding one or more predicted outcomes of the possible activity achieves the corresponding objective. The operations further include selecting one or more possible activities based on evaluations of one or more behaviors and outputting results including the selected one or more possible activities.

Yet another aspect provides a system that includes data processing hardware and memory hardware in communication with the data processing hardware. The memory hardware stores instructions that when executed by the data processing hardware cause the data processing hardware to perform operations including receiving inputs indicative of a user state of a user. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or user inputs received from a graphical user interface. The operations include determining possible information for the user based on the received inputs and executing behaviors having corresponding objectives. Each behavior is configured to evaluate the possible information based on whether the possible information is related to the corresponding objective. The operations further include selecting suggested information from the possible information based on evaluations of one or more behaviors for presentation to the user.

Implementations of these aspects may include one or more of the following optional features. The received inputs may include biometric data of the user and or environmental data regarding a surrounding of the user. In some implementations one or more behaviors elect to participate or not participate in evaluating the possible activities based on the received inputs. The operations may include for each behavior determining whether any input of the received inputs is of an input type associated with the behavior and when an input of the received inputs is of an input type associated with the behavior incrementing an influence value associated with the behavior. When the influence value of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activities and when the influence value of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activities.

The operations may include for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value of the behavior when the decrement criterion is satisfied. In some examples the decrement criterion is satisfied when a threshold period of time has passed since lasting incrementing the influence value. The evaluation of at least one behavior may be weighted based on the corresponding influence value of the at least one behavior.

In some implementations the operations include determining using the data processing hardware the possible activities based on one or more preferences of the user. At least one behavior may evaluate a possible activity based on at least one of a history of selected activities for the user or one or more preferences of the user. In some examples a first behavior evaluates a possible activity based on an evaluation by a second behavior of the possible activity.

Another aspect of the disclosure provides a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on a screen in communication with the data processing hardware. The method includes determining using the data processing hardware a collective user state based on the received inputs and determining one or more possible activities for the user and one or more predicted outcomes for each activity based on the collective user state. The method includes executing at the data processing hardware one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The method further includes selecting using the data processing hardware one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities from the data processing hardware to the screen for display on the screen.

Implementations of the disclosure may include one or more of the following optional features. In some implementations the inputs include biometric data of the user and or environmental data regarding a surrounding of the user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well.

In some implementations the method includes querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The method may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the method may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The method may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the method may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the method includes selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The method may include combining selected activities and sending a combined activity in the results.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Another aspect of the disclosure provides a system that includes data processing hardware and non transitory memory in communication with the data processing hardware. The non transitory memory stores instructions that when executed by the data processing hardware cause the data processing hardware to perform operations that include receiving inputs indicative of a user state of a user. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on a screen in communication with the data processing hardware. The operations include determining a collective user state based on the received inputs determining one or more possible activities for the user and one or more predicted outcomes for each activity based on the collective user state and executing one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The operations further include selecting one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities to the screen for display on the screen.

In some implementations the inputs include biometric data of the user and or environmental data regarding a surrounding of the user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well.

In some implementations the operations include querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The operations may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the operations may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The operations may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the operations may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the operations include selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The operations may include combining selected activities and sending a combined activity in the results.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Another aspect of the disclosure provides a method that includes receiving at data processing hardware inputs indicative of a user state of each user of a group of users. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on one or more screens in communication with the data processing hardware. The method includes determining using the data processing hardware a collective user state for each user based on the received inputs e.g. inputs of that user and or inputs associated with other users in the group and determining one or more possible activities for group of users and one or more predicted outcomes for each activity based on the collective user states. The method includes executing at the data processing hardware one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The method further includes selecting using the data processing hardware one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities from the data processing hardware to the one or more screens for display on the one or more screens.

Implementations of the disclosure may include one or more of the following optional features. In some implementations the inputs include biometric data of at least one user and environmental data regarding a surrounding of the at least one user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well.

In some implementations the method includes querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The method may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the method may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The method may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the method may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the method includes selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The method may include combining selected activities and sending a combined activity in the results.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Another aspect of the disclosure provides a system that includes data processing hardware and non transitory memory in communication with the data processing hardware. The non transitory memory stores instructions that when executed by the data processing hardware cause the data processing hardware to perform operations that include receiving inputs indicative of a user state of each user of a group of users. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on one or more screens in communication with the data processing hardware. The operations include determining a collective user state for each user based on the received inputs e.g. inputs of that user and or inputs associated with other users in the group determining one or more possible activities for the group of users and one or more predicted outcomes for each activity based on the collective user states and executing one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The operations further include selecting one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities to the one or more screens for display on the one or more screens.

In some implementations the inputs include biometric data of at least one user and environmental data regarding a surrounding of at least one user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well.

In some implementations the operations include querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The operations may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the operations may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The operations may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the operations may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the operations include selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The operations may include combining selected activities and sending a combined activity in the results.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Yet another aspect of the disclosure provides a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on a screen in communication with the data processing hardware. In response to receiving a trigger sensor input the method includes determining using the data processing hardware a collective user state based on the received inputs and determining one or more possible activities for the user and one or more predicted outcomes for each activity based on the collective user state. The method includes executing at the data processing hardware one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The method further includes selecting using the data processing hardware one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities from the data processing hardware to the screen for display on the screen.

Implementations of the disclosure may include one or more of the following optional features. In some implementations the inputs include biometric data of the user and environmental data regarding a surrounding of the user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well. The trigger sensor input may be from the inertial measurement unit indicating a threshold amount of shaking of the inertial measurement unit e.g. indicating that a user is shaking a mobile device .

In some implementations the method includes querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The method may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the method may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The method may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the method may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the method includes selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The method may include combining selected activities and sending a combined activity in the results. The results may include one or more activity records where each activity record includes an activity description and an activity location. The method may include displaying on the screen a map and for each activity record displaying the activity location on the map and the activity description.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Another aspect of the disclosure provides a system that includes data processing hardware and non transitory memory in communication with the data processing hardware. The non transitory memory stores instructions that when executed by the data processing hardware cause the data processing hardware to perform operations that include receiving inputs indicative of a user state of a user. The inputs include sensor inputs from one or more sensors in communication with the data processing hardware and or user inputs received from a graphical user interface displayed on a screen in communication with the data processing hardware. In response to receiving a trigger sensor input the operations include determining a collective user state based on the received inputs determining one or more possible activities for the user and one or more predicted outcomes for each activity based on the collective user state and executing one or more behaviors that evaluate the one or more possible activities and or the corresponding one or more predicted outcomes. Each behavior models a human behavior and or a goal oriented task. The operations further include selecting one or more activities based on the evaluations of the one or more possible activities and or the corresponding one or more predicted outcomes and sending results including the selected one or more activities to the screen for display on the screen.

In some implementations the inputs include biometric data of the user and environmental data regarding a surrounding of the user. The one or more sensors may include at least one of a global positioning system a temperature sensor a camera a three dimensional volumetric point cloud imaging sensor a fingerprint reader a blood glucose monitor a skin PH meter an inertial measurement unit a microphone a blood oxygen meter a humidistat or a barometer. Other sensors are possible as well. The trigger sensor input may be from the inertial measurement unit indicating a threshold amount of shaking of the inertial measurement unit e.g. indicating that a user is shaking a mobile device .

In some implementations the operations include querying one or more remote data sources in communication with the data processing hardware to identify possible activities and or predicted outcomes. The operations may include determining using the data processing hardware the one or more possible activities and the one or more predicted outcomes for each activity based on one or more preferences of the user. Each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves an objective of the behavior. Moreover each behavior may evaluate an activity or a corresponding outcome positively when the activity or the corresponding outcome at least partially achieves a user preference stored in non transitory memory in communication with the data processing hardware. In some examples a first behavior evaluates an activity or a corresponding outcome based on an evaluation by a second behavior of the activity or the corresponding outcome. Each behavior may elect to participate or not participate in evaluating the one or more activities and or the one or more predicted outcomes for each activity based on the collective user state.

When an input is related to a behavior the operations may include incrementing an influence value associated with the behavior. The input is related to the behavior when the input is of an input type associated with the behavior. In some implementations the evaluations of each behavior can be weighted based on the influence value of the corresponding behavior. The operations may include decrementing the influence value of each behavior after a threshold period of time. When an influence value equals zero the operations may include deactivating the corresponding behavior. Any behaviors having an influence value greater than zero may participate in evaluating the activities or the corresponding outcomes and any behaviors having an influence value equal to zero may not participate in evaluating the activities or the corresponding outcomes.

In some implementations the operations include selecting for the results a threshold number of activities having the highest evaluations or a threshold number of activities having corresponding predicted outcomes that have the highest evaluations. The operations may include combining selected activities and sending a combined activity in the results. The results may include one or more activity records where each activity record includes an activity description and an activity location. The method may include displaying on the screen a map and for each activity record displaying the activity location on the map and the activity description.

The data processing hardware may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor. For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Another aspect provides a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The received inputs include one or more of 1 sensor inputs from one or more sensors in communication with the data processing hardware 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface. The method includes determining by the data processing hardware a collective user state of the user based on the received inputs and obtaining at the data processing hardware user data of other users. The user data of each other user includes a collective user state of the corresponding other user. The method includes displaying on a screen in communication with the data processing hardware other user glyphs representing the other users. Each other user glyph 1 at least partially indicates the collective user state of the corresponding other user and or 2 is associated with a link to a displayable view indicating the collective user state of the corresponding other user and or the inputs used to determine the collective user state of the corresponding other user.

In some implementations the method includes obtaining the user data of the other users that have corresponding collective user states satisfying a threshold similarity with the collective user state of the user. The method may include arranging each other user glyph on the screen based on a level of similarity between the collective user state of the user and the collective user state of the corresponding other user. In some examples a size a shape a color a border and or a position on the screen of each other user glyph is based on a level of similarity between the collective user state of the corresponding other user and the collective user state of the user.

The method may include displaying a user glyph representing the user in a center portion of the screen and the other user glyphs around the user glyph. The other user glyphs may be displayed in concentric groupings about the user glyph based on a level of similarity between the collective user states of the corresponding other users and the collective user state of the user.

In some implementations the method includes receiving at the data processing hardware an indication of a selection of one or more other user glyphs and executing by the data processing hardware messaging e.g. via a messaging view between the user and the one or more other users corresponding to the selected one or more other user glyphs. The method may include receiving a gesture across the screen where the gesture indicates selection of the one or more other user glyphs. In some examples the method includes receiving at the data processing hardware an indication of a selection of a messenger glyph displayed on the screen. The messenger glyph has a reference to an application executable on the data processing hardware and indicates one or more operations that cause the application to enter an operating state that allows messaging between the user and the one or more other users corresponding to the selected one or more other user glyphs.

In some implementations the method includes displaying a map on the screen and arranging the other user glyphs on the screen based on geolocations of the corresponding other users. The user data of each other user may include the geolocation of the corresponding other user. Moreover the method may include displaying a user glyph representing the user on the map based on a geolocation of the user.

The method may include receiving at the data processing hardware an indication of a selection of one or more other user glyphs and determining by the data processing hardware possible activities for the user and the one or more other users corresponding to the selected one or more other user glyphs to perform based on the collective user states of the user and the one or more other users. The method may also include executing by the data processing hardware behaviors having corresponding objectives. Each behavior is configured to evaluate a possible activity based on whether the possible activity achieves the corresponding objective. The method includes selecting by the data processing hardware one or more possible activities based on evaluations of one or more behaviors and displaying by the data processing hardware results on the screen. The results include the selected one or more possible activities. In some examples the method includes determining by the data processing hardware one or more predicted outcomes for each possible activity based on the collective user states of the user and the one or more other users. In such examples each behavior is configured to evaluate a possible activity based on whether the possible activity and the corresponding one or more predicted outcomes of the possible activity achieves the corresponding objective. In additional examples the method may include receiving an indication of a gesture across the screen indicating selection of the one or more other user glyphs.

In some implementations at least one behavior is configured to elect to participate or not participate in evaluating the possible activities based on the received inputs. The method may include for each behavior determining whether any input of the received inputs is of an input type associated with the behavior and when an input of the received inputs is of an input type associated with the behavior incrementing an influence value I associated with the behavior. When the influence value I of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activities and when the influence value I of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activities. In some examples the method includes for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value of the behavior when the decrement criterion is satisfied. The decrement criterion may be satisfied when a threshold period of time has passed since last incrementing the influence value. In some examples the evaluation of at least one behavior is weighted based on the corresponding influence value of the at least one behavior. Moreover the method may include determining the possible activities based on one or more preferences of the user. At least one behavior may evaluate a possible activity based on at least one of a history of selected activities for the user or one or more preferences of the user. Furthermore a first behavior may evaluate a possible activity based on an evaluation by a second behavior of the possible activity.

In some implementations the method includes receiving at the data processing hardware a selection of a suggestion glyph displayed on the screen and in response to the selection of the suggestion glyph displaying by the data processing hardware an activity type selector on the screen. The method may further include receiving at the data processing hardware a selection of an activity type and filtering by the data processing hardware the results based on the selected activity type.

Another aspect provides a method that includes receiving at data processing hardware a request of a requesting user to identify other users as likely participants for a possible activity. Each user has an associated collective user state based on corresponding inputs that include one or more of 1 sensor inputs from one or more sensors 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface. The method may include for each other user 1 executing by the data processing hardware behaviors having corresponding objectives where each behavior is configured to evaluate the possible activity based on whether the possible activity achieves the corresponding objective and 2 determining by the data processing hardware whether the other user is a likely participant for the possible activity based on evaluations of one or more of the behaviors. The method includes outputting results identifying the other users determined as being likely participants for the possible activity.

In some implementations each other user is associated with the user based on a geographical proximity to the user a linked relationship e.g. family member friend co worker acquaintance etc. . Other relationships are possible as well to narrow a pool of other users.

In some implementations at least one behavior is configured to elect to participate or not participate in evaluating the possible activity based on the corresponding inputs of the other user. The method may include for each behavior determining whether any input of the other user is of an input type associated with the behavior and when an input of the other user is of an input type associated with the behavior incrementing an influence value associated with the behavior. When the influence value of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activity and when the influence value of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activity. The method may include for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value of the behavior when the decrement criterion is satisfied. The decrement criterion may be satisfied when a threshold period of time has passed since last incrementing the influence value.

In some examples the evaluation of at least one behavior is weighted based on the corresponding influence value of the at least one behavior. At least one behavior may evaluate the possible activity based on at least one of a history of positively evaluated activities for the other user or one or more preferences of the other user. Moreover a first behavior may evaluate the possible activity based on an evaluation by a second behavior of the possible activity.

The method may include displaying on a screen in communication with the data processing hardware other user glyphs representing the selected other users. Each other user glyph 1 at least partially indicates the collective user state of the corresponding other user and or 2 is associated with a link to a displayable view indicating the collective user state of the corresponding other user and or inputs used to determine the collective user state of the corresponding other user.

Another aspect provides a method that includes receiving at data processing hardware inputs indicative of a user state of a user. The received inputs include one or more of 1 sensor inputs from one or more sensors in communication with the data processing hardware 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface. The method includes determining by the data processing hardware a collective user state of the user based on the received inputs and receiving at the data processing hardware a request of a requesting user to identify other users as likely participants for a possible activity. The method further includes obtaining at the data processing hardware user data of other users having corresponding collective user states satisfying a threshold similarity with the collective user state of the user and outputting results identifying the other users based on the corresponding user data.

The details of one or more implementations of the disclosure are set forth in the accompanying drawings and the description below. Other aspects features and advantages will be apparent from the description and drawings and from the claims.

The present disclosure describes a system that allows a user to learn about a current state of physical and emotional well being of herself himself and other users to foster meaningful communications and interactions amongst the user and the other users. The system may gather inputs from a variety of sources that include but are not limited to sensors software applications and or the user to determine a collective user state of the user. The system may display representations e.g. icons or images of the user and other users in an arrangement that allows the user to identify and connect e.g. message with other users most similar dissimilar to the user at that moment. Moreover the user may view the collective user states of the user and other users to learn more about each of them. The system may suggest activities or information to the user or a group of users based on the collective user state of each user.

The system may gather data of the user and his her surrounding environment to know the context of the user s current state of being and may model the human thought process to suggest activities and or information to the user. Unlike reactive systems that provide information in response to a user entered query the system may proactively suggest activities and information based on the user s current state of being. Moreover the activities can be tailored for the user to enhance a life objective or certain relationships with other users.

Referring to in some implementations user devices communicate with the search system via the network or a partner computing system . The partner computing system may be a computing system of a third party that may leverage the search functionality of the search system . The partner computing system may belong to a company or organization other than that which operates the search system . Example third parties which may leverage the functionality of the search system may include but are not limited to internet search providers and wireless communications service providers. The user devices may send search requests to the search system and receive search results via the partner computing system . The partner computing system may provide a user interface to the user devices in some examples and or modify the search experience provided on the user devices .

The search system may use e.g. query the data sources when generating search results . Data retrieved from the data sources can include any type of data related to assessing a current state of the user . Moreover the data retrieved from the data sources may be used to create and or update one or more databases indices tables e.g. an access table files or other data structures of the search system .

The data sources may include a variety of different data providers. The data sources may include application developers such as application developers websites and data feeds provided by developers and operators of digital distribution platforms configured to distribute content to user devices . Example digital distribution platforms include but are not limited to the GOOGLE PLAY digital distribution platform by Google Inc. the APP STORE digital distribution platform by Apple Inc. and WINDOWS PHONE Store developed by Microsoft Corporation.

The data sources may also include websites such as websites that include web logs i.e. blogs review websites or other websites including data related to assessing a state of the user . Additionally the data sources may include social networking sites such as FACEBOOK by Facebook Inc. e.g. Facebook posts and TWITTER by Twitter Inc. e.g. text from tweets . Data sources may also include online databases that include but are not limited to data related to movies television programs music and restaurants. Data sources may also include additional types of data sources in addition to the data sources described above. Different data sources may have their own content and update rate.

User devices can be any computing devices capable of communicating with the search system . User devices include but are not limited to mobile computing devices such as laptops tablets smart phones and wearable computing devices e.g. headsets and or watches . User devices may also include other computing devices having other form factors such as desktop computers vehicles gaming devices televisions or other appliances e.g. networked home automation devices and home appliances .

The user device may use any of a variety of different operating systems . In examples where a user device is a mobile device the user device may run an operating system including but not limited to ANDROID developed by Google Inc. IOS developed by Apple Inc. or WINDOWS PHONE developed by Microsoft Corporation. Accordingly the operating system running on the user device may include but is not limited to one of ANDROID IOS or WINDOWS PHONE . In an example where a user device is a laptop or desktop computing device the user device may run an operating system including but not limited to MICROSOFT WINDOWS by Microsoft Corporation MAC OS by Apple Inc. or Linux. User devices may also access the search system while running operating systems other than those operating systems described above whether presently available or developed in the future.

In some implementations the user device includes one or more sensors in communication with the computing device and capable of measuring a quality such as a biometric quality of the user . The sensor s may be part of the user device e.g. integrally attached and or external from e.g. separate and remote from but in communication with the user device . Sensors separate and remote from the user device may communicate with the user device through the network wireless communication such as Bluetooth or Wi Fi wired communication or some other form of communication. The computing device receives biometric data e.g. sensor signals or bioinformatics and or environmental data e.g. sensor signals data structures data objects etc. from one or more sensors . Examples of biometric data may include but are not limited to a temperature of the user an image e.g. 2D image 3D image infrared image etc. of the user a fingerprint of the user a sound of the user a blood oxygen concentration of the user a blood glucose level of the user a skin PH of the user a blood alcohol level of the user an activity level of the user e.g. walking step count or other movement indicator a wake up time of the user a sleep time of the user eating times eating duration eating type e.g. meal vs. snack etc. Examples of environmental data may include but are not limited to a geolocation of the user device a temperature humidity and or barometric pressure about the user device a weather forecast for a location of the user device an image e.g. 2D image 3D image infrared image etc. of a surrounding of the user device a sound about the user etc.

Example sensors that may be included with the user device include but are not limited to a camera e.g. digital camera video recorder infrared imaging sensor 3D volumetric point cloud imaging sensor stereo imaging sensor etc. a microphone a geolocation device an inertial measurement unit IMU e.g. 3 axis accelerometer a fingerprint reader a blood oxygen meter a PH meter etc. The camera may capture image data indicative of an appearance of the user and or an environment or scene about the user . The microphone may sense audio of the user and or an environment or scene about the user . Example sensors that may be separate from the user device include a camera a temperature sensor a humidistat a barometer or any sensing device capable of delivering a signal to the user device that is indicative of the user a surrounding of the user or something that can affect the user .

If the user device does not include a geolocation device the user device may provide location data as an input in the form of an internet protocol IP address which the search system may use to determine a location of the user device . Any of the sensors described as being included in the user device may be separate from the user device and any of the sensors described as being separate from the user device may be included with the user device .

In some examples the user device runs a native application dedicated to interfacing with the search system while in other examples the user device communicates with the search system using a more general application such as a web browser application accessed using a web browser. In some implementations the search application receives one or more inputs such as biometric data or environmental data from the sensor s associated software and or the user via a graphical user interface GUI and transmits a search request based on the received inputs to the search system . The search application may also receive platform data form the user device e.g. version of the operating system device type and web browser version an identity of the user of the user device e.g. a username partner specific data and or other data and include that information in the search request as well. The search application receives a search result set from the search system in response to submitting the search request and optionally displays one or more result records of the search results set on the display of the user device . In some implementations the search request includes a search query containing a user specified selection e.g. a category genre or string . The search application may display a graphical user interface GUI on the display that may provide a structured environment to receive inputs and display the search results . In some implementations the search application is a client side application and the search system executes on the remote system as a server side system.

Referring to in some implementations the state analyzer receives one or more inputs indicators of the state of the user e.g. physical and or emotional state and determines the collective user state of the user . The state analyzer may combine the received user state indicators to generate the collective user state . In additional implementations the state analyzer executes an algorithm on the received user state indicators to generate the collective user state . The algorithm may logically group user state indicators and select one or more groups of user state indicators to generate the collective user state . Moreover the state analyzer may exclude user state indicators logically opposed to other more dominant user state indicators . For example the state analyzer may form a group of user state indicators indicative of an emotional state of happiness and another on a state of hunger. For example if the state analyzer receives several user state indicators e.g. a majority indicative of happiness and only a few or one e.g. a minority user state indicator indicative of sadness the state analyzer may form a group of user state indicators indicative of an emotional state of happiness while excluding the minority user state indicators indicative of an emotional state of sadness since they re diametrically opposed . Accordingly the state analyzer may group user state indicators into groups or clusters of user states and use those groups or clusters of user states to determine the collective user state .

In some implementations the state analyzer models the user using the received user state indicator s to generate the collective user state . Each received user state indicator provides an aspect of the modeled user as the collective user state . The state analyzer may store the collective user state in memory such as the storage resources of the remote system . In some examples the state analyzer generates and or stores the collective user state as an object such as a Java script object notation JSON object a metadata data object structured data or unstructured data. Other methods of storing the collective user state are possible as well.

The input user state indicator may include any information indicative of the user s state of being in terms of a physical state of being and or an emotional state of being. Optional examples of a physical state may include but are not limited to date and or time stamp e.g. from the computing device of the user device a location of the user a user identified state indicator of a physical well being of the user and a sensed indicator of a physical well being of the user e.g. biometrics . The location of the user may be a geolocation e.g. latitude and longitude coordinates of the user device a description of the physical location of the user in terms of landmarks and or environmental descriptions a description of a dwelling or building a floor of the dwelling or building a room of the dwelling or building an altitude etc. Examples of emotional states include but are not limited to user identified state indicators of an emotional state of the user and sensed indicators of a physical well being of the user e.g. biometrics .

In some examples the state analyzer receives image inputs of the user from the camera and determines an emotional state of the user based on the images and optionally other inputs . The state analyzer can gauge whether the user is angry happy sad surprised eating moving etc. based on the image inputs . The image inputs may be considered as user identified state indicators and or sensed indicators

The user device may receive the user identified state indicator from the user through the GUI . The user identified state indicator may include one or more selections of images and or description indicative of different states of physical or emotional well being or states of the user . In some examples the user can select one or more user identified state indicators on the GUI that correspond to a combination of different user state indicators . The search application may execute logic that disallows inconsistent selections. For example the search application may not allow the user to select user identified state indicators of happy and sad at the same time.

The user state indicator may optionally include user state indicators of friends referred to as friend state indicator from the remote system or a data source. The friend state indicator may be from any person having an identified association with the user . The user may designate the associations of other people with their account and or the state analyzer may identify and designate other people as having an association with the user based on the user state indicator of other users and or authorized searching of email account s social networking account s or other online resources of the user .

The user state indicator may optionally include a partner metric e.g. available funds from a banking institution received from the user device e.g. as a user input and or from a remote data source e.g. a linked back account . The partner entities may be data sources that provide information relative the user s state. For example a mobile payment plan can provide mobile payment information such as a purchase time purchase location store entity goods purchased purchase amount and or other information which the search system can use to determine the user collective state . Moreover the activity system may use partner metrics to suggest activities A and predict outcomes O the behavior system may use partner metrics to evaluate the activities A and predicted outcomes O and the activity selector may use partner metrics to select one or more activities A. Other examples of partner metrics include but are not limited to fitness and or nutrition information of the user from a fitness application e.g. a data source dating information from a dating application work history or work activities from a work related application such as LinkedIn or any other application. The application s may be installed on the user device or offered as web based applications. The search system may access the partner metrics via an application programming interface API associated with each application or other data retrieval methods.

Similarly the user state indicator may optionally include a user schedule received from the user device e.g. as a user input and or from a remote data source e.g. a linked scheduler or partner system . The schedule may be related to eating exercise work to do list etc.

Referring to in some implementations the search application displays a state acquisition view having a collection of images e.g. a tiling of pictures in the GUI and prompts the user to select the image most indicative of a current state of the user e.g. a user state indicator . The images may depict a variety of possible user states such as happy or sad hungry of full energetic or lethargic etc. The selected image may be a user state indicator . Additionally or alternatively the GUI may display one or more images and prompts the user to tag the images with a corresponding user state. As the user tags the images the search system learns the user s preferences and or state.

In the example shown in the search application may group the images e.g. by a category into one or more groups and display the one or more groups in the GUI . The user may scroll through the images in each group and select an image most indicative of a current state of the user . For example the search application may display each group of images as a linear or curved progression e.g. a dial such that the user can swipe across the screen to move the linear progression or rotate the curve progression of images onto and off the screen . The user may scroll through each group of images and position a selected image in a selection area e.g. selection box . The search application may alter the selected image or otherwise designate the selected image as being selected. For example the search application may change the image into another related image or animate the image e.g. video . The search application may highlight the selected image or provide a visual or audio cue of the selection. In some examples the search application displays a gauge indicating a level of discernment of the user s current state based on the number and or type of images currently selected in the collection of images . The search application may indicate a threshold number of images that the user should select before proceeding to obtain a suggested activity A.

In the example shown in the search application may display a state acquisition view having first and second images in the GUI and prompt the user to select the image most indicative of a current state of the user e.g. a user state indicator . When the user selects one of the images the search application may display two more images in the GUI and prompt the user to select the image most indicative of his her current state and continue recursively for a threshold period of time or until the user selects a threshold number of images . The search application may display a gauge indicating a level of discernment of the user s current state based on the number and or type of images selected. Moreover the search application may in some instances not allow the user to proceed to receive a suggested activity A until the search application and or the search system has ascertained a threshold level of discernment of the user s current state based on the number and or type of images selected. For example the search application may display a first image showing a person eating to illustrate a hungry state and a second image showing a person full with a finished dinner plate to illustrate a full or not hungry state. In other examples the search application may display a first image showing a person running to illustrate an inkling to go running and a second image showing a person sitting or resting to illustrate an inkling to sit and rest. The user may continue to select one of two images until the gauge indicates a threshold level of discernment of the user s current state or until the user selects a query element displayed in the GUI at which point the search application sends the query request to the search system to receive search result s for display in the GUI .

Referring to in some implementations the search application displays a state acquisition view having one or more menus e.g. categories of user state indicators . Each menu may have one or more sub menus that further group or categories user state indicators . The user may swipe across the screen of the user device in a non linear path e.g. step like fashion to navigation the menus to select a user state indicator most indicative of the user s current state. The user may continue to navigate the menus to select user state indicators until the gauge indicates a threshold level of discernment of the user s current state or until the user selects the query element displayed in the GUI at which point the search application sends the query request to the search system to receive search result s for display in the GUI .

Referring to in some implementations the search application displays a preferences view that allows the user to set and modify user preferences P P P. The search system may use the user preferences P Pfor generating search results . For example the activity system may use the user preferences P Pfor identifying possible activities A. Moreover the behavior system may use the user preferences P Pfor evaluating the possible activities A and optionally any corresponding predicted outcomes O . When the user selects a preference P P the search application may display an edit preference view that allows the user to modify the selected preference P P. In the example shown when the user selects a second preference P corresponding to a sports preference the search application may display an edit preference view customized to allow the user to modify the selected preference P P. Example preferences may include but are not limited to preferred eating times eating duration dining preferences e.g. food types restaurants restaurant types eating locations leisure activities cinema preferences theaters theater show types to do lists sports activities shopping preferences e.g. stores clothing types price ranges allowable purchase ranges for different types of goods or services disposable income personality type etc. In some implementations the user may select an auto populate preferences icon to cause the search application and or the search system to populate the preferences P Pbased on previous inputs and or selected activities A of the user e.g. stored in non transitory memory . After auto populating the preferences P P the user may further customize the preferences P Pusing the preferences view .

Referring to in some implementations the activity system receives the collective user state from the state analyzer applies the collective user state to an activity model and determines the collection of possible activities A A Aand corresponding outcomes O O Ofor the user i.e. the activity outcome set . The activity system may use a user profile of the user to determine the activity outcome set . A data source e.g. data store non transitory memory a database etc. in communication with the activity system may store the user profile possible activities A and or possible outcomes O. For example the activity system may identify one or more preferences P Pof the user from the user profile for use with the activity model to determine the activity outcome set . The activity system may optionally query one or more data sources or the storage resources of the remote system for data on possible activities A and or corresponding outcomes O. In some examples the activity system simulates each activity A using the activity model over a time horizon in the future to predict a corresponding outcome O optionally using results queried from the data source s . The time horizon may be a short term horizon e.g. less than one hour or a few hours or a long term horizon e.g. greater than one hour or a few hours . The activity system may select the time horizon based on the collective user state the user preferences P and or other factors.

Referring also to in some implementations the activity system includes an activity generator that generates possible activities A based on the received inputs and or collective user state and an outcome generator that generators the set of possible outcomes O for each activity A. The activity generator may generate an activity search query based on the inputs and a type of each input and query the data source s to obtain results which the activity generator can use to determine one or more possible activities A. For example an input may be a global positioning system GPS coordinate having an input type of location. The input type may be strongly typed to accept coordinate values as the corresponding input . An activity search query may include criteria to seek possible activities A within a threshold distance of the location. Moreover the threshold distance may be based on the location.

In some implementations the activity generator seeks activities A relevant to active behaviors . The activity generator may identify all or a sub set of the active behaviors and then seek activities A that each behavior can evaluate positively. For example if a sports behavior is active then the activity generator may seek possible activities A related to sports.

After the activity generator generates a collection of possible activities A the outcome generator generates a collection of one or more predicted outcomes O for each activity A. In some implementations the outcome generator retrieves possible outcomes O from a data store storing outcomes O for various activities A. For example the outcome generator may query the data source s for possible outcomes O matching criteria indicative of the activity A. The data source s may include databases partner systems and other sources of information.

Referring to in some implementations the behavior system receives the activity outcome set from the activity system evaluates each activity A based on its corresponding predicted outcome O and or objectives of the behavior system and provides the collection of evaluated activities A and outcomes O i.e. the evaluated activity outcome set . The behavior system includes behaviors that provide predictive modeling of the user and allows the behaviors to collaboratively decide on the activities A by evaluating the activities A and or the corresponding possible outcomes O of activities A. A behavior may use the inputs the collective user state the preferences P P Pin the user profile of the user any additional sensory feedback of the user and or any relevant information from data sources to evaluate each activity A and or its predicted outcome s O and therefore provide evaluation feedback on the allowable activities A of the user . The behaviors may be pluggable into the behavior system e.g. residing inside or outside of a software application such that they can be added and removed without having to modify the behavior system . Each behavior is a standalone policy. To make behaviors more powerful it is possible to attach the output of one or more behaviors together into the input of another behavior .

A behavior may model a human behavior and or a goal oriented task. Each behavior may have a specific objective. Example behaviors include but are not limited to an eating behavior a happiness behavior e.g. a pursuit of happiness a retail shopping behavior a grocery shopping behavior a sports behavior a love behavior a work behavior a leisure behavior etc.

Behaviors may model psychological decision making of humans. Moreover the behaviors may be configurable. In some examples the user may set a preference P to configure or bias one or more behaviors to evaluate activities A and or outcomes O toward that bias. In some examples the user can set a preference P to have the search system aid the user in making better choices e.g. choices toward a healthier lifestyle . For example the user may set a preference P to bias one or more behaviors to evaluate activities A and or outcomes O that help the user live a healthier lifestyle e.g. in terms of diet exercise relationships work etc. .

A behavior may have one or more objectives that it uses when evaluating activities A and or outcomes O. The behavior may evaluate activities A outcomes O or activities A and outcomes O. The behavior may execute a scoring algorithm or model that evaluates outcomes O against the one or more objectives. The behavior may score activities A and or outcomes O fulfilling the objective s higher than other activities A and or outcomes O that do not fulfill the objective s . Moreover the evaluations of the activities A and or outcomes O may be weighted. For example an eating behavior may evaluate an activity A based on whether the predicted outcome O will make the user less hungry. Moreover the outcome evaluation may be weighted based on a user state of hunger and on the likelihood of fulfilling the objective of making the user less hurry. For example the eating behavior may evaluate a first activity Aof going to a restaurant to eat pizza more favorably than a second activity Aof going to the cinema because a predicted first outcome Oof going to a restaurant to pizza will more likely have an outcome O of satisfying a user state of hunger than going to the cinema even though a predicted second outcome Ofor the second activity Aof going to the cinema may include eating popcorn.

A behavior may optionally base its evaluations E on preferences P P Pin the user profile of the user . For example the eating behavior may evaluate a third activity Aof going to LOU MALNATIS a registered trademark of Lou Malnatis Inc. to eat pizza more favorably than the first activity Aof going to PIZZA HUT a registered trademark of Pizza Hut Inc. to eat pizza when a first preference Pin the user profile indicates that LOU MALNATIS pizza is the user s favorite brand of pizza. Therefore a behavior may use the one or more objectives of that behavior in combination with one or more preferences P P Pof the user profile of the user to evaluate activities A and or outcomes O of those activities A.

The activity outcome evaluation E of one behavior may be used by another behavior when evaluating the corresponding activity A and or outcome O. For example a happiness behavior may evaluate the third activity Aof going to eat LOU MALNATIS pizza more favorably based the favorable evaluation of the eating behavior and on the corresponding predicted outcome Othat eating pizza will make the user more happy e.g. versus sad . Moreover the collective user state may indicate that the user is cold based on sensor data of a sensor and the happiness behavior may evaluate the third activity Aof going to eat LOU MALNATIS pizza even more favorably based on the predicted outcome O that eating pizza will make the user warmer and therefore happier. Therefore the behavior system may execute many combinations of evaluations by behaviors some in parallel or some in series based on prior evaluations preferences P etc.

Based on internal policy or external input e.g. the collective user state or other information each behavior may optionally decide whether or not it wants to participate in evaluating any activities A in the activity outcome set . In some examples if the collective user state indicates that the user is full i.e. not hungry the eating behavior may opt out of evaluating the activities A and outcomes O. In other examples if the collective user state indicates that the user is full i.e. not hungry the eating behavior may evaluate activities A having predicted outcomes O of making the user more full as undesirable e.g. a poor evaluation or a low score . Each behavior may decide to participate or not participate in evaluating activities A and or outcomes O based on the inputs e.g. based on the collective user state a history of received inputs a rate of received inputs input types and or other factors related to inputs .

Different inputs user state indicators can trigger different behaviors . A behavior may persist for a duration of time. In some examples a behavior has a state and exists in an active state or an inactive state. Certain types of inputs may pertain to certain types of behaviors . One or more input types user state indicator types may be associated with each behavior . In other words each behavior may have an associated collection of input types that the behavior finds pertinent to its operation. For example an input type of hunger level for a user defined input of hunger having a scale e.g. 1 10 indicating a level of hunger can be related to an eating behavior . Another input type that may be associated with the eating behavior is proximity which may be strongly typed as a distance in miles for an input of distance to a nearest restaurant. When the search system e.g. in particular the behavior system receives an input of a type associated with a behavior the receipt of that input may trigger activation of the behavior . The receipt of the input may cause a behavior to change state from an inactive state to an active state.

In addition to becoming active upon the receipt of one or more inputs having a type associated with the behavior the number of those inputs in some implementations has a direct correlation to an influence I of the behavior . In other words the greater the number of received inputs having a type associated with the behavior the greater the influence I of that behavior . Evaluations of predicted outcomes O of a behavior may be weighted based on the influence I of the behavior . For example the evaluation E can be a number which is multiplied by the influence I e.g. a number . As a result behaviors with greater influence I have a relatively greater influence on the selection of an activity A.

In some implementations the influence I is a count. Each time the behavior system receives an input the behavior system increments a value of the influence I of each behavior that has associated therewith the input type of the received input . The behavior system may include an input type filter that receives the inputs identifies which behaviors if any are associated with the input type of the input and increment the influence I of the affected behavior s .

In some implementations each behavior has an associated duration D. Receipt of an input having a type associated with the behavior commences an input timer set for a duration of time associated with the input or the input type . When the input timer expires the behavior system decrements the influence I of the behavior which was previously incremented for that input . Alternatively or additionally the behavior system may decrement the influence I of each behavior every threshold period of time or since a last received input . When the influence I of a behavior is zero the behavior changes state from the active state to the inactive state. If the behavior system receives an input having an input type associated with an inactive behavior the behavior system increments the influence I of that behavior causing the behavior to have an influence I greater than zero which causes the behavior to change state from the inactive state to the active state. Once in the active state the behavior can participate in evaluating predicted outcomes O of activities A and or the activities A themselves.

Behaviors may evaluate activities A and or predicted outcomes O of activities A. By evaluating both an activity A and the predicted outcomes O of the activity A the behavior offers a multi pronged evaluation E. For example while the behavior may positively evaluate an activity A it may negatively evaluate one or more of the predicted outcomes O of that activity A. As an illustrative example if the behavior system receives inputs indicating that the user is outdoors and on a street then a sports behavior may positively evaluate an activity A to ride a bicycle. If additional inputs indicate that the user is on a very busy street then the sports behavior may negatively evaluate a predicted outcome O of getting hit by a car.

In some implementations a behavior evaluates activities A and or predicted outcomes O of activities A positively when the activity A has a type associated with the behavior and negatively when the activity A has a type not associated with the behavior . The behavior system may reference behavior activity associations stored in non transitory memory . The behavior activity associations may have several nested layers e.g. associations in a nested arrangement .

In some examples an assistive behavior is linked to an external resource and can manipulate control or at least bias the external resource based on the objective of the assistive behavior a preference P set by the user or one or more inputs . In some examples the assistive behavior becomes active after receipt of one or more inputs having an input type associated with the assistive behavior . While active the assistive behavior may cause instruct or influence an action of an external resource e.g. other software or hardware directly or indirectly in communication with user device . For example an assistive behavior having an objective of accommodating the environmental comfort of the user may become active after receiving a temperature input from a temperature sensor a humidity input from a humidity sensor or some other input related to the environmental comfort of the user . While active the assistive behavior may cause a thermostat near the user to change temperature e.g. to a preferred temperature as set by the user in a corresponding preferences P . Moreover the assistive behavior can be influenced by other behaviors and or a previously selected activity A. If a previously selected activity A entailed running the assistive behavior may adjust the thermostat to a post running temperature cooler than a standard temperature and then re adjust the thermostat to the standard temperature after receiving a body temperature input indicating that the user has cooled down to a normal body temperature. Assistive behaviors may communicate with home automation systems security systems vehicle systems networked devices and other systems to adjust those systems to accommodate one or more preferences P of the user and or to facilitate participation in a suggested activity A. For example if the search system suggests a romantic evening with the spouse of the user one or more assistive behaviors which may have scored the selected activity A favorably may communicate with a home automation system of the user to cause that system to dim the home lights play romantic music e.g. music have a category of romance and set the indoor temperature to a temperature preferred by the spouse of the user .

Referring to in some implementations the activity selector receives the evaluated activity outcome set from the behavior system and determines the collection of one or more selected activities A A A i.e. the selected activity set . The activity selector executes an activity selection routine that searches for the best activity s A A Agiven the evaluations E E Eof their corresponding outcomes O O Oby all of the participating active behaviors . In some implementations the activity selector calculates one or more preferred outcomes O O O based on the outcome evaluations E E Eof the behaviors and selects one or more corresponding activities A A Afor the selected activity set . The activity selector may optionally send the selected activity set to the activities system e.g. to the activity model as feedback.

In some implementations the activity selector assesses the evaluations E E Eof the possible outcomes O O Oof the activities A A Aand determines a combination of activities A A Athat provides a combined outcome O. The combined outcome O may achieve higher user stratification than any single individual outcome O. The activity selector may select the combination of activities A A Ahaving the determined combined outcome O as the selected activity set . For example if the inputs indicate that the user is hungry and likely seeking entertainment a combined outcome O of both eating and watching a show may be very favorable. Therefore a combined action may be going to a dinner theater event that includes eating and watching a show.

Referring again also to the search system sends search results to the user device in response to the search query . In some implementations the search results include one or more result records which include information about or pertaining to the selected activity set . For example the search results may be a recordset that includes a result record for each selected activity A. Moreover the result record may include a description of the corresponding selected activity A referred to as an activity description that identifies the activity A and how to experience the activity A. In some examples the activity description includes an activity name an activity description a link e.g. a uniform resource locator URL or other type or resource locator for accessing a webpage an application etc. display data and or other data related to the activity A such as an evaluation score e.g. by the activity selector a popularity score e.g. retrieved from a data source . The activity description may include a textual description of the activity A and or location information e.g. geolocation coordinates a textual street location etc. for the activity A. In some examples the activity description may include information explaining why the search system chose a particular activity A. For example the activity description may explain that the search system chose an activity A related to eating because a majority of the inputs indicated that the user was very hungry and close in proximity to a favorite restaurant e.g. as indicated by a user preference P .

In some implementations the search application executing on the user device generates a result view based on the received search results and displays the result view in the GUI . The result view includes one or more activity messages corresponding to each result record in the search results .

In additional examples the search application groups the search results by activity type. When the GUI allows the user to select an activity type the GUI limits filters the search results to activities A having the selected activity type. For example when the user wishes to receive a suggestion for eating dinner the user may select an activity type of eating and the search application via the search system suggests an activity A of eating at a nearby restaurant.

The search system may autonomously generate and provide search results to the user based on one or more inputs . In such examples the search system may suggest information activity A relevant to the current state and context of the user . The suggested information may help the user improve his her current state. For example if the search system identifies that the user is far from a scheduled appointment and traffic is heavy e.g. based on inputs the search system may suggest that the user leave for the appointment early. Moreover the search system may suggest on device features software and or hardware features of the user device or for application executable on the user device or a web based application accessible by the user device that may be helpful to the user at that moment. For example the search system may recommend an application executable on the user device relevant to the user at that moment based on one or more inputs or the collective user state . Moreover the recommended feature may be one of the inputs or related to functionality of one of the inputs . For example when the search system recommends an outdoor activity A the search system may also provide information about a weather application or an outdoor related application installed on or executable by the user device .

In some implementations the search system provides a suggestion on demand. When the user is seeking a particular type of suggestion the user may select a suggestion type to guide the selection of the suggestion by the search system . The suggestion type provides the search system with a user intent.

Referring to in some implementations the search application displays a message in the GUI prompting the user to shake the user device to receive a suggested activity A. When the user shakes the user device the search application receives an input from the IMU of the user device indicating that the user is shaking the user device back and forth. In response to the received input the search application may send the query request to the search system to receive search result s for display in the GUI . The search application may display a result view in the GUI that shows one or more activity messages .

In some implementations the result view includes an activity message that includes the activity name the activity description the link the evaluation score and or the popularity score from the corresponding result record . The result view may also include a result view selector having icons corresponding to alternative result views . When the user selects one of the icons the search application displays the corresponding result view 

In response to selection of a link the user device may launch a corresponding software application e.g. a native application or a web browser application referenced by the link and perform one or more operations indicated in the link and or the display data . For example the link may include a URL having query string containing data to be passed to the software application or software running on a remote server e.g. the query string may contain name value pairs separated by delimiters such as ampersands . If the link is configured to access a native application the link may include a string e.g. a query string that includes a reference to the native application and indicates one or more operations for the user device to perform. When the user selects the link for the native application the user device launches the native application referenced in the link and performs the one or more operations indicated in the link . If the references application is not installed on the user device the link may direct the user to a location e.g. a digital distribution platform where a native application can be downloaded. If the link is configured to access a web based application the link may include a string e.g. a query string that includes a reference to a web resource e.g. a page of a web application website . For example the link may include a URL i.e. a web address used with hypertext transfer protocol HTTP . When the user selects the link the user device launches a web browser application and retrieves the web resource indicated in the resource identifier.

The search application may display the search results to the user in a variety of different ways depending on what information is transmitted to the user device . Moreover the search application may display the search results in the GUI based on the display data . The display data may include text images layout information a display template a style guide e.g. style sheet etc.

In the example shown in a result view may include a map having a user icon indicating a current location of the user device on the map and the one or more activity results in their corresponding locations on the map . The user can view information from the corresponding result record displayed in the activity result e.g. the activity name the activity description the link the evaluation score and or the popularity score . The link may include a link display name as well as the underlying resource locator.

Referring to in examples where the search results include a recordset of results records the search application may display the search results to the user in a results view that includes a list view of the result records e.g. in a tabular form . Moreover the search application may arrange the result records in order based on their evaluation score and or the popularity score . In some examples the search application displays the result records in a table grid and in other examples the search application displays the result records in a tree grid as shown grouping result records under separate parent nodes by a category or other grouping.

In some implementations the user can enter feedback in the GUI of the search application so that the search system can learn whether the suggested activities A were well received by the user . The search system can use the user feedback for future activity selections.

In the example shown the user has the largest icon in the center portion of the screen surrounded by other user icons . Each other user icon has a size similar to or smaller than the user icon and corresponds to another user having a collective user state having a degree of similarity to the collective user state of the user and or located within some geographical distance of the user . The other user icon may be arranged in groups about the user icon . Other users having collective user states satisfying a first threshold similarity to the collective user state of the user and or located within a first threshold geographical distance of the user have other user icons arranged in a first icon group around the user icon . While the first icon group is shown as a circular arrangement around the user icon other arrangements are possible as well. Other users having collective user states satisfying a second threshold similarity less than the first threshold similarity to the collective user state of the user and or located within a second threshold geographical distance of the user further away than the first threshold geographical distance have corresponding other user icons arranged in a second icon group around the user icon and the first icon group . In the example shown the second icon group has corresponding other user icons smaller than the other user icons of the first icon group . The user may scroll or otherwise navigate e.g. in any direction on the screen to view other user icons and their visual representation arrangement indicating the relative similarity of the collective user state of the other users and or the geographical proximity of the other users 

In the example shown in the user may toggle between first and second home views . The first home view may provide an arrangement of other user icons around the user icon where the other user icons represent other users having the collective user state similar to that of the user and or are geographically located relatively close to the user . The second home view may provide an arrangement of other user icons around the user icon where the other user icons represent other users having a collective user state very dissimilar or opposite to that of the user and or are geographically located relatively far from the user . By toggling between the first and second home views the user can quickly ascertain which other users have similar or dissimilar corresponding collective user states and or are geographically within a close or far proximity of the user

The home view may visually distinguish between other users having collective user states that satisfy a threshold similarity to the collective user state of the user and other users located within a threshold geographical distance of the user . For example other user icons of other users having collective user states satisfying the threshold similarity to the collective user state of the user may have a first outline color e.g. border color whereas other user icons of other users located within a threshold geographical distance of the user may have a second outline color different from the first outline color. Moreover other users satisfying the threshold similarity to the collective user state of the user and being located within the threshold geographical distance of the user may have a third outline color different from the first and second outline colors.

Referring to in some implementations a home view includes other user icons sized shaped and or arranged with respect to the user icon based on a level of similarity of collective user state and or geographical proximity. For example the size and position of each other user icon on the screen may represent a degree of similarity of the collective user state of the other user and geographical closeness of the other user to the user . The size of each other user icon relative to the user icon may be based on a percentage of similarity between the collective user states of the other user and the user . For example another user having the exact same collective user state e.g. 100 similarity may have a corresponding other user icon having the same size as the user icon or a maximum size and yet another user having a least similarity of collective user state with respect to that of the user may have a corresponding other user icon having a minimum size. In some examples other users located very close to the user may have corresponding other user icons arranged on one side of the screen for example on the right side of the screen and additional other users located far away from the user may have corresponding other user icons arranged on an opposite side of the screen for example on the left side of the screen . Other icon arrangements are possible as well to visually represent similarity of collective user state and or geographical proximity of other users to the user such as but not limited to a differing shape brightness position or appearance of the other user icons 

In some implementations the user may select another user icon for enlargement to see additional information. For pressure sensitive screens the user may execute a long press for example causing the GUI to display an enlarged other user icon and or other information about the corresponding other user . In additional examples selection of the other user icon may open a separate window view providing additional information about the corresponding other user 

Referring to in some implementations while on the home view the user may gesture e.g. swipe with one or more fingers on the screen over one or more other user icons to select the corresponding other users and either end the gesture on or separately select a messenger icon to initiate a group message e.g. text messaging to each of the selected other users in a messenger view . The messenger view may include messages amongst the user and the selected other users . Each message may include text audio images and or video. The user may communicate with the other users based on knowing the collective user states of the other users and or a level of similarity of collective user states amongst the user and the other users 

Referring to in some implementations the user may view a map view having the user icon indicating a current geographical location of the user on a map . The other user icons may indicate on the map current geographical locations of the corresponding other users . In the example shown the map shows that two other users represented by corresponding other user icons are within a threshold distance of the user . The user may gesture e.g. swipe with one or more fingers on the screen over the other user icons as shown to select the corresponding other users and either end the gesture on or separately select the messenger icon to initiate a group message e.g. text messaging to each of the selected other users in the messenger view

Referring to in some implementations while on the home view the user may gesture e.g. swipe with one or more fingers on the screen over one or more other user icons to select the corresponding other users and either end the gesture on or separately select a suggestion icon to receive a suggested activity A for the user and the selected other users in a suggestion view . The user may select an activity type to narrow the suggestion to a desired type of activity A. In some examples when the user executes a long press double select or other interaction on the suggestion icon the GUI displays an activity type selector e.g. a pop up a menu or a separate view where the user can select an activity type from a list of activity types. The search system may use the selected activity type to narrow the results to one or more activities A having the selected activity type. For example the activity selector may select one or more possible activities A based on the evaluations E of the behaviors and the selected activity type.

The suggestion view may include textual and or graphical representation of the suggested activity A an accept graphical input allowing the user to accept the suggested activity A a decline graphical input allowing the user to decline the suggested activity A a re try graphical input allowing the user to request another suggested activity A for the group of users an information graphical input allowing the user to view an activity information view as shown in having additional information about the suggested activity A and or a map graphical input allowing the user to view the map view e.g. showing a location of the suggested activity A and or the proximity of the user and or the other users to the suggested activity A.

Referring to in some implementations the GUI includes a find participant view which allows the user to enter a suggested activity A and receive an indication of other users I who might be interested in participating in the suggested activity A. The user may enter the suggested activity A using one or more activity inputs such as but not limited to typing the suggested activity into a text box or dictating e.g. using voice recognition the suggested activity A to the user device . The search system can identify other users that the suggested activity A would apply to at that moment and return results or user data see identifying those other users . In the example shown in the search application displays a participant view in the GUI . The participant view may be similar to the home view by having other user icons corresponding to the identified other users displayed around the user icon . The participant view may include the messenger icon so that the user may gesture e.g. swipe with one or more fingers over one or more other user icons to select the corresponding other users and either end the gesture on or separately select a messenger icon to initiate a group message e.g. text to each of the selected other users in a messenger view . In some examples the participant view includes the map icon so that the user may access the map view which has the user icon indicating a current geographical location of the user on the map along with the other user icons identifying the current geographical locations of the corresponding other users . The participant view may include the suggestion icon so that user may gesture e.g. swipe with one or more fingers over one or more other user icons to select the corresponding other users and either end the gesture on or separately select a suggestion icon to receive a suggested activity A for the user and the selected other users in the suggestion view

Referring to in some implementations the user may select the user icon or one or more other user icons to open a user state view of the user or the one or more other users . The user state view may provide a textual or graphical representation of the collective user state of the corresponding user and or a textual or graphical representation of the inputs received and used to derive the collective user state of the corresponding user . In the example shown in the user state view includes a textual representation of the collective user state of the user and or a textual representation e.g. listing of one or more inputs . The user may select the collective user state to view more information e.g. a detailed description of the collective user state . Similarly the user may select any input to view more information e.g. a detailed description of the selected input . In some examples the user can post his her current collective user state to a third party e.g. Facebook or other social media by selecting a post icon . As shown in in response to selection of the post icon the search system may send a user state card including at least a portion of the collective user state of the user to a third party system e.g. a partner system or another user . By posting sending user state cards to other users or other systems the user can share and indication of his her current state of being with other users or systems to foster meaningful communications and interactions with others.

In the example shown in a user state view includes a graphical representation of the collective user state referred to as the collective user state icon surrounded by graphical representations of at least some of the inputs referred to as input icons received and used to derive the collective user state of the corresponding user . The collective user state icon may provide a glyph text video or other representation of the corresponding collective user state . For example the collective user state icon may provide a color gradient e.g. a radial color gradient across a color spectrum representing a range of collective user states and an indicator marking the corresponding collective user state within that range of collective user states . The input icons may offer a visual representation of the corresponding received input e.g. the color or meter indicating a temperature or other measurement . Moreover the user may select an input icon to view more detailed information about the received input . For example selection of a geolocation input icon corresponding to a received geolocation input of the geolocation device may open the map view providing a map and identifying the current location of the corresponding user . In the example shown in the map view also indicates the current location of nearby other users .

In some implementations the user may view a real time image video e.g. as a user icon of another user on the screen of the user device using the camera . The search application may augment the real time image by overlaying graphics depicting the collective user state and or inputs of the other user . In some examples the overlain graphics include the collective user state icon and or the input icons . As such the user may view another user e.g. image or video augmented with overlain graphics e.g. the collective user state icon and or the input icons depicting the collective user state of the other user allowing the user to know and understand the current state of being of the other user without having to actually ask the other user . By knowing more about the other user the user can initiate a meaningful conversation with the other user

In some implementations the method includes querying one or more remote data sources in communication with the computing device to identify possible activities A A Aand or predicted outcomes O O O. The method may include determining using the computing device the one or more possible activities A A Aand the one or more predicted outcomes O O Ofor each activity A based on one or more preferences P Pof the user . Each behavior may evaluate an activity A or a corresponding outcome O positively when the activity A or the corresponding outcome O at least partially achieves an objective of the behavior . For example the eating behavior may positively evaluate an eating activity whereas the sports behavior may negatively evaluate the eating activity. Moreover each behavior may evaluate an activity A or a corresponding outcome O positively when the activity A or the corresponding outcome O at least partially achieves a user preference P P. In some examples a first behavior evaluates an activity A or a corresponding outcome O based on an evaluation E by a second behavior of the activity A or the corresponding outcome O. This allows evaluations E of one behavior to be based on evaluations E of another behavior . Each behavior may elect to participate or not participate in evaluating the one or more activities A A Aand or the one or more predicted outcomes O O Ofor each activity A based on the collective user state .

When an input is related to a behavior the method may include incrementing an influence value I associated with the behavior . The input may be related to the behavior when the input is of an input type associated with the behavior . In some implementations the evaluations E of each behavior can be weighted based on the influence value I of the corresponding behavior . The method may include decrementing the influence value I of each behavior after a threshold period of time. When an influence value I equals zero the method may include deactivating the corresponding behavior . Any behaviors having an influence value I greater than zero may participate in evaluating the activities A or the corresponding outcomes O and any behaviors having an influence value I equal to zero may not participate in evaluating the activities A or the corresponding outcomes O.

In some implementations the method includes selecting for the results a threshold number of activities A having the highest evaluations E or a threshold number of activities A having corresponding predicted outcomes O that have the highest evaluations E. The method may include combining selected activities A and sending a combined activity A in the results .

The computing device may include a user computer processor of a user device including the screen and or one or more remote computer processors in communication with the user computer processor . For example the computer device can be the computer processor of a mobile device a computer processor of an elastically scalable cloud resource or a combination thereof.

Referring to in some implementations a method includes at block receiving at data processing hardware inputs indicative of a user state of a user . The received inputs include one or more of 1 sensor inputs from one or more sensors in communication with the data processing hardware 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface . At block the method includes determining by the data processing hardware a collective user state of the user based on the received inputs and at block obtaining at the data processing hardware user data of other users . The user data of each other user includes a collective user state of the corresponding other user . In some examples the user data includes an identifier an image video address mobile device identifier platform data or other information related to the user . The user data may be metadata in a Java script objection notation JSON object or some data structure. At block the method includes displaying on a screen in communication with the data processing hardware other user glyphs representing the other users . Each other user glyph 1 at least partially indicates the collective user state of the corresponding other user and or 2 is associated with a link to a displayable view indicating the collective user state of the corresponding other user and or the inputs used to determine the collective user state of the corresponding other user 

In some implementations the method includes obtaining the user data of the other users that have corresponding collective user states satisfying a threshold similarity with the collective user state of the user . The method may include arranging each other user glyph on the screen based on a level of similarity between the collective user state of the user and the collective user state of the corresponding other user . In some examples a size a shape a color a border and or a position on the screen of each other user glyph is based on a level of similarity between the collective user state of the corresponding other user and the collective user state of the user 

The method may include displaying a user glyph representing the user in a center portion of the screen and the other user glyphs around the user glyph . The other user glyphs may be displayed in concentric groupings about the user glyph based on a level of similarity between the collective user states of the corresponding other users and the collective user state of the user 

In some implementations the method includes receiving at the data processing hardware an indication of a selection of one or more other user glyphs and executing by the data processing hardware messaging e.g. via the messaging view between the user and the one or more other users corresponding to the selected one or more other user glyphs . The method may include receiving a gesture across the screen where the gesture indicates selection of the one or more other user glyphs . In some examples the method includes receiving at the data processing hardware an indication of a selection of a messenger glyph displayed on the screen . The messenger glyph has a reference to an application executable on the data processing hardware and indicates one or more operations that cause the application to enter an operating state that allows messaging between the user and the one or more other users corresponding to the selected one or more other user glyphs 

In some implementations the method includes displaying a map on the screen and arranging the other user glyphs on the screen based on geolocations of the corresponding other users . The user data of each other user may include the geolocation of the corresponding other user . Moreover the method may include displaying a user glyph representing the user on the map based on a geolocation of the user 

The method may include receiving at the data processing hardware an indication of a selection of one or more other user glyphs and determining by the data processing hardware possible activities A for the user and the one or more other users corresponding to the selected one or more other user glyphs to perform based on the collective user states of the user and the one or more other users . The method may also include executing by the data processing hardware behaviors having corresponding objectives. Each behavior is configured to evaluate a possible activity A based on whether the possible activity A achieves the corresponding objective. The method includes selecting by the data processing hardware one or more possible activities A based on evaluations E of one or more behaviors and displaying by the data processing hardware results on the screen . The results include the selected one or more possible activities A. In some examples the method includes determining by the data processing hardware one or more predicted outcomes O for each possible activity A based on the collective user states of the user and the one or more other users . In such examples each behavior is configured to evaluate a possible activity A based on whether the possible activity A and the corresponding one or more predicted outcomes O of the possible activity A achieves the corresponding objective. In additional examples the method may include receiving an indication of a gesture across the screen indicating selection of the one or more other user glyphs 

In some implementations at least one behavior is configured to elect to participate or not participate in evaluating the possible activities A based on the received inputs . The method may include for each behavior determining whether any input of the received inputs is of an input type associated with the behavior and when an input of the received inputs is of an input type associated with the behavior incrementing an influence value I associated with the behavior . When the influence value I of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activities A and when the influence value I of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activities A. In some examples the method includes for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value I of the behavior when the decrement criterion is satisfied. The decrement criterion may be satisfied when a threshold period of time has passed since last incrementing the influence value I. In some examples the evaluation E of at least one behavior is weighted based on the corresponding influence value I of the at least one behavior . Moreover the method may include determining the possible activities A based on one or more preferences P of the user . At least one behavior may evaluate a possible activity A based on at least one of a history of selected activities A for the user or one or more preferences P of the user . Furthermore a first behavior may evaluate a possible activity A based on an evaluation E by a second behavior of the possible activity A.

In some implementations the method includes receiving at the data processing hardware a selection of a suggestion glyph displayed on the screen and in response to the selection of the suggestion glyph displaying by the data processing hardware an activity type selector on the screen . The method may further include receiving at the data processing hardware a selection of an activity type and filtering by the data processing hardware the results based on the selected activity type.

Referring to in some implementations a method includes at block receiving at data processing hardware a request of a requesting user to identify other users as likely participants for a possible activity A. The request may be a search request with a search query for other users as likely participants for the possible activity A. The request may be a search request with a search query for other users as likely participants for the possible activity A. Each user has an associated collective user state based on corresponding inputs that include one or more of 1 sensor inputs from one or more sensors 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface . At block the method may include for each other user 1 executing by the data processing hardware behaviors having corresponding objectives where each behavior is configured to evaluate the possible activity A based on whether the possible activity A achieves the corresponding objective and 2 determining by the data processing hardware whether the other user is a likely participant for the possible activity A based on evaluations E of one or more of the behaviors . At block the method includes outputting results e.g. user data identifying the other users determined as being likely participants for the possible activity A.

In some implementations each other user is associated with the user based on a geographical proximity to the user a linked relationship e.g. family member friend co worker acquaintance etc. . Other relationships are possible as well to narrow a pool of other users 

In some implementations at least one behavior is configured to elect to participate or not participate in evaluating the possible activity A based on the corresponding inputs of the other user . The method may include for each behavior determining whether any input of the other user is of an input type associated with the behavior and when an input of the other user is of an input type associated with the behavior incrementing an influence value I associated with the behavior . When the influence value I of the behavior satisfies an influence value criterion the behavior participates in evaluating the possible activity A and when the influence value I of the behavior does not satisfy the influence value criterion the behavior does not participate in evaluating the possible activity A. The method may include for each behavior determining whether a decrement criterion is satisfied for the behavior and decrementing the influence value I of the behavior when the decrement criterion is satisfied. The decrement criterion may be satisfied when a threshold period of time has passed since last incrementing the influence value I.

In some examples the evaluation E of at least one behavior is weighted based on the corresponding influence value I of the at least one behavior . At least one behavior may evaluate the possible activity A based on at least one of a history of positively evaluated activities A for the other user or one or more preferences P of the other user . Moreover a first behavior may evaluate the possible activity A based on an evaluation E by a second behavior of the possible activity A.

The method may include displaying on a screen in communication with the data processing hardware other user glyphs representing the selected other users . Each other user glyph 1 at least partially indicates the collective user state of the corresponding other user and or 2 is associated with a link to a displayable view indicating the collective user state of the corresponding other user and or inputs used to determine the collective user state of the corresponding other user 

Referring to in some implementations a method may include at block receiving at data processing hardware inputs indicative of a user state of a user . The received inputs include one or more of 1 sensor inputs from one or more sensors in communication with the data processing hardware 2 application inputs received from one or more software applications executing on the data processing hardware or a remote device in communication with the data processing hardware and or 3 user inputs received from a graphical user interface . At block the method includes determining by the data processing hardware a collective user state of the user based on the received inputs and at block receiving at the data processing hardware a request of a requesting user to identify other users as likely participants for a possible activity A. The request may be a search request with a search query for other users as likely participants for the possible activity A. At Block the method further includes obtaining at the data processing hardware user data of other users having corresponding collective user states satisfying a threshold similarity with the collective user state of the user and at block outputting results identifying the other users based on the corresponding user data .

The computing device includes a processor memory a storage device a high speed interface controller connecting to the memory and high speed expansion ports and a low speed interface controller connecting to low speed bus and storage device . Each of the components and are interconnected using various busses and may be mounted on a common motherboard or in other manners as appropriate. The processor can process instructions for execution within the computing device including instructions stored in the memory or on the storage device to display graphical information for a graphical user interface GUI on an external input output device such as display coupled to high speed interface . In other implementations multiple processors and or multiple buses may be used as appropriate along with multiple memories and types of memory. Also multiple computing devices may be connected with each device providing portions of the necessary operations e.g. as a server bank a group of blade servers or a multi processor system .

The memory stores information non transitorily within the computing device . The memory may be a computer readable medium a volatile memory unit s or non volatile memory unit s . The non transitory memory may be physical devices used to store programs e.g. sequences of instructions or data e.g. program state information on a temporary or permanent basis for use by the computing device . Examples of non volatile memory include but are not limited to flash memory and read only memory ROM programmable read only memory PROM erasable programmable read only memory EPROM electronically erasable programmable read only memory EEPROM e.g. typically used for firmware such as boot programs . Examples of volatile memory include but are not limited to random access memory RAM dynamic random access memory DRAM static random access memory SRAM phase change memory PCM as well as disks or tapes.

The storage device is capable of providing mass storage for the computing device . In some implementations the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device a flash memory or other similar solid state memory device or an array of devices including devices in a storage area network or other configurations. In additional implementations a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that when executed perform one or more methods such as those described above. The information carrier is a computer or machine readable medium such as the memory the storage device or memory on processor .

The high speed controller manages bandwidth intensive operations for the computing device while the low speed controller manages lower bandwidth intensive operations. Such allocation of duties is exemplary only. In some implementations the high speed controller is coupled to the memory the display e.g. through a graphics processor or accelerator and to the high speed expansion ports which may accept various expansion cards not shown . In some implementations the low speed controller is coupled to the storage device and low speed expansion port . The low speed expansion port which may include various communication ports e.g. USB Bluetooth Ethernet wireless Ethernet may be coupled to one or more input output devices such as a keyboard a pointing device a scanner or a networking device such as a switch or router e.g. through a network adapter.

The computing device may be implemented in a number of different forms as shown in the figure. For example it may be implemented as a standard server or multiple times in a group of such servers as a laptop computer or as part of a rack server system

Various implementations of the systems and techniques described here can be realized in digital electronic and or optical circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product non transitory computer readable medium apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Moreover subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more of them. The terms data processing apparatus computing device and computing processor encompass all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as an application program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interactivity with a user one or more aspects of the disclosure can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor or touch screen for displaying information to the user and optionally a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide interactivity with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

One or more aspects of the disclosure can be implemented in a computing system that includes a backend component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a frontend component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such backend middleware or frontend components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some implementations a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interactivity can be received from the client device at the server.

While this specification contains many specifics these should not be construed as limitations on the scope of the disclosure or of what may be claimed but rather as descriptions of features specific to particular implementations of the disclosure. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multi tasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims. For example the activities recited in the claims can be performed in a different order and still achieve desirable results.

