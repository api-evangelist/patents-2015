---

title: Multi-stream video switching with selective optimized composite
abstract: A method of facilitating a multi-participant communication session with an efficient use of network bandwidth and processing resources is described. The processing resources are made available to the session participants via a switching fabric and composites of less active session participants can be used to minimize the bandwidth utilization between a media server and endpoints.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09538139&OS=09538139&RS=09538139
owner: Avaya Inc.
number: 09538139
owner_city: Santa Clara
owner_country: US
publication_date: 20150424
---
The present disclosure is generally directed toward communications and more particularly toward video based communications.

Advantages of multi stream multi spatial video switching architectures are well understood. High scalability high quality and low latency are included among the advantages of Scalable Video Coding SVC and video simulcast implementations. Disadvantages of these methods however include higher bandwidth usage as the number of participants increase and any single stream devices are limited to one participant.

Traditional video conferencing solutions create a composite consisting of multiple video windows resized and arranged in a configurable layout. The result is a single video image containing all participants delivered from the conferencing mixer to each participant over a single stream. The advantages of this method include bandwidth efficiency and less dependence on client capabilities. But disadvantages include scalability issues high latency less efficient use of resources and less flexibility in window placement on the endpoints.

Multi stream and traditional video conferencing both have their advantages and disadvantages. Embodiments of the present disclosure seek to exploit the advantages of both approaches by combining the approaches and using multi stream as the core of the video conference.

It is therefore one aspect of the present disclosure to provide a combined multi stream switching fabric which may also be referred to as an SVC router or video router or video multi stream switcher. In some embodiments the switching fabric described herein is capable of supporting multiple codecs including non SVC codecs. It should also be appreciated that the switching fabric described herein may correspond to a back to back media relay. In this model each session is assigned a unique SSRC timestamp sequence number and SRTP security context to mask the dynamic nature of the switching fabric resources. In some embodiments the switching fabric comprises a video switching software fabric core with a composite video processing function that can be utilized on demand e.g. during an in progress conference . As an example conferences start out as multi stream switched to a configured participant limit. As a non limiting example the configured participant limit may be three four five . . . ten or more participants depending upon the technology employed bandwidth availabilities and user preferences. In an example of five participants four stream can be delivered to each endpoint thereby enabling each participant to see view every other participant e.g. four because you don t see yourself . On the endpoint four windows can be presented with one participant being presented in each window.

Continuing the example if a sixth participant joins the conference thereby exceeding the configured participant limit video processing resources are surveyed for availability. If video processing resources are available and successfully allocated the two least active speaker streams can be composited and sent on one of the four streams to all endpoints. At the endpoint a user sees three windows with one participant each and a fourth with two participants e.g. the two least active speakers . Using the paradigm the active talker is switched and remains in a window that utilizes very low latency thereby maintaining an acceptable video conferencing experience. It should be appreciated that it is acceptable for the media server to use 100 processed video for endpoints which can only support receiving one stream.

As more participants join the in progress conference they are packed into a subset of the windows. Two or more windows may be dedicated for switching e.g. the two most active speakers to provide a premium low latency experience with scale. Devices which join the conference that are non multi stream capable can be allocated video processing resources on demand or receive a single window switched stream. A minimally capable endpoint with only two receive streams could see many more participants with less network resources than either switched or processing methods alone. The decoding composite and encoding is much more efficient than a typical processed video conference. First an optimal spatial video layer can be used for decoding. This may be the base layer at a low resolution for example 180p. Fewer processing resources are required to decode the lower resolution video. This provides much greater scale and the ability to process video efficiently in software.

In a traditional video conference solution the decoding would be on a high resolution e.g. 720 p or higher stream from each endpoint which requires more resources this is where hardware acceleration and digital signal processors are typically deployed . Second only a portion of the conference is being processed lowering resource requirements. Third the resources can be added behind the switching fabric on demand and only when required e.g. when video switching is not adequate thereby lowering the video processing resource requirements even further. Finally if resources are not available the conference can continue in a switching mode where in the traditional video conference solution resources are required up front or the call is rejected. This simplifies engineering and is a natural way to provide premium service to select individuals easily.

Compared to existing dual hybrid solutions with a Multi Point Control Unit MCU and a cascading media server the proposed solution is less complex and less costly to implement. Embodiments of the present disclosure can provide very high scale video conferencing augmented with bandwidth efficient compositing on demand where required and in software. The multi stream switching is used in conjunction with the video processing to minimize video decoding and encoding demands. This is achieved by utilizing video switching up to a configured stream window limit and then applying processing resources on the remainder of the streams and switching out the composited video. In addition utilizing the multi spatial streams being received to select the appropriate layer to decode further reduces video processing resource consumption.

In other words it is an aspect of the present disclosure to provide a video switching fabric at the core of a video conference and combine multi stream video with embedded optimized on demand compositing.

determining that a number of participants involved in a communication session exceeds a predetermined threshold 

in response to determining that the number of participants involved in the communication session exceeds the predetermined threshold creating a composite of at least two media streams for delivery along with other individual media streams to a communication device of a first participant wherein the composite is encoded to utilize less bandwidth than the streams that make up the composite individually and

causing the combined media stream to be delivered to the communication device of the first participant in addition to the switched video streams so that the communication device of the first participant presents the composite in a viewing screen along with the other individual media streams in separate viewing screens.

The term automatic and variations thereof as used herein refers to any process or operation done without material human input when the process or operation is performed. However a process or operation can be automatic even though performance of the process or operation uses material or immaterial human input if the input is received before performance of the process or operation. Human input is deemed to be material if such input influences how the process or operation will be performed. Human input that consents to the performance of the process or operation is not deemed to be material .

The term computer readable medium as used herein refers to any tangible storage that participates in providing instructions to a processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example NVRAM or magnetic or optical disks. Volatile media includes dynamic memory such as main memory. Common forms of computer readable media include for example a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium magneto optical medium a CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes a RAM a PROM and EPROM a FLASH EPROM a solid state medium like a memory card any other memory chip or cartridge or any other medium from which a computer can read. When the computer readable media is configured as a database it is to be understood that the database may be a graph database as described herein. Accordingly the disclosure is considered to include a tangible storage medium and prior art recognized equivalents and successor media in which the software implementations of the present disclosure are stored.

The terms determine calculate and compute and variations thereof as used herein are used interchangeably and include any type of methodology process mathematical operation or technique.

The term module as used herein refers to any known or later developed hardware software firmware artificial intelligence fuzzy logic or combination of hardware and software that is capable of performing the functionality associated with that element. Also while the disclosure is described in terms of exemplary embodiments it should be appreciated that individual aspects of the disclosure can be separately claimed.

The ensuing description provides embodiments only and is not intended to limit the scope applicability or configuration of the claims. Rather the ensuing description will provide those skilled in the art with an enabling description for implementing the embodiments. It being understood that various changes may be made in the function and arrangement of elements without departing from the spirit and scope of the appended claims.

It should be appreciated that embodiments of the present disclosure can be utilized in numerous conferencing environments such as video conferencing environments audio conferencing environments multi media conferencing environments etc.

Furthermore while the illustrative embodiments herein show the various components of a system collocated it is to be appreciated that the various components of the system can be located at distant portions of a distributed network such as a communication network and or the Internet or within a dedicated secure unsecured and or encrypted system. Thus it should be appreciated that the components of the system can be combined into one or more devices such as an enterprise server or collocated on a particular node of a distributed network such as an analog and or digital communication network. As will be appreciated from the following description and for reasons of computational efficiency the components of the system can be arranged at any location within a distributed network without affecting the operation of the system. For example the various components can be located in a local server at one or more users premises or some combination thereof.

With reference initially to an illustrative communication system in which collaboration amongst a plurality of users is facilitated as will be described in accordance with at least some embodiments of the present disclosure. The system is shown to include a communication network multiple communication devices operated by one or more users a second communication network an optional border element between the networks a media server and a conference server .

In accordance with at least some embodiments of the present disclosure the communication network and second network may comprise any type of known communication medium or collection of communication media and may use any type of protocols to transport messages between endpoints. The communication networks may include wired and or wireless communication technologies. The Internet is an example of the communication network that constitutes and Internet Protocol IP network consisting of many computers computing networks and other communication devices located all over the world which are connected through many telephone systems and other means. Other examples of the communication network include without limitation a standard Plain Old Telephone System POTS an Integrated Services Digital Network ISDN the Public Switched Telephone Network PSTN a LAN a WAN a Session Initiation Protocol SIP network a Voice over IP VoIP network a cellular network an enterprise network a contact center and any other type of packet switched or circuit switched network known in the art. In addition it can be appreciated that the communication network need not be limited to any one network type and instead may be comprised of a number of different networks and or network types. Moreover the communication network may comprise a number of different communication media such as coaxial cable copper cable wire fiber optic cable antennas for transmitting receiving wireless messages and combinations thereof. In some embodiments the communication network may correspond to a public network e.g. the Internet whereas the second network may correspond to a private network administered by a private enterprise with personalized security rules. Thus the network border element may comprise functionality to secure the second network from attempted attacks from the public network . Examples of a network border element or functions that may be performed thereby include without limitation a firewall a Session Border Controller SBC a Network Address Translator NAT or the like.

In some embodiments a communication device may include a personal communication device or a shared communication device e.g. a conference phone . Examples of suitable communication devices include without limitation a telephone a softphone a cellular phone a multi speaker communication device e.g. conference phone a video phone a PC a laptop a tablet a PDA a smartphone a thin client or the like. The communication devices may be pure consumers of audio video e.g. having a speaker only and or having a screen only pure producers of audio video e.g. having a microphone and or camera only or consumers and producers of audio video. It should be appreciated that a communication device may be configured to support single or multi user interactions with other network connected devices within an enterprise communication network and or across multiple communication networks e.g. across Session Border Controllers SBCs . In the depicted embodiment each communication device has a single user associated therewith but it should be appreciated that a single communication device may be shared by more than one user without departing from the scope of the present disclosure.

The media server may correspond to one or more servers e.g. a single server or a server cluster that facilitates the distribution and sharing of media between communication session participants. In some embodiments the media server may be configured to receive a plurality of media streams from each communication device involved in a communication session and then distribute those streams to the other participants. The media server may therefore correspond to the media bridge and distribution center of a communication session or conference.

The conference server may correspond to a controller for the media server and or provide communication session participants the ability to control various aspects of the communication session. In some embodiments the conference server may instruct the media server to distribute different types of media to different participants depending upon each participant s involvement in the session. For instance the conference server may instruct the media server to transmit higher resolution voice and or video media for a first participant to other participants if that first participant is a more active participant in the communication session e.g. speaking more frequently asking more questions moving more etc. . Conversely the conference server may instruct the media server to transmit lower resolution voice and or video media for a second participant to other participants if that second participant is less active in the communication session e.g. speaking less frequently asking fewer questions moving less etc. . As shown in the conference server may have an optional control link directly to the media server to provide control instructions and receive status information for the media being distributed by the media server . Alternatively or additionally the conference server may communicate with the media server via the communication network . In still other embodiments the functionality of the conference server and media server may be incorporated into a single server or collection of servers that are co located with one another.

The media server may correspond to a device e.g. server or collection of devices that enable media compositing and distribution during a communication session between two or more and usually three or more session participants. In some embodiments the media server may include a media mixer and logic for distributing the composited media among the conference participants. The media server may even provide a fully composited version of the conference to each participant or user s communication device .

With reference now to additional details of a system for sharing media between conference participants will be described in accordance with at least some embodiments of the present disclosure. As shown in each communication device involved in a communication session may receive a media stream from the media server that corresponds to a combination of at least some media being provided to the media server by each communication device . More specifically the first user s e.g. User A communication device may provide a first media stream to the media server . The first media stream may correspond to encoded voice and or video content captured by a camera and or microphone of User A s communication device and delivered to the media server via communication network . The second user s e.g. User B communication device may provide a second media stream to the media server . The second media stream may correspond to encoded voice and or video content captured by a camera and or microphone of User B s communication device and delivered to the media server via communication network . The third user s e.g. User C communication device may provide a third media stream to the media server . The third media stream may correspond to encoded voice and or video content captured by a camera and or microphone of User B s communication device and delivered to the media server via communication network . The fourth user s e.g. User D communication device may provide a fourth media stream to the media server . The fourth media stream may correspond to encoded voice and or video content captured by a camera and or microphone of User B s communication device and delivered to the media server via communication network . Although shows four participants to the communication session conference it should be appreciated that embodiments of the present disclosure can accommodate a greater or lesser number of participants. In fact embodiments of the present disclosure are better suited to gain efficiencies with a larger number of participants as will be described in further detail herein.

The media server receives all of the media content from each communication device and is configured to build composited media streams and distribute the composited media streams to each conference participant. The composited media streams distributed to the conference participants may be the same or they may be different e.g. specific to the participant . In some embodiments the first combined media stream may only comprise content from the second media stream third media stream and fourth media stream . Similarly the second media stream may only comprise content from the first media stream the third media steam and the fourth media stream . In other words the media server may be intelligent enough to not provide media back to a communication device that already sent that media. Instead a user may be allowed to view their own local media feed with a local feedback rather than requiring their media to travel back and forth between the media server .

The conference server may be further configured to instruct the media server to provide different resolution of media to different communication devices depending upon the relative involvement and or activity of a particular conference participant. For instance if all participants are highly involved in a communication session then the media server may provide the highest resolution or lowest latency media to all other participants. However as the number of participants grows there will be a greater opportunity to identify those participants that are less involved in a communication session than others. In such a circumstance the conference server may instruct the media server to provide lower bandwidth or higher latency media on the composited media streams for the less active participants. Thus the combined media stream and or may comprise a composite of higher resolution media for more active participants and lower resolution media for less active participants . In some embodiments the media server may transcode or lower the resolution of media received from a media stream prior to compositing it with other media streams to create a combined media stream .

It should be kept in mind that with SVC or simulcast architectures the clients endpoints send multiple spatial layers multiple resolutions as well as multiple temporal layers possible frame rates and multiple quality layers or a combination thereof. SVC codecs support this behavior natively. The simulcast approach can be done without an SVC codec by using a traditional codec and performing multiple encodes and sending those to the server. The key is the server can choose the resolution which matches the endpoint and or network requirements for either switching or processing for compositing . Ideally the media server chooses the resolution to composite that is closest to the target in resolution so it doesn t waste cpu decoding higher resolution video.

With reference now to additional details of a media server will be described in accordance with at least some embodiments of the present disclosure. The media server is shown to include a controller switching fabric including an endpoint side and a processing resources backplane a plurality of endpoint ports N and one or more network interfaces for interfacing with processing resources. In some embodiments the processing resources backplane corresponds to an IP network or the like. Thus the backplane may be logical in nature as it is an IP network using IP protocols.

In some embodiments the controller may include functionality of the conference server or the controller may be configured to implement actions consistent with instruction received from the conference server . The controller controls operations of the switching fabric which basically enables a connection between the endpoint side of the switching fabric and the processing resources backplane . In other words the controller may control the types and number of interconnections between the endpoint side and the processing resources backplane . The endpoint side of the switching fabric interfaces with the ports N of the media server that are exposed to communication devices . The ports N may be specifically addressed or made dynamically available depending upon need. Each port may correspond to an Ethernet port or similar interface between the communication network and the media server . The ports used are TCP or UDP ports but typically would be UDP since RTP is transported most commonly over UDP. The media server may use one or more network interface ports typically Ethernet connected to a layer 2 3 switch to communicate with the endpoints and the processing resources. Both could be reached through a single Ethernet port on the server or multiple. We could use a dedicated Ethernet port for the processing resources if we want or multiple same for the endpoints or we could share one. In other words the ports N provide the physical interface between the media server and the communication network thereby enabling the media server to interact with the communication devices .

The network interface s may be used to connect the media server to one or more processing resources as the size of a communication session changes e.g. grows or becomes smaller . In some embodiments the media server may utilize the switching fabric to initially connect the communication devices together with a single processing resource if the communication session is only among a small number of participants. If the number of participants grows however and additional processing resources are required to continue facilitating the communication session the controller may instruct the switching fabric to connect the endpoint side with more processing resources via the network interface s . In other words as processing demands change during a communication session the controller may cause the switching fabric to connect more or fewer processing resources. In the context of video processing resources the video processing resources can be delivered to the communication devices if and when required using the backplane of the switching fabric . Each communication device or endpoint may be anchored to the switching fabric via the ports N. In some embodiments each endpoint session attached to the switching fabric has a unique SSRC timestamp sequence numbers SRTP security contexts and or SDP negotiation options. Thus each communication device can negotiate the unique parameters of their connection with the media server but receive the benefits of shared processing resources made available via the switching fabric .

In accordance with at least some embodiments of the present disclosure. The video processing resources made available via the switching fabric may correspond to software based processing resources thereby enabling a flexible implementation and allowing for virtualization of the resources. Furthermore the switching fabric provides the ultimate flexibility in resource packing because resources can be swapped out and or replaced with other resources without moving or re inviting the endpoints communication devices . The switching fabric enables processing resources to be made available on demand and or during session setup. Furthermore resource pools can be expanded or contracted dynamically e.g. during a communication session to adapt to processing requirements of the session e.g. a session having a growing or shrinking number of participants .

With reference now to additional details of an intelligent and flexible processing system will be described in accordance with at least some embodiments of the present disclosure. The system is shown to include a plurality of video processing resources made available to endpoints via a video switching fabric and audio anchoring and compositing module . The video switching fabric and or audio anchoring and compositing module may be incorporated in or similar to the switching fabric or they may be provided as separate components of the media server .

The video processing resources may correspond to software transcoding resources that are capable of being distributed across multiple servers for scale. The video processing resources can be added to support an in progress communication session seamlessly e.g. without notifying any user of their addition . As discussed above the transcoding in software enables support for virtualization as well as scaling schemes through the pooling of servers. In some embodiments an instance of each video processing resource may run co resident on the same server. It may be possible to provide a cluster of media server that share the same pool of video processing resources. In other words a plurality of media servers may share a common pool of video processing resources . A network control protocol may be used to enable the exchange of control information and status information between the video processing resources and the video switching fabric whereas a media channel e.g. video over LAN backplane can be used to carry media between the video processing resources and the video switching fabric .

In the depicted embodiment the endpoints communication devices are connected to the video processing resources via the switching fabric . The switching fabric in some embodiments may correspond to a low latency and high capacity software video switching fabric that provides the most flexible resource selection options due to its high capacity. Video processing resources can be delivered to communication devices via the fabric as opposed to endpoints being delivered to the video processing resources . A media channel may be used to carry video e.g. RTP secure RTP RTCP secure RTCP to from communication devices . Likewise media streams from communication devices may also be provided by media channel . Audio may be shared between communication devices and the media server via a separate communication channel which is used to carry audio e.g. RTP secure RTP RTCP secure RTCP to from communication devices . A network control protocol may be used to share audio and video synchronization data between the video switching fabric and the audio anchoring and compositing module .

Network control protocols can be used to connect the controller and SIP User Agent to the video switching fabric and audio anchoring and compositing module respectively. The use of a separate controller and SIP User Agent may be contrasted to the media server implementation of where the controller was internal to the media server . In the embodiment of there is no application or service logic in the media server and the controller and SIP User Agent use standard media control protocols to control the operations of the media server as well as the switching fabric and audio anchoring and compositing module contained therein. As a non limiting example server media server may be provided that has two transports for control protocols. One is SIP the other is HTTP REST. More specifically the media server may have a SIP useragent and a REST useragent. The type of UA used to control the media server is not significant since the control protocols used are agnostic. In a non limiting example MSML over SIP or over REST can be used.

With reference now to user conference views and a user experience associated with a conference call between a plurality of users will be described in accordance with at least some embodiments of the present disclosure. Referring initially to a first conference view for User A is shown to include a viewing window having a plurality of conference view elements incorporated therein. The window may be rendered via an application on the communication device via a browser of the communication device or a combination thereof. In some embodiments the window includes a plurality of video screens for each of the other participants e.g. User B User C User D as well as a self viewing screen that enables User A to see the video information of himself that is being provided to the other participants. In some embodiments the sizes of screens may be the same but larger as compared to the self viewing screen but the sizes of each or all of the screens may be specifically configured to accommodate each user s viewing preferences.

As discussed above the content displayed in screens may correspond to content received via the combined media stream whereas the content displayed in screen may correspond to content being delivered to media server via the first media stream . The media server may provide each video feed via the combined media stream with an index indicating metadata associated with the feed. Thus the first video screen knows to also present identifying information for User B and similar information for the other video screens.

Since collaboration is also enabled via the communication session the window may include other collaboration features such as a document sharing window a plurality of control buttons for the document sharing window a plurality of control buttons for the audio and or video portions of the collaboration as well as a participant list . In some embodiments the participants may be enabled to share views of their desktops or share documents for collaboration and editing among the other participants. Each participant may request or obtain control and or stop sharing a desktop view by utilizing the appropriate control buttons . Moreover a user may be allowed to hang up on a call mute their microphone record some or all of the media streams adjust audio parameters and or adjust video parameters with the appropriate control buttons .

The participant list may include a display of each participant involved in the communication session. The information displayed in the participant list may be received from the media server or from the conference server . The status information displayed for a particular user in the communication session may include an indication of whether a particular user is speaking not speaking has their microphone on mute is moving or any other status information that can be shared amongst participants.

In some embodiments each user displayed in the screens may have their video information encoded similarly which means that the resolution of each participant s video may be comparable or identical. Of course if a particular user s communication device does not support a higher level of encoding as compared to another user s communication device then the media server may provide the best resolution for each participant or alternatively provide a best common resolution for every participant.

With reference now to the window is updated to show that an additional user e.g. User E has joined the in progress communication session. In accordance with at least some embodiments the additional user e.g. User E can have their media displayed in a shared viewing screen along with media from another user e.g. User D . As an example the other user displayed with the newly added user may correspond to the least active user in the conference the most junior user in the conference or the like. Any other selection criteria for including users in the shared viewing screen can be used without departing from the scope of the present disclosure.

Advantageously since the overall size of the shared viewing screen is approximately the same as the overall size of an individual screen or there is not as much need for the highest resolution of video for the users displayed in the shared viewing screen . Thus the media server may know that User A is viewing Users D and E in the shared viewing screen and therefore may provide a lower quality resolution or higher latency video in the combined media stream for the portions attributed to Users D and E. This enables a bandwidth savings between the media server and User A s communication device .

With reference now to the window is shown to be updated to move User E into the top viewing screen whereas now Users C and D are in the shared viewing screen . This movement may have been done in response to determining that User E is more active in the communication session e.g. speaking more moving more sharing their screen currently has control of the document sharing window etc. as compared to Users B C and D. In response to making a determination to move User E to the top viewing screen the other viewing screens may also be updated such that the second viewing screen displays User B and the shared viewing screen displays Users C and D. Again even though five participants are involved in the communication session the window only has three viewing screens in addition to the self viewing screen and since the users displayed in the shared viewing screen are displayed in a smaller viewing area the resolution of their media is less important than the resolution of the media for Users B and E. Furthermore User A may also tolerate higher latency for the media of Users C and D since they are less active and presumably listening to Users E and B more than speaking and providing actual content to the communication session.

In some embodiments the status of each participant may also be updated to reflect that a particular user is being displayed in a particular location of User A s window . For instance the status depicted for User E may indicate that he is most active whereas the status depicted for User B may indicate that she is currently controlling the document sharing window . The status for User A as an example may indicate whether User A is in one or more shared screens of other participants whether User A is in a primary viewing screen of other participants and to what extent if at all User A s media is being transcoded for the other users.

Another scenario is depicted in where additional users are included in the shared viewing screen . In accordance with at least some embodiments of the present disclosure the most active users hosts of the meeting users currently under control of the document sharing window or the like may be presented in the primary viewing screens whereas less active users non hosts or users not controlling the document sharing window may be displayed in the shared viewing screen . Again the amount of bandwidth required to carry the video content being displayed in the shared viewing screen may be less than is required to carry the video content being displayed in the primary viewing screens . At a minimum utilization of the shared viewing screen and a decreased bandwidth for the video of the users presented therein is at least saving from the need to carry full high bandwidth video for each user in the shared viewing screen .

With reference now to various methods will be described. It should be appreciated that the steps of any method described herein may be performed in any order and by any component or combination of components depicted and or described in connection with . As an example the method depicted in may be performed by a media server and or conference server or components thereof.

With reference initially to a method of delivering video composites to endpoints involved in a conference will be described in accordance with embodiments of the present disclosure. The method begins with a media server component thereof or equivalent structure receiving multiple media streams for conference participants involved in a communication session or conference e.g. video conference step . Each participant s communication device may deliver media in different encoding types and at different resolutions. Some communication devices may provide the media server with encoded media at 180 p whereas other communication devices may provide the media server with encoded media at 720 p or 1080 p. The quality of the media may also depend upon the network capabilities connecting the communication device with the media server . What is described here is spatial scalability resolution . Temporal and quality are also factors. An example would be non active talkers who are composited may have their video sent at a lower frame rate temporal scalability to save bandwidth and or processing resources. The media server may also just tell the endpoint what it needs it to encode based on the requirements it sees from other endpoints in the same conference.

The method continues by determining a best encoding for each endpoint step . In some embodiments the best encoding may correspond to a highest possible encoding for every media stream to be delivered to an endpoint. In some embodiments the best encoding may correspond to a best common encoding among all media streams received at the media server . In some embodiments the media server may provide higher bit encoding for participants that are more active in a communication session whereas lower bit encoding can be used for less active participants or for participants that will be depicted in a shared viewing screen of the receiving user s window .

The method then mixes the video composites for each endpoint based on the best encoding determination of step step . The composited video composites are then transmitted to each endpoint via the communication network step . In some embodiments the combined media stream delivered to each endpoint may be specially configured for that endpoint e.g. to exclude that user s video and to minimize bandwidth consumption for other participants that will be depicted in a shared viewing screen for that user . Transmission of the video composites for each user can be accomplished using any known video delivery techniques and can be customized for each user based on their device s capabilities network capabilities communication preferences viewing preferences relative activity in the communication session etc.

With reference now to a method of dynamically adjusting a video conference presentation will be described in accordance with embodiments of the present disclosure. The method begins by determining a number of conference participants involved in a communication session step . The determined number of participants is compared to a participant threshold step . Any integer value can be used for this threshold. In the depicted example of the threshold may correspond to four participants but it should be appreciated that a larger or smaller threshold can be used without departing from the scope of the present disclosure.

If the determined number of participants does not exceed the predetermined threshold then the method continues by utilizing the media server and or video processing resources to generate a composited video with fully encoded media streams for each participant step . Each stream generated in step is delivered to each participant as a combined media stream so that each participant s communication device can display the portions of the composited media stream in their presentation window step . Thereafter the method continues by determining if the conference is completed step . If not the method returns to step .

Referring back to step if the number of participants involved in the communication session at any time e.g. at its beginning or at some point in time thereafter and before the conference is completed exceeds the predetermined threshold then the method proceeds by creating network composites of two or more media streams step . In some embodiments the composites for each user can be custom created to include those participants that are least active in the communication session. For instance User A may receive a composite of Users D and E if those users correspond to the least active users among Users B C D and E. Simultaneously User B may receive a composite of Users A and E if those users correspond to the least active users among Users A C D and E. Thus each composite can be different for each endpoint since a user will not receive a composite of themselves. The composite can be encoded at a lower resolution that other media streams when included in the combined media stream thereby saving network bandwidth and processing resources.

The composite is then composited with the other individual feeds to form the combined media stream for each user step . The composited media streams each containing a variation of the composited composite are then delivered to each participant s communication device step . Again the method determines if the conference is completed step and if not returns to step . If however the conference is determined to be completed then the method proceeds by ending the conference and returning any video processing resources and or media servers back to their respective pools so that they can be used by other conferences step .

With reference now to a method of adjusting participants being depicted in a composite view e.g. a shared viewing screen based on active speaker information will be described in accordance with embodiments of the present disclosure. The method begins by determining a number of participants included in a conference current exceeds a predetermined threshold step . This particular step may be similar or identical to step being answered in the affirmative.

The method proceeds by dedicating one or more screens of a window for switching during the conference step . The one or more dedicated screens may correspond to a shared viewing screen of a window .

The method then proceeds by adjusting the participants presented in the dedicated screen s based on active speaker information step . As can be appreciated relative voice activity e.g. frequency of speaking may correspond to one parameter used to determine which participants correspond to the most active or are considered active speakers. Other parameters or information that may be considered as part of determining which participants are most active speakers include voice amplitude time since last utterance motion frequency time since last motion conference host e.g. meeting coordinator versus non host e.g. non meeting coordinator current controller of shared documents current controller of pointer current participant sharing screen or combinations thereof.

Based on the current active speaker information the method proceeds by performing relatively low resolution decoding for the presentation of participants within the dedicated screen s step . Other participants that are not included in the presentation within the dedicated screen s e.g. shared viewing screen may have their video information encoded at a higher resolution and or lower latency thereby enabling a savings of bandwidth to avoid higher resolution for less active participants.

With reference now to a method of dynamically adjusting a number of resources used during a conference will be described in accordance with embodiments of the present disclosure. The method begins by assigning a first number of video processing resources to a conference or communication session step . The video processing resources may be made available to the conference participants and their communication devices via a switching fabric and intelligent control by a controller as described herein.

The method continues by determining whether it is necessary to adjust the number of resources made available to the communication session participants step . This may correspond to determining that the number of participants has increased and or decreased as compared to a time when the initial determination of step was made. If the number of participants has not changed then it can be assumed that there is no need to adjust the number of resources e.g. increase or decrease thus the method proceeds by determining if the conference is complete step . If not then the method returns back to step . Higher priority conferences may also take resources away from lower priority conferences. In this case a previously switched conference with processing resources may have those processing resources reaped for use by a different conference thus falling back to switched video only. Although this would not be typical outside of military type deployments it is a benefit because the reclaiming of resources can be less intrusive. i.e. impacted conference is not dropped .

If the number of resources is determined to be in need of adjustment e.g. due to an increase or decrease in conference participants the method continues by adding or subtracting one or more resources for the in progress communication session via manipulation of the switching fabric step . The addition or subtraction of video processing resources is seamless and transparent to the session participants. The method then proceeds to step to determine if the conference is completed. Once the conference has completed e.g. all participants have hung up the method continues by releasing the video processing resource and or media server resources for use by other communication sessions step .

In the foregoing description for the purposes of illustration methods were described in a particular order. It should be appreciated that in alternate embodiments the methods may be performed in a different order than that described. It should also be appreciated that the methods described above may be performed by hardware components or may be embodied in sequences of machine executable instructions which may be used to cause a machine such as a general purpose or special purpose processor GPU or CPU or logic circuits programmed with the instructions to perform the methods FPGA . These machine executable instructions may be stored on one or more machine readable mediums such as CD ROMs or other type of optical disks floppy diskettes ROMs RAMs EPROMs EEPROMs magnetic or optical cards flash memory or other types of machine readable mediums suitable for storing electronic instructions. Alternatively the methods may be performed by a combination of hardware and software.

Specific details were given in the description to provide a thorough understanding of the embodiments. However it will be understood by one of ordinary skill in the art that the embodiments may be practiced without these specific details. For example circuits may be shown in block diagrams in order not to obscure the embodiments in unnecessary detail. In other instances well known circuits processes algorithms structures and techniques may be shown without unnecessary detail in order to avoid obscuring the embodiments.

Also it is noted that the embodiments were described as a process which is depicted as a flowchart a flow diagram a data flow diagram a structure diagram or a block diagram. Although a flowchart may describe the operations as a sequential process many of the operations can be performed in parallel or concurrently. In addition the order of the operations may be re arranged. A process is terminated when its operations are completed but could have additional steps not included in the figure. A process may correspond to a method a function a procedure a subroutine a subprogram etc. When a process corresponds to a function its termination corresponds to a return of the function to the calling function or the main function.

Furthermore embodiments may be implemented by hardware software firmware middleware microcode hardware description languages or any combination thereof. When implemented in software firmware middleware or microcode the program code or code segments to perform the necessary tasks may be stored in a machine readable medium such as storage medium. A processor s may perform the necessary tasks. A code segment may represent a procedure a function a subprogram a program a routine a subroutine a module a software package a class or any combination of instructions data structures or program statements. A code segment may be coupled to another code segment or a hardware circuit by passing and or receiving information data arguments parameters or memory contents. Information arguments parameters data etc. may be passed forwarded or transmitted via any suitable means including memory sharing message passing token passing network transmission etc.

While illustrative embodiments of the disclosure have been described in detail herein it is to be understood that the inventive concepts may be otherwise variously embodied and employed and that the appended claims are intended to be construed to include such variations except as limited by the prior art.

