---

title: Methods and computer program products for generating a model of network application health
abstract: Provided are methods and computer program products for generating a model of network application health. Methods may include receiving activity data that corresponds to activities of multiple applications that are operable to execute on at least one networked device, and combining the received activity data to remove redundant portions thereof and/or to reconcile inconsistencies therein. Based on the received activity data, ones of the multiple applications are identified, and relationships between the identified applications are determined. A model is generated including the identified applications and the relationships therebetween, and a representation of the model is displayed. Related computer program products are also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09634915&OS=09634915&RS=09634915
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09634915
owner_city: Redmond
owner_country: US
publication_date: 20151012
---
This application is a continuation of U.S. application Ser. No. 12 855 839 filed Aug. 13 2010 entitled Methods and Computer Program Products for Generating a Model of Network Application Health and assigned U.S. Pat. No. 9 158 649 which is the non provisional patent application claiming priority to U.S. Provisional Application No. 61 234 049 filed Aug. 14 2009 and entitled Network Monitoring Methods Systems and Computer Program Products the disclosures of which are hereby incorporated by reference in their entirety.

The present invention relates to computer networks and more particularly to network performance monitoring methods devices and computer program products.

The growing presence of computer networks such as intranets and extranets has brought about the development of applications in e commerce education manufacturing and other areas. Organizations increasingly rely on such applications to carry out their business production or other objectives and devote considerable resources to ensuring that the applications perform as expected. To this end various application management monitoring and analysis techniques have been developed.

One approach for managing an application involves monitoring the application generating data regarding application performance and analyzing the data to determine application health. Some system management products analyze a large number of data streams to try to determine a normal and abnormal application state. Large numbers of data streams are often analyzed because the system management products may not have a semantic understanding of the data being analyzed. Accordingly when an unhealthy application state occurs many data streams may have abnormal data values because the data streams are causally related to one another. Because the system management products may lack a semantic understanding of the data they may not be able to assist the user in determining either the ultimate source or cause of a problem. Additionally these application management systems may not know whether a change in data indicates an application is actually unhealthy or not.

Current application management approaches may include monitoring techniques such as deep packet inspection DPI which may be performed as a packet passes an inspection point and may include collecting statistical information among others. Such monitoring techniques can be data intensive and may be ineffective in providing substantively real time health information regarding network applications. Additionally packet trace information may be lost and application specific code may be required.

Embodiments of the present invention are therefore directed towards solving these and other related problems.

It should be appreciated that this Summary is provided to introduce a selection of concepts in a simplified form the concepts being further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of this disclosure nor is it intended to limit the scope of the invention.

Some embodiments of the present invention are directed to a method for monitoring application performance in a networked device. Methods may include collecting performance data using at least one kernel space driver interface the collected performance data corresponding to at least one application running on the networked device. Multiple kernel level metrics and or multiple user level metrics based on the collected performance data may be generated and an event incorporating at least one of the kernel level metrics and at least one of the user level metrics may be generated.

In some embodiments ones of the kernel level metrics and or ones of the user level metrics that were generated during a predefined time interval may be aggregated. The event generated may incorporate the aggregated metrics generated during the predefined time interval.

Some embodiments provide that the at least one application includes multiple applications and ones of the kernel level metrics and or ones of the user level metrics that correspond to a specified one of the applications may be aggregated. The event generated may incorporate the aggregated metrics corresponding to the specified one of the applications.

In some embodiments a first portion of performance data may be selectively collected from an operating system internal kernel interface that provides an interface between a network protocol and a network protocol client. A second portion of performance data may be selectively collected from an application oriented system call interface to a transport network stack. Some embodiments provide that the at least one application includes multiple applications. The first portion and the second portion of performance data may be aggregated where the first portion and second portion correspond to a specified one of the applications. The event generated may incorporate aggregated performance data corresponding to the specified one of the applications.

In some embodiments the collected performance data may be processed to remove redundant portions thereof and or to reconcile inconsistent data therein.

Some embodiments provide that the collected performance data may indicate detection of network link establishment detection of extant network links detection of network link failure detection of network link termination detection of network port binding detection of extant bound network ports detection of network port unbinding detection of pending reads detection of completed reads detection of stalled reads network bytes sent network bytes received process identification process start time process exit time local Internet Protocol IP address local port remote IP address and or remote port among others.

In some embodiments respective ones of the kernel level metrics may include server response time read wait time number of pending reads number of completed reads average read wait time number of stalled reads number of completed responses total read wait time total bytes sent total response time and or number of responses among others.

Some embodiments provide that respective ones of the user level metrics may include aggregate central processing unit percentage aggregate memory percentage total network bytes sent total network bytes received number of page faults number of pages input number of pages output queue length number of bytes read from logical disk number of bytes written to logical disk number of completed read requests on logical disk number of completed write requests on logical disk total read wait times and or total write wait times among others.

In some embodiments the collected performance data may include an Internet Protocol IP address. A reverse Domain Name System DNS lookup of the IP address may be performed to determine a DNS name associated with the IP address. The event generated may incorporate the determined DNS name.

Some embodiments provide a method for generating a model of network application health. Activity data corresponding to activities of multiple applications executing on at least one networked device is received and combined to remove redundant portions thereof and or to reconcile inconsistencies therein. Based on the received activity data ones of the multiple applications are identified and relationships between the applications are determined. A model including the identified applications and the relationships between the applications is generated and a representation thereof is displayed.

Some embodiments provide that the at least one networked device includes multiple networked devices. Receiving activity data includes receiving activity data from multiple collector applications that are each operable to execute on respective ones of multiple networked devices. In some embodiments the existence of a second application for which corresponding activity data was not received may be inferred based on identification of a first application for which corresponding activity data was received and the relationship between the first and second applications may be inferred based on the identification of the first application.

Some embodiments provide that the received activity data is stored along with associated data indicating when the activity data was received. Identification of applications is based on stored activity data received during a specified time interval.

In some embodiments the at least one network device includes a virtual machine and receiving activity data includes receiving activity data from a collector application executing within the virtual machine. In other embodiments the at least one network device includes a host machine that is operable to execute at least one virtual machine and receiving activity data includes receiving activity data from a collector application executing on the host machine with the collector application being external to the at least one virtual machine.

Some embodiments provide that identifying the ones of multiple applications and the relationships between the applications includes correlating the received activity data with a predefined telecommunications standard. In some embodiments the predefined telecommunications standard includes the port numbers list maintained by the Internet Assigned Numbers Authority IANA .

Some embodiments provide that generating a model includes dynamically generating a real time or near real time representation of the activities of the multiple applications.

In some embodiments a computer program product including a non transitory computer usable storage medium having computer readable program code embodied in the medium is provided. The computer readable program code is configured to perform operations corresponding to methods described herein.

Other methods devices and or computer program products according to exemplary embodiments will be or become apparent to one with skill in the art upon review of the following drawings and detailed description. It is intended that all such additional methods devices and or computer program products be included within this description be within the scope of the present invention and be protected by the accompanying claims.

In the following description for purposes of explanation and not limitation specific details are set forth such as particular architectures interfaces techniques etc. in order to provide a thorough understanding of the present invention. However it will be apparent to those skilled in the art that the present invention may be practiced in other embodiments that depart from these specific details. In other instances detailed descriptions of well known devices circuits and methods are omitted so as not to obscure the description of the present invention with unnecessary detail. While various modifications and alternative forms of the embodiments described herein may be made specific embodiments are shown by way of example in the drawings and will herein be described in detail. It should be understood however that there is no intent to limit the invention to the particular forms disclosed but on the contrary the invention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the invention as defined by the claims. Like reference numbers signify like elements throughout the description of the figures.

As used herein the singular forms a an and the are intended to include the plural forms as well unless expressly stated otherwise. It should be further understood that the terms comprises and or comprising when used in this specification are taken to specify the presence of stated features steps operations elements and or components but do not preclude the presence or addition of one or more other features steps operations elements components and or groups thereof. It will be understood that when an element is referred to as being connected or coupled to another element it can be directly connected or coupled to the other element or intervening elements may be present. Furthermore connected or coupled as used herein may include wirelessly connected or coupled. As used herein the term and or includes any and all combinations of one or more of the associated listed items and may be abbreviated as .

Unless otherwise defined all terms including technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. It will be further understood that terms such as those defined in commonly used dictionaries should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.

It will be understood that although the terms first second etc. may be used herein to describe various elements these elements should not be limited by these terms. These terms are only used to distinguish one element from another.

Exemplary embodiments are described below with reference to block diagrams and or flowchart illustrations of methods apparatus systems and or devices and or computer program products. It is understood that a block of the block diagrams and or flowchart illustrations and combinations of blocks in the block diagrams and or flowchart illustrations can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer and or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer and or other programmable data processing apparatus create means functionality and or structure for implementing the functions acts specified in the block diagrams and or flowchart block or blocks.

These computer program instructions may also be stored in a computer readable memory that can direct a computer or other programmable data processing apparatus to function in a particular manner such that the instructions stored in the computer readable memory produce articles of manufacture including instructions which implement the functions acts specified in the block diagrams and or flowchart block or blocks.

The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer or other programmable apparatus to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide steps for implementing the functions acts specified in the block diagrams and or flowchart block or blocks.

Accordingly exemplary embodiments may be implemented in hardware and or in software including firmware resident software micro code etc. . Furthermore exemplary embodiments may take the form of a computer program product on a non transitory computer usable or computer readable storage medium having computer usable or computer readable program code embodied in the medium for use by or in connection with an instruction execution system. In the context of this document a non transitory computer usable or computer readable medium may be any medium that can contain store or transport the program for use by or in connection with the instruction execution system apparatus or device.

The computer usable or computer readable medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device. More specific examples a non exhaustive list of the computer readable medium would include the following a portable computer diskette a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory and a portable compact disc read only memory CD ROM .

Computer program code for carrying out operations of data processing systems discussed herein may be written in a high level programming language such as C C or Java for development convenience. In addition computer program code for carrying out operations of exemplary embodiments may also be written in other programming languages such as but not limited to interpreted languages. Some modules or routines may be written in assembly language or even micro code to enhance performance and or memory usage. However embodiments are not limited to a particular programming language. It will be further appreciated that the functionality of any or all of the program modules may also be implemented using discrete hardware components one or more application specific integrated circuits ASICs or a programmed digital signal processor or microcontroller.

It should also be noted that in some alternate implementations the functions acts noted in the blocks may occur out of the order noted in the flowcharts. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality acts involved. Moreover the functionality of a given block of the flowcharts and or block diagrams may be separated into multiple blocks and or the functionality of two or more blocks of the flowcharts and or block diagrams may be at least partially integrated.

Reference is made to which are block diagrams illustrating exemplary networks in which operations for monitoring and reporting network application performance may be performed according to some embodiments of the present invention.

Referring to a network according to some embodiments herein may include a health data processing application and a plurality of network devices and that may each include respective collector applications . It is to be understood that a network device as discussed herein may include physical as opposed to virtual machines host machines each of which may be a physical machine on which one or more virtual machines may execute and or virtual machines executing on host machines . It is to be further understood that an application as discussed herein refers to an instance of executable software operable to execute on respective ones of the network devices. The terms application and network application may be used interchangeably herein regardless of whether the referenced application is operable to access network resources.

Collector applications may collect data related to the performance of network applications executing on respective network devices. For instance a collector application executing on a physical machine may collect performance data related to network applications executing on that physical machine. A collector application executing on a host machine and external to any virtual machines hosted by that host machine may collect performance data related to network applications executing on that host machine while a collector application executing on a virtual machine may collect performance data related to network applications executing within that virtual machine.

The health data processing application may be on a network device that exists within the network or on an external device that is coupled to the network . Accordingly in some embodiments the network device on which the health data processing application may reside may be one of the plurality of machines or or virtual machines . Communications between various ones of the network devices may be accomplished using one or more communications and or network protocols that may provide a set of standard rules for data representation signaling authentication and or error detection that may be used to send information over communications channels therebetween. In some embodiments exemplary network protocols may include HTTP TDS and or LDAP among others.

Referring to an exemplary network may include a web server one or more application servers and one or more database servers . Although not illustrated a network as used herein may include directory servers security servers and or transaction monitors among others. The web server may be a computer and or a computer program that is responsible for accepting HTTP requests from clients e.g. user agents such as web browsers and serving them HTTP responses along with optional data content which may be for example web pages such as HTML documents and linked objects images etc. . An application server may include a service hardware and or software framework that may be operable to provide one or more programming applications to clients in a network. Application servers may be coupled to one or more web servers database servers and or other application servers among others. Some embodiments provide that a database server may include a computer and or a computer program that provides database services to other computer programs and or computers as may be defined for example by a client server model among others. In some embodiments database management systems may provide database server functionality.

Some embodiments provide that the collector applications and the health data processing application described above with respect to may reside on ones of the web server s application servers and or database servers among others. In some embodiments the health data processing application may reside in a dedicated computing device that is coupled to the network . The collector applications may reside on one some or all of the above listed network devices and provide network application performance data to the health data processing application .

Web server s application servers and or database servers may be deployed as and or executed on any type and form of computing device such as a computer network device or appliance capable of communicating on any type and form of network and performing the operations described herein. depict block diagrams of a computing device useful for practicing some embodiments described herein. Referring to a computing device may include a central processing unit and a main memory unit . A computing device may include a visual display device a keyboard and or a pointing device such as a mouse. Each computing device may also include additional optional elements such as one or more input output devices generally referred to using reference numeral and a cache memory in communication with the central processing unit .

The central processing unit is any logic circuitry that responds to and processes instructions fetched from the main memory unit . In many embodiments the central processing unit is provided by a microprocessor unit such as those manufactured by Intel Corporation of Mountain View Calif. those manufactured by Motorola Corporation of Schaumburg Ill. the POWER processor those manufactured by International Business Machines of White Plains N.Y. and or those manufactured by Advanced Micro Devices of Sunnyvale Calif. The computing device may be based on any of these processors and or any other processor capable of operating as described herein.

Main memory unit may be one or more memory chips capable of storing data and allowing any storage location to be directly accessed by the microprocessor such as Static random access memory SRAM Burst SRAM or SynchBurst SRAM BSRAM Dynamic random access memory DRAM Fast Page Mode DRAM FPM DRAM Enhanced DRAM EDRAM Extended Data Output RAM EDO RAM Extended Data Output DRAM EDO DRAM Burst Extended Data Output DRAM BEDO DRAM Enhanced DRAM EDRAM synchronous DRAM SDRAM JEDEC SRAM PC100 SDRAM Double Data Rate SDRAM DDR SDRAM Enhanced SDRAM ESDRAM SyncLink DRAM SLDRAM Direct Rambus DRAM DRDRAM or Ferroelectric RAM FRAM among others. The main memory may be based on any of the above described memory chips or any other available memory chips capable of operating as described herein. In some embodiments the processor communicates with main memory via a system bus described in more detail below . In some embodiments of a computing device the processor may communicate directly with main memory via a memory port . Some embodiments provide that the main memory may be DRDRAM.

The computing device may support any suitable installation device such as a floppy disk drive for receiving floppy disks such as 3.5 inch 5.25 inch disks or ZIP disks a CD ROM drive a CD R RW drive a DVD ROM drive tape drives of various formats USB device hard disk drive HDD solid state drive SSD or any other device suitable for installing software and programs such as any client agent or portion thereof. The computing device may further comprise a storage device such as one or more hard disk drives or solid state drives or redundant arrays of independent disks for storing an operating system and other related software and for storing application software programs such as any program related to the client agent . Optionally any of the installation devices could also be used as the storage device . Additionally the operating system and the software can be run from a bootable medium for example a bootable CD such as KNOPPIX a bootable CD for GNU Linux that is available as a GNU Linux distribution from knoppix.net.

Furthermore the computing device may include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. T T 56 kb X.25 broadband connections e.g. ISDN Frame Relay ATM wireless connections e.g. IEEE 802.11 or some combination of any or all of the above. The network interface may comprise a built in network adapter network interface card PCMCIA network card card bus network adapter wireless network adapter USB network adapter modem or any other device suitable for interfacing the computing device to any type of network capable of communication and performing the operations described herein. A wide variety of I O devices may be present in the computing device . Input devices include keyboards mice trackpads trackballs microphones and drawing tablets among others. Output devices include video displays speakers inkjet printers laser printers and dye sublimation printers among others. The I O devices may be controlled by an I O controller as shown in . The I O controller may control one or more I O devices such as a keyboard and a pointing device e.g. a mouse or optical pen. Furthermore an I O device may also provide storage and or an installation medium for the computing device . In still other embodiments the computing device may provide USB connections to receive handheld USB storage devices such USB flash drives.

In some embodiments the computing device may comprise or be connected to multiple display devices which each may be of the same or different type and or form. As such any of the I O devices and or the I O controller may comprise any type and or form of suitable hardware software or combination of hardware and software to support enable or provide for the connection and use of multiple display devices by the computing device . For example the computing device may include any type and or form of video adapter video card driver and or library to interface communicate connect or otherwise use the display devices . In some embodiments a video adapter may comprise multiple connectors to interface to multiple display devices . In some other embodiments the computing device may include multiple video adapters with each video adapter connected to one or more of the display devices . In some embodiments any portion of the operating system of the computing device may be configured for using multiple displays . In some embodiments one or more of the display devices may be provided by one or more other computing devices connected to the computing device for example via a network. Such embodiments may include any type of software designed and constructed to use another computer s display device as a second display device for the computing device . One ordinarily skilled in the art will recognize and appreciate the various ways and embodiments that a computing device may be configured to have multiple display devices 

In further embodiments an I O device may be a bridge between the system bus and an external communication bus such as a USB bus an Apple Desktop Bus an RS 232 serial connection a SCSI bus a FireWire bus a FireWire 800 bus an Ethernet bus an AppleTalk bus a Gigabit Ethernet bus an Asynchronous Transfer Mode bus a HIPPI bus a Super HIPPI bus a SerialPlus bus a SCl LAMP bus a FibreChannel bus and or a Serial Attached small computer system interface bus among others.

A computing device of the sort depicted in may typically operate under the control of operating systems which control scheduling of tasks and access to system resources. The computing device can be running any operating system such as any of the versions of the Microsoft Windows operating systems any of the different releases of the Unix and Linux operating systems any version of the Mac OS for Macintosh computers any embedded operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices and or any other operating system capable of running on a computing device and performing the operations described herein. Typical operating systems include WINDOWS 3.x WINDOWS 95 WINDOWS 98 WINDOWS 2000 WINDOWS NT 3.51 WINDOWS NT 4.0 WINDOWS CE WINDOWS XP WINDOWS VISTA WINDOWS 7.0 WINDOWS SERVER 2003 and or WINDOWS SERVER 2008 all of which are manufactured by Microsoft Corporation of Redmond Wash. MacOS manufactured by Apple Computer of Cupertino Calif. OS 2 manufactured by International Business Machines of Armonk N.Y. and Linux a freely available operating system distributed by Red Hat of Raleigh N.C. among others or any type and or form of a Unix operating system among others.

In some embodiments the computing device may have different processors operating systems and input devices consistent with the device. For example in one embodiment the computing device is a Treo or small phone manufactured by Palm Inc. In this embodiment the Treo smart phone is operated under the control of the PalmOS operating system and includes a stylus input device as well as a five way navigator device. Moreover the computing device can be any workstation desktop computer laptop or notebook computer server handheld computer mobile telephone any other computer or other form of computing or telecommunications device that is capable of communication and that has sufficient processor power and memory capacity to perform the operations described herein.

Reference is now made to which is a block diagram illustrating an architecture of a computing device as discussed above regarding . The architecture of the computing device is provided by way of illustration only and is not intended to be limiting. The architecture of computing device may include a hardware layer and a software layer divided into a user space and a kernel space .

Hardware layer may provide the hardware elements upon which programs and services within kernel space and user space are executed. Hardware layer also provides the structures and elements that allow programs and services within kernel space and user space to communicate data both internally and externally with respect to computing device . The hardware layer may include a processing unit for executing software programs and services a memory for storing software and data and network ports for transmitting and receiving data over a network. Additionally the hardware layer may include multiple processors for the processing unit . For example in some embodiments the computing device may include a first processor and a second processor . In some embodiments the processor or includes a multi core processor. The processor may include any of the processors described above in connection with and

Although the hardware layer of computing device is illustrated with certain elements in the hardware portions or components of computing device may include any type and form of elements hardware or software of a computing device such as the computing device illustrated and discussed herein in conjunction with . In some embodiments the computing device may comprise a server gateway router switch bridge or other type of computing or network device and have any hardware and or software elements associated therewith.

The operating system of computing device allocates manages or otherwise segregates the available system memory into kernel space and user space . As discussed above in the exemplary software architecture the operating system may be any type and or form of various ones of different operating systems capable of running on the computing device and performing the operations described herein.

The kernel space may be reserved for running the kernel including any device drivers kernel extensions and or other kernel related software. As known to those skilled in the art the kernel is the core of the operating system and provides access control and management of resources and hardware related elements of the applications. In accordance with some embodiments of the computing device the kernel space also includes a number of network services or processes working in conjunction with a cache manager sometimes also referred to as the integrated cache. Additionally some embodiments of the kernel will depend on embodiments of the operating system installed configured or otherwise used by the device .

In some embodiments the device includes one network stack such as a TCP IP based stack for communicating with a client and or a server. In other embodiments the device may include multiple network stacks. In some embodiments the network stack includes a buffer for queuing one or more network packets for transmission by the computing device .

As shown in the kernel space includes a high speed layer 2 7 integrated packet engine and a policy engine . Running these components or processes and in kernel space or kernel mode instead of the user space improves the performance of each of these components alone and in combination. Kernel operation means that these components or processes and run in the core address space of the operating system of the device . For example data obtained in kernel mode may not need to be passed or copied to a process or thread running in user mode such as from a kernel level data structure to a user level data structure. In this regard such data may be difficult to determine for purposes of network application performance monitoring. In another aspect the number of context switches between kernel mode and user mode are also reduced. Additionally synchronization of and communications between any of the components or processes and can be performed more efficiently in the kernel space .

In some embodiments any portion of the components and may run or operate in the kernel space while other portions of these components and may run or operate in user space . In some embodiments the computing device uses a kernel level data structure providing access to any portion of one or more network packets for example a network packet comprising a request from a client or a response from a server. In some embodiments the kernel level data structure may be obtained by the packet engine via a transport layer driver interface TDI or filter to the network stack . The kernel level data structure may include any interface and or data accessible via the kernel space related to the network stack network traffic or packets received or transmitted by the network stack . In some embodiments the kernel level data structure may be used by any of the components or processes and to perform the desired operation of the component or process. Some embodiments provide that a component and is running in kernel mode when using the kernel level data structure while in some other embodiments the component and is running in user mode when using the kernel level data structure. In some embodiments the kernel level data structure may be copied or passed to a second kernel level data structure or any desired user level data structure.

A policy engine may include for example an intelligent statistical engine or other programmable application s . In some embodiments the policy engine provides a configuration mechanism to allow a user to identify specify define or configure a caching policy. Policy engine in some embodiments also has access to memory to support data structures such as lookup tables or hash tables to enable user selected caching policy decisions. In some embodiments the policy engine may include any logic rules functions or operations to determine and provide access control and management of objects data or content being cached by the computing device in addition to access control and management of security network traffic network access compression and or any other function or operation performed by the computing device .

High speed layer 2 7 integrated packet engine also generally referred to as a packet processing engine or packet engine is responsible for managing the kernel level processing of packets received and transmitted by computing device via network ports . The high speed layer 2 7 integrated packet engine may include a buffer for queuing one or more network packets during processing such as for receipt of a network packet or transmission of a network packer. Additionally the high speed layer 2 7 integrated packet engine is in communication with one or more network stacks to send and receive network packets via network ports . The high speed layer 2 7 integrated packet engine may work in conjunction with policy engine . In particular policy engine is configured to perform functions related to traffic management such as request level content switching and request level cache redirection.

The high speed layer 2 7 integrated packet engine includes a packet processing timer . In some embodiments the packet processing timer provides one or more time intervals to trigger the processing of incoming i.e. received or outgoing i.e. transmitted network packets. In some embodiments the high speed layer 2 7 integrated packet engine processes network packets responsive to the timer . The packet processing timer provides any type and form of signal to the packet engine to notify trigger or communicate a time related event interval or occurrence. In many embodiments the packet processing timer operates in the order of milliseconds such as for example 100 ms 50 ms or 25 ms. For example in some embodiments the packet processing timer provides time intervals or otherwise causes a network packet to be processed by the high speed layer 2 7 integrated packet engine at a 10 ms time interval while in other embodiments at a 5 ms time interval and still yet in further embodiments as short as a 3 2 or 1 ms time interval. The high speed layer 2 7 integrated packet engine may be interfaced integrated and or in communication with the policy engine during operation. As such any of the logic functions or operations of the policy engine may be performed responsive to the packet processing timer and or the packet engine . Therefore any of the logic functions and or operations of the policy engine may be performed at the granularity of time intervals provided via the packet processing timer for example at a time interval of less than or equal to 10 ms.

In contrast to kernel space user space is the memory area or portion of the operating system used by user mode applications or programs otherwise running in user mode. Generally a user mode application may not access kernel space directly and instead must use service calls in order to access kernel services. As shown in user space of computing device includes a graphical user interface GUI a command line interface CLI shell services and daemon services . Using GUI and or CLI a system administrator or other user may interact with and control the operation of computing device . The GUI may be any type and form of graphical user interface and may be presented via text graphical or otherwise by any type of program or application such as a browser. The CLI may be any type and form of command line or text based interface such as a command line provided by the operating system. For example the CLI may comprise a shell which is a tool to enable users to interact with the operating system. In some embodiments the CLI may be provided via a bash csh tcsh and or ksh type shell. The shell services may include the programs services tasks processes and or executable instructions to support interaction with the computing device or operating system by a user via the GUI and or CLI .

Daemon services are programs that run continuously or in the background and handle periodic service requests received by computing device . In some embodiments a daemon service may forward the requests to other programs or processes such as another daemon service as appropriate. As known to those skilled in the art a daemon service may run unattended to perform continuous and or periodic system wide functions such as network control or to perform any desired task. In some embodiments one or more daemon services run in the user space while in other embodiments one or more daemon services run in the kernel space.

Reference is now made to which is a block diagram illustrating operations and or functions of a collector application as described above regarding . The collector application includes a kernel space module and a user space module . The kernel space module may generally operate to intercept network activities as they occur. Some embodiments provide that the kernel space module may use a kernel mode interface in the operating system such as for example Microsoft Windows transport data interface TDI . The kernel space module may include a TDI filter that is configured to monitor and or intercept interactions between applications. Additionally some embodiments provide that the kernel space module may include an ancillary functions driver AFD filter that is configured to intercept read operations and the time of their duration. Some operating systems may include a kernel mode driver other than the AFD. In this regard operations described herein may be used with other such kernel mode drivers to intercept application operational data.

The raw data related to the occurrence of and attributes of transactions between network applications may be generally referred to as performance data. The raw data may have value for diagnosing network application performance issues and or for identifying and understanding the structure of the network applications. The measurements or aggregations of performance data may be generally referred to as metrics. Performance data and the metrics generated therefrom may be temporally relevant i.e. the performance data and the metrics may be directly related to and or indicative of the health of the network at the time the performance data is collected. Performance data may be collected and metrics based thereon may be generated on a client side and or a server side of an interaction. Some embodiments provide that performance data is collected in substantially real time. In this context substantially real time means that performance data is collected immediately subsequent to the occurrence of the related network activity subject to the delays inherent in the operation of the computing device and or the network and in the method of collection. The performance data collected and or the metrics generated may correspond to a predefined time interval. For example a time interval may be defined according to the dynamics of the network and may include exemplary period lengths of less than 1 1 5 10 15 20 30 and or 60 seconds among others.

Exemplary client side metrics may be aggregated according to one or more applications or processes. For example the client side metrics may be aggregated according to destination address port number and a local process identifier PID . A PID may be a number used by some operating system kernels to uniquely identify a process. This number may be used as a parameter in various function calls allowing processes to be manipulated such as adjusting the process s priority and or terminating the process. In this manner multiple connections from the same application or process to the same remote service may be aggregated.

Similarly server side metrics may be aggregated according to the same application or service regardless of the client. For example some embodiments provide that server side metrics may be aggregated according to local address port number and PID. Respective ones of the client side and server side metrics may be collected from the kernel space and or user space.

The kernel space module may include a kernel events sender that is configured to receive performance data from the AFD filter and or the TDI filter and generate metrics based on the performance data for receipt by a kernel events receiver in the user space module . In the user space module metrics data received by the kernel event receiver may be processed by a reverse domain name system DNS resolver to map an observed network address to a more user friendly DNS name. Additionally metrics data received by the kernel events receiver may be used by a process resolver to determine the processes and or applications corresponding to the collected kernel metrics data.

The user space module may include a machine information collector that is operable to determine static machine information such as for example CPU speed memory capacity and or operating system version among others. As the performance data is collected corresponding to applications and or processes the machine information may be non correlative relative to the applications and or processes. The user space module may include a process data collector that collects data corresponding to the processes and or applications determined in the process resolver . A machine data collector may collect machine specific data. Examples of machine data may include information about resource utilization such as the amount of memory in use and or the percentage of available CPU time consumed. The user space module may include an event dispatcher that is configured to receive the machine information resolved DNS information process identification process data and or machine data and to generate events incorporating the aggregated metrics data for dispatch to a health data processor application that is operable to receive aggregated metrics data from multiple collectors .

Some embodiments provide that the performance data collected and or metrics generated may be diagnostically equivalent and thus may be aggregated into a single event. The identification process may depend on which application initiates a network connection and which end of the connection is represented by a current collector application host.

Kernel level metrics may generally include data corresponding to read operations that are in progress. For example reference is now made to which is a diagram illustrating determining a read wait time corresponding to a user transaction according to some embodiments of the present invention. A user transaction between a client and a server are initiated when the client sends a write request at time T to the server . The server completes reading the request at time T and responds to the request at time T and the client receives the response from the server at time T. A kernel metric that may be determined is the amount of time spent between beginning a read operation and completing the read operation. In this regard client measured server response time is the elapsed time between when the request is sent T and when a response to the request is read T by the server. Accordingly the client measured server response time may be determined as T T. The server may determine a server measured server response time that is the elapsed time between when the request is read T by the server and when the response to the request is sent T by the server to the client . Accordingly the server measured server response time may be determined as T T.

As the application response is measured in terms of inbound and outbound packets the application response time may be determined in an application agnostic manner.

Additionally another metric that may be determined is the read wait time which is the elapsed time between when the client is ready to read a response to the request T and when the response to the request is actually read T. In some embodiments the read wait time may represent a portion of the client measured server response time that may be improved upon by improving performance of the server . Further the difference between the client measured server response time and the server measured server response time may be used to determine the total transmission time of the data between the client and the server . Some embodiments provide that the values may not be determined until a read completes. In this regard pending reads may not be included in this metric. Further as a practical matter higher and or increasing read time metrics discussed above may be indicative of a slow and or poor performing server and or protocol where at least some messages originate unsolicited at the server .

Other read metrics that may be determined include the number of pending reads. For example the number of read operations that have begun but are not yet completed may be used to detect high concurrency. In this regard high and or increasing numbers of pending read operations may indicate that a server is not keeping up with the workload. Some embodiments provide that the total number of reads may include reads that began at a time before the most recent aggregated time period.

Additionally some embodiments provide that the number of reads that were completed during the last time period may be determined. An average of read wait time per read may be generated by dividing the total read wait time corresponding to a sum of all of the T T values during the time period by the number of completed reads in that period.

In some embodiments the number of stalled reads may be determined as the number of pending reads that began earlier than a predefined threshold. For example a predefined threshold of 60 seconds may provide that the number of pending read operations that began more than 60 seconds ago are identified as stalled read operations. Typically any value greater than zero may be undesirable and or may be indicative of a server initiated protocol. Some embodiments may also determine the number of bytes sent received on a connection.

The number of completed responses may be estimated as the number of times a client to server message commonly interpreted as a request was followed by a server to client message commonly interpreted as a response . Some embodiments provide that this may be measured by both the server and the client connections. In some embodiments this may be the same as the number of completed reads for a given connection. Additionally a total response time may be estimated as the total time spent in request to response pairs.

Reference is now made to which is a block diagram illustrating a kernel level architecture of a collector application to explain kernel level metrics according to some embodiments of the present invention. As discussed above regarding the collector may use a TDI filter and an AFD filter . The AFD filter may intercept network activity from user space processes that use a library defined in a standard interface between a client application and an underlying protocol stack in the kernel.

The TDI filter may operate on a lower layer of the kernel and can intercept all network activity. As the amount of information available at AFD filter and TDI filter is different the performance data that may be collected and the metrics that may be generated using each may also be different. For example the AFD filter may collect AFD performance data and generate AFD metrics that include total read wait time number of completed reads number of pending reads and number of stalled reads among others. The TDI filter may collect TDI performance data and generate TDI metrics including total bytes sent total bytes received total response time and the number of responses from the server. Depending on the architecture of a target application the AFD metrics for client side connections may or may not be available. In this regard if the application uses the standard interface the collector may report non zero AFD metrics. Otherwise all AFD metrics may not be reported or may be reported as zero.

Some embodiments provide that kernel level metrics may be generated corresponding to specific events. Events may include read wait metrics that may include client side metrics such as total read wait time number of completed reads number of pending reads number of stalled reads bytes sent bytes received total response time and or number of responses among others. Events may further include server response metrics such as bytes sent bytes received total response time and or number of responses among others.

In addition to the kernel metrics discussed above the collector may also generate user level metrics. Such user level metrics may include but are not limited to aggregate CPU percentage representing the percentage of CPU time across all cores aggregate memory percentage i.e. the percentage of physical memory in use by a process and or all processes and or total network bytes sent received on all network interfaces among others. User level metrics may include but are not limited to the number of page faults the number of times any process tries to read from or write to a page that was not in its resident in memory the number of pages input i.e. the number of times any process tried to read a page that had to be read from disk and or the number of pages output representing the number of pages that were evicted by the operating system memory manager because it was low on physical memory among others. User level metrics may include but are not limited to a queue length the number of outstanding read or write requests at the time the metric was requested the number of bytes read from and or written to a logical disk in the last time period the number of completed read write requests on a logical disk in the last time period and or total read write wait times corresponding to the number of milliseconds spent waiting for read write requests on a logical disk in the last time interval among others.

Further some additional metrics may be generated using data from external application programming interfaces. Such metrics may include for example the amount of memory currently in use by a machine memory control driver CPU usage expressed as a percentage memory currently used as a percentage of total memory and or total network bytes sent received among others.

In some embodiments events may be generated responsive to certain occurrences in the network. For example events may be generated when a connection such as a TCP connection is established from or to a machine when a connection was established in the past and the collector application first connects to the health data processing application and or when a connection originating from the current machine was attempted but failed due to timeout refusal or because the network was unreachable. Events may be generated when a connection is terminated when a local server process is listening on a port when a local server process began listening on a port in the past and the collector application first connects to the health data processing application and or when a local server process ceases to listen on a port. Events may be generated if local network interfaces have changed and or if a known type of event occurs but some fields are unknown. Events may include a description of the static properties of a machine when a collector application first connects to a health data processing application process information data when a process generates its first network related event and or information about physical disks and logical disks when a collector application first connects to a health data processing application .

Some embodiments provide that the different link events may include different data types corresponding to the type of information related thereto. For example data strings may be used for a type description of an event. Other types of data may include integer bytes and or Boolean among others.

In some embodiments the events generated by collector application for dispatch to heath data processing application may incorporate metrics related to network structure network health computational resource health virtual machine structure virtual machine health and or process identification among others. Metrics related to network structure may include data identifying the network device on which collector application is executing or data related to the existence establishment or termination of network links or the existence of bound ports or the binding or unbinding of ports. Metrics pertinent to network health may include data related to pending completed and stalled reads bytes transferred and response times from the perspective of the client and or the server side. Metrics related to computational resource health may include data regarding the performance of the network device on which collector application is executing such as processing and memory usage. Metrics related to virtual machine structure may include data identifying the physical host machine on which collector application is executing and or data identifying the virtual machines executing on the physical host machine. Metrics pertinent to virtual machine health may include regarding the performance of the host machine and or the virtual machines executing on the host machine such as processing and memory usage as determined from the perspective of the host machine and or the virtual machines. Finally metrics related to process identification may include data identifying individual processes executing on a network device.

Reference is made to which illustrates exemplary operations that may be carried out by collector application in monitoring and reporting network application performance according to some embodiments of the present invention. At block collector application establishes hooks on a networked device to an internal network protocol kernel interface utilized by the operating system of the networked device. In some embodiments these hooks may include for instance a TDI filter. Collector application also establishes hooks to an application oriented system call interface to a transport network stack said hooks including in some embodiments an AFD filter. Collector application collects via the established hooks performance data corresponding to at least one network application running on the networked device block . At block kernel level and user level metrics are generated based on the collected performance data. The generated metrics may provide an indication of the occurrence of an interaction e.g. establishment of a network link or may provide measurements of for instance a count of some attribute of the collected performance data e.g. number of completed reads or a summation of some attribute of the collected performance data e.g. total read attempts . The kernel level and user level metrics are aggregated by application e.g. by aggregating metrics associated with the same IP address local port and process ID block . At block the kernel level and user level metrics generated within a specified time interval are aggregated. For instance in some embodiments metrics generated within the most recent 15 second time interval are aggregated.

At block redundant data are removed from the aggregated metrics and inconsistent data therein are reconciled. Redundant data may include for instance functionally equivalent data received from both the TDI and AFD filters. Collector application performs a reverse DNS lookup to determine the DNS name associated with IP addresses referenced in the generated kernel level and user level metrics block . Finally at block an event is generated incorporating the kernel level and user level metrics and the determined DNS name s . The generated event may be subsequently transmitted to health data processing application for incorporation into a model of network health status.

In some embodiments the collector application may be installed into a machine of interest without requiring a reboot of the machine. This may be particularly useful in the context of a continuously operable system process and or operation as may be frequently found in manufacturing environments among others. As the collector operations interface with the kernel and more specifically the protocol stack installation without rebooting may entail intercepting requests coming in and out of the kernel using the TDI filter. Some embodiments include determining dynamically critical offsets in potentially undocumented data structures. Such offsets may be used in intercepting network activity for ports and connections that exist prior to an installation of the collector application . For example such previously existing ports and connections may be referred to as the extant state of the machine.

Some embodiments provide that intercepting the stack data may include overwriting the existing stack function tables with pointers and or memory addresses that redirect the request through the collector filter and then to the intended function. In some embodiments the existing stack function tables may be overwritten atomically in that the overwriting may occur at the smallest indivisible data level. Each entry in a function table may generally include a function pointer and a corresponding argument. However only one of these entries either the function or the argument can be overwritten at one time. Thus intercepting function calls may rely on two consecutive overwrites of the stack data corresponding to the function and corresponding argument. In some embodiments there is no means for protecting from an intervening operation between overwriting one of the function and argument and overwriting the other one of them. In this regard system stability may be at risk from two attempted consecutive overwrites.

As the consecutive overwrites of intercepting function calls may place the machine at risk of instability a dynamic overwriting operation may be used. Specifically a separate data structure is provided that includes a pointer to the original function its original argument and dynamically generated code to invoke a filter in the collector application . The address of this data structure may be used to atomically overwrite the original function pointer in a single operation. The collector collects the data and then calls the original function corresponding to the overwritten stack data to perform its intended purpose. In this manner the original behavior of the machine is preserved and the collector application collects the relevant data without rebooting the machine and or placing the machine at risk of instability.

Some embodiments may include identifying the potentially undocumented data structures representing bound ports and network connections. For example TDI objects connections and bound ports created prior to the installation of the collector application may be determined by first enumerating all objects identified in a system. Each of the enumerated objects may be tagged with an identifier corresponding to its sub system. A request corresponding to a known TDI object is created and sent for processing. The type codes of the enumerated objects are compared to those of the known TDI object to determine which of the objects are ports and which of the objects are connections. The enumerated objects may then be filtered as either connections or ports.

In some embodiments this may be accomplished using an in kernel thread. The thread may monitor network connections having restricted visibility and may detect when a monitored connection no longer exists. Connections may be added dynamically to the monitored list as needed.

Some embodiments provide that events may be generated to indicate that visibility into network events may be incomplete. For example information may be missing corresponding to an active process the state of a known connection and or missing information regarding network activity. In this manner depending on conditions a custom event can be transmitted to indicate what type of information is missing and what process may be responsible for that information.

In some embodiments the health data processing application may be operable to receive from at least one collector application network activity data corresponding to network activity of the applications on the network device on which the collector application is installed. The health data processing application may combine the network activity data received from the collector application to remove redundant portions thereof. In some embodiments the health data processing application may archive the received activity data in a persistent data store along with a timestamp indicating when the activity data was collected and or received. The health data processing application may generate a model that includes identified network application components and their relatedness and or links therebetween. The generated model may be displayed via one or more display devices such as e.g. display devices discussed in greater detail above.

In some embodiments the health data processing application may be operable to combine network activity data reported from multiple collector applications to eliminate redundancy and to address inconsistencies among data reported by different collector applications . For example network data from multiple collector applications may be stitched together to create a consistent view of the health of the network applications.

Some embodiments provide that the model may be a graphical display of the network including application components machines clients processes etc. and the relationships therebetween. In some embodiments the model may be generated as to reflect the real time or near real time activity of the network. It is to be understood that in this context near real time may refer to activity occurring in the most recent of a specified time interval for which activity data was received. For instance health data processing application may receive from collector applications aggregated activity data corresponding to the most recent 15 second interval of network operation and accordingly the model of near real time activity may reflect the activity of the network as it existed during that most recent 15 second interval.

Some embodiments provide that the model may be generated to reflect an historical view of network activity data corresponding to a specified time interval. The historical view may be generated based on archived activity data retrieved from a persistent data store and having a timestamp indicating that the activity data was collected or received during the specified time interval. In other embodiments the model may be dynamically updated to reflect new and or lost network collectors and or network components. Further graphs may be provided at each and or selected network resource indicators to show activity data over part of and or all of the time interval.

In some embodiments a model may include sparklines to provide quick access to trends of important metrics process and application views to provide different levels of system detail and or model overlays to provide additional application analysis. For example visual feedback regarding the contribution of a network link relative to a given criterion may be provided. In this manner hop by hop transaction data about the health of applications can be provided. Additionally visual ranking of connections based on that criteria may be provided. Bottleneck analysis based on estimated response times may be provided to identify slow machines applications and or processes among others.

Some embodiments provide that health data processing application may be operable to infer the existence of network devices and or network applications for which no activity data was received or on which no collector application is running based on the identification of other network devices and or other network applications for which activity data was received. For instance activity data received by health data processing application may indicate that a network link has been established between a local network device running collector application and a remote network device that is not running collector application . Because the activity data may include identifying information for both the local and remote network devices health data processing application may infer that the remote network device exists and incorporate the remote network device into the generated model of network activity.

In other embodiments health data processing application may be operable to identify a network application based on predefined telecommunications standards such as e.g. the port numbers list maintained by the Internet Assigned Numbers Authority IANA . Health data processing application may for example receive activity data indicating that a process on a network device is bound to port . By cross referencing the indicated port number with the IANA port numbers list health data processing application may identify the process as a File Transfer Protocol FTP server and may include the identification in the generated model.

Brief reference is made to which is a screen shot of a graphical user interface GUI including a model generated by a health data processing application according to some embodiments of the present invention. The GUI includes a model portion that illustrates representations of various network applications and or application components . Such representations may include identifier fields that are operable to identify application and or application component addresses ports machines and or networks. Connections between network applications and or application components may be operable to convey additional information via color size and or other graphical and or text based information. A summary field may be provided illustrate summary information corresponding to one or more applications and or application components among others. A port identification portion may be operable to show the connections corresponding to and or through a particular port. The GUI may include a system and or network navigation field overlay selection field and one or more time interval and or snapshot field s .

Some embodiments provide that transferring the activity data between the collector applications and the health data processing application may be performed using a compact self describing linear buffer communications protocol. In some embodiments the custom protocol uses a common representation for monitoring information commands and configuration data. As the methods and systems described herein are intended to monitor network performance the protocol may be operable to minimize the volume of information exchanged between the collector applications and the health data processing application .

In some embodiments the collector applications are operable to generate events in a streaming data format. Events may be generated corresponding to the predefined monitoring time period. Information provided corresponding to an event may include an event type network resource identification data including PID remote identifiers quantities and or types of data sent received and or response time information among others. The protocol may include a banner portion that may be established through a handshaking process that may occur when a collector application initially communicates with the health data processing application.

The banner portion may define the data types and formats to be transferred. In this manner the protocol may be flexible by virtue of the self descriptive banner portion and may avoid sending unused unwanted or blank data fields.

Many variations and modifications can be made to the embodiments without substantially departing from the principles of the present invention. The following claims are provided to ensure that the present application meets all statutory requirements as a priority application in all jurisdictions and shall not be construed as setting forth the scope of the present invention.

