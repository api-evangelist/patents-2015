---

title: Systems and methods for digital workflow and communication
abstract: Systems and methods for authoring and performing procedural workflows, and engaging in multimedia communication, remote assistance, training, data entry, inventory management, authentication, and secure networking using a hands-free or substantially hands-free wearable digital device are described. In one implementation, a user logs into a secure network using existing credentials, and a Quick Response Code is generated to temporarily authorize the user's wearable device within the secure network. In another implementation, information is encrypted and transferred between a computing device and a remote system, and the computing device is verified as being connected to a particular network and located within a particular geofence. In a further implementation, an interface for authoring a procedural workflow includes defining workflow steps based on selected primitives, and displaying rendered previews of the workflow as it would appear on different user devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619771&OS=09619771&RS=09619771
owner: Parsable, Inc.
number: 09619771
owner_city: San Francisco
owner_country: US
publication_date: 20150406
---
This application claims priority to and the benefit of U.S. Provisional Patent Application No. 61 975 800 filed on Apr. 5 2014 and entitled Systems and Methods for Digital Workflow and Communication the entirety of which is incorporated by reference herein.

The present disclosure relates generally to procedural workflow and communications and more particularly to systems and methods for authoring and engaging in procedural workflows multimedia communication remote assistance training data entry inventory management authentication data transfer and secure networking using hands free or substantially hands free wearable digital devices.

Onsite workers in industrial clinical and other settings routinely perform standard procedures that consist of ordered steps. However these workers often do not have the information needed to perform these procedures readily available at their fingertips nor is help easily available when obstacles are encountered. Furthermore it is difficult to ensure that the workers have properly performed each step in a particular standard procedure let alone performed the steps in a reasonable amount of time.

Systems and methods for digital procedural workflow authoring and execution and secure network connectivity and data transfer are described. In one aspect a method performed by a computing device comprises receiving an indication that a user has successfully logged into a secure network using existing credentials creating a temporary session for the user based on the existing credentials generating a Quick Response QR code comprising a secure token associated with the temporary session and providing the QR code for display to the user on a first device such that the user can scan the QR code and authorize a second device for the temporary session based on the secure token.

In one implementation generating the temporary session further comprises defining a permitted session length associated with the temporary account. The QR code can further include information associated with the temporary session the information comprising at least one of permitted session length and a condition for ending the temporary session.

In another implementation the method further includes transmitting an encrypted payload to the second device. Transmitting the encrypted payload to the second device can include providing a second QR code for scanning by the second device wherein the second QR code comprises the encrypted payload. The encrypted payload can be generated based on a password provided by the second device.

In another aspect a method performed by a computing device comprises receiving at a first device a password generated by a second device receiving at the first device a message to be transferred to the second device generating an encrypted payload based on the password and the message generating a Quick Response QR code based on the encrypted payload and providing the QR code for scanning by the second device.

In one implementation the password is inputted into the first device by a user of the first device. The password can be a randomly generated character string. Generating the encrypted payload can include converting the message to a UTF 8 encoded format padding the message to a fixed length and or generating a salt. The salt can be a random initialization vector.

In another implementation the encrypted payload further includes generating an encryption key based on the password and the salt. Generating the encrypted payload can further include encrypting the message using the encryption key and the salt.

In another aspect a method performed by a computing device includes generating a password at a first device making the password available to a second device receiving at the first device a Quick Response QR code generated by the second device the QR code comprising an encrypted payload and decrypting the encrypted payload based at least in part on the password.

In one implementation decrypting the encrypted payload includes identifying a portion of the payload that comprises a salt. Decrypting the encrypted payload can include generating a decryption key based on the password and the salt. Decrypting the encrypted payload can further include decrypting at least a portion of the encrypted payload using the decryption key and the salt.

In another aspect a method performed by a computing device comprises encrypting information comprising a secret and a public key of the computing device using a public key of a remote system sending the encrypted information to the remote system receiving a response to the encrypted information from the remote system and decrypting the response using a private key of the computing device determining at a first time that the decrypted response matches the secret and based thereon verifying that the computing device is connected to a first network and verifying that the computing device is located within a first geofence.

In one implementation the method further includes determining at a second time following the first time that the computing device is not connected to the first network or is not within the first geofence and based thereon performing an action. The action can be one or more of erasing application data stored on the computing device erasing an application stored on the computing device and sending a message to the remote system.

In another implementation the method further includes determining that a location of the computing device has changed. Determining at the second time can further include determining that the computing device is connected to a second network wherein the second is not an approved network. The secret can be a random number and the computing device can be a wearable computing device.

In a further implementation verifying that the computing device is connected to a first network includes verifying that a service set identifier SSID of a network that the computing device is connected to matches an SSID for the first network.

In another aspect a method performed by a computing device comprises providing an interface for authoring a procedural workflow receiving via the authoring interface a selection of one or more primitives wherein a particular primitive comprises an element of interaction between a user and a data item defining a step of the procedural workflow based on the selected primitives displaying via the authoring interface a plurality of different views each view comprising a rendering preview of the procedural workflow on a different user device.

In one implementation the method further includes deploying the procedural workflow to a user device for execution on the user device. The method can further include storing the procedural workflow in an XML based format. The method can further include providing a scheme that defines a plurality of primitives and how subsets of the primitives can be combined to form steps of a procedural workflow. A particular primitive can include one of an element for capturing using a device executing the procedural workflow one of an image a text input an option input a voice input a video a bar code a Quick Response Code and a beacon signal. A particular user device can include a tablet a smartphone smart glasses or a smart watch.

In another implementation the method further includes storing the defined step in a step library for reuse in other procedural workflows. The method can further include receiving a definition via the authoring interface of an approval flow for the procedural workflow wherein the approval flow comprises a plurality of approval stages in which the procedural workflow is approved or rejected prior to deployment.

In a further implementation defining the step of the procedural workflow includes receiving via the authoring interface an ordering of the selected primitives and defining the step based further on the ordering. The method can further include defining a plurality of steps of the procedural workflow based on sets of primitives selected and configured via the authoring interface.

Other aspects of the above include corresponding systems and computer programs. The details of one or more implementations of the subject matter described in the present specification are set forth in the accompanying drawings and the description below. Other features aspects and advantages of the subject matter will become apparent from the description the drawings and the claims.

Systems and methods are presented for engaging in procedural workflows multimedia communication remote assistance training data entry inventory management authentication and secure networking using a hands free or substantially hands free wearable digital device such as the Google Glass or Microsoft HoloLens headsets. The techniques disclosed herein are applicable to a variety of fields including but not limited to healthcare and industrial fields such as energy oil gas manufacturing and maintenance such as aerospace and automotive field service transport and logistics warehousing distribution and retail and construction.

In one implementation referring to an operator authenticates with a device e.g. a wearable device such as Google Glass smart glasses using a wearable optimized QR code based single session user authentication mechanism. The authentication scheme involves the use of a secure workstation handheld mobile device or other device in combination with the wearable device . The session authentication mechanism provides for the use of the wearable device among multiple users in an enterprise setting in contrast to the typical use of a wearable device particularly Google Glass smart glasses in which the typical wearable device is tied to a single user and session data and other properties are not a concern.

Referring now to in an example authentication process an operator first logs into a secure workstation or other device within an organization s secure network using his or her existing credentials with the organization. A server side component can exist within the secure network that acts as an authorization bridge between the organization credentials and temporary session based credentials that authorize the operate to use the wearable device . Once the user is authorized STEP the organization credentials allow communication with the authorization bridge . In STEP the authorization bridge generates a temporary user session that is linked to the existing organization credentials and defined for a finite amount of time e.g. session length can be defined in hours days until the wearable device is removed etc. . To link the wearable device with the operator s organization credentials in STEP the authorization bridge generates a Quick Response QR code bar code or other scannable code containing a secure token along with encoded session information such as session length conditions for the end of the session and so on. In STEP the QR code is displayed to the operator via a webpage or application that is in communication with the authorization bridge . For example the QR code can be displayed on the secure workstation . The QR code can then be scanned by a camera on the wearable device and the session token is extracted and stored and used to identify the operator in question for the duration of the session.

In some instances the authorization bridge or other server side component is configured to retrieve additional data from the internal systems of the organization and provide it to the authenticated device e.g. data specific to the operator the operator s session the operator s workspace the operator s tasks and so on . The authorization bridge can also retrieve data from external systems e.g. updates to the device software etc. and transmit it to the wearable device . In one example an encrypted payload is transmitted to the wearable device using a QR code STEP . The payload can be transmitted from the secure workstation or another device to the wearable device .

In further implementations authentication can be performed by carrying a Bluetooth low energy enabled biometric key fob. The key fob can require the operator to authenticate himself or herself by a biometric scan such as a fingerprint reading which is compared to a previous reading captured upon the operator s enrollment with the biometric device.

In order to transfer non binary data a common format can be used between the devices . Due to the limited bandwidth of QR codes and the devices that can scan them it was determined through trial and error that a reasonable QR code length is around 110 bytes for devices such as Google Glass smart glasses. Because of this limit the transfer format should be efficient for a variety of input data. Based on these requirements and the ease of implementation in one example UTF 8 is a useful format for textual data representation. As the target data to be transferred such as login credentials is most likely made up of ASCII characters or other European languages UTF 8 on average should yield binary streams that are smaller than UTF 16 or UTF 32 encoding formats. Therefore in this example before encoding the data in the QR code the data is converted to UTF 8 first unless that is otherwise the native encoding of the platform software.

On modern UNIX based systems a library that obtains random data from dev urandom is generally sufficient for cryptographic use. Such systems include GNU Linux derivatives FreeBSD OpenBSD NetBSD Darwin OSX and the like. To enhance security the libraries in use should not generate entropy in userspace and should not use dev urandom as a seed.

In one implementation to provide for a better user experience while still maintaining adequate security the single use encryption password is 14 random characters from the ASCII set 0 9a z . In order to extend this key to 256 bits password based key derivation function 2 PBKDF2 is used. Secure Hash Algorithm 256 SHA 256 can be used as a digest psudo random function PRF function for PBKDF2 however it is possible to use SHA1 if the iteration count is high enough to make PBKDF2 execute in a reasonable amount of time e.g. at least 80 ms .

Due to asymmetric ciphers such as RSA with 2048 bit keys generating relatively large ciphertexts a symmetric cipher can be used for encryption. In testing it was noted that a QR code with more than 110 120 bytes was too difficult for Google Glass smart glasses to scan. Specifically Advanced Encryption Standard AES in cipher feedback CFB mode was chosen as a symmetric encryption cipher. Due to the nature of this system it is not required that the chosen mode of operation provides authentication as there is limited chance for an attacker to tamper with the QR code. Also not all Android based platforms provide authenticated modes of operation for the symmetric block ciphers.

In one implementation to provide for easier entry of the 14 character random password string into the companion device user interface the companion device user interface can allow the 14 character random string to be entered as a set of two 7 character strings. Consequently the mobile device would present the random string to the user as a set of two 7 character strings. Other methods of providing the password by the companion device to the mobile device are contemplated.

In order to avoid using stale encryption keys the mobile device can regenerate a password every 60 seconds or some other fixed or variable period. This gives a user up to the time period to enter the required information into the companion device and in some instances scan the QR code generated by the companion device.

As this proposed system can be used to handle very sensitive user information it is imperative that the user is not tricked into entering the user information into an unsecured companion device.

In one implementation to minimize information leaks plaintext is padded to the length of a fixed number of bytes e.g. 64 bytes using 0x0 NULL bytes or some other character. The padding can be performed after the input conversion to UTF 8 and after UTF 8 is represented to the system as a stream of raw bytes. Because NULL bytes are used for padding other ASCII UTF 8 control bytes can be used as field separators within the message.

In STEPS the password is then provided to and received at the companion device e.g. the same or different user can manually enter the password at the companion device or it can be transmitted in some other manner . Along with the encryption password a user can enter information e.g. a message in the companion device to be transferred to the mobile device STEP . The message can be user credentials such as a username and password and or other sensitive data.

In STEP the companion device generates an encrypted payload. In one implementation the encrypted payload is generated as follows. Initially the user input message is converted from the system application native encoding into UTF 8. The resulting raw bytes are used as plaintext. If the resulting length in the raw binary form is greater than 64 bytes the input is not accepted and the operation is aborted. It should be noted that in this example only the raw bytes are counted and not the characters in the UTF 8 message as the number of characters in the message can be less than the actual number of bytes used to represent the message in UTF 8.

A salt is generated in the form of a 16 byte random initialization vector IV using a cryptographically secure pseudo random number generator CSPRNG and the UTF 8 encoded message is padded to 64 bytes with 0x0 NULL bytes to obtain plaintext.

The PBKDF2 key derivative function KDF is used to generate a 256 bit key that will be used for the actual encryption. Specifically the originally supplied encryption password that was converted to UTF 8 is used as the input password to the key derivation function and the IV is used as the salt. In this example the number of iterations is set to 5000 and SHA 256 is used as a pseudorandom function PRF. The padded plaintext is then encrypted using the encryption key derived using the KDF and the IV with an AES cipher in the CFB mode of operation with a segment size of 128 bits and no padding. This generated ciphertext is prepended with the non encrypted IV to obtain the payload IV encrypted payload portion . The payload can then be Base64 encoded.

In STEP the Base64 encoded payload is used to generate a QR code with the pixel size is set to 7 and the error correction level set to L low . However other QR code configurations are contemplated. The QR code is then presented by the companion device for scanning by the mobile device STEP . In some instances the QR code is erased after a certain amount of time e.g. 30 seconds and or manually by the user.

In STEP the QR code is received from the companion device and the payload is decrypted to obtain the transmitted information STEP . In one implementation the payload is decrypted as follows. First the QR code is Base64 decoded to obtain the payload. The first 16 bytes from the payload are assigned to the initialization vector IV and the remainder of the payload is assigned to be the ciphertext.

The PBKDF2 key derivative function is used to generate a 256 bit key that is used for the actual decryption of the ciphertext. The encryption password originally generated by the mobile device in STEP is converted to UTF 8 encoding and is used as the input password to the KDF and the assigned IV is used as the salt. Further in this example the number of iterations is set to 5000 and SHA 256 is used as the pseudorandom function. Plaintext is then obtained by decrypting the assigned ciphertext using the derived key and assigned IV with an AES cipher in the CFB mode of operation with a segment size of 128 bits and no padding. The 0x0 NULL bytes are then stripped from the resulting plaintext to obtain the original message.

In one implementation a wearable or other user device is bound to a specific organizational e.g. corporate clinical secure network. The device can automatically lock to a splash screen and or prevent the use of some or all functionality unless the device is connected to that specific network. In another implementation the device is bound to a specific geographical premise. The device can automatically lock to a splash screen and or prevent the use of some or all functionality unless the device is within the defined geographical area. In other circumstances the device can be partially useable outside the geographical area but restrict access to an internal network and or sensitive data such as patient records.

User devices can be bound to a specific organizational network and or geographical premises using one or more techniques. In one implementation a device is bound to the foregoing via a connection to one or a series of Wi Fi networks. As a primary measure to be bound to the network premises the device can be securely connected to the organization Wi Fi network s using certificate based credentials. Without this secure connection the wearable device is considered unauthorized and can be locked or placed in a state of reduced functionality. As a secondary check even if the device is connected to the organizational network the device can still be deactivated if it is determined to be located outside of a set of permitted locations. For example the wearable device can measure the signal strength of certain Wi Fi network s whether or not the device is connected and if signal strength drops below a threshold strength for a certain period of time the device can be disabled. Upon returning to a permitted location and or reconnecting to the organization network the features of the device can be automatically re enabled.

In other instances the operator can reauthenticate e.g. with a QR code to continue using the device. Other implementations can use various binding techniques instead of or in addition to Wi Fi network connection and signal strength analysis. For example the wearable device can include a GPS module that provides location information for the device. The permitted areas of use for the device can be defined using geofences such that features of the device can be disabled and or enabled when a geo fence is crossed.

The client device includes a NVS client administration component NVSCA and an NVS client component NVSC that resides within the application . The application can query the NVSC in order to determine if the client device is located in an approved geofence and is communicating over an approved network. The configuration storage stores configuration data for the NVSC such as MDM policies. The NVSCA is used when the client device is not under control of MDM policies or as an additional component alongside MDM policies. If present the NVSC can communicate with the NVSCA component to perform actions that otherwise cannot be performed by an application containing the NVSC due to application permissions. In various implementations communication between the NVS NVSC and the MDM uses transport layer security to provide secure communication. In some implementations the NVS can also be used by the NVSC to attempt to ascertain if the client device s environment is being altered. For example the client device can use data packet round trip times to determine if the distance between NVS and client device is within a same geofence. If they are not within the same geofence it may be likely that the client device is communicating with a fake NVS.

If the initialization fails because the received secret key does not match the sent secret or because the client device is not connected to a permitted network or located in a permitted geofence the NVSC can perform one or more actions such as erasing the application data storage erasing the application erasing the entire storage of the client device sending an alert message to the NVS and attempting to restart the initialization process . If the NVSC lacks permission to perform one or more of the aforementioned actions the NVSC can request permission for doing so from the NVSCA . In some implementations the NVSCA can send a message to the MDM requesting that the MDM direct a MDM proxy process on the client device to perform the action.

In some implementations a wearable device can act as a bridge to interface with legacy or other systems in an organization s network. For example in a retail system as an operator scans product barcodes using the wearable device various information about the products can retrieved from the organization s legacy inventory system translated or transformed as necessary and displayed to operator via the device. Likewise the operator can scan a number of the same item gesture that the count is complete and the wearable device can transmit the inventory count to the legacy system. Data translation interfacing and bridge based computation can be performed on the wearable device as necessary.

In one implementation the present system is ruggedized for poor or low connectivity states. Data is fetched and cached when the network is available. When offline the system continues with last known data and bi directional transmission payloads are built and queued up for later transmission when the network is made available again .

Further the system supports deferred speech to text recognition. When no network connection is available the system first tries to transcribe the spoken audio snippet locally on the device. The device can attempt to recognize spoken keywords that are in the device s local dictionary e.g. navigational commands document names etc. . If this is not possible due to the complexity of the audio captured e.g. if no keywords are recognized the system can record and save the audio for later analysis. Once the network connection is restored the saved audio can be transmitted to a remote server for transcription. If the saved audio included instructions for the device the system can then attempt to execute the instructions on the device or ask the user for permission to do so.

A checklist represents the work that the worker can perform. The checklists are hosted in a checklist repository on a server and are synched to a user device when the user logs in or performs a force refresh. The checklists can be downloaded from the server in a compressed format as a single file and can be stored locally on the device in uncompressed state. This allows the user of the system to perform work even when there is no network available. Data generated by the user is stored locally on device storage and is pushed to the server as and when network connectivity is available.

The Checklist Management Framework is responsible for downloading checklists from the server version management and storage management. The Persistence Framework provides an application programming interface API to store and retrieve data asynchronously to from different data stores such as SQLite dBase flat files Android preferences etc. The data stored is persistent and is not lost if the system crashes restarted or is updated. The API allows users to store structured data such as date number text as well as unstructured data like an image video etc.

The Sync Framework is responsible for sending data to the server. It tries to send data to the server when the network is available and batches data to provide optimal network usage. Once the data is sent to the server and an acknowledgement is received the space is reclaimed for future use. Data is sent to the server in order of when the data is stored so the server can play back the worker s actions as they occurred on the worker s device. The Sync Framework monitors network connectivity and as soon as the network is available it sends data that is not yet synchronized with the server.

In one implementation a worker must be connected to a network when logging on to his wearable device for the first time. This allows for the storage of an authentication token from the server and the downloading of standard work locally to the device. If a network failure occurs while attempting to download a procedural checklist it can be re downloaded when opened. This authentication token can last for a certain time period e.g. 24 hours after which point the worker will be asked to login again if on the network . The token can continue to exist even if the worker device is completely restarted or the worker quits a workflow application. The token can be deleted if the worker manually selects a log out option or if the workflow application is uninstalled or the application data is otherwise deleted.

The token can be continually extended e.g. every hour as long as the worker has network connectivity and is using the workflow application so that he or she will not be prompted to login again while active on the network. The worker can also go out into the field in a region not having network connectivity and will be able to use the workflow application completely offline. This includes executing all standard work and all execution data can be captured and stored locally. In some implementations even after the expiry of the token the worker can continue to use the workflow application on the worker s device to execute checklists and capture data locally. When the worker reconnects to the network and the workflow application attempts to upload execution data if the token has already expired e.g. it has been more than 24 hours since login last activity the worker will be prompted to login before the execution data can be uploaded to the server.

The present system allows multiple workers to perform work offline on the same device and the data and session information for each worker is stored in separate data blocks and synched to the server when the network is available Workers are also able to pause and resume a session. Session state can be preserved even if the device reboots or loses power.

Referring now to in one implementation the workflow and communication system described herein includes a management system that allows a user to create procedural workflows that are deployable to one or more end user devices over a network . The workflows are write once run anywhere in that a created workflow can be created once and deployed to various different end user devices without requiring customizations per device to properly function. End user devices can be mobile devices such as digital wearable devices e.g. Google Glasses smart glasses smartphones laptops tablets and the like. As noted herein the end user devices can include software applications that execute procedural workflows created by using the management system that allow for a user to communicate with or be guided trained by remotely located personnel and so on. For example a software application can execute on an end user wearable headset that enables the user to step through checklists in order to accurately and safely complete company workflows. In addition users can capture audio images video and other data relating to procedures which can be stored on the management system and can be used for compliance audit troubleshooting and so on.

In an industrial setting an application for executing procedural workflows referred to herein as the Director application provides field service operators with a hands free digital workflow system for performing standardized procedures in conjunction with end user devices that execute the application. The Director application can be navigated with voice commands and head gestures and in field data can be captured in the form of dictated messages or point of view perspective photos and recorded videos. The Director application can record extensive metrics for workforce analytics such as the length of time taken for the operator to complete each step which can be used for audit compliance and continuous improvement. The data can also be automatically fetched edited and uploaded from to the relevant organization servers e.g. industrial database systems including but not limited to an inventory management system or a materials management system .

In a clinical setting the Director application provides healthcare providers with a hands free digital workflow system for performing standardized exams tests or procedures. The Director application can be navigated with voice commands head gestures and touch actions and in field data can be captured in the form of dictated messages or point of view perspective photos and recorded videos. The Director application can record extensive metrics for analytics which can be used for audit compliance and continuous improvement. The data can also be automatically fetched edited and uploaded from to the relevant organization servers e.g. clinical systems including but not limited to electronic health record EHR servers emergency department trackboards ED Trackboard etc. .

In some implementations the Director application can be executed entirely or partially offline. For example when the application has network connectivity it can retrieve all or a subset of the standardized procedures to which the operator user has access. The operator can navigate through a particular workflow in an online or offline state and the collected result data and analytics can be packaged up locally on the wearable device . Upon restoration of network connectivity the collected data and analytics can be uploaded to a remote organization server for storage and analysis.

The management system can be instantiated in a secure cloud environment installed within a company s network or in a third party cloud hosted service. This system provides a web based management interface with a visual authoring interface to create edit audit approve and delete checklist workflow procedures to be deployed on operator devices. The management system also provides the ability to also import workflows from XML Microsoft SharePoint documents and other systems as needed. In addition the management system can store an audit trail of completed steps and procedures including time location operator ID steps completed and responses given video audio photo recordings if applicable etc. .

In one implementation the management system has eight main components 1 a Domain Specific Language DSL to specify information transfer between application components 2 a standard work creation interface having a WYSIWYG editor to create and view procedures backed by the DSL 3 standard work approval deployment and versioning using an approval dashboard 4 intelligent work scheduling primitives and a standard work scheduling algorithm to assign available work to workers 5 standard work execution using client devices to capture field data 6 reporting and displaying data generated by standard work execution 7 standard work feedback alerts provided to an author using in application feedback submission and 8 an administrator dashboard to allow administrative users to define the information structure of a standard work library.

These system components provide for a system where an author can generate a procedure on an authoring dashboard once and execute capture data for that procedure on any supported device or context e.g. a web based execution on a desktop in a browser tablet based execution on a tablet device wearable based execution on Google Glass etc. 

Accordingly in one implementation a method for authoring a procedural flow is depicted in . In STEP the management system provides an interface for authoring the procedural workflow. A user can select order and configure one or more primitives STEP using the interface. Generally a primitive is a component of a procedural step. For example a primitive can be an element of interaction between a user and a data item such as image or video capture or display text entry or display option selection and so on. In STEP a step of the procedural workflow is defined based on the selected primitives. Further in STEP the interface displays one or more rendering previews of the procedural workflow as it would appear on different user devices. In some implementations workflows are write once run anywhere in that customized workflows do not need to be created per unique user device. For example the same workflow can run on a wearable device and a tablet and while it may be displayed differently or accept user output the workflow will proceed through its steps in an equivalent functional manner on each device. The above steps are explained in further detail below.

Procedural checklists can be custom built from a set of primitives which cover a wide variety of situations. Additional primitive types can be added to the set. Primitives can include for example scanning getting data taking transcription and other basic functions. The management system can include authoring capability to allow for the creation of workflows from combinations of primitives. In one implementation an XML schema defines the primitives and the manners in which they can be combined to form procedural checklists. Accordingly a completed workflow can be represented in an XML based language such as that described in Appendix A Wearable Intelligence Markup Language WIML XML below. In other implementations WIML can be represented using JavaScript Object Notation JSON as shown in Appendix B below.

The WIML procedures can be processed and composed into instructions compatible with the end user wearable device . The device can execute the instructions to for example provide a procedural checklist to the operator such as those described below. The result of the executed instructions e.g. the operator s progress through the checklist can transmitted to a remote server e.g. organization server along with analytics data relating to the performance of the operator.

As noted above a DSL can be used to transfer information and encode standard work. The DSL can be encoded in XML documents referred to herein as WIML documents . In one implementation each WIML document has 4 elements at the root a metadata element a head element a body element and a foot element. The metadata element is encoded with metadata related to the standard work for instance the name of the author of the document can be listed within the metadata. The metadata also includes the document type. Different document types can be populated with different steps.

The head body and foot elements are each populated by step elements. A step element represents a single execution frame in a procedure and steps are composed of customizable primitives that allow users to create their own step architecture. Examples of primitives include a text element that allows the display of text a picture element that allows the display of pictures an image capture element that allows the user to capture a picture using the end user device a text input which allows the user to record textual data and an option input that allows the user to select and record one choice from a list. Other primitives are contemplated. It should be noted that steps are composable and constructed from the primitives.

The primitives that represent data capture during execution allow the captured data to be viewed on an analytics dashboard described below. The DSL provides for a common data architecture among multiple execution contexts i.e. a write once run anywhere paradigm. Additionally this construction allows for different input formats on different devices. For instance a textual input primitive may accept a voice input on a wearable device and a typed input on a tablet.

One possible primitive is the capture scanning or recognition of a bar code QR code text beacon signal RFID tag signal or other object. In one implementation the wearable device can be used to scan the particular barcode or QR code. In an industrial setting for example this feature can be used to identify the tool being worked on or materials that are required to complete a task see . In a clinical setting this can also be used to identify the patient or medications or tools that are required to complete the procedure see . In either setting the QR code system can also be used to authenticate a user.

More complex data capture can occur using an end user device . For example the device can include optical character recognition OCR and or object recognition to provide for task commencement and or other functions through interpretation of text rather than a barcode or QR code. Image analysis techniques can also be used to recognize objects. For example a database of industrial objects in three dimensional form can be maintained and edge matching feature matching and or other techniques can be used to determine which object or objects are shown in the view of the operator. Based on the object detected a workflow can be started a task can be accomplished and so on. In other instances Bluetooth beacons and or RFID tags associated with objects and or locations can be scanned using the wearable device to start or finish an event.

The Information Display primitive does not require a response from the operator but rather is used to display information to the operator prior to completing a step. For example it can display a how to procedure using video photos audio and or text prior to the procedure being performed. Information from the industrial knowledge management systems or the clinical systems can be incorporated as well as past incidents from the event database to ensure mistakes are not repeated.

The Gating Step primitive supports a step that is gating and must be completed or acknowledged in order to continue to the next step in the checklist. depicts a text based gating step primitive that requires user interaction to confirm. depicts a point of view perspective of an operator navigating hands free via voice through a gating step.

The Binary Response primitive supports a checklist step that has a response with one of two values e.g. yes no true false successful unsuccessful etc. . depicts an example binary response step as displayed to a user.

The Multiple Choice primitive supports selecting one of an arbitrary number of possible responses. depicts an example multiple choice step as displayed to a user.

The Dictated Data Entry primitive supports a free form response which is dictated by the operator and transcribed. This primitive can optionally be constrained to for example accept only a numerical response. depicts an example dictated data entry step as displayed to a user.

Another primitive supports taking a picture for example as a form of compliance that the step is completed see . Similarly one primitive supports the recording of a video while the operator is completing a task for example as confirmation that the task was done correctly see .

In one implementation the management system provides an authoring interface that allows users to create and edit procedural workflows in a WYSIWYG editor. The interface allows users to create procedures and edit these procedures in views that simulate how the procedure would be rendered in multiple formats and on multiple devices e.g. a printed PDF a tablet a wearable device and an unstyled construction view . depicts an example document view for a pizza delivery procedural workflow. depicts a wearable device view for the same workflow an example tablet view and an example outline construction view.

To create a procedure a user can select a new standard work button on the front page dashboard of the authoring interface see and input various configuration metadata entries see . The user is then redirected to a page displaying a blank procedure see .

In the editing dashboard there are two main active panels the left panel contains the step palette and the right panel contains the WYSWIG interface. To add a step to the new procedure the user can drag one of the elements from the step palette on the left into an active area on the right. As the step is dropped into an active area a modal dialogue appears that allows the user to input information about the step see .

WYSIWYG editing is shown in for this step in a few different views. The text this is editing is in a text field that is being edited during the screen capture. depicts the document view the wearable device view and the tablet view.

The steps within the step palette are each constructed from step primitives and represent steps in WIML. In the administrative construction panel administrative users can construct steps from primitives and add these steps to the palette. Completed steps can be saved in a step library and used in different procedures. This allows common steps to be written once and run in multiple procedures where needed. Additionally each procedure can load steps from this step library. Completed checklists can be combined into work sets that can be executed in series executed using predetermined branching logic or executed intelligently where branching between procedures is determined via an customer provided software integration.

In one implementation the authoring interface provides a dashboard to approve version and deploy procedures across all execution platforms. The dashboard allows a procedural workflow author to configure the versioning system. The author can define the value of the initial version and can also define how the value changes on every version update. When a procedural workflow is created it gets assigned the initial version value e.g. 1.0 and its status is set to Editing. The author can edit the procedure when it is in the Editing status.

Once satisfied with the changes made to a procedure the procedural workflow author can send the procedure for review. This puts the procedure in a Sent for Review status and freezes it against edits until it goes through the approval process. The approval process is configurable and can consist of multiple stages to be executed concurrently or sequentially. A sample approval flow is illustrated in . As shown each stage is associated with a role. At each stage an approver with the role corresponding to that stage can either approve or reject the procedure.

In some implementations rejection at any stage removes the procedure from Sent for Review status and puts it back into the Editing status. The author of the procedure is notified of the same. When an approver rejects the procedure the approver can be provided with the option to add comments explaining the action. The author of the workflow can refer to the comments make corresponding changes to the procedure and send it again for review.

If the procedural workflow successfully makes it through all or at least the required defined stages of the approval process it proceeds to the Approved status. An approved workflow is ready to be deployed across all execution platforms. The workflow can be saved e.g. as an XML based file and packaged into a zip archive along with accompanying media assets and uploaded to a procedural workflow storage server. Workflow execution platforms can periodically query the procedural workflow storage server for new procedures or version updates to existing workflows and subsequently new checklists can appear automatically on connected devices.

The execution of standard work allows a few ways for work to be intelligently scheduled for workers during both authoring and execution. Intelligent work scheduling is a way to enhance bundles of procedures that are executed in series by selecting correct branching logic or removing duplicate work using built in primitives.

One way to intelligently schedule execute standard work procedures is using the do once primitive within a step. This primitive allows steps to be hidden depending on the context of execution. Individual steps can appear in multiple different procedures the user can load commonly used steps from a library of complete steps . These library steps can be tagged with a do once flag. During the execution of a workflow if a step with a do once flag is encountered the execution engine will check if an identifier associated with the step exists in a list of completed steps indicating that the step has been completed in an earlier procedure within the set. If the identifier is found within the list then the step is skipped because of its previous execution. If on the other hand the identifier is not found within the list then the step is displayed normally because it is the first time that the step is executed.

An example use case for the do once primitive in a step is in a work set that contains multiple procedures relating to machine maintenance. Procedures A and B are executed sequentially. Step 1 of both procedures A and B is a library step that instructs the executor to Lock Out Tag Out for safety compliance. Both procedures A and B when executed individually require the lock out tag out instruction but if they are executed in sequence the maintainer should already be locked out tagged out during the execution of procedure B because they will have had completed that step in procedure A. Adding this primitive to the step allows the execution engine to not display the log out tag out step in procedure B after it has been executed in procedure A thus reducing redundant work.

Another way to schedule execute standard work procedures is by creating standard work sets dynamically based on application programming interface API links to a workflow service. The API provides access to procedure libraries and execution data in real time. This allows a procedural workflow author to build software services that read data using the API and select which procedures to branch to given current conditions. This in essence allows the creation of dynamic work sets or dynamically created work sets that exist only in a current execution context and are assembled based on values determined in execution.

An example of this is a when a user begins a dynamic checklist starting with procedure A which walks the user through changing the transmission fluid of an oil rig drill bit gear driver. Procedure A instructs the user to measure the specific gravity and temperature of the transmission fluid. At the end of procedure A the dynamic set execution context makes a call to a dynamic work set generation engine which can be provided by the workflow author organization passing in certain data gathered in executing the procedure. The dynamic work set generation engine returns an identifier associated with a library procedure that can be executed given the gathered data from procedure A. The workflow then proceeds to execute the procedure selected by the dynamic work set generation engine.

The Director application allows for the execution of procedural workflows on end user devices such as desktops laptops tablets and mobile devices via browser applications as well as tablets mobile devices and wearable devices via native applications.

With respect to wearable devices e.g. Google Glass various software enhancements provide user experience and navigation improvements. For example a software based component is included for passive voice listening and evaluating voice commands for navigation between screens. Rather than wait for a particular keyword or phrase e.g. OK Glass the component ignores filters noise and listens for audio that sounds like spoken words. Recognized words can then be matched to navigation commands. As another example sensors in the wearable device e.g. gyroscope accelerometer etc. can be used to determine head position and movement allowing for head scrolling recognition and navigation of views which exceed the physical size of the screen.

In one instance interface screens or cards can include titles or other text that has semantic value and can be included in the local and or remote dictionary of the wearable device. Voice recognition can be used to detect when a title or other text associated with a card is spoken and the card can be navigated to on command. Other commands associated with a card can also be executed on voice command such as retrieving or sending data capturing an image or video and so on.

As another example the wearable device can be paired with and controlled using a Bluetooth and or near field communication NFC ring. Further a peripheral projector can display a virtual keyboard that is paired to the wearable device and acts as an alternate means of input.

The Director application provides significant benefits over existing ad hoc mobile workflow solutions such as an increase in procedural adherence. By having a standardized and easy to use checklist operators are far more likely to complete procedures as specified. In addition the user experience is designed to be engaging rather than a burden on the field operator. Because many procedures and workflows are designed to increase safety increased adherence also leads to fewer incidents or accidents. Operators failing to adhere to procedures can lead to costly downtime due to incorrect operation of equipment etc. and thus reducing downtime has a tangible financial benefit.

Using the Director application a company can also easily maintain records that tasks were completed and protocols followed with video and photo evidence. Further unlike alternative solutions based on mobile phone or tablet hardware the hands free nature of the wearable headset provides for greater convenience leaving both of the operator s hands free to do the job is more robust less chance of devices being dropped lost or broken and in situations requiring it the hands free nature allows for sterile conditions to be maintained.

In one implementation once authenticated on an end user device a user is presented with a dashboard that lists the standard work procedural workflow s filterable by one or a combination of options available in the metadata of that standard work. The status of each standard work is also displayed e.g. Not Started Aborted Incomplete Complete .

Upon selecting a standard work to execute the Director application on the end user devices renders the WIML document of that standard work into viewable and or actionable steps. The user can be initially presented with a preview of the steps that compose that standard work on a single screen in a scrollable view. From there the user can continue on to execute the standard work step by step.

There are several types of steps that a user can be presented with as constructed using the authoring interface described above . They can be viewable steps that display content such as text zoomable images video audio etc. There are also actionable steps that request input such as capturing images or video scanning barcodes alphanumeric text entry selecting an option from a dropdown menu etc. The actionable steps can also be skipped provided that a reason for skipping the step is given.

Depending on the medium of execution the steps may be presented or interacted with in different fashions. For example on a wearable device such as Google Glass the primary means of input are voice commands and due to the limited screen real estate some presentable data may be hidden until triggered visible by a specific voice command. On the other hand a desktop web browser can present more information at one time and can accept keyboard and mouse input.

In addition to user interface and experience changes across the mediums of execution architectural changes can also exist. For example a mobile device may need to queue posting data to a server to save on battery or until a stable network connection is established whereas a desktop web browser that has more computational power and a persistent network connection can post data to the server as it comes in. Of note the various execution platforms render and handle the WIML document in these various fashions but the document itself does not change the same document can be used across these execution platforms.

In some implementations a user can navigate forwards and or backwards through the standard work with the Director application recording a stack trace of the steps visited. The user is typically presented with the option to proceed to the next step or go back in the stack trace. Actionable steps can also contain branching logic which depending on the input the user provides can navigate the user to different steps of the standard work though not necessarily in chronological order.

Actionable steps can be marked as gating or blocking which will not allow the user to proceed until the requested action is completed. Actionable steps can also be assigned expected minimum and or maximum values. In the event that the user s input does not fit the bounds assigned the standard work can proceed as defined in the WIML document. For example the WIML document can require the standard work to ignore the invalid input and proceed to the next step jump to a specified step or abort and return to the dashboard.

Various metrics can be collected by the Director application such as the time a user spends on each step. A user can also optionally choose to leave feedback on a step. At points throughout the standard work the user can also has the option to abort the standard work and return to the dashboard provided a reason for aborting is given. The user can also choose to see all of the input he or she has currently recorded.

Upon completion of the standard work the user can be presented with a review of the steps and recorded values for those steps in a similar fashion to the preview of the steps the user initially saw when beginning execution of the standard work. Here the user can also be given the option to provide feedback on the standard work as a whole. The data collected and the user actions performed can be recorded on a remote server connected to the end user device.

The execution of procedural workflows can result in the collection of data which can be further analyzed. Such data can include average amount of time required to complete a standard procedure average amount of time required to complete a step in a standard procedure average amount of time taken by a particular person to complete a standard procedure average amount of time taken by a particular person to complete a step in a standard procedure average value generated by a step in a procedure for example average pressure recorded in a pipe each of the foregoing but instead of average value the range of values and the total values and completion or abortion percentage for a step or procedure. Other types of collected data are contemplated. depict an example graph and histogram respectively of trend data collected over multiple executions of a standard procedure. depicts an example accounting of steps taken during the execution of a standard procedure.

When executing a standard work procedure an operator can submit feedback for each step in the procedure and for a procedure as a whole. The feedback can be submitted in a number of different ways depending on the execution device being used. For example feedback can be submitted using text entry speech to text and or video. In the case of poor or no connectivity the feedback can be saved locally on the end user device and then transmitted to a remote server when the device regains connectivity.

Feedback can be aggregated in various ways for example per step in a procedure per procedure per executor per author and or per region. The aggregated feedback can be provided to the procedural workflow author via the dashboard and or through email notifications whenever an executor submits feedback for a step procedure that was created by the author. The author can then modify the procedure or take other appropriate action based on the feedback.

In one implementation the present system provides multimedia communication and remote assistance functionality through an Avatar application executing on an end user device and a corresponding application executing on a remotely connected system. The system enables a remote expert to communicate with an onsite worker operator or other user who has a wearable or other mobile device. The system incorporates live video and audio streaming as well as text image video and audio messaging to establish communication.

In an industrial setting the Avatar application enables experts to remotely supervise and guide field operators through complex procedures using two way text and audio communications augmented by point of view perspective video. An in field component of the Avatar application is controlled in a completely hands free manner allowing the operator to focus on the task at hand. The communication system can also interface with an existing corporate telecom infrastructure.

In a clinical setting the Avatar application enables clinician experts to remotely supervise and guide other physicians surgeons nurses and physician assistants through complex diagnoses or procedures using two way text and audio communications augmented by point of view perspective video. The communication system can also interface with an existing clinical telecom infrastructure. For example it can enable hands free dictated paging of a resident attending nurse tech that is delivered via an existing pager network.

Referring to a worker using a wearable device can send live audio and or video feeds over a network to Media Server . Media Server can then relay the feeds to an expert who can be located anywhere in the world where network connectivity is available. The expert can use telestration tools on the live video feed including but not limited to adding free hand drawings to the live video feed highlighting areas of the live video feed adding text to areas of the live video feed and highlighting objects on the live video feed. The expert can then send the telestrated images back to the wearable device of the onsite worker through Messaging Server . The expert can also record his voice and send text messages to the worker through Messaging Server and similarly the work can send messages recorded audio images and the like back to the expert through Messaging Server .

Messaging Server guarantees delivery of a particular message at least once to the receiver up to a certain amount of time if it has acknowledged receiving the message to the sender regardless of whether the receiver is currently online. In low bandwidth situations where live video and audio are not possible the expert and onsite worker can communicate through Messaging Server using messaging methods that use minimal amounts of bandwidth.

Each worker can be equipped with a wearable headset such as the Google Glass or Microsoft HoloLens wearable devices thereby enabling the operators to stream their point of view perspective video and have a two way text and audio conversation with experts while leaving their hands free to focus on the task at hand. The headsets can run custom software stacks to ensure that no data is transmitted to third party servers and that the devices are secure within a particular organization s network. The communication system used by the headsets can also interface with mobile phones tablets pagers computers and other devices. It is not a requirement that both parties worker and expert are using a wearable headset. illustrate two way text based message communication while streaming a point of view perspective video using a wearable device.

The expert facing video receiving end of the interface can run on wearable hardware including Google Glass hardware as well as standard mobile devices phones tablets etc. and or desktop and laptop computers.

In various implementations a worker can discover an expert that he would like to communicate with. For example the worker can locate an expert using metadata associated with the expert such as name organization unit role e.g. Systems Engineer Drilling Machine Expert etc. and or geographical area e.g. the expert closest to the worker in city X etc. . A company can also specify criteria by which an expert can be chosen based on an incoming request for a worker. For example a company can filter incoming requests based on the specific business unit of the employee i.e. match expert and worker from the same business unit . Experts can also be located using combinations of the foregoing criteria e.g. Machine Drilling Expert in Houston .

The simple matching procedure described above works in many cases but in order for a worker to connect with an expert that is well suited to address their problem an advanced matching procedure allows the worker to specify the problem in a few words before calling for an expert e.g. stating that the oil pump is not starting .

Referring now to a signaling server is responsible for call setup management and tear down. Experts log into the remote help system and make themselves available to workers requesting assistance. When a worker needing help initiates a call to an expert the signaling server can match the worker with the expert and set up the call. The signaling server can also perform teardown of the call once the call is terminated.

In a specific example the signaling server performs a basic match with metadata to build a list of experts that can help a worker that has requested assistance. Once a group of experts is determined the signaling server forwards the call acceptance request along with the problem statement mentioned by the worker to allow one or more experts to see the problem faced by the worker before they accept the call thus allowing the right expert to help the worker. The system also allows the worker to record a small audio or video message instead of text which the expert can also see before accepting the call.

The remote help system also allows an expert to respond to a worker in the event the worker does not receive help e.g. no expert was available when the worker reported the problem . The issues provided by the worker in the form of text or a short video message can be made available to the expert when he logs in to the remote help system. The expert can then send a notification to the requesting worker to see if he or she is interested establishing a communication session to try and resolve the problem. In this case the system can link the worker directly to the expert thereby bypassing the selection process.

In some implementations the remote help system allows workers to communicate with an expert over low bandwidth networks such as satellite via mobile devices. Due to high latency and low bandwidth it may not be possible to establish a live audio video session between the two parties. When a live session is not possible the worker can start the communication over a message channel where recorded audio recorded video image and text messages can be exchanged. This allows the expert to guide the worker even when network connection is not optimal.

In this instance referring to Messaging Server is responsible for relaying messages between the worker and expert. The messages can be video audio text and or image based. Since the remote help system is not live streaming the quality of video and audio can be much higher compared to a live stream since they are recorded locally on the device and not compressed. The video and audio messages can be very short e.g. a few seconds in order to conserve bandwidth such that messages can be exchanged quickly. Messaging Server is also responsible for caching the messages so that if the worker or expert loses network connectivity intermittently they can reconnect to retrieve the messages.

In one implementation the present system includes a Mentor application that allows for video training to be recorded by and provided to an user s wearable device while the user is operating in the field. In an industrial setting the Mentor application enables best practice specialists to record point of view video in an unobtrusive hands free manner while completing complex operations. Other operators and trainees can review these videos in the field in a hands free fashion in advance of performing critical steps. In a clinical setting the Mentor application enables best practice clinician specialists to record point of view video in an unobtrusive hands free manner while completing complex operations. Other clinicians residents and support staff can review these videos in the clinical environment in a hands free fashion in advance of performing critical steps. depicts a best practice procedure video requested and viewed in the field on a heads up display.

In one implementation the present system includes an Informant application that provides real time data to the wearable device on an onsite worker. For example in an industrial setting the Informant application provides critical data in the operator s field of view to improve safety and situational awareness. Real time telemetric data along with critical alerts and notifications of error or exception conditions is displayed in a hands free unobtrusive manner in the field of view. The system is also able to respond to intelligent environment cues including Bluetooth smart beacons to display contextually relevant data. In some instances the data alerts that are generated as a result of the wearable device detecting an object condition or other item are part of a primitive in a workflow or initiate a set of primitives in a new workflow. depicts an example live telemetric report retrieved and streamed to a heads up display in an industrial setting.

In a clinical setting the Informant application provides data in the clinician s field of view to improve safety and situational awareness. Real time telemetric data including vitals streams data pulled from the clinical systems like the Electronic Health Record along with critical alerts and notifications of error or exception conditions is displayed in a hands free unobtrusive manner in the field of view. Data pulled from clinical systems can include but is not limited to patient lists including room patient name chief complaint resident assigned labs vitals radiology data provider lists the resident attending nurse and tech assigned to this patient medications comments and so on. The system can send push notifications to clinicians when new data arrives that is relevant to one of their patients e.g. a new radiology result . The system is also able to respond to intelligent clinical environment cues including Bluetooth smart beacons to display contextually relevant data. In some instances the data alerts that are generated as a result of the wearable device detecting an object condition or other item are part of a primitive in a workflow or initiate a set of primitives in a new workflow. depicts example contextually relevant health data retrieved and provided to a heads up display in a clinical setting.

In one implementation the present system provides the ability for operators to record data into central systems while they are remote mobile and on the move. For example a doctor can dictate comments after examining a patient and have the comments immediately sent and stored in a central Electronic Health Record system. Similarly a field operator can dictate information about equipment in the field and have the information sent back to a central server.

Operators often need to track materials and equipment in the field. To avoid the cumbersome task of carrying around pen and paper or running back and forth to a nearby computer the present system can allow an operator to scan equipment barcodes and dictate relevant information using voice. This data can then be transmitted to a central inventory management server for tracking.

Implementations of the present system can use appropriate hardware or software for example the various applications executing on user devices and or remote server s as described herein can execute on a systems capable of running an operating system such as the Microsoft Windows operating systems the Apple OS X operating systems the Apple iOS platform the Google Android platform the Linux operating system and other variants of UNIX operating systems and the like. The software described herein can be implemented on a general purpose computing device in the form of a computer including a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit.

Additionally or alternatively some or all of the functionality described herein can be performed remotely in the cloud or via software as a service. For example as described above certain functions can be performed on one or more servers or other devices that communicate with user devices over a network. The remote functionality can execute on server class computers that have sufficient memory data storage and processing power and that run a server class operating system e.g. Oracle Solaris GNU Linux and the Microsoft Windows family of operating systems .

The system can include a plurality of software processing modules stored in a memory and executed on a processor. By way of illustration the program modules can be in the form of one or more suitable programming languages which are converted to machine language or object code to allow the processor or processors to execute the instructions. The software can be in the form of a standalone application implemented in a suitable programming language or framework.

Method steps of the techniques described herein can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. Method steps can also be performed by and apparatus can be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit . Modules can refer to portions of the computer program and or the processor special circuitry that implements that functionality.

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors. Generally a processor receives instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Information carriers suitable for embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. One or more memories can store media assets e.g. audio video graphics interface elements and or other media files configuration files and or instructions that when executed by a processor form the modules engines and other components described herein and perform the functionality associated with the components. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

In some implementations a user device includes a web browser native application or both that facilitates execution of the functionality described herein. A web browser allows the device to request a web page or other program applet document or resource e.g. from a remote server such as a web server with an HTTP request. One example of a web page is a data file that includes computer executable or interpretable information graphics sound text and or video that can be displayed executed played processed streamed and or stored and that can contain links or pointers to other web pages. In one implementation a user of the user device manually requests a resource from a server. Alternatively the user device automatically makes requests with a browser application. Examples of commercially available web browser software include Microsoft Internet Explorer Mozilla Firefox and Apple Safari .

In other implementations the user device includes client software that provides for the implementation and execution of the features described herein. The client software can be implemented in various forms for example it can be in the form of a native application web page widget and or Java JavaScript .Net Silverlight Flash and or other applet or plug in that is downloaded to the device and runs in conjunction with a web browser. The client software and the web browser can be part of a single client server interface for example the client software can be implemented as a plug in to the web browser or to another framework or operating system. Other suitable client software architecture including but not limited to widget frameworks and applet technology can also be employed with the client software.

A communications network can connect user devices with one or more servers or devices. The communication can take place over media such as standard telephone lines LAN or WAN links e.g. T1 T3 56kb X.25 broadband connections ISDN Frame Relay ATM wireless links 802.11 Wi Fi Bluetooth GSM CDMA etc. for example. Other communication media are contemplated. The network can carry TCP IP protocol communications and HTTP HTTPS requests made by a web browser and the connection between the client device and servers can be communicated over such TCP IP networks. Other communication protocols are contemplated.

The system can also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules can be located in both local and remote computer storage media including memory storage devices. Other types of system hardware and software than that described herein can also be used depending on the capacity of the device and the amount of required data processing capability. The system can also be implemented on one or more virtual machines executing virtualized operating systems such as those mentioned above and that operate on one or more computers having hardware such as that described herein.

It should also be noted that implementations of the systems and methods can be provided as one or more computer readable programs embodied on or in one or more articles of manufacture. The program instructions can be encoded on an artificially generated propagated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. A computer storage medium can be or be included in a computer readable storage device a computer readable storage substrate a random or serial access memory array or device or a combination of one or more of them. Moreover while a computer storage medium is not a propagated signal a computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium can also be or be included in one or more separate physical components or media e.g. multiple CDs disks or other storage devices .

Wearable Intelligence Markup Language WIML is an XML based markup language used to define structured information for display on wearable technology e.g. Google Glass . WIML can support both JSON and XML based representations. The examples below are directed toward structured workflows and checklists for industrial workers although other purposes are contemplated.

A procedure s metadata section provides information about the procedure s author approver date and version as shown in the example below.

The overview section describes the procedure s name and number its objective and any preconditions necessary before beginning the procedure.

A procedure can be broken up into a series of sections in order to help with organization or to facilitate branching logic. A section has a title and can have a list of required safety equipment as well as set of steps.

The core unit of a procedure is a step. Steps can contain text images video and other elements. There are different types of steps described below depending on whether an instruction simply needs to be presented or input is required. Additional complex types of steps such as multi party collaboration can be added.

A manual step display an individual step that needs to be performed by the worker completing this procedure. It is simply a descriptive step with the only option being to advance to the next step or the previous step.

This type of step requires the worker to input some data. This may be one or more of text photo or video. The value is stored in a variable that can be referenced elsewhere in the procedure and will be accessible on the server.

This type of step requires the worker to explicitly verify a piece of information and record a pass or fail value. The boolean result will be stored in the specified variable so that it can be referenced elsewhere in the procedure and will be accessible on the server.

To facilitate procedures that must branch based on certain results WIML supports simple branching logic as shown below. Branching is based on the value of a variable defined by an input or verify step as above and causes execution to jump to a specified step or section.

If execution should simply jump to a different location no branching logic the following can be used to jump to a specified section or step.

Lastly if the procedure should terminate at this point the following can be used along with specifying an overall result . If execution reaches the end of the procedure it will exit with value success .

As mentioned in the overview in Appendix A WIML can be expressed in either XML or JSON. For clarity the XML examples from that Appendix are repeated here in JSON format.

The terms and expressions employed herein are used as terms and expressions of description and not of limitation and there is no intention in the use of such terms and expressions of excluding any equivalents of the features shown and described or portions thereof. In addition having described certain implementations in the present disclosure it will be apparent to those of ordinary skill in the art that other implementations incorporating the concepts disclosed herein can be used without departing from the spirit and scope of the invention. The features and functions of the various implementations can be arranged in various combinations and permutations and all are considered to be within the scope of the disclosed invention. Accordingly the described implementations are to be considered in all respects as illustrative and not restrictive. The configurations materials and dimensions described herein are also intended as illustrative and in no way limiting. Similarly although physical explanations have been provided for explanatory purposes there is no intent to be bound by any particular theory or mechanism or to limit the claims in accordance therewith.

