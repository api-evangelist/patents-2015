---

title: Adaptive mapping to navigate autonomous vehicles responsive to physical environment changes
abstract: Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide map data for autonomous vehicles. In particular, a method may include accessing subsets of multiple types of sensor data, aligning subsets of sensor data relative to a global coordinate system based on the multiple types of sensor data to form aligned sensor data, and generating datasets of three-dimensional map data. The method further includes detecting a change in data relative to at least two datasets of the three-dimensional map data and applying the change in data to form updated three-dimensional map data. The change in data may be representative of a state change of an environment at which the sensor data is sensed. The state change of the environment may be related to the presence or absences of an object located therein.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09612123&OS=09612123&RS=09612123
owner: Zoox, Inc.
number: 09612123
owner_city: Menlo Park
owner_country: US
publication_date: 20151104
---
This application is related to U.S. patent application Ser. No. 14 932 959 filed Nov. 4 2015 entitled AUTONOMOUS VEHICLE FLEET SERVICE AND SYSTEM U.S. patent application Ser. No. 14 932 966 filed Nov. 4 2015 entitled TELEOPERATION SYSTEM AND METHOD FOR TRAJECTORY MODIFICATION OF AUTONOMOUS VEHICLES U.S. patent application Ser. No. 14 932 940 filed Nov. 4 2015 entitled AUTOMATED EXTRACTION OF SEMANTIC INFORMATION TO ENHANCE INCREMENTAL MAPPING MODIFICATIONS FOR ROBOTIC VEHICLES U.S. patent application Ser. No. 14 756 995 filed Nov. 4 2015 entitled COORDINATION OF DISPATCHING AND MAINTAINING FLEET OF AUTONOMOUS VEHICLES U.S. patent application Ser. No. 14 756 992 filed Nov. 4 2015 entitled ADAPTIVE AUTONOMOUS VEHICLE PLANNER LOGIC U.S. patent application Ser. No. 14 756 991 filed Nov. 4 2015 entitled SENSOR BASED OBJECT DETECTION OPTIMIZATION FOR AUTONOMOUS VEHICLES and U.S. patent application Ser. No. 14 756 996 filed Nov. 4 2015 entitled CALIBRATION FOR AUTONOMOUS VEHICLE OPERATION all of which are hereby incorporated by reference in their entirety for all purposes.

Various embodiments relate generally to autonomous vehicles and associated mechanical electrical and electronic hardware computer software and systems and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically systems devices and methods are configured to provide updates to maps such as three dimensional 3D maps either locally e.g. in situ at autonomous vehicles or remotely or both for navigating one or more of this vehicles adapted to changes in environments through which the vehicles traverse.

A variety of approaches to developing driverless vehicles focus predominately on automating conventional vehicles e.g. manually driven automotive vehicles with an aim toward producing driverless vehicles for consumer purchase. For example a number of automotive companies and affiliates are modifying conventional automobiles and control mechanisms such as steering to provide consumers with an ability to own a vehicle that may operate without a driver. In some approaches a conventional driverless vehicle performs safety critical driving functions in some conditions but requires a driver to assume control e.g. steering etc. should the vehicle controller fail to resolve certain issues that might jeopardize the safety of the occupants.

Although functional conventional driverless vehicles typically have a number of drawbacks. For example a large number of driverless cars under development have evolved from vehicles requiring manual i.e. human controlled steering and other like automotive functions. Therefore a majority of driverless cars are based on a paradigm that a vehicle is to be designed to accommodate a licensed driver for which a specific seat or location is reserved within the vehicle. As such driverless vehicles are designed sub optimally and generally forego opportunities to simplify vehicle design and conserve resources e.g. reducing costs of producing a driverless vehicle . Other drawbacks are also present in conventional driverless vehicles.

Other drawbacks are also present in conventional transportation services which are not well suited for managing for example inventory of vehicles effectively due to the common approaches of providing conventional transportation and ride sharing services. In one conventional approach passengers are required to access a mobile application to request transportation services via a centralized service that assigns a human driver and vehicle e.g. under private ownership to a passenger. With the use of differently owned vehicles maintenance of private vehicles and safety systems generally go unchecked. In another conventional approach some entities enable ride sharing for a group of vehicles by allowing drivers who enroll as members access to vehicles that are shared among the members. This approach is not well suited to provide for convenient transportation services as drivers need to pick up and drop off shared vehicles at specific locations which typically are rare and sparse in city environments and require access to relatively expensive real estate i.e. parking lots at which to park ride shared vehicles. In the above described conventional approaches the traditional vehicles used to provide transportation services are generally under utilized from an inventory perspective as the vehicles are rendered immobile once a driver departs. Further ride sharing approaches as well as individually owned vehicle transportation services generally are not well suited to rebalance inventory to match demand of transportation services to accommodate usage and typical travel patterns. Note too that some conventionally described vehicles having limited self driving automation capabilities also are not well suited to rebalance inventories as a human driver generally may be required. Examples of vehicles having limited self driving automation capabilities are vehicles designated as Level 3 L3 vehicles according to the U.S. Department of Transportation s National Highway Traffic Safety Administration NHTSA .

As another drawback typical approaches to driverless vehicles are generally not well suited to detect and navigate vehicles relative to interactions e.g. social interactions between a vehicle in travel and other drivers of vehicles or individuals. For example some conventional approaches are not sufficiently able to identify pedestrians cyclists etc. and associated interactions such as eye contact gesturing and the like for purposes of addressing safety risks to occupants of a driverless vehicles as well as drivers of other vehicles pedestrians etc.

Thus what is needed is a solution for facilitating an implementation of autonomous vehicles without the limitations of conventional techniques.

Various embodiments or examples may be implemented in numerous ways including as a system a process an apparatus a user interface or a series of program instructions on a computer readable medium such as a computer readable storage medium or a computer network where the program instructions are sent over optical electronic or wireless communication links. In general operations of disclosed processes may be performed in an arbitrary order unless otherwise provided in the claims.

A detailed description of one or more examples is provided below along with accompanying figures. The detailed description is provided in connection with such examples but is not limited to any particular example. The scope is limited only by the claims and numerous alternatives modifications and equivalents thereof. Numerous specific details are set forth in the following description in order to provide a thorough understanding. These details are provided for the purpose of example and the described techniques may be practiced according to the claims without some or all of these specific details. For clarity technical material that is known in the technical fields related to the examples has not been described in detail to avoid unnecessarily obscuring the description.

According to some examples at least some of autonomous vehicles to are configured as bidirectional autonomous vehicles such as bidirectional autonomous vehicle AV . Bidirectional autonomous vehicle may be configured to travel in either direction principally along but not limited to a longitudinal axis . Accordingly bidirectional autonomous vehicle may be configured to implement active lighting external to the vehicle to alert others e.g. other drivers pedestrians cyclists etc. in the adjacent vicinity and a direction in which bidirectional autonomous vehicle is traveling. For example active sources of light may be implemented as active lights when traveling in a first direction or may be implemented as active lights when traveling in a second direction. Active lights may be implemented using a first subset of one or more colors with optional animation e.g. light patterns of variable intensities of light or color that may change over time . Similarly active lights may be implemented using a second subset of one or more colors and light patterns that may be different than those of active lights . For example active lights may be implemented using white colored lights as headlights whereas active lights may be implemented using red colored lights as taillights. Active lights and or portions thereof may be configured to provide other light related functionalities such as provide turn signal indication functions e.g. using yellow light . According to various examples logic in autonomous vehicle may be configured to adapt active lights and to comply with various safety requirements and traffic regulations or laws for any number of jurisdictions.

In some embodiments bidirectional autonomous vehicle may be configured to have similar structural elements and components in each quad portion such as quad portion . The quad portions are depicted at least in this example as portions of bidirectional autonomous vehicle defined by the intersection of a plane and a plane both of which pass through the vehicle to form two similar halves on each side of planes and . Further bidirectional autonomous vehicle may include an autonomous vehicle controller that includes logic e.g. hardware or software or as combination thereof that is configured to control a predominate number of vehicle functions including driving control e.g. propulsion steering etc. and active sources of light among other functions. Bidirectional autonomous vehicle also includes a number of sensors disposed at various locations on the vehicle other sensors are not shown .

Autonomous vehicle controller may be further configured to determine a local pose e.g. local position of an autonomous vehicle and to detect external objects relative to the vehicle. For example consider that bidirectional autonomous vehicle is traveling in the direction in road network . A localizer not shown of autonomous vehicle controller can determine a local pose at the geographic location . As such the localizer may use acquired sensor data such as sensor data associated with surfaces of buildings and which can be compared against reference data such as map data e.g. 3D map data including reflectance data to determine a local pose. Further a perception engine not shown of autonomous vehicle controller may be configured to detect classify and predict the behavior of external objects such as external object a tree and external object a pedestrian . Classification of such external objects may broadly classify objects as static objects such as external object and dynamic objects such as external object . The localizer and the perception engine as well as other components of the AV controller collaborate to cause autonomous vehicles to drive autonomously.

According to some examples autonomous vehicle service platform is configured to provide teleoperator services should an autonomous vehicle request teleoperation. For example consider that an autonomous vehicle controller in autonomous vehicle detects an object obscuring a path on roadway at point as depicted in inset . If autonomous vehicle controller cannot ascertain a path or trajectory over which vehicle may safely transit with a relatively high degree of certainty then autonomous vehicle controller may transmit request message for teleoperation services. In response a teleoperator computing device may receive instructions from a teleoperator to perform a course of action to successfully and safely negotiate obstacles . Response data then can be transmitted back to autonomous vehicle to cause the vehicle to for example safely cross a set of double lines as it transits along the alternate path . In some examples teleoperator computing device may generate a response identifying geographic areas to exclude from planning a path. In particular rather than provide a path to follow a teleoperator may define areas or locations that the autonomous vehicle must avoid.

In view of the foregoing the structures and or functionalities of autonomous vehicle and or autonomous vehicle controller as well as their components can perform real time or near real time trajectory calculations through autonomous related operations such as localization and perception to enable autonomous vehicles to self drive.

In some cases the bidirectional nature of bidirectional autonomous vehicle provides for a vehicle that has quad portions or any other number of symmetric portions that are similar or are substantially similar to each other. Such symmetry reduces complexity of design and decreases relatively the number of unique components or structures thereby reducing inventory and manufacturing complexities. For example a drivetrain and wheel system may be disposed in any of the quad portions . Further autonomous vehicle controller is configured to invoke teleoperation services to reduce the likelihood that an autonomous vehicle is delayed in transit while resolving an event or issue that may otherwise affect the safety of the occupants. In some cases the visible portion of road network depicts a geo fenced region that may limit or otherwise control the movement of autonomous vehicles to the road network shown in . According to various examples autonomous vehicle and a fleet thereof may be configurable to operate as a level 4 full self driving automation or L4 vehicle that can provide transportation on demand with the convenience and privacy of point to point personal mobility while providing the efficiency of shared vehicles. In some examples autonomous vehicle or any autonomous vehicle described herein may be configured to omit a steering wheel or any other mechanical means of providing manual i.e. human controlled steering for autonomous vehicle . Further autonomous vehicle or any autonomous vehicle described herein may be configured to omit a seat or location reserved within the vehicle for an occupant to engage a steering wheel or any mechanical steering system.

At data representing a subset of candidate trajectories may be received from an autonomous vehicle responsive to the detection of the event. For example a planner of an autonomous vehicle controller may calculate and evaluate large numbers of trajectories e.g. thousands or greater per unit time such as a second. In some embodiments candidate trajectories are a subset of the trajectories that provide for relatively higher confidence levels that an autonomous vehicle may move forward safely in view of the event e.g. using an alternate path provided by a teleoperator . Note that some candidate trajectories may be ranked or associated with higher degrees of confidence than other candidate trajectories. According to some examples subsets of candidate trajectories may originate from any number of sources such as a planner a teleoperator computing device e.g. teleoperators can determine and provide approximate paths etc. and may be combined as a superset of candidate trajectories. At path guidance data may be identified at one or more processors. The path guidance data may be configured to assist a teleoperator in selecting a guided trajectory from one or more of the candidate trajectories. In some instances the path guidance data specifies a value indicative of a confidence level or probability that indicates the degree of certainty that a particular candidate trajectory may reduce or negate the probability that the event may impact operation of an autonomous vehicle. A guided trajectory as a selected candidate trajectory may be received at responsive to input from a teleoperator e.g. a teleoperator may select at least one candidate trajectory as a guided trajectory from a group of differently ranked candidate trajectories . The selection may be made via an operator interface that lists a number of candidate trajectories for example in order from highest confidence levels to lowest confidence levels. At the selection of a candidate trajectory as a guided trajectory may be transmitted to the vehicle which in turn implements the guided trajectory for resolving the condition by causing the vehicle to perform a teleoperator specified maneuver. As such the autonomous vehicle may transition from a non normative operational state.

According to some embodiments portions of the autonomous vehicle AV control logic may be implemented using clusters of graphics processing units GPUs implementing a framework and programming model suitable for programming the clusters of GPUs. For example a compute unified device architecture CUDA compatible programming language and application programming interface API model may be used to program the GPUs. CUDA is produced and maintained by NVIDIA of Santa Clara Calif. Note that other programming languages may be implemented such as OpenCL or any other parallel programming language.

According to some embodiments autonomous vehicle control logic may be implemented in hardware and or software as autonomous vehicle controller which is shown to include a motion controller a planner a perception engine and a localizer . As shown autonomous vehicle controller is configured to receive camera data Lidar data and radar data or any other range sensing or localization data including sonar data or the like. Autonomous vehicle controller is also configured to receive positioning data such as GPS data IMU data and other position sensing data e.g. wheel related data such as steering angles angular velocity etc. . Further autonomous vehicle controller may receive any other sensor data as well as reference data . In some cases reference data includes map data e.g. 3D map data 2D map data 4D map data e.g. including Epoch Determination and route data e.g. road network data including but not limited to RNDF data or similar data MDF data or similar data etc.

Localizer is configured to receive sensor data from one or more sources such as GPS data wheel data IMU data Lidar data camera data radar data and the like as well as reference data e.g. 3D map data and route data . Localizer integrates e.g. fuses the sensor data and analyzes the data by comparing sensor data to map data to determine a local pose or position of bidirectional autonomous vehicle . According to some examples localizer may generate or update the pose or position of any autonomous vehicle in real time or near real time. Note that localizer and its functionality need not be limited to bi directional vehicles and can be implemented in any vehicle of any type. Therefore localizer as well as other components of AV controller may be implemented in a unidirectional vehicle or any non autonomous vehicle. According to some embodiments data describing a local pose may include one or more of an x coordinate a y coordinate a z coordinate or any coordinate of any coordinate system including polar or cylindrical coordinate systems or the like a yaw value a roll value a pitch value e.g. an angle value a rate e.g. velocity altitude and the like.

Perception engine is configured to receive sensor data from one or more sources such as Lidar data camera data radar data and the like as well as local pose data. Perception engine may be configured to determine locations of external objects based on sensor data and other data. External objects for instance may be objects that are not part of a drivable surface. For example perception engine may be able to detect and classify external objects as pedestrians bicyclists dogs other vehicles etc. e.g. perception engine is configured to classify the objects in accordance with a type of classification which may be associated with semantic information including a label . Based on the classification of these external objects the external objects may be labeled as dynamic objects or static objects. For example an external object classified as a tree may be labeled as a static object while an external object classified as a pedestrian may be labeled as a dynamic object. External objects labeled as static may or may not be described in map data. Examples of external objects likely to be labeled as static include traffic cones cement barriers arranged across a roadway lane closure signs newly placed mailboxes or trash cans adjacent a roadway etc. Examples of external objects likely to be labeled as dynamic include bicyclists pedestrians animals other vehicles etc. If the external object is labeled as dynamic and further data about the external object may indicate a typical level of activity and velocity as well as behavior patterns associated with the classification type. Further data about the external object may be generated by tracking the external object. As such the classification type can be used to predict or otherwise determine the likelihood that an external object may for example interfere with an autonomous vehicle traveling along a planned path. For example an external object that is classified as a pedestrian may be associated with some maximum speed as well as an average speed e.g. based on tracking data . The velocity of the pedestrian relative to the velocity of an autonomous vehicle can be used to determine if a collision is likely. Further perception engine may determine a level of uncertainty associated with a current and future state of objects. In some examples the level of uncertainty may be expressed as an estimated value or probability .

Planner is configured to receive perception data from perception engine and may also include localizer data from localizer . According to some examples the perception data may include an obstacle map specifying static and dynamic objects located in the vicinity of an autonomous vehicle whereas the localizer data may include a local pose or position. In operation planner generates numerous trajectories and evaluates the trajectories based on at least the location of the autonomous vehicle against relative locations of external dynamic and static objects. Planner selects an optimal trajectory based on a variety of criteria over which to direct the autonomous vehicle in way that provides for collision free travel. In some examples planner may be configured to calculate the trajectories as probabilistically determined trajectories. Further planner may transmit steering and propulsion commands as well as decelerating or braking commands to motion controller . Motion controller subsequently may convert any of the commands such as a steering command a throttle or propulsion command and a braking command into control signals e.g. for application to actuators or other mechanical interfaces to implement changes in steering or wheel angles and or velocity .

Localizer is configured to localize autonomous vehicle i.e. determine a local pose relative to reference data which may include map data route data e.g. road network data such as RNDF like data and the like. In some cases localizer is configured to identify for example a point in space that may represent a location of autonomous vehicle relative to features of a representation of an environment. Localizer is shown to include a sensor data integrator which may be configured to integrate multiple subsets of sensor data e.g. of different sensor modalities to reduce uncertainties related to each individual type of sensor. According to some examples sensor data integrator is configured to fuse sensor data e.g. Lidar data camera data radar data etc. to form integrated sensor data values for determining a local pose. According to some examples localizer retrieves reference data originating from a reference data repository which includes a map data repository for storing 2D map data 3D map data 4D map data and the like. Localizer may be configured to identify at least a subset of features in the environment to match against map data to identify or otherwise confirm a pose of autonomous vehicle . According to some examples localizer may be configured to identify any amount of features in an environment such that a set of features can one or more features or all features. In a specific example any amount of Lidar data e.g. most or substantially all Lidar data may be compared against data representing a map for purposes of localization. Generally non matched objects resulting from the comparison of the environment features and map data may be a dynamic object such as a vehicle bicyclist pedestrian etc. Note that detection of dynamic objects including obstacles may be performed with or without map data. In particular dynamic objects may be detected and tracked independently of map data i.e. in the absence of map data . In some instances 2D map data and 3D map data may be viewed as global map data or map data that has been validated at a point in time by autonomous vehicle service platform . As map data in map data repository may be updated and or validated periodically a deviation may exist between the map data and an actual environment in which the autonomous vehicle is positioned. Therefore localizer may retrieve locally derived map data generated by local map generator to enhance localization. Local map generator is configured to generate local map data in real time or near real time. Optionally local map generator may receive static and dynamic object map data to enhance the accuracy of locally generated maps by for example disregarding dynamic objects in localization. According to at least some embodiments local map generator may be integrated with or formed as part of localizer . In at least one case local map generator either individually or in collaboration with localizer may be configured to generate map and or reference data based on simultaneous localization and mapping SLAM or the like. Note that localizer may implement a hybrid approach to using map data whereby logic in localizer may be configured to select various amounts of map data from either map data repository or local map data from local map generator depending on the degrees of reliability of each source of map data. Therefore localizer may still use out of date map data in view of locally generated map data.

Perception engine is configured to for example assist planner in planning routes and generating trajectories by identifying objects of interest in a surrounding environment in which autonomous vehicle is transiting. Further probabilities may be associated with each of the object of interest whereby a probability may represent a likelihood that an object of interest may be a threat to safe travel e.g. a fast moving motorcycle may require enhanced tracking rather than a person sitting at a bus stop bench while reading a newspaper . As shown perception engine includes an object detector and an object classifier . Object detector is configured to distinguish objects relative to other features in the environment and object classifier may be configured to classify objects as either dynamic or static objects and track the locations of the dynamic and the static objects relative to autonomous vehicle for planning purposes. Further perception engine may be configured to assign an identifier to a static or dynamic object that specifies whether the object is or has the potential to become an obstacle that may impact path planning at planner . Although not shown in note that perception engine may also perform other perception related functions such as segmentation and tracking examples of which are described below.

Planner is configured to generate a number of candidate trajectories for accomplishing a goal to reaching a destination via a number of paths or routes that are available. Trajectory evaluator is configured to evaluate candidate trajectories and identify which subsets of candidate trajectories are associated with higher degrees of confidence levels of providing collision free paths to the destination. As such trajectory evaluator can select an optimal trajectory based on relevant criteria for causing commands to generate control signals for vehicle components e.g. actuators or other mechanisms . Note that the relevant criteria may include any number of factors that define optimal trajectories the selection of which need not be limited to reducing collisions. For example the selection of trajectories may be made to optimize user experience e.g. user comfort as well as collision free trajectories that comply with traffic regulations and laws. User experience may be optimized by moderating accelerations in various linear and angular directions e.g. to reduce jerking like travel or other unpleasant motion . In some cases at least a portion of the relevant criteria can specify which of the other criteria to override or supersede while maintain optimized collision free travel. For example legal restrictions may be temporarily lifted or deemphasized when generating trajectories in limited situations e.g. crossing double yellow lines to go around a cyclist or travelling at higher speeds than the posted speed limit to match traffic flows . As such the control signals are configured to cause propulsion and directional changes at the drivetrain and or wheels. In this example motion controller is configured to transform commands into control signals e.g. velocity wheel angles etc. for controlling the mobility of autonomous vehicle . In the event that trajectory evaluator has insufficient information to ensure a confidence level high enough to provide collision free optimized travel planner can generate a request to teleoperator for teleoperator support.

Autonomous vehicle service platform includes teleoperator e.g. a teleoperator computing device reference data repository a map updater a vehicle data controller a calibrator and an off line object classifier . Note that each element of autonomous vehicle service platform may be independently located or distributed and in communication with other elements in autonomous vehicle service platform . Further element of autonomous vehicle service platform may independently communicate with the autonomous vehicle via the communication layer . Map updater is configured to receive map data e.g. from local map generator sensors or any other component of autonomous vehicle controller and is further configured to detect deviations for example of map data in map data repository from a locally generated map. Vehicle data controller can cause map updater to update reference data within repository and facilitate updates to 2D 3D and or 4D map data. In some cases vehicle data controller can control the rate at which local map data is received into autonomous vehicle service platform as well as the frequency at which map updater performs updating of the map data.

Calibrator is configured to perform calibration of various sensors of the same or different types. Calibrator may be configured to determine the relative poses of the sensors e.g. in Cartesian space x y z and orientations of the sensors e.g. roll pitch and yaw . The pose and orientation of a sensor such a camera Lidar sensor radar sensor etc. may be calibrated relative to other sensors as well as globally relative to the vehicle s reference frame. Off line self calibration can also calibrate or estimate other parameters such as vehicle inertial tensor wheel base wheel radius or surface road friction. Calibration can also be done online to detect parameter change according to some examples. Note too that calibration by calibrator may include intrinsic parameters of the sensors e.g. optical distortion beam angles etc. and extrinsic parameters. In some cases calibrator may be performed by maximizing a correlation between depth discontinuities in 3D laser data and edges of image data as an example. Off line object classification is configured to receive data such as sensor data from sensors or any other component of autonomous vehicle controller . According to some embodiments an off line classification pipeline of off line object classification may be configured to pre collect and annotate objects e.g. manually by a human and or automatically using an offline labeling algorithm and may further be configured to train an online classifier e.g. object classifier which can provide real time classification of object types during online autonomous operation.

Teleoperator manager is configured to manage a number of teleoperator computing devices with which teleoperators provide input. Simulator is configured to simulate operation of one or more autonomous vehicles as well as the interactions between teleoperator manager and an autonomous vehicle . Simulator may also simulate operation of a number of sensors including the introduction of simulated noise disposed in autonomous vehicle . Further an environment such as a city may be simulated such that a simulated autonomous vehicle can be introduced to the synthetic environment whereby simulated sensors may receive simulated sensor data such as simulated laser returns. Simulator may provide other functions as well including validating software updates and or map data. Policy manager is configured to maintain data representing policies or rules by which an autonomous vehicle ought to behave in view of a variety of conditions or events that an autonomous vehicle encounters while traveling in a network of roadways. In some cases updated policies and or rules may be simulated in simulator to confirm safe operation of a fleet of autonomous vehicles in view of changes to a policy. Some of the above described elements of autonomous vehicle service platform are further described hereinafter.

Communication channels are configured to provide networked communication links among a fleet of autonomous vehicles and autonomous vehicle service platform . For example communication channel includes a number of different types of networks and with corresponding subnetworks e.g. to to ensure a certain level of redundancy for operating an autonomous vehicle service reliably. For example the different types of networks in communication channels may include different cellular network providers different types of data networks etc. to ensure sufficient bandwidth in the event of reduced or lost communications due to outages in one or more networks and .

An example of a data exchange for facilitating teleoperations via the communications protocol is described as follows. Consider that obstacle data is generated by a perception system of an autonomous vehicle controller. Further planner options data is generated by a planner to notify a teleoperator of a subset of candidate trajectories and position data is generated by the localizer. Obstacle data planner options data and position data are transmitted to a messaging service bridge which in accordance with message service configuration data generates telemetry data and query data both of which are transmitted via data centric messaging bus into teleoperator application as telemetry data and query data . Teleoperator API receives telemetry data and inquiry data which in turn are processed in view of Route data and message service configuration data . The resultant data is subsequently presented to a teleoperator via teleoperator computing device and or a collaborative display e.g. a dashboard display visible to a group of collaborating teleoperators . Teleoperator reviews the candidate trajectory options that are presented on the display of teleoperator computing device and selects a guided trajectory which generates command data and query response data both of which are passed through teleoperator API as query response data and command data . In turn query response data and command data are transmitted via data centric messaging bus into autonomous vehicle application as query response data and command data . Messaging service bridge receives query response data and command data and generates teleoperator command data which is configured to generate a teleoperator selected trajectory for implementation by a planner Note that the above described messaging processes are not intended to be limiting and other messaging protocols may be implemented as well.

Trajectory evaluator includes a state and event manager which in turn may include a confidence level generator . Trajectory evaluator further includes a guided trajectory generator and a trajectory generator . Further planner is configured to receive policy data perception engine data and localizer data .

Policy data may include criteria with which planner uses to determine a path that has a sufficient confidence level with which to generate trajectories according to some examples. Examples of policy data include policies that specify that trajectory generation is bounded by stand off distances to external objects e.g. maintaining a safety buffer of 3 feet from a cyclist as possible or policies that require that trajectories must not cross a center double yellow line or policies that require trajectories to be limited to a single lane in a 4 lane roadway e.g. based on past events such as typically congregating at a lane closest to a bus stop and any other similar criteria specified by policies. Perception engine data includes maps of locations of static objects and dynamic objects of interest and localizer data includes at least a local pose or position.

State and event manager may be configured to probabilistically determine a state of operation for an autonomous vehicle. For example a first state of operation i.e. normative operation may describe a situation in which trajectories are collision free whereas a second state of operation i.e. non normative operation may describe another situation in which the confidence level associated with possible trajectories are insufficient to guarantee collision free travel. According to some examples state and event manager is configured to use perception data to determine a state of autonomous vehicle that is either normative or non normative. Confidence level generator may be configured to analyze perception data to determine a state for the autonomous vehicle. For example confidence level generator may use semantic information associated with static and dynamic objects as well as associated probabilistic estimations to enhance a degree of certainty that planner is determining safe course of action. For example planner may use perception engine data that specifies a probability that an object is either a person or not a person to determine whether planner is operating safely e.g. planner may receive a degree of certainty that an object has a 98 probability of being a person and a probability of 2 that the object is not a person .

Upon determining a confidence level e.g. based on statistics and probabilistic determinations is below a threshold required for predicted safe operation a relatively low confidence level e.g. single probability score may trigger planner to transmit a request for teleoperation support to autonomous vehicle service platform . In some cases telemetry data and a set of candidate trajectories may accompany the request. Examples of telemetry data include sensor data localization data perception data and the like. A teleoperator may transmit via teleoperator computing device a selected trajectory to guided trajectory generator . As such selected trajectory is a trajectory formed with guidance from a teleoperator. Upon confirming there is no change in the state e.g. a non normative state is pending guided trajectory generator passes data to trajectory generator which in turn causes trajectory tracker as a trajectory tracking controller to use the teleop specified trajectory for generating control signals e.g. steering angles velocity etc. . Note that planner may trigger transmission of a request for teleoperation support prior to a state transitioning to a non normative state. In particular an autonomous vehicle controller and or its components can predict that a distant obstacle may be problematic and preemptively cause planner to invoke teleoperations prior to the autonomous vehicle reaching the obstacle. Otherwise the autonomous vehicle may cause a delay by transitioning to a safe state upon encountering the obstacle or scenario e.g. pulling over and off the roadway . In another example teleoperations may be automatically invoked prior to an autonomous vehicle approaching a particular location that is known to be difficult to navigate. This determination may optionally take into consideration other factors including the time of day the position of the sun if such situation is likely to cause a disturbance to the reliability of sensor readings and traffic or accident data derived from a variety of sources.

In another state of operation e.g. a normative state static map data current and predicted object state data local pose data and plan data e.g. global plan data are received into trajectory calculator which is configured to calculate e.g. iteratively trajectories to determine an optimal one or more paths. Next at least one path is selected and is transmitted as selected path data . According to some embodiments trajectory calculator is configured to implement re planning of trajectories as an example. Nominal driving trajectory generator is configured to generate trajectories in a refined approach such as by generating trajectories based on receding horizon control techniques. Nominal driving trajectory generator subsequently may transmit nominal driving trajectory path data to for example a trajectory tracker or a vehicle controller to implement physical changes in steering acceleration and other components.

Teleoperator action recommendation controller includes logic configured to receive and or control a teleoperation service request via autonomous vehicle AV planner data which can include requests for teleoperator assistance as well as telemetry data and other data. As such planner data may include recommended candidate trajectories or paths from which a teleoperator via teleoperator computing device may select. According to some examples teleoperator action recommendation controller may be configured to access other sources of recommended candidate trajectories from which to select an optimum trajectory. For example candidate trajectories contained in autonomous vehicle planner data may in parallel be introduced into simulator which is configured to simulate an event or condition being experienced by an autonomous vehicle requesting teleoperator assistance. Simulator can access map data and other data necessary for performing a simulation on the set of candidate trajectories whereby simulator need not exhaustively reiterate simulations to confirm sufficiency. Rather simulator may provide either confirm the appropriateness of the candidate trajectories or may otherwise alert a teleoperator to be cautious in their selection.

Teleoperator interaction capture analyzer may be configured to capture numerous amounts of teleoperator transactions or interactions for storage in repository which for example may accumulate data relating to a number of teleoperator transactions for analysis and generation of policies at least in some cases. According to some embodiments repository may also be configured to store policy data for access by policy manager . Further teleoperator interaction capture analyzer may apply machine learning techniques to empirically determine how best to respond to events or conditions causing requests for teleoperation assistance. In some cases policy manager may be configured to update a particular policy or generate a new policy responsive to analyzing the large set of teleoperator interactions e.g. subsequent to applying machine learning techniques . Policy manager manages policies that may be viewed as rules or guidelines with which an autonomous vehicle controller and its components operate under to comply with autonomous operations of a vehicle. In some cases a modified or updated policy may be applied to simulator to confirm the efficacy of permanently releasing or implementing such policy changes.

Simulator interface controller is configured to provide an interface between simulator and teleoperator computing devices . For example consider that sensor data from a fleet of autonomous vehicles is applied to reference data updater via autonomous AV fleet data whereby reference data updater is configured to generate updated map and route data . In some implementations updated map and route data may be preliminarily released as an update to data in map data repositories and or as an update to data in route data repository . In this case such data may be tagged as being a beta version in which a lower threshold for requesting teleoperator service may be implemented when for example a map tile including preliminarily updated information is used by an autonomous vehicle. Further updated map and route data may be introduced to simulator for validating the updated map data. Upon full release e.g. at the close of beta testing the previously lowered threshold for requesting a teleoperator service related to map tiles is canceled. User interface graphics controller provides rich graphics to teleoperators whereby a fleet of autonomous vehicles may be simulated within simulator and may be accessed via teleoperator computing device as if the simulated fleet of autonomous vehicles were real.

Fleet optimization manager is shown to include a hybrid autonomous vehicle non autonomous vehicle processor which in turn includes an AV non AV optimization calculator and a non AV selector . According to some examples hybrid autonomous vehicle non autonomous vehicle processor is configured to manage a hybrid fleet of autonomous vehicles and human driven vehicles e.g. as independent contractors . As such autonomous vehicle service may employ non autonomous vehicles to meet excess demand or in areas such as non AV service region that may be beyond a geo fence or in areas of poor communication coverage. AV non AV optimization calculator is configured to optimize usage of the fleet of autonomous and to invite non AV drivers into the transportation service e.g. with minimal or no detriment to the autonomous vehicle service . Non AV selector includes logic for selecting a number of non AV drivers to assist based on calculations derived by AV non AV optimization calculator .

Communication event detector includes a policy download manager and communications configured COMM configured AV dispatcher . Policy download manager is configured to provide autonomous vehicles an updated policy in view of reduced communications region whereby the updated policy may specify routes to quickly exit region if an autonomous vehicle enters that region. For example autonomous vehicle may receive an updated policy moments before driving into region . Upon loss of communications autonomous vehicle implements the updated policy and selects route to drive out of region quickly. COMM configured AV dispatcher may be configured to identify points at which to park autonomous vehicles that are configured as relays to establishing a peer to peer network over region . As such COMM configured AV dispatcher is configured to dispatch autonomous vehicles without passengers to park at locations for the purposes of operating as communication towers in a peer to peer ad hoc network.

Further to diagram localization based data and relative localization based data may be fed into data integrator and localization data integrator respectively. Data integrator and localization data integrator may be configured to fuse corresponding data whereby localization based data may be fused at data integrator prior to being fused with relative localization based data at localization data integrator . According to some embodiments data integrator is formed as part of localization data integrator or is absent. Regardless a localization based data and relative localization based data can be both fed into localization data integrator for purposes of fusing data to generate local position data . Localization based data may include unary constrained data and uncertainty values from projection processor as well as binary constrained data and uncertainty values from odometry processor and integrator processor . Relative localization based data may include unary constrained data and uncertainty values from localization processor and visual registration processor and optionally from radar return processor . According to some embodiments localization data integrator may implement non linear smoothing functionality such as a Kalman filter e.g. a gated Kalman filter a relative bundle adjuster pose graph relaxation particle filter histogram filter or the like.

Referring back to diagram also includes classifier which may include a track classification engine for generating static obstacle data and dynamic obstacle data both of which may be transmitted to the planner for path planning purposes. In at least one example track classification engine is configured to determine whether an obstacle is static or dynamic as well as another classification type for the object e.g. whether the object is a vehicle pedestrian tree cyclist dog cat paper bag etc. . Static obstacle data may be formed as part of an obstacle map e.g. a 2D occupancy map and dynamic obstacle data may be formed to include bounding boxes with data indicative of velocity and classification type. Dynamic obstacle data at least in some cases includes 2D dynamic obstacle map data.

Simulator may be configured to generate a simulated autonomous vehicle controller which includes synthetic adaptations of a perception engine a localizer a motion controller and a planner each of which may have functionalities described herein within simulated environment . Simulator may also generate simulated interfaces I F to simulate the data exchanges with different sensors modalities and different sensor data formats. As such simulated interface may simulate a software interface for packetized data from for example a simulated Lidar sensor . Further simulator may also be configured to generate a simulated autonomous vehicle that implements simulated AV controller . Simulated autonomous vehicle includes simulated Lidar sensors simulated camera or image sensors and simulated radar sensors . In the example shown simulated Lidar sensor may be configured to generate a simulated laser consistent with ray trace which causes generation of simulated sensor return . Note that simulator may simulate the addition of noise or other environmental effects on sensor data e.g. added diffusion or reflections that affect simulated sensor return etc. . Further yet simulator may be configured to simulate a variety of sensor defects including sensor failure sensor miscalibration intermittent data outages and the like.

Simulator includes a physics processor for simulating the mechanical static dynamic and kinematic aspects of an autonomous vehicle for use in simulating behavior of simulated autonomous vehicle . For example physics processor includes a content mechanics module for simulating contact mechanics a collision detection module for simulating the interaction between simulated bodies and a multibody dynamics module to simulate the interaction between simulated mechanical interactions.

Simulator also includes a simulator controller configured to control the simulation to adapt the functionalities of any synthetically generated element of simulated environment to determine cause effect relationship among other things. Simulator includes a simulator evaluator to evaluate the performance synthetically generated element of simulated environment . For example simulator evaluator may analyze simulated vehicle commands e.g. simulated steering angles and simulated velocities to determine whether such commands are an appropriate response to the simulated activities within simulated environment . Further simulator evaluator may evaluate interactions of a teleoperator with the simulated autonomous vehicle via teleoperator computing device . Simulator evaluator may evaluate the effects of updated reference data including updated map tiles and route data which may be added to guide the responses of simulated autonomous vehicle . Simulator evaluator may also evaluate the responses of simulator AV controller when policy data is updated deleted or added. The above description of simulator is not intended to be limiting. As such simulator is configured to perform a variety of different simulations of an autonomous vehicle relative to a simulated environment which include both static and dynamic features. For example simulator may be used to validate changes in software versions to ensure reliability. Simulator may also be used to determine vehicle dynamics properties and for calibration purposes. Further simulator may be used to explore the space of applicable controls and resulting trajectories so as to effect learning by self simulation.

Further to the example shown autonomous vehicle application may also include a user identification controller that may be configured to detect that user is in a geographic region or vicinity near autonomous vehicle as the vehicle approaches. In some situations user may not readily perceive or identify autonomous vehicle as it approaches for use by user e.g. due to various other vehicles including trucks cars taxis and other obstructions that are typical in city environments . In one example autonomous vehicle may establish a wireless communication link e.g. via a radio frequency RF signal such as WiFi or Bluetooth including BLE or the like for communicating and or determining a spatial location of user relative to autonomous vehicle e.g. using relative direction of RF signal and signal strength . In some cases autonomous vehicle may detect an approximate geographic location of user using for example GPS data or the like. A GPS receiver not shown of mobile computing device may be configured to provide GPS data to autonomous vehicle service application . Thus user identification controller may provide GPS data via link to autonomous vehicle service platform which in turn may provide that location to autonomous vehicle via link . Subsequently autonomous vehicle may determine a relative distance and or direction of user by comparing the user s GPS data to the vehicle s GPS derived location.

Autonomous vehicle may also include additional logic to identify the presence of user such that logic configured to perform face detection algorithms to detect either user generally or to specifically identify the identity e.g. name phone number etc. of user based on the user s unique facial characteristics. Further autonomous vehicle may include logic to detect codes for identifying user . Examples of such codes include specialized visual codes such as QR codes color codes etc. specialized audio codes such as voice activated or recognized codes etc. and the like. In some cases a code may be an encoded security key that may be transmitted digitally via link to autonomous vehicle to ensure secure ingress and or egress. Further one or more of the above identified techniques for identifying user may be used as a secured means to grant ingress and egress privileges to user so as to prevent others from entering autonomous vehicle e.g. to ensure third party persons do not enter an unoccupied autonomous vehicle prior to arriving at user . According to various examples any other means for identifying user and providing secured ingress and egress may also be implemented in one or more of autonomous vehicle service application autonomous vehicle service platform and autonomous vehicle .

To assist user in identifying the arrival of its requested transportation autonomous vehicle may be configured to notify or otherwise alert user to the presence of autonomous vehicle as it approaches user . For example autonomous vehicle may activate one or more light emitting devices e.g. LEDs in accordance with specific light patterns. In particular certain light patterns are created so that user may readily perceive that autonomous vehicle is reserved to service the transportation needs of user . As an example autonomous vehicle may generate light patterns that may be perceived by user as a wink or other animation of its exterior and interior lights in such a visual and temporal way. The patterns of light may be generated with or without patterns of sound to identify to user that this vehicle is the one that they booked.

According to some embodiments autonomous vehicle user controller may implement a software application that is configured to control various functions of an autonomous vehicle. Further an application may be configured to redirect or reroute the autonomous vehicle during transit to its initial destination. Further autonomous vehicle user controller may be configured to cause on board logic to modify interior lighting of autonomous vehicle to effect for example mood lighting. Controller may also control a source of audio e.g. an external source such as Spotify or audio stored locally on the mobile computing device select a type of ride e.g. modify desired acceleration and braking aggressiveness modify active suspension parameters to select a set of road handling characteristics to implement aggressive driving characteristics including vibrations or to select soft ride qualities with vibrations dampened for comfort and the like. For example mobile computing device may be configured to control HVAC functions as well like ventilation and temperature.

Note that various structures and or functionalities of are applicable to and as such some elements in those figures may be discussed in the context of .

In some cases computing platform can be disposed in any device such as a computing device which may be disposed in one or more computing devices in an autonomous vehicle service platform an autonomous vehicle and or mobile computing device

Computing platform includes a bus or other communication mechanism for communicating information which interconnects subsystems and devices such as processor system memory e.g. RAM etc. storage device e.g. ROM etc. an in memory cache which may be implemented in RAM or other portions of computing platform a communication interface e.g. an Ethernet or wireless controller a Bluetooth controller NFC logic etc. to facilitate communications via a port on communication link to communicate for example with a computing device including mobile computing and or communication devices with processors. Processor can be implemented with one or more graphics processing units GPUs with one or more central processing units CPUs such as those manufactured by Intel Corporation or one or more virtual processors as well as any combination of CPUs and virtual processors. Computing platform exchanges data representing inputs and outputs via input and output devices including but not limited to keyboards mice audio inputs e.g. speech to text devices user interfaces displays monitors cursors touch sensitive displays LCD or LED displays and other I O related devices.

According to some examples computing platform performs specific operations by processor executing one or more sequences of one or more instructions stored in system memory and computing platform can be implemented in a client server arrangement peer to peer arrangement or as any mobile computing device including smart phones and the like. Such instructions or data may be read into system memory from another computer readable medium such as storage device . In some examples hard wired circuitry may be used in place of or in combination with software instructions for implementation. Instructions may be embedded in software or firmware. The term computer readable medium refers to any tangible medium that participates in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media and volatile media. Non volatile media includes for example optical or magnetic disks and the like. Volatile media includes dynamic memory such as system memory .

Common forms of computer readable media includes for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge or any other medium from which a computer can read. Instructions may further be transmitted or received using a transmission medium. The term transmission medium may include any tangible or intangible medium that is capable of storing encoding or carrying instructions for execution by the machine and includes digital or analog communications signals or other intangible medium to facilitate communication of such instructions. Transmission media includes coaxial cables copper wire and fiber optics including wires that comprise bus for transmitting a computer data signal.

In some examples execution of the sequences of instructions may be performed by computing platform . According to some examples computing platform can be coupled by communication link e.g. a wired network such as LAN PSTN or any wireless network including WiFi of various standards and protocols Bluetooth NFC Zig Bee etc. to any other processor to perform the sequence of instructions in coordination with or asynchronous to one another. Computing platform may transmit and receive messages data and instructions including program code e.g. application code through communication link and communication interface . Received program code may be executed by processor as it is received and or stored in memory or other non volatile storage for later execution.

In the example shown system memory can include various modules that include executable instructions to implement functionalities described herein. System memory may include an operating system O S as well as an application and or logic module s . In the example shown in system memory includes an autonomous vehicle AV controller module and or its components e.g. a perception engine module a localization module a planner module and or a motion controller module any of which or one or more portions of which can be configured to facilitate an autonomous vehicle service by implementing one or more functions described herein.

Referring to the example shown in system memory includes an autonomous vehicle service platform module and or its components e.g. a teleoperator manager a simulator etc. any of which or one or more portions of which can be configured to facilitate managing an autonomous vehicle service by implementing one or more functions described herein.

Referring to the example shown in system memory includes an autonomous vehicle AV module and or its components for use for example in a mobile computing device. One or more portions of module can be configured to facilitate delivery of an autonomous vehicle service by implementing one or more functions described herein.

Referring back to the structures and or functions of any of the above described features can be implemented in software hardware firmware circuitry or a combination thereof. Note that the structures and constituent elements above as well as their functionality may be aggregated with one or more other structures or elements. Alternatively the elements and their functionality may be subdivided into constituent sub elements if any. As software the above described techniques may be implemented using various types of programming or formatting languages frameworks syntax applications protocols objects or techniques. As hardware and or firmware the above described techniques may be implemented using various types of programming or integrated circuit design languages including hardware description languages such as any register transfer language RTL configured to design field programmable gate arrays FPGAs application specific integrated circuits ASICs or any other type of integrated circuit. According to some embodiments the term module can refer for example to an algorithm or a portion thereof and or logic implemented in either hardware circuitry or software or a combination thereof. These can be varied and are not limited to the examples or descriptions provided.

In some embodiments module of module of and module of or one or more of their components or any process or device described herein can be in communication e.g. wired or wirelessly with a mobile device such as a mobile phone or computing device or can be disposed therein.

In some cases a mobile device or any networked computing device not shown in communication with one or more modules module of module of and module of or one or more of its components or any process or device described herein can provide at least some of the structures and or functions of any of the features described herein. As depicted in the above described figures the structures and or functions of any of the above described features can be implemented in software hardware firmware circuitry or any combination thereof. Note that the structures and constituent elements above as well as their functionality may be aggregated or combined with one or more other structures or elements. Alternatively the elements and their functionality may be subdivided into constituent sub elements if any. As software at least some of the above described techniques may be implemented using various types of programming or formatting languages frameworks syntax applications protocols objects or techniques. For example at least one of the elements depicted in any of the figures can represent one or more algorithms. Or at least one of the elements can represent a portion of logic including a portion of hardware configured to provide constituent structures and or functionalities.

For example module of module of and module of or one or more of its components or any process or device described herein can be implemented in one or more computing devices i.e. any mobile computing device such as a wearable device an audio device such as headphones or a headset or mobile phone whether worn or carried that include one or more processors configured to execute one or more algorithms in memory. Thus at least some of the elements in the above described figures can represent one or more algorithms. Or at least one of the elements can represent a portion of logic including a portion of hardware configured to provide constituent structures and or functionalities. These can be varied and are not limited to the examples or descriptions provided.

As hardware and or firmware the above described structures and techniques can be implemented using various types of programming or integrated circuit design languages including hardware description languages such as any register transfer language RTL configured to design field programmable gate arrays FPGAs application specific integrated circuits ASICs multi chip modules or any other type of integrated circuit.

For example module of module of and module of or one or more of its components or any process or device described herein can be implemented in one or more computing devices that include one or more circuits. Thus at least one of the elements in the above described figures can represent one or more components of hardware. Or at least one of the elements can represent a portion of logic including a portion of a circuit configured to provide constituent structures and or functionalities.

According to some embodiments the term circuit can refer for example to any system including a number of components through which current flows to perform one or more functions the components including discrete and complex components. Examples of discrete components include transistors resistors capacitors inductors diodes and the like and examples of complex components include memory processors analog circuits digital circuits and the like including field programmable gate arrays FPGAs application specific integrated circuits ASICs . Therefore a circuit can include a system of electronic components and logic components e.g. logic configured to execute instructions such that a group of executable instructions of an algorithm for example and thus is a component of a circuit . According to some embodiments the term module can refer for example to an algorithm or a portion thereof and or logic implemented in either hardware circuitry or software or a combination thereof i.e. a module can be implemented as a circuit . In some embodiments algorithms and or the memory in which the algorithms are stored are components of a circuit. Thus the term circuit can also refer for example to a system of components including algorithms. These can be varied and are not limited to the examples or descriptions provided.

In view of the foregoing the structures and or functionalities of mapping engine as well as its components can facilitate the generation of self healing maps and map data by for example detecting variations in portions of map data over time and generating updated maps i.e. updated map data that include the variations or changes to the physical environment in which autonomous vehicle travels. In some implementations mapping engine may generate an adaptive three dimensional model of a cityscape adjacent to networks of paths and roadways over which a fleet of autonomous vehicles travel. A 3D model of a portion of the cityscape can be derived by identifying data that represent surfaces and other surface attributes such as shape size texture color etc. of the surfaces that constitute the fa ade or exterior surfaces of objects such as buildings including commercial signage trees guard rails barriers street lamps traffic signs and signals and any other physical feature that may be detected by sensors and . Thus mapping engine may be configured to detect an object or the absence of the object associated with a portion of map data as well as changes in the object e.g. changes in color size etc. and may be further configured to incorporate changes to an object into map data to adaptively form e.g. automatically an updated portion of the map data. Therefore an updated portion of map data may be stored in map repository so as to enhance among other things the accuracy of localization functions for autonomous vehicle as well as other autonomous vehicle controller functions including planning and the like .

In some cases map data generated by mapping engine may be used in combination with locally generated map data not shown as generated by a local map generator not shown in autonomous vehicle . For example an autonomous vehicle controller not shown may detect that one or more portions of map data in map repository varies from one or more portions of locally generated map data. Logic in the autonomous vehicle controller can analyze the differences in map data e.g. variation data to identify a change in the physical environment e.g. the addition removal or change in a static object . In a number of examples the term variation data may refer to the differences between remotely generated and locally generated map data. Based on the changed portion of an environment the autonomous vehicle controller may implement varying proportional amounts of map data in map repository and locally generated map data to optimize localization. For example an autonomous vehicle controller may generate hybrid map data composed of both remotely generated map data and locally generated map data to optimize the determination of the location or local pose of autonomous vehicle . Further an autonomous vehicle controller upon detecting variation data may cause transmission at various bandwidths or data rates of varying amounts of sensor based data or other data to autonomous vehicle service platform . For example autonomous vehicle service platform may receive different types of data at different data rates based on for instance the criticality of receiving guidance from a teleoperator. As another example subsets of sensor data and may be transmitted e.g. at appropriate data rates to for example modify map data to form various degrees of updated map data in real time or near real time and to further perform one or more of the following 1 evaluate and characterize differences in map data 2 propagate updated portions of map data to other autonomous vehicles in the fleet 3 generate a notification responsive to detecting map data differences to a tele operator computing device 4 generate a depiction of the environment and the changed portion thereof as sensed by various sensor devices and to display at any sufficient resolution in a user interface of a teleoperator computing device. Note that the above described examples are not limiting and any other map related functionality for managing a fleet of autonomous vehicles may be implemented using mapping engine in view of detected changes in physical environments relative to map data.

According to some examples sensor type sensor type and sensor type may include laser based sensors image based sensors and radar based sensors respectively. As such sensors and may include Lidars cameras and radar devices respectively. As shown in diagram multiple sensor devices e.g. Lidars each generate different laser based sensed data at a geographic location. For example each Lidar may be disposed at different locations on autonomous vehicle and each may be oriented differently see both of which depict different Lidars having different views and sensor fields . Given the directional nature of projecting laser beams different laser returns of different Lidars may return from a common point or a common set of points associated with for example a traffic sign at different times. Mapping engine and or components of autonomous vehicle services platform may be configured to align map transform or correlate the laser returns of different Lidars for common points of laser returns from a surface in the environment. Mapping engine and or components of autonomous vehicle services platform may also process sensor data and sensor data similarly.

In some examples one or more sensors may include various different sensor types n to generate various different subsets of sensor data . Examples of sensors include positioning sensors such as one or more global positioning system GPS data receiver sensors one or more inertial measurement units IMUs one or more odometry sensors e.g. wheel encoder sensors wheel speed sensors and the like one or more wheel angle sensors and the like to provide autonomous vehicle position and pose data. Such pose data may include one or more coordinates e.g. an x coordinate a y coordinate and or a z coordinate a yaw value a roll value a pitch value e.g. an angle value a rate e.g. velocity an altitude and the like

A log data repository in autonomous vehicle services platform is configured to receive and store subsets of sensor data and which in at least one example include raw Lidar data raw camera data raw radar data and other raw sensor data respectively. As shown in diagram subsets of sensor data at may be stored or logged at a common point in time or during a common interval of time as data set 1 data set 2 and data set n or as any number of data sets. Data sets and may be stored in data structures of log files according to some examples. Further sensor data which may be sensed contemporaneously with subsets of sensor data and may also be stored as part of log files for data sets and

Alignment controller may be configured to receive one or more of sensor data and as well as other data . Alignment controller may also be configured to generate data representing aligned subsets of sensor data and . In some cases sensor data may include a subset of sensor data that includes positioning data e.g. sensor data may include GPS IMU and odometry data . Regarding sensor data alignment examples of data representing aligned subsets of sensor data include data representing at least aligned Lidar data and aligned camera data. According to some examples alignment controller may be configured to implement a registration algorithm to align sensor data by identifying registration points at which to register portions or frames of Lidar sensor data and to register portions or frames of camera data. For example alignment controller may map or relate laser returns from one Lidar to other Lidars and may map or relate pixel data from one camera to other cameras. Further alignment controller may generate positioning map data such data may be stored in a data structure based on a pose graph model in which data specifying individual poses e.g. local poses may be interrelated spatially based on positioning sensor data collected from sensors e.g. GPS data IMU data odometry data etc. .

Mapping engine may be configured to receive the above described aligned sensor data e.g. registered sensor data and positioning map data e.g. pose graph related data to generate a high definition HD three dimensional model of a cityscape adjacent a network of roadways based on the integration of the subsets of sensor data and . As shown in diagram mapping engine may include one or more of the following an integrator to integrate sensor data a calibrator to calibrate sensor data a data change detector to detect changes in portions of map data a tile generator to generate formatted map data and a data change manager to manage implementation of changed map data according to various examples.

Integrator may be configured to integrate multiple subsets of sensor data e.g. of the same and different sensor modalities to generate high resolution e.g. relatively high resolution imagery data as a 3D model of an environment in which autonomous vehicles travel and may be further configured to reduce errors related to the individual types of sensors. According to some examples integrator is configured to fuse sensor data e.g. Lidar data camera data radar data etc. to form integrated sensor data. Further raw sensor data sets and may be received from one or more autonomous vehicles so as to fuse the aggregation of one or more subsets of sensor data of one or more sensor modalities from a fleet of autonomous vehicles . By fusing data from raw sensor data sets and integrator may generate 3D data sets that include fused sensor data such as data set 1 and data set 2 . Integrator may integrate or otherwise fuse at least two types of sensor data including the subsets of laser return data and the subsets of image data. In some examples the fusing of laser and image data may include correlating pixel data of subsets of image data to subsets of laser return data. Optionally integrator may associate pixel data of one or more pixels to one or more laser returns whereby the laser data may be associated with a portion of a surface in the three dimensional tile data. Note that pixel data may specify one or more surface characteristics including texture color reflectivity transparency etc. According to some examples integrator may implement a Kalman filtering process or a variant thereof e.g. an extended Kalman filtering process or any other process in which to fuse sensor data. Integrator may also include logic to extract or otherwise determine surfaces of objects e.g. buildings trees parked automobiles etc. or features as well as surface characteristics relative to a pose of an autonomous vehicle at which sensor data may be acquired.

Integrator may be configured to use sensor data sets and to extract surface related data of physical objects in an environment of an autonomous vehicle. Data set and data set as well as others not shown may include fused sensor data representing a three dimensional model relative to different points in time or different intervals of time. Therefore data sets may be used to detect whether there are changes to the physical environment or portions thereof over time. Note that at least in some implementations integrator may also implement a distance transform such as signed distance function SDF to determine one or more surfaces external to an autonomous vehicle. In one example a truncated sign distance function TSDF or equivalent may be implemented to identify one or more points on the surface relative to a reference point e.g. one or more distances to points on a surface of an external object relative to a local pose .

Integrator may be configured to generate 3 D models of a cityscape or any external object feature as probabilistic maps whereby map data may represent probability distributions over one or more environmental properties. For example the probabilistic map may be formed using laser intensity e.g. average laser intensity or reflectivity and variances of infrared remittance value at distances or points in space relative to a pose of an autonomous vehicle. A data structure for storing map data may include a number of cells that include for example an intensity average value and a variance value. In some examples this or any other data structure may also include a number of cells for storing 3 D map data such as color data e.g. RGB values or other color space values texture data reflectance data or any other surface characteristic or attribute data e.g. specular data . A cell that is configured to store map related data may be implemented as a voxel or as a 3 D tile according to some examples.

Mapping engine and or integrator as well as other components of mapping engine may be configured to generate 3 D map data in an offline mode of operation. For example mapping engine may implement algorithms e.g. machine learning including deep learning algorithms that analyze data sets based on logged data sets e.g. static data to generate map data. Note however mapping engine may not be limited to off line map generation but may also implement online map generation techniques in which one or more portions of raw sensor data may be received in real time or nearly real time to generate map data or identify changes thereto. Mapping engine may implement logic configured to perform simultaneous localization and mapping SLAM or any suitable mapping technique.

Data change detector is configured to detect changes in data sets and which are examples of any number of data sets of 3 D map data. Data change detector also is configured to generate data identifying a portion of map data that has changed as well as optionally identifying or classifying an object associated with the changed portion of map data. In the example shown a number of data sets including data set includes map data configured to generate map data which is conceptually depicted as 3 D model data e.g. a roadway at time T including portions of map data . At time T however data change detector may detect that another number of data sets including data set includes data representing the presence of external objects in portions of map data of 3 D model data whereby portions of map data coincide with portions of map data at different times. Therefore data change detector may detect changes in map data and may further adaptively modify map data to include the changed map data e.g. as updated map data .

According to some examples data change detector is configured to perform one or more statistical change detection algorithms to detect changes in physical environments. Multi temporal analysis techniques or the other suitable algorithms may also be used. The structures of data sets and may be implemented as cumulative data structures with which to index sensor data e.g. measurements thereof stored in a 3 D map data structure. As an example a statistical change detection algorithm may be configured to detect portions of map data that change by identifying boundaries over one or more iterations of a deep learning computation. In particular data changed detector may be configured to detect boundaries of map data portions and over time such as over two or more data sets e.g. over one or more passes or epochs of application of data sets to statistical change detection algorithms or deep learning algorithms . Epoch determination may also be applied to for example construct 4D maps and associated 4D map data. In some examples data change detector may classify portions of map data as well as an object therein to identify whether an object is static or dynamic. In some cases dynamic objects may be filtered out from map data generation.

Mapping engine is configured to provide map data to map data repository in reference data repository . Mapping engine may be configured to apply the change in map data to form updated three dimensional 3 D map data as reference data for transmission to reference data stores i.e. repositories in a fleet of autonomous vehicles. The change in data may be representative of a state change of an environment at which various types of sensor data are sensed. The state change of the environment therefore may be indicative of change in state of an object located therein e.g. inclusion of data representing the presence or absence of one or more objects . In some examples data change manager may be configured to identify or otherwise specify e.g. via identifier or indicator data that a portion of map data includes changed map data or an indication thereof . As shown map data stored map repository is associated with or linked to indication data delta data that indicated that an associated portion of map data has changed. Further to the example shown indication data may identify a set of traffic cones as changed portions of map data disposed in a physical environment associated with 3 D model through which an autonomous vehicle travels.

A tile generator may be configured to generate two dimensional or three dimensional map tiles based on map data from data sets and . The map tiles may be transmitted for storage in map repository . Tile generator may generate map tiles that include indicator data for indicating a portion of the map is an updated portion of map data. Further an updated map portion may be incorporated into a reference data repository in an autonomous vehicle. Therefore consider an example in which an autonomous vehicle travels through the physical environment and plans on traveling near a recently added object e.g. traffic cones in an environment. A localizer not shown may access map data that is associated with a changed portion of map data e.g. an updated portion of map data to localize the autonomous vehicle. Upon detecting the performance of localization with an updated map version logic may invoke additional processing to ensure that the use of updated map data may be used effectively and safely to navigate an autonomous vehicle . For example when a map tile including changed map data is accessed or implemented during localization a request for teleoperator monitoring or assistance may be generated. Note that in some examples changed portions of map data may also refer to temporary map data as such data may be used in fewer situations than for example validated map data.

Note however changed portions of map data may also be validated for integration into map data whereby the status of the changed map data is transitioned from temporary to validated. To illustrate an example of validating such data consider that a change in map data may be exported as updated three dimensional map data to a simulator computing device. The simulator computing device may then simulate performance of a portion of the fleet of autonomous vehicles in a simulated environment based on the updated three dimensional map data. Upon validating the updated three dimensional map data the changed map portions may be incorporated to form new three dimensional map data. New three dimensional map data may be viewed as three dimensional map data that may be relied upon such that indications of changed map data i.e. indications of changed map data may be removed as well as invocation of requests e.g. automatic requests for teleoperator assistance.

According to some examples mapping engine may include or be implemented as a 3D mapping engine and or a mapper as shown in . Further components of mapping engine may be combined or otherwise distributed within or without mapping engine . Mapping engine and any of its components may be implemented in hardware or software or a combination thereof. Moreover mapping engine may include any functionality and or structure described herein including one or more components of a perception engine to perform object detection segmentation and or classification.

As a further example consider that alignment controller may include one or more components of mapping engine of . For example alignment controller may include a loop closure detector a registration controller a global pose generator and a registration refinement module . In the example shown in autonomous vehicle service platform may implement as part of alignment controller loop closure detector of that may be configured to detect one or more portions of pose graphs at which autonomous vehicle of has previously traversed e.g. loop closure detector of may perform one or more loop closure processes to identify a closed loop . Registration controller may be configured to align or register multiple portions or frames of the same or different sensor data. For example one or more data sets of image data may be transformed or otherwise mapped to each other as well as to one or more data sets of laser return data and or radar return data. Registration controller may be configured to align subsets of laser return data subsets of image data and the like based on trajectory data representing position data to identify a relative coordinate of the global coordinate system. Examples of trajectory data include GPS data IMU data odometry data etc. Global pose graph generator may be is configured to generate pose graph data to specify a pose of autonomous vehicle of relative to global coordinate system. Therefore locally detected poses of a pose graph may be referenced to a global coordinate system. For example global pose graph generator of may be configured to form a global pose graph referenced to a global coordinate system. A global pose graph may be formed based on a first type of sensor data e.g. subsets of laser return data and a second type of sensor data e.g. subsets of image data as well as other optional sensor data e.g. subsets of radar data . Further global pose graph generator may also be configured to align the subsets of laser return data and the subset of image data to a location relative to a coordinate of a global coordinate system. Registration refinement module is configured to refine the registration of one or more of captured image data captured laser return data or other captured sensor data such as radar data and the like. In some examples registration refinement module is configured to reduce or eliminate artifacts of map data e.g. blurring artifacts or the like subsequent to for example the projection of color data onto 3 D mapped surfaces.

In some examples mapping data generated by mapping engine may be used to generate other reference data such as route data e.g. road network data such as RNDF like data mission data such as MDF like data and other reference data that may be used to navigate a fleet of autonomous vehicles. As shown route data generator may be configured to generate route data based on unchanged and or validated map data. Further route generator may be configured to generate changed route data which may be generated using changed and or non validated map data. In some cases autonomous vehicle controller may generate teleoperator request data responsive to detecting the use of changed route data . Therefore changed route data e.g. non validated or temporary map data route data may be used to navigate an autonomous vehicle with or without assistance of guidance data generated by a teleoperator.

Diagram depicts an autonomous vehicle which includes autonomous vehicle controller a local map generator and a reference data repository . Diagram also depicts an autonomous vehicle service platform including a mapping engine and a teleoperator computing device . Reference data repository includes a map store configured to store three dimensional map data and an route data store which may be a data repository for storing route data e.g. with or without an indication that a portion of a route data or road network data is associated with changed road network data or updated road network data .

Local map generator may be configured to receive multiple amounts and types of sensor data such as sensor data from sensor types and . According to various examples local map generator may be configured to generate map data e.g. three dimensional map data locally in real time or nearly in real time based on sensor data from sensor types and e.g. from groups of Lidar sensors groups of cameras groups of radars etc. . Local map generator may implement logic configured to perform simultaneous localization and mapping SLAM or any suitable mapping technique. In at least some examples local map generator may implement online map generation techniques in which one or more portions of raw sensor data from sensor types to may be received in real time or nearly real time to generate map data or identify changes thereto with which to navigate autonomous vehicle . Local map generator may also implement a distance transform such as signed distance function SDF to determine surfaces external to an autonomous vehicle. In one example a truncated sign distance function TSDF or equivalent may be implemented to identify one or more points on a surface relative to a reference point e.g. one or more distances to points on a surface of an external object whereby the TSDF function may be used to fuse sensor data and surface data to form three dimensional local map data .

Localizer may be configured to receive sensor data as well as locally generated map data and map data to localize autonomous vehicle relative to a coordinate of the global coordinate system associated with three dimensional map data or any other reference data . Also localizer is shown to include a variant detector and a hybrid map selection controller . Variant detector is configured to compare locally generated map data to map data to determine whether portions of map data associated with a specific surface or point in space varies. In particular variant detector may detect that data e.g. variance data representing one or more map portions of local map data varies from the three dimensional map data .

Localizer upon detecting varying map data portions or variance data may be configured to localize autonomous vehicle using hybrid map data from locally generated map data and map data . In the example shown hybrid map selection controller is configured to control whether locally generated map data or map data or a combination thereof may be used for localization. According to some examples different amounts of locally generated map data and map data may be used based on for example corresponding probability distributions that may indicate the reliability or accuracy of each. In some examples hybrid map selection controller may be configured to characterize the difference between the one or more map portions of map data and one or more portions of local map data to form variation data. Based on the variation data hybrid map selection controller may be configured to determine priorities of using local map data and priorities of using map data and may be further configured to cause localizer to use a first prioritized amount of local map data and a second prioritized amount of three dimensional map data based on the variation data. As an example consider an example in which variant detector detects variance data for several portions of map data that varies from corresponding portions of local map data . Further consider that local map data is determined to be more accurate for most portions of variance data. However at least one portion of local map data has a relatively lower probability of being accurate than a corresponding portion of map data . In this case hybrid map selection controller may rely more on local map data for localization with some reliance on map data but may also rely more on a specific portion of map data e.g. having a higher priority for localization than the corresponding portion of local map data e.g. having a lower priority .

Subsequent to detecting a variation between local map data and map data generated by mapping engine communication controller may be configured to control transceiver as well as the types or amounts of data transmitted to autonomous vehicles service platform . Therefore communication controller is configured to provide sufficient data for teleoperation logic and or teleoperator to select an optimal set of guidance data to resolve detected map data variations according to various examples. Communication controller is configured to provide optimal amounts of data or data rates so as to conserve bandwidth. To illustrate operation of communication controller consider that variant detector detects relatively minor or small amount of differences between map data and local map data . In this case communication controller may transmit relatively low amounts of data to provide an alert to teleoperator to urge the teleoperator to at least monitor autonomous vehicle as it travels through an environment that includes a minor change. Moreover during degraded or low speed data communication connections simpler or more abstract depictions of the data may be transmitted e.g. bounding boxes with associated metadata etc. rather than greater amounts of data.

As another example consider that variant detector detects relatively moderate amounts of differences between map data and local map data . In this case communication controller may be configured to increase the transmission bandwidth of transceiver to transmit one or more portions of local map data to autonomous vehicle service platform for evaluation by teleoperator logic . In yet another example consider that variant detector detects relatively large amounts of differences between map data and local map data . In this case communication controller may be configured to further increase the transmission bandwidth by transceiver to transmit one or more portions of high resolution sensor data to autonomous vehicle service platform for visual presentation of the physical environment on a display . For example all or substantially all Lidar data may be transmitted however any amount of less than all Lidar data may be transmitted. Sensor based data may be used to generate a three dimensional view in real time or nearly in real time so that teleoperator may identify changes in map data visually. As shown recently placed traffic cones are identified as being a cause of variance data or the differences between portions of map data and local map data . Note that the above described implementations are just a few examples of any number of implementations of the elements shown in diagram and as such the above description of diagram is not intended to be limiting.

Referring to the example shown in system memory includes an autonomous vehicle service platform module and or its components e.g. a mapping engine module etc. any of which or one or more portions of which can be configured to facilitate navigation for an autonomous vehicle service by implementing one or more functions described herein.

Referring to the example shown in system memory includes an autonomous vehicle AV module and or its components e.g. a local map generator module a hybrid map selection control module a communication control module etc. may be implemented for example in an autonomous vehicle . In some cases system memory or a portion thereof may be disposed in mobile computing device . One or more portions of module can be configured to facilitate navigation of an autonomous vehicle service by implementing one or more functions described herein.

Although the foregoing examples have been described in some detail for purposes of clarity of understanding the above described inventive techniques are not limited to the details provided. There are many alternative ways of implementing the above described invention techniques. The disclosed examples are illustrative and not restrictive.

