---

title: Temporal metadata track
abstract: Methods, data processing systems and machine readable non-transitory storage media are described that can provide, in one embodiment, a non-time based description of types of metadata in a time based metadata track that can be associated with, in time, a time based media track. The description can include a set of keys, or other identifiers, that specify the types of metadata in the metadata track, and the description can also include values describing the structure of each key and values describing how to interpret each key.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09507777&OS=09507777&RS=09507777
owner: Apple Inc.
number: 09507777
owner_city: Cupertino
owner_country: US
publication_date: 20150819
---
The present invention relates to in one embodiment methods and systems for using a temporal metadata track. Many electronic devices have the ability to capture media such as still images video audio or a combination thereof. For example an electronic device can include a lens that is used to capture light from a user s environment and use the captured light to generate the still image or video. When the electronic device captures images substantially continuously e.g. at a rate of 30 frames per second the electronic device can store the images as video and play them back to provide a movie. To assist the user in managing the stored media the electronic device can mark the media file with different types of information such as metadata. For example the electronic device can provide a date and time indicating when the video was recorded. As another example an electronic device can specify attributes of the lens and other camera data such as shutter speed F stop and other information related to the camera. Some electronic devices can also mark a recorded video with location information specifying a location where the recording started and another location where the recording stopped. The metadata can be stored in a time independent manner or can be stored in a time dependent manner such as the manner described in part 12 of ISO IEC 14496 12 2008 The ISO Base Media File Format available from the International Organization for Standardization. One or more metadata tracks can when possible and appropriate be linked to one or more tracks of the video or audio file that they described. The metadata tracks can include metadata values such as GPS coordinates camera data etc.

Methods data processing systems and machine readable non transitory storage media are described that can provide in one embodiment a non time based description of metadata in a time based metadata track that can be associated with in time a time based media track. The description can include a set of keys or other identifiers that specify the types of metadata in the metadata track and the description can also include values describing the structure of each key and values describing how to interpret each key or metadata identified by each key. In one embodiment the non time based description of metadata can provide an index and other information about the metadata in the time based metadata track. A playback device or other system can use the index to determine whether certain metadata exists in the time based metadata track without having to examine or search through the time based metadata track. In one embodiment each key in the description uniquely specifies a type of metadata relative to all other types of metadata in the time based metadata track. Further in one embodiment a unique key can be reserved as a null value to specify the absence of metadata for any type of metadata in the time based metadata track. In one embodiment the time based metadata track and the associated media tracks such as audio or video tracks can be stored in a container such as a container used in the QuickTime movie file format.

In one embodiment a machine readable non transitory storage medium can include in one file a time based metadata track and a time based media track which is associated in time with the time based metadata track and also can include a non time based description of types of metadata in the time based metadata track.

In another aspect of the invention a method implemented through an application program interface API can include calling through the API to cause a definition of metadata in a time based metadata track that is associated with a time based media track. The call can specify a unique key for a particular type of metadata and the call can cause the key and other data to be stored in a non time based description of types of metadata in the metadata track.

Some embodiments include one or more application programming interfaces APIs in an environment with calling program code interacting with other program code being called through the one or more interfaces. Various function calls messages or other types of invocations which further may include various kinds of parameters can be transferred via the APIs between the calling program and the code being called. In addition an API may provide the calling program code the ability to use data types or classes defined in the API and implemented in the called program code.

At least certain embodiments include an environment with a calling software component interacting with a called software component through an API. A method for operating through an API in this environment includes transferring one or more function calls messages other types of invocations or parameters via the API.

Various embodiments and aspects of the inventions will be described with reference to details discussed below and the accompanying drawings will illustrate the various embodiments. The following description and drawings are illustrative of the invention and are not to be construed as limiting the invention. Numerous specific details are described to provide a thorough understanding of various embodiments of the present invention. However in certain instances well known or conventional details are not described in order to provide a concise discussion of embodiments of the present inventions.

Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in conjunction with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification do not necessarily all refer to the same embodiment. The processes depicted in the figures that follow are performed by processing logic that comprises hardware e.g. circuitry dedicated logic etc. software or a combination of both. Although the processes are described below in terms of some sequential operations it should be appreciated that some of the operations described may be performed in a different order. Moreover some operations may be performed in parallel rather than sequentially.

In at least certain embodiments of the invention a time based metadata track can be described by a non time based description that can be referred to as a sample description. The time based metadata track can be a concatenated series of metadata contained within samples or other distinct retrievable objects and each of these objects or samples can be associated with a playback time such as a time stamp for a particular playback time such that the metadata can be presented or retrieved along with audio or video when the audio or video or both is presented e.g. displayed even without presenting the media track. In other words the time based metadata track has content such as data for one or more types of metadata that is synchronized in time with media content that is dependent upon time such as audio or video or both audio and video. In the case of the ISO International Organization for Standardization Standard ISO IEC 14496 12 2008 The ISO Base Media File Format a track is a time sequence of related samples in an ISO base media file for a media track implemented according to this international standard a sample is an individual frame of video a series of video frames in a decoding order or a compressed section of audio in decoding order and a sample is all data associated with a single time stamp. In one implementation of this international standard no two samples within a track can share the same time stamp and the time stamps can progress in time from a starting time to an ending time. The sample description on the other hand is not time based although it can include references to time for those embodiments in which the sample description provides an index to the location of metadata within the time based metadata track. The sample description provides a way to search or examine the time based metadata track without having to scan through or search the metadata track. This is useful because the metadata can sometimes be missing in the metadata track.

For example runs of metadata within a time based metadata track can be interspersed with runs of no metadata. For example GPS data may not be available when a recording system such as a video camera which includes a GPS receiver is used within a building but the GPS signals and hence GPS data will generally be available when the recording device is used outside of the building. If a video is recorded both indoors and outdoors and the GPS receiver operates during the entire recording session GPS data may be available while the device is outside of the building but often will not be available when the recording device is within the building. Hence a metadata track containing GPS data may have time periods in the metadata track which include GPS data and other time periods where there is no GPS metadata in the metadata track and thus this metadata track includes GPS metadata interspersed with no GPS metadata associated with the movie that was recorded. In some cases the movie could be recorded and there is no GPS metadata because the entire movie was recorded within a building which prevented the GPS receiver from receiving GPS signals.

The various embodiments of the invention can provide a set of files e.g. one or more files or a file format that includes the time based media track s and a time based metadata track s and also includes the non time based sample description. The set of files can be stored on a machine readable non transitory storage medium such as a flash memory or other semiconductor memory magnetic memory optical memory etc. Other embodiments can include methods of creating the files methods of transmitting or otherwise distributing the set of files methods of using the set of files such as playback or examination of the sample description that describes the metadata track and methods of revising a sample description to correct for the absence of metadata that was expected or declared in the sample description. These methods can be performed by one or more data processing systems and can be performed by executing instructions from a machine readable non transitory storage medium.

Sample description can include a variety of information about each of the tracks and and can be one or more sample descriptions even though only one sample description is shown in . In one embodiment each track has at least one sample description. For example sample description can include height and width data specifying the height and width of the video in the video tracks and sample description can include codec data which specifies the codecs that can be used to decode one or both of the audio content or video content contained within audio track and video track respectively. In addition sample description can include data describing the metadata in the metadata track . In one implementation this data describing the metadata in a metadata track can be an index specifying what metadata exists within a metadata track and further the index can optionally specify the location of each type of metadata within the metadata track in at least certain embodiments.

Sample description can include some of the same type of information as the sample description such as codec data and height and width data . Sample description can also include a description of the metadata within the time based metadata track and this sample description can provide information specifying the location of each group of samples in time within the metadata track . This sample description of the metadata is not dependent upon time and is not time based. Metadata information A provides information about the sample group within metadata track which includes metadata of the types A and C. The sample description includes those identifiers A and C and includes an indication of the location of that group of samples containing metadata of the types A and C where the location is shown in this case as spanning a period of time measured in for example seconds and milliseconds or other time measurements. Metadata information B can provide information about the metadata of metadata type B and can provide the location of the two sample groups of that metadata type access units C and G within the metadata track . Metadata information C can provide information in the sample description for the types of metadata B and C designated as such by the identifiers within the sample description and can also provide the location of the sample group containing these two types of metadata. Metadata information D can provide information about the metadata of three different types of metadata designated with the identifiers A B and C which are specified within the sample description along with the location of that sample group access unit F in the metadata track . Finally metadata information E can provide information about the metadata C and the location of that metadata within the metadata track .

Sample description can be similar to the sample description or sample description . For example it can include codec data and height and width data and other information commonly stored in a sample description such as the sample descriptions for movies stored in a QuickTime movie format. In addition sample description includes information about the metadata stored within metadata tracks and of . This information includes for each type of metadata the identifier for the type of metadata a key name space for the identifier data type information specifying how to interpret the metadata and potentially other information such as for example the location within the metadata track of the metadata of that type. The sample description can also include the null identifier null ID which will match and be identical to the null ID contained within the time based metadata tracks such as the null ID contained within metadata track or metadata track or metadata track . Metadata information provides information for the clip name metadata type and includes the identifier or key for that type of metadata ID as well as a key name space information for that identifier and a data type information specifying how to interpret the clip name e.g. the clip name is provided in ASCII format etc. . Metadata information includes the identifier or key for GPS type metadata as well as information with respect to the key name space for that identifier and data type information indicating how to interpret the GPS data coordinates e.g. as latitude and longitude or other types of position information . Further metadata information can include other types of metadata information relating to that type of metadata. Metadata information can include the identifier ID for copyright metadata and can include a key name space information describing a structure of that identifier for the copyright metadata and can also include data type information indicating how to interpret the metadata of this type. Metadata information can include the identifier ID for camera data metadata and can include a key name space describing a data structure for the identifier ID and can also include data type information specifying how to interpret metadata of the camera data type such as whether the film speed is in ASA or ISO etc. Metadata information can include the identifier ID for face detection metadata and information about the key name space for that identifier ID and data type information specifying how to interpret the face detection metadata and potentially other types of information with respect to this type of metadata. While the examples shown in includes five different types of metadata it will be appreciated that a variety of different types of metadata can be included such as any one of the types shown in and other types of metadata such as spatial orientation information e.g. obtained from accelerometers picture quality metadata user added metadata other types of position information metadata such as position information derived from a cellular telephone communication system or other types of satellite positioning systems other than the GPS system or location information derived from data networks such as WiFi hotspot location information or other information derived from a data network. It will also be understood that the sample description may include other types of information with respect to the metadata tracks and that the metadata tracks can also include information about the metadata track such as the height and width both being zero in a typical implementation and a track volume of zero for the metadata track. Further the metadata track can be associated with a time based media track e.g. video and or audio tracks by a reference that the time based metadata track describes the time based media track.

In certain embodiments a system can allow additional metadata to be added after the creation or recording of a movie for example post processing of the movie can be performed to add face detection metadata or to add metadata of picture quality so that this metadata can be used in further editing of the movie to for example improve picture quality by identifying areas of the movie that have poor picture quality and by performing image enhancements on those portions of the movie. The use of the key name space for an identifier allows certain formats to receive data from other formats without having to transcode the key or identifier from one format into another format. The data type information allows any system receiving the file containing the sample description and the time based metadata track to interpret the metadata in the metadata track.

A method for creating a sample description will now be provided with reference to . It will be appreciated that the operations shown in can be performed in an order which is different than that shown in . In operation a movie can be created by recording audio and video or by creating the audio and video to be stored in a time based media track. In operation metadata is recorded into one or more metadata tracks which are associated in time with the time based media content such as a movie. The metadata may be location metadata or copyright metadata or face detection metadata or other types of metadata known in the art. The metadata is captured and recorded into the one or more metadata tracks which are time based tracks such as the metadata track shown in . In operation the sample description which describes the metadata in the metadata track can be created. Operation could occur before operation in some embodiments. In operation the time based media content and the time based metadata content with the sample description which is not time based can be stored as a single file or optionally as multiple files. For example the time based media content and the time based metadata track and the sample description could be stored as a single file in the QuickTime movie file format that is known in the art.

The metadata may not exist in some embodiments during recording because of power constraints. For example in some embodiments a low power mode to conserve battery life may cause a restriction on the amount or even the presence of metadata in a time based metadata track. For example GPS receivers can consume a lot of power and hence reduce battery life. It may be desirable in some embodiments to turn off the GPS receiver during a portion of recording a movie or during the entire movie in order to conserve battery power. Hence as a result certain types of metadata which are expected to be available may not in fact be available due to power conservation. Moreover the frequency of the metadata within a metadata track may vary depending upon the power mode of the system. If the system has enough battery power the metadata may be recorded with a first frequency which is greater than a second frequency used when the system is operating under a low battery power mode.

After determining in operation that certain expected types of metadata do not exist in the time based metadata track then in operation the sample description is revised to reflect what metadata actually exists within the metadata track. In one embodiment a null value may be inserted into the sample description created in operation and this null value is selected so that the size of the sample description does not change as a result of inserting the null value. Moreover the insertion of a null value into the sample description can be an insertion and replacement in place such that the size of the sample description does not change and no other re writing of the sample description is required. Table shows an example of the revised sample description which includes a null value which has been inserted in place of the face detection data . This creates the revised sample description in which the null value replaces the face detection data in the sample description . In an alternative embodiment the sample description can be rewritten to remove identifiers of metadata that do not actually exist within the metadata track and the rewritten sample description can as a result of this removal change in size and the containers or boxes that contain the sample description can also be rewritten to change their sizes as a result of this removal.

Some clients using timed metadata tracks may prefer to create metadata tracks samples that have the same size. Two exemplary approaches are described here. In one approach the access values written might contain a fixed set of fixed sized metadata values see MetaDataAUBox above . If one or more values are not used boxes corresponding to unused values can have their local key id set to an unreferenced value e.g. 0 . This can be done without resizing the AU. In the second approach the size of individual metadata values may vary. It is possible to create constant sized AUs by determining a maximum size and using unreferenced boxes to pad to this size. The approach is 

The following description provides an example of a specific embodiment of the invention. Metadata tracks use a null media header nmhd as defined in subclause 8.4.5.5 of ISO IEC 14496 12. As a metadata track is neither visual nor aural the following track properties should have these values 

Per ISO IEC 14496 12 the sample entry or SampleDescription in QuickTime is a MetaDataSampleEntry and is defined as 

The optional BitRateBox exists to indicate bitrates of the corresponding timed metadata streams. A sample entry format is described in which access units such as media samples in QuickTime contain values that are boxed. In a boxed access unit metadata values are each surrounded by a ISO IEC 1449642 Box structure. Access units may also include other boxes not holding metadata values. In this boxed design zero one or more values may be carried in an access unit for a particular time actually a time range .

The MetaDataKeyTableBox contains a table of keys and mappings to payload data in the corresponding access units. It is defined as 

If the MetaDataKeyTableBox does not contain a key for which a client is searching no access units associated with this sample entry contain values with that key. If the MetaDataKeyTableBox does contain a particular key this does not however guarantee that any access units containing a value for the key were written. So clients finding a key in the MetaDataKeyTableBox may still need to look through the track s access units for values to determine if the track has the particular metadata. This rule allows a sample entry to be populated with keys that might be discovered say during a capture process and then access units to be written with a binding only for the keys found. If never used there is no requirement that the sample entry be rewritten to exclude the key that was not needed. This makes writing using movie fragments easier as the sample entries in the initial movie never need to be rewritten. It is possible to remove unused sample entries efficiently and rewrite the sample entry and this can be done using a method described relative to .

The box type for each MetaDataKeyBox is here referred to as local key id and serves 1 as a unique identifier among all MetaDataKeyBoxes and 2 as the identifier for the metadata value boxes within access units that have that key.

The box type for the contained MetaDataKeyBox is local to the containing track and corresponds to the box types 32 bit integers or four CCs for boxes within metadata access units that hold that particular metadata value. For example if the MetaDataKeyBox has the box type of stuf any boxes of type stuf in access units sharing this sample entry hold the value for this key. Any value fitting in a 32 bit big endian integer can be used e.g. stuf the integer 72 but it is recommended that it be mnemonic if possible.

There is one reserved box type for boxes of type MetaDataKeyBox. A local key id of 0 indicates that the MetaDataKeyBox is unused and should not be interpreted. This allows the key to be marked as unused in the sample entry without requiring the sample entry and parent atoms to be rewritten resized. All other box types are available for use. Because the children boxes within MetaDataKeyTableBox can take on any box type there should be no special interpretation of the box type for contained boxes other than the special value 0. Therefore including a free box does not have the conventional meaning in the MetaDataKeyBox. Even so it is recommended but not required to avoid overly confusing use of existing four CCs.

Each MetaDataKeyBox contains a variable number of boxes that define the key structure optionally the datatype for values optionally the locale for the values and optional setup information needed to interpret the value.

The MetaDataKeyDeclarationBox holds the key namespace and key value of that namespace for the given values 

To specify the data type of the value it is possible to include an optional MetaDataDatatypeDefinitionBox as defined here 

A metadata value may optionally be tagged with its locale so that it may be chosen based upon the user s language country etc. This makes it possible to include several keys of the same key type e.g. copyright or scene description but with differing locales for users of different languages or locations.

This is accomplished by including a MetaDataLocaleBox within the MetaDataKeyBox. The definition of MetaDataLocaleBox is 

Some metadata values benefit from having setup information to describe their interpretation. This setup data is private to the metadata datatype. The data can take the form of leaf data bytes or children boxes.

An example might be information used to interpret the coordinate system of rectangles used in face detection metadata. As mentioned the contents of MetaDataSetupBox can be boxes or raw data the structure being dependent upon the data type. Another kind of setup might be a media type e.g. vide and a sample description. This would allow the metadata to reference a still image compliant with H.264 because the setup for the acv1 decoder is available.

Some metadata values may benefit from having publicly defined and interpretable state associated with them. This is in contrast to the type specific private state held in MetaDataSetupBox . By analogy VisualSampleEntries may have PixelAspectRatioBox pasp or CleanApertureBox clapC extensions.

An access unit e.g. a media sample is structured as a concatenation of one or more Boxes. Typically each box will contain a metadata value corresponding to a key signaled in the sample entry.

If no value for a particular key is present in the access unit at the given time the interpretation should be that there is no metadata of that type at the time. Metadata values for that key for other times e.g. from a previous access unit should not be interpreted as applying to the target time.

If no values for any key are present for a time range one approach is to include a NULL access unit or AU for the time range. In one embodiment a zero byte sized AU should not be used in one embodiment as all sample sizes must be one or more bytes in size. Also an empty track edit list entry could be used to indicate there is no metadata for a range of movie time.

In one embodiment however it is preferable to include a NULL AU instead of using a track edit with an empty edit to indicate the absence of metadata.

So by way of an example if one were to carry VANC data in an access unit it might be carried in a derived MetaDataAUEntry something like this 

Here the structure of the value is specific to how such VANC data is thought useful to carry. There is no VANCMetaDataAUEntry described herein it is simply an example. As described before local key id values of 0 are reserved.

A MetaDataAccessUnit may contain boxes with types the local key id other than those advertised in the MetaDataKeyTableBox although this is discouraged. Any instances of such boxes may be interpreted according to their conventional meaning e.g. free or in a private way so long as they are not advertised as keys.

This section describes an optional mechanism to optimize searches for metadata track access units containing particular key value pairs.

A metadata track conforming to this specification may optionally make use of the SampleGroupDescriptionBox and SampleToGroupBox constructs to optimize searching for access units containing particular keys. This can be characterized as having a key search sample group. 

The SampleGroupDescriptionBox and SampleToGroupBox are defined in ISO IEC 14496 12. A sample group consists of two parts a SampleGroupDescriptionBox containing a collection of differing descriptions serving to describe properties of samples and a SampleToGroupBox mapping samples to a description. Each of SampleGroupDescriptionBox and SampleToGroupBox making up the sample group are tagged with the same grouping type field to indicate the type of grouping and to distinguish this sample group from other sample groups. At most in one embodiment one sample group within a track may have the same grouping type.

An example sample group is the pre roll sample group used with audio pre roll. The pre roll group uses the grouping type roll .

In a metadata track containing one or more sample entries in one embodiment the MetaDataKeyTableBox in the BoxedMetaDataSampleEntry can be used to determine possible keys present in the track s AUs. If a key is not present in the MetaDataKeyTableBox it is known that the key doesn t exist in any AUs. It doesn t however indicate which samples have particular keys and associated values . Therefore to determine which metadata keys are present in the track requires an exhaustive search of AUs associated with that sample entry in the metadata track in one embodiment.

While it would be possible to create a track with sample entries for each combination of keys present in the track and only associate the samples with that combination with the particular sample entry having many sample entries may not be ideal or easily done. An alternative described here is to define a new kind of sample group that indicates the keys present in an AU.

The new sample group consists of a SampleGroupDescriptionBox holding a new group description for each new combination of keys present in AUs. If all AUs consist of the same four keys for example there would be one group description with these four keys. If the set of keys varied there need only be as many descriptions as there are different sets of keys present in AUs.

A client looking for AUs with a particular key or keys would first consult the sample entry or sample entries if there are more than one and determine if the key is present in the set of possible keys via MetaDataKeyTableBox . If this succeeds the client would check if the optional sample group exists and finding this to be the case the client would walk through the SampleToGroupBox checking if the corresponding sample group description contains the key. As these operations require only information present in the MovieBox direct reading and processing of AUs is unnecessary. While key is used here as being present in the sample group description an equivalent more compact identifier can be used.

For this section an optional sample group known as a key search sample group can be defined. It consists of SampleGroupDescriptionBox and SampleToGroupBox having the grouping type keyp .

The SampleGroupDescriptionBox can contain variable sized SampleGroupDescriptionEntries each of type MetaDataKeySearchGroupEntry. MetaDataKeySearchGroupEntry is defined in one embodiment as 

Each sample group description entry signals the presence of one or more keys from the key table found in the sample entry associated with the sample s . Access units associated with this sample group description shall have corresponding metadata values with these same keys.

Each key in use can be signaled by using the 32 bit integer value of the local key id field associated with the MetaDataKeyTableBox entry. This local key id is also used in access units as the type of Box holding the corresponding value.

If two samples differ in the keys present they cannot in one embodiment share the same sample group description. A sample group description for each combination should be created. While not strictly required it is recommended that the order of local key ids be the same as the order of local key ids in the MetaDataKeyTableBox of the sample entry. This prevents group descriptions with the same set of keys but differing only in key order from creating multiple trivially different sample group descriptions.

As the number of local key ids present in MetaDataKeySearchGroupEntry will typically vary the containing SampleGroupDescriptionBox should be a version 1 SampleGroupDescriptionBox with a default length set to 0. This indicates there is a 32 bit size before each group description entry holding the size in bytes of the following entry. A version 0 SampleGroupDescriptionBox should not be used.

Finally if a sample group spans multiple sample entries with different sets of keys the local key ids present in the sample entries spanned should be compatible in one embodiment i.e. the local key id must be present in each MetaDataKeyTableBox and the corresponding key table entry must be the same .

The use of sample group descriptions can allow for rapid search of a run of access units that contain the same set of metadata types. A sample group description in one embodiment can be limited to a specific consecutive in time set of access units that contain the same set of metadata types and each of the access units in this set can include an identifier that maps to or points to the corresponding sample group description.

One or more Application Programming Interfaces APIs may be used in some embodiments. An API is an interface implemented by a program code component or hardware component hereinafter API implementing component that allows a different program code component or hardware component hereinafter API calling component to access and use one or more functions methods procedures data structures classes and or other services provided by the API implementing component. An API can define one or more parameters that are passed between the API calling component and the API implementing component.

An API allows a developer of an API calling component which may be a third party developer to leverage specified features provided by an API implementing component. There may be one API calling component or there may be more than one such component. An API can be a source code interface that a computer system or program library provides in order to support requests for services from an application. An operating system OS can have multiple APIs to allow applications running on the OS to call one or more of those APIs and a service such as a program library can have multiple APIs to allow an application that uses the service to call one or more of those APIs. An API can be specified in terms of a programming language that can be interpreted or compiled when an application is built.

In some embodiments the API implementing component may provide more than one API each providing a different view of or with different aspects that access different aspects of the functionality implemented by the API implementing component. For example one API of an API implementing component can provide a first set of functions and can be exposed to third party developers and another API of the API implementing component can be hidden not exposed and provide a subset of the first set of functions and also provide another set of functions such as testing or debugging functions which are not in the first set of functions. In other embodiments the API implementing component may itself call one or more other components via an underlying API and thus be both an API calling component and an API implementing component.

An API defines the language and parameters that API calling components use when accessing and using specified features of the API implementing component. For example an API calling component accesses the specified features of the API implementing component through one or more API calls or invocations embodied for example by function or method calls exposed by the API and passes data and control information using parameters via the API calls or invocations. The API implementing component may return a value through the API in response to an API call from an API calling component. While the API defines the syntax and result of an API call e.g. how to invoke the API call and what the API call does the API may not reveal how the API call accomplishes the function specified by the API call. Various API calls are transferred via the one or more application programming interfaces between the calling API calling component and an API implementing component. Transferring the API calls may include issuing initiating invoking calling receiving returning or responding to the function calls or messages in other words transferring can describe actions by either of the API calling component or the API implementing component. The function calls or other invocations of the API may send or receive one or more parameters through a parameter list or other structure. A parameter can be a constant key data structure object object class variable data type pointer array list or a pointer to a function or method or another way to reference a data or other item to be passed via the API.

Furthermore data types or classes may be provided by the API and implemented by the API implementing component. Thus the API calling component may declare variables use pointers to use or instantiate constant values of such types or classes by using definitions provided in the API.

Generally an API can be used to access a service or data provided by the API implementing component or to initiate performance of an operation or computation provided by the API implementing component. By way of example the API implementing component and the API calling component may each be any one of an operating system a library a device driver an API an application program or other module it should be understood that the API implementing component and the API calling component may be the same or different type of module from each other . API implementing components may in some cases be embodied at least in part in firmware microcode or other hardware logic. In some embodiments an API may allow a client program to use the services provided by a Software Development Kit SDK library. In other embodiments an application or other client program may use an API provided by an Application Framework. In these embodiments the application or client program may incorporate calls to functions or methods provided by the SDK and provided by the API or use data types or objects defined in the SDK and provided by the API. An Application Framework may in these embodiments provide a main event loop for a program that responds to various events defined by the Framework. The API allows the application to specify the events and the responses to the events using the Application Framework. In some implementations an API call can report to an application the capabilities or state of a hardware device including those related to aspects such as input capabilities and state output capabilities and state processing capability power state storage capacity and state communications capability etc. and the API may be implemented in part by firmware microcode or other low level logic that executes in part on the hardware component.

The API calling component may be a local component i.e. on the same data processing system as the API implementing component or a remote component i.e. on a different data processing system from the API implementing component that communicates with the API implementing component through the API over a network. It should be understood that an API implementing component may also act as an API calling component i.e. it may make API calls to an API exposed by a different API implementing component and an API calling component may also act as an API implementing component by implementing an API that is exposed to a different API calling component.

The API may allow multiple API calling components written in different programming languages to communicate with the API implementing component thus the API may include features for translating calls and returns between the API implementing component and the API calling component however the API may be implemented in terms of a specific programming language. An API calling component can in one embodiment call APIs from different providers such as a set of APIs from an OS provider and another set of APIs from a plug in provider and another set of APIs from another provider e.g. the provider of a software library or creator of the another set of APIs.

It will be appreciated that the API implementing component may include additional functions methods classes data structures and or other features that are not specified through the API and are not available to the API calling component . It should be understood that the API calling component may be on the same system as the API implementing component or may be located remotely and accesses the API implementing component using the API over a network. While illustrates a single API calling component interacting with the API it should be understood that other API calling components which may be written in different languages or the same language than the API calling component may use the API .

The API implementing component the API and the API calling component may be stored in a machine readable medium which includes any mechanism for storing information in a form readable by a machine e.g. a computer or other data processing system . For example a machine readable medium includes magnetic disks optical disks random access memory read only memory flash memory devices etc.

In Software Stack an exemplary embodiment applications can make calls to Services A or B using several Service APIs and to Operating System OS using several OS APIs. Services A and B can make calls to OS using several OS APIs.

Note that the Service has two APIs one of which Service API receives calls from and returns values to Application and the other Service API receives calls from and returns values to Application . Service which can be for example a software library makes calls to and receives returned values from OS API and Service which can be for example a software library makes calls to and receives returned values from both OS API and OS API . Application makes calls to and receives returned values from OS API .

As shown in the computer system which is a form of a data processing system includes a bus which is coupled to a microprocessor s and a ROM Read Only Memory and volatile RAM and a non volatile memory . The microprocessor may retrieve the instructions from the memories and execute the instructions to perform operations described above. Memories and are examples of machine readable non transitory storage media that can store computer program instructions for execution. The bus interconnects these various components together and also interconnects these components and to a display controller and display device and to peripheral devices such as input output I O devices which may be mice keyboards modems network interfaces printers and other devices which are well known in the art. Typically the input output devices are coupled to the system through input output controllers . The volatile RAM Random Access Memory is typically implemented as dynamic RAM DRAM which requires power continually in order to refresh or maintain the data in the memory.

The mass storage is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD RAM or a flash memory or other types of memory systems which maintain data e.g. large amounts of data even after power is removed from the system. Typically the mass storage will also be a random access memory although this is not required. While shows that the mass storage is a local device coupled directly to the rest of the components in the data processing system it will be appreciated that the present invention may utilize a non volatile memory which is remote from the system such as a network storage device which is coupled to the data processing system through a network interface such as a modem an Ethernet interface or a wireless network. The bus may include one or more buses connected to each other through various bridges controllers and or adapters as is well known in the art. Computer system can optionally include a metadata and media acquisition device . While one such metadata and media acquisition device is shown it will be appreciated that the computer system can include a plurality of such metadata and media acquisition devices. In one embodiment the metadata and media acquisition device is an electronic device tethered to the computer system . In another embodiment the metadata and media acquisition device is a device integrated into the computer system and can capture media and metadata such as location orientation and motion information etc. Furthermore this device can associate the location orientation or motion information or other metadata with the captured media as described herein. In another embodiment system can include one or more devices for capturing media e.g. a camera and a microphone for capturing a movie and one or more other separate devices e.g. a GPS receiver for capturing metadata e.g. GPS coordinates .

A display controller and display device can provide a visual user interface for the user this interface may include a graphical user interface which is similar to that shown on a Macintosh computer when running OS X operating system software or on an iPhone. The system also includes one or more wireless transceivers to communicate with another data processing system. A wireless transceiver may be a WLAN transceiver e.g. WiFi an infrared transceiver a Bluetooth transceiver and or a wireless cellular telephony transceiver. It will be appreciated that additional components not shown may also be part of the system in certain embodiments and in certain embodiments fewer components than shown in may also be used in a data processing system. The system further includes one or more communications ports to communicate with another data processing system. The communications port may be a USB port Firewire port Bluetooth interface a docking port etc.

The data processing system also includes one or more input devices which are provided to allow a user to provide input to the system. These input devices may be a keypad or a keyboard or a touch panel or a multi touch panel which is overlaid and integrated with a display device. The data processing system also includes an optional input output device which may be a connector for a dock. It will be appreciated that one or more buses not shown may be used to interconnect the various components as is well known in the art. The data processing system shown in may be a handheld computer or a personal digital assistant PDA or a cellular telephone with PDA like functionality or a handheld computer which includes a cellular telephone or a media player such as an iPod or a game or entertainment device or devices which combine aspects or functions of these devices such as a media player combined with a PDA and a cellular telephone in one device or an embedded device or other consumer electronic devices. In other embodiments the data processing system may be a network computer or an embedded processing device within another device or other types of data processing systems which have fewer components or perhaps more components than that shown in .

Data processing system can optionally include one or more metadata and media acquisition devices such as device . In one embodiment the metadata and media acquisition device is an electronic device tethered to the data processing system . In another embodiment metadata and media acquisition device is a device integrated into the computer system and can capture media and metadata information. In another embodiment system can include one or more devices for capturing media e.g. a camera and a microphone for capturing a movie and one or more other separate devices e.g. a GPS receiver for capturing metadata. Furthermore this device can associate the metadata information with the captured media as described herein.

At least certain embodiments of the inventions may be part of a digital media player such as a portable music and or video media player which may include a media processing system to present the media a storage device to store the media and may further include a radio frequency RF transceiver e.g. an RF transceiver for a cellular telephone coupled with an antenna system and the media processing system. In certain embodiments media stored on a remote storage device may be transmitted to the media player through the RF transceiver. The media may be for example one or more of music or other audio still pictures or motion pictures.

The portable media player may include a media selection device such as a click wheel input device on an iPod or iPod Nano media player from Apple Inc. of Cupertino Calif. a touch screen input device pushbutton device movable pointing input device or other input device. The media selection device may be used to select the media stored on the storage device and or the remote storage device. The portable media player may in at least certain embodiments include a display device which is coupled to the media processing system to display titles or other indicators of media being selected through the input device and being presented either through a speaker or earphone s or on the display device or on both display device and a speaker or earphone s . Examples of a portable media player are described in published U.S. Pat. No. 7 345 671 and U.S. published patent application number 2004 0224638 both of which are incorporated herein by reference.

In the foregoing specification the invention has been described with reference to specific exemplary embodiments thereof. It will be evident that various modifications may be made thereto without departing from the broader spirit and scope of the invention as set forth in the following claims. The specification and drawings are accordingly to be regarded in an illustrative sense rather than a restrictive sense.

