---

title: Pre-fetching of network page content in a browser application
abstract: Disclosed are various embodiments for pre-fetching resources referenced on a network page using a browser application executable on a client device. A network page predicted to be accessed by a user of a browser application may be identified that references resources, such as image, video, text, and multimedia resources. A prioritization of retrieval may be determined for the resources according to retrieval criteria. The browser application may retrieve at least a portion of the resources according to the prioritization of retrieval and store the retrieved sources in memory, thereby causing the network page predicted to be accessed to render more quickly, when accessed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09582593&OS=09582593&RS=09582593
owner: Amazon Technologies, Inc.
number: 09582593
owner_city: Seattle
owner_country: US
publication_date: 20150804
---
This application claims the benefit of and priority to U.S. patent application Ser. No. 14 460 432 entitled PRE FETCHING OF NETWORK PAGE CONTENT filed on Aug. 15 2014 now issued as U.S. Pat. No. 9 116 999 and U.S. patent application Ser. No. 13 112 545 entitled PRE FETCHING OF NETWORK PAGE CONTENT filed on May 20 2011 now issued as U.S. Pat. No. 8 812 658 the contents of which are hereby incorporated by reference in their entirety herein.

Online shoppers interact with electronic commerce network sites to find products of interest and obtain information about those products. Such sites may allow users to interact with a network page in a browser in order to browse a catalog hierarchy sort items by various criteria perform searches using keywords and perform various other actions. In doing so the user accesses or views a series of pages moving from one page to another. To view these pages each page is retrieved which includes layout code and any content referenced by the page.

The various embodiments described herein relate to pre fetching resources referenced in a network page and more specifically in a predicted next network page. A prediction engine is used to predict which network page will next be viewed or accessed by a user and the browser pre fetches portions of this network page so that the predicted next network page may be made visible to the user in immediate response to the user selecting the predicted page. In addition to the page itself resources referenced within the page are also pre fetched before the predicted next page is viewed by the user. Various criteria related to attributes of those resources may be used to select which resources are pre fetched and or to set the order of the pre fetching. In this manner the network page and the resources referenced therein may be rendered by the browser in immediate response to the user choosing the predicted page.

With reference to shown is a networked environment according to various embodiments. The networked environment includes one or more computing devices in data communication with one or more client devices by way of a network . The network includes for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks or any combination of two or more such networks.

The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. A plurality of computing devices together may comprise for example a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in various arrangements.

Various applications and or other functionality may be executed in the computing device according to various embodiments. Also various data is stored in a data store that is accessible to the computing device . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing device include for example a page prediction engine a resource pre fetch engine and a network page server application . In some embodiments the computing device also includes an electronic commerce application . The components executed on the computing device may also include other applications services processes systems engines or functionality not discussed in detail herein. These components may communicate with each other using various mechanisms including but not limited to any type of middleware framework. Though shown as logically separate components the functionality of the page prediction engine the network page server application and the electronic commerce application can be combined and or distributed in various ways as can be appreciated.

The data stored in the data store includes for example network page data a catalog of items and potentially other data. As used herein the term item may refer to a product good service software download multimedia download social networking profile or other item that may be offered for sale purchase rental lease download and or any other form of consumption as may be appreciated. Associated with items and stored in catalog are data such as titles descriptions keywords metadata weights customer reviews multimedia and other data relating to the items . The catalog may be arranged in a hierarchical manner with categories and subcategories.

The optional electronic commerce application if present is executed in order to facilitate the online viewing and or purchase of items and products over the network . The electronic commerce application also performs various backend functions associated with the online presence of a merchant in order to facilitate the online purchase of items as should be appreciated. In embodiments which include the electronic commerce application the catalog of items comprises a product catalog of items offered for sale so that data associated with items comprises product data.

The network page server application is executed to generate network pages that describe items. To this end the network page server application uses network page data which may include any type of data related to the generation of network pages . Such data may include for example templates executable code interpreted code hypertext markup language HTML extensible markup language XML images video text graphics and any other type of data that may be used in network pages . The network page server application may comprise a commercially available hypertext transfer protocol HTTP server such as for example Apache HTTP Server Microsoft Internet Information Services IIS and other servers.

The page prediction engine may improve rendering at the client by making a prediction as to which network page a user will select next and generating a predicted next network page that includes partial predicted page data . The prediction techniques used by the page prediction engine may include for example those described in commonly assigned applications having Ser. Nos. 13 037 829 13 037 837 13 037 842 13 037 852 and 13 037 857 all of which were filed on Mar. 1 2011 and each of which is hereby incorporated by reference herein.

The network page may include rendering code . The network page with the partial predicted page data and the rendering code is provided to the client device which allows the browser to render more quickly a portion of the predicted page and the resources referenced therein before the user actually takes the action which leads to the page. In some embodiments the partial predicted page data corresponds to the portion of the predicted network page that is first seen by the user a region sometimes referred to as above the fold. 

A network page may include references or links to resources which may be stored in files separate from the network page . The resources may be media resources such as graphics audio video and multimedia. The resources may also be code resources such as executable code or scripting code. The resource pre fetch engine operates to select and or prioritize resources for pre fetching and to provide a list of the resources for pre fetch to the browser executing on the client device . The browser then retrieves one or more of the listed resources from the network page server application . This retrieval can be performed before the user views the network page so that the pre fetch resources are immediately available to the user without a delay.

The network page server application may be configured to generate the partial predicted page data for a specific network page and or client device based on stored rendering code in the data store . The stored rendering code may include for example JavaScript dynamic HTML DHTML Ajax and any other type of code that may be executed in a client device from within a network page . The stored rendering code may also include asynchronous exchange of data with the page prediction engine the network page server application or other applications using Ajax simple object access protocol SOAP remote procedure call RPC and or other technologies.

Having discussed the computing device the client device will now be considered. The client device is representative of a plurality of client devices that may be coupled to the network . The client device may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer a laptop computer a personal digital assistant a cellular telephone a set top box a music player a video player a media player a web pad a tablet computer system a game console an electronic book reader or other devices with like capability.

The client device may be configured to execute various applications such as a browser and other applications. The browser may be executed in a client device for example to access and render network pages or other network content served up by the network page server application thereby generating a rendered network page. The rendering code included within a predicted next network page may be executed in the context of the browser . The client device may be configured to execute applications beyond the browser such as for example email applications instant message applications and or other applications.

A general description of the operation of the various components of the networked environment is provided. To begin the browser requests a network page from the network page server application . In response the network page server application provides the requested network page as well as at least a portion of a predicted next network page in the form of partial predicted page data . The predicted next network page includes references to one or more resources which are stored separately from the predicted next network page and thus must be retrieved before viewing by the user. The resource pre fetch engine uses selection and or prioritization criteria related to attributes of the referenced resources to determine which of the resources on the predicted next network page are to be pre fetched by the browser and or to determine a recommended order in which the resources should be pre fetched. The resource pre fetch engine then provides the list of resources for pre fetch to the browser .

The browser then pre fetches the listed resources in the order dictated by the resource pre fetch engine before the user has selected the predicted next network page described by the partial predicted page data . Thus when the user does access the predicted next network page not only the page itself but one or more referenced resources are available for immediate rendering.

Turning now to shown is a flowchart that provides one example of the operation of a portion of the resource pre fetch engine according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the resource pre fetch engine as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

Beginning at box the resource pre fetch engine obtains a network page from the page prediction engine . This network page is not the page that the user is currently interacting with but is instead a predicted next page and as such includes partial predicted page data . At box the resource pre fetch engine parses the predicted next network page to find one or more resources referenced within the page. These referenced resources may include for example various media resources such as still image files graphics files audio files video files multimedia files such as Adobe Flash or other types of media files. These referenced resources may also include for example code or scripts executable by the browser such as for example Java code JavaScript or other types of code. These resources have various attributes such as file name file type file size resource type media type media version viewing position of the resource within the network page whether viewing of the resource is triggered by an explicit user action etc.

At box the resource pre fetch engine prioritizes the pre fetch or downloading of the resources identified in box . Pre fetching of the resources is prioritized according to a resource attribute criteria such that some resources referenced within the predicted next network page are marked for retrieval before others. Various criteria related to resource attributes may be used to determine pre fetch order. As one example file size may be used as a criteria and larger files may be retrieved before smaller files or smaller files may be retrieved before larger files. As another example resource type may be used as a criteria and resource types may have a preferred order for example retrieve image resources first then code resources then audio resources then video resources then multimedia resources. As yet another example a resource type may be associated with an indicator of how much delay a user expects when viewing or consuming the resource and the delay indicator may be used as a criteria so that resources for which the user expects little or no delay e.g. still image are retrieved ahead of resources for which the user expects significant delay e.g. video . As still another example the resource s viewing position within the network page may be used as a criteria so that resources which are visible earlier in the rendering process sometimes referred to as above the fold are retrieved sooner than resources that are visible later.

Yet another example of a resource attribute criteria is whether rendering of the resource is triggered by an explicit user action in which case such resources are prioritized for later retrieval as compared to resources which are rendered without explicit user action. For example the predicted next network page may be coded so that a user presses a preview button in order to view a video file but still images are presented and audio files are played without any button press in which case the still image s and the audio file s are retrieved before the video file s . Another example of a resource triggered by explicit user action may be a code resource such as a script widget or other code component.

Still another example of a resource attribute criteria is whether the resource type is one that involves user interaction so that interactive resources are preferred when pre fetching. For example a user control such as a text box or a button may be preferred for pre fetch since the user cannot complete the task associated with the network page until he interacts with this resource.

At box having determined a pre fetch priority for the resources the resource pre fetch engine provides to the browser a list of the resources to be pre fetched along with a link or uniform resource locator URL for each resource . The list may also include an indication of priority for each resource . The process of is then complete. The browser uses the links to pre fetch the listed resources before the network page is rendered. In some embodiments the resources are retrieved by the browser as a low priority task in background mode when the browser is otherwise idle or when the client device is otherwise idle.

In some scenarios all resources selected for pre fetch may have been successfully retrieved before the rendering of predicted next network page is completed by the browser . In other scenarios only some of the resources selected for pre fetch may have been retrieved before the rendering of predicted next network page . It is also possible that the rendering of predicted next network page occurs before any of the resources selected for pre fetch were retrieved. It is even possible that the predicted next network page is never rendered because the next page selected by the user for viewing is a page other than the predicted next page.

With reference now to shown is a flowchart that provides one example of the operation of a portion of the resource pre fetch engine according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the resource pre fetch engine as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

Beginning at box the resource pre fetch engine obtains a network page from the page prediction engine . This network page is not the page that the user is currently interacting with but is instead a predicted next page and as such includes partial predicted page data . At box the resource pre fetch engine parses the predicted next network page to find one or more resources referenced within the page. These referenced resources and their attributes were described above in connection with .

At box the resource pre fetch engine evaluates at least one attribute of one of the referenced resources according to a pre fetch criteria which is described below. At box the resource pre fetch engine determines whether the current resource meets the pre fetch criteria and if so adds the current resource to the pre fetch list at box . In some embodiments the resources are retrieved as a low priority task in background mode when the browser is otherwise idle or when the client device is otherwise idle. At box the resource pre fetch engine determines whether any more resources on the predicted next network page remain to be processed and if so processing continues at box where the attribute of the next resource is evaluated according to the criteria and added to the pre fetch list if the criteria is met.

If it is determined at box that all resources have been evaluated for pre fetch then at box the list of resources to be pre fetched along with a link or uniform resource locator URL for each resource is provided to the browser . The list may also include an indication of priority for each resource . The process of is then complete. The browser uses the links to pre fetch the listed resources before the network page is rendered. As described above the rendering is performed when a user action causes the predicted next network page to be the visible chosen or current page so the timing may vary.

Various resource attributes were described above in connection with prioritizing retrieval and these same attributes may be used as retrieval criteria at box to determine whether or not a particular resource is added to the pre fetch list. As one example resources below a maximum size may be retrieved or resources above a minim size may be retrieved. As another example resources of certain types may be retrieved while resources of other types are not retrieved. As yet another example resources immediately visible to the user above the fold may be retrieved while resources not immediately visible to the user are not retrieved.

In some embodiments the determination made in box to retrieve a set of resources is combined with the prioritizing described in connection with . For example if the resource attribute criteria is to retrieve resources with a size larger than 256 KB then the resource pre fetch engine may further prioritize those resources larger than 256 KB to retrieve in increasing order of size or to retrieve in decreasing order of size.

The retrieval selection and prioritizing techniques of may be further refined to use capabilities or performance information for the browser and or the client device . As one example the type and or version of the browser may be used in selecting or prioritizing resources for retrieval so that unsupported resource types are not pre fetched by the resource pre fetch engine . As another example the speed of the network connection of client device or the current available bandwidth of the network connection may be used in selecting or prioritizing resources for retrieval so that more resources are pre fetched when more speed or bandwidth is available. As yet another example the type of processor on the client device and or the utilization of the processor may be used in selecting or prioritizing resources for pre fetch. As still another example the type of client device may be used in selecting or prioritizing resources for pre fetch. In some embodiments more resources are pre fetched for a client device with lesser capabilities. In some embodiments more resources are pre fetched for a client device with greater capabilities.

Moving on to shown is a schematic block diagram of the computing device according to an embodiment of the present disclosure. The computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end the computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor are the network page server application the page prediction engine the resource pre fetch engine the electronic commerce application and potentially other applications. Also stored in the memory may be a data store and other data. In addition an operating system may be stored in the memory and executable by the processor .

Turning now to shown is a schematic block diagram of the client device according to an embodiment of the present disclosure. The computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end the computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor are the browser the rendering code and potentially other applications. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memories and are executable by a respective one of the processors as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memories and are executable by a respective one of the processors . In this respect the term executable means a program file that is in a form that can ultimately be run by a respective one of the processors . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memories and run by a respective one of the processors source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memories and executed by a respective one of the processors or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memories to be executed by a respective one of the processors etc. An executable program may be stored in any portion or component of the memories including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memories are defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memories may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also each of the processors may represent multiple processors and each of the memories may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any of the processors and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. Each of the processors may be of electrical or of some other available construction.

Although the network page server application the electronic commerce application the page prediction engine the browser the resource pre fetch engine and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the resource pre fetch engine . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as one of the processors in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in flowcharts of may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the network page server application the electronic commerce application the page prediction engine the browser the resource pre fetch engine that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example one of the processors in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system. The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

