---

title: System and method for fully configurable real time processing
abstract: Provided are systems, methods, and architectures for a neutral input/output (NIO) platform that includes a core that supports one or more services. The core may be thought of as an application engine that runs task specific applications called services. The services are constructed using defined templates that are recognized by the core, although the templates can be customized. The core is designed to manage and support the services, and the services in turn manage blocks that provide processing functionality to their respective service. Due to the structure and flexibility provided by the NIO platform's core, services, and blocks, the platform can be configured to asynchronously process any input signals from one or more sources and produce output signals in real time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09454385&OS=09454385&RS=09454385
owner: SOCIETAL INNOVATIONS IPCO LIMITED
number: 09454385
owner_city: London
owner_country: GB
publication_date: 20151016
---
This application is a Continuation of International PCT Application No. PCT IB15 01288 filed on May 21 2015 entitled SYSTEM AND METHOD FOR FULLY CONFIGURABLE REAL TIME PROCESSING. PCT Application No. PCT IB15 01288 claims the benefit of U.S. Provisional Application No. 62 001 457 filed on May 21 2014 entitled SYSTEM AND METHOD FOR ASYNCHRONOUSLY CAPTURING PROCESSING AND PUBLISHING DATA STREAMS IN REAL TIME U.S. Provisional Application No. 62 028 145 filed on Jul. 23 2014 entitled SYSTEM AND METHOD FOR FULLY CONFIGURABLE ASYNCHRONOUS REAL TIME PROCESSING U.S. Provisional Application No. 62 041 566 filed on Aug. 25 2014 entitled SYSTEM AND METHOD FOR AGGREGATING AND PUBLISHING DATA FROM MULTIPLE SOURCES IN REAL TIME OR NEAR REAL TIME and U.S. Provisional Application No. 62 137 007 filed on Mar. 23 2015 entitled SYSTEM AND METHOD FOR CONFIGURING SERVICES AND BLOCKS IN A PLATFORM INSTANCE. International PCT Application No. PCT IB15 01288 and U.S. Provisional Application Nos. 62 001 457 62 028 145 62 041 566 and 62 137 007 are incorporated by reference in their entirety.

The proliferation of devices has resulted in the production of a tremendous amount of data that is continuously increasing. Current processing methods are unsuitable for processing this data. Accordingly what is needed are systems and methods that address this issue.

The present disclosure is directed to a system and method for fully configurable real time processing. It is understood that the following disclosure provides many different embodiments or examples. Specific examples of components and arrangements are described below to simplify the present disclosure. These are of course merely examples and are not intended to be limiting. In addition the present disclosure may repeat reference numerals and or letters in the various examples. This repetition is for the purpose of simplicity and clarity and does not in itself dictate a relationship between the various embodiments and or configurations discussed.

The present disclosure describes various embodiments of a neutral input output NIO platform that includes a core that supports one or more services. While the platform itself may technically be viewed as an executable application in some embodiments the core may be thought of as an application engine that runs task specific applications called services. The services are constructed using defined templates that are recognized by the core although the templates can be customized to a certain extent. The core is designed to manage and support the services and the services in turn manage blocks that provide processing functionality to their respective service. Due to the structure and flexibility of the runtime environment provided by the NIO platform s core services and blocks the platform is able to asynchronously process any input signal from one or more sources in real time.

Referring to one embodiment of a NIO platform is illustrated. The NIO platform is configurable to receive any type of signal including data as input process those signals and produce any type of output. The NIO platform is able to support this process of receiving processing and producing in real time or near real time. The input signals can be streaming or any other type of continuous or non continuous input.

When referring to the NIO platform as performing processing in real time and near real time it means that there is no storage other than possible queuing between the NIO platform instance s input and output. In other words only processing time exists between the NIO platform instance s input and output as there is no storage read and write time even for streaming data entering the NIO platform .

It is noted that this means there is no way to recover an original signal that has entered the NIO platform and been processed unless the original signal is part of the output or the NIO platform has been configured to save the original signal. The original signal is received by the NIO platform processed which may involve changing and or destroying the original signal and output is generated. The receipt processing and generation of output occurs without any storage other than possible queuing. The original signal is not stored and deleted it is simply never stored. The original signal generally becomes irrelevant as it is the output based on the original signal that is important although the output may contain some or all of the original signal. The original signal may be available elsewhere e.g. at the original signal s source but it may not be recoverable from the NIO platform .

It is understood that the NIO platform can be configured to store the original signal at receipt or during processing but that is separate from the NIO platform s ability to perform real time and near real time processing. For example although no long term e.g. longer than any necessary buffering memory storage is needed by the NIO platform during real time and near real time processing storage to and retrieval from memory e.g. a hard drive a removable memory and or a remote memory is supported if required for particular applications.

The internal operation of the NIO platform uses a NIO data object referred to herein as a niogram . Incoming signals are converted into niograms at the edge of the NIO platform and used in intra platform communications and processing. This allows the NIO platform to handle any type of input signal without needing changes to the platform s core functionality. In embodiments where multiple NIO platforms are deployed niograms may be used in inter platform communications.

The use of niograms allows the core functionality of the NIO platform to operate in a standardized manner regardless of the specific type of information contained in the niograms. From a general system perspective the same core operations are executed in the same way regardless of the input data type. This means that the NIO platform can be optimized for the niogram which may itself be optimized for a particular type of input for a specific application.

The basic structure of a niogram is designed to allow the information within the niogram to change as it moves through the NIO platform . For example different types of information can be added to or removed from a niogram e.g. a niogram containing a radio frequency identifier RFID value from an RFID tag can be modified to include an expiration date of a corresponding product from which the tag was read . Furthermore multiple niograms can be merged into a single niogram and a single niogram can be divided into multiple niograms. The NIO platform can also create and destroy niograms as needed. The ability to create niograms destroy niograms and change the internal information of a niogram enables information to be enriched contextually in many different ways by the NIO platform without changing the niogram s basic structure and this enrichment can occur in real time or near real time.

The NIO platform is designed to process niograms in a customizable and configurable manner using processing functionality and support functionality . The processing functionality is generally both customizable and configurable by a user. Customizable means that at least a portion of the source code providing the processing functionality can be modified by a user. In other words the task specific software instructions that determine how an input signal that has been converted into one or more niograms will be processed can be directly accessed at the code level and modified. Configurable means that the processing functionality can be modified by such actions as selecting or deselecting functionality and or defining values for configuration parameters. These modifications do not require direct access or changes to the underlying source code and may be performed at different times e.g. before runtime or at runtime using configuration files commands issued through an interface and or in other defined ways.

The support functionality is generally only configurable by a user with modifications limited to such actions as selecting or deselecting functionality and or defining values for configuration parameters. In other embodiments the support functionality may also be customizable. It is understood that the ability to modify the processing functionality and or the support functionality may be limited or non existent in some embodiments.

The support functionality supports the processing functionality by handling general configuration of the NIO platform at runtime and providing management functions for starting and stopping the processing functionality. The resulting niograms can be converted into any signal type s for output s .

Referring to one embodiment of a NIO platform instance illustrates a data path that starts when the input signal s are received and continues through the generation of the output s . The NIO platform instance is created when the NIO platform of is launched. A NIO platform may be referred to herein as a NIO platform before being launched and as a NIO platform instance after being launched although the terms may be used interchangeably for the NIO platform after launch. As described above niograms are used internally by the NIO platform instance along the data path.

In the present example the input signal s may be filtered in block to remove noise which can include irrelevant data undesirable characteristics in a signal e.g. ambient noise or interference and or any other unwanted part of an input signal. Filtered noise may be discarded at the edge of the NIO platform instance as indicated by arrow and not introduced into the more complex processing functionality of the NIO platform instance . The filtering may also be used to discard some of the signal s information while keeping other information from the signal. The filtering saves processing time because core functionality of the NIO platform instance can be focused on relevant data having a known structure for post filtering processing. In embodiments where the entire input signal is processed such filtering may not occur. In addition to or as alternative to filtering occurring at the edge filtering may occur inside the NIO platform instance after the signal is converted to a niogram.

Non discarded signals and or the remaining signal information are converted into niograms for internal use in block and the niograms are processed in block . The niograms may be converted into one or more other formats for the output s in block including actions e.g. actuation signals . In embodiments where niograms are the output the conversion step of block would not occur.

Referring to one embodiment of a stack is illustrated. In the present example the NIO platform interacts with an operating system OS that in turn interacts with a device . The interaction may be direct or may be through one or more other layers such as an interpreter or a virtual machine. The device can be a virtual device or a physical device and may be standalone or coupled to a network.

Referring to another embodiment of a stack is illustrated. In the present example the NIO platform interacts with a higher layer of software and or a lower layer of software . In other words the NIO platform may provide part of the functionality of the stack while the software layers and or provide other parts of the stack s functionality. Although not shown it is understood that the OS and device of may be positioned under the software layer if the software is present or directly under the NIO platform as in if the software layer is not present.

Referring to in one embodiment an environment is illustrated with the NIO platform of . As illustrated the NIO platform supports instance to instance or device and system which enables a NIO platform to subscribe from and publish to one or more other platforms broadly or specifically to a single application logic context requirement. The NIO platform provides functionality needed to receive process and or act on any input signal received from one or more external sources as represented by arrow and or from the NIO platform itself as represented by arrow . Once the input signal is handled as defined by the configuration of the NIO platform the input signal and or other signals that may result from processing may be output to one or more external destinations as represented by arrow and or to the NIO platform itself as represented by arrow .

In the present embodiment the input signals are not stored except for queuing if needed and no database or other permanent storage mechanism need be used for information handled by the NIO platform . Queuing may be handled in a variety of ways including the use of memory random access memory RAM and or other mechanisms such as a persistence layer e.g. an SQLite persistence layer . As the received input signals are handled in real time or near real time and the NIO platform is not constrained by database access limitations throughput can occur at a much higher rate than can be achieved in systems that rely on database access or that require storing data prior to processing.

In some embodiments the NIO platform allocates and de allocates functionality as needed thereby minimizing the platform s footprint.

The NIO platform provides its functionality via a generic architecture that may be configured to address specific needs. Although the architecture may be implemented as an application specific integrated circuit ASIC or as another application specific embodiment the architecture itself is configurable and accordingly highly flexible. Furthermore the architecture is able to process signals in one platform instance and then pass the processed signals back to itself for further processing in the same or another platform instance. This ability to internally link to itself enables the architecture to take advantage of multiple concurrently executing related platform instances. With each platform instance being fully configurable the architecture is able to rapidly process large amounts of information while also providing highly customizable outputs.

The NIO platform may be implemented in a manner that is relatively OS independent. For example the NIO platform may be implemented using a language such as Python. To provide additional OS neutrality design decisions may include avoiding the use of library calls that are OS specific and or may avoid the inclusion of modules that are OS specific.

The NIO platform may provide self awareness functional capability through services configured to support platform instances advanced dynamic context artificial intelligence and or system monitoring. With respect to instances pre configured services may be based on specific indices relating to signal type and source level of awareness function and actions. The services may be utilized for device and or system diagnostics and quality control. With respect to advanced dynamic context artificial intelligence custom developed composite context within a process resident within the NIO platform may be specific to a use case business process system of devices or signal producers or a single device specification.

With respect to system monitoring the NIO platform may be used to monitor the state or condition of itself i.e. the NIO platform as a self aware system. To accomplish this monitoring niograms may be generated that correspond to the current state of the NIO platform . Details contained in such niograms may range from the amount of central processing unit CPU usage of the NIO platform to an error generated from one aspect of the NIO platform . These niograms can then be processed by services and combined with internal actions to create a self aware and proactive system monitoring solution. Additionally a separate instance of the NIO platform can be set up to apply this system monitoring logic and the niograms from the internal monitoring service can be sent there.

The NIO platform may be stored and executed on the device . The NIO platform may be an application residing on the device and or may be embedded in the device . Examples of the device include single board computing SBC and onboard computing OBC platforms cellular telephones including smart phones personal digital assistants PDAs netbooks tablets laptops desktops workstations servers equipment e.g. manufacturing equipment monitoring equipment and security equipment home appliances e.g. refrigerators stoves ovens coffee makers stereos and televisions vehicles and other mobile systems e.g. air land sea and or spents vehicles whether manned or autonomous and any other device that is able to execute instructions and support some or all of the architecture of the NIO platform .

Communications to and from the NIO platform may be direct e.g. via a peer to peer network an ad hoc network or using a direct connection indirect such as through a server or other proxy e.g. in a client server model or a wireless network or may use a combination of direct and indirect communications.

Referring to one embodiment of an environment is illustrated where the functionality provided by the NIO platform is distributed as represented by NIO platforms and on devices and respectively. Although only two NIO platforms and are shown it is understood that the functionality may be distributed across many devices. The distributed NIO platforms and may communicate with one another as represented by arrows and . Each distributed NIO platform and may communicate with the external source destination only a particular one of the NIO platforms and may be configured for communication with the external source destination or one NIO platform or may be configured to receive communications from the external source while the other of the NIO platforms may be configured to send communications to the external destination .

In another embodiment of each NIO platform and may be a complete platform with full functionality and may be configured to communicate with one another and or with the external source destination in order to accomplish designated tasks. In such embodiments one NIO platform or may be offline unless needed e.g. if the other platform fails or becomes overloaded . In other embodiments although each NIO platform and provides full functionality some functionality on one or both platforms may not be used. This enables the same NIO platform to be used on multiple devices while still allocating particular functionality to one or more specific devices.

Referring to one embodiment of an environment is illustrated where some or all of the functionality provided by the NIO platform is provided by one or more storage and or processing systems that provides services from one or more remote locations such as is provided by cloud computing. It is understood that the storage and or processing systems may have distributed control with functionality provided by different entities and combined within the NIO platform .

Referring to one embodiment of an environment is illustrated where some or all of the functionality provided by the NIO platform is used only within the device . In the present embodiment the device does not communicate with external source destinations unless needed for purposes such as installation maintenance and or configuration.

Referring to one embodiment of an environment is illustrated where multiple NIO platforms and are running on a single device . Although only two NIO platforms and are shown it is understood that many instances of the NIO platform may be deployed on a single device. The NIO platforms and may communicate with one another as represented by arrows and . Each distributed NIO platform and may communicate with the external source destination only a particular one of the NIO platforms and may be configured for communication with the external source destination or one NIO platform or may be configured to receive communications from the external source while the other of the NIO platforms may be configured to send communications to the external destination .

It is understood that the environments of may be combined in various ways. For example the functionality of the NIO platform may be distributed between the device of and the cloud of .

Referring to one embodiment of a system is illustrated. The system is one possible example of a portion or all of the device of and or the external source s destinations of . The system may include a controller e.g. a processor central processing unit CPU a memory unit an input output I O device and a network interface . The components and are interconnected by a data transport system e.g. a bus . A power supply PS may provide power to components of the system via a power transport system shown with data transport system although the power and data transport systems may be separate .

It is understood that the system may be differently configured and that each of the listed components may actually represent several different components. For example the CPU may actually represent a multi processor or a distributed processing system the memory unit may include different levels of cache memory main memory hard disks and remote storage locations the I O device may include monitors keyboards and the like and the network interface may include one or more network cards providing one or more wired and or wireless connections to a network . Therefore a wide range of flexibility is anticipated in the configuration of the system which may range from a single physical platform configured primarily for a single user or autonomous operation to a distributed multi user platform such as a cloud computing system.

The system may use any operating system or multiple operating systems including various versions of operating systems provided by Microsoft such as WINDOWS Apple such as Mac OS X UNIX and LINUX and may include operating systems specifically developed for handheld devices e.g. iOS Android Blackberry and or Windows Phone personal computers servers and other computing platforms depending on the use of the system . The operating system as well as other instructions e.g. for telecommunications and or other functions provided by the device may be stored in the memory unit and executed by the processor . For example if the system is the device the memory unit may include instructions for providing the NIO platform and for performing some or all of the methods described herein.

The network may be a single network or may represent multiple networks including networks of different types whether wireless or wireline. For example the device may be coupled to external devices via a network that includes a cellular link coupled to a data packet network or may be coupled via a data packet link such as a wide local area network WLAN coupled to a data packet network or a Public Switched Telephone Network PSTN . Accordingly many different network types and configurations may be used to couple the device with external devices.

Referring to one embodiment of a system is illustrated. The system is another possible example of a portion or all of the device of and or the external source s destinations of . The system may be similar to the system of but may contain only the CPU and memory . Other components such as the power supply and I O may be external. In the present example the system may have no network capability. In other embodiments the system may access a network such as the network using a network interface such as the network interface .

Referring to one embodiment of a system is illustrated. The system is another possible example of a portion or all of the device of and or the external source s destinations of . The system may be similar to the system of but may contain only the CPU . The memory and other components such as the power supply and I O may be external. For example the system may rely on an external drive. In the present example the system may have no network capability. In other embodiments the system may access the memory via a network such as the network using a network interface such as the network interface .

Referring to a NIO platform illustrates a more detailed embodiment of the NIO platform of . In the present example the NIO platform includes two main components service classes for one or more services that are to provide the configurable processing functionality and core classes for a core that is to provide the support functionality for the services. Each service corresponds to block classes for one or more blocks that contain defined task specific functionality for processing niograms. The core includes a service manager that will manage the services e.g. starting and stopping a service and platform configuration information that defines how the NIO platform is to be configured such as what services are available when the instance is launched.

When the NIO platform is launched a core and the corresponding services form a single instance of the NIO platform . It is understood that multiple concurrent instances of the NIO platform can run on a single device e.g. the device of . Each NIO platform instance has its own core and services. The most basic NIO platform instance is a core with no services. The functionality provided by the core would exist but there would be no services on which the functionality could operate. Because the processing functionality of a NIO platform instance is defined by the executable code present in the blocks and the services are configured as collections of one or more blocks a single service containing a single block is the minimum configuration required for any processing of a niogram to occur.

It is understood that illustrates the relationship between the various classes and other components. For example the block classes are not actually part of the service classes but the blocks are related to the services. Furthermore while the service manager is considered to be part of the core for purposes of this example and so created using the core classes the core configuration information is not part of the core classes but is used to configure the core and other parts of the NIO platform .

With additional reference to embodiments of two NIO platform instances and respectively are illustrated as hierarchies that are created when a NIO platform such as the NIO platform of is launched. The NIO platform instance is an instance of a NIO platform and the NIO platform instance is an instance of a NIO platform . The NIO platforms and may be different platforms or may be different configurations of the same platform. Multiple NIO platform instances can be launched and executed concurrently either on a single device or on separate devices and each instance can be separately closed. The NIO platform instances can be based on the same NIO platform in which case the instances will have identical functionality when launched. Alternatively the NIO platform instances can be based on different NIO platform configurations in which case the instances will have different functionality when launched with the functionality of a particular instance being based on the particular configuration of the underlying NIO platform.

Each NIO platform instance and contains a core and one or more services and each service contains one or more blocks . Each NIO platform instance and may have different numbers of services running and those services may use different numbers of blocks . The services running within a single NIO platform instance or can be identical in functionality different in functionality related e.g. one service may perform one task in a series of tasks and then another service may perform the next task and or unrelated.

This hierarchical structure enables the configurability of the NIO platform to be accessed at different levels each of which offers a different level of granularity in the configuration process. Each NIO platform instance and can be configured by adding removing and or modifying the services that form the instance. A service can be configured by adding removing and or modifying the blocks that form the service by modifying the arrangement of the blocks to change the data path through the blocks by setting various configuration parameters corresponding to the service and or by enabling the service to use functionality provided by the core . In some embodiments a service can also be customized by adding removing and or modifying the instructions e.g. the source code contained in the corresponding service class . A block can be customized by adding removing and or modifying the instructions e.g. the source code contained in the corresponding block class . A block can also be configured by setting various configuration parameters corresponding to the block.

It is understood that once configured using the platform configuration information the NIO platform may be reduced to a minimal footprint. This may in some embodiments involve removing or otherwise limiting the configurable and or customizable functionality with only defined service classes and or block classes remaining with respect to the processing functionality . Similarly unused modules and or core components discussed later may also be removed from the support functionality . Even if the NIO platform is made to be no longer customizable or configurable by a user it is understood that updates and other changes may still be made to existing service classes and or block classes in some embodiments.

Removing and or otherwise limiting the configurability and or customizability may be used to ensure that the existing functionality is not changed once defined as desired. It is understood that the support functionality would still remain in the NIO platform to manage the services and or blocks in a running instance. Accordingly the NIO platform may be reduced to a more conventional application style format for distribution installation and or use for a targeted purpose although services and or blocks would still run via the core environment provided by the NIO platform .

With additional reference to one embodiment of a service based on one of the service classes of as launched in one of the instances of of is illustrated with multiple blocks . . . and M based on block classes with M being the total number of blocks contained by the service . The service may be viewed as the framework that is responsible for assembling the contained group of blocks e.g. blocks M into a workflow to define the logical path that a niogram within the service will follow. While the blocks M may not be literally linked within the service the service may manage the order in which blocks are called for processing and in so doing direct a niogram within the service to the appropriate next block. Starting the service enables an instance of the NIO platform to use the blocks functionality to process niograms. Accordingly the value of M is greater or equal to one as a service that has no blocks would provide no functionality. It is understood that the service may include blocks that are not always used such as blocks that are only executed if a particular conditional branch occurs.

While entirely custom service classes and block classes may be created and used with the NIO platform for custom services and blocks the functionality of some or all services and or blocks may be predefined either in whole or in part. For example a service directed to receiving and forwarding a particular type of message may be defined in the corresponding service class with the exception of configuration parameters for source and destination. Starting the service would automatically start the blocks to be used with the service and provide an instance of the NIO platform with the service s receive and forward functionality. The source and destination can be added via the platform configuration information or in another way such as through the use of commands issued to the service and or blocks through an interface.

In a more complex example a largely pre defined service may be modifiable by defining the behavior of one or more blocks classes for the blocks within the service either by providing original code for the block class or by selecting a predefined block class . For example the service may process the received message and forward the message to one of various different destinations depending on the message s contents. This conditional functionality may be achieved by writing instructions for inclusion in a new block class for a new block to be used in the service by writing instructions for inclusion in one of the block classes for a block that is already part of the service and or by configuring an existing block class that already enables such conditional functionality.

A single defined service may be used in multiple platform instances and a single defined block may be used in multiple services. It is understood that modifying a service by customizing and or reconfiguring the service class service may require a restart of any platform instances currently using that service for the modification to take effect as the platform instances may otherwise continue running the previous version of the service that was instantiated when launched. Similarly modifying a block by customizing and or reconfiguring the block class service may require a restart of any services currently using that block for the modification to take effect as the services may otherwise continue running the previous version of the block that was instantiated when launched.

With additional reference to another embodiment of the NIO platform of is illustrated as a NIO platform prior to being launched and as a NIO platform instance after being launched . illustrates the NIO platform with core classes service classes block classes and configuration information that are used to create and configure the core services N and blocks M of the NIO platform instance . It is understood that although not shown in the core classes service classes block classes and configuration information generally continue to exist as part of the NIO platform instance .

Referring specifically to the NIO platform instance may be viewed as a runtime environment within which the core creates and runs the services . . . and N. Each service N may have a different number of blocks. For example service includes blocks and . Service includes a single block . Service N includes blocks . . . and M.

One or more of the services N may be stopped or started by the core . When stopped the functionality provided by that service will not be available until the service is started by the core . Communication may occur between the core and the services N as well as between the services N themselves.

In the present example the core and each service N is a separate process from an operating system hardware perspective. Accordingly the NIO platform instance of would have N 1 processes running and the operating system may distribute those across multi core devices as with any other processes. It is understood that the configuration of particular services may depend in part on a design decision that takes into account the number of processes that will be created. For example it may be desirable from a process standpoint to have numerous but smaller services in some embodiments while it may be desirable to have fewer but larger services in other embodiments. The configurability of the NIO platform enables such decisions to be implemented relatively easily by modifying the functionality of each service N.

In other embodiments the NIO platform instance may be structured to run the core and or services N as threads rather than processes. For example the core may be a process and the services N may run as threads of the core process.

Referring to one embodiment of a diagram illustrates the core process and the services and N of plotted against an axis representing time. More specifically the diagram illustrates examples of stop and start times for the core process and services and N relative to one another with multiple services running simultaneously at some times and with no services running at other times.

At time t the NIO platform instance is not running. At time t the NIO platform instance is started with the core process as indicated by line . The core process generally remains running the entire time the NIO platform instance is running as the core process is needed for the NIO platform instance to exist. It is understood that if the core process crashes the services and N may continue to run as long as they are separate processes from the core process . However the core process can no longer be used to communicate with the service processes or otherwise control them and so the NIO platform instance no longer exists when the core process ends even if the service processes continue to run. If the services and N are threads of the core process then the services and N will typically end if the core process crashes.

At time t the service is started as indicated by line . At time t the service is stopped but the core process continues running even though no services are running at this time. At time t the service N is started as indicated by line . At time t the service is restarted as indicated by line . At time t the service is started as indicated by line . At time t the service is stopped. At time t the services and N are stopped. At time t the core process is stopped which shuts down the NIO platform instance . If the core process is stopped while services are still running the core process may shut down the running services before stopping.

Referring to embodiments of the service of are illustrated. Any service defined in the processing functionality of may be altered by adding removing and or modifying one or more of the blocks that form that service. Each block within the service contains instructions. The instructions within a particular block may be simple or complex. Accordingly a particular service that is configured to provide a particular function may be implemented in many different ways depending on the blocks used and the instructions contained within each block . In this respect the service may be viewed as an executable program that can be written in many different ways and then executed by the NIO platform instance .

Referring specifically to one embodiment of the service is formed from a single block . This is the minimal requirement for a service having functionality. Referring specifically to another embodiment of the service is formed from two blocks and that are linked together to form a chain of blocks. In this embodiment block feeds into block . It is understood that the blocks and may not be literally linked within the service but that the service links the blocks from an operational perspective by directing that a niogram that is an output of block becomes an input to block

Referring specifically to yet another embodiment of the service is illustrated with a more complicated block structure. Although the service is made up of a chain of blocks it is understood that the blocks may not be executed in a linear manner. In other words the blocks may include instructions that vary the execution order within the service . For example a block may contain an instruction that is conditional with the next block being selected and executed depending on how the condition is met. Furthermore it is understood that the blocks need not be literally arranged in an order of execution and that the platform configuration information is used to define the service and in some embodiments the various dependencies between the blocks 

The blocks and the arrangement of those blocks may be optimized for use with a particular service . For example the blocks may be optimized for a particular pattern of execution that corresponds to the service s processing needs.

The blocks of serve to illustrate various possible combinations that may occur within the service although it is understood that other combinations may be used that are not illustrated. In the present embodiment block is able to call or otherwise return to itself as indicated by arrow . Block feeds into block as indicated by arrow and or block as indicated by arrow . For example block may split a niogram into two niograms. One niogram may be passed to block and the other niogram may be passed to block . In another example the block may contain instructions for a conditional branch and an evaluation of the niogram may determine whether the niogram is sent to block or block . Alternatively the block may send the niogram to both block and block . One or both of the blocks and may then filter the niogram after receiving it or another block not shown may be added before one or both of the blocks or to filter the niogram before it reaches the block.

One or both blocks and may feed into block as indicated by arrows and respectively which illustrates how multiple blocks can feed into a single block. For example a niogram from each of blocks and may be passed to block where the niograms are combined or otherwise processed. In another example a niogram may be received from only one of blocks and depending on factors such as the processing within those blocks and whether a conditional statement executed in block passed a niogram to only one of the blocks and . Block feeds into block as indicated by arrow .

It is understood that a block may be called without being a link in the overall chain. For example block may use block to obtain a value e.g. perform a calculation and return a value and then continue execution with block after the value is returned. In this case arrow would not exist. The manner in which the block returns the value depends on the particular implementation of the blocks. As will be described below the blocks may be implemented so that the output of a block is routed to another block by the service may be implemented to support direct calls between blocks or may be implemented with one or more commands used to access a block. Regardless of the implementation from this perspective the blocks may be viewed as modular components of a program that can be called within the program based on the desired functionality provided by a particular block.

It is understood that although complex arrangements of blocks may be used to create the service it may be desirable in some embodiments to arrange the blocks in a single chain to create an optimized execution path. Furthermore the service of may be created as a single block in some embodiments.

While input to the service is often fed first to the initial block in a chain e.g. block input may be handled by any block within the service based on how the service and or the blocks are configured. For example input may enter block and be passed to block and or . In turn block may remain as part of the output path for block . This allows a great deal of flexibility within a particular service .

It is understood that when the present disclosure refers to a service receiving input the input is actually being received by a block within the service . Similarly output is produced by a block within the service . However as the service includes the blocks used within the service the service may be described generally as receiving input and producing output.

Accordingly a single service may be configured in many different ways. While optimizations may indicate a particular desirable service configuration for a particular use a service can be fine tuned based on factors such as the desired functionality of the service and the characteristics of the device on which the NIO platform is to run e.g. memory limitations such as cache size and throughput processor speed number of processor cores and or data rates of input data streams . This configurability enables the NIO platform to be optimized for many different environments if needed by changing the structure of the services and blocks when possible rather than the core .

Referring to embodiments of services and respectively are illustrated. In the present embodiments each block is decoupled from both the service by which it is being used and from the other blocks that are used by the service . Each block is a self contained entity that asynchronously receives input processes that input in a manner defined by the block s internal code and produces an output. The block s asynchronicity is possible because the block has no awareness that it is part of a service or that it is associated with other blocks as part of a functional chain. The block simply handles data as it arrives and creates an output.

This decoupling of the block s functionality from other blocks in the service enables each block to be reused without having to alter the code within the block itself. For example if a block was configured to call a specific destination block after finishing its own processing this call would likely have to be modified for each service in which the block was used and also if the block was moved to a different location of the functional path within the same service . Instead because the block is decoupled and the service is configured to manage the block s output the block can remain unchanged for different services or during moves within the same service even though its output may be routed differently.

By making the service responsible for the data flow path between blocks the actual block structure is simplified and need not be concerned with anything except its own processing and at the end notifying the service that output is available. Decoupling the block s functionality from the service and other blocks in this manner also enables the block to be swapped out for another block with different functionality which makes service modification easier.

This decoupling is illustrated in which represent embodiments of services and respectively. Each service and has the same number of blocks . However the order of the blocks is different and the final output is different. For example the service of has the following functional chain block input block filter block convert to niograms block compare niograms block combine niograms and block output as actuation . In contrast the service of has the following functional chain block input block filter block convert to niograms block combine niograms block compare niograms and lock output as email .

These functional chains are illustrated below in Table 1 for service and Table 2 for service in the form of source and destination information. For example each service and may manage a list table or other data storage structure with such information. It is understood that the actual order of the blocks in the data storage structure may vary as long as the services and can tell which destination block s are to be serviced with output from a particular source block.

As can be seen the order of execution of blocks and in the service has been altered in the service . Because the blocks are decoupled the alteration can be accomplished simply by modifying the order of blocks e.g. the source destination pairs in the service and requires no changes to the blocks themselves or to the blocks preceding or succeeding the blocks and

Another difference between the two services and is that the output block of sends an email rather than the actuation of . One way to perform this change in functionality is to swap out the block of for the block of . This may be done when the blocks and contain only the specific functionality required for their purpose. Another way to perform this change in functionality would be to modify the block to give it the desired functionality of the block or to create a new block with the desired functionality. Yet another way would be to set configuration parameters for the block to select the desired functionality assuming that the block already contains the functionality for producing both actuations and email as outputs. Regardless of the way in which the functionality is implemented for the blocks and the decoupled aspect of the blocks means that the preceding block or is unaware of the changes and is not affected.

With additional reference to embodiments of a service and multiple block threads are illustrated. In the present example the service includes five blocks which may also be referred to as Blocks respectively. Due to the asynchronous nature of the blocks some or all of the blocks in the service can process niograms concurrently. In other words different niograms may be concurrently processed by the different blocks of the single service . Furthermore a single block may process multiple niograms concurrently due to threading.

The ability to concurrently process multiple niograms may increase the throughput of the service . The ability to replicate one or more of the blocks by executing the block s functionality in multiple concurrent threads enables the service to dynamically scale its processing capacity as needed. For example this allows the service to increase its processing capacity to handle input surges and then reduce its processing capacity once the surge subsides.

Each block takes a period of time e.g. a second or a fraction of a second to process a single signal or niogram although it is understood that the actual rate of a particular block may vary depending on such factors as the complexity of the block the content of the niograms the processor speed of the device on which the service is running the number of processor cores and or the size of the cache. For purposes of example the block is able to process a signal and produce an output of a niogram in 0.5 seconds the block is able to process a niogram in 1.5 seconds the block is able to process a niogram in 1.0 seconds the block is able to process a niogram in 0.5 seconds and the block is able to process a niogram in 1.0 seconds.

If only one thread can exist for each block the block that takes the longest time to process a signal or niogram would determine the throughput of the service assuming that the input rate to the service is higher than the slowest block s processing rate. In this case the block would be the bottleneck and would limit the service s throughput to one niogram every 1.5 seconds if only one thread exists for each block . The blocks and would be bottlenecks if not for the block . The blocks and would not be bottlenecks as they can process more quickly than the other blocks. With only one thread for each block the service would be processing five niograms every 1.5 seconds e.g. one niogram in each block with an output of one niogram every 1.5 seconds but this would not be efficient as four of the five blocks would spend time waiting on block

One way to address this problem would be to construct the blocks so that all of the blocks in the service process niograms at approximately the same rate. However this is a relatively inefficient way to handle the problem as any changes might affect the processing rate of one or more blocks and each new service would have to be balanced in this manner. This approach would complicate the design and implementation of services within the NIO platform .

Accordingly as shown in the NIO platform is designed so that the service can make use of concurrent threads for a single block which allows the service to dynamically scale its processing capacity as needed. Continuing the previous example Block is executing at a speed of 0.5 seconds per niogram so it is processing two signals per second and outputting two niograms per second. It is assumed that Block outputs its niograms at a steady rate of one niogram every 0.5 seconds. This and other simplifications such as a block execution speed measured in seconds are used in the present example for purposes of illustration and it is understood that inputs may be irregular processing may occur much more rapidly and threading within an actual executing service may be far more complicated.

Block has three threads and running. It is noted that each thread of Block is only processing one niogram and a total of three concurrent threads will be needed to process the three niograms output by Block during the 1.5 second processing time required by Block . Block has two threads and running. Block has only thread running. Block has two threads and running.

If the input lessens the number of threads may lessen. If the input rate drops to one signal or less every 1.5 seconds only a single thread of each block would exist. If the input rate increases the number of threads may increase and Blocks and may also have additional threads. Accordingly the NIO platform is able to dynamically scale its processing capacity to handle scenarios such as varying input rates.

In cases where race conditions or similar thread collision issues may present a problem between concurrently executing threads resource locking and unlocking may be used. For example if the Block threads and are to write to a file as output it may be undesirable to allow them both to write to the file concurrently. Accordingly one thread may acquire a lock write to the file and then release the lock. The other thread cannot write to the file until the lock is released. In other cases race conditions or other thread collision issues may not be a concern.

It is noted that while intra service interactions are decoupled in the present embodiment certain blocks may be aware of sources and or destinations outside of the service . For example the block may be configured to poll or otherwise pull data from a data source and would need to be aware of the source e.g. the source s network address in order to accomplish its purpose. Likewise the blocks and may be configured with an awareness of the destination.

It is understood that some embodiments may use blocks that are implemented in such a way that the blocks are responsible for calling the next block. In other words the blocks may be coupled with a block being aware of the next block to which it should pass its output. For example a block may contain instructions identifying another block to which output is to be sent. The block may then execute those instructions when output is available and directly call the next block without needing the service to handle the output. The blocks may still execute in an asynchronous manner in such embodiments. While this implementation is within the scope of the present application it is not used in this embodiment due to the additional complexity and lack of reusability that would result from such an implementation.

Referring to a method illustrates one embodiment of a process that may be executed by the NIO platform instance of or the NIO platform instance of . In step a platform instance is launched. In step one or more services and or blocks may be configured. For example a block may be configured with customized code and or configuration parameters and a service may be configured by assigning various blocks to it and defining a data flow among those blocks and or by setting various configuration parameters. In step one or more of the configured service s and block s are started. In step input data is processed as defined by the service s and block s in the instance. In other embodiments one or more services and or blocks may be configured before the platform instance is launched.

Referring to a method illustrates a more detailed embodiment of step of . In step one or more blocks are selected or defined for use in the service . For example predefined blocks may be selected for use in their current form or may be selected and modified. Custom blocks may also be created by inserting instructions into a blank block and saving the block as a new block.

In step the service is defined by creating a new service and configuring it with information identifying the blocks to be used and the arrangement e.g. the data flow of those blocks . Configuration parameters may also be set for the service . In other embodiments an existing service may be configured by setting configuration parameters associated with the service and or by adding removing and or modifying blocks as well as by modifying the data flow defined for the blocks . In step the service is saved.

It is understood that if an existing service is to be used without modification the method would simply involve selecting that service for use as the corresponding blocks would already be associated with the service . In some embodiments the service may be created before the blocks are selected or defined and the service may then be updated with blocks and other information.

Referring to a method illustrates a more detailed embodiment of steps and of . In step a platform instance is launched which includes launching a core process. In step the core process discovers the platform instance s services using the available configuration information. Among other items the configuration information identifies whether any services are configured to auto start as represented by step .

If one or more services are configured to auto start the method moves to step . In step the service or services are started without needing additional start commands and the method then moves to step . If no services are configured to auto start the method moves from step to step .

In step a determination is made as to whether any commands have been received. If no command has been received step may repeat until a command is received. If a command has been received the method moves to step .

In step a determination is made as to whether any service start stop commands have been received. In other words whether a command has been received to start a service or to stop a currently running service . If the determination of step indicates that a start or stop command has been received the method continues to step . In step a determination is made as to whether the command was a start command or a stop command. If the determination of step indicates that a stop command was received the method continues to step where the service or services identified in the stop command are stopped. If the determination of step indicates that a start command was received the method continues to step where the service or services identified in the start command are started. Following the execution of either step or step the method returns to step .

If the determination of step indicates that a start or stop command has not been received the method continues to step . In step a determination is made as to whether a command has been received to close the platform instance. If the determination of step indicates that a close command was received the method continues to step where the platform instance is closed. This may entail closing any running services prior to closing the platform instance. If the determination of step indicates that no close command was received the method continues to step .

In step the command which is not a service stop start command or a close instance command is executed. The method then returns to step . The method may repeat from step multiple times starting and stopping services and or executing other commands if requested until the platform instance is closed. It is understood that the order of some steps in may vary such as the order of steps and . Furthermore some steps such as steps for handling errors e.g. requests for invalid commands are not shown.

Referring to a method illustrates a more detailed embodiment of step of . In step one or more input signal streams are received as defined by the NIO platform instance s configuration. For example the NIO platform instance may be configured to pull and or receive data from one or more streaming sources. These signal streams may contain any type of analog and or digital signal and may contain data. In step the signals are extracted from the signal stream in real time as defined by the NIO platform instances s configuration. This step may include filtering to separate noise from relevant signal information. In step the extracted signals are converted into niograms for internal processing as defined by the NIO platform instance s configuration.

In step the internal processing is performed which may include real time context enrichment. The particular processing and context enrichment if applicable that occurs depends on the configuration of the NIO platform instance . In step output is produced by the NIO platform instance as defined by the platform instance s configuration. The output may be in the form of a niogram and or any type of signal including data of any format type and or actuation signals.

Referring to a NIO platform illustrates a more detailed embodiment of the NIO platform of the NIO platform of or the NIO platform of from a platform perspective and a stack perspective FIG. B . For purposes of example the NIO platform is written in the programming language Python but it is understood that any suitable programming language can be used including but not limited to languages such as C . The NIO platform is built on a core . When launched a core process creates a core server generally referred to herein as the core which forms the underlying structure of the NIO platform .

Service components include services and blocks from a functional perspective even though the services and blocks are illustrated separately in the stack of . As previously described the service components are responsible for user defined functionality by enabling block and service functionality to be defined and changed. Much of the functionality in a service component can be user specific which allows for a high level of customization.

In the present example the service components are provided as service classes that define how services are created and executed. The execution of services includes routing signals executing commands and defining class structures. Some or all of the service classes that form a service component can be extended to define new functionality. This provides a large amount of flexibility in a neutral manner as a user can define whatever functionality is desired through the service components and that functionality will be executed by the NIO platform .

Generally the service components in one platform instance have no dependency or awareness of another platform instance s service components which allows for each particular platform instance to be configured without having to take into account how the configuration would affect other platform instances. Furthermore changing functionality in a service component has no effect on the core . This ensures that the core does not have to be modified to be compatible with the service components .

In the present example from a functional perspective the service components include blocks block classes block instances also referred to simply as blocks block groups commands services and niograms.

In the NIO platform blocks classes may include classes for both custom blocks and blocks having predefined functionality such as RFID block s short message service SMS block s sensor block s programmable logic controller PLC block s and global positioning satellite GPS block s . Although not shown it is understood that many other blocks may be defined for use with systems using Electronic Product Codes EPCs a trademark of EPCglobal Inc. of Lawrenceville N.J. Low Level Reader Protocol LLRP information email e.g. simple mail transfer protocol SMTP hypertext transfer protocol HTTP documents and or any other protocols.

Blocks are classes that specify the metadata template and computational functionality of block instances. In the present example blocks are built from block classes that extend a BaseBlock class and can specify custom behavior by overriding any of the following five basic methods provided by the BaseBlock class BaseBlock.initialize BaseBlock.configure BaseBlock.start BaseBlock.stop and BaseBlock.processSignals. These methods are used by the service that corresponds to the blocks .

The BaseBlock.initialize method is called to instantiate the block using the corresponding block class . The BaseBlock.configure method is called to configure the block after initialization using a saved block configuration. The BaseBlock.start method is called to start the block after instantiation and configuration. The BaseBlock.stop method is called to stop the block e.g. when the containing service has been stopped . The BaseBlock.processSignals contains the main processing functionality provided by the block . The BaseBlock.processSignals method processes a possibly empty list of incoming signals and notifies the service when done e.g. via a notifySignals method which is discussed below .

A block instance is created when a block is instantiated from a block class . A block instance may be viewed as the fundamental unit of computation in the NIO platform and may be customized and configured as prescribed by the block class being instantiated. A block instance only exists inside a service . Accordingly when a service is started or stopped the blocks inside that service are also started or stopped. In the present example of the NIO platform there is no concept of a block running outside a service .

Block configurations which are used to configure blocks can be reused in different services and may be viewed as saved configurations of blocks . When the configuration of a block is changed it will be changed for all blocks in all services that contain it. However if a service is running the configuration of the running block instance may only be updated after the service is restarted.

In other embodiments a block instance may be updated without restarting the service . For example if the block instance is not currently in use by the service the block instance may be stopped reconfigured with the new block configuration and restarted. Alternatively if not in use the block instance may be destroyed and a new block instance may be instantiated with the new block configuration. In such embodiments the service may continue running or may be paused rather than stopped and restarted.

Outside agents e.g. other services and or external APIs may modify the behavior of specific blocks via a command API discussed below . Within the command API block instances may be referenced by a service level block alias and or a block group level. For this reason globally unique block identifiers are not necessary in the present example although they may be used in some embodiments.

Block instances can directly receive and send signals without going through the service . In this respect a block can serve as an interface through which signals can enter the NIO platform and be sent from the NIO platform .

With additional reference to one embodiment of a hierarchy is illustrated with a single service blocks and block groups and . Block groups provide re usable assemblies of block configurations that can be dropped into a service like other blocks. The configuration of a block group resembles a service in that there is a list of blocks and block mappings to define the flow of niograms between the blocks . Whenever one of these inner blocks produces niograms the block group s logic handles the routing of those niograms to the next blocks in the chain similar to how a service would handle such routing. For example the block group may include one or more controllers e.g. one or more blocks or other control mechanisms containing the logic to handle routing within the block group to control the data flow within the block group. In such embodiments the service may treat the block group s control block as simply another block within the service and may communicate with the control block just as with other non grouped blocks.

In the present embodiment the block groups and specifically define entry and exit points for niograms. In contrast niograms may enter and leave the service through any properly configured block . In other embodiments the block groups and may not specifically define such entry and exit points.

Block groups can be nested in some embodiments with a block group forming part of another block group. This is shown in with block group nested inside of block group . A nested block group may only communicate with the service through the higher level block group. For example block group may only communicate with the service through block group rather than directly. In other embodiments the service may have direct access to nested block groups.

Since a block group is to be used inside a service the service may need to access commands discussed later of the inner blocks . In the present example of the NIO platform this may be accomplished by defining command mappings inside the block group s configuration. After these mappings are defined the block group knows to pass the command down to one of the inner blocks when a certain command is called on the block group. It is understood that not every inner block command may need to be exposed to the service in the block group s command mappings. Accordingly access may be provided based on such factors as the particular functionality of the block group and how that functionality is used by a service .

While blocks have specific entry and exit points for niograms block groups may have more than one entry and or exit point. More specifically a block only has one possible entry point for use by previous blocks in a service chain. In contrast a block group has many blocks that could be considered the starting point for niogram processing. As a result one of the configuration options of the block group is defining one or more starting points for niogram processing. Then when a service passes niograms to the block group those niograms will be forwarded to each block in the list of starting points. Similarly the block group can be configured to define a list of end points. When blocks specified in this list produce niograms the block group s logic handles the process of notifying the parent service and or the parent block group of those niograms.

For purposes of example one embodiment of a block group may include various configuration options such as blocks blockMappings commandMappings startPoints and endPoints. An object blocks provides a mapping of the block names of all blocks within a block group to the unique block alias of each block . An object blockMappings provides a mapping of the block aliases to a list of the next block aliases that fall in the chain of the block group i.e. which block feeds into which block . An object commandMappings provides a mapping of commands to inner block commands.

An array startPoints is an array of strings that defines the block aliases that should be used as the starting points of the block group. When niograms are delivered from the service to the block group the blocks listed in the startPoints array will receive the niograms for processing. An array endPoints is an array of strings that defines the block aliases that should be used as the ending points of the block group. When blocks listed in the endPoints array produce niograms a notification will propagate up outside of the block group.

With additional reference to as described previously services are the main organizational component of the NIO platform s configurable processing functionality. Each service maintains a block router a block controller for each block M its own configuration parameters a list of block instances for that service and an associative list of block aliases. In the present embodiment where the service is a process the service process may handle all communications between the service and the service manager . In other embodiments the block router or another component within the service may handle such communications.

The block controllers M serve as intermediaries between the block router and their respective blocks M. In performing this intermediary function the block controllers M mimic both the block router and the blocks M. For example the block router may instantiate the block controller which in turn instantiates the block instance . In other embodiments the block router may instantiate the block controller and the block instance . After instantiation the block router communicates with the block controller as though the block controller is the block . Similarly the block communicates with the block controller as though the block controller is the block router . Accordingly removal of the block controllers M would not prevent communications between the block router and the blocks M but would remove the functionality provided by the block controllers M from the service unless that functionality was included elsewhere in the service e.g. in the block router and or the blocks M .

The block controllers M may be configured to perform error handling and or other functions for their respective blocks . Generally only functions that are likely needed by many or all blocks may be provided by the block controllers M. This enables a generic block controller to be used for a block regardless of the functionality of that particular block. Accordingly each block controller M is identical in the present example. In other embodiments block controllers having different configurations may be used for different blocks based on the need of a particular block and or other criteria.

The block controllers M may be configured to make certain decisions about whether to pass information to the block router . For example when the block throws an error the error is caught by the block controller . The block controller may then decide how to handle the error including passing the error up to the block router ignoring the error and or taking other action. For example if the error indicates that the block instance has stopped working the block controller may proactively notify the block router or may wait to notify the block router until the block router attempts to use the block instance. Removal of the block controller would remove this error handling functionality so that when the block throws the error the block router would catch it.

The block router handles data flow among the blocks M by defining the flow of niograms between blocks M within the service . More specifically communication between block instances within the service is managed by the block router via a Blockrouter.notifySignals method and a processSignals method. The Blockrouter.notifySignals call is issued by a block that has output ready. The Blockrouter.notifySignals method identifies the source block and contains the niogram s forming the output. For example the Blockrouter.notifySignals may be implemented as Blockrouter.notifySignals source block identifier niogram s .

In the current embodiment this call is made whenever a block within the service has output and the block need not be aware of the service at all. In other words the block receives input processes the input calls Blockrouter.notifySignals and is done without even knowing that it is part of a service. In other embodiments the block may know the service of which it is a part which enables the block to notify the signal to the particular service . Although the output itself is passed as a parameter in the method call in the present embodiment it is understood that other processes may be used to transfer the output. For example a pointer to the output may be passed rather than the output itself.

When Blockrouter.notifySignals is invoked the block router looks up the source block in the routing table to determine the destination block s to which the output should be directed. The block router then calls processSignals on each of the next blocks in succession. The processSignals method identifies the destination block and contains the niogram s to be processed e.g. the niograms that were the output of the source block . For example the processSignals method may be implemented as processSignals destination block identifier niogram s . Although the niogram s themselves are passed as a parameter in the method call in the present embodiment it is understood that other processes may be used to transfer the niogram s . For example a pointer to the niogram s may be passed rather than the niogram s themselves. The block router may with each call for processSignals launch the called block instance in a new thread of the service process.

In the present example the blocks operate asynchronously i.e. each block executes independently of other blocks . When a block publishes a niogram to another block the receiving block executes immediately. This means that there is no buffering of niograms between blocks except as needed e.g. buffering may occur if a thread pool is used and there is no currently available thread for the receiving block and data passes through the service as quickly as the blocks can process the data. The processing speed for a given block may depend on the complexity of the block s instructions as well as on factors outside of a block s control such as the speed of the device s processor and the amount of processor time allocated to the block s thread.

Services are started and stopped by commands issued through a service API. When a service receives the start command it starts all blocks contained by the service . Similarly when a service receives the stop command it stops all blocks contained by the service . It is noted that the blocks may not actually be started but simply notified that the service encapsulating them has been started. If desired the blocks can then use the notification hook to execute some functionality e.g. a block that polls an external API and needs to know when to start polling could use the notification as the polling trigger .

In some embodiments stopping a service may result in the loss of any information e.g. the local state in any corresponding block instances. For example in the current example that uses Python objects for block instances block objects can be wiped out by calling the Blockinstance.destroy method. In other embodiments it may be desirable to maintain the local state after a service is stopped. For example instead of wiping out the local state of instantiated blocks when a service is stopped the service can instead be paused to stop the service s execution temporarily without losing potentially valuable data. This may be accomplished by issuing the stop command to all the blocks in the service without doing the normally associated cleanup e.g. without calling Blockinstance.destroy and or in other ways.

Commands are used to interact with blocks and must be reachable from outside the blocks . Accordingly how a block defines and exposes a command needs to be known. For example a block may be used to provide SMS functionality. To accomplish this the block may be configured to expose a command sendSMS. For the block to function within the NIO platform the method for actually sending an SMS would be written in the block in executable instructions and then the method would have to be declared as a command to make it reachable through for example a REST API. A command to call the method may be formatted in various ways depending on the particular implementation of the block structure such as a name e.g. the block s method name title e.g. a descriptive name and arguments. It is noted that this may be the same command structure used to start stop services.

As previously described the niogram is the primary mechanism for intra service data transmission e.g. between blocks block groups . All blocks may accept and emit generic niograms of a base niogram class. The base niogram class generally has no required fields and does not require validation. The base niogram class simply exposes a way to add or remove attributes and serialize de serialize the niogram into different forms e.g. JavaScript Object Notation JSON . In the present example an instance of the base niogram can add or remove attributes freely.

The base niogram can be subclassed for use in a block . However in the present embodiment the NIO platform will not maintain any awareness of these subclasses and other blocks will expect base niograms. In general blocks should not rely on processing a sub class of the base niogram unless it is mandatory. Using only the base niogram class ensures that blocks can be reused in different services with minimal impact. Filtering of blocks should generally be done via a type attribute of the niogram rather than the class type. Accordingly while the generic niogram class can be extended for convenience and or encapsulation only the attributes of an incoming niogram should be taken into account by a receiving block .

Another benefit of using the base class of niograms is to enable real time cross referencing. For example a niogram could start out containing data from one source and then have its information enriched using data from another source. The resulting niogram would contain information from both sources rather than having to carry around multiple niogram types.

With continued reference to the modules are modules containing predefined code that the NIO platform may use itself and that blocks may also use. The modules may provide functionality defined with respect to each module such as a logging module a security module a threading module a communication module a scheduler module a persistence module and or a web server module . Some or all of the modules are designed so that they can be exchanged for different implementations of the same functionality without affecting existing blocks or platform functionality. A role of the modules within the NIO platform is to provide swappable functionality for different platform instances without affecting the blocks and the core . The modules provide APIs that can be called by blocks and the core . The result of the API call is defined by the functionality of the called module .

The functionality defined in the modules spans an entire platform instance. Accordingly when the functionality within a module is changed the entire platform instance will use the new version of the module. For example if the logging module is changed to log to a remote database instead of a local file all logging calls in the core and in the services will start logging accordingly. However such changes may require a platform instance restart to take effect.

The modules support the ability of the NIO platform to run within different environments without having to modify the core design of the NIO platform . For example if a particular environment does not support some needed feature the module responsible for that feature can be reconfigured or replaced with functionality that is supported by the environment. Accordingly by changing modules as needed platform instances may be run in varied environments that have different needs.

Depending on the functionality of the particular module a module may need to initialize its functionality based on variable data. For example the logging module may need a file name where the information is saved while the communication module may need a list of current publishers in the platform instance. In order to accomplish this both the core and the services initialize the modules by calling a setup method and passing context information with this data.

For services the module s initialization data may come directly or indirectly as part of the service s initialization data. For example the data may be provided indirectly by providing the name of the configuration file where the data for the module resides. For the core the data may reside in a system wide configuration file that can be read during start up and then used for initializing the module .

The logging module is used to provide logging functionality and like all of the modules may provide a customized solution or may use an existing solution such as Python s built in logging module. At initialization the logging module receives parameters detailing adapters that are active in the NIO platform which may include adapters for logging to a local file for logging to a shared database e.g. MySQL and or for creating a niogram and publishing the niogram through the NIO platform . In the present example the logging module exposes two classes one for logging and one to retrieve logged information. This enables the core and services which may be separate processes to log to a single environment.

The security module enables blocks to interface with internal or external security applications. In the present example the security module provides an authentication method and an authorization method both of which may be overridden. The authentication method enables the security module to authenticate a user. This method can take arguments and will return an instance of the SecureUser class see below . Examples of authentication include username password OAuth Secure Token and MAC Address. The authorization method enables a consumer of the security module to be able to authorize an authenticated user e.g. a SecureUser against a certain set of SecureTasks. The existing forms of authentication include access control lists role based security and User Group Other Permissions e.g. 755 . This enables the blocks to use the same security implementation as the core without being concerned about how the security is actually implemented.

In addition to overriding the methods of the security module a secure implementation may also override two objects that can be secure which are SecureUser and SecureTask. SecureUser is a class that represents a user. There are no required fields and these objects will be returned by the authentication method. When implementing the security module this class should be overridden to map to users in the secure system. SecureTask is a class that represents something to be done. In general a SecureUser either can or cannot perform a SecureTask. These tasks will be passed to the authentication method and SecureUsers will be authenticated against them. The security module should override this class with tasks that it wishes to secure.

The threading module provides threading support and may provide one or more threading options. For example two threading modules may be available with non native threading used only when needed. In the present embodiment the main NIO platform process may not need any thread customization and can run under Python s regular threading module. Services and blocks however may benefit from having a large number of light threads and the ability to launch asynchronous tasks in a short amount of time. Accordingly the NIO platform can provide a wrapper for Python s threading functionality with the objective of making it transparent to a developer and allowing switching from one threading mode to another. The threading module that will be in effect for a particular service may be specified through a setting.

The communication module enables services within a platform to subscribe and publish niograms. The niograms can be transported within the platform instance or between platform instances. The communication module may use ZeroMQ or a similar library as a publish and subscribe mechanism. It is noted that queuing may occur between services if needed and such queuing may be handled by the communication module via ZeroMQ or another selected library.

The communication module exposes two classes a publisher class and a subscriber class. Each class may include a list of arguments that are treated as flags and a subscriber matches a publisher when all flags are matched. All functionality handling the subscription publication mechanism is controlled within the individual communication module that the NIO platform is running. When a service wants to publish it simply publishes to the communication module and the communication module determines where the published niograms will go.

For example assume there are four publishers A D as follows A publisher type RFID source Dock Door B publisher type RFID source Conveyor C publisher type BarCode source Conveyor and D publisher type RFID source Shelf . A subscriber may designate the publishers to which it is subscribing as follows. A subscriber type RFID would receive publications from A B and D. A subscriber type RFID source Dock Door Conveyor would receive publications from A and B. A subscriber source Conveyor would receive publications from B and C.

The scheduler module facilitates the execution of tasks at scheduled intervals or at a single point in the future. The scheduler module may be included in the NIO platform so that the scheduler can be replaced if issues arise with a particular scheduler in a given environment. The scheduler module operates via instances of a job class which will be needed only to cancel the job at the end. The implementation of the scheduler module is responsible for initializing and terminating the underlying scheduler.

The persistence module enables blocks and core components to persist certain information relevant to them that will survive through a platform instance restart. The persistence module can choose to save wherever and however it wants e.g. in a flat text file or a local database . It exposes several methods that can be used within a block to access this functionality such as save load and clear.

The web server module enables services and or blocks to expose a web server for interacting on an isolated port. In addition the core may use the web server module to expose a web server that hosts the API . The web server module provides an interface for each to do so using several methods such as open handle and close. The web server module may use a library such as the CherryPy library in Python. This removes the core dependency of CherryPy and allows block writers to utilize the same web server functionality as the core . This not only allows other libraries to be substituted but also allows block writers to easily expose web servers without having to worry about conflicting with the core s API .

Services which operate as different processes in the present example can ease the load on the core process by receiving data directly through their own web server. Without this blocks services use commands to receive data through HTTP but those commands are regulated and passed through the core . By using the web server module the blocks can listen directly to a port for incoming HTTP requests and handle the requests accordingly without loading the core process.

In the present example the core includes an API a service manager and a configuration manager . The configuration manager includes configurations a loader and discovery functionality which may be part of the loader in some embodiments. In other embodiments the configuration manager may not exist as a component but the loader discovery functionality and the configurations may continue to exist within the core e.g. as part of the service manager or elsewhere . The core may also include core components in some embodiments. The core maintains the services provided by the NIO platform . The core is not directly exposed to the service components and can use the modules .

The API represents multiple APIs but it is understood that blocks and block groups may be able to receive and or send information without passing through the API in the core . For example a block may be able to send and receive SMS messages without using the API . It is understood that many different APIs and API calls may be defined and that the examples described below are only for the purpose of illustrating how various components of the NIO platform may be accessed and managed. In the present example the API includes a block API a block configuration API a command API a mechanism for providing custom APIs and a service API.

The block API enables a user to alter the state of the blocks loaded in the NIO platform . For example the block API enables a user to add reload and or remove blocks without having to restart the instance in which the blocks are located. For purposes of example the block API follows the create read update delete CRUD model exposing four methods to interact with blocks as well as an instances endpoint to interact with a block s instances.

A create method adds a new block to an instance and may be accomplished in multiple ways. For example a file module and or package may be attached for use as the block a file name where the block code is loaded may be referenced a remotely hosted block may be referenced and or a class may be specified and the NIO platform may be configured to locate and retrieve the class s code.

A read method returns a list of blocks and therefore exposes the functionality of the NIO platform . In addition to the list of blocks the read method may return other block meta information such as version dependencies and install time.

An update method refreshes a block in the NIO platform . This may include reloading the block s code re validating and updating references. The update method may not update the block code for block instances that are currently in running services . In such cases the service may have to be restarted to realize the block code. In other embodiments a block instance may be updated without having to restart the service .

A delete method enables a block to be deleted from the NIO platform . Any block instances of the block will also be deleted. Any blocks that are in running services will continue to run but when the service is restarted an error will be thrown and the service will not be able to start unless the service is updated to reflect the deletion.

An instances method enables interaction with the instances of a block . For example instances may be viewed as a custom endpoint that is essentially an alias for instances block BlockName. The instances method allows a user to modify the block instances associated with a given block . This will be discussed in greater detail below with respect to the block instance API.

The block configuration API enables a user to alter the state of the block instances loaded in the NIO platform . Because block configurations are configured instances of blocks some API calls can happen through the previously described block API. For purposes of example the block configuration API follows the CRUD model but may also define some alternative methods.

A create method adds a new block configuration. To create a block configuration a relevant block must exist for the configuration. As a result configuration creation can go through the specified block s API endpoint within the block API. Configuration creation can also go through the NIO platform s block configuration API as long as a valid block is specified.

A read method returns a list of block configurations although there may be multiple ways to see the block configurations that are configured within the NIO platform . For example by hitting the main block configurations endpoint all configurations in the NIO platform will be returned. Further refinement can be achieved by specifying a block name as a parameter or issuing the GET to the block configuration s endpoint. The GET calls will return the configuration s name as well as the configuration defined within the block .

An update method updates the configuration of a block configuration on the NIO platform . Blocks that are part of a currently running service will not have their configuration updates realized until the service is restarted.

A delete method enables a block configuration to be deleted from the NIO platform . This removes a block configuration from the NIO platform but not the block itself. If the block is part of a running service the service will continue to run with the original block code. When the service is restarted an error will be thrown indicating the block cannot be found.

The command API enables a user to interact with previously described command handlers that have been defined to expose commands for blocks . Services and blocks can both be commanded. However in the present embodiment because blocks do not stand alone but exist within a service the caller must go through the service to command a block . Depending on the particular implementation a command may be called in many different ways including hypertext transfer protocol HTTP methods such as GET and POST. The block being called should define the proper handling for each type of allowed call.

A command method can be used to command a block inside a service . For example the method may be structured as services ServiceName BlockAlias commandName. The root of this API call is the service since the block inside of that service is what will be commanded. If the specified service does not exist an error will be thrown. The next component in the method is the BlockAlias. By default this will be the block configuration name. However if a service builder wishes to include more than one of the same blocks within a service a block alias can be defined for each configuration of that block . The final component is the command name. This command must be a valid command as defined by the block connected to BlockAlias.

The mechanism for defining custom APIs leverages the ability of blocks to define custom command handlers. Because of this custom APIs can be written as blocks and implemented as block configurations within a service . For example a service builder can drop an API block into any point in a service . The API block does not affect the operation of the service but does provide a new API endpoint that can be used to leverage attributes of the service at the point where the block is inserted.

The service API enables a user to alter the state of the services in the NIO platform . For purposes of example the service API follows the CRUD model as well as a command model that allows a user to start stop a service .

A create method adds a new service to the NIO platform . The specification of the service e.g. blocks and block mappings may be included in the body of the call.

A read method returns a list of services and their configuration. This information may include the blocks within a service the state of the service e.g. running or stopped and any other configuration options specified when the service was created.

An update method updates a service s configuration. If the service is currently running the configuration update will be accepted but the changes will not be realized until the service is restarted.

A delete method removes a service from the NIO platform . If the service is currently running this call will return an error. The service should be stopped before being deleted.

A command method is used to start or stop a service . If a problem exists with the configuration of a service e.g. there are non existent blocks block instances with an invalid block and or other validation issues the call will return an error.

With continued reference to in the present embodiment the configuration manager manages configurations for the current instance of the NIO platform loads services and blocks for inspection if needed and performs auto discovery. Ideally the core has no dependency on its functionality e.g. the blocks or its configuration e.g. the block instances and services . This lack of dependency enables the use of relocatable instance configurations such as one or more directories specified by a user. Then when an instance of the NIO platform is launched the location of the instance configuration will be identified and the NIO platform will load the instance s blocks services and other needed components from that location. This enables a user to version control their configurations create multiple configurations on the same machine and easily share and inspect their configurations.

Configurations may be represented within the NIO platform in many different ways. For example block instances and services may use JSON flat files SQLite databases and or zip files while blocks may use python files or python module directories. It is understood that these are merely examples and that many different formats may be used to represent configuration information.

The NIO platform may include different types of configurations depending on what part of the NIO platform is being described. Examples include a core configuration a platform configuration a core components configuration a service configuration and a block configuration. It is understood that these configurations may be stored as separate files or may be combined. Furthermore any of these configurations may be divided into multiple configurations or combined in many different ways.

The core configuration is directed to settings related to the core . These values may be private to the core and visible to the services . The platform configuration is directed to settings for the entire NIO platform . These include all settings that are visible to the core and to the services . The core components configuration is directed to settings related to a specific core component. The service configuration is directed to settings related to a specific service . The block configuration is directed to settings related to a specific block .

The NIO platform may use a configuration data file that details what is included in the NIO platform . This data file may be different from what is actually inside the configuration directory. For example if a user copies a block file into a block directory the block file may not be picked up by an instance until the block file is loaded via the block API. At this point the instance may load that block into the configuration data file. Similarly block instance configurations may be copied to the directory but may not be recognized until the instance is restarted. In other embodiments an instance restart may not be needed in order for the block instance configurations to be recognized.

In some embodiments the data may reside at a remote location e.g. in a remote database or a data structure server which allows definitions to be shared among different platform instances. In such embodiments the handler to use in loading a particular configuration may be specified through a platform setting. The NIO platform would then instantiate the specified handler and use it to fetch the instance configuration. One example of an instance configuration directory for the NIO platform is illustrated below with comments in parentheses.

With continued reference to the core components are modules containing predefined code that the NIO platform may use. The core components provide functionality to the NIO platform and may include modules such as a monitoring module a messaging module a communication manager module and or an instance distribution module .

The core components are somewhat different from core functionality provided by the configuration manager and service manager . While core functionality is generally hidden from block writers and required for operation of the NIO platform core components are swappable components similar to the modules that are positioned within the core and provide functions usable by the core . Like the core functionality the core components are hidden from block writers unlike the modules . Unlike the core functionality the core components are not required for the NIO platform to run. However it is understood that certain implementations of the NIO platform may rely on the core components due to the platform s configuration in which case the functionality of one or more of the core components would be needed to provide the desired functionality. In other words the NIO platform might run without the needed core components but would be unable to accomplish certain tasks. In other embodiments the NIO platform may not start without the needed core components .

With additional reference to one embodiment of an environment that is internal to the NIO platform illustrates the communication manager module serving as a broker for all processes that participate in publish subscribe operations. To accomplish this the communication manager module interacts with the previously described communication module . When a service containing publishing subscribing functionality is launched the communication manager module assigns two ports to the service . One port is for subscribing to management data and the other port is for publishing management data. The communication module that is being used by the service tracks these ports for the service.

The communication manager module subscribes to the publisher in the service e.g. the communication module corresponding to the service . When the communication manager module receives a message from the service the communication manager module broadcasts the message to existing services. This aids in maintaining a synchronized state among all services regarding the publishers in the NIO platform . In some embodiments where multiple platform instances are running concurrently the communication manager modules of the different platform instances may share an internal channel to aid in communications among the various instances. In other embodiments where multiple platform instances are running concurrently one communication manager module may act as a broker for the other communication manager modules.

The basic communication process provided by the communication module and the communication manager module is illustrated in . For purposes of illustration each step is labeled in as a number in a circle. In step the communication manager module populates a service context received from the service manager with channel information for a new service . This includes the subscribe publish ports introduced previously. In step the service manager passes the context with the channel information during the initialization of the new service

In step the new service s communication manager opens a publisher via the communication module that is being used by the service and provides its own information to the communication manager module . The new service s communication module also opens a subscriber for receiving information about other services. In step the communication manager module broadcasts the publisher information received in step to the other services such as a service . In step the other service uses its communication module to open a subscriber to the publisher of the new service . The service can then receive communications to which it is subscribed directly from the service

It is understood that the described communication process may be accomplished in many different ways. For example while the present embodiment illustrates a processes that uses the communication manager module to aid in establishing direct communications between the communication modules and the communication manager module may continue to receive and broadcast messages published by the communication modules and . In other embodiments the communication modules and may not communicate directly and may subscribe and publish only to the communication manager module .

Referring again to the instance distribution module may be used when more than one platform instance is sharing the services . For example in a distributed system where multiple platform instances work together with the purpose of sharing the load of running intended services information about the platform instances currently in the distributed system has to be maintained. This information enables each platform instance in the distributed system to be able to find out if the other instances are running. For example each platform instance may ping the other instances and when an instance is detected to be non functioning may remove any existing dependencies to the non functioning instance.

The instance distribution module maintains a list of other platform instances in the distributed system as well as metadata about each platform instance e.g. how long each instance has been running how many services are running in each instance communication ports and or other information . In some embodiments an instance distribution module will reside on every platform instance within the distributed system and self update when platform instances are added or removed. Whenever this list is updated relevant information will be published through the communication module for blocks and core components to consume.

To accomplish this the instance distribution module in each platform instance subscribes to the instance distribution module in each of the other platform instances. When the instance distribution module of an instance detects a change e.g. a new instance or a dead instance it publishes that relevant information to the remaining instance distribution modules . The instance distribution modules receiving this information then update their respective lists accordingly. Publishing may be centralized or distributed.

Because load balancing tends to be dependent on the way services are built and the metrics of each service e.g. throughput the actual balancing process of launching new platform instances and tearing down platform instances may be performed within a service . This places the responsibility of load balancing on the services . In other embodiments the core may take a larger role in load balancing.

Referring to the messaging module provides a way for external systems to send and receive information from the NIO platform . It is understood that such communications may be accomplished in many different ways and may vary depending on the implementation of a particular external system. For example some external systems may inquire about the data available and formulate a request based on the response while other external systems may know exactly what data to request and what data to provide. In some embodiments the messaging module may be replaced by using commands in conjunction with the web server module .

With continued reference to the service manager handles the interaction of the core with the services running in a platform instance. The service manager handles starting and stopping services and may also manage a service s incoming commands e.g. commands received via the REST interface API . The service manager may use functionality provided by the modules and core components . The service manager may be accessed from outside the NIO platform via the API .

Referring to one embodiment of an environment that is internal to the NIO platform illustrates a service and the core . As previously described the service process handles communications with the service manager such as commands received through the REST API . The block router handles intra service communications between the blocks via the corresponding block controllers in embodiments where the block controllers are present . The loader and discovery functionality may be used by the service manager to load service and or block classes for discovery purposes. External sources destinations and can communicate via blocks and or via the REST API .

Referring to one embodiment of an environment that is internal to the NIO platform illustrates various components of the NIO platform of interacting to launch a platform instance and a service . For purposes of illustration each step is labeled in as a number in a circle.

After a new core process is launched the core process accesses the configuration manager and retrieves one or more configurations in step . The configuration provides information as to which if any modules and core components are available within the NIO platform . The core process then for each module that is available creates and initializes the module for use in step . In step the core process for each core component that is available creates and initializes the core component .

In step the service manager is started. In step the service manager accesses the service configuration information via the configuration manager . In step the service manager then calls the loader discovery functionality to discover all the services and blocks available in the NIO platform . The loader may access a repository in which the services and blocks are stored and if needed load each service and or block to examine them and discover their characteristics. This process may include examining each block to see if the block requires a particular module. For example a block may explicitly define the module s that it needs or the loader may examine the block s code to determine if it uses any modules.

In step for each service configured to be auto started the service manager launches the service with the configuration information corresponding to that service. Although not shown the service manager may also expose the handling for the REST interface API through the web server module during this process.

Referring to a method illustrates one embodiment of a process that may be executed by the NIO platform of when an instance of the platform is launched. In the present example a core process has been launched and is running prior to step but no modules or services have yet been launched. The method is a more detailed embodiment of a process that may occur during steps of .

In step the core process accesses the configuration information and in step uses the configuration information to identify the available modules and or core components . Step may use the loader discovery functionality if needed during the discovery process of step in which case at least part of step would be executed prior to step . In step the core process creates a context to store the information for the various modules.

In step the core process starts and configures each available module . It is noted that a module may be instantiated prior to step or when started but the configuration occurs when each module is started. During configuration the configuration information and or context is passed to the module being configured. The module then updates the context with its own information such as information that may be needed by the core process and or another of the modules to call the current module.

In step the core process starts and configures each available core component . It is noted that a core component may be instantiated prior to step or when started but the configuration occurs when each module is started. During configuration the configuration information and or context is passed to the core component being configured. The core component then updates the context with its own information such as information that may be needed by the core process one of the modules and or another of the core components to call the current module.

It is noted that the current embodiment starts the modules before starting the core components . As the modules cannot use the core components but the core components can use the modules this order of steps enables the modules to update the context before the context is passed to the core components . As the modules have no need for the context from the core components this is a more efficient process. However in other embodiments the steps may be reversed or even mixed with modules and core components being started in some other order. In such embodiments all modules may receive the context for all other modules.

In step the core process starts and configures other core components such as the service manager and the loader discovery functionality . The service manager may then start services as described in .

Referring to a method illustrates one embodiment of a process that may be executed by the NIO platform of after the service manager is started and configured by the core process. In the present example the modules and core components have been launched and a context exists with the information about those modules. The method is a more detailed embodiment of a process that may occur during steps of .

In step the service manager accesses the configuration information for the services and in step calls the loader discovery functionality to discover the services and blocks available to the NIO platform . In step the service manager may obtain a context e.g. the context with the information for the modules and core components or may create a new context for use with the services .

In step the service manager starts and configures each available service that is configured to auto start. It is noted that a service may be instantiated prior to step or when started but the configuration occurs when each service is started in the present embodiment. In other embodiments some or all of the configuration may occur when the service is instantiated. During configuration the configuration information and or context is passed to the service being configured. The service then updates the context with its own information.

In step the service manager exposes the handling for the REST interface API through the web server module although this step may occur earlier in the method . In step the service manager waits for instructions such as stop and start commands for services .

Referring to a method illustrates one embodiment of a process that may be executed by a service process of the NIO platform of after the corresponding service is started. As stated previously when a service is started the service context is passed to the service process by the service manager .

In step the service process receives the service context. In step the service process initializes any modules needed by the service process itself and modules needed by the blocks used in the service . The service process may directly use modules such as the logging module and the threading module . Some modules like the communications module may be used by the service process to aid a block in setting up a communications channel. Other modules may be used directly by a block . In step the block router launches the blocks belonging to the service .

Referring to a method illustrates one embodiment of a process that may be executed by a service process of the NIO platform of after the corresponding service is started. For example the method may be a more detailed embodiment of step of and may occur for each block . In step the block is initialized to create a block instance. In step the block instance is configured which may include passing information such as module information needed by the block instance to use the module.

In step the block instance is started. As previously described starting a block instance may include notifying the block instance that the corresponding service has been started. If configured to do so the block instance can then execute instructions using the notification as a trigger. Without this notification the block instance may remain idle until called by processSignals .

Referring to a method illustrates one embodiment of a process that may be executed by the block router of the NIO platform of . In step the block router receives an output notification from a block . In step the block router looks up the next block s in the routing table and in step calls the next block s to process the output. As described previously this process may involve calls such as Blockrouter.notifySignals and processSignals .

As described previously due to the asynchronous nature of the blocks some or all of the blocks in the service can process niograms concurrently. Furthermore a single block may process multiple niograms concurrently by using threading to execute the block s functionality in multiple concurrent threads. The method does not need to be changed for this process as each processSignals call launches a new thread. In the present example the thread may spawn with a target of block.processSignals . If needed the blocks may include instructions for acquiring and releasing locks to prevent problems between concurrently executing threads. These instructions may be included on a block by block basis as race conditions or other thread collision issues may not be a concern for some blocks.

Referring to a method illustrates one embodiment of a process that may be executed by the block router of the NIO platform of . In step the block router receives a message. The message may be from a block and intended for the REST API or may be from the REST API and directed to the block. In step the block router passes the message on to the destination e.g. via the REST API by publishing the message to a channel or via another transfer mechanism .

Referring to a method illustrates one embodiment of a process that may be executed by a block of the NIO platform of . In step the block receives one or more signals and or niograms. The block may receive signals if the block is directly coupled to an external source and may receive niograms from another block directly or via the block router depending on the particular implementation . It is understood that receiving includes active processes through which the block may obtain data such as pulling data from an external source.

In step the block performs processing based on the block s internal instructions. As described previously such instructions may range from simple to complex depending on the particular configuration of the block . In step once the processing of step produces an output the block may issue a notification that there is output e.g. by notifying the block router and or may send the output directly to an external source depending on the block s internal instructions.

Referring again to the NIO platform includes a REST interface that may be part of the API . The REST interface aids in communicating with external tools and systems such as a console enterprise monitoring tools enterprise applications and external devices e.g. mobile devices servers databases machinery manufacturing equipment and or any other device system and or application with which the NIO platform is configured to communicate .

The NIO platform may use a runtime environment for a particular language e.g. Python and also interacts with an operating system on whatever device is running the NIO platform .

Referring to one embodiment of an environment illustrates a user s perspective of the NIO platform of with external devices systems and applications . For example the external devices systems and applications may be similar or identical to the external source s destination s of .

From the user s perspective much of the core s functionality not shown is hidden. The user has access to some components of the NIO platform from external systems and applications via the REST API . The external devices systems and applications may include mobile devices enterprise applications an administration console for the NIO platform and or any other external systems and applications that may access the NIO platform via the REST API.

Using the external devices systems and applications the user can issue commands e.g. start and stop commands to services which in turn either process or stop processing niograms . As described above the services use blocks which may receive information from and send information to various external devices systems and applications . The external devices systems and applications may serve as signal sources that produce signals using sensors e.g. motion sensors vibration sensors thermal sensors electromagnetic sensors and or any other type of sensor the web RFID voice GPS SMS RTLS PLC and or any other analog and or digital signal source as input for the blocks . The external devices systems and applications may serve as signal destinations for any type of signal produced by the blocks including actuation signals. It is understood that the term signals as used herein includes data.

Referring to a diagram illustrates one embodiment of a workflow that runs from creation to launch of a NIO platform which may be similar or identical to the NIO platform of of of and or of . The workflow begins with a library . The library includes core classes that include the classes for any core components and modules in the present example a base service class a base block class and block classes that are extended from the base block class . Each extended block class includes task specific code. A user can modify and or create code for existing blocks classes in the library and or create new block classes with desired task specific functionality. Although not shown the base service class can also be customized and various extended service classes may exist in the library .

The configuration environment enables a user to define configurations for the core classes the service class and the block classes that have been selected from the library in order to define the platform specific behavior of the objects that will be instantiated from the classes within the NIO platform . The NIO platform will run the objects as defined by the architecture of the platform itself but the configuration process enables the user to define various task specific operational aspects of the NIO platform . The operational aspects include which core components modules services and blocks will be run what properties the core components modules services and blocks will have as permitted by the architecture and when the services will be run. This configuration process results in configuration files that are used to configure the objects that will be instantiated from the core classes the service class and the block classes by the NIO platform .

In some embodiments the configuration environment may be a graphical user interface environment that produces configuration files that are loaded into the NIO platform . In other embodiments the configuration environment may use the REST interface of the NIO platform to issue configuration commands to the NIO platform . Accordingly it is understood that there are various ways in which configuration information may be created and produced for use by the NIO platform .

When the NIO platform is launched each of the core classes are identified and corresponding objects are instantiated and configured using the appropriate configuration files for the core core components and modules. For each service that is to be run when the NIO platform is started the service class and corresponding block classes are identified and the services and blocks are instantiated and configured using the appropriate configuration files . The NIO platform is then configured and begins running to perform the task specific functions provided by the services.

Referring to one embodiment of a service configuration environment within which a service is configured at runtime is illustrated. Within the NIO platform each service is created using a class file and configuration information . The configuration information includes predefined information that exists before runtime e.g. as part of the platform configuration information of and information that is dynamically generated at runtime. The dynamically generated information is not known until the NIO platform is launched and may include information described with respect to the environment of .

The class file may be used by multiple services but the configuration information is unique to the particular service being created. The configuration information may be in a separate file for each service or may be in a larger file from which a particular service s configuration information is extracted. At runtime the class file is instantiated and then the configuration information is applied to the instantiated service object.

Referring to one embodiment of a block configuration environment within which a block is configured at runtime is illustrated. Within the NIO platform each block is created using a class file and configuration information . The configuration information includes predefined information that exists before runtime e.g. as part of the platform configuration information of and information that is dynamically generated at runtime. The dynamically generated information is not known until the NIO platform is launched and may include information described with respect to the environment of .

The class file may be used by multiple blocks but the configuration information is unique to the particular block being created. The configuration information may be in a separate file for each block or may be in a larger file from which a particular block s configuration information is extracted. At runtime the class file is instantiated and then the configuration information is applied to the instantiated block object.

Referring to embodiments of class files and for blocks and not shown respectively are illustrated. Within the NIO platform the service class files and block class files are based on a base service template for services and a base block template for blocks respectively. These base templates include NIO platform specific behavior that is inherited by any class that extends them. This means that each service class and block class inherits NIO platform specific behavior that allows the corresponding service or block to work within the NIO platform architecture. Without this NIO platform specific behavior the class files and would not be recognized within the NIO platform architecture and so the corresponding services and classes could not be created. In addition to the NIO platform specific behavior each block class contains executable instructions that provide particular task specific functionality.

Referring specifically to the class file for Block Class includes the standard base block code for the NIO platform and also contains custom code for connecting to an external signal source which is Twitter for purposes of example. Referring specifically to the class file for Block Class includes the standard base block code for the NIO platform and also contains custom code for sending email.

If there is not an existing block class that contains the code needed to perform a particular task either a new block class can be created using the base block template or an existing block class can be modified. While service classes can also include custom code they rarely do so because the base service template generally provides all the functionality needed for a service . However it is understood that service classes can also be customized.

Referring to one embodiment of an environment within which configuration information is used to configure two blocks based on the same block class in different ways is illustrated. The configuration information allows configuration of a particular block at runtime by setting the values of configurable parameters defined within the block class . This means that the same block can be configured in different ways depending on the values in the configuration information that is used to configure the block .

The block class as shown in contains custom code to send any information received by the block to a destination email address. The code includes a configurable parameter for the destination email address to avoid having to change the underlying block class each time a different email address is used. This allows the email address to be defined in the configuration information which means that the same block class can be used to create multiple blocks that send their emails to different addresses.

Accordingly in the present example the block class is to be used to instantiate two blocks also referred to as Block and also referred to as Block . The blocks and are to be configured to send email to two different addresses using configuration information also referred to as Block configuration information and also referred to as Block configuration information respectively. When the blocks and are instantiated and configured the two blocks will have the same email sending functionality but will send their emails to different email addresses.

Referring to one embodiment of an environment within which configuration information is used to configure two services based on the same service class in different ways is illustrated. The configuration information allows limited configuration of a particular service at runtime by defining which blocks are to be executed by the service and the order of execution of the blocks . The configuration information may also be used to set the values of configurable parameters defined within the service class . This means that the same service can be configured in different ways depending on the blocks the order of execution and the values in the configuration information that is used to configure the service .

In the present example the configuration information for a service includes source blocks and destination blocks needed to build a routing table when the service is instantiated. Because the blocks do not have any connection to each other except through the service the service uses the routing table to direct information from one block a source block to the next block a destination block . The service receives the source and destination blocks as configuration information after the service is instantiated so the same underlying service class can be used for different services . This means that the services can have different functionality based on the particular blocks and block execution order defined in their configuration information .

Accordingly in the present example a service class is to be used to instantiate two services also referred to as Service and also referred to as Service . The services and are to be configured using different blocks and different orders of execution using configuration information also referred to as Service configuration information and also referred to as Service configuration information respectively. When the services and are instantiated and configured the two services will have different functionality.

In the present example the fact that a service is made up of a service class and configuration information means that prior to instantiation there is no service class that can be examined to determine the execution order of blocks or even the blocks that are to be used within the service . To determine the behavior of the service the configuration information would have to be examined.

Referring to one embodiment of an environment is illustrated with a base block class that is extended to create various customized block classes not shown such as those in the library of . The customized block classes can then be instantiated as described previously to form various blocks . As described above a NIO platform operates by using a service to organize the appropriate blocks to perform a particular task. In the present example the blocks do not have any connection to each other except through the service . This organizational structure provides benefits such as asynchronicity in block execution dynamic expansion and retraction of block resources in response to input changes and the ability to modify services and blocks without having to restart the NIO platform .

For example as shown in the environment includes a block library that contains the ten blocks . Each of the blocks is built from the base block template so each block is compatible with the NIO platform architecture. The blocks have no connection to each other except that all of them can operate within the NIO platform architecture. Each block contains task specific code that allows that block to perform a particular function. For example the block connects to Twitter the block sends an email containing any information received from another block the block connects to a machine in an assembly line the block filters any input received from another block for one or more defined text strings the block sends a signal to turn off the machine on the assembly line and so on.

Assume that a user wants to create two different services and using the ten blocks . Service is to monitor an external source e.g. Twitter Twitter for the words company name and send an email to user1 companyname.com if such a tweet is detected. Service will monitor an assembly line machine for the occurrence of certain error codes and send an email to user2 companyname.com if an error is detected. Service will also shut the machine down if an error is detected. Services and are to run simultaneously on a single NIO platform and perform their tasks asynchronously and in real time without any data storage.

With additional reference to one embodiment of the service is illustrated using blocks from the environment of . Service is created by identifying the needed block classes and defining their order of execution. For example the block connecting to Twitter will be followed by the block filtering for company name and then the block will send an email to user1 companyname if block identifies any tweets with company name. The block classes include configurable parameters that allow them to be customized without needing to open the block classes and change their code. illustrates the configured appearance of the service from a functional perspective.

The routing table for the service defines the destination block for any output from a source block. If a block does not send output to another block i.e. the block there is no entry in the routing table. There is no source block for block because block is connecting directly to Twitter. Table 3 illustrates an example of a routing table for the service .

The decoupled nature of the blocks and the flexibility provided by the routing table allow the service to be modified or blocks swapped for other blocks relatively easily. It is understood that any configuration changes and any new blocks must be loaded into the NIO platform assuming the new blocks are not already there and then the service must be restarted for changes to take effect. For example if a user wants to swap the email block for a text message block block can be replaced with a suitably configured block for sending texts. If the block s name remains the same the routing table may not even change in some embodiments. If the block s name is different the routing table needs to be updated but no other change may be needed. Table 4 illustrates an example of the routing table for the service with the block replaced by a text message block .

If the user wants to send both the text message and the email then the text message block can be added so that it exists within the service alongside the email block . In this case the routing table can be updated to include the new block as another destination for source block . Table 5 illustrates an example of the routing table for the service with both block and block .

With additional reference to one embodiment of the service is illustrated using blocks from the environment of . Service is created by identifying the needed block classes and defining their order of execution. For example the block connecting to the machine will be followed by the block filtering against an error list . If an error is detected the block will send an email to user2 companyname and the block will shut down the machine. The block classes include configurable parameters that allow them to be customized without needing to open the block classes and change their code. illustrates the configured appearance of the service from a functional perspective. Table 6 illustrates an example of a routing table for the service .

Referring to one embodiment of the NIO platform is shown within an environment . The environment includes access to Twitter and a machine . As shown the NIO platform includes a core and is running the two services and simultaneously. Each service and performs its configured functions independently of the other service.

Referring to a method illustrates one embodiment of a process that may be executed by the NIO platform of to create and configure a block . In step a block class is identified along with the block s corresponding configuration information and dynamically generated information needed for the block . In step the block is instantiated from the block class . In step the block is configured using the corresponding configuration information and dynamically generated information.

Referring to a method illustrates one embodiment of a process that may be executed by the NIO platform of to create and configure a service . In step a service class is identified along with the service s corresponding configuration information and dynamically generated information needed for the service . In step the service is instantiated from the service class . In step the service is configured using the corresponding configuration information and dynamically generated information.

Referring to one embodiment of an environment is illustrated in which a real time publishing system asynchronously captures normalizes filters prioritizes and publishes data from multiple data streams in real time or near real time. Unlike conventional systems the real time publishing system does not need to store data in a data repository e.g. a database after capturing the data but is instead able to process the data as it is received directly from the data sources and publish the data for viewing to a display. The display is updated in real time or near real time whenever additional data is captured from the sources providing a dynamically updating display with consistently refreshing information.

In the present example a NIO platform which may be similar or identical to the previously described NIO platform NIO platform or NIO platform may be used with one or more publishing servers e.g. a web services server for publication via a website to provide the real time publishing system . The NIO platform receives data from one or more external sources . . . and N where N is the total number of external sources. The external sources . . . and N produce data . . . and N respectively that is captured by the NIO platform .

The NIO platform processes and feeds the data in niograms or a different format to the publishing server which handles the process of publishing the information for viewing. The publishing server may publish to one or more channels such as the web email SMS feed e.g. RSS feeds post e.g. to social media sites voicemail and or any other channel . For purposes of example the publishing server is a web services server that is configured to publish the information via one or more web pages.

The real time publishing system is configured to obtain data from the external sources N process the data and publish the data in real time or near real time. The NIO platform is configured to send a relatively steady stream of data e.g. a minimum number of niograms per second to the publishing server for publication. The publication may occur in many different ways but in the present example is accomplished via a matrix of tiles described below in greater detail that is refreshed on a relatively continuous basis.

The real time publishing system has no control over the external sources N and cannot be sure that new data will be received on a regular basis. As new data may not always be available for use in refreshing the matrix the NIO platform may cache data and use the cached data to continually refresh the matrix. Without the cached data there would be nothing for the NIO platform to send to the publishing server if no new data had been received when it was time to send. Accordingly new data may be sent to the matrix in real time or near real time and cached data may be used when needed to ensure that the publishing server receives a steady supply of data to display.

Referring to one embodiment of an environment illustrates the NIO platform of as configured to provide various components functions that both capture data and prepare the captured data for publishing. It is understood that the functionality provided by the components may be organized in many different ways and may be spread across additional components or combined into fewer components.

In the present example the functionality includes data components . . . and M that obtain information from external sources N and then transform and filter the data. In the present example the process of data retrieval transformation and filtering occurs on a per source basis. The data retrieval components M may have a one to one correspondence with the external sources N or a single data component may connect to more than one external source.

The functionality also includes a prioritization component that receives the transformed and filtered data from the data components M and prioritizes the data for publishing. As will be described below in greater detail this allows particular types of data and or particular external sources to be given priority in publishing which in turn allows the data that is actually displayed to be tuned as desired. Although the prioritization component performs prioritization for all data components M it is understood that a separate prioritization component may exist for each of the data components M.

In the present example the prioritization component sends the prioritized data to both a queuing component and directly to a delivery component . The queuing component provides one or more queues in which data is temporarily stored to ensure that the NIO platform always has data to send to the web services server . The direct path to the delivery component provides real time or near real time data for the server without the delay introduced by the queue component .

Referring to one embodiment of the NIO platform of is illustrated in greater detail with source services M and a stream service . The source services M and stream service are services configured to operate within the NIO platform as described in previous embodiments.

The NIO platform includes multiple source services . . . and M. The source services M are configured to obtain data from the external sources N respectively. In the present example the source services M include blocks not shown that perform the data retrieval transforming and filtering functionality described with respect to . The source services M pass the data to the stream service which handles the prioritization queuing and delivery described with respect to .

It is understood that one or more of the source services M and the stream service may be combined into a single service in other embodiments. In still other embodiments the source services M and the stream service may be further divided. For example one or more additional services may be created and configured to handle the transforming functionality the filtering functionality the prioritization functionality the queuing functionality and or the delivery functionality. As described previously the NIO platform may be configured in many different ways with many different services and or blocks to provide the same functionality.

Referring to one embodiment of the source service of is illustrated. In the present example the source service includes a connect block a transform block a white list filter block a black list filter block and a publish block . When a block is finished performing its configured processing it calls Blockrouter.notifySignals as previously described and the service s block router calls processSignals on the next block.

The connect block is configured to connect to a specific external source such as Twitter Facebook Google Instagram Youtube or another source that provides content. The type of connection may be based on the particular site with some sites pushing data to the connect block and other sites requiring that the connect block be configured to pull data from those sites. Accordingly the actual configuration of the connect block may vary depending on the API of the external source the type of information being obtained e.g. streaming data versus other non streaming data types whether authentication credentials are needed for access and or other factors.

The transform block converts the obtained data into niograms with each niogram containing a single piece of content e.g. a Facebook post a tweet an article with accompanying pictures or a Youtube vide . In the present example regardless of the external source and the type of data e.g. video audio images and or text the data will be placed into defined fields in a niogram. This deconstruction process normalizes the data for later processing. The transform block may retain all information obtained from an external source or may discard information. The transform block may also insert other information into the niogram such as a source type e.g. Twitter or Facebook a username corresponding to the source data text e.g. relevant text for each content source a link to the content a unique ID e.g. either global or on a local basis such as per type and or a status flag e.g. old new or VIP .

The filter blocks and perform filtering against the contents contained in the fields of the niogram. The white list block contains text e.g. words or phrases that must be present in the fields to pass the filter and the black list block contains text that must not be present in the fields to pass the filter. The text may be in posts image captions user names and or elsewhere and may vary depending on the particular source and or the contents to be published. The filter blocks and enable content to be screened to prevent false positives and to remove unwanted e.g. objectionable offensive and or irrelevant material.

One or more custom blocks may be positioned anywhere within the service or may be omitted entirely. In the present example no custom blocks are used.

The publish block publishes the transformed and filtered niograms for use by the service . For example the publish block may publish to a publisher sources channel that is common to all of the source services M.

It is understood that one or more of the blocks may be combined into a single block in other embodiments. In still other embodiments one or more of the blocks may be further divided.

Referring to one embodiment of the stream service of is illustrated. In the present example the stream service includes a subscribe block a queue by type block a timestamp block a freshness block a priority block a queue by priority block and an output block . When a block is finished performing its configured processing it calls Blockrouter.notifySignals as previously described and the service s block router calls processSignals on the next block.

The subscribe block is subscribed to subscriber sources which receives all niograms published by the source services M via publisher sources. The subscribe block passes received niograms to both the queue block and the timestamp block .

The queue by type block along with the queue by priority block may be used to provide cached data to ensure that a steady stream of data is sent for publication to the web services server . In the present example the two separate queue blocks are used to ensure that content is published based on both type and priority.

The queue block stores a queue for each type of external source e.g. Twitter Facebook and Google . Each queue is configured to hold a defined number of niograms. The queue block emits a niogram from each queue as defined intervals e.g. every X milliseconds or seconds and automatically reloads the niograms that are popped off the queue to the end of the queue to be recycled through. A new addition to the queue pops the queue discarding the front niogram and adding the new niogram to the end of the queue. The reloading ensures that the queue will remain full even without new niograms being added. Accordingly if an external source does not produce new content frequently the niograms in the queue for that type will typically be older than the niograms in a queue that corresponds to a frequently updated type.

The queue block may use a value e.g. a throttle to spread out the emitted niograms. For example if there are eight types and the queue block is configured to emit a niogram for each type every five seconds then eight niograms are emitted every five seconds. The throttle may be used to queue up the eight niograms so that their emission is spread relatively evenly across the five second window.

The timestamp block assigns a timestamp to each niogram that identifies a particular reference time such as when that niogram s content was received by the timestamp block . Because niograms are initially passed through to the timestamp block in real time or near real time the timestamp will be close to the time the niogram was received by the corresponding source service.

In embodiments that use freshness the freshness block assigns a freshness level to each niogram. Each niogram is assigned a freshness level that changes over time e.g. a niogram loses its freshness over time . Different levels of freshness and different rates of decline may be applied based on content e.g. text may lose freshness faster than images type and or other factors. The freshness levels enable the stream service to tune the content to be displayed by the web services server based on how long ago the content was received.

The priority block assigns a priority to each niogram based on one or more defined criteria. For example a priority scale of 1 5 may be used with niograms being assigned priority based on content e.g. images may be assigned a higher priority than text type and or other criterion. Freshness may affect priority level with the priority level of a niogram decreasing as its freshness decreases.

The queue by priority block which may be similar or identical to the queue block in its manner of operation stores a queue for each priority of niogram.

The output block receives niograms and sends them to the web services server . The output block may be a web socket that is able to communicate directly with the web services server .

Referring to one embodiment of a method illustrates a process that may be used within the NIO platform of . It is noted that the method focuses on the real time or near real time aspect of publishing and does not describe queueing. In step media is obtained from an external source. In step the media is transformed and inserted into a niogram. Additional tagging may also occur in this step. In step the media is filtered based on white list and or black list information.

In step a determination is made as to whether to discard the niogram based on the filtering of step . If the niogram is to be discarded the method moves to step and discards the niogram. If the niogram is not discarded the method moves to step . In step a timestamp is added to assign a reference time to the niogram. In step a freshness level of the media is set in embodiments that use a freshness level to control the display of the media. In step a priority is assigned to the media. In step the media is output to the server for display.

Referring to the web services server uses the prioritized data stream from the NIO platform to fill and refresh a matrix. In the present example the web services server has two main functions. The first function is an assignment function with which the web services server assigns a niogram to a tile. As will be described below not all niograms may be assigned to a tile. The second function is a publication function with which the web services server publishes the niograms via the matrix for viewing on one or more device displays .

Referring to one embodiment of a matrix is illustrated. The matrix represents one example of how the real time publishing system of may organize and present published data for viewing on a website within a mobile device application and or elsewhere.

In the present example the web services server determines where the prioritized data belongs in the matrix which may then be published to a display. For example the matrix may be defined using cascading style sheets CSS . The matrix represents a portion or all of a display area e.g. within a web browser or other viewing software that can be displayed on an analog or digital display. As shown the matrix is divided into sixteen tiles e.g. cells . . . and and each tile represents a unique area of the matrix in which data can be displayed.

It is understood that the matrix can be of any size and shape but is rectangular in the present embodiment for purposes of illustration. While rectangular the matrix may have irregular columns and or rows as shown or the columns and or rows may be regular. Furthermore the matrix and or one or more of the tiles can be fixed or dynamic.

With additional reference to a portion of the matrix is illustrated with tiles and . In the present example tiles and are assigned changing content and tile is static e.g. the content does not change .

Because the tiles and contain content that changes it may be difficult for a user to read or otherwise view a tile s contents before the content changes. As the content may not appear in the matrix again or may appear in another tile at some seemingly random time from the user s perspective the constantly changing tiles may be difficult to view. Accordingly the tiles and may include user selectable regions and respectively. The user selectable regions and may be any shape and or size and may be positioned anywhere within their respective tiles and .

Each user selectable region and enables the respective tile to be locked which prevents the contents from changing until the tile is unlocked. For example in none of the user selectable regions and are selected and the content in the respective tiles and is changing. In contrast in the user selectable region has been selected which locks the tile and prevents the contents of the tile from being refreshed with new content. The user selectable regions and are not selected and the content in the respective tiles and continues to change.

Deselection of the user selectable area e.g. selecting the user selectable area a second time will unlock the tile and allow the contents to be refreshed. When the tile is unlocked the tile may refresh instantly or may refresh using one or more other criterion. For example a timer corresponding to the tile may continue running while the tile is locked. In this case if the timer expires while the tile is locked the tile may refresh once unlocked based on the expired timer. In other embodiments locking the tile may freeze the timer and unlocking the tile may unfreeze the timer. In this case the timer may continue normally once unfrozen and the tile may be refreshed when the timer expires.

Referring specifically to selection of a tile and may enlarge that tile if the tile is configured to be enlarged. For example selection of the tile e.g. user selection of a portion of the tile in both has enlarged the tile. In some embodiments the contents of the enlarged tile may continue to change as shown in . In other embodiments the contents may be locked when the tile is enlarged as shown in D. The tile may be unlocked when the tile is minimized. In the case where enlarging the tile locks the tile s contents a corresponding timer may operate as previously described.

Referring to one embodiment of the tile is illustrated in greater detail. In the present example the tile may include a header area delineated by a line . The header area may include the user selectable area a user name if applicable corresponding to the source of the media currently being displayed by the tile and an indicator e.g. an icon identifying the type of contents. The tile may also include a footer area delineated by a line . The footer area may include a source link corresponding to the source of the media currently being displayed by the tile enabling a user to select the source link to load the media from the original source. For example if the user is viewing the matrix in a browser selecting the link may open the source in another browser tab or another browser window.

In some embodiments the header area and or footer area may only be displayed when a trigger occurs such as a user mousing over or otherwise selecting the tile. In some embodiments the header area and or footer area may cover a portion of the media being displayed by the tile while in other embodiments the media may be fully displayed between the header area and the footer area . In some embodiments the header area and or footer area may be partially transparent. In some embodiments the tile may be assigned a particular color based on type or another attribute so that text contents are displayed with different color backgrounds depending on the source of the text.

The matrix may be filtered in many different ways. For example a user may select the username to show only content from that user. A user may also select the indicator to display only content from that source. Filters may be stacked with selection of one or more usernames and or sources enabling customizable displays to be created.

With additional reference to a method illustrates one example of a process that may be used within the real time publishing system of to assign data to various tiles of the matrix . It is understood that this is a real time or near real time process with data being identified assigned to one of the tiles and published for display in real time or near real time without storing the data in a data repository.

In step content is identified for publication. In steps and the particular tile to be used to display the content is determined and the content is assigned to the tile. The tile assignment occurs in a defined manner. In some embodiments one external source may be assigned to one tile of the matrix or to multiple tiles e.g. with data interleaved among the tiles or otherwise assigned . For example external source may be assigned to tiles and . External source may be assigned to tiles and . External source N may be assigned to tiles and . Tile is not assigned to any external source. Tile may be used to provide articles comments advertisements and or any other desired content. In some embodiments tile may be used for overflow if needed such as when a spike occurs as will be described later.

Within the tiles assigned to a particular external source the data may be updated in various ways. For example the newest data may be assigned to the next tile to be refreshed for that external source or may be assigned to a tile selected from an available group of tiles e.g. a group of all tiles within five seconds of a refresh . Selecting the tile from a group may aid in providing a level of randomness to the matrix .

This external source grouping of tiles for the assignment process allows advertisers or other sponsors to reserve certain tiles. This assignment process also enables the real time publishing system to reserve more tiles for external sources with a higher volume of data which allows some level of load balancing by controlling the assignment of tiles .

In other embodiments the data may be randomly assigned to tiles rather than tying a tile to a particular external source and tile assignments may change frequently. For example the newest data may be assigned to the next tile to be refreshed regardless of the external source from which the data was obtained although this may depend on certain criteria such as whether the tile is inappropriate for the content e.g. too small to display an image or a block of text .

When randomly assigned the tiles may be grouped so that each external source has a certain number of tiles. For example external source may be assigned X tiles with X being a whole number from one to sixteen tiles forming a percentage area of the matrix e.g. tiles forming at least fifty percent of the matrix area a number of tiles between X and Y with X being a whole number equal to or greater than one and less than Y and Y being a whole number from X 1 to sixteen or X tiles that are all larger than a specified minimum size per tile. Accordingly the tiles may be assigned in many different ways.

Tiles may also be assigned based on content. For example tweets may always be assigned to tiles and . Images may always be assigned to tiles and . Text may always be assigned to tile . The other tiles may be similarly linked to types of content or may be assigned as previously described. This enables a designer to distribute content throughout the matrix as desired in a known pattern regardless of the source of the content.

Regardless of the amount of data being received the real time publishing system is configured to publish as much new content as possible given the constraints within which the publication occurs e.g. the number of tiles in the matrix . It is understood that content may be throttled or otherwise limited based on user preferences bandwidth limitations and or similar factors and so the amount of new content that is published may vary among users.

In some embodiments to determine which content should be shown content may be prioritized based on source type of content e.g. images may have a higher priority than text freshness a relevancy weighting based on a number of factors and or other criteria. The priority of a piece of content may be added to the content e.g. as tags and when the content is to be assigned to a tile may be used to determine whether to replace the content with other content. Accordingly the display attributes of a tile may change based on the contents currently being displayed by that tile. This means that tiles may be prioritized for replacement based on their content.

In the present example tile assignment prioritization is based on making sure that as much new content as possible is being published which generally means that the real time publishing system replaces older content with new content whenever new content become available. This means that tile assignment prioritization decisions can be focused on what tile is to be replaced in the matrix . While simply assigning the new content to tiles containing the oldest content in the matrix or in the group of tiles assigned to the particular source is one approach that may be used by the real time publishing system other approaches may focus on more than simply tile content age such as the priority level of the tile s contents.

More specifically while tile assignment prioritization may be an age based decision in part in some embodiments the age may not be the only factor or even the dominant factor in deciding what tile is to be replaced. For example the real time publishing system may be configured to replace newer content in the matrix before older content if the older content has a higher priority rating than the newer content. In some embodiments age may be viewed as a sliding scale priority factor in determining replacement priority so the priority rating of a tile s content may decrease over time as the content ages. In other words as a tile s contents get older the contents priority level may drop in some manner e.g. continuously or based on a step function . This dropping may continue until the tile s contents fall below the priority level of newer content that originally had a lower priority level. Using this approach the tile that will be replaced with new content is the tile with the oldest content and or lowest priority level.

In step a determination may be made as to whether the assigned tile is ready to be refreshed. The tiles within the matrix are refreshed when a trigger occurs such as when new data is captured and or when a timer expires. For example a trigger may occur when new data is captured but the tile may not be updated until a timer expires. The timer prevents the tile from being refreshed too rapidly when new data is being received in a short amount of time. For example if the timer is set to two seconds and five pieces of data arrive for that tile in two seconds the timer may prevent the last four pieces of data from being displayed on arrival as a user would likely have difficulty consuming the data that quickly.

The trigger may be operate on a per tile basis e.g. each tile may have its own timer or may operate multiple tiles or the entire matrix. Generally some or all tiles in the matrix will be regularly refreshed to maintain an appearance of dynamic data. In some embodiments at least one tile may be refreshing at any particular time.

Different triggers may be assigned to different types of data. For example images and tweets may have different refresh rates which may affect the refresh rate of the tile to which that content has been assigned. When the refresh rate is tied to the content itself some tiles may be omitted from selection. For example tile may be considered too small for an image and so may not be considered if an image is the next content to be assigned to a tile.

If the determination of step indicates that the tile is not ready the method may repeat step until the tile is ready. If the tile is ready the method moves to step and updates the tile.

A more detailed example of prioritization for contents within the matrix is illustrated below with respect to Table 7.

Table 7 shows five priority levels with level one being the lowest and level five the highest. Each priority level is associated with three durations which are in seconds in the present example. Each priority level has a minimum duration a minimum duration for new content and a maximum duration.

The minimum duration is the shortest period of time that the content assigned to that tile will be displayed unless new content is available. This duration setting enables higher priority content to remain in the matrix longer than lower priority content. The maximum duration is the longest period of time that the content will be displayed before being refreshed even if the refresh uses cached content. This duration setting ensures that the matrix will be periodically refreshed with different content. The minimum duration for new content is the amount of time that the current content will be shown before being refreshed with the new content. This duration setting ensures that new content is pushed to the matrix over previous content but may also be set to prevent content from being refreshed so quickly that it cannot be consumed.

Based on Table 7 there are three time periods involved assuming no new content and or higher priority content is available. Before the minimum duration is reached after the maximum duration has been reached and between the minimum duration and the maximum duration. Before the minimum duration is reached for a tile the tile s contents will not be replaced. Past the maximum duration the tile s contents will always be replaced even by lower priority contents with the oldest tile replaced first.

Any tiles falling between the minimum and maximum durations are compared based on the percentage of time remaining in their time window. For example a priority two tile has minimum and maximum durations of fifteen and thirty seconds respectively for a fifteen second window. A priority three tile has minimum and maximum durations of twenty and forty seconds respectively for a twenty second window. Assume that the contents of the priority two tile have been displayed for twenty seconds and the contents of the priority three tile have been displayed for thirty seconds. The priority two tile is approximately thirty three percent through its fifteen second window and the priority three tile is fifty percent through its twenty second window. In this case the priority three tile would be replaced because it has used more of its display time than the priority two tile. In other embodiments windows may only be compared for equal priority tiles and lower priority tiles may always be refreshed before higher priority tiles regardless of the amount of time remaining.

If new content is available the minimum duration for new content is applied to the tile. For example a priority one tile may have displayed its information for five seconds when it is checked. If the available content is not new nothing happens because the seven second minimum duration time has not expired. However if the available content is new the minimum duration for new content is applied and the tile is refreshed because the minimum duration is one second and the timer is at five seconds. This enables existing content to be refreshed quickly when new content becomes available with lower priority content being replaced more rapidly than higher priority content.

In some embodiments there may be a priority level that is always given priority. For example a VIP level may mean that a tile is refreshed even if no tiles are ready to be refreshed. Designating content as VIP ensures that the content will be instantly published regardless of tiles states. It is understood that the tile being replaced may still be the tile that is the oldest has the least time remaining etc. but even the minimum duration for new content period will be overridden to display the new content. For example assume that the next tile to be replaced is a priority five tile that has only used five seconds of its fifteen second minimum duration for new content. If VIP content is available the remaining ten seconds will be ignored and the tile will be refreshed with the VIP content.

It is understood that the different types of tile assignment can be mixed as desired. This provides a great deal of flexibility in presenting the content and enables the matrix to be dynamically adjusted as the content changes.

In the present embodiment content is published to the matrix and then replaced with other content in real time or near real time. While some content may be cached temporarily and delivered e.g. to quickly fill the matrix when the matrix is first loaded and or redelivered e.g. in situations where no new content has been received but a tile must be refreshed the real time publishing system does not store the content in a data repository and once the content is discarded by the system it cannot be retrieved and redisplayed. In other words there is no back button or other mechanism by which a user can move backwards in time through a tile s contents. The real time aspect of the system means that information is constantly coming in and being used to replace previous information and the previous information is no longer available. It is understood that content including a tile s contents may be cached or otherwise saved in other embodiments.

With additional reference to a method illustrates one example of a process that may be used by the web services server within the real time publishing system of to assign data to various tiles of the matrix . It is understood that this is a real time or near real time process with data being identified assigned to one of the tiles and published for display in real time or near real time. If needed cached data may be used to prevent tiles from remaining in an unrefreshed or blank state as previously described.

In step media is received from the NIO platform . In step a determination is made as to whether any appropriate tile timers have expired. For example if the media is tagged as new the appropriate tile timers would be the new content duration timers. If the media is not new the appropriate tile timers would be the minimum duration timers. If no tile timers have expired the media is discarded in step and the method returns to step .

If an appropriate tile timer has expired the method moves to step . In step a determination is made as to whether the tile with the expired timer is an appropriate e.g. a matching tile for the media. For example if the tile is a priority tile and the media is priority media then there is no match. If there is no match the media is discarded in step and the method returns to step . If there is a match the media currently being displayed at the matching tile is replaced with the new media in step .

It is understood that the method may occur rapidly with media being received and either assigned or discarded continuously. The actual speed depends on factors such as the input rate of received media the content of the media relative to how the assignment occurs e.g. the ratio of high priority content to the number of high priority tiles in the matrix the duration of the timers the size of the matrix and or other factors.

Referring to a method illustrates one example of a process that may be used within the real time publishing system of . The real time publishing system may cache some or all of the captured content and if no new content has been received when a tile is due to be refreshed the tile may be refreshed using the cached content. In other words old content whether previously shown or not may be used to keep the matrix in a refreshed state. This method may be used when the cached content is injected into the media stream on an as needed basis instead of being automatically injected on a timed basis.

Accordingly in step a determination is made as to whether a tile is ready to be refreshed. If the tile is not ready to be refreshed the method returns to step and waits for the tile to be ready to be refreshed. If the tile is ready to be refreshed the method continues to step . In step a determination is made as to whether there is new content for the tile. If there is new data the tile is updated with the new content in step . If there is no new content the tile is updated with cached content in step .

It is noted that step may vary depending upon the configuration of the real time publishing system . For example if there is no new content from an external source assigned to the tile e.g. the external source but there is new content from another external source e.g. the external source the new content from external source may be used to refresh the tile. In other words fresh content may be given priority over cached content. However if the real time publishing system is configured to use only certain external sources for certain tiles then only cached content will be used when a given tile is to be refreshed and no new content is available from the corresponding external source.

Referring to various methods illustrate examples of processes that may be used within the real time publishing system of when a spike occurs in the input rate from one or more of the external sources N. More specifically regardless of how the tiles are assigned the real time publishing system should be prepared to handle spikes in the input rate and therefore the input volume of the external sources N. Because the real time publishing system is displaying content in real time or near real tile spikes may occur unexpectedly and the system must handle those spikes in a manner that maintains the real time nature of the display without refreshing the matrix so rapidly that the content cannot be consumed by someone viewing the display.

Accordingly illustrate methods that may be executed by the real time publishing system when too much data is received. The determination of what constitutes too much data may be made on a per stream basis or on an aggregate basis i.e. multiple streams or all streams .

Referring specifically to one embodiment of a method illustrates a process by which the real time publishing system can respond to a spike in the input rate. In step a determination is made as to whether the input rate is over a defined threshold. If not step may repeat until an input rate is detected that surpasses the threshold. If the input rate surpasses the threshold the method continues to step .

In step any content that is not displayed is discarded. This results in the discarded content not being shown at all with the amount of lost content depending on factors such as the input rate the number of tiles being used for that stream and the refresh rate of those tiles.

Referring specifically to one embodiment of a method illustrates another process by which the real time publishing system can respond to a spike in the input rate. Step is identical to step of and is not repeated in the present example.

In step tiles are added to the matrix automatically. For example tiles may be added to the bottom of the matrix which makes the matrix longer. Since the matrix is a live display the tiles should be added in a way that minimizes any possible disruption to someone viewing the matrix at the time the addition occurs. Adding tiles to the sides and or top of the matrix may be done in some embodiments but adding to the bottom of the matrix may lessen the disruption to a viewer.

Once the spike ends the extra tiles may be removed although this may be done over time to avoid wiping out content that a user may be viewing. In some embodiments cached content may be used in the tiles before they are removed as this will be older content and may not be as appealing to a viewer. The viewer may then move up higher on the matrix searching for new content and the bottom tiles can then be removed. In other embodiments the added tiles may not be removed as long as they are in the visible area of the display but may be removed then they are no longer visible.

Referring specifically to one embodiment of a method illustrates yet another process by which the real time publishing system can respond to a spike in the input rate. Step is identical to step of and is not repeated in the present example.

In step the content is cached and shown as the rate slows down although this will result in a time delay on some of the content. Content past a certain age may be discarded although the discard age may vary depending on how much data is being received. For example if the stream slows down below the threshold some content may be cached longer so that the matrix can be refreshed with unseen content even if that content is somewhat dated. If the input rate remains above the threshold more content may be discarded to keep up.

Referring specifically to one embodiment of a method illustrates a process by which the real time publishing system can respond to a spike in the input rate. Step is identical to step of and is not repeated in the present example.

In step one or more additional tiles in the matrix may be assigned to the external source s N that is having the input rate spike. For example if the input rate from the external source has spiked tiles that are exclusively assigned to the external source that is updating slowly may be assigned to the external source or content from the external source may be interleaved with the content from the external source . Once the spike ends the tiles may be returned to the external source to which they were originally assigned.

In configurations where the tiles are randomly assigned to external sources rather than being assigned to specific external sources tiles may be reserved for the external source having the spike. For example a certain percentage of the tiles may remain in use for the other external sources while another percentage of the tiles are assigned specifically to the external source having the spike. Once the spike ends the tiles can be allocated normally.

Referring specifically to one embodiment of a method illustrates still another process by which the real time publishing system can respond to a spike in the input rate. Step is identical to step of and is not repeated in the present example. In step the refresh rate of one or more tiles assigned to the external source having the input rate spike may be changed so that more content can be shown in the same amount of time. For example if the current refresh rate is two seconds the refresh rate may be lowered to one second which would double the amount of data that could be displayed using the same tile s . The refresh rate timer may be lowered repeatedly if the input rate remains high until a floor that defines the minimum refresh rate is reached. Once the spike ends the refresh rates can be returned to normal although this may occur gradually.

If the refresh rate for the entire matrix is to be changed the change may be phased in across different tiles until the entire matrix has been changed. This phased approach may be used to minimize the visual disruption that suddenly changing the entire matrix may cause for a viewer.

As stated previously the methods of may be combined either in a cascading approach or simultaneously. The combination of methods may be based on factors such as the actual input rate whether a single external source or multiple external sources are involved how the tiles are being assigned e.g. per external source or across multiple external sources which external source is involved e.g. whether it is an external source that is already assigned multiple tiles historical trend data for the external source e.g. how long the spikes typically last for this external source and what the maximum volume during a spike and or similar information.

For example in a cascading approach the content may first be cached . Then if the input rate does not drop below the threshold within a certain period of time and or the input rate increases the refresh rate may be changed . Then if the input rate does not drop below threshold within a certain period of time and or the input rate increases tiles may be reassigned . Then if the input rate does not drop below threshold within a certain period of time and or the input rate increases the matrix may be expanded . It is understood that this order is only for purposes of example and that the methods of may be executed in any order.

In an example of simultaneously combining the methods of content may be cached while tiles are being reassigned and then the reassigned tiles may be used for the cached and or new content. In another example the refresh rate may be changed while the matrix is being expanded .

Accordingly many different approaches can be used to handle spikes in the input rate from the external sources N. Generally the approach will be directed to preserving as much content as possible while displaying as much real time or near real time content as possible. The real time publishing system may be specifically configured for the external sources N thereby enabling the system to be optimized in response to changes in the external sources.

In some embodiments users can select the data that is to be displayed in the matrix . For example a user may select only certain tiles or types of content and the real time publishing system may then adjust to that selection.

In other embodiments the user may adjust the tiles in the matrix . For example the user may assign content to certain tiles moves tiles and or otherwise modify the visual display provided by the matrix .

The matrix represents one possible display format for information to be published and many other formats may be used. For example histograms Venn diagrams bar charts word clouds tickers hive plots and or any other format that is appropriate for the content being published may be used. In some embodiments a three dimensional shape may be used with information projected onto the shape. In such embodiments the shape may be rotated to view the information.

In still other embodiments the real time publishing system can display in real time information about its own performance and about the data. For example the real time publishing system may display information about how much data is being processed per unit time how much is being discarded and similar information. The real time publishing system may also display how much relevant information is not being shown because for example the system cannot display it all because of the volume of information. For example the real time publishing system may show how many tweets are not being displayed. Such information may then be used to modify what the real time publishing system is publishing so that a user can narrow the focus down to particular content.

In addition to the claimed embodiments in the appended claims the following is a list of embodiments which may serve as the basis for additional claims in this application or subsequent divisional applications 

A method for execution on a digital device includes running a core process to create a platform instance of a real time processing platform wherein the platform instance interacts with an operating system on the digital device and is configured to run any service instance that is created using extendable base classes that have been defined for use within the processing platform and wherein the core process includes a service manager configured to manage any service instance run by the platform instance identifying by the service manager from configuration information corresponding to the platform instance that the platform instance is configured to run a service instance that is defined by a service class that extends a defined base service class identifying from the configuration information by the service manager that the service instance is to use a plurality of block instances that are defined by a plurality of block classes wherein each block class extends a defined base block class and contains executable instructions that provide processing functionality for the service instance starting by the service manager the service instance wherein the service instance includes a block router and a routing table starting by the block router the block instances wherein each block instance has no knowledge of the service instance and the plurality of block instances other than itself receiving by a first block instance of the plurality of block instances streaming input data to be processed from a source that is external to the platform instance processing by the first block instance the streaming input data to create processed data sending by the first block instance a notification to the block router that the first block instance has the processed data ready for output identifying by the block router that the processed data from the first block instance is to be directed to a second block instance of the plurality of block instances based on the routing table directing by the block router the processed data from the first block instance to the second block instance repeating the steps of processing sending identifying and directing for each of the plurality of block instances until a final block instance is reached wherein the final block instance creates output data and sending by the final block instance the output data to a destination that is external to the platform instance wherein each step from the step of receiving the streaming input data by the first block instance to the step of sending the output data from the final block instance occurs in real time without queuing the data within the platform instance.

The method of embodiment 1 further including receiving by the service manager a stop command from a source that is external to the platform instance wherein the stop command indicates that the service instance is to be stopped sending by the service manager the stop command to the block router and stopping by the block router the plurality of block instances.

The method of any of embodiments 1 or 1 1 further including receiving by the first block instance second streaming input data to be processed from a second source that is external to the platform instance wherein the second streaming input data is received immediately after the notification is sent to the block router that the first block instance has the processed data ready for output processing by the first block instance the second streaming input data to create second processed data sending by the first block instance a notification to the block router that the first block instance has the second processed data ready for output identifying by the block router that the second processed data from the first block instance is to be directed to the second block instance based on the routing table directing by the block router the second processed data from the first block instance to the second block instance repeating the steps of processing sending identifying and directing for each of the plurality of block instances until the final block instance is reached wherein the final block instance creates second output data and sending by the final block instance the second output data to a destination that is external to the platform instance wherein each step from the step of receiving the second streaming input data by the first block instance to the step of sending the second output data from the final block instance occurs in real time without queuing the data within the platform instance.

A method for execution on a digital device includes running a core process to create a platform instance of a processing platform wherein the platform instance interacts with an operating system on the digital device and is configured to run any service created using extendable base classes that have been defined for use within the processing platform identifying by the core process from configuration information corresponding to the platform instance that the platform instance is configured to run a service that is defined by a service class that extends a defined base service class wherein the configuration information further identifies a plurality of block classes to be used by the service wherein each block class extends a defined base block class and contains executable instructions that provide processing functionality for the service instantiating the service class to create a service instance and each of the block classes to create a plurality of block instances wherein the block instances have no awareness of one another and wherein the service instance is configured to direct data among the block instances and processing by the service instance incoming data using the block instances to provide the processing functionality to the platform instance.

The method of embodiment 2 further including creating by the core process a service context defining functionality of the platform instance that is external to the service instance and accessible by the service instance and passing the service context to the service instance when the service class is instantiated.

The method of embodiment 2 1 wherein creating the service context includes passing the service context to a module wherein the module inserts information needed by the service instance to use the module into the service context.

The method of any of embodiments 2 through 2 2 receiving by the core process a command to instantiate the service class.

The method of any of embodiments 2 through 2 3 further including receiving by the core process a command to stop the service instance and stopping by the core process the service instance wherein the core process continues running after the service instance has been stopped.

The method of any of embodiments 2 through 2 4 further including stopping the core process wherein the platform instance is destroyed when the core process is stopped.

The method of any of embodiments 2 through 2 5 wherein the service instance is configured to direct data among the block instances based on a routing table wherein a publication by one of the block instances is routed to another of the block instances based on the routing table.

The method of any of embodiments 2 through 2 6 wherein the service instance is run by the operating system as a separate process from the core process.

The method of any of embodiments 2 through 2 6 wherein the service instance is a thread of the core process.

The method of any of embodiments 2 through 2 8 further including converting all data entering the service instance into generic data objects wherein only the generic data objects are passed between the block instances.

The method of any of embodiments 2 through 2 9 further including identifying by the core process from the configuration information corresponding to the platform instance that the platform instance is configured to run a second service that is defined by a second service class that extends the defined base service class wherein the configuration information further identifies a plurality of second block classes to be used by the second service wherein each second block class extends the defined base block class and contains executable instructions that provide second processing functionality for the second service instantiating the second service class to create a second service instance and each of the second block classes to create a plurality of second block instances operating as part of the second service instance wherein the second block instances have no awareness of one another and wherein the second service instance is configured to direct data among the second block instances and processing by the second service instance incoming data using the second block instances to provide the second processing functionality to the platform instance.

The method of embodiment 2 10 wherein the service instance and the second service instance run simultaneously on the platform instance.

The method of any of embodiments 2 10 through 2 11 wherein the service instance and the second service instance communicate with one another.

The method of any of embodiments 2 10 through 2 12 wherein each of the service instance and the second service instance includes a communication manager that publishes communications for consumption by subscribed service instances.

A method for execution on a digital device includes running by a platform instance that is configured to interact with an operating system running on the digital device a service instance that is configured to use a routing table to direct data among a plurality of block instances that provide processing capability to the service instance wherein each block instance executes any internal instructions contained within that block instance asynchronously upon receiving input receiving by a first block instance of the plurality of block instances input data from a source that is external to the platform instance processing by the first block instance the input data to create processed data notifying by the first block instance the service instance of the processed data determining by the service instance that the processed data is to be directed to a second block instance of the plurality of block instances based on the routing table and transferring by the service instance the processed data to the second block instance for further processing.

The method of embodiment 3 further including accessing by the service instance functionality provided by a module that is part of a core process of the platform instance.

The method of any of embodiments 3 through 3 1 wherein the service instance includes a block router wherein the service instance communicates with a core process of the platform instance using the block router and the core process starts and stops the service instance.

The method of embodiment 3 2 wherein the core process communicates with at least one of the plurality of block instances through the block router.

The method of any of embodiments 3 1 through 3 3 wherein the configuration parameters of the first block instance are set by a user via the core process.

The method of any of embodiments 3 1 through 3 4 wherein the configuration parameters of the service instance are set by a user via the core process.

A method for using a configurable platform stored on a digital device includes receiving instructions by the digital device defining a service to be executed by the configurable platform wherein the service is represented within the configurable platform by a service class that extends a base service class defined for use within the configurable platform wherein defining the service includes identifying a plurality of blocks to be used by the service wherein each block is represented within the configurable platform by a block class that extends a base block class defined for use within the configurable platform defining instructions within at least one of the block classes wherein the instructions configure the block class to perform functionality defined by the instructions and defining within a routing table for each of the plurality of block classes any other of the plurality of blocks to which output is to be directed when that block produces output and receiving instructions by the digital device for saving the service in a memory accessible by the configurable platform.

The method of embodiment 4 wherein identifying the plurality of blocks to be used by the service includes defining a location remote from the digital device where at least one of the plurality of blocks is stored.

The method of any of embodiments 4 through 4 1 wherein identifying the plurality of blocks to be used by the service includes loading at least one of the plurality of blocks that was received as an attachment to a message.

The method of any of embodiments 4 through 4 2 further including receiving instructions by the digital device to label the service as an autostart service in a configuration file.

The method of any of embodiments 4 through 4 3 further including receiving instructions to run the configurable platform and executing a core process to create an instance of the configurable platform.

The method of any of embodiments 4 through 4 4 further including receiving instructions by the core process to run the service and starting by the core process a service instance that is an instantiation of the service class and a plurality of block instances that are instantiations of the block classes.

The method of any of embodiments 4 through 4 5 further including providing by the core process a graphical user interface wherein the graphical user interface enables a user to modify the service class and the plurality of blocks classes.

The method of any of embodiments 4 through 4 6 further including providing by the core process a graphical user interface that enables a user to modify the base service class and the plurality of base block classes.

The method of any of embodiments 4 through 4 7 further including providing by the core process a graphical user interface that enables a user to select and run an existing service from a plurality of existing services available on the configurable platform.

The method embodiment 4 8 further including providing by the core process a graphical user interface that enables a user to modify the existing service.

A method for using a configurable platform stored on a digital device includes receiving instructions by an operating system running on the digital device to start a core process corresponding to an instance of the configurable platform identifying by the core process a service to be executed by the configurable platform wherein the service is represented within the configurable platform by a service class that extends a base service class defined for use within the configurable platform identifying by the core process a plurality of blocks to be used by the service wherein each block is represented within the configurable platform by a block class that extends a base block class defined for use within the configurable platform starting by the core process the service starting by the service the blocks and processing by the blocks data received by the configurable platform from a source that is external to the configurable platform wherein the processing creates an output that is sent to a destination that is external to the configurable platform.

The method of embodiment 5 further including passing a service context from the core process to the service wherein the core context contains configuration information needed by the service.

The method of any of embodiments 5 through 5 1 further including determining by the service that a module is needed by a first block of the plurality of blocks wherein the module is provided by the core process and is configured to provide predefined functionality initializing by the service the module and passing by the service module information to the first block wherein the module information is used by the first block to access the predefined functionality of the module.

The method of any of embodiments 5 through 5 2 further including determining by the service that a module is needed by the service wherein the module is provided by the core process and is configured to provide predefined functionality initializing by the service the module and using by the service the predefined functionality of the module.

The method of any of embodiments 5 through 5 3 wherein the service includes a block router configured to receive a notification from a source block of the plurality of blocks that the source block has an output look up a destination block in a routing table corresponding to the source block and call the destination block to handle the output from the source block.

The method of embodiment 5 4 wherein all communications among the plurality of blocks pass through the block router.

The method of any of embodiments 5 through 5 5 wherein a block that is configured to pass output to another block contains destination information identifying the other block.

The method of any of embodiments 5 through 5 6 further including converting by a first block of the plurality of blocks the data into a plurality of data objects corresponding to an internal data object template that is defined for use within the configurable platform wherein all communications among the plurality of blocks are based on the internal data object template.

The method of any of embodiments 5 through 5 7 wherein the service is a first service of the plurality of services and the method further includes receiving instructions by the core process to start a second service of the plurality of services to be executed by the configurable platform wherein the second service is represented within the configurable platform by a second service class that extends the base service class identifying by the core process a plurality of second blocks to be used by the second service wherein each second block is represented within the configurable platform by a second block class that extends the base block class starting by the core process the second service and starting by the second service the second blocks.

The method of embodiment 5 8 further including processing by the second blocks data received by the configurable platform from a source that is external to the configurable platform wherein the processing creates an output that is sent to a destination that is external to the configurable platform.

The method of any of embodiments 5 8 through 5 9 further including processing by the second blocks data received from the first service wherein the processing creates an output that is sent to a destination that is external to the configurable platform.

The method of any of embodiments 5 8 through 5 10 further including processing by the second blocks data received from the first service wherein the processing creates an output that is sent to the first service.

A method for using a configurable platform on a digital device includes providing by the configurable platform a runtime environment that interacts with an operating system on the digital device and within which any service that is compatible with the configurable platform can be executed wherein the runtime environment includes a service manager configured to manage any service that extends a base service class that is defined for use within the configurable platform a configuration file that identifies any services loaded into the configurable platform for execution within the runtime environment and an application programming interface API that enables a user to configure a service for use within the configurable platform.

The method of embodiment 6 further including providing by the configurable platform a plurality of blocks to be used by the service wherein each block is represented within the configurable platform by a block class that extends a base block class defined for use within the configurable platform.

The method of any of embodiments 6 through 6 1 further including providing by the configurable platform a plurality of core modules accessible to the service manager but not accessible to any service executed within the runtime environment.

The method of any of embodiments 6 through 6 2 further including providing by the configurable platform a plurality of functional modules accessible to the service manager and to any service executed within the runtime environment.

The method of any of embodiments 6 through 6 3 further including loading a service identified in the configuration file and identifying any blocks to be used by the service wherein each block is represented within the configurable platform by a block class that extends a base block class defined for use within the configurable platform.

A method for use by a configurable platform stored on a digital device includes creating by a core process necessary for an instance of the configurable platform to exist on the digital device a service context that includes information needed for a service instance to be created on the configurable platform starting by a service manager of the core process a service instance to be executed by the configurable platform wherein the service instance is an instantiation of a service class that extends a base service class defined for use by the configurable platform and starting by a block router of the service instance based on the service context a plurality of block instances to be used by the service instance wherein each block instance is an instantiation of a block class that extends a base block class defined for use by the configurable platform and wherein each block instance contains instructions that are executed when an input is received by that block instance.

The method of embodiment 7 further including routing by the block router data among the plurality of block instances based on a routing table wherein each block instance is unaware of the other block instances and all communication between block instances relies on the block router.

The method of any of embodiments 7 through 7 1 wherein no queuing occurs within the service instance.

The method of any of embodiments 7 through 7 2 wherein one of the block instances uses a module provided by the core process.

The method of embodiment 7 3 further including initializing by the block router the module for use based on the service context and passing by the block router information about the module to the block instance that uses the module wherein the information about the module is needed by the block instance to use the module.

The method of any of embodiments 7 through 7 4 wherein the block router uses a module provided by the core process.

The method of embodiment 7 5 further including initializing by the block router the module for use by the block router based on the service context.

A method includes receiving by a block router that is part of a service instance running within a runtime environment provided by a platform instance of a configurable platform stored on a digital device a notification from a first block instance that the first block instance has produced an output object wherein the first block instance is one of a plurality of block instances that provide processing functionality to the service instance accessing by the block router a routing table wherein the routing table identifies a second block instance of the plurality of block instances as an output destination for output objects produced by the first block instance and routing by the block router the output object to the second block instance.

The method of embodiment 8 wherein the block instances have no awareness of the other block instances of the plurality of block instances.

The method of any of embodiments 8 through 8 1 wherein the notification from the first block instance is a call to a method defined within the service instance.

The method of any of embodiments 8 through 8 3 wherein routing the output object includes performing a call to the second block instance.

The method of embodiment 8 4 wherein the call to the second block instance includes the output object.

The method of any of embodiments 8 4 through 8 5 further including starting by the block router a thread for the second block instance.

The method of any of embodiments 8 through 8 6 further including receiving by the block router a message for the first block instance from a core process of the platform instance and passing by the block router the message to the first block instance.

The method of any of embodiments 8 through 8 7 wherein all communications between the core process and the plurality of block instances pass through the block router.

The method of any of embodiments 8 through 8 8 wherein a third block instance of the plurality of block instances communicates without going through the block router with at least one of a signal source and a signal destination that is external to the platform instance.

The method of any of embodiments 8 through 8 9 further including receiving by the block router a message to stop and stopping by the block router each of the plurality of block instances.

The method of any of embodiments 8 through 8 10 further including publishing by the block router information for consumption by subscribers of the service instance.

The method of any of embodiments 8 through 8 11 wherein the first block instance manages a data flow among a subset of the plurality of block instances based on a group routing table that identifies a data flow within the subset of block instances and all communications between the subset of block instances and the block router pass through the first block instance.

A method for configuring a service within a platform on a digital device includes providing by the configurable platform a runtime environment that interacts with an operating system on the digital device and within which any service that is compatible with the configurable platform can be executed wherein the runtime environment includes a service configuration file that contains information detailing an operation of a service within the runtime environment and an application programming interface API that enables a user to modify the service configuration file to configure the service receiving service configuration information about a plurality of blocks to be associated with the service wherein the service configuration information identifies a location of each of the plurality of blocks and identifies for each of the plurality of blocks that produces output to be consumed by another of the plurality of blocks the block to which the output should be directed and saving the service configuration information in the service configuration file for use when the service is started within the runtime environment.

The method of embodiment 9 wherein the service configuration information identifies a module to be used by the service wherein the module is provided by a core process within the runtime environment.

The method of any of embodiments 9 through 9 1 further including receiving block configuration information containing parameters for one of the blocks and saving the block configuration information in a block configuration file for use when the block is started within the runtime environment.

The method of embodiment 9 2 wherein the block configuration information identifies a module to be used by the block wherein the module is provided by a core process within the runtime environment.

The method of any of embodiments 9 through 9 3 further including receiving instructions to be executed by one of the blocks and saving the instructions in a block class file that is used to instantiate the block.

A method for providing a runtime environment on a digital device includes running a platform core wherein the platform core is a first process within an operating system on the digital device and provides the runtime environment running a first service that can only run within the runtime environment wherein the first service is a second process within the operating system and wherein the first service provides first data processing functionality using a first plurality of configurable blocks and running a second service that can only run within the runtime environment wherein the second service runs simultaneously with the first service and is a third process within the operating system and wherein the second service provides second data processing functionality using a second plurality of configurable blocks.

The method of embodiment 10 further including communicating by the first service and second service with one another within the runtime environment.

The method of any of embodiments 10 through 10 1 wherein any communication that occurs within the runtime environment uses a data object that complies with a data object template that is configured for use within the runtime environment.

The method of any of embodiments 10 through 10 2 further including using by the first service functionality provided by a module that is supported by the platform core.

The method of any of embodiments 10 through 10 3 wherein at least one block of the first plurality of blocks and the second plurality of blocks uses a single block configuration shared by the first service and the second service.

The method of any of embodiments 10 through 10 4 wherein the first plurality of blocks are threads of the second process and the second plurality of blocks are threads of the third process.

The method of any of embodiments 10 through 10 5 wherein the first service is an instantiation of a first service class that extends a base service class defined for use within the runtime environment and the second service is an instantiation of a second service class that extends the base service class.

The method of embodiment 10 6 wherein the first service class is identical to the second service class.

The method of embodiment 10 6 wherein the first service class is different from the second service class.

The method of any of embodiments 10 through 10 8 wherein the first data processing functionality is different from the second data processing functionality.

The method of any of embodiments 10 through 10 8 wherein the first data processing functionality is identical to the second data processing functionality.

The method of embodiment 10 10 further including performing load balancing by the first service and the second service to balance an amount of input data to be processed using the first processing functionality and the second processing functionality.

The method of any of embodiments 10 through 10 11 further including running a second platform core on the digital device wherein the second platform core is a fourth process within the operating system on the digital device and provides a second runtime environment that is separate from the runtime environment provided by the first process and running a third service that is fifth process within the operating system wherein the third service provides third data processing functionality using a third plurality of configurable blocks.

The method of embodiment 10 12 wherein the third service is identical to the first service and the method further includes performing load balancing by the first service and the third service to balance an amount of input data to be processed using the first processing functionality and the third processing functionality.

The method of any of embodiments 10 12 through 10 13 further including sending output data from the third service to the second service.

A method for configuring a service within a platform instance at runtime includes identifying by a platform instance that is running on a digital device and interacting with an operating system of the digital device a service that is to be run by the platform instance wherein the service is one of a plurality of available services that can be run by the platform instance and wherein the available services correspond to a single service class instantiating by the platform instance the service using the service class identifying by the platform instance a configuration file for the service wherein the configuration file contains predefined service configuration information that includes block information identifying a plurality of blocks that are to be run by the service wherein the blocks are based on a corresponding plurality of block classes that are usable by any of the available services and wherein each of the blocks provides task specific functionality when included in one of the available services configuring the service using the predefined service configuration information from the configuration file and dynamically generated information about the platform instance that is not known until after the platform instance has begun running wherein the configuring prepares the service to use the blocks by providing a plurality of routing directions that enable the service to route data between the blocks and running the service after the service is configured wherein the task specific functionality provided by the blocks is available to the platform instance when the service is running.

The method of embodiment 11 wherein the service class includes at least one configurable parameter and configuring the service includes assigning a configuration value to the configurable parameter.

The method of embodiment 11 1 wherein the configurable parameter defines an execution rule for the blocks.

The method of embodiment 11 2 wherein the execution rule determines whether the blocks will be executed synchronously or asynchronously.

The method of embodiment 11 1 wherein the configurable parameter identifies one of a plurality of block routers that is to be used by the service and the block router is responsible for passing data between the blocks.

The method of any of embodiments 11 through 11 4 further including instantiating a first block of the plurality of blocks from a first block class of the plurality of block classes identifying a first block configuration file for the first block configuring a first configurable parameter of the first block with a first configuration value from the first block configuration file and running the first block within the service.

The method of embodiment 11 5 further including instantiating a second block of the plurality of blocks from a second block class of the plurality of block classes identifying a second block configuration file for the second block configuring a second configurable parameter of the second block with a second configuration value from the second block configuration file and running the second block within the service.

The method of embodiment 11 6 wherein the first block class and the second block class are the same block class and the first block differs in functionality from the second block due to differences between the first block configuration file and the second block configuration file.

The method of any of embodiments 11 through 11 7 wherein the dynamically generated information identifies a module that is external to the service and part of the platform instance wherein the module is to be used by the service.

The method of embodiment 11 8 further including instantiating by the service an instance of the module for use by the service.

A method for configuring services within a platform instance at runtime includes identifying by a platform instance that is running on a digital device and interacting with an operating system of the digital device a first service and a second service that are to be simultaneously run by the platform instance instantiating by the platform instance the first service and the second service using a single service class identifying by the platform instance a first configuration file that identifies a plurality of first blocks that are to be run by the first service wherein each of the first blocks is configured to provide task specific functionality when run by the first service identifying by the platform instance a second configuration file that identifies a plurality of second blocks that are to be run by the second service wherein each of the second blocks is configured to provide task specific functionality when run by the second service configuring the first service using the first configuration file and dynamically generated information about the platform instance that is not known until after the platform instance has begun running wherein the configuring prepares the first service to use the first blocks by providing a first plurality of routing directions that enable the first service to route data between the first blocks configuring the second service using the second configuration file and the dynamically generated information wherein the configuring prepares the second service to use the second blocks by providing a plurality of routing directions that enable the second service to route data between the second blocks and running the first service and the second service simultaneously.

The method of embodiment 12 wherein configuring the first service includes applying a first configuration value from the first configuration file to a first configurable parameter of the first service and configuring the second service includes applying a second configuration value from the second configuration file to a second configurable parameter of the second service.

The method of embodiment 12 1 wherein the first configurable parameter instructs a block router used by the first service to execute the first blocks asynchronously and the second configurable parameter instructs a block router used by the second service to execute the second blocks synchronously.

The method of any one of embodiments 12 through 12 2 wherein the dynamically generated information identifies a module that is part of the platform instance and is external to the first service and the second service.

The method of embodiment 12 3 further including instantiating by the first service an instance of the module for use by the first service.

A method for displaying a plurality of media objects based on priority includes providing a matrix having a plurality of tiles wherein each tile represents a display location for a media object and is assigned one of a plurality of priority levels and wherein each priority level is associated with a minimum duration time and a maximum duration time tracking for each of the tiles a tile timer that represents how long the tile has been displaying a current media object assigned to that tile receiving a first media object that has been assigned one of the plurality of priority levels determining that the tile timer for a first tile of the plurality of tiles has exceeded the minimum duration time for the priority level assigned to the tile determining that the priority level of the first media object is identical to the priority level of the first tile and assigning the first media object to the first tile for display wherein the current media object being displayed at the first tile is replaced by the first media object.

The method of embodiment 13 further including receiving a second media object that has been assigned one of the plurality of priority levels determining that none of the tile timers for tiles having a priority level identical to the priority level assigned to the second media object have exceeded the minimum duration time and discarding the second media object without assigning the second media object to any of the tiles.

The method of any of embodiments 13 or 13 1 wherein each priority level is further associated with a new content duration time that has a shorter duration than the minimum duration time the method further comprising receiving a second media object that has been assigned one of the plurality of priority levels and has also been assigned a tag indicating that the second media object includes new content that has not previously been displayed determining that the tile timer for a second tile of the plurality of tiles has exceeded the new content duration timer for the priority level assigned to the tile wherein the new content duration time is used instead of the minimum duration time due to the presence of the tag determining that the priority level of the second media object is identical to the priority level of the second tile and assigning the second media object to the second tile for display wherein the current media object being displayed at the second tile is replaced by the second media object.

The method of embodiment 13 2 wherein the tile timer for the second tile has not yet exceeded the minimum duration time when the second media object is assigned to the second tile.

The method of any of embodiments 13 through 13 3 further including receiving a second media object that has been assigned one of the plurality of priority levels and has also been assigned a tag indicating that the second media object includes very important person VIP content that takes precedence over any other content type identifying each of the plurality of tiles that has a priority level that is identical to the priority level of the second media object determining that none of the identified tiles have passed their corresponding minimum duration times selecting a second tile from the identified tiles to use for the second media object based on at least one defined replacement criterion and assigning the second media object to the second tile.

The method of embodiment 13 4 wherein the defined replacement criterion is a least amount of remaining time and wherein selecting the second tile includes determining a remaining time for each of the identified tiles.

The method of embodiment 13 5 wherein determining the remaining time includes calculating for each identified tile a percentage of time remaining within a time window defined between the minimum duration time and the maximum duration time.

The method of embodiment 13 5 wherein determining the remaining time includes calculating for each identified tile a percentage of time remaining within a window defined between the new content duration time and the maximum duration time.

The method of embodiment 13 5 wherein determining the remaining time includes calculating for each identified tile a percentage of time remaining within a time window defined between the minimum duration time and the maximum duration time.

The method of embodiment 13 5 wherein determining the remaining time includes calculating for each identified tile a percentage of time remaining within a window defined between the new content duration time and the maximum duration time.

The method of any of embodiments 13 through 13 9 further including determining that a second tile of the plurality of tiles has displayed a second media object for a period of time longer than the maximum duration time of the second tile and replacing the second media object with a next received media object that has a priority level identical to the priority level of the second tile.

The method of any of embodiments 13 through 13 10 wherein each media object is assigned a priority level based on a source of the media object.

The method of any of embodiments 13 through 13 12 wherein each media object is assigned a priority level based on at least one content type corresponding to content of the media object.

The method of any of embodiments 13 through 13 13 wherein each media object contains content from one of a plurality of media sources and wherein each media object is in a single standardized format accepted by the matrix regardless of the content contained by the media object.

The method of any of embodiments 13 through 13 14 further including publishing the matrix for viewing.

A method for displaying media objects including providing a matrix having a plurality of tiles wherein each tile represents a display location for a media object on a user viewable display screen and is assigned one of a plurality of priority levels and wherein each priority level is associated with a maximum duration time receiving a stream of media objects wherein each media object has been assigned one of the plurality of priority levels determining for each tile whether the tile has exceeded the maximum duration time corresponding to the assigned priority level and for each tile that has exceeded its maximum duration time replacing a media object currently displayed by the tile with another one of the media objects having a priority level that matches the tile s priority level.

The method of embodiment 14 further including providing a user selectable region associated with a first tile of the plurality of tiles wherein selection of the user selectable region by a user prevents the media object being displayed at the first tile from being replaced.

The method of embodiment 14 1 wherein re selection of the user selectable region enables the media object being displayed at the first tile to be replaced.

The method of one of embodiments 14 through 14 2 further including providing a link associated with a first tile of the plurality of tiles wherein the link identifies a remote location storing an original source of the media object displayed at the first tile and wherein selection of the first tile opens the original source of the media object from the remote location.

The method of one of embodiments 14 through 14 3 further including providing a user selectable region covering at least a portion of a first tile of the plurality of tiles wherein selection of the user selectable region enlarges the first tile.

The method of embodiment 14 4 wherein the matrix rearranges when the first tile is enlarged to ensure that all the tiles of the matrix are visible.

The method of embodiment 14 4 wherein the media object being displayed at the first tile is not replaceable while the first tile is enlarged.

The method of embodiment 14 4 further including providing a link associated with the first tile wherein the link identifies a remote location storing an original source of the media object displayed at the first tile and wherein selection of the first tile opens the original source of the media object from the remote location.

The method of embodiment 14 4 further including discarding any media objects for which no tile is available.

The method of embodiment 14 4 wherein at least one of the media objects has been assigned a timestamp indicating when the media object was received wherein the method further comprises displaying a representation of the timestamp with the media object.

The method of embodiment 14 9 wherein the representation of the timestamp is an age of the media object.

A method including providing a matrix of repeatedly refreshing tiles for display to a user wherein each tile represents a display location for a media object receiving a stream of media objects representing content from a plurality of media sources and repeatedly updating each of the tiles with different media objects from the stream of media objects.

The method of embodiment 15 wherein each tile displays a media object for no longer than a defined maximum amount of time before the media object is replaced with another media object.

The method of embodiment 15 1 wherein the media object is replaced unless the tile is locked by the user to prevent the replacement from occurring.

A software architecture for a configurable processing platform for use on a device including a core configured to interact with an operating system on the device wherein the core is configurable to simultaneously run any of a plurality of services that are defined for the processing platform by configuration information wherein each service to be run on the processing platform is defined by a service class and the configuration information to include a set of platform specific instructions that enable the service to operate within the processing platform and a set of service specific instructions that enable the service to run a plurality of blocks that provide task specific functionality to the service and wherein each block to be run on the processing platform is defined by a block class and the configuration information to include a set of platform specific instructions that enable the block to operate asynchronously and independently from the other blocks within the processing platform and a set of task specific instructions that enable the block to perform a specific processing task for the service that uses the block wherein an order of execution of the blocks within the service is defined by the configuration information.

A processing system includes a processor and a memory coupled to the processor and containing instructions for execution by the processor the instructions for performing any of the methods or implementing the architecture described herein.

A computer program product configured to be operable to perform any of the methods or implementing the architecture described herein.

