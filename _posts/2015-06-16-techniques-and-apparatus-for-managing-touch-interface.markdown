---

title: Techniques and apparatus for managing touch interface
abstract: An apparatus may comprise a touch-sensitive user interface, a processor circuit; and a personalized touch event filter that includes a touch trainer module for execution on the processor circuit to generate a user touch profile based upon user touch input received at the touch-sensitive user interface, and a revising plug-in component for execution on the processor circuit to generate a revised touch event based upon a raw touch event received at the touch-sensitive user interface and the user touch profile.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09501175&OS=09501175&RS=09501175
owner: INTEL CORPORATION
number: 09501175
owner_city: Santa Clara
owner_country: US
publication_date: 20150616
---
This application is a continuation of claims the benefit of and priority to previously filed U.S. patent application Ser. No. 13 976 968 filed Jun. 27 2013 entitled TECHNIQUES AND APPARATUS FOR MANAGING TOUCH INTERFACE which is a U.S. national phase application of PCT CN2012 86281 filed Dec. 10 2012 both of which are incorporated herein by reference in their entirety.

Touch interfaces such as touchscreens are increasingly being deployed in computing devices communications devices entertainment devices and other components. As touch operation is increasingly improving its widespread adoption in such applications as mobile devices is changing the model of mobile device usage. In particular a typical touchscreen such as a capacitive touchscreen provides a different user experience as compared to pixel based devices such as a mouse or track pad. This is at least in part due to the multi touch experience afforded by touchscreens which may be sensitive to properties of a human finger such as pressure moving speed and size etc.

One issue that arises with this sensitivity is that typical touch operations employed in touchscreen interfaces may have poor accuracy especially as compared to mouse or track pad devices. This may lead to user dissatisfaction with operation of a touchscreen device in spite of advantages afforded by a touchscreen. If the results of touch inputs do not match a user s expectation a user has to revoke an operation and repeat the operation. This reduces the efficiency of device operation and boosts the power consumption of the device during operation. Moreover even though efforts are underway to develop a variety of more user friendly user interfaces UI to provide a better touch experience it remains difficult to equip the touch based UIs for all native or web applications.

In present day touchscreen devices the event simulators are typically designed to fetch raw data from the kernel of an operating system and to map it directly for the application involved in the particular touch event. If such raw touch events spring out without revision the upper application response may be far from a user s expectation. In general the accuracy and efficiency of interpreting touch events remain key issues that affect the touchscreen device user experience. In particular different users have different touching habits that are based on differences in finger size whether a device is held in the left or right hand sensitive finger snap and environmental noise.

Such personalized traits may involve many unclear or brand new events which do not take place in standard input devices such as pixel based mouse physical sensing keypad wheel and joystick. To solve these and other issues a developer has to prepare a variety of events filters to facilitate the ability of applications to adjust to each user which may difficult because of the large variation in individual traits across potentially hundreds of millions of users.

Various embodiments may be generally directed to methods and apparatus for interpreting touch input received at a user interface of an electronic device. Various embodiments are described herein provide apparatus methods and systems that process touch events based upon user specific characteristics. In particular the present embodiments may include various electronic apparatus that have a user interface that includes a device that detects signals based upon touch. Examples of electronic apparatus that may contain a touch sensing device include a remote control a touchscreen computer a personal digital assistant a cellular telephone smart phone a videogame player an audio player a home appliance digital music device and a display coupled to other devices. Each of these apparatus may employ a touch sensing device to provide touch input to perform one or more functions according to an application running in the electronic apparatus.

In accordance with various embodiments a personalized touch event filter PTEF is provided for an electronic apparatus having a touchscreen in order to generate revised touch events based upon events generated from touchscreen input by a user. In various embodiments the PTEF is designed to improve the ability of an application to provide accuracy for touch inputs received at the user interface by revising the raw events according to personalized characteristics. The PTEF may be embodied as software or a combination of software and hardware in various embodiments. In particular in some embodiments the PTEF may operate in the backend as a pluggable mapping of toolkits and may provide updated analysis of received touch events before transmitting the revised events to a touch event queue. A toolkit may represent a set of basic building units for user interfaces. The toolkit may be composed of software that is built on the top of an operating system windowing system or window manager in order to provide programs with an application programming interface.

The PTEF may be deployed such that applications can choose to receive revised personal touch events by enabling the PTEF or to directly receive raw touch events.

Various embodiments may comprise one or more elements. An element may comprise any structure arranged to perform certain operations. Some elements may be implemented as hardware software or any combination thereof as desired for a given set of design parameters or performance constraints. Although an embodiment may be described with a limited number of elements in a certain topology by way of example the embodiment may include more or less elements in alternate topologies as desired for a given implementation. It is worthy to note that any reference to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

During touchscreen operation user input may be received at various locations on the display surface as generally provided in known touchscreen devices. In some instances objects such as icons may be presented on the display surface that are selectable when a user touches the icon. In other instances a user may interact with the display surface through one or more operations such as a single tap double tap a sweeping gesture a squeeze or other gesture. As illustrated in the touchscreen device further includes a personalized touch event filter PTEF through which the touchscreen device may more accurately interpret such user operations. As noted above in conventional touchscreen devices the accuracy and efficiency of interpreting touch events remain key issues that affect the touchscreen device user experience. As detailed below a personalized touch event filter such as PTEF addresses this problem by providing among other features a personalized profile that takes into account user touch characteristics.

As further shown in the touchscreen device includes a memory which may be used to store a file or files that define a profile or profiles for user touch interaction with the touch based user interface . In some instances the memory may be included in the PTEF . The touchscreen device also includes a processor . According to some embodiments the PTEF may be operative on the processor to perform various tasks as described below with respect to the FIGs. to follow.

As further illustrated in the PTEF is operative to receive kernel raw events which may be generated when user input is detected at a user interface see touch based user interface in . Based upon information contained in the RCF the kernel raw events are converted into revised touch events which are output as revised touch events to the toolkits . By virtue of the information in the RC the revised touch events may reflect for example individual personalized characteristics of the user that generates the touch input received as kernel raw events . In this manner the touch input may be more accurately interpreted and acted upon by the appropriate application s .

In operation the touch trainer may be employed to develop and store a personalized touch profile or user touch profile for use in revising touch events received as kernel raw events . When active the touch trainer may determine user specific touch information based upon user interaction with a touchscreen. This interaction is shown as user training profiling input in . In general the touch trainer may generate a user s touch habit and adjusted thresholds or touch properties associated with the user for use by the PTEF . This information may specifically include the size and shape of a user s digit that interacts with the touchscreen the pressure applied when the touchscreen is engaged the rapidity of movement of a user s digit across the touchscreen the interval between taps when more than one tap is used to engage the touchscreen and so forth. The user touch profile may be generated and updated during initial training dedicated to developing the user touch profile as well as during device use when an actual application is running and the user touch input is received to direct operations to be performed.

As noted above the user specific information may be stored as a user touch profile in the RCF . As further illustrated in the touch trainer is operative to receive device information regarding the device though which user touch input is received. For example the device information may include touchscreen device properties of the touchscreen device . Examples of specific device information include the type of touchscreen technology employed by the touchscreen device such as capacitive touchscreen resistive touchscreen infrared touchscreen optical touchscreen and so forth. Other examples of device information include the sensitivity of the touchscreen to user input such as the amount of force required to register input in a touchscreen such as a resistive or capacitive touchscreen. Device information may also include information regarding pixel density of the touchscreen interface employed by the touchscreen device .

The combination of user training profiling input and device information may be employed to revise the kernel raw events when an actual application is running. Referring also to as an example in this manner the commands selections and other actions performed by a user via the touch based user interface may be more accurately and responsively performed thereby enhancing the user s experience with the touchscreen device .

In addition to the touch trainer the revising plug in group is operative to generate output for the PTEF to employ to revise kernel raw events in order to output the revised touch events . The revising plug in group may include multiple plug ins not shown that are each designed to address one or more touch features to improve accuracy of generating a touch event in response to user input. In particular the revising plug ins may analyze user touch information in the RCF in conjunction with raw touch input such as in the form of kernel raw events in order to generate revised touch events.

The press region identify plug in may be used for example to determine whether a series of touch events in fact constitute a single touch press event. It is typical that when a user s finger touches a touchscreen that the finger engaging the touchscreen moves unnecessarily for example from side to side which actions may cause an operating system in response to generate pointless touch move events in addition to the intended touch press event. The press region identify plug in is operative to address this circumstance by for example building a touch move events factory and by determining whether multiple regions generated by a user s inadvertent sloppy touch response are to be joined to represent a single touch press event. In one example multiple raw touch events may be deemed to constitute a single touch press event if the interval between touch move events is smaller than a predetermined threshold and the total area of the multiple touch events is less than a user touch area as predetermined by the personalized touch event filter. below details further aspects of determining a touch press event consistent with the present embodiments.

The jitter smoothing plug in may be used to facilitate accurate determination of whether a continuous tap constitutes a double tap event. In one implementation the jitter smoothing plug in may create a touch release events factor and set up a time stamp for every touch event in an event queue. The jitter smoothing plug in may generate a double tap output in response to a series of raw touch events if certain criteria are met. For example if the time interval between two raw touch release events is smaller than a threshold which may be prestored in an RCF and if the ratio of an intersection region of the raw touch events to the union area of the raw touch events exceeds a user preferred rate a double tap event may be output. below details further aspects of determining a double tap event consistent with the present embodiments.

The pressure threshold plug in may be employed to adjust threshold of pressure received in a raw touch event for determining an actual touch event. This adjustment may be based upon for example information in an RCF as determined by a touch trainer. Similarly the left right hand redress plug in may adjust raw touch events to account for the handedness of a user. The acceleration amplifier may adjust the acceleration recorded in a user gesture.

In order to properly manage touch input in a touchscreen device the present embodiments provide the ability to selectively activate components of a PTEF such as a touch trainer and or revising plug ins. depicts a configuration of the PTEF according to some embodiments. In the example shown the PTEF includes a touch trainer activation deactivation component and a revising plug in activation deactivation component . The touch trainer activation deactivation component is arranged to activate operation of the touch trainer . In one implementation of the touch trainer activation deactivation component a touchscreen device that includes the PTEF may provide a selectable item in a user interface that allows a user to activate or deactivate the touch trainer . The selectable item may be for example an icon or menu item presented on a touchscreen display. Thus when a user wishes to activate touch training the user may engage the item provided on the touchscreen display to launch the touch trainer . Once activated the touch trainer may then receive user input from the touchscreen in order to create or update a user touch profile that may be used by the PTEF to modify raw touch events subsequently received at the PTEF .

When it is not desirable for the touch trainer to be active the touch trainer activation deactivation component may be used to deactivate the touch trainer . Thus a user may select through an icon or other means to deactivate the touch trainer as desired. This may be useful under different circumstances. For example when an application is active in which user touch input is required to operate the application in some circumstances it may be desirable that the touch trainer remain active to update the user s touch profile to an RCF while in some cases it may be desirable that the touch trainer not remain active so that the revision of raw touch events received by the PTEF take place based upon the existing user touch profile. In particular if a touchscreen device containing the PTEF is to be used by a second user different from the user that created a user profile created for a first user via touch trainer it may be especially desirable to deactivate the touch trainer activation deactivation component before the second user employs the touchscreen device.

In particular the deactivation of the touch trainer prevents the inadvertent revision of a user touch profile for the first user based upon the touch characteristics of the second user. For example the second user may have digits that are very different in size than the first user and or may employ touch habits that are substantially different from those of the first user. In such circumstances where first and second user touch characteristics substantially differed were the characteristics of both the first and second user to be stored in a common user touch profile the results would not accurately reflect the touch characteristics of either user. Accordingly in operation when raw touch events generated by the first user were received by the PTEF while the user touch profile for the first user were active the revision of the raw touch events to reflect the first user s personal touch characteristics may not be as accurate as in the case where the user touch profile for the first user actually only contained touch input from the first user.

Consistent with the present embodiments the revising plug in activation deactivation component may also provide for selective activation or deactivation of the revising plug in group . When the revising plug in group is active one or more of the plug ins contained therein are active to process received raw touch events and to thereby generate revised touch events according to the operation of the individual plug in or plug ins. However as with the touch trainer activation deactivation component in some cases it may be desirable that one or more plug ins of the revising plug in group be inactivated. In such cases and consistent with the present embodiments a user may select to deactivate the revising plug in group .

In some embodiments individual plug ins of the revising plug in group may be individually selectable for activation deactivation. In this manner a user may tailor the type of operations if any to be performed on raw touch input events as desired. depicts one embodiment of the revising plug in activation deactivation component . In this example the revising plug in activation deactivation component includes multiple sub components that provide for the individual activation deactivation of respective individual plug ins that form part of a revising plug in group. In the example shown in the sub components illustrated correspond to the individual plug ins of the embodiment of the revising plug in group that is illustrated in . In particular the revising plug in activation deactivation component may include a press region identify activation deactivation component a pressure threshold activation deactivation component a jitter smoothing activation deactivation component a left right hand redress activation deactivation component and an acceleration amplifier activation deactivation component . The revising plug in activation deactivation component may further activation deactivation components for any other plug ins that may be provided in the revising plug in group which are generally depicted as the other plug ins activation deactivation components 

By providing individual activation deactivation for each plug in of the revising plug in group the embodiment of the revising plug in group activation deactivation component of allows a user to activate or deactivate only those plug ins of interest at any given instance. In the scenario suggested by for example a user may activate the press region identify plug in and jitter smoothing plug in by engaging a respective icon or other device not shown that engages the respective press region identify activation deactivation component and jitter smoothing activation deactivation component to activate their respective plug ins. Once active the press region identify plug in and jitter smoothing plug in may perform appropriate operations associated with each respective plug in when raw touch events are received by a PTEF containing the revising plug in group activation deactivation component . This scenario may take place for example when the user has determined that for a certain application the plug ins selected for activation such as the press region identify plug in and jitter smoothing plug in are most effective to accurately generate revised touch events that capture the user intention based upon input of raw touch events. Other plug ins on the other hand which may not be needed may be deactivated as also suggested by .

As noted previously in some cases multiple users may frequently or upon occasion use the same touchscreen device. To account for this the present embodiments provide the ability of a personalized touch event filter to store and employ multiple different user touch profiles so that the appropriate user touch profile may be used to revise raw touch events according to the current user of the touchscreen device containing the personalized touch event filter. Moreover multiple user touch profiles may be stored for the same user. This may be useful for example to tailor the user profile according to the type of activity and or application to be run on a touchscreen device. For example during browsing or reading of an electronic book the touch characteristics employed to engage a touchscreen may differ from the touch characteristics that the same user employs to create or read electronic mail. Accordingly an individual user may wish to activate a specific user touch profile based upon a planned activity to be performed on a touchscreen device.

Included herein is a set of flow charts representative of exemplary methodologies for performing novel aspects of the disclosed architecture. While for purposes of simplicity of explanation the one or more methodologies shown herein for example in the form of a flow chart or flow diagram are shown and described as a series of acts it is to be understood and appreciated that the methodologies are not limited by the order of acts as some acts may in accordance therewith occur in a different order and or concurrently with other acts from that shown and described herein. For example those skilled in the art will understand and appreciate that a methodology could alternatively be represented as a series of interrelated states or events such as in a state diagram. Moreover not all acts illustrated in a methodology may be required for a novel implementation.

At block device information is received for a user device for which the initial user training and profiling information is received. For example the device information may include touchscreen device properties.

At block the device information and the user training profile information is stored to a memory such as in a current revising configuration file RCF .

At block raw touch events generated by the user device are received. The raw touch events may be generated by an operating system kernel when an active application is running and a user interacts with a touchscreen of the user device. The raw touch events may be received by a personalized touch event filter arranged according to the embodiments disclosed herein.

At decision block a determination is made as to whether PTEF self training is active. The PTEF self training when active may allow the current RCF to receive updates based upon user interaction with the touch based interface of the user device. If at decision block a determination is made that the PTEF self training is not active then the logic flow proceeds to block .

At the block the received raw touch events are processed and revised according to the current latest RCF. Thus the current RCF may reflect a personalized touch profile for the user that was generated and stored based upon previous user interaction with a touchscreen of the user device. This current RCF is then used to generate revised touch events based upon the received raw touch events generated by the operating system kernel.

If at decision block a determination is made that the PTEF self training is active then the logic flow proceeds to block . At block a redo tip is generated when a user performs an unexpected operation while interacting with a touch based user interface such as a touchscreen. The unexpected operation may be analyzed and stored to an updated user profile in the PTEF. The flow then proceeds to block .

At block the RCF is updated based upon the unexpected user operation. The flow then proceeds to block . At block the detected raw events are processed and revised according to the updated RCF.

At block a determination is made as to whether a press region identify plug in is active. The press region identify plug in may form part of a set of plug ins of a revising plug in group as described hereinabove.

If the press region identify plug in is not active the flow moves to block . At block the raw touch events are processed without revision by the press region identify plug in.

If the press region identify plug in is determined to be active the flow moves to block . At the decision block a determination is made as to whether a time interval between succeeding touch events is smaller than a threshold. In one example the threshold may be set to reflect an interval that represents an upper limit that is indicative of a single touch event.

If at block it is determined that the interval between succeeding touch events is not less than the threshold the flow moves to block . At block one or more touch move events are output after an original touch press event is output.

If at block it is determined that the interval between succeeding touch events is less than the threshold the flow moves to block . At block a calculation is performed to determine an area Uthat represents the area of a single region defined by the sum of the multiple touch events. In one example the area Ur may be determined by adding up individual areas of touch events and subtracting from that sum the area corresponding to regions of overlap between touch events.

The logic flow then proceeds to decision block where a determination is made as to whether the value of Uis greater than a user s touch region. The user s touch region may be represented by an area that is characteristic of a user touch. In one example such an area may be determined by a touch trainer as detailed hereinabove and may be stored in a revising configuration file of the PTEF component.

If at block the value of Uis determined to not be greater than a user s touch region the flow proceeds to block . In this case a determination is made that the multiple raw touch events that were received do represent separate events. Accordingly one or more touch move events are output after an original touch press event is output.

If at block the value of Uis determined to be greater than a user s touch region the flow proceeds to block . At block a determination is made that the multiple raw touch events received actually represent only a single touch event. Accordingly only a single touch event touch press is output.

At block a determination is made as to whether a jitter smoothing plug in is active. The jitter smoothing plug in may form part of a set of plug ins of a revising plug in group as described hereinabove.

If the jitter smoothing plug in is not active the flow moves to block . At block the raw touch events are processed without revision by the jitter smoothing plug in.

If at block the jitter smoothing plug in is determined to be active the flow moves to decision block where a determination is made as to whether the time interval between two succeeding events is smaller than a threshold. In one example the threshold may be set to reflect an interval that represents an upper limit that is indicative of a double tap as opposed to a set of separate single taps. If at block a determination is made that the time interval is smaller than the threshold the flow moves to block .

At block a determination is made that because the interval between the raw touch events is longer than the threshold the raw touch events are meant to represent separate single taps. Accordingly the two single tap events are output as originally received.

If at block a determination is made that the time interval is not smaller than the threshold the flow moves to block . At block the area Uthat represents the area of a single region defined by the sum of the multiple touch events is determined. In addition the area of intersecting regions between the different touch events determined.

The flow then moves to decision block where a determination is made as to whether the ratio Uis larger than a user rate. If the ratio is larger than a user rate then the logic flow moves to block where two single tap events are emitted.

IF the ratio is smaller than a user rate the logic flow moves to block . At block a double tap event is output with an intersection region.

As shown in I O device RAM and ROM are coupled to processor by way of chipset . Chipset may be coupled to processor by a bus . Accordingly bus may include multiple lines.

Processor may be a central processing unit comprising one or more processor cores and may include any number of processors having any number of processor cores. The processor may include any type of processing unit such as for example CPU multi processing unit a reduced instruction set computer RISC a processor that have a pipeline a complex instruction set computer CISC digital signal processor DSP and so forth. In some embodiments processor may be multiple separate processors located on separate integrated circuit chips. In some embodiments processor may be a processor having integrated graphics while in other embodiments processor may be a graphics core or cores.

Some embodiments may be described using the expression one embodiment or an embodiment along with their derivatives. These terms mean that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment. Further some embodiments may be described using the expression coupled and connected along with their derivatives. These terms are not necessarily intended as synonyms for each other. For example some embodiments may be described using the terms connected and or coupled to indicate that two or more elements are in direct physical or electrical contact with each other. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other.

In one embodiment an apparatus may comprise a touch sensitive user interface a processor circuit and a personalized touch event filter that includes a touch trainer module for execution on the processor circuit to generate a user touch profile based upon user touch input received at the touch sensitive user interface and a revising plug in component for execution on the processor circuit to generate a revised touch event based upon a raw touch event received at the touch sensitive user interface and the user touch profile.

In another embodiment the touch trainer module may be for execution on the processor circuit to receive device information and to generate the user touch profile based upon the device information and the user touch input.

Alternatively or in addition in a further embodiment the touch trainer module may be for execution on the processor circuit to read a current user touch profile based upon touch input from a first user to receive additional touch input from the first user and to generate an updated user touch profile based upon the current user touch profile and the additional touch input.

Alternatively or in addition in a further embodiment the apparatus may include a touch trainer module activation deactivation component for execution on the processor circuit to place the touch trainer module in an active or an inactive state according to user selection.

Alternatively or in addition in a further embodiment the touch trainer module may be for execution on the processor circuit to store a first user specific profile based upon user touch input that is received at the user interface when a first action is performed by a user and to store a second user touch profile based upon user touch input that is received at the user interface when a second action different from the first action is performed by the user.

store a first user specific profile based upon first user touch input that is received at the user interface and store a second user touch profile based upon second user touch input that is received at the user interface.

Alternatively or in addition in a further embodiment the revising plug in group may include a press region identifier plug in for execution on the processor circuit to determine when a set of multiple touch invents represents one touch event and a jitter smoothing plug in for execution on the processor circuit to determine when a set of multiple touch release events represents a double tap event.

Alternatively or in addition in a further embodiment the revising plug in group may be for execution on the processor circuit to analyze a multiplicity of raw touch events and to generate a respective multiplicity of revised touch events.

Alternatively or in addition in a further embodiment the apparatus may include a plug in activation component for execution on the processor circuit to place one or more plug ins of the revising plug in component in an active or inactive state according to user selection.

Alternatively or in addition in a further embodiment the press region identifier plug in may be for execution on the processor circuit to calculate an area of the multiple touch events to determine if the area of the multiple touch events exceeds a user s touch region and to output a single touch press event if the area of the multiple touch events does not exceed a user s touch region.

Alternatively or in addition in a further embodiment the jitter smoothing plug in may be for execution on the processor circuit to calculate an area Uof the multiple touch release events calculate an area of intersection of the multiple touch release events determine if the area of the multiple touch events exceeds a user s touch region and output a double tap event when a ratio Usingle is not greater than a user s rate.

Alternatively or in addition in a further embodiment the apparatus may comprise a touchscreen display.

In a further embodiment a computer implemented method may include receiving one or more touch events generating a user touch profile based upon user touch input at the user interface and generating a revised touch event based upon a raw touch event received at the user interface and the user touch profile.

In a further embodiment a computer implemented method may include receiving user touch input at a touch sensitive user interface generating a user touch profile based upon the user touch input at the user interface and generating a revised touch event based upon a raw touch event received at the touch sensitive user interface and the user touch profile.

In a further embodiment the computer implemented method may include receiving device information and generating the user touch profile based upon the device information and the user touch input.

Alternatively or in addition in a further embodiment the computer implemented method may include placing the touch trainer module in an active or an inactive state according to user selection.

Alternatively or in addition in a further embodiment the computer implemented method may include storing a first user specific profile based upon user touch input that is received at the user interface when a first action is performed by a user and storing a second user touch profile based upon user touch input that is received at the user interface when a second action different from the first action is performed by the user.

Alternatively or in addition in a further embodiment the computer implemented method may include determining when a set of multiple touch invents represents one touch event and determining when a set of multiple touch release events represents a double tap event.

Alternatively or in addition in a further embodiment the computer implemented method may include analyzing a multiplicity of raw touch events and generating a respective multiplicity of revised touch events.

Alternatively or in addition in a further embodiment the computer implemented method may include placing one or more plug ins of the revising plug in component in an active or inactive state according to user selection.

Alternatively or in addition in a further embodiment the computer implemented method may include calculating an area of the multiple touch events determining if the area of the multiple touch events exceeds a user s touch region and outputting a single touch press event if the area of the multiple touch events does not exceed a user s touch region.

Alternatively or in addition in a further embodiment the computer implemented method may include calculating an area Uof the multiple touch release events calculating an area of intersection of the multiple touch release events determining if the area of the multiple touch events exceeds a user s touch region and outputting a double tap event when a ratio Usingle is not greater than a user s rate.

In a further embodiment an apparatus may be configured to perform the method of any one of the preceding embodiments.

In another embodiment at least one machine readable medium may comprise a plurality of instructions that in response to being executed on a computing device cause the computing device to carry out a method according to any one of the preceding embodiments.

It is emphasized that the Abstract of the Disclosure is provided to allow a reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description it can be seen that various features are grouped together in a single embodiment for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description with each claim standing on its own as a separate embodiment. In the appended claims the terms including and in which are used as the plain English equivalents of the respective terms comprising and wherein respectively. Moreover the terms first second third and so forth are used merely as labels and are not intended to impose numerical requirements on their objects.

What has been described above includes examples of the disclosed architecture. It is of course not possible to describe every conceivable combination of components and or methodologies but one of ordinary skill in the art may recognize that many further combinations and permutations are possible. Accordingly the novel architecture is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims.

Various embodiments may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements may include processors microprocessors circuits circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software may include software components programs applications computer programs application programs system programs machine programs operating system software middleware firmware software modules routines subroutines functions methods procedures software interfaces application program interfaces API instruction sets computing code computer code code segments computer code segments words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors such as desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

Some embodiments may be described using the expression coupled and connected along with their derivatives. These terms are not intended as synonyms for each other. For example some embodiments may be described using the terms connected and or coupled to indicate that two or more elements are in direct physical or electrical contact with each other. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other.

Some embodiments may be implemented for example using a computer readable medium or article which may store an instruction or a set of instructions that if executed by a computer may cause the computer to perform a method and or operations in accordance with the embodiments. Such a computer may include for example any suitable processing platform computing platform computing device processing device computing system processing system computer processor or the like and may be implemented using any suitable combination of hardware and or software. The computer readable medium or article may include for example any suitable type of memory unit memory device memory article memory medium storage device storage article storage medium and or storage unit for example memory removable or non removable media erasable or non erasable media writeable or re writeable media digital or analog media hard disk floppy disk Compact Disk Read Only Memory CD ROM Compact Disk Recordable CD R Compact Disk Rewriteable CD RW optical disk magnetic media magneto optical media removable memory cards or disks various types of Digital Versatile Disk DVD a tape a cassette or the like. The instructions may include any suitable type of code such as source code compiled code interpreted code executable code static code dynamic code encrypted code and the like implemented using any suitable high level low level object oriented visual compiled and or interpreted programming language.

Unless specifically stated otherwise it may be appreciated that terms such as processing computing calculating determining or the like refer to the action and or processes of a computer or computing system or similar electronic computing device that manipulates and or transforms data represented as physical quantities e.g. electronic within the computing system s registers and or memories into other data similarly represented as physical quantities within the computing system s memories registers or other such information storage transmission or display devices. The embodiments are not limited in this context.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

Numerous specific details have been set forth herein to provide a thorough understanding of the embodiments. It will be understood by those skilled in the art however that the embodiments may be practiced without these specific details. In other instances well known operations components and circuits have not been described in detail so as not to obscure the embodiments. It can be appreciated that the specific structural and functional details disclosed herein may be representative and do not necessarily limit the scope of the embodiments.

