---

title: Conversation assistance system
abstract: Systems and methods for providing conversation assistance include receiving from at least one user device of a user, conversation information and determining that the conversation information is associated with a conversation involving the user and a first person that is associated with first conversation assistance information in a non-transitory memory. Body measurement data of the user is retrieved from the at least first user device. A need for conversation assistance in the conversation involving the user and the first person is detected using the body measurement data. First conversation assistance information associated with the first person is retrieved from the non-transitory memory. The first conversation assistance information associated with the first person is provided through the at least one user device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09635167&OS=09635167&RS=09635167
owner: PAYPAL, INC.
number: 09635167
owner_city: San Jose
owner_country: US
publication_date: 20150929
---
The present disclosure generally relates to mobile communication networks and more particularly to a conversation assistance system that may provide conversation assistance to users using mobile communication devices.

People can now communicate and interact with more people than ever before. To keep in contact with friends business associates and or other relationships people are increasingly joining social networks and sharing various types of information via those social networks. For example people may share family information with others that they are connected to via friend networks such as for example those provided by FACEBOOK and share business information with others that they are connected to via business networks such as for example those provided by LINKEDIN .

However while people are more connected than ever before it can sometimes be hard for a person to remember the name or other information of another person when interacting with that other person e.g. particularly when that interaction is unexpected or the previous connection was brief or distant which can make it difficult or awkward to start or carry on a conversation. Conventional solutions to this problem include the person attempting to search the Internet to retrieve for information about the other person e.g. from a social network on a portable device. However such searches are time consuming and can interrupt a conversation that has already begun with the other person.

Embodiments of the present disclosure and their advantages are best understood by referring to the detailed description that follows. It should be appreciated that like reference numerals are used to identify like elements illustrated in one or more of the figures wherein showings therein are for purposes of illustrating embodiments of the present disclosure and not for purposes of limiting the same.

The present disclosure provides systems and methods for providing conversation assistance to a user for a conversation involving the user and at least one other person. Various user devices may be used during a conversation by the user with a person and may be configured to capture conversation information including body measurement data of the user. In some embodiments the body measurement data may include heart rate data temperature data and or perspiration data. The conversation information from the user devices may be determined to be associated with a conversation involving the user and the first person and may be used to automatically detect that the user needs conversation assistance in the conversation. Information types of conversation assistance information that the user needs may then be automatically and dynamically determined. For example it may be determined that the user needs information about the family of a first person when the first person starts to talk about his family. Determined conversation assistance information may then be retrieved and provided to the user. In some embodiments the conversation assistance information is provided according to a conversation assistance information configuration. In one example the conversation assistance information configuration may provide for the display of an image that is associated with the name of the first person in order to help the user remember the first person s name. However these embodiments are meant to be merely exemplary and one of skill in the art will recognize that a variety of modifications may be made to the conversation assistance system discussed below without departing from the scope of the present disclosure.

Referring now to an embodiment of a method for providing conversation assistance is provided. The method begins at block where conversation information associated with a conversation is received from an at least one first user device used by a first user. Various embodiments of one or more user devices may be used during a conversation and the first user device may be configured to capture the conversation information associated with the conversation by itself and or via communication with others of the user devices. In some embodiments the conversation information may include body measurements data e.g. heart rate data temperature data perspiration rate data and or any other data that may be captured via body measurements gesture information e.g. interaction gesture information hand gesture information and or other gesture information audio information location data and or a variety of other information that may be used to identify characterize and otherwise analyze the conversation. At block in some embodiments the first user device may save the conversation information and or send the conversation information over a network such as for example the Internet. For example the first user device may send the conversation information to a system provider device that operates to provide the conversation assistance system e.g. a conversation assistance system provider device operated by a conversation assistance system provider a third party system provider device operated by a third party system provider and or any other provider of the conversation assistance system . However in some embodiments the conversation assistance functionality discussed below may be performed by the first user device without the need for a network connected system provider device.

Referring now to an embodiment of a first user device being used in a conversation is illustrated. In the embodiment illustrated in only one person other than the first user is illustrated as a participant of a conversation. However in some embodiments multiple persons other than the first user may participate in a conversation which will be discussed in detail below with reference to . As illustrated in the embodiment of a first user device is being used by a first user during a conversation with a first person that in the illustrated embodiment uses a broadcast user device .

In the illustrated embodiment of the first user device and the broadcast user device are wearable devices e.g. smart watches such as for example the Apple Watch available from Apple Inc. of Cupertino Calif. . However the first user device and the broadcast user device may be other types of devices e.g. other wearable devices such as smart glasses mobile devices such as phones etc. while remaining within the scope of the present disclosure. In some embodiments the broadcast user device may be substantially similar to the first user device . In some embodiments the broadcast user device may be a device of a type that is different from the first user device . In some embodiments one or more first user devices may be used by the first user e.g. a plurality of wearable devices one or more wearable devices and a mobile phone etc. . In some embodiments the first user may be in a position during the conversation e.g. facing the first person such that the first user device e.g. smart glasses may capture images and or gestures of one or both of the first user and the first person .

In some embodiments the first user may instruct the first user device when to begin capturing the conversation information e.g. via a voice command a selection of a physical or graphical input etc. . In some embodiments the first user device may continuously capture the conversation information at an event e.g. a birthday party a business conference where conversations may occur based on for example recognition of the event in a user s calendar based on a location and publicly available information on the Internet etc. In some embodiments the first user device may be informed e.g. by the first user or may automatically recognize the beginning of a conversation e.g. based on detected audio detected gestures and or other conversation initiator information known in the art and in response may begin capturing conversation information until the first user device determines that conversation has ended e.g. via detected audio detected gestures and or other conversation ending information known in the art .

In some embodiments the conversation information may include location data indicating the location of the first user . In some embodiments the first user device provides location data based on the location of the first user and or the first user device . For example the first user device may include a location determination device e.g. a Global Positioning System GPS device a cell tower triangulation device a Wi Fi location determination device and or a variety of other location determination devices known in the art to determine location data related to a current location of the first user device . For example the first user device may be a mobile phone or wearable device that changes locations as the first user moves and may provide the current location of the first user using the location determination device discussed above. In some embodiments the first user may be prompted by the first user device to provide its current location. In some embodiments a system provider device may retrieve the conversation information that includes the location determined by the first user device over the network.

In some embodiments the conversation information may include body measurement data of the first user . For example the first user device may provide perspiration data of the first user captured by the perspiration sensor of the first user device . In another example the first user device may provide heart rate data of the first user using a heart rate sensor of the first user device . In yet another example the first user device may provide temperature data of the first user using a temperature sensor of the first user device . While a few specific examples of body measurement data have been described one of skill in the art in possession of the present disclosure will recognize that any of a variety of body measurements may be made and provided by the first user device while remaining within the scope of the present disclosure.

In some embodiments the conversation information may include audio information that captures one or more statements e.g. spoken by the first user and or the first person during a conversation . In some embodiments the first user device may be configured to receive audio information from the first user and or the first person . For example a microphone or other audio capturing system in the first user device may be configured to capture audio information of statements made by one or both of the first user and the first person . In some embodiments a speech recognition engine e.g. provided by a processing system executing instructions on a memory system in the first user device may be configured to analyze the audio information to recognize the corresponding statements. While the analysis of the audio information to recognize the statements has been discussed as being performed in the first user device in some embodiments the audio file may be sent to the system provider device and then analyzed by a speech recognition engine in the system provider device to determine the corresponding statements while remaining within the scope of the present disclosure.

In some embodiments the conversation information may include gesture information corresponding to a gesture of the first user and or the first person . In some embodiments the gesture information may include interaction gesture information corresponding to an interaction gesture e.g. a handshake a hug a bow a kiss on the cheek and or other interaction gestures known in the art . In one example the interaction gesture may be a gesture of the first user requesting interaction with the first person e.g. a gesture to request a handshake by extending the right hand towards the first person . In some embodiments the gesture information may include hand gesture information corresponding to a hand gesture e.g. an ok hand gesture using a thumb and a forefinger of the hand of the first user or the first person . In one example the hand gesture may be made by extending a specific number of fingers in a direction parallel to a top surface of the first user device .

In some embodiments the first user device may capture gesture information corresponding to gestures provided by the first user and or the first person . For example a camera in the first user device may capture an image or video corresponding to gestures of the first user and or the first person . In another example a motion sensor e.g. an accelerometer in the first user device worn on the wrist of the first user may capture movement data e.g. up and down motion indicative of hand shaking associated with a gesture e.g. a handshake . In some embodiments a gesture recognition engine e.g. in the first user device service provider device or any other device may be configured to analyze the gesture information including the images videos motion data and or other gesture information to determine the gesture performed by the first user and or the first person .

In some embodiments the first user device may include other sensors such as position sensors muscle tension sensors network communication devices and or a variety of other sensors known in the art that may be used to determine and transmit conversation information and as such may provide other functions related to conversation . In an example a muscle tension sensor may be used to capture gesture information corresponding to a gesture e.g. gripping a hand during a handshake . In another example a wireless communication device in the first user device may be used to transmit and receive information e.g. conversation information over the network .

A variety of devices may be suitable for implementing the first user device . As discussed above the first user device may be a wearable device e.g. Google Glass available from Google Inc. of Mountain View Calif. Apple Watch available from Apple Inc. of Cupertino Calif. etc. . However in another example the first device may be a mobile phone or other mobile computing device known in the art. One of skill in the art will recognize a variety of other portable mobile user devices and or wearable user devices may be utilized in at least some embodiments without departing from the scope of the present disclosure.

In some embodiments the first user may use the first user device to provide the system provider device with first user information of the first user over the network. For example first user information of the first user may include a user name a user identification number a user account number a user password login information of various social networks and or a variety of other information known in the art for associating the first user with a first user account. In some embodiments the first user may sign into an account with the system provider device before or during conversation .

In some embodiments similar to the first user device the broadcast user device may be used by the first person to provide the system provider device with first person information of the first person over the network. As such the first user device may receive first person information of the first person from broadcast user device and send the received first person information of the first person to the service provider device. In one example the first user device may be configured to receive information broadcast by the broadcast user device when the first user device is within a predetermined distance of the broadcast user device e.g. a conversation distance of approximately 4 feet . In another example the first user device may receive the first person information of the first person from the broadcast user device when the first user is within the broadcast range of the broadcast user device . In another example the first user device may receive the first person information of the first person from broadcast user device when the first person provides an instruction to do so e.g. by pointing a hand or the broadcast user device in the direction of the first user . In another example the first user device may receive the first person information of the first person from broadcast user device when the first user is associated with the first person e.g. the first user is associated with the first person via a social network by a second degree connection .

Thus in some embodiments the system provider device may receive conversation information associated with a conversation involving the first user and first person along with user information that is associated with a user account and or first person information that is associated with the first person account.

While a few example of the conversation information received from the first user device have been provided one of skill in the art in possession of the present disclosure will recognize that a wide variety of systems and methods for providing receiving storing determining and or otherwise communicating conversation information at block will fall within the scope of the present disclosure.

Referring now to the method then proceeds to block where a need for conversation assistance and conversation assistance information types also referred to below as information types is determined for example according to the received first conversation information the body measurement data conversation assistance settings and or any of the other information described herein.

In some embodiments the conversation assistance settings may be default conversation assistance settings provided by the conversation assistance system while in other embodiments the conversation assistance settings may be configured by the first user . As discussed below the conversation assistance settings may include body measurement settings region settings language settings interaction gesture settings hand gesture settings audio settings and or settings for any other information that may be captured determined and or otherwise utilized in the conversation assistance system.

In some embodiments conversation assistance settings include body measurement settings. In some embodiments body measurement data may indicate that a user needs or desires conversation assistance. For example particular body measurements such as an increased heart rate increased perspiration increased body temperature and or other indications of user anxiety may indicate that a user is nervous or anxious. The detection of such nervousness and or anxiousness in combination with determinations that a conversation has begun may be indicative that the user is beginning a conversation with a person whose name or other important information they have forgotten or otherwise should know.

Referring now to an embodiment of a first user device displaying a conversation assistance settings screen is illustrated. As illustrated in the first user device includes a display displaying a conversation assistance settings screen that includes a body measurement settings section . The body measurement settings section may include body measurement settings and each of which includes a body measurement type a reference a criterion and an enablement status . In the particular example illustrated in for example the body measurement setting includes a body measurement type of heart rate a reference of 70 beats every minute a criterion of greater than 85 beats per second and an enablement status of YES . In another example the body measurement setting includes a body measurement type of body temperature a reference of 36.5 C. a criterion of greater than 37 C. or less than 36 C. and an enablement status of NO. In another example the body measurement setting includes a body measurement type of perspiration rate a reference of 0 a criterion of greater than 0.5 milligram per square centimeter per minute and an enablement status of YES .

In some embodiments the first user device may determine references of the body measurement settings according to body measurement data captured when the first user does not need or want conversation assistance. For example references may be determined according to body measurement data captured when the first user is not engaged or is not about to engage in a conversation or alternatively and or in combination with the first user engaging or about to engage in a conversation but not in need of conversation assistance. In some embodiments the first user device may determine criteria of body measurement settings during a training period with a training set of body measurement data which may be captured during previous conversation s where the first user indicates that conversation assistance is needed. The criteria may be based on an average of the training set the lowest and or highest value of the training set and or other criterion determination methods known in the art.

In some embodiments body measurement settings may be associated with or adjusted according to environmental factors e.g. a time of day the ambient temperature humidity and or other environmental factors known in the art . For example body measurement settings may be associated with a time of day and include a morning body measurement setting an afternoon body measurement setting and an evening body measurement setting each of which may be used based on the time of the conversation . In another example the captured body measurement data may be adjusted according to a time of day to reduce possible error caused by environment factors. In some embodiments the first user may configure the body measurement settings to for example disable or enable a particular body measurement setting. Using the specific example of the conversation assistance settings illustrated in if the first user would like to save the conversation assistance settings including body measurement settings and e.g. on the first user device on the system provider device or any other device the first user may select the SAVE choice in the body measurement settings section .

In some embodiments body measurement settings may be updated according to the first user s feedback regarding any conversation. For example the first user device may detect that conversation ends e.g. according to audio information that includes the statement goodbye send a feedback request to the first user and receive feedback from the first user . In another example the first user device may automatically detect feedback from the first user e.g. according to audio information that includes the statement conversation assistance is not needed . In some embodiments the first user device may update the body measurement settings according to the feedback received from the first user . In one example the feedback may indicate that the first user did not need conversation assistance in conversation when the heart rate of the first user was between 87 and 97 beats per minute. Accordingly to the feedback the first user device may update the criterion of the body measurement setting to be greater than 97 beats every minute.

In some embodiments conversation assistance settings may include a region setting and a language setting. Referring now to an embodiment of a first user device displaying a conversation assistance settings screen is illustrated. As illustrated in the first user device includes a display displaying a conversation assistance settings screen that includes a region and language section including a region setting e.g. Japan and a language setting e.g. Japanese . In different embodiments the region setting and or language setting may be automatically determined by the first user device using the location data of the conversation information or be provided by the first user e.g. Japanese for a special event involving Japanese guest . In some embodiments a speech recognition engine e.g. in the first user device service provider device or any other device may recognize the language of the audio information in conversation information and the first user device may automatically configure the language setting according to the recognized language.

In some embodiments conversation assistance settings may include interaction gesture settings. As illustrated in in some embodiments the conversation assistance settings screen may include an interaction gesture settings section which includes interaction gesture settings and . Each interaction gesture setting may include an interaction gesture type and an indicator status . For example as illustrated in the interaction gesture settings and provide interaction gesture types e.g. handshake bow indicating a need for conversation assistance according to the indicator status of Yes . On the other hand the interaction gesture settings and provide interaction gesture types e.g. hug kiss on the cheek that do not indicate a need for conversation assistance according to the indicator status of No . In some embodiments some interaction gesture settings e.g. interaction gesture setting associated with a bow are automatically provided by the first user device e.g. according to greeting etiquette associated with a region setting of Japan . In some embodiments some interaction gesture settings are configured by the first user for example according to the first user s personal greeting preferences.

In some embodiments conversation assistance settings may include audio settings. As illustrated in the conversation assistance settings screen includes an audio settings section providing statements indicating a need for conversation assistance and or information types needed by the first user . Audio settings section may include audio settings and each of which may include at least one statement and an information type . In the example illustrated in the audio setting includes statements Hey you . . . Long time no see and Hey man . . . which correspond to an information type for the name of the first person involved in conversation . In another example the audio setting includes a statement How is life corresponding to an information type for the wife and children of the first person involved in conversation . In some embodiments some audio settings e.g. an audio setting including a statement Konnichiwa may be automatically provided by the first user device for example according to greeting etiquette corresponding to the region setting e.g. Japan and or the language setting e.g. Japanese . In some embodiments the audio settings are configured by the first user for example according to the first user s personal preferences of greetings.

Using the specific example of the conversation assistance settings illustrated in if the first user would like to save the conversation assistance settings including region setting language setting interaction gesture settings and audio settings e.g. on the first user device on the system provider device or any other device the first user may select the SAVE choice in the conversation assistance settings screen .

In some embodiments conversation assistance settings may include hand gesture settings. Referring now to the example of the first user device includes a display displaying a conversation assistance settings screen that includes a hand gesture settings section including hand gesture settings and . Each hand gesture setting may include a hand gesture type and information type . For example the hand gesture setting provides that an ok hand gesture indicates the first user needs information about the children of the first person . In another example the hand gesture setting provides that a hand gesture of extending one finger indicates that the first user needs information about the name of the first person . In another example the hand gesture setting provides that a hand gesture of extending two fingers indicates the first user needs information about the employer and job title of the first person . As discussed below the hand gesture settings may be provided by the first user to activate the conversation assistance system discreetly such that conversation assistance may be provided to the first user without knowledge of the first person .

In some embodiments the first user device may determine that a particular gesture may be offensive e.g. a thumb down hand gesture according to the region setting e.g. Japan and or language setting e.g. Japanese and exclude the particular gesture from hand gestures that the first user may be able to choose in the hand gesture settings section .

Using the specific example of the conversation assistance settings illustrated in if the first user would like to save the conversation assistance settings including the hand gesture settings e.g. on the first user device on the system provider device or any other device the first user may select the SAVE choice in the conversation assistance settings screen .

In some embodiments conversation assistance settings may include conversation history settings. As illustrated in the first user device includes a display displaying a conversation assistance settings screen that includes a conversation history settings section including conversation history settings and . Each conversation history setting may include a last conversation time a last conversation setting and an information type needed by the first user . In the example of the conversation history setting provides that if the last conversation between the first user and the first person happened within the last month then the first user needs conversation assistance information of information types for the wife and children but not the name of the first person . In another example the conversation history setting provides that if the last conversation between the first user and the first person happened over one month ago in a social setting e.g. a birthday party the corresponding information types are associated with for the name wife and children of the first person . In another example the conversation history setting provides that if the last conversation happened over one month ago in a business setting e.g. a business conference the corresponding information types are for the name employer and job title of the first person .

Referring back to at block in some embodiments during conversation or when conversation is about to happen the first user device may retrieve the conversation assistance settings e.g. from the first user device the system provider device or any other device and determine the need for conversation assistance and conversation assistance information types needed by the first user according to conversation assistance settings.

In some embodiments the first user device determines the need for conversation assistance according to the body measurement data of the conversation information and body measurement settings. In one example the body measurement data of the conversation information may include heart rate data e.g. with a heart rate of 86 beats each minute body temperature data e.g. with a temperature of 37.1 C. and perspiration rate data e.g. with a perspiration rate of 0.6 milligram per square centimeter per minute . The first user device may analyze the body measurement data of the conversation information using the criterion of enabled body measurement settings e.g. body measurement settings and of and determine that the first user needs conversation assistance because the body measurement data meet the criterion of enabled body measurement setting e.g. greater than 85 beats per minute and or the criterion of enabled body measurement setting e.g. greater than 0.5 milligram per square centimeter per minute . In the particular example illustrated in the body temperature data would not be used because body measurement setting associated with body temperature is not enabled.

In some embodiments the first user device determines the need for conversation assistance according to the interaction gesture information of the conversation information and interaction gesture settings . The interaction gesture information of the conversation information corresponds to an interaction gesture of the first user . In one example the corresponding interaction gesture is a handshake and the first user device may determine that the first user needs conversation assistance in conversation according to the indicator status of Yes in the interaction gesture setting associated with a handshake. In another example the corresponding interaction gesture is a hug and the first user device may determine that the first user does not need conversation assistance in conversation according to the indicator status of No in the interaction gesture setting associated with a hug.

In some embodiments the first user device determines the need for conversation assistance according to the audio information of the conversation information and audio settings . The audio information of the conversation information may correspond to one or more statements of the first user . In one example the corresponding statement is Hey you . . . . The first user device may determine that the first user needs conversation assistance in conversation according to audio setting associated with the statement Hey you . . . . In another example the corresponding statement is Hi James provided by the first user or Hi my name is James provided by the first person and the first user device may determine that the first user does not need conversation assistance for the name of the first person in conversation because it determines that the first person s name e.g. James has already been spoken e.g. by the first user or the first person .

In some embodiments the first user device may also determine the information types needed by the first user in conversation according to the audio information of the conversation information and audio settings . In one example the statement corresponding to the audio information is How is life The first user device may determine that the first user needs conversation assistance information of information types associated with the wife and children of the first person according to information types of audio setting

In some embodiments the first user device may determine the need for conversation assistance according to the hand gesture information of the conversation information and hand gesture settings . The hand gesture information of the conversation information may correspond to a hand gesture of the first user . In one example the corresponding hand gesture is an ok hand gesture. The first user device may determine that the first user needs conversation assistance in conversation according to the hand gesture setting associated with the ok hand gesture.

In some embodiments the first user device may also determine the information types needed by the first user in conversation according to the hand gesture information of the conversation information and hand gesture settings . In one example the corresponding hand gesture is a hand gesture of extending two fingers. The first user device may determine that the first user needs conversation assistance information of information types for the employer and job title of the first person according to information types of hand gesture setting associated with the hand gesture of extending two fingers.

In some embodiments the first user device may also determine the information types needed by the first user in conversation according to the conversation history information and conversation history settings . The conversation history information may be collected e.g. by the first user device system provider device or any other device from previous conversation s between the first user and the first person stored in a database e.g. a conversation assistance information database . In one example the conversation history information indicates that the last conversation between the first user and first person happened over a month ago in a business setting. The first user device may determine that the first user needs conversation assistance information of information types for the name employer and job title of the first user according to the information type of conversation history setting associated with the last conversation time and setting of the last conversation.

While the analysis of the determination of the need for conversation assistance and information types has been discussed as being performed in the first user device in some embodiments the conversation information may be sent to the system provider device and then analyzed by the system provider device to determine a need for conversation assistance and information types while remaining within the scope of the present disclosure. Furthermore while a variety of specific information uses has been described to determine whether to provide conversation assistance and what type of conversation assistance to provide different combinations of conversation information as well as other information not discussed explicitly above may be utilized in the method while remaining within the scope of the present disclosure.

Referring now to the method now proceeds to block where conversation assistance information associated with the first person is retrieved. Conversation assistance information of various information types may be retrieved from various information sources. Referring now to an embodiment of a conversation assistance system with various information sources is illustrated. The conversation assistance system includes a system provider device communicatively coupled through a network to the first user device and the broadcast user device . The system provider device is further communicatively coupled to a conversation assistance information database . While illustrated as a single database that is directly connected to the system provider device the conversation assistance information database may be provided in multiple databases and or may be coupled to the system provider device by the network . The system provider device is further communicatively coupled to a first social network and a second social network . In some embodiments the system provider device may receive conversation information from the first user device and may further analyze conversation information received from the first user device e.g. the audio information body measurement data gesture information etc. . In some embodiments the system provider device may determine that the first user needs conversation assistance in conversation and conversation assistance information types needed by the first user .

In some embodiments the system provider device may select information sources e.g. the social networks and the broadcast user device the conversation assistance information database other information sources and or combinations thereof for retrieving conversation assistance information according to the information types needed by the first user and the specific information types provided by respective information sources. In some embodiments different information sources may provide conversation assistance information that includes different information types. In some embodiments instead of retrieving conversation assistance information of all information types from all information sources the system provider device only retrieves conversation assistance information from selected sources which may improve the performance e.g. in computation bandwidth speed power consumption of the conversation assistance system .

In some embodiments the broadcast user device may provide conversation assistance information of specific information types e.g. for a name a real time speaking status a look discussed further below and or a real time location which may be determined according to broadcast settings. Referring now to in some embodiments the first person involved in the conversation may configure broadcast user device to broadcast conversation assistance information of specific information types associated with the first person according to broadcast settings including information type settings. As illustrated in broadcast user device includes a display displaying a broadcast settings screen that includes an information type settings section including information type settings and . Each information type setting includes an information type and a broadcast enabled status . In the examples illustrated in the information type settings and provide that broadcast is enabled for information types that include the name the real time speaking status the look and the real time location of the first person . On the other hand the information type setting provides that broadcast is not enabled for information type for the child of the first person .

In some embodiments the broadcast settings may include social network connections range settings which may be used by the broadcast user device to determine its broadcast range. As illustrated in broadcast settings screen includes a social network connections range settings section including social network connections range settings and . In the example illustrated in the social network connections range setting provides for the broadcast of communication assistance information to users with a first second or third degree connection of the first person via a social network. In another example the social network connections range setting provides for the broadcast of communication assistance information to users included in a social network provided by FACEBOOK and a social network provided by LINKEDIN . Using the specific example of the broadcast settings illustrated in if the first person would like to save the broadcast settings e.g. on the broadcast user device on the system provider device or any other device the first person may select the SAVE choice in the broadcast settings screen .

In some embodiments the conversation assistance information database may include conversation assistance information of specific information types e.g. for the name last conversation time last conversation location event job title employer wife children description and or conversation history which may be determined according to configurations of the conversation assistance information database . Referring now to an embodiment of a conversation assistance information database including a conversation assistance information table is illustrated. The conversation assistance information table is associated with the first user . In the illustrated example the conversation assistance information table may include columns that provide a name field a time field a location field an event field a job title field an employer field a wife field a children field and description field for any of a plurality of rows in the conversation assistance information table that identify a previous conversation involving the first user . Each column may correspond to an information type. In the illustrated example conversation assistance information corresponding to two previous conversations and involving the first user and the first person e.g. Donald is stored in the conversation assistance information table . As such information captured during previous conversations by the user may be stored in the conversation assistance information database and provided during current and or subsequent conversations as conversation assistance information to the user . Furthermore information in the conversation assistance information database may be provided to a user during a current conversation based on a variety of factors. For example information e.g. a name associated with a conversation several weeks before between the user and a person may be provided to the user upon a new conversation with that person while the same information associated with a conversation a few hours before between the user and a person may not be provided to the user upon a new conversation with that person.

In some embodiments each of the social networks and may provide conversation assistance information of specific information types e.g. for connections in the social network employer and or job title which may be determined according to configurations of the social networks. In one example conversation assistance information of an information type for connections in a social network may be available from the first social network . In another example conversation assistance information of information types for the employer and job title may be available from the second social network e.g. LINKEDIN .

In some embodiments the system provider device may retrieve conversation assistance information of the one or more information types needed by the first user from selected information sources. In one example the first user may need conversation assistance information of information types that include the name employer and children of a person. In a specific example the system provider device may then retrieve the name information from broadcast user device the employer information from the second social network and the children information from the conversation assistance information database .

Referring now to the method now proceeds to block where a conversation assistance information configuration is retrieved e.g. from the first user device the system provider device or any other device .

In some embodiments the conversation assistance information configuration may include discreet configurations to provide for discreet provision of conversation assistance information to the first user e.g. through the at least one first user device in an ongoing conversation so that for example other persons involved in conversation e.g. the first person do not notice that the first user is asking for and or receiving conversation assistance. Referring now to embodiments of various discreet configurations are illustrated. As illustrated in the example of the first user device includes a display displaying a conversation assistance information configurations screen including a discreet configurations section . The discreet configurations section includes various discreet configurations and . For example as illustrated in the discreet configuration provides images for corresponding names e.g. images of a duck for the name Donald keys for the name Keith a bee for the name Abby and tiles for the name Kyle . In another example the discreet configuration may provide for displaying the conversation assistance information e.g. the name of the first person in an assistance language e.g. Chinese that may be different than the language being spoken in the conversation . In another example the discreet configuration may provide for vibrating the first user device in code e.g. Morse code for the conversation assistance information e.g. the name of the first person . In another example the discreet configuration may provide for making a fake phone call to the first user and displaying the conversation assistance information e.g. the name of the first person as the caller identifier displayed on the at least one first user device . In another example the discreet configuration may provide for using audio in an earphone of the at least one first user device to provide the conversation assistance information. In some embodiments specific discreet configurations may be enabled or disabled automatically according to the availability of required devices e.g. an earphone or functions e.g. vibration or according to the first user s personal preferences provided by the first user .

Using the specific example of the conversation assistance information configurations illustrated in if the first user would like to save conversation assistance information configurations including discreet configurations e.g. on the first user device on the system provider device or any other device the first user may select the SAVE choice in the conversation assistance information configurations screen .

In some embodiments the conversation assistance information configuration may include a non discreet configuration which may be used to provide conversation assistance information associated with potential conversation participants.

Referring now to after a conversation assistance information configuration has been retrieved the method may proceed to block where the conversation assistance information including information types needed by the first user is provided to the first user through the at least one user device according to the conversation assistance information configuration.

In some embodiments the conversation assistance information configuration includes the discreet configurations for providing conversation assistance information during conversation discreetly and the system provider device may adapt the conversation assistance information according to the enabled discreet configurations e.g. discreet configuration of . In one example the conversation assistance information includes a name Donald. If discreet configuration is enabled an image e.g. a duck for the name adapted using discreet configuration is displayed on the first user device . In another example if discreet configuration is enabled a name in the assisted language e.g. or Donald in Chinese adapted according to discreet configuration is displayed on the first user device . In another example if discreet configuration is enabled the first user device vibrates according to the Morse code for Donald according to discreet configuration . In another example if discreet configuration is enabled the first user device receives a fake phone call displaying a caller identifier e.g. Donald or if discreet configuration is also enabled . In another example if discreet configuration is enabled the first user receives audio of Donald in an earphone of the first user device .

Referring to in some embodiments the conversation assistance information is provided to the first user through the first user device according to non discreet configurations. In one example when the first user arrives at a specific event the first user may be provided with conversation assistance information associated with potential conversation participants e.g. according to persons connected to the first user in social networks at the specific event and or location data from broadcast user devices at the specific event . Unlike providing conversation assistance information during an ongoing conversation conversation assistance information associated with potential conversation participants may be provided according to non discreet configurations and more information types may be retrieved and or provided to the first user .

Referring now to an embodiment of conversation assistance information associated with one potential conversation participant is provided to the first user device . As illustrated in the example of the first user device includes a display displaying a potential conversation participant s screen including a participants section . In the example illustrated in only one potential conversation participant has been discovered e.g. based on persons connected to the first user in social networks at the specific event and displayed in the participants section and the conversation assistance information may be displayed according to a non discreet configuration for a single potential conversation participant. The participants section displays conversation assistance information of various types including name e.g. DONALD look e.g. an image of Donald and connections between the first user and the potential conversation participant e.g. retrieved from first social network .

In some embodiments the potential conversation participant s screen includes a family section including conversation assistance information of information types e.g. wife children related to the family. In some embodiments the potential conversation participant s screen includes a conversation history section including information about previous conversations e.g. retrieved from conversation assistance information database involving the first user and the potential conversation participant .

Referring now to conversation assistance information associated with multiple potential conversation participants and is provided to the first user device . As illustrated in the example of the first user device includes a display displaying a potential conversation participant s screen including a participants section . In the example illustrated in at the specific event the three potential conversation participants and are discovered e.g. based on location data provided by broadcast user devices used by the potential conversation participants and conversation assistance information associated with the three potential conversation participants and are displayed in the participants section . The conversation assistance information may be displayed according to a non discreet configuration for multiple potential conversation participants. In addition to the information types e.g. name look connections displayed for a single potential conversation participant in the participants section includes connection indicating connections between the potential conversation participants and

In some embodiments the participants section includes speaking status indicating the real time speaking status e.g. retrieved from a broadcast user device carried by the potential conversation participant of the potential conversation participant . In some embodiments the participants section includes a location section including relative location indicators and for respective potential conversation participants. In one example the relative location indicator indicates that potential conversation participant is immediately in front of the first user . While the speaking status and location indicators are provided in an example of the identification of potential conversation participants such features may be provided as conversation assistance information to the user during a conversation with multiple people. For example the user may be in a conversation with multiple people and the techniques described above may be utilized to identify each of those people similarly as illustrated in while also providing the relative location of each person via the location indicators and the speaking status . As such a user may quickly and easily determine information about a plurality of people in a conversation and may quickly distinguish information associated with those different people based on which one is currently speaking.

Referring now to the method may proceed to block where after the conversation ends a device e.g. the first user device the service provider device and or any other device receives a conversation record of the conversation . In some embodiments the user device may automatically update conversation assistance information database e.g. using a speech recognition engine to analyze audio of the conversation record . In some embodiments the first user may review the conversation record e.g. listening to the audio of the conversation record and update the conversation assistance information database. Referring now to illustrated is a conversation assistance information database including a conversation assistance information table updated with the conversation record of the conversation . As illustrated in a time location event employer children and description corresponding to the conversation have been updated to include information collected in conversation . In some embodiments the information in the conversation assistance information table may be provided for display to a user subsequent to a conversation to allow that user to review the details of a conversation that may be important to remember.

Thus conversation assistance systems and methods have been described that operate to assist a user engaging in a conversation by providing that user with relevant information for use in that conversation. The systems and methods may use a variety of data to detect that a conversation is occurring and then automatically retrieve and provide conversation assistance information to the user in a variety of ways to allow that user to use that conversation assistance in the conversation. For example the system may discreetly detect that a conversation has begun via conversation initiate actions such as handshakes and may also determine that body measurement data e.g. an increased heart rate increased perspiration etc. indicates that the user may not know a name of the person with whom the user is starting the conversation. The systems may then retrieve the name of that person and provide it discreetly to the user so that they may use it during the conversation. Such systems and methods improve the ability of users to participate in conversations with people whom they may have forgotten relevant and or important information about thus enhancing the users interactions with others.

Referring now to an embodiment of a network based system for implementing one or more processes described herein is illustrated. As shown network based system may comprise or implement a plurality of servers and or software components that operate to perform various methodologies in accordance with the described embodiments. Exemplary servers may include for example stand alone and enterprise class servers operating a server OS such as a MICROSOFT OS a UNIX OS a LINUX OS or other suitable server based OS. It can be appreciated that the servers illustrated in may be deployed in other ways and that the operations performed and or the services provided by such servers may be combined or separated for a given implementation and may be performed by a greater number or fewer number of servers. One or more servers may be operated and or maintained by the same or different entities.

The embodiment of the networked system illustrated in includes a plurality of user devices a plurality of broadcast user devices a system provider device and a plurality of social network service provider devices in communication over a network . Any of the user devices may be the user devices discussed above. The broadcast user devices may be the broadcast user devices discussed above and may be used by the first person discussed above. The system provider device may be the system provider device discussed above and may be operated by a system provider such as for example PayPal Inc. of San Jose Calif.

The user devices broadcast user devices and system provider device may each include one or more processors memories and other appropriate components for executing instructions such as program code and or data stored on one or more computer readable mediums to implement the various applications data and steps described herein. For example such instructions may be stored in one or more computer readable mediums such as memories or data storage devices internal and or external to various components of the system and or accessible over the network .

The network may be implemented as a single network or a combination of multiple networks. For example in various embodiments the network may include the Internet and or one or more intranets landline networks wireless networks and or other appropriate types of networks.

The user device may be implemented using any appropriate combination of hardware and or software configured for wired and or wireless communication over network . For example in one embodiment the user device may be implemented as a personal computer of a user in communication with the Internet. In some embodiments the user device may be a wearable device. In some embodiments the user device may be a smart phone personal digital assistant PDA laptop computer and or other types of computing devices.

The user device may include one or more browser applications which may be used for example to provide a convenient interface to permit the first user to browse information available over the network . For example in one embodiment the browser application may be implemented as a web browser configured to view information available over the Internet.

The user device may also include one or more toolbar applications which may be used for example to provide user side processing for performing desired tasks in response to operations selected by the first user. In one embodiment the toolbar application may display a user interface in connection with the browser application.

The user device may further include other applications as may be desired in particular embodiments to provide desired features to the user device . In particular the other applications may include a social network application provided by a social network service provider through the social network service provider device . The other applications may also include security applications for implementing user side security features programmatic user applications for interfacing with appropriate application programming interfaces APIs over the network or other types of applications. Email and or text applications may also be included which allow the user to send and receive emails and or text messages through the network . The user device includes one or more user and or device identifiers which may be implemented for example as operating system registry entries cookies associated with the browser application identifiers associated with hardware of the user device or other appropriate identifiers such as a phone number. In one embodiment the user identifier may be used by the system provider device and or social network service provider device to associate the user with a particular account as further described herein.

Referring now to an embodiment of a user device is illustrated. The user device may be the user devices or broadcast user device . The user device includes a chassis having a display and an input device including the display and a plurality of input buttons . One of skill in the art will recognize that the user device is a portable or mobile phone including a touch screen input device and a plurality of input buttons that allow the functionality discussed above with reference to the method . However a variety of other portable mobile user devices may be used in the method without departing from the scope of the present disclosure.

Referring now to an embodiment of a wearable user device is illustrated. The wearable user device may be the may be the wearable user devices or broadcast user device discussed above. The wearable user device includes a frame having a computing chassis that extends from the frame a display device that extends from the computing chassis a microphone located on the computing chassis a camera located on the computing chassis and a speaker located on the computing chassis . One of skill in the art will recognize that the wearable user device is a mobile wearable device such as for example Google Glass available from Google Inc. of Mountain View Calif. that may provide a user with the functionality discussed above with reference to the methods discussed above. However a variety of other mobile wearable devices may be used in the methods discussed above without departing from the scope of the present disclosure.

Referring now to an embodiment of a computer system suitable for implementing for example the user devices broadcast user device and or system provider device is illustrated. It should be appreciated that other devices utilized by users persons and or system providers in the system discussed above may be implemented as the computer system in a manner as follows.

In accordance with various embodiments of the present disclosure computer system such as a computer and or a network server includes a bus or other communication mechanism for communicating information which interconnects subsystems and components such as a processing component e.g. processor micro controller digital signal processor DSP etc. a system memory component e.g. RAM a static storage component e.g. ROM a disk drive component e.g. magnetic or optical a network interface component e.g. modem or Ethernet card a display component e.g. CRT or LCD an input component e.g. keyboard keypad or virtual keyboard a cursor control component e.g. mouse pointer or trackball a location sensor component e.g. a Global Positioning System GPS device as illustrated a cell tower triangulation device and or a variety of other location determination devices known in the art. a camera component a perspiration sensor component a heart rate sensor a motion sensor component and or a temperature sensor . In one implementation the disk drive component may comprise a database having one or more disk drive components.

In accordance with embodiments of the present disclosure the computer system performs specific operations by the processor executing one or more sequences of instructions contained in the memory component such as described herein with respect to the user device s the broadcast user device s and or the system provider device s . Such instructions may be read into the system memory component from another computer readable medium such as the static storage component or the disk drive component . In other embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the present disclosure.

Logic may be encoded in a computer readable medium which may refer to any medium that participates in providing instructions to the processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. In one embodiment the computer readable medium is non transitory. In various implementations non volatile media includes optical or magnetic disks such as the disk drive component volatile media includes dynamic memory such as the system memory component and transmission media includes coaxial cables copper wire and fiber optics including wires that comprise the bus . In one example transmission media may take the form of acoustic or light waves such as those generated during radio wave and infrared data communications.

Some common forms of computer readable media includes for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge carrier wave or any other medium from which a computer is adapted to read. In one embodiment the computer readable media is non transitory.

In various embodiments of the present disclosure execution of instruction sequences to practice the present disclosure may be performed by the computer system . In various other embodiments of the present disclosure a plurality of the computer systems coupled by a communication link to the network e.g. such as a LAN WLAN PTSN and or various other wired or wireless networks including telecommunications mobile and cellular phone networks may perform instruction sequences to practice the present disclosure in coordination with one another.

The computer system may transmit and receive messages data information and instructions including one or more programs i.e. application code through the communication link and the network interface component . The network interface component may include an antenna either separate or integrated to enable transmission and reception via the communication link . Received program code may be executed by processor as received and or stored in disk drive component or some other non volatile storage component for execution.

Referring now to an embodiment of a system provider device is illustrated. In an embodiment the system provider device may be the system provider devices discussed above. The system provider device includes a communication engine that is coupled to the network and to a conversation assistance engine that is coupled to a conversation assistance information database . The communication engine may be software or instructions stored on a computer readable medium that allows the system provider device to send and receive information over the network . The conversation assistance engine may be software or instructions stored on a computer readable medium that is operable to receive conversation information including body measurement data determine a need for conversation assistance using the body measurement data and information types needed by the first use retrieve conversation assistance information provide the conversation assistance information to the first user and provide any of the other functionality that is discussed above. While the databases and have been illustrated as located in the system provider device one of skill in the art will recognize that it may be connected to the conversation assistance engine through the network without departing from the scope of the present disclosure.

Where applicable various embodiments provided by the present disclosure may be implemented using hardware software or combinations of hardware and software. Also where applicable the various hardware components and or software components set forth herein may be combined into composite components comprising software hardware and or both without departing from the scope of the present disclosure. Where applicable the various hardware components and or software components set forth herein may be separated into sub components comprising software hardware or both without departing from the scope of the present disclosure. In addition where applicable it is contemplated that software components may be implemented as hardware components and vice versa.

Software in accordance with the present disclosure such as program code and or data may be stored on one or more computer readable mediums. It is also contemplated that software identified herein may be implemented using one or more general purpose or specific purpose computers and or computer systems networked and or otherwise. Where applicable the ordering of various steps described herein may be changed combined into composite steps and or separated into sub steps to provide features described herein.

The foregoing disclosure is not intended to limit the present disclosure to the precise forms or particular fields of use disclosed. As such it is contemplated that various alternate embodiments and or modifications to the present disclosure whether explicitly described or implied herein are possible in light of the disclosure. Having thus described embodiments of the present disclosure persons of ordinary skill in the art will recognize that changes may be made in form and detail without departing from the scope of the present disclosure. Thus the present disclosure is limited only by the claims.

