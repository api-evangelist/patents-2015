---

title: System and method for determining distances from an object
abstract: According to one or more embodiments, the processes and systems disclosed allow a user of a mobile device to determine their distance from an object. The object may be an image of a pattern having a known size. The image may be displayed on a computer screen or other suitable medium such as a printed sheet. According to one or more embodiments, the disclosed processes and systems aid in determining or guiding a user to a distance at which an eye examination is conducted.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09532709&OS=09532709&RS=09532709
owner: JAND, INC.
number: 09532709
owner_city: New York
owner_country: US
publication_date: 20150605
---
The technical field generally relates to camera calibration and distance determination and more particularly in one aspect to systems and methods for calculating user distance from an object during an eye examination.

Eye examinations are routinely used to determine the appropriate lens prescription for patients. One variable that must be known to perform an effective eye exam is the distance between a test subject and the displayed eye test. Eye exams have traditionally been performed by optometrists or the like in an office where a set distance from the patient to an eye chart or other testing material is easily maintained. Efforts to translate eye exam procedures from a doctor or technician s office to non traditional locations such as self administered tests at home are hampered by the difficulties associated with a user s ability to determine with confidence his or her distance from the testing material so that reliable results may be obtained. Proposed solutions such as using measuring tape or counting steps to determine a distance from a computer screen displaying an eye test require additional equipment or steps and may erode a user s confidence in the results making a test administered out of office less attractive.

In accordance with one or more aspects a process for conducting an eye examination is provided. The process comprises calibrating a camera of a mobile device using the mobile device tracking a current distance from the mobile device to an object while the current distance is changing guiding a user to a specified distance from the object for conducting the eye examination and receiving at the mobile device input from the user in response to eye examination material presented on the object.

In accordance with one or more aspects the process calibrating the camera may comprise receiving and analyzing a series of images taken from the camera at multiple angles in relation to a calibration pattern presented on the object. Guiding the user may comprise providing instructions to the mobile device to display an indication of the current distance between the mobile device and the object in relation to the specified distance between the mobile device and the object. The object may be a monitor of a computer and the process may further comprise receiving an indication from the user of the size of a displayed object on the monitor. Receiving the indication from the user of the size of the displayed object on the monitor may comprise receiving input from a user matching the dimensions of the displayed object to a reference shape having a known size. Receiving the indication from the user of the size of the displayed object on the monitor may comprise receiving and analyzing one or more images taken from the camera the one or more images including the displayed object and a reference object having a known size.

In accordance with one or more aspects the object may be a monitor of a computer and guiding the user may comprise providing instructions to the computer to display directions on the monitor instructing the user to continue moving to or from the monitor. The object may be a monitor of a computer and the process may further comprise pairing the mobile device to the computer. Pairing may comprise receiving input entered on the mobile device indicative of an identifier displayed on the monitor.

In accordance with one or more aspects the process may further comprise providing indication from the mobile device to the user when the specified distance has been reached. Providing indication to the user may comprise superimposing an icon indicating the current location of the user on an icon indicating the specified distance for conducting the eye examination. The process may further comprise determining a diagnosis or lens prescription in response to receiving input from the user in response to eye examination material presented on the object. The process may further comprise guiding a user to a second specified distance from the monitor in response to receiving input from the user in response to eye examination material displayed on the monitor.

In accordance with one or more aspects a mobile device is provided. The mobile device comprises a camera and a processor coupled to the camera the processor configured to calibrate the camera by capturing a series of images track a current distance from the mobile device to an eye examination chart and guide a user holding the mobile device to a specified distance from the eye examination chart.

In accordance with one or more aspects the processor may be further configured to calibrate the camera by analyzing the series of images. The processor may be further configured to receive input from a user in response to the eye examination chart. The processor may be further configured to generate a diagnosis or lens prescription in response to the received input from the user in response to the eye examination chart.

In accordance with one or more aspects a server associated with a remote mobile device is provided. The server is configured to receive images of a calibration pattern taken by a camera of the remote mobile device at various angles calibrate the camera using the images received determine a current position of the remote mobile device in relation to a target object determine a specified position for the remote mobile device provide instructions to the remote mobile device to display an indication of the current position as the current position changes and provide instructions to the remote mobile device to display an indication of the current position matching relative to the specified position.

In accordance with one or more aspects the server may be further associated with a remote computer and a monitor of the remote computer may be the target object. The server may be further configured to provide instructions to the computer to display on the monitor eye exam material upon the current position matching the specified position. The server may be configured to pair the remote mobile device and the remote computer by providing instructions to the computer to display on the monitor a code and receiving from the remote mobile device an indication of the displayed code matching the remote mobile device to the remote computer.

In accordance with one or more aspects a process for conducting an eye examination is provided. The process comprises calibrating a camera of a mobile device using the mobile device tracking a current distance from the mobile device to a computer monitor while the current distance is changing using the mobile device determining a testing distance from the mobile device to the computer monitor when the current distance ceases to change presenting eye examination material on the computer monitor wherein a size of the eye examination material is based in part on the testing distance and receiving at the mobile device input from the user in response to the eye examination material.

In accordance with one or more aspects a process for conducting an eye examination is provided. The process comprises calibrating a camera of a mobile device using the mobile device tracking a current distance from the mobile device to a computer monitor while the current distance is changing presenting eye examination material on the computer monitor guiding a user to move to or from the computer monitor and then stop in response to the eye examination material using the mobile device measuring a distance from the mobile device to the computer monitor when the user has stopped and determining a characteristic of the user s vision in response to the measured distance.

Still other aspects embodiments and advantages of these exemplary aspects and embodiments are discussed in detail below. Moreover it is to be understood that both the foregoing information and the following detailed description are merely illustrative examples of various aspects and embodiments and are intended to provide an overview or framework for understanding the nature and character of the claimed subject matter. Particular references to examples and embodiments such as an embodiment an example one example another embodiment another example some embodiments some examples other embodiments an alternate embodiment various embodiments one embodiment at least one embodiments this and other embodiments or the like are not necessarily mutually exclusive and are intended to indicate that a particular feature structure or characteristic described in connection with the embodiment or example and may be included in that embodiment or example and other embodiments or examples. The appearances of such terms herein are not necessarily all referring to the same embodiment or example.

Furthermore in the event of inconsistent usages of terms between this document and documents incorporated herein by reference the term usage in the incorporated references is supplementary to that of this document for irreconcilable inconsistencies the term usage in this document controls. In addition the accompanying drawings are included to provide illustration and a further understanding of the various aspects and embodiments and are incorporated in and constitute a part of this specification. The drawings together with the remainder of the specification serve to explain principles and operations of the described and claimed aspects and embodiments.

According to one or more embodiments the methods and systems disclosed allow a person to easily determine their distance from an object. The target object may be an image of a pattern an eye exam or other suitable item. The image may be displayed on a computer screen or other suitable medium such as a printed sheet or series of printed sheets.

According to one or more embodiments the disclosed methods and systems may guide a person to a specific distance from the object. According to one or more embodiments the provided guidance may facilitate a user to undergo an eye exam without the need for technical or trained personnel to administer the test. As such this disclosure opens up the potential for a range of people to receive an accurate eye exam who may have difficulty accessing an optician s office those that are infirm remote etc. or those who may prefer the convenience of self administering an exam.

According to one or more embodiments distance from a target is determined by using a camera capable of running custom software and according to some examples displaying feedback to the user such as may be provided by a smartphone or other mobile or portable device such as a tablet or laptop computer . According to one or more embodiments the methods provided do not require specific information about the camera and can be run on most consumer mobile phones or any portable computing device that includes a camera.

According to one or more embodiments a user may begin the process while positioned close to a displayed pattern run the application and point the camera at the calibration pattern. The user then engages in a process for calibrating the camera to determine the camera s intrinsic and extrinsic properties. Alternatively the camera s properties may be retrieved programmatically in certain cases Calibration of the camera on the mobile device may be carried out according to any methods known to a person of ordinary skill in the art. According to one or more embodiments calibration requires images of the calibration pattern from multiple angles to determine camera properties. As such better calibration results can be achieved closer to the pattern where the camera can be moved at a greater angle. In the case that the camera device has other sensors such as an accelerometer those sensors may be used to make calibration faster or more accurate.

The calibration pattern may be an object with a known geometry and easily detectable feature points. According to some embodiments a chessboard pattern is used. The calibration process may determine certain intrinsic properties of the camera such as those relating to focal length image sensor format and principal point. The calibration aids in relating pixel count of an object to actual dimensions. The results of the calibration may be used to determine the distance between the camera and a target. By using an easily identifiable pattern or shape one may accurately then track the distance from the target to the camera as one is moved in relation to the other.

According to one or more embodiments the pattern is presented on an electronic display. However it is to be understood that any medium for the pattern including paper can be used. Furthermore the calibration pattern and the eye exam chart may be displayed on the same monitor or on separate displays and may be collectively referred to as an object or target object. Unless stated otherwise the terms eye exam material and eye exam chart may be understood to encompass any image static or dynamic associated with determining one or more characteristics of a test subject s vision.

In the case where the calibration pattern is on a piece of paper the chessboard itself or an eye chart can be used as a target during the tracking stage during which the camera is moving. In the case where the chessboard pattern is on a computer screen after calibration the screen can be changed to solid white so that the target is large and is not blurred by lighting contrast or glare as the camera of the mobile device is moved.

In the case where the calibration pattern is displayed on a computer screen the mobile device can be linked to a web page or application running on the computer such that the mobile device can be used to control the application on the computer. This can be helpful for guiding the user through the calibration process and also for guiding the user through an eye exam.

In the case where the calibration pattern and exam chart are each on a piece of paper all instruction can be given through the mobile device.

Once the properties of the mobile device s camera are determined either through calibration or through a retrieval process the physical distance to the screen may be determined Calibration of the camera gives a full transformation from three dimensional space to a two dimensional projection where one can solve for the distance in three dimensional space given the size of an object in three dimensional space and its size in the two dimensional projection. The application of this transformation can be simplified by using only the focal constant from the intrinsic matrix. The size in pixels of the monitor is inversely proportional to the physical distance from the camera with a proportionality constant given by the intrinsic matrix determined through calibration or some other means and the known physical size of the object. Such a calculation allows for the distance to be tracked as the mobile device is moved.

Turning to the figures illustrates a block diagram of an eye examination system according to one or more embodiments. In the embodiment shown in the system comprises a server in communication with a first device and a second device . As shown the first device is coupled to and can exchange data with server and computing device via network . In addition according to this example the first device includes a camera a processor coupled to the camera an output device such as a monitor or display screen or audio speaker an input device such as a touch surface a keyboard microphone or a mouse a data storage module and a memory coupled to the processor . The first device also includes camera calibration and eye examination software .

The server includes one or more computing devices located remote or local to the first and second devices and . The server includes a processor and a memory coupled to the processor. In one example the memory includes volatile memory such as RAM and non volatile memory such as a magnetic disk.

The second device is coupled to and can exchange data with server and mobile device via network . In addition according to this example the second device includes processor a data storage module a memory coupled to the processor an output device such as a monitor or display screen or audio speaker and an input device such as a touch surface a keyboard microphone or a mouse.

The first device is a portable computing device. For example it may be a mobile device such as a smart phone tablet or laptop computer all of which are encompassed by the terms portable computing device or mobile device. The mobile device is capable of delivering and or receiving data to or from server . The second device may be a portable computing device like any of those described for the first device or a stationary computing device. Unless specified otherwise the terms monitor or display screen may be understood to encompass any visual display associated with a portable or stationary computing device.

The server exchanges data with the first and second devices and . This data may be exchanged through an installed program in the first or second device or or through a web page loaded on the first or second device or .

In use the first and second devices and may be used in conjunction to determine the distance between the two devices. The output display of the second device may be used to display a calibration pattern a substantially blank screen for distance tracking and or an eye examination chart. The images displayed on the monitor may be provided to the monitor by the server in response to instructions received from the server and the particular instructions provided to the monitor may be based on information received from the camera device . A pairing of the first and second devices and as further discussed below may facilitate their coordination.

The computing device as shown in is internet enabled and the various patterns images or testing material displayed is provided through a web page in response to output from the first device . In alternative embodiments an application or program running on the computer is responsible for the content displayed.

While in the system shown in both the first device and the second device are in communication with the server alternative configurations are also considered within the scope of the present disclosure. For example according to certain embodiments the device including the camera and or the second device may not be in communication with a server or each other. For example all the instructions required by the camera device may already be stored on device . Likewise information or instructions for what to display on the second device may be provided without requiring communication over a network. Also the second device may be in direct communication with the first device using one of a number of known wireless protocols. Furthermore as discussed elsewhere according to certain embodiments the second device may comprise simply an image printed on a sheet of paper. for example shows an alternative simplified embodiment where the second device comprises a target calibration pattern and eye chart printed out and attached to a wall. A software enabled camera device is still used to track distance and guide a user to a specified position.

According to one or more embodiments a system like that shown in is implemented in processes directed to self administered eye examination.

A first step of the process includes determining an object display size on an output device such as output device of computing device . Where the screen is a computer monitor the step may include displaying an object on the screen and receiving input from a user resizing the object until its dimensions match a reference object of known dimensions. The reference object may be any object readily available and having a standardized shape. For example the reference object may be a ruler or a credit card. The object may also include other configurations such as a line. In other embodiments step may be omitted if the characteristics of the monitor are known or an electronic screen is not being used.

Step of the process includes pairing the camera of the portable device with the computer . The step of pairing facilitates the coordination of instructions and information between the portable device and the computer but in some embodiments this step is not used. Once paired the server may deliver instructions to the computer directing what images are displayed on its monitor in response to information received from the camera of the device . The step of pairing may be achieved by any technique known to one of ordinary skill in the art that will allow the server to associate the portable device with the computer . For example an identifier may be displayed on the monitor of computer and captured by the camera of device or vice versa. In some embodiments a QR code is displayed on the monitor . The camera then captures an image of the code and transmits it to the server allowing the server to match the two devices and and coordinate the instructions sent to each.

Step of the process includes calibrating the camera to determine certain characteristics of the camera and using that information to standardize measurements made using the camera . Any process for calibrating a camera known to a person of ordinary skill in the art may be utilized. In other embodiments the characteristics of the camera may be known for example based on the model of the mobile device used and calibration of the camera may not be necessary where for example the properties of the camera model may be retrieved from a program.

Step of the process includes tracking the distance from the device to the monitor of computer as the device is moved away from or toward the monitor with the camera of device trained on the monitor . As a user holding the camera moves in relation to the monitor the monitor may be maintained in the camera viewfinder. As the distance changes the portion of the viewfinder taken up by the monitor will also change. This data may be used along with the initial distance determination to track the current distance of the camera from the monitor on a near real time basis.

Step of the process includes guiding a user holding the mobile device to a specific distance from the monitor . Guiding may comprise providing an indication to the user equipped with the mobile device of the current distance from the monitor determined as a result of the tracking step . Guiding may further comprise providing an indication as to where the user is in a relation to a specified end point distance that the user is attempting to reach to aid the user in determining whether to continue to move away from the monitor . Guiding may further comprise providing instructions to the user to continue to move to or from the monitor . These instructions may be provided on the monitor of the computer or on an output display of the mobile device or conveyed audibly.

The specific distance from the monitor that the user is attempting to reach may be a fixed distance determined as required by the particular application. In the context of providing an eye examination a particular eye test may require that the user be at a specific distance for example ten feet from the monitor displaying an eye chart give or take some acceptable range of error which may be one foot or ten percent of the total distance according to certain embodiments. Alternatively the specific distance may be a function of the displayed object size determined in step . Where the displayed object is found to be smaller the specified end distance from the monitor may be shorter as the items displayed on the monitor will be smaller. Alternatively the results of step may be used to display letters of a fixed size allowing the same distance to be used regardless of the screen size.

As the mobile device is moved in relation to the screen ultimately the designated distance from the screen is reached. Step of the process includes providing an indication to a user once the designated distance has been reached. The indication may be a display on the monitor or an output device of the mobile device of any general type that would allow a user to know that he or she can stop moving in relation to the monitor.

In the context of an eye examination the distance from the eye to the eye test chart may be slightly different from the distance between the camera and the testing display depending on the positioning of the camera by the user relative to the user s eyes. In some embodiments the user may be instructed to position the camera near the user s eyes to reduce this error or the system may include an adjustment to the measurement distance based on a typical distance between the position at which the user holds the camera and the user s eyes. Nevertheless this difference is generally within an acceptable range of error and therefore does not harm the integrity of the test. Unless stated otherwise the phrase specified distance and related terms are understood to include a distance within a reasonable range of error. According to some embodiments the range of error may be one foot or ten percent of the total distance whichever is greater.

At step of process eye examination material is displayed on the monitor and the eye test or a new phase of the eye test may begin. In embodiments which include a step of pairing the camera device to the computer the eye exam material may automatically be displayed once the designated distance is reached.

A variety of different eye tests may be implemented in step depending on the needs of the user. Tests may include tests of visual acuity both cylindrical power and spherical power tests tests for peripheral vision or color blindness tests for astigmatism cataracts and various pathologies or diseases etc. Tests may be static or dynamic. Specific examples of testing material include without limitation Snellen charts E charts Landoldt C charts etc.

During testing at step of process indications are received from the user in response to the displayed eye exam material. The indications may be in the form of vocal or typed responses or any suitable input. The indications may be in response to a prompt provided to the user by one or both of devices and . The prompt may include text on one of the screens and or an audio prompt. The prompt may display or state a command such as read the second line of characters on the eye chart. 

The process may include a step of determining a diagnosis or prescription based on the test subject s responses. The determination may be conducted automatically by one of the devices and or by the server. The determination may also be done by an optometrist that receives results of the test from the server for example over the Internet.

In one alternative embodiment a process shown in is provided for directing a test subject to two or more distances from the eye exam chart over the course of the examination. As shown in the flow chart in the process includes a step of receiving indications from the test subject at a first distance in response to displayed eye examination material. The process may occur after the process . In particular the process may be used based on a user s results or partial results to an eye examination performed using process . In particular if the user is at too great a distance to be able to properly read a displayed chart based on the user s eye sight the process may be used to conduct an eye exam at a closer distance from the displayed eye chart.

A second specified distance for the test subject is determined using a step of process . This second distance may be determined in consideration of various factors. According to some embodiments this determination may be made after ascertaining that the first distance is inappropriate. For example if the user test subject s eyesight is especially poor then the user may not be able to engage in a meaningful eye examination from the first distance and steps may be taken to have the user move closer. Alternatively if the examination is too easy and therefore not allowing for the provision of appropriate feedback it may be required that a user move to a second distance that is greater than the first distance. In some embodiments the step of determining and guiding a test subject to one or more additional distances may be in response to the requirements of a battery of tests. According to some embodiments the determination of the second distance may be advantageous where one eye test in a battery of tests provides more reliable results if performed at a second distance different from the first distance at which one or more tests were carried out.

Once a second distance is determined the test subject may be guided to the second distance according to a step . The step may be carried out in a manner corresponding to steps and of the process as shown in the flow chart of .

Once the test subject has reached the new position a step of displaying the eye examination material may take place. As discussed above this material may be the same material as displayed when the test subject was at the first position or it may be new material. In at least one embodiment the user is prompted to move to the additional test locations using the process described with reference to .

Finally the steps of repositioning may be repeated as necessary to place the test subject in a third position fourth position etc. as provided for in step .

According to another alternative embodiment a final distance from the user to the test material is not pre determined. Instead according to process as shown in the flow chart in the user moves to a distance of his choice from the monitor and undertakes an eye examination from that distance. The basis of the user s choice of the testing distance may be a variety of factors such as limited room space. Or the user may choose the testing distance based on when an image displayed on the monitor becomes recognizable. Alternatively the choice of distance may be arbitrary.

As shown in the flow chart in the initial steps and are similar to the initial steps shown in . However instead of guiding a user to a specified distance from the monitor the method incorporates a step of receiving indication that a testing distance has been reached. Indication may be in the form of direct user input into the camera enabled mobile device. Alternatively indication may be in the form of the mobile device detecting no change in distance for a period of time for example three seconds or more.

Once the system has received indication that the testing distance has been reached the step of displaying eye exam material on the monitor is carried out. Characteristics of the displayed material such as their display size are based on the determined testing distance. For example the closer the user is to the monitor the smaller the size of the displayed testing materials. Conversely the further the user is from the monitor the larger the display size.

According to another alternative embodiment the user may change his distance from the screen in response to the material presented on the screen as part of a testing procedure. For example an image may be presented on the screen and the user may be directed to walk to a distance where he can see this object clearly. That distance is noted by the system and aids in determining a characteristic of the user s vision. shows a flow diagram of a process incorporating this embodiment. The initial steps and are similar to corresponding steps discuss in relation to . In step eye examination material is displayed. The user then moves to or from the displayed material with the mobile device in hand while according to step the distance to the eye examination material is tracked. The user then stops when reaching a certain distance such as when he can see the displayed object clearly. According to step of the process the system then received indication from the user in response to the displayed eye examination material. The indication may be in the form of direct user input into the mobile device. Alternatively indication may be in the form of the mobile device detecting no change in distance for a period of time for example three seconds or more. At this point in step the user s distance from the eye exam material is measured. This measured distance is then used at least in part to determine a characteristic of the user s vision in step .

According to an alternative process the size of a display object on the monitor may be determined with minimal input from the user as shown in . According to the alternative process the step of pairing devices similar to that described above in reference to step of precedes the step of determining a displayed object size. Like the embodiment described in conjunction with a shape for example a rectangle is displayed on the monitor screen and the user positions a reference object of a known size such as a credit card against the sizing shape. The user using the camera of the mobile device then captures one or more images of the credit card against the rectangle. The images are then analyzed to determine the size of the displayed object on the computer screen relative to the size of the reference object positioned against the screen. Based on this information and the link between the mobile device and the computer associated with the monitor the size of the display object may be determined without any further input from the user. The process may continue with a calibration step which can also precede steps and and move on to a distance tracking step . The alternative process of determining screen object size may be incorporated into any of the described eye examination processes or any alternative application of the disclosed methods as would be understood by a person of ordinary skill in the art.

As discussed above aspects and functions disclosed herein may be implemented as hardware or software on one or more of these computer systems. There are many examples of computer systems that are currently in use. These examples include among others network appliances personal computers workstations mainframes networked clients servers media servers application servers database servers and web servers. Other examples of computer systems may include mobile computing devices such as cellular phones and personal digital assistants and network equipment such as load balancers routers and switches. Further aspects may be located on a single computer system or may be distributed among a plurality of computer systems connected to one or more communications networks.

For example various aspects and functions may be distributed among one or more computer systems configured to provide a service to one or more client computers. Additionally aspects may be performed on a client server or multi tier system that includes components distributed among one or more server systems that perform various functions. Consequently examples are not limited to executing on any particular system or group of systems. Further aspects may be implemented in software hardware or firmware or any combination thereof. Thus aspects may be implemented within methods acts systems system elements and components using a variety of hardware and software configurations and examples are not limited to any particular distributed architecture network or communication protocol.

As shown the computer devices and are interconnected by and may exchange data through communication a network . The network may include any communication network through which computer systems may exchange data. To exchange data using the network the computer systems and and the network may use various methods protocols and standards including among others Fibre Channel Token Ring Ethernet Wireless Ethernet Bluetooth IP IPV6 TCP IP UDP DTN HTTP FTP SNMP SMS MMS SS7 JSON SOAP CORBA REST and Web Services. To ensure data transfer is secure the computer systems and may transmit data via the network using a variety of security measures including for example TSL SSL or VPN.

As discussed above with regard to various aspects and functions may be implemented as specialized hardware or software executing in one or more computer systems. As illustrated in the device includes a processor a memory a camera an output display a data storage module and an input device . The following detailed description of the components of mobile device may be generally understood to also apply to corresponding structure present in computer or server . 

The processor may perform a series of instructions that result in manipulated data. The processor may be a commercially available processor such as an Intel Xeon Itanium Core Celeron Pentium AMD Opteron Sun UltraSPARC IBM Power5 or IBM mainframe chip but may be any type of processor multiprocessor or controller. The processor is connected to other system elements including one or more memory devices the camera etc.

The memory may be used for storing programs and data during operation of the device . Thus the memory may be a relatively high performance volatile random access memory such as a dynamic random access memory DRAM or static memory SRAM . However the memory may include any device for storing data such as a disk drive or other non volatile storage device. Various examples may organize the memory into particularized and in some cases unique structures to perform the functions disclosed herein.

The mobile device also includes one or more interface devices such as input devices and output devices . Interface devices may receive input or provide output. More particularly output devices may render information for external presentation. Input devices may accept information from external sources. Examples of interface devices include keyboards mouse devices trackballs microphones touch screens printing devices display screens speakers network interface cards etc. Interface devices allow the computer system to exchange information and communicate with external entities such as users and other systems.

The data storage may include a computer readable and writeable nonvolatile non transitory data storage medium in which instructions are stored that define a program that may be executed by the processor . The data storage also may include information that is recorded on or in the medium and this information may be processed by the processor during execution of the program. More specifically the information may be stored in one or more data structures specifically configured to conserve storage space or increase data exchange performance. The instructions may be persistently stored as encoded signals and the instructions may cause the processor to perform any of the functions described herein. The medium may for example be optical disk magnetic disk or flash memory among others. In operation the processor or some other controller may cause data to be read from the nonvolatile recording medium into another memory such as the memory that allows for faster access to the information by the processor than does the storage medium included in the data storage . The memory may be located in the data storage or in the memory however the processor may manipulate the data within the memory and then copy the data to the storage medium associated with the data storage after processing is completed. A variety of components may manage data movement between the storage medium and other memory elements and examples are not limited to particular data management components. Further examples are not limited to a particular memory system or data storage system.

Although the device is shown by way of example as one type of a computer device upon which various aspects and functions may be practiced aspects are not limited to being implemented on the device as shown in . Various aspects and functions may be practiced on one or more computers having a different architectures or components than that shown in . For instance the device may include specially programmed special purpose hardware such as for example an application specific integrated circuit ASIC tailored to perform a particular operation disclosed herein. While another example may perform the same function using a grid of several general purpose computing devices running MAC OS System X with Motorola PowerPC processors and several specialized computing devices running proprietary hardware and operating systems.

The device may include an operating system that manages at least a portion of the hardware elements included in the device . Usually a processor or controller such as the processor executes an operating system which may be for example a Windows based operating system such as Windows NT Windows 2000 Windows ME Windows XP Windows Vista or Windows 7 operating systems available from the Microsoft Corporation a MAC OS System X operating system available from Apple Computer one of many Linux based operating system distributions for example the Enterprise Linux operating system available from Red Hat Inc. a Solaris operating system available from Sun Microsystems or a UNIX operating systems available from various sources. Many other operating systems may be used and examples are not limited to any particular implementation.

The processor and operating system together define a computer platform for which application programs in high level programming languages may be written. These component applications may be executable intermediate bytecode or interpreted code which communicates over a communication network for example the Internet using a communication protocol for example TCP IP. Similarly aspects may be implemented using an object oriented programming language such as .Net SmallTalk Java C Ada or C C Sharp . Other object oriented programming languages may also be used. Alternatively functional scripting or logical programming languages may be used.

Additionally various aspects and functions may be implemented in a non programmed environment for example documents created in HTML XML or other format that when viewed in a window of a browser program render aspects of a graphical user interface or perform other functions. Further various examples may be implemented as programmed or non programmed elements or any combination thereof. For example a web page may be implemented using HTML while a data object called from within the web page may be written in C . Thus the examples are not limited to a specific programming language and any suitable programming language could be used. Thus functional components disclosed herein may include a wide variety of elements e.g. executable code data structures or objects configured to perform described functions.

Embodiments described above utilize a process for determining distance between two objects in conjunction with the performance of an eye exam. Other embodiments may be used to determine distance for a number of different applications including providing directions or orientation guidance for use in a retail store or other location to allow a user to find a specific location or object relative to the screen games in which a player must throw something at a target a certain distance away from their present location visualizing the size of an object that might be later placed in that space such as furniture in a room or other applications which require a user to determine absolute distances or sizes. Having thus described several aspects of at least one example it is to be appreciated that various alterations modifications and improvements will readily occur to those skilled in the art. For instance examples disclosed herein may also be used in other contexts. Such alterations modifications and improvements are intended to be part of this disclosure and are intended to be within the scope of the examples discussed herein. Accordingly the foregoing description and drawings are by way of example only.

