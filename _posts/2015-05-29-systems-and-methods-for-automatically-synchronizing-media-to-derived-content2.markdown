---

title: Systems and methods for automatically synchronizing media to derived content
abstract: A system for creating synchronized content is provided. The system includes a memory, at least one processor coupled to the memory, and a synchronization engine component executable by the at least one processor. The synchronization engine component is configured to locate a media file associated with synchronization information; locate at least one clip derived from the media file; generate a reference template representative of the media file; generate a derived content template representative of the at least one clip; align the derived content template with the reference template to create alignment information; and generate the synchronized content based on the at least one clip, the alignment information, and the synchronization information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633696&OS=09633696&RS=09633696
owner: 3Play Media, Inc.
number: 09633696
owner_city: Boston
owner_country: US
publication_date: 20150529
---
The present application claims priority under 35 U.S.C. 119 e to U.S. Provisional Application 62 005 224 titled SYSTEMS AND METHODS FOR AUTOMATICALLY SYNCHRONIZING MEDIA TO DERIVED CONTENT filed on May 30 2014 which is hereby incorporated herein by reference in its entirety. The present application relates to U.S. application Ser. No. 13 246 123 filed on Sep. 27 2011 and titled ELECTRONIC TRANSCRIPTION JOB MARKET Electronic Transcription Job Market application which is hereby incorporated herein by reference in its entirety. The present application relates to U.S. application Ser. No. 13 426 339 filed on Mar. 21 2012 and titled INTELLIGENT CAPTION SYSTEMS AND METHODS Intelligent Captions application which is hereby incorporated herein by reference in its entirety. The present application relates to U.S. application Ser. No. 13 589 801 filed on Aug. 20 2012 and titled METHODS AND SYSTEMS OF ASSOCIATING METADATA WITH MEDIA Metadata Media Associator application which is hereby incorporated herein by reference in its entirety. The present application relates to U.S. application Ser. No. 14 508 866 filed on Oct. 7 2014 and titled AUTOMATED CAPTION POSITIONING SYSTEMS AND METHODS Automated Caption Positioning application which is hereby incorporated herein by reference in its entirety.

Portions of the material in this patent document are subject to copyright protection under the copyright laws of the United States and of other countries. The owner of the copyright rights has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the United States Patent and Trademark Office publicly available file or records but otherwise reserves all copyright rights whatsoever. The copyright owner does not hereby waive any of its rights to have this patent document maintained in secrecy including without limitation its rights pursuant to 37 C.F.R. 1.14.

The technical field relates generally to transcription of content and more particularly to systems and methods for finding relationships between multiple portions of content.

Media content for example video and audio content is becoming increasingly prevalent as a medium on the internet. For the hearing impaired individuals with attention deficits and non native speakers of the language in which the video audio content is recorded this content presents significant challenges. Legislation and regulations often mandate that at least some of this content be made accessible to this population of consumers. Typically content providers make available transcripts and captions of this content to assist this population and to more generally e.g. even with non impaired users increase engagement with the online media. Time coded transcriptions of the content also make possible advanced capabilities such as the interactive transcript plugins and archive search plugins provided by 3Play Media of Cambridge Mass.

In a typical use case a content provider or a third party produces clips from an original media file. The clips are subsets of the original full length media file often comprised of multiple sub segments and often reordered for various purposes. Each contiguous sub segment of the original media file may be referred to herein as a clip. A collection of clips concatenated in any order into a new file may be referred to herein as a clip reel. 

Occasionally clip reels may include additional footage e.g. an introductory sequence or the audio track or video track may be altered slightly e.g. music added voiceovers added time expanded text overlaid profane language edited commercial or product placement added . For example clip reels may be made from a television show to create sharable video teasers or other advertising vehicles. Or clips of a university lecture may be produced to highlight a particular sub topic discussed by the professor. As with the original complete media file it is important that time coded transcripts captions subtitles annotations semantic tagging advertising temporal metadata and any other events that rely on the timeline be produced as quickly as possible for any clip reels derived from the original media file.

Presently manual tools exist for producing clip reels and their associated synchronized transcripts and captions. For example 3Play Media s Clip Maker tool enables users of the 3Play Media system to create clip reels from existing transcribed captioned media files using textual searching to identify salient regions user interaction to select a set of regions and then automatically extracting the video and audio sections from the original media file to create the clip reel. In this case Clip Maker enables the user to directly control which sections of the original transcript and captions are extracted for the clip reel and makes available to the user the time codes in the original media file. The user may then use the 3Play Media Timeshift API to extract the relevant portions of the transcript and or captions that were produced from the original media file using the time codes from Clip Maker.

However in a typical use case the clip reels are produced independently of the original media file. For example in the film industry it is common for a teaser or advertising clip reel to be made from the original media file e.g. a feature length film in a video editor program such as Final Cut Pro available from Apple Inc. . Often this reel is produced by a third party such as an advertising department or firm and this third party does not have access to the time coded transcript or captions for the original media file. It would of course be possible for the clip reel to be processed separately by transcription and captioning services. However this is expensive and time consuming particularly as video programming providers and distributors already have many such clips and the number of clip reels increases.

Embodiments disclosed herein address the problems described above by automatically e.g. without human intervention creating synchronized time coded or frame coded content derived from reference content. The reference content may include one or more full length media files. The derived content may include video frames clips and clip reels. The synchronized derived content may include video frames clips clip reels transcripts captions subtitles and other synchronized data. At least some features of these embodiments are included in the Video Clip Captioner which is commercially available from 3Play Media.

In at least one embodiment a system for creating synchronized content is provided. The system includes a memory at least one processor coupled to the memory and a synchronization engine component executable by the at least one processor. The synchronization engine component is configured to locate a media file associated with synchronization information locate at least one clip derived from the media file generate a reference template representative of the media file generate a derived content template representative of the at least one clip align the derived content template with the reference template to create alignment information and generate the synchronized content based on the at least one clip the alignment information and the synchronization information.

In the system the synchronization information may include information descriptive of at least one of a final transcription a draft transcription a caption frame and a caption position. The synchronization information may include at least one of time codes and frame codes.

The system may further include a customer interface component configured to import the synchronization information from a system distinct from the system. The system may further include a market engine component and the synchronization engine component may be further configured to transmit a request to the market engine component to generate the synchronization information.

In the system the derived content template may include a first plurality of feature vectors and the reference template may include a second plurality of feature vectors. The synchronization engine component may be configured to align the derived content template with the reference template where a similarity metric between the first plurality of feature vectors and the second plurality of feature vectors transgresses at least one threshold value. The similarity metric may be at least one of a correlation coefficient and an average distance.

In the system the first plurality of feature vectors may include a first group of feature vectors and a third group of feature vectors. The second plurality of feature vectors may include a second group of feature vectors and a fourth group of feature vectors. The threshold value may be a first distance that is less than a second distance the first distance being between the first group and the second group the second distance being between the third group and the fourth group.

In the system the first plurality of feature vectors may include a first group of feature vectors and a third group of feature vectors. The second plurality of feature vectors may include a second group of feature vectors and a fourth group of feature vectors. The threshold value may be a first correlation coefficient that is greater than a second correlation coefficient the first correlation coefficient being between the first group and the second group the second correlation coefficient being between the third group and the fourth group.

In the system the synchronization engine component may be configured to align the derived content template with the reference template at least in part by partitioning the derived content template into a plurality of template elements and aligning a template element of the plurality of template elements with the reference template where a similarity metric between the first plurality of feature vectors and the second plurality of feature vectors transgresses at least one threshold value. Each element template of the plurality of template elements may span a configurable length. The plurality of template elements may include at least one other template element comprising a third plurality of feature vectors. The reference template may include a fourth plurality of feature vectors. The synchronization engine component may be configured to align the derived content template with the reference template at least in part by concatenating the at least one other template element to the template element where a similarity metric between the third plurality of feature vectors and the fourth plurality of feature vectors transgresses the threshold value.

In the system the synchronization engine component may be further configured to concatenate the at least one other template element to the template element in a location before to the template element. The synchronization engine component may be further configured to concatenate the at least one other template element to the template element in a location after the template element. The synchronization engine component may be further configured to initiate generation of caption frames based on the synchronized content. The synchronization engine component may be further configured to initiate generation of caption positioning information based on the caption frames.

In the system the at least one clip may include added content omitted from the media file. The synchronization engine component may be further configured to initiate generation of at least one of a synchronized transcription caption frames and caption positioning information for the added content. The synchronization engine component may be further configured to generate a confidence document including a score indicating whether the synchronized content is correct. The synchronization engine component may be further configured to determine whether the score transgressed a threshold value and to either transmit the synchronized content in response to determining that the score transgressed the threshold value or initiate editing of the synchronized content in response to determining that the score transgressed the threshold value.

In another embodiment a method for creating synchronized content using a computer system is provided. The method includes acts of executing a synchronization engine component locating by the synchronization engine component a media file associated with synchronization information locating by the synchronization engine component at least one clip derived from the media file generating by the synchronization engine component a reference template representative of the media file generating by the synchronization engine component a derived content template representative of the at least one clip aligning by the synchronization engine component the derived content template with the reference template to create alignment information and generating by the synchronization engine component the synchronized content based on the at least one clip the alignment information and the synchronization information. Other embodiments of the method may include any combination of the acts disclosed herein.

In another embodiment a non transitory computer readable medium storing sequences of computer executable instructions for creating synchronized content is provided. The sequences of computer executable instructions include instructions that instruct at least one processor to execute a synchronization engine component locate by the synchronization engine component a media file associated with synchronization information locate by the synchronization engine component at least one clip derived from the media file generate by the synchronization engine component a reference template representative of the media file generate by the synchronization engine component a derived content template representative of the at least one clip align by the synchronization engine component the derived content template with the reference template to create alignment information and generate by the synchronization engine component the synchronized content based on the at least one clip the alignment information and the synchronization information. Other embodiments of the computer readable medium may store instructions to execute any combination of the computer executable acts disclosed herein.

Still other aspects embodiments and advantages of these exemplary aspects and embodiments are discussed in detail below. Moreover it is to be understood that both the foregoing information and the following detailed description are merely illustrative examples of various aspects and embodiments and are intended to provide an overview or framework for understanding the nature and character of the claimed aspects and embodiments. Any embodiment disclosed herein may be combined with any other embodiment. References to an embodiment an example some embodiments some examples an alternate embodiment various embodiments one embodiment at least one embodiment this and other embodiments or the like are not necessarily mutually exclusive and are intended to indicate that a particular feature structure or characteristic described in connection with the embodiment may be included in at least one embodiment. The appearances of such terms herein are not necessarily all referring to the same embodiment.

At least one embodiment disclosed herein includes apparatus and processes for implementing using a computer system a transcription job market. In some embodiments the transcription job market receives transcription request information from customers that identifies media files with encoded audio content that the customers seek to have transcribed. In these embodiments the transcription job market creates and posts jobs associated with the media files.

In other embodiments the transcription job market manages market elements to ensure that jobs are being completed according to schedule and with quality. These market elements may include one or more attributes of one or more jobs. In some embodiments the transcription job market receives information from editors that identifies jobs that the editors seek to complete. In these embodiments the transcription job market further provides tools used by the editors to complete their transcription tasks. These tasks may produce transcriptions that are synchronized and transcriptions that lack time coding or frame coding i.e. are synchronized. 

Other embodiments include a synchronization engine that synchronizes content derived from reference content. The reference content may include one or more media files. The derived content may include one or more clips or clip reels as described above. In some embodiments the synchronization engine generates synchronized transcription products based on the location of the derived content within the one or more media files. These transcription products may include transcriptions captions frames such as those described in the Intelligent Captions application and the Automated caption positioning application and captions encoded within the derived content for example a copy of a clip uploaded to the system .

Examples of the methods and systems discussed herein are not limited in application to the details of construction and the arrangement of components set forth in the following description or illustrated in the accompanying drawings. The methods and systems are capable of implementation in other embodiments and of being practiced or of being carried out in various ways. Examples of specific implementations are provided herein for illustrative purposes only and are not intended to be limiting. In particular acts components elements and features discussed in connection with any one or more examples are not intended to be excluded from a similar role in any other examples.

Also the phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. Any references to examples embodiments components elements or acts of the systems and methods herein referred to in the singular may also embrace embodiments including a plurality and any references in plural to any embodiment component element or act herein may also embrace embodiments including only a singularity. References in the singular or plural form are not intended to limit the presently disclosed systems or methods their components acts or elements. The use herein of including comprising having containing involving and variations thereof is meant to encompass the items listed thereafter and equivalents thereof as well as additional items. References to or may be construed as inclusive so that any terms described using or may indicate any of a single more than one and all of the described terms. In addition in the event of inconsistent usages of terms between this document and documents incorporated herein by reference the term usage in the incorporated references is supplementary to that of this document for irreconcilable inconsistencies the term usage in this document controls.

Various embodiments implement a transcription system using one or more computer systems. illustrates one of these embodiments a transcription system . As shown includes a server computer client computers and a customer an editor an administrator networks and and an automatic speech recognition ASR device . The server computer includes several components a customer interface an editor interface a system interface an administrator interface a market engine a market data storage a media file storage and a synchronization engine .

As shown in the system interface exchanges i.e. sends or receives media file information with the ASR device . The customer interface exchanges information with the client computer via the network . The editor interface exchanges information with the client computer via the network . The networks and may include any communication network through which computer systems may exchange information. For example the network the network and the network may be a public network such as the internet and may include other public or private networks such as LANs WANs extranets and intranets.

Information within the transcription system including data within the market data storage and the media file storage may be stored in any logical construction capable of holding information on a computer readable medium including among other structures file systems flat files indexed files hierarchical databases relational databases or object oriented databases. The data may be modeled using unique and foreign key relationships and indexes. The unique and foreign key relationships and indexes may be established between the various fields and tables to ensure both data integrity and data interchange performance. In one embodiment the media file storage includes a file system configured to store media files and other transcription system data and acts as a file server for other components of the transcription system. In another embodiment the media file storage includes identifiers for files stored on another computer system configured to serve files to the components of the transcription system.

Information may flow between the components illustrated in or any of the elements components and subsystems disclosed herein using a variety of techniques. Such techniques include for example passing the information over a network using standard protocols such as TCP IP or HTTP passing the information between modules in memory and a passing the information by writing to a file database data store or some other non volatile data storage device. In addition pointers or other references to information may be transmitted and received in place of in combination with or in addition to copies of the information. Conversely the information may be exchanged in place of in combination with or in addition to pointers or other references to the information. Other techniques and protocols for communicating information may be used without departing from the scope of the examples and embodiments disclosed herein.

One goal of the transcription system is to receive media files from customers and to provide both final and intermediate transcriptions of the content included in the media files to the customers. One vehicle used by the transcription system to achieve this goal is a transcription job. Within the transcription system transcription jobs are associated with media files and are capable of assuming several states during processing. illustrates an exemplary process during the execution of which a transcription job assumes several different states.

As shown in the process begins when the transcription system receives transcription request information that identifies a media file to transcribe in act . The transcription request information may also include delivery criteria that specifies a schedule e.g. one or more delivery times quality levels or other criteria defining conditions to be satisfied prior to delivery of transcription products. In some embodiments the transcription system receives the transcription request information and the media file via an upload from a customer interface such as the customer interface or as a result of a previously received media file being split per act below. Upon receipt of the transcription request information and the media file the transcription system creates a job associates the job with the media file and sets the job to a new state . In act the transcription system sets the job to an ASR in progress state generates draft transcription information and determines a pay rate for the job. When executing the act some embodiments track completion percentage of the draft transcription during ASR processing. Record of completion percentage is used to execute subsequent delivery processes where ASR processing is not complete due to the schedule or interruption by another delivery request. Further these embodiments compute one or more metrics that characterize the quality of the draft transcription. Draft transcriptions may be full transcriptions or partial transcriptions where ASR processing is not completed . Some embodiments incorporate information descriptive of the completion percentage and quality metrics into the draft transcription information.

In act the transcription system posts the job making the job available for editors to claim and sets the job to an available state . Jobs in the available state correspond to draft transcriptions that have completed full or partial ASR processing. As described further below in some embodiments in accord with the transcription system monitors the due dates and times of available jobs and if necessary alters the pay rate or other job characteristics of the available jobs to ensure the available jobs are completed by the due date and time.

In act the transcription system accepts an offer by an editor to claim the job and sets the job to an assigned state . In the illustrated embodiment jobs in the assigned state are not available for claiming by other editors. In act the transcription system determines whether the predicted completion date and time for the job as assigned occurs before the due date and time. If so the transcription system executes act . Otherwise the transcription system executes act .

In the act the transcription system determines whether to revoke the job. If so the transcription system executes the act . Otherwise the transcription system executes the act .

In the act the transcription system records and monitors actual progress in transcribing the media file associated with the job as the progress is being made by editors. Also in the act the transcription system sets the job to an editing in progress state . In the act the transcription system determines whether the job is progressing according to schedule. If so the transcription system executes act . Otherwise the transcription system executes act .

In the act the transcription system determines whether to split the media file associated with the job into multiple media files. For example the transcription system may split the media file into one segment for any work already completed and into another segment for work yet to be completed. This split may enable the transcription system to further improve the quality on a segment by segment basis. For example a segment which has been edited may be split from other segments so that the edited segment may proceed to quality assurance QA . Thus splitting the media file may enable the transcription system to provide partial but progressive delivery of one or more transcription products to customers. If the transcription system splits the media file the transcription system stores the edited completed segment and executes the act for any segments that include content not completely transcribed. If in the act the transcription system determines to not split the media file the transcription system executes the act .

In the act the transcription system determines whether the content of the media file associated with the job is completely transcribed. If so the transcription system stores the edited complete transcription and sets the state of the job to a complete state and the process ends. Otherwise the transcription system executes the act .

In some embodiments completed transcriptions may be the subject of other jobs such as QA jobs as described further below. Components included within various embodiments of the transcription system and acts performed as part of the process by these components are described further below.

According to various embodiments illustrated by the market engine is configured to both add jobs to the transcription job market provided by the transcription system and to maintain the efficiency of the transcription job market once the market is operational. To achieve these goals in some embodiments the market engine exchanges market information with the customer interface the administrator interface the editor interface the system interface the market data storage the media file storage and the synchronization engine . Market information may include any information used to maintain the transcription job market or stored within the market data storage . Specific examples of market information include media file information job information customer information editor information administrator information and transcription request information. Each of these types of information is described further below with reference to .

In some embodiments the synchronization engine is configured to synchronize derived content e.g. video frames clips or clips reels with one or more media files. When executing according to this configuration the synchronization engine exchanges market information with customer interface the market engine the market data storage and the media file storage .

In some examples the synchronization engine is configured to receive notifications from other components of the transcription system such as the customer interface and the market engine . These notifications may include transcription request information and may describe the status and location of transcription information corresponding to the one or more media files being processed by the transcription system . As described further below transcription information may include textual representations of audio information associated with a media file and may include or be associated with synchronization information e.g. codes indicating a time or a video frame during which the audio information associated with the textual representation is output . For instance these notifications may indicate that the transcription information includes final transcription information draft transcription information or segments thereof. In some embodiments in response to receiving notifications the synchronization engine may take one of several actions as specified by previously received parameters and the transcription request information.

In other examples the synchronization engine does not receive notifications regarding transcription information availability. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether transcription information is available for processing. Where the synchronization engine detects transcription information targeted for synchronization via this periodic scan the synchronization engine may take one of several actions as specified by previously received parameters and the transcription request information.

In some examples the synchronization engine is configured to receive transcription request information including an automatic synchronization request that identifies final transcription information generated prior to receipt of the transcription request information. For example the transcription request information may include an automatic synchronization request that identifies a clip derived from a media file associated with the final transcription information. This final transcription information may have been generated by the transcription system via the process . Alternatively this final transcription information may have been generated by some other system and uploaded or imported into the transcription system via the customer interface .

To process the transcription request information the synchronization engine may generate templates of the one or more media files and the derived content align the templates generate a synchronized version of the derived content and generate transcription products using the synchronized derived content and other associated transcription information. These transcription products may include transcriptions e.g. synchronized and non synchronized captions frames such as those described in the Intelligent Captions application and the Automated caption positioning application captions encoded in media files for example a copy of the media file uploaded to the system and auxiliary deliverables such as search keywords semantic tags annotations subtitles descriptive summarization and other metadata derived either automatically or manually from the transcription information. These auxiliary products may be derived automatically from the synchronized derived content at any stage using natural language processing algorithms such as TextRank GRASSHOPPER and maximum entropy modeling. The auxiliary deliverables may be used on web sites to optimize for search engine ranking of the page by for example directly encoding the auxiliary deliverables into the HTML that constitutes the web sites.

In some embodiments the synchronization engine produces caption frames from the synchronized derived content via natural language processes as described in the Intelligent Captions application. These processes when executed by the synchronization engine determine syntactic boundaries for example sentence and paragraph boundaries. The synchronization engine may convert caption frames into various caption formats for embedding internet based media players or may include the caption frames directly into a version of the original media file to provide open or closed caption playback for the media file.

In some embodiments the synchronization engine is configured to generate information descriptive of the quality level achieved by its synchronization process. For instance in one example the synchronization engine generates a confidence document for example a json document that is stored in association with the synchronized derived content to indicate the degree to which the automated synchronization process results in properly aligned and valid synchronized derived content. illustrates one example of a confidence document. Elements of this document may include an overview of confidence scores associated with each stage of the synchronization process an overall score a specific list of time points for identified problematic areas metadata associated with each matched region and each unmatched region and a listing of matched time regions showing correspondence between the reference content file times and associated times in the derived content as determined by the synchronization process.

In some examples the overview of confidence scores includes distances measured between a reference template and a derived content template for each contiguous region. In these examples the reference template is representative of the one or more media files and the derived content template is representative of the content derived from the one or more media files. In other examples the overview of confidence scores includes the total percentage of the derived content matched to the reference content and a summary of scores for each transcript element or caption frame included in the output. The summary of scores indicates the quality of the match with regard to each transcript element or caption frame. For example a caption frame might contribute a low score if it includes a sentence that was cut in half by the estimated match.

In some examples the overall score within the confidence document represents a single value of confidence for the generated transcription products. In other examples the specific list of time points for identified problematic areas includes for example regions with low match scores or with caption frames that are split by a matched region boundary. This list can be used for a quick review of the output.

In some examples the metadata associated with each matched region e.g. where the reference content time points are non null and each unmatched region e.g. where the reference content time points are null region includes individual match scores for each region average acoustic power in each region and estimates of the amount of speech in each region based on audio and image processing of these regions. In some examples the average acoustic power in an unmatched region is used to determine the contribution of the unmatched duration to the scores described above. For instance if an unmatched region in the derived content has very low power it may not penalize the score significantly. However if an unmatched region has high power the fact that no match was found in the reference content might cause the score to be decreased.

In some embodiments the synchronization engine is configured to utilize the quality information included in the confidence document to execute further processing. For example if the overall confidence score is above a first threshold value the synchronization engine may publish the synchronized derived content. This publication may include for example automatic transmission of the synchronized derived content to the customer s system or web page as described further below. Alternatively if the overall confidence score is below a second threshold value the synchronization engine may submit the synchronized derived content to the transcription workflow process of the transcription system . Otherwise if the first threshold value is distinct from the second threshold value and the confidence score is between the first threshold value and the second threshold value the synchronization engine may prompt a user to examine or modify the synchronized derived content using a tool such as 3Play Media s clip captioning editor. which is described further below illustrates a screen presented by the customer interface when executing the clip captioning editor. The first threshold value and second threshold values may be specified by a configurable parameter in the transcription system transcription request information or a combination of both. The annotations and other information in the confidence document may be used to facilitate this editing process. In some examples the customer interface may automatically download the confidence document e.g. using an HTTP API request or a parameter to the same request by which the synchronized derived data is downloaded to facilitate automation of various process such as those described above.

In some embodiments the synchronization engine is configured to automatically transmit transcription products by embedding the transcription products directly onto a web page for example by modifying plugin HTML code to point to the updated resource URL or executing an HTTP API to modify the web page HTML code. In other embodiments the synchronization engine is configured to transmit the transcription products to an FTP folder specified in the transcription request information or a configurable parameter.

While the synchronization engine is illustrated as a component distinct from the market engine in it is appreciated that the synchronization engine may be incorporated into the market engine according to some embodiments. In addition processes executed by the synchronization engine according to various embodiments are described further below with reference to .

In some embodiments the market engine is configured to identify unprocessed media files stored in the media file storage . In some of these embodiments the market engine identifies unprocessed media files after receiving an indication of the storage of one or more unprocessed media files from another component such as the customer interface which is described further below. In others of these embodiments the market engine identifies unprocessed media files by periodically executing a query or some other identification process that identifies new unprocessed media files by referencing information stored in the market data storage or the media file storage . In some embodiments the market engine is also configured to send a request for ASR processing of unprocessed media files to the system interface . This request may include information specifying that only a limited portion of the unprocessed media file e.g. a specified time period be processed. Further in at least one embodiment the market engine tracks completion percentage of the draft transcription during subsequent ASR processing. The market engine may store in the market data storage the completion percentage associated with partial transcriptions stored in the media file storage .

In these embodiments the system interface is configured to receive requests for ASR processing and in response to these requests provide the unprocessed media files to the ASR device along with any requested limits on the ASR processing. The ASR device is configured to receive a media file to perform transcoding and automatic speech recognition on the received media file in accord with the request and to respond with draft transcription information that includes a draft synchronized or non synchronized transcription of the content of the received media file and a predicted cost of editing the draft transcription. This predicted cost referred to herein as the ASR cost is based on information computed as part of the ASR processing and a cost model. The cost model may be a general model or may be associated with the project customer or editor associated with the media file. A project is a set of media files grouped by a customer according to domain due date and time or other media file attribute. Projects are described further below. Cost models predict the cost of editing a draft transcription and are described further with reference to below. The system interface is further configured to receive the draft transcription information store the draft transcription information in the media file storage store the location of the draft transcription information in the market data storage and notify the market engine of the availability of the draft transcription information.

In one example illustrated by the market engine receives an identifier of a newly stored media file from the customer interface . Responsive to receipt of this identifier the market engine provides a request to perform ASR processing on the media file to the system interface . The system interface in turn retrieves the media file from the media file storage and provides the media file along with a set of parameters that indicate appropriate language acoustic cost and formatting models to the ASR device . The ASR device responds with draft transcription information that includes a synchronized draft transcription lattices search statistics ASR cost and other associated data. The system interface receives the draft transcription information stores the draft transcription information in the media file storage stores the location of the draft transcription information in the market data storage and notifies the market engine of the availability of the draft transcription information.

In other embodiments the market engine is configured to perform a variety of processes in response to receiving a notification that draft transcription information is available. For instance in one example after receiving a notification that draft transcription information is available the market engine notifies the synchronization engine that draft transcription information is available by providing the synchronization engine with a notification describing the location and status of the draft transcription information. In other examples the market engine does not notify the synchronization engine of draft transcription information availability. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether draft transcription information is available for processing. In another example the market engine employs natural language processing techniques to determine the type of content or domain included in the media file associated with the draft transcription information and stores this information in the market data storage . In another example the market engine determines the duration of the content included in the media file and stores the duration in the market data storage . In another example after receiving a notification that draft transcription information is available the market engine determines an initial pay rate for editing the draft transcription included in the draft transcription information and stores job information associated with the draft transcription in the market data storage . In this example the initial pay rate included in the job information is determined using the due date and time difficulty duration domain and ASR cost of the media file associated with the draft transcription information. In other examples other combinations of these factors may be used or these factors may be weighted differently from one another. For instance in one example due date and time and duration may be replaced with times real time. In another example the weight applied to any particular factor may be 0.

In other embodiments the market engine is configured to periodically publish or push notifications to editors that indicate the availability of new jobs. In one of these embodiments the market engine tailors these notifications by sending them only to particular editors or groups of editors such as those editors who have permission to edit the jobs. In other embodiments the market engine tailors notifications based on other job characteristics such as the type of job editing QA etc difficult domain or due date and time. In some examples the market engine sends notifications to editors based on their ability to complete jobs having the attribute to which that the notification is tailored. Continuing the previous examples the market engine may send notifications to editors who may assume particular roles editor QA etc. who have a track record of handling difficult jobs who are well versed in a particular domain or who are highly efficient.

In at least one embodiment the market engine notifies editors of near term future job availability based on the upstream workflow. In this embodiment as files are uploaded by customers and processed by the ASR device the market engine predicts how many more jobs will be available and based on one or more the attributes of these jobs such as duration domain etc. the market engine sends out advanced notice to one or more editors via the editor interface .

In other embodiments the market engine is configured to determine the difficulty of successfully editing the draft transcription and to store the difficulty in the market data storage . In these embodiments the market engine may base this determination on a variety of factors. For example in one embodiment the market engine calculates the difficulty using an equation that includes weighted variables for one or more of the following factors the content type domain of the media file the historical difficulty of media files from the customer or the project the draft transcription information and acoustic factors such as noise level signal to noise ratio bandwidth and distortion .

In some embodiments the market engine is configured to create and post jobs corresponding to unedited media files thereby making the jobs available to the editors for claiming and completion. According to one example as part of this processing the market engine stores an association between each job and a media file targeted for work by the job. This action is performed so that factors affecting pay rate such as those described above can be located in a media file table.

As described further below with reference to the editor interface editors claim jobs by indicating their preferences on a user interface provided by the editor interface . After a job is claimed the job is removed from the market so that no other editors can access the job. However until the editor has actually begun to edit the job it is relatively easy for the job to be put back on the market. Typically leaving the original claim in place is preferred. However in some embodiments the market engine is configured to determine whether the editor who claimed the job will be able to complete the job before the due date and time. In these embodiments the market engine is configured to make this determination based on the job characteristics difficulty domain duration etc. and the editor s historical proficiency as stored in the market data storage . For example the editor may be associated with a times real time statistic stored in the market data storage . The times real time statistic measures editor productivity and is calculated by dividing the time it takes for the editor to complete each job by the duration of the media file associated with each job. In some embodiments the market engine is configured to use this statistic to estimate the completion time of the job based on duration multiplied by times real time . In some embodiments the market engine is configured to condition this statistic based on job attributes and thus compute the statistic from similar jobs performed by the editor in the past. The set of historical jobs used to compute the times real time statistic may include all jobs performed by the editor a subset of jobs which have similar attributes to the present job or other combinations of historical jobs including those that were not performed by the editor. The market engine may calculate this statistic as a mean a median a duration weighted mean or using summaries of historical processing times for the editor or other editors for different media file subsets.

In other embodiments if the market engine determines that an editor may be unlikely to complete a job before the due date and time the market engine may reverse the assignment and put the job back on the market thus allowing some number of other editors to claim the job. In some these embodiments the market engine determines the likelihood that the editor will complete the job before its due date and time using one or more of the following factors historical productivity of the editor in general or more specifically when editing media files having a characteristic in common with the media file associated with the job the number of jobs currently claimed by the editor the number of jobs the editor has in progress and the due dates and times of the jobs claimed by the editor. When the market engine reverses an assignment the original editor is informed of this condition via the editor interface . The market engine may or may not allow the original editor to reclaim the job from the market depending on whether data indicates interest of other editors in the job. One example of an indicator of interest is whether the job is being previewed by any other editors. Another factor which may influence this decision is if the total volume of unedited draft transcriptions exceeds a threshold.

In some embodiments the market engine determines a likelihood of completion for each possible combination of editor and job. In these embodiments the market engine may calculate this likelihood using any combination of the factors discussed above historical productivity number of jobs claimed number of jobs in progress due dates and times of claimed jobs etc. . Further in some embodiments the market engine prevents editors from claiming jobs for which the editor s likelihood of completion metric transgresses a threshold. In these embodiments the threshold is a configurable parameter. Further according to these embodiments the market engine may prevent an editor from claiming a job in a variety of ways including rejecting an offer from the editor to claim the job and causing the job to not be display to the editor within the editor interface via for example a meta rule. Meta rules are discussed further below.

In other embodiments if the market engine determines that an editor may be unlikely to complete a job before the due date and time the market engine sends a notification to the editor who claimed the job via the editor interface . The notification may include a variety of information such as a notification that the job may be revoked shortly or including a link to allow the editor to voluntarily release the job.

In several embodiments the market engine is configured to give permission to many editors to edit the same draft transcription and to offer all editors the same pay rate to do so. In some alternative embodiments however the market engine is configured to determine if based on historical information some editors display an increased proficiency with particular types of media files for example in certain domains and to increase the pay rate for these editors when transcribing media files having the particular type. In addition some embodiments of the market engine are configured to adjust the pay rate based on overall editor experience levels as well as the historical productivity of the editors both in general and on the type of media file for which the rate is being set.

In general the market engine sets the pay rate based on the aforementioned factors such as job difficulty required times real time and ASR cost. However to maintain an efficient market in some embodiments the market engine is configured to determine when market conditions suggest intervening actions and to in some cases automatically take those intervening actions. For example when the market is saturated with non difficult jobs an abnormally large amount of unassigned difficult jobs may develop. According to this example to correct the inefficiency in the market the market engine intervenes by increasing the pay rate of difficult jobs or decreasing the pay rate of low difficulty jobs. In still another example the market engine intervenes to increase the pay rate of a job where the proximity of the current date and time and due date and time for the media file associated with the job transgresses a threshold.

In some embodiments the market engine is configured to use the preview functionality as an indicator of job difficulty and appropriate pay rate. For instance in one example the market engine detects that the number of editors who have previewed a job and not claimed it has exceeded a threshold. Alternatively in another example the market engine detects that the total preview duration of an unclaimed job has transgressed a threshold. These phenomena may indicate that the job is more difficult than is reflected by the current pay rate. The market engine may then intervene to increase the pay rate to improve the chance that the job will be claimed or to split the media file into segments.

Additionally in some embodiments the market engine monitors the status of and information associated with all jobs available on the market. This information includes difficulty pay rate due date and time domain and summary information such as the number of editors with permission to edit a draft transcription the amount of time a job has been on the market the number of previews of the media file associated with a job and other data concerning the market status of the job and its associated media file. In some embodiments the market engine is configured to use this information to ensure that problem jobs are accepted. For example the market engine may increase the pay rate may enable a larger number of editors to access to the file or may cut the file into shorter segments thus producing several less difficult editing jobs for the same media file.

In other embodiments the market engine is configured to under certain conditions hide some of the low difficulty jobs in order to create a more competitive environment or to induce editors to work on difficult jobs. Additionally in some embodiments the market engine is configured to encourage the editors to accept less desirable jobs by bundling jobs together with more desirable jobs. For example the market engine may group a selection of jobs with variable difficulty together so that a single editor would need to claim all of these jobs instead of claiming only low difficulty jobs. Other characteristics that may determine the desirability of a job and which may be used to determine the bundling include customer project domain e.g. interesting content and historical time waiting on the market for the customer project.

In some embodiments the market engine is configured to analyze the overall status of the market prior to modifying job characteristics. For instance in one example the market engine monitors the amount of work available in the market and if the amount transgresses a threshold increases the pay rate for jobs that are within a threshold value of their due dates and times. In other embodiments the market engine is configured to analyze the dynamics of the overall market to determine intervening actions to perform. In one example the market engine measures the rate at which jobs are being accepted and measures the number of jobs or duration of the jobs and estimates the time at which only the least popular jobs will remain in the market. If the market engine determines that this time is sufficiently ahead of the due date and time for these jobs then the market engine may wait before increasing the pay rate.

In other embodiments the market engine is configured to set meta rules to affect the behavior of the market. Meta rules globally modify the behavior of the market by affecting how all or some of the available jobs will appear on the market. For instance the market engine may set a meta rule that prevents some percentage of the jobs from being available to any editors for a certain time period. The market engine may use this rule during periods when there is a surplus of work and therefore help to smooth out the flow of files through the system. Or the market engine may set a meta rule to make files available only to relatively inexperienced editors for a certain time period. The market engine may use this rule where many relatively easy jobs are being processed by the market so that the market presents a good opportunity to give less experienced editors more work in learning how to efficiently operate the editing platform. Or the market engine may set a meta rule that automatically send some percentage of jobs to multiple editors for cross validation. Various embodiments may implement a variety of meta rules and embodiments are not limited to a particular meta rule or set of meta rules.

In other embodiments the market engine is configured to implement a rewards program to encourage editors to claim difficult jobs. In one embodiment the market engine issues rewards points to editors for completing files and bonus points for completing difficult files. In this embodiment the editor interface is configured to serve a rewards screen via the user interface rendered on the client computer . The rewards screen is configured to receive requests to redeem reward and bonus points for goods and services or access to low difficulty media files.

In some embodiments the market engine is configured to estimate the expected completion time of the editing job and further refine the market clearing processes discussed above. If the market engine determines that the current progress is not sufficient to complete the file on time the editor may be notified of this fact via the editor interface and should the condition persist the market engine is configured to make the job available to other editors i.e. to put the jobs back on the market . In some circumstances the market engine may revoke the entire job from the original editor. In this case the job is put back on the market as if no work had been done. In other cases the market engine may dynamically split the job at the point where the original editor has completed editing creating one or more new jobs that are comprised of the remaining file content. The market engine puts these one or more new jobs on the market and the original editor is paid only for the completed work. In this situation the market engine may notify the synchronization engine of the status and location of any completed transcription segments. This functionality enables time efficient delivery to the customer of transcription products based on media e.g. clips or clip reels derived from the completed segments as described further with reference to the synchronization engine and the processes it executes. In other examples the market engine does not notify the synchronization engine of completed transcription segments. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether one or more completed segments are available for processing.

In some embodiments the market engine is configured to process a delivery request or partial delivery request received from another component such as the customer interface . In response to receiving a partial delivery request targeting a media file being processed in a job the market engine dynamically splits the job at the point where the original editor has completed editing and creates one or more new jobs that are comprised of the remaining file content. The market engine puts these one or more new jobs on the market and the original editor is paid only for the completed work. Further in these embodiments the market engine notifies the synchronization engine of the status and location of completed segments stored as a result of the job split. It is appreciate that the splitting functionality described herein may apply to any jobs being processed by the transcription system such as QA jobs. In other examples the market engine does not notify the synchronization engine of completed transcription segments. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether one or more completed segments are available for processing.

In another embodiment in response to receiving a partial delivery request targeting a media file being processed in a job the market engine stores one or more segments of the transcription up to the point where the editor has completed editing without interrupting the job. In this embodiment the market engine notifies the synchronization engine of the status and location of completed segments. In other examples the market engine does not notify the synchronization engine of completed transcription segments. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether one or more completed segments are available for processing.

In other embodiments the market engine is configured to perform a variety of processes after receiving an indication that a job has been completed. For example if a newly completed draft transcription information was split into segments then the market engine concatenates completed segments together into a completed transcript. In another example the market engine notifies the synchronization engine of the location and status of the completed transcript. In other examples the market engine does not notify the synchronization engine of the completed transcript. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether one or more completed transcripts are available for processing.

In another example the market engine is configured to compare a completed synchronized transcript with the draft transcription produced by the ASR device . In this example the market engine uses the number of corrections performed on the transcript to compute a standard distance metric such as the Levenshtein distance. The market engine stores this measurement in the market data storage for later use in determining an objective difficulty for the editing job.

In various embodiments the market engine is configured to use the objective difficulty in a variety of processes. For example in some embodiments the market engine uses the objective difficulty for a set of jobs to adjust the historical times real time statistic for an editor to determine the actual price that the customer pays for the transcription service or as input to the automated difficulty determination process discussed herein.

In other embodiments the market engine is configured to prior to making the completed transcript available to the customer create and post a new job to validate the completed transcription or the completed segments of a transcription. For example in one embodiment the market engine creates and posts a QA job on the same market as the editing jobs. This QA job may target completed transcriptions or a completed segment of a transcription. A subset of editors may be qualified for the QA role and the profiles of this subset may include a QA attribute. These editors would then be permitted to view preview and claim the QA jobs in the market via the editor interface . However in some examples the editor of the original transcript would not have permission to QA their own job even if the editor in general is qualified to perform in a QA role. The profiles of some editors may include a QA attribute but lack an editor attribute. These editors would only be permitted to view preview and claim QA jobs.

As the QA jobs normally require much less work than the original editing job in some embodiments the market engine is configured to set the pay rate for the QA jobs at a lower level. However in other embodiments the market engine is configured to monitor and adjust the pay rate for the QA jobs as for the editing jobs with similar factors determining the pay rate including file difficulty the ASR cost the proximity of the due date and time and the media file duration. Additionally in some embodiments the market engine is configured to use QA specific factors to determine the pay rate for QA jobs. For example in one embodiment the market engine adjusts the pay rate based on the number of flags in the edited transcript the historical proficiency of the original editor the times real time it took to produce the completed transcription and the ASR distance metric for the media file. Flags are set during the editing process and indicate problem content within the edited transcript. For example flags may indicate content that is unclear or that requires additional research to ensure accurate spelling. In some embodiments the flags are standardized to facilitate automatic processing by the components of the transcription system.

After this QA processing is complete in some embodiments the market engine is configured to make the final synchronized transcription or its final synchronized segments available to the customer who may then download the transcription or transcription segments for his or her own use via the customer interface . In other embodiments after the QA processing is complete the market engine notifies the synchronization engine of the status and location of the final synchronized transcription or its final synchronized segments. In other examples the market engine does not notify the synchronization engine of final transcription information availability. In these examples the synchronization engine periodically scans the market data storage and the media file storage to determine whether final transcription information is available for processing. The final transcription or its finalized segments are also maintained in the media file storage for reference and further processing as discussed herein.

In some embodiments to periodically measure editor proficiency the market engine is configured to allow a media file to be edited by multiple editors. For instance in one example the market engine periodically creates several different editing jobs from the same media file and these jobs are claimed and processed by multiple editors. The market engine tracks the underlying media file and does not assign more than one of these jobs to the same editor. After several editors edit the same file the market engine executes a ROVER or similar process to determine intra editor agreement and thereby assign quality scores to individual editors the quality score being proportional to the number of words in the editor s final transcript which have high agreement among the other editors. In addition the market engine may use the ROVER process to produce the final transcript. In this case the market engine may assign different weights to different editors based on the editor characteristics domain or customer expertise historical transcription proficiency etc .

In other embodiments the market engine is configured to build cost models that are used to determine predicted costs for editing draft transcriptions. In some of these embodiments the market engine is configured to generate cost models based on variety of information including historical productivity information such as times real time statistics and ASR distance information. Further in these embodiments the cost models may be specific to particular editors customers or projects. For instance in one example the market engine builds cost models that accept a unique identifier for a media file the ASR information synchronized draft transcription lattices search statistics acoustic characteristics for the media file and an indication of an editor customer or project associated with the media file and that return a projected transcription cost that is conditioned on historical productivity associated with the editor customer or project. Once these models are built the market engine stores them in the media file storage .

In some embodiments customers may be given access to the transcripts for final editing via the customer interface . In these embodiments the market engine uses the customer edits as the gold standard reference for computing editor accuracy. In other embodiments the market engine is configured to use times real time stored in the market data storage at the time of job upload as a factor in determining editor proficiency. Typically the market engine also adjusts the editing time and thus the historical editing productivity for editors by an objective difficulty such as the ASR distance because more difficult files will necessarily take longer to edit.

As described above in some examples customers are given access to edit transcription and caption information associated with synchronized derived content e.g. clips or clip reels . illustrates one example screen served by the customer interface that supports this function. As shown in the screen includes transcription information section and video clip captioning results section . The transcription information section highlights text that is associated with synchronized derived content. The transcription information section further includes an edit word button a delete word button and an edit paragraph button that facilitate editing of the transcription information. In response to receiving input selecting any of these buttons the screen provides one or more user interface elements or executes other processes that perform the function recited in the name of the button. The video clip captioning results section includes a graphical representation of the locations within the media file where portions of the clip may be found.

In some embodiments the customer interface is configured to provide a user interface to the customer via the network and the client computer . For instance in one embodiment the customer interface is configured to serve a browser based user interface to the customer that is rendered by a web browser running on the client computer . In this embodiment the customer interface exchanges customer and media file information with the customer via this user interface. Media file information may include one or more media files information associated with the one or more media files or information descriptive of the attributes of the one or more media files. Specific examples of media file information include a media file to be transcribed content derived from the media file e.g. captions and caption placement information a type of content included in a media file a date and time a transcription of a media file is due a domain of the subject matter presented in the content a unique identifier of a media file storage location of a media file subtitles associated with a media file annotations associated with a media file semantic tagging associated with a media file and advertising associated with a media file. Media file information is described further below with reference to . According to an example illustrated by the customer interface receives media file information from the user interface. This media file information includes a media file information indicating a date and time that transcription of the media file is due and a type of content included in the media file. Responsive to receipt of this media file information the customer interface stores the media file in the media file storage and stores a unique identifier of the media file the due date and time and the content type in the market data storage .

According to an example illustrated by the customer interface receives media file information from the user interface. This media file information includes a media file and media file information indicating a domain of the subject matter of the content included in the media file or a project to be associated with the media file from which the domain may be derived. Responsive to receipt of this media file information the customer interface stores the media files in the media file storage and stores a unique identifier of the media file and other media file information in the market data storage .

According to another example illustrated by the customer interface provides media file information to the user interface. This media file information includes unique identifiers of one or more media files previously received from the customer the due dates and times associated with the received media files and the project information associated with the received media files. In this example the customer interface receives modifications to the provided media file information made by the customer via the user interface. Responsive to receiving the modifications the customer interface stores the modifications in the market data storage .

According to another example illustrated by the customer interface provides media file information to the user interface. This media file information includes one or more unique identifiers of one or more media files previously received from the customer and other attributes of these files including for example the due dates and times content types prices difficulties and statuses or states of jobs associated with the previously received media files. As discussed above with reference to examples of job states include New ASR In Progress Available Assigned Editing In Progress and Complete. In some embodiments the customer interface serves media file information as one web page while in other embodiments the customer interface serves this media file information as multiple web pages. It is to be appreciated that different due dates and times and content type may be associated with different prices to the customer. Customer prices may also be impacted by other factors that impact the underlying transcription cost including how objectively difficult the media file transcription is to edit as described above.

In another example the customer interface serves media file information that includes final transcription information to the user interface rendered by the client computer . This final transcription information includes a final synchronized or non synchronized transcription of the content included in a media file. The synchronized transcription is comprised of a textual representation of the content of the media file where each textual token has associated with it indicia of the location in the media file to which it applies. The textual tokens may include words numerics punctuation speaker identification formatting directives non verbal indicators such as BACKGROUND NOISE MUSIC LAUGHTER PAUSING and other markings that may be useful in describing the media file content. The empty string may also be used as a textual token in which case the location indicia serves to keep the transcription synchronized with the media file content in the absence of useful textual information. In the case of the draft transcription from the ASR device these empty string tokens may be used if the ASR process was confident that some transcription worthy event has occurred at that location but is unsure of the particular identity of that event. In this case having the location indicia associated with the event facilitates synchronized correction by the editor.

In other embodiments the customer interface is configured to receive a request to edit final transcription information from the user interface and in response to the request to provide an editing platform such as the editing screen described below with reference to the editor interface to the user interface. In this example the editing platform enables customers to edit the final transcription information. Also in this example user interface includes elements that enable the customer to initiate an upload of the edited final transcription information to the customer interface . The customer interface in turn receives the edited final transcription information stores the final transcription information in the media file storage and stores an association between the edited final transcription information and the media file with content that was transcribed in the market data storage .

Although the examples described above focus on a web based implementation of the customer interface embodiments are not limited to a web based design. Other technologies such as technologies employing a specialized non browser based client may be used to implement the user interface without departing from the scope of the aspects and embodiments disclosed herein. For instance according to one embodiment the customer interface is a simple locally executed upload client that allows the customer to do nothing more than upload media files to the server via FTP or some other protocol. In other embodiments the customer interface is configured to perform a variety of processes in response to exchanging information via the user interface. For instance in one embodiment after receiving one or more media files via the user interface the customer interface provides the market engine with an identifier of newly stored unprocessed media files.

In some embodiments the customer interface is configured to provide a system interface to the client computer via the network . For instance in one embodiment the customer interface implements an HTTP API through which the client computer exchanges transcription request information with the customer interface . The transcription request information may include request type information e.g. an identifier indicating that the transcription request information includes an automatic synchronization request project information e.g. an identifier of a project customer information e.g. an identifier of a customer media file information e.g. an identifier of a media file or derived content boolean values used to synchronize reference content with derived content values of one or more thresholds used to synchronize reference content with derived content identifiers of one or more requested transcription products a delivery point identifier and responses to any requests. In some embodiments the delivery point identifier may include URI s URL s an FTP folder identifier along with authentication credentials or the like. In response to receiving the transcription request information the customer interface may store the transcription request information in the market data storage in association with the identifier of the media file project or customer for which the requested transcription products are to be generated. In addition responsive to receiving the transcription request information the customer interface may store the media file identified in the transcription request information in the media file storage . Transcription request information is described further below with reference to .

In some embodiments the customer interface is configured to perform a variety of processes in response to exchanging information via the system interface with the client computer . For instance in one embodiment after receiving transcription request information specifying a request for partial delivery of one or more transcription products the customer interface provides the request for delivery or partial delivery to the market engine .

In some embodiments the administrator interface is configured to provide a user interface to the administrator via the network and the client computer . For instance in one embodiment the administrator interface is configured to serve a browser based user interface to the administrator that is rendered by a web browser running on the client computer . In this embodiment the administrator interface exchanges market information with the administrator via this user interface. Market information may include any information used to maintain the transcription job market and stored within the market data storage . Specific examples of market information include a media file information job information customer information editor information administrator information and transcription request information. Market information is described further below with reference to . Using the administrator interface the administrator acts as a transcription manager who regulates the transcription job market as a whole to promote its efficient allocation of resources.

In these embodiments the administrator interface is also configured to receive a request from the user interface to provide a preview of a media file and in response to the request serve a preview screen for the requested media file to the user interface. This preview screen provides the content of the media file and the draft transcription associated with the media file. More particular in some embodiments the preview screen is configured to provide the media file content in the form of for example a streamed version of the original file as well as the draft transcription information for the media file which includes time codes or frame codes. This information enables the preview screen to display the draft transcription in synchronization with the media file content. A preview may consist of all or some of this information.

According to an example illustrated by the administrator interface provides media file information to the user interface. This media file information includes one or more unique identifiers of one or more media files previously received from the customer the content types associated with the received media files and the difficulties associated with the received media files. In this example responsive to receipt of an indication that the administrator wishes to preview a media file the administrator interface provides a preview of the media file and the draft transcription information associated with the media file. Further in this example the administrator interface receives modifications to the provided media file information made by the administrator via the user interface. Responsive to receiving the modifications the administrator interface stores the modifications in the market data storage .

In other embodiments the administrator interface is also configured to receive a request from the user interface to provide an administrator view of all jobs available on the market and in response to the request serve an administrator screen to the user interface. This administrator view is configured to display the same information available to editors viewing the job market difficulty pay rate due date and time domain etc. and also displays additional information to assist the administrator. For example the administrator view may display the number of editors with permission to edit each available media file the amount of time each job has been on the market the number of previews of the media file and other data concerning the market status of the media file. In this way the administrator view displays information that enables administrators to ensure that the media file is accepted as an editing job.

The administrator interface is also configured receive a request from the user interface to modify information displayed by administrator view and in response to the request store the modified information. Thus the administrator view may increase the pay rate may manually enable a larger number or smaller number of editors access to the file or may cut the file into shorter segments thus producing several editing jobs for the same media file. The administrator view may also bundle jobs together to ensure that all editors have access to a reasonable cross section of work. For example the administrator view may group a selection of jobs with variable difficulty together so that a single editor would need to accept all of these jobs instead of just picking low difficulty jobs for themselves. The administrator view may also throttle the supply of low difficulty jobs in order to create a more competitive environment or to induce editors to work on difficult jobs. The administrator view may also record as accepted a claim offer that is higher than the pay rate for a job.

In other embodiments the administrator interface is also configured to receive a request from the user interface to provide a meta rules view and in response to the request serve a meta rules screen to the user interface. Meta rules globally modify the behavior of the market by affecting how all or some of the available jobs will appear on the market. In some embodiments the administrator interface is configured receive a request from the user interface to add to or modify meta rules displayed by meta rules view and in response to the request store the newly introduced meta rule information.

In other embodiments the administrator interface is also configured to receive a request from the user interface to provide a market view of jobs available on the market and in response to the request serve a market screen to the user interface. The market screen is configured to provide summarized information about jobs organized according to one or more job or associated media file attributes. For instance one example of the market screen displays all of the jobs assigned to one or more editors. In another example the market screen displays all jobs organized by due date and time in the form of a calendar. In yet another example the market screen displays all jobs belonging to a particular customer.

Although the examples described above focus on a web based implementation of the administrator interface embodiments are not limited to a web based design. Other technologies such as technologies employing a specialized non browser based client may be used without departing from the scope of the aspects and embodiments disclosed herein.

In some embodiments the editor interface is configured to provide a user interface to the editor via the network and the client computer . For instance in one embodiment the editor interface is configured to serve a browser based user interface to the editor that is rendered by a web browser running on the client computer . In this embodiment the editor interface exchanges media file information editor information and job information with the editor via this user interface. Editor information may include information associated with an editor profile or the history of an editor within the transcription job market. Job information may include information associated with transcription jobs that are available or that have been completed via the transcription job market. Specific examples of editor information include a unique identifier of the editor domains of subject matter in which the editor is qualified to work and identifiers of currently claimed jobs. Specific examples of job information include a unique identifier of the job a deadline for the job and a pay rate for the job. Media file information editor information and job information are described further below with reference to .

In these embodiments the editor interface is configured to provide job information only for jobs that the editor is permitted to work. In one example the editor interface determines that an editor is permitted to edit a draft transcription based on a complex of factors. If a media file associated with the draft transcription has a specific content type then in some examples the editor interface will only provide job information associated with the media file to editors qualified to edit that specific content type. In other examples the editor interface may provide job information associated with more difficult files to more experienced editors. In still other examples the editor interface provides job information for jobs associated with specific customers to particular subset of editors. This approach may be advantageous for example if there are confidentiality concerns and only that subset of editors have signed non disclosure agreements. Thus examples of the editor interface do not provide job information to the editor for jobs claimed by another editor or for jobs that the editor does not have permission to claim.

In other embodiments the editor interface is configured to receive a request from the user interface to provide a preview of a media file and in response to the request serve a preview screen for the requested media file to the user interface. This preview screen provides the content of the media file and the draft transcription information associated with the media file. Editors may be given access to the preview screen for a media file before they choose to accept the editing job at the given pay rate. The preview screen includes the media file content in the form of for example a streamed version of the original media file as well as the draft transcription information for the media file which includes time codes or frame codes. This information enables the preview screen to display and draft transcription in synchronization with playback of the media file content. A preview may consist of all or some of this content. The editors may access the preview screen content and thereby assess for themselves the difficulty of the editing job and then make a judgment as to whether they are willing to accept the job at the current pay rate. This enables editors to select content that they are interested in and to reveal their expertise or preferences for subject matter that would otherwise by unknown to administrators. In aggregate this will tend to improve transcription quality since the jobs will be better matched to editors than if randomly assigned.

According to an example illustrated by the editor interface provides job information to the user interface. This job information includes one or more unique identifiers of one or more jobs available for the editor identifiers of the media files associated with the jobs pay rates of the jobs domain information and durations of the content of the media file associated with the job. In this example responsive to receipt of an indication that the editor wishes to preview a media file the editor interface provides a preview of the media file and the draft transcription information associated with the media file. If the editor wishes to claim the job the editor indicates this intent by interacting with the user interface and the user interface transmits a request to claim the job for the editor to the editor interface . Next in this example the editor interface receives the request to claim an available job from the user interface and responsive to receiving this request the editor interface records the job as claimed in the market data storage .

In other embodiments the editor interface is configured to receive a request from the user interface to edit a draft transcription and in response to the request serve an editing screen to the user interface. The editing screen is configured to provide a variety of tools for editing and correcting the draft transcription. For instance the editing screen provides access to the original file or a converted version of the original file along with the draft transcription information by referencing information contained in both the market data storage and the media file storage .

In one embodiment once an editor begins working on a job the editing screen provides the complete media file content and synchronized draft transcription information for editing using client computer based editing software. The editor interface also transitions the job into a working state by recording the working state for the job in the market data storage .

The editing process consists of playing the media file content and following along with the draft transcription modifying the draft transcription information as necessary to ensure that the saved draft transcription reflects the content of the media file. According to some embodiments as the editor modifies the draft transcription information the editing screen communicates with the editor interface to indicate progress through the editing job. The editing screen tracks the time point into the file that the editor is playing as well as the parts of the draft transcription information that has been modified in order to estimate progress. The progress is communicated back to the editor interface and the editor interface then stores this progress in the market data storage in association with the editing job. In the course of editing a job the editor may come across words or phrases that are difficult to understand. The editing screen allows editors to flag these regions so that they may be reviewed and possibly corrected by an administrator. A flag may indicate complete unintelligibility or may include a guess as to the correct word but with an indicator that it is a guess. For each job the prevalence of corrected flags in the edited transcript is stored in the market data storage and the market engine may use stored flags as an indicator of editor proficiency to aid with future job assignment. In some embodiments the editing screen allows editors to store auxiliary deliverables such as search keywords descriptive summarization and other metadata derived from the transcription information during editing jobs and QA jobs.

In other embodiments the editor interface is configured to receive a request from the user interface to save an edited draft transcription and in response to the request save the edited draft transcription to the media file storage and update progress information for the job in the market data storage . In some embodiments saving the progress information triggers estimation of a new completion date and time which is then evaluated relative to the due date and time as discussed with reference to below.

According to an example illustrated by the editor interface provides job information to the user interface. This job information includes one or more unique identifiers of one or more jobs available for the editor identifiers of the media files associated with the jobs pay rates of the jobs durations of the content of the media file associated with the job and progress the editor has made editing the draft transcription associated with the job. In this example responsive to receipt of an indication that the editor wishes to edit the draft transcription the editor interface serves an editing screen to the user interface.

In some embodiments the editing screen is configured to receive an indication that the editor has completed a job. In these embodiments the editing screen is also configured to in response to receiving the indication store the edited draft transcription information as final transcription information in the media file storage and update the market data storage to include an association between the media file and the final transcription information.

The examples described above focus on a web based implementation of the editor interface . However embodiments are not limited to a web based design. Other technologies such as technologies employing a specialized non browser based client may be used without departing from the scope of the aspects and embodiments disclosed herein.

Each of the interfaces disclosed herein may both restrict input to a predefined set of values and validate any information entered prior to using the information or providing the information to other components. Additionally each of the interfaces disclosed herein may validate the identity of an external entity prior to or during interaction with the external entity. These functions may prevent the introduction of erroneous data into the transcription system or unauthorized access to the transcription system .

In the embodiment of the customer table stores information descriptive of the customers who employ the transcription job market to have their media files transcribed. In at least one embodiment each row of the customer table stores information for a customer and includes an customer id field and a customer name field. The customer id field stores an identifier of the customer that is unique within the transcription job market. The customer name field stores information that represents the customer s name within the transcription job market. The customer id is used as a key by a variety of functions disclosed herein to identify information belonging to a particular customer.

The media file table stores information descriptive of the media files e.g. reference files and derived content files that have been uploaded to the transcription job market for transcription. In at least one embodiment each row of the media file table stores information for one media file and includes the following fields media file id customer id state duration due date and time difficulty domain ASR cost proposed pay rate ASR transcript location edited transcript location QA transcript location advertisement transcript product1 transcript product2 etc. . . . . The media file id field stores a unique identifier of the media. The customer id field stores a unique identifier of the customer who provided the media file. The state field stores information that represents the state of the media file. The duration field stores information that represents the duration of the content of the media file. The due date and time field stores information that represents the date and time by which the customer requires a transcription be complete. The difficulty field stores information that represents an assessed difficulty of completing a transcription of the media file. The domain field stores information that identifies a subject matter domain to which the media file belongs. The ASR cost field stores information that represents a predicted cost of transcribing the media file as assessed using draft transcription information. The proposed pay rate field stores information that represents a pay rate proposed using draft transcription information. The ASR transcript location field stores an identifier of a location of draft transcript information associated with the media file. The edited transcript location field stores an identifier of a location of edited draft transcript information associated with the media file. The QA transcript location field stores an identifier of a location of QA transcription information associated with the media file. The advertisement field stores one or more identifiers of one or more locations of one or more advertisements associated with the media file. The transcript product1 transcript product2 etc. . . . store identifiers of locations of other transcription products or other derived content associated with the media file e.g. products that may be uploaded via the customer interface or generated by the transcription system . The media file id is used as a key by a variety of functions disclosed herein to identify information associated with a particular media file.

The job table stores information descriptive of the jobs to be completed within the transcription job market. In at least one embodiment each row of the job table stores information for one job and includes the following fields job id media file id deadline state job type pay rate editor id progress flags XRT corrections hide ASR distance. The job id field stores an identifier of the job that is unique within the transcription job market. The media file id field stores the unique identifier of the media file to be transcribed by an editor working the job. The deadline field stores information that represents the date and time by which the job must be complete. The state field store the current state or status of the job. Examples values for the state field include New ASR In Progress Available Assigned Editing In Progress and Complete. The job type field stores information that represents a type of work that must be performed to complete the job for example editing QA etc. The pay rate field stores information that represents a pay rate for completing the job. The editor id field stores the unique identifier of the editor who has claimed this job. The progress field stores information that represents an amount of work completed for the job. The flags field stores information that represents the number and type of flags assigned to the job during editing as described above. The XRT field stores information that represents the times real time statistic applicable to the job. The corrections field stores information that represents corrections made to the draft transcription as part of the job. The hide field stores information that determines whether components such as the market engine and the editor interface should filter out the job from job views. The ASR distance field stores information that represents the number of changes from the draft transcription made as part of the job. The job id is used as a key by a variety of functions disclosed herein to identify information associated with a particular job.

The editors table stores information descriptive of the editors who prepare transcriptions within the transcription job market. In at least one embodiment each row of the editors table stores information for one editor and includes the following fields editor id roles reward points domains and special capabilities. The editor id field stores an identifier of the editor that is unique within the transcription job market. The roles field stores information representative of roles that the editor is able to assume with the transcription job market for example editor QA etc. Examples of these roles include editor and QA editor. The reward points field stores information that represent the number of reward points accumulated by the editor. The domains field stores information that represents subject matter domains of media files that the editor has permission to edit. The special capabilities field stores information that represents specialized skills that the editor possesses. The editor id is used as a key by a variety of functions disclosed herein to identify information belonging to a particular editor.

In the embodiment of the project table stores information descriptive of projects that the transcription job market is being utilized to complete. In at least one embodiment each row of the project table stores information for a project and includes an project id field a project name field a customer id field and a domain field. The project id field stores information that identifies a group of media files that belong to a project. The project name field stores information that represents the project s name within the transcription job market. The customer id field indicates the customer to whom the project belongs. The domain field stores information that identifies a subject matter domain of media files included in the project. The project id is used as a key by a variety of functions disclosed herein to identify information grouped into a particular project.

In the embodiment of the cost model table stores information descriptive of one or more cost models used to predict the cost of editing the content included media files. In at least one embodiment each row of the cost model table stores information representative of a cost model and includes an editor id field a customer id field a project id field and a Cost Model Location field. The editor id field stores the unique identifier of an editor to whom the cost model applies. The customer id field stores the unique identifier of a customer to whom the cost model applies. The project id field stores the unique identifier of a project to which the cost model applies. The Cost Model Location field stores information identifying a location of the cost model. The editor id customer id or project id any of which may be null or the wildcard indicator may be used as a key by a variety of functions disclosed herein to identify a location of a cost model applicable to any of these entities.

The transcription request table stores information descriptive of requests for delivery of transcription products. In at least one embodiment each row of the transcription request table stores information for one transcription request and includes the following fields media file id project id customer id delivery point transcription product and quality thresholds. The media file id field stores a unique identifier of a media file that is the basis for the requested transcription products. The customer id field stores a unique identifier of the customer who provided the transcription request. The delivery point field stores an identifier of a location to which the requested transcription products may be transmitted. The transcription product field stores identifiers of the requested transcription products which include derived content such as transcriptions captions caption positioning information and the like. The quality thresholds field stores values of one or more quality thresholds associated with one or more potential delivery types. The delivery types may be defined by points in time transcription status or derived content status.

Various embodiments implement the components illustrated in using a variety of specialized functions. For instance according to some embodiments the customer interface uses a File Upload function and a File Update function. The File Upload function uploads a file stored on a customer s computer to the server computer and accepts parameters including customer id project id filename and optionally domain. The customer id parameter identifies the customer s unique customer id. The project id identifies the project to which the media file belongs. The filename parameter specifies the name of the media file or derived content file to be uploaded by the customer interface . The domain parameter specifies the subject matter domain to which the media file belongs. In at least one embodiment if the domain parameter is not specified the market engine determines the value of the domain parameter from the value of the domain field of a record stored within the project table that has a project id field that is equal to the project id parameter.

In other embodiments the File Update function updates an attribute of a media file record and accepts parameters including media file id attribute and value. The media file id parameter identifies the media file record with attributes that will be modified as a result of execution of the File Update function. The attribute parameter identifies an attribute to be modified. In at least one embodiment this attribute may be the domain difficulty or state of the media file as stored in the media file table . The value parameter specifies the value to which the attribute is to be set as a result of executing the File Update function.

In other embodiments the system interface uses a File Send to ASR function and a File Create Draft function. The File Send to ASR function provides a media file to the ASR device and causes the ASR device to perform automatic speech recognition on the content included in the media file. The File Send to ASR function accepts parameters including media file id. The media file id parameter identifies the media file to be processed by the ASR device .

In other embodiments the File Create Draft function creates draft transcription information for a media file and accepts parameters including media file id and ASR output. The media file id parameter identifies the media file for which the draft transcription information will be created by execution of the File Create Draft function. The ASR output parameter specifies the location of the ASR output generated by the ASR device during its processing of the media file.

In other embodiments the market engine uses the following functions File Assess Difficulty File Propose Pay Rate File Compute Actual Difficulty Job Create Job Split Job Adjust Parameter and Job Revoke. The File Assess Difficulty function determines an estimated difficulty to transcribe the content included in a media file and accepts parameters including a media file id. The media file id parameter identifies the media file including the content for which difficulty is being accessed.

In other embodiments the File Propose Pay Rate function determines an initial pay rate for transcribing the content included in a media file and accepts parameters including media file id and draft transcription information. The media file id parameter identifies the media file for which the proposed pay rate that will be determined as a result of execution of the File Propose Pay Rate function. The draft transcription information parameter specifies the location of the draft transcription information associated with the media file. The File Propose Pay Rate function determines the initial pay rate using the information included in the draft transcription information.

In other embodiments the File Compute Actual Difficulty function determines an actual difficulty of transcribing the content included in a media file and accepts parameters including media file id from which it determines the location of the draft transciption information and final transcription information from the media file table . The media file id parameter identifies the media file for which the actual difficulty will be determined as a result of execution of the File Compute Actual Difficulty function. The File Compute Actual Difficulty function determines the actual difficulty by comparing the content of the draft transcription included in the draft transcription information to the content of the final transcription included in the final transcription information. In one embodiment File Compute Actual Difficulty function uses the number of corrections performed on the transcription to compute a standard distance metric such as the Levenshtein distance. The File Compute Actual Difficulty function stores this measurement in the ASR distance field of the job table .

In other embodiments the Job Create function creates a job record and stores the job record in the job table . The Job Create function and accepts parameters including media file id job type pay rate and optionally deadline. The media file id parameter identifies the media file for which the job is being created. The job type parameter specifies the type of editing work to be performed by an editor claiming the job. The pay rate parameter specifies the amount of pay an editor completing the job will earn. The deadline parameter specifies the due date and time for completing the job.

In other embodiments the Job Split function segments a job into multiple jobs and accepts parameters including job id and a list of timestamps. The job id parameter identifies the job to be segmented into multiple jobs. The list of timestamps indicates the location in the media file at which to segment the media file to create new jobs.

In other embodiments the Job Adjust Attribute function modifies the value of an attribute stored in a job record and accepts parameters including job id attribute and value. The job id parameter identifies the job record with an attribute to be modified. The attribute parameter identifies an attribute to be modified. In at least one embodiment this attribute may be the pay rate deadline XRT or ASR distance of the job record as stored in the job table . The value parameter specifies the value to which the attribute is to be set as a result of executing the Job Adjust Attribute function.

In other embodiments the Job Revoke function removes a job from an editor and makes the job available for other editors to claim according to the current market rules. The Job Revoke function accepts parameters including job id. The job id parameter identifies the job to be revoked.

In other embodiments the synchronization engine uses the Derive Product function and the Deliver Product function. The Derive Product function synchronizes derived content with reference content and derives one or more transcription products from the synchronized derived content. The Derive Product function accepts parameters including transcription product transcription information and derived content. The transcription product parameter identifies a transcription product to be derived. For example the transcription product parameter may specify a clip with embedded captions captions for the clip a binary encoded caption format e.g. such as SCC format for the clip and the like. The derived content parameter specifies the location of derived content targeted for synchronization with the reference content pointed to be the transcription information parameter. For example the derived content parameter may specify a location of a clip or clip reel. The transcription information parameter specifies the location of the transcription information targeted for synchronization with the derived content. For example the transcription information parameter may specify a location of draft ASR transcription information edited transcription information or QA transcription information. The transcription product may be stored in the media file storage at a location specified by a product id.

In other embodiments the Deliver Product function transmits one or more transcription products to a delivery point via the customer interface and accepts parameters including a product id and delivery point. The product id parameter identifies the transcription product to be delivered to the location identified by the delivery point parameter.

In other embodiments the editor interface uses the following functions Job Store Output Job Update Progress Job List Available Job Preview Job Claim and Job Begin. The Job Store Output function stores the current version of the edited draft transcription and accepts parameters including a job id. The job id parameter identifies the job for which the current version of the edited draft transcription is being stored.

In other embodiments the Job Update Progress function updates the progress attribute included in a job record and saves the current state of the transcription. The Job Update Progress function accepts parameters including job id transcription data and progress. The job id parameter identifies the job record for which the progress attribute will be updated to the value specified by the progress parameter. The transcription data is saved to the location specified in the media file record associated with the job id.

In other embodiments the Job List Available function returns a list of jobs available to an editor and accepts parameters including editor id and optionally job type domain difficulty deadline and proposed pay rate. The editor id parameter identifies the editor for which the list of available jobs is being created. The job type parameter specifies a job type to which each job in the list of available jobs must belong. The domain parameter specifies a domain to which each job in the list of available jobs must belong. The difficulty parameter specifies a difficulty that the media file associated with the job in the list must have. The deadline parameter specifies a deadline that each job in the list of available jobs must have. The proposed pay rate parameter specifies a proposed pay rate that the media file associated with the job must have. It is to be appreciated that meta rules may also impact the list of jobs returned by the Job List Available function.

In other embodiments the Job Preview function causes a preview screen to be provided to a user interface and accepts parameters including editor id and job id. The editor id parameter identifies the editor for which the preview is being provided. The job id parameter specifies the job that is being previewed.

In other embodiments the Job Claim function records a job as claimed and accepts parameters including editor id and job id. The editor id parameter identifies the editor for which the job is being claimed. The job id parameter specifies the job that is being claimed.

In other embodiments the Job Begin function causes an editing screen to be provided to a user interface and accepts parameters including job id. The job id parameter specifies the job associated with the draft transcription to be edited.

Embodiments of the transcription system are not limited to the particular configuration illustrated in . Various examples utilize a variety of hardware components software components and combinations of hardware and software components configured to perform the processes and functions described herein. In some examples the transcription system is implemented using a distributed computer system such as the distributed computer system described further below with regard to .

As discussed above with regard to various aspects and functions described herein may be implemented as specialized hardware or software components executing in one or more computer systems. There are many examples of computer systems that are currently in use. These examples include among others network appliances personal computers workstations mainframes networked clients servers media servers application servers database servers and web servers. Other examples of computer systems may include mobile computing devices such as cellular phones and personal digital assistants and network equipment such as load balancers routers and switches. Further aspects may be located on a single computer system or may be distributed among a plurality of computer systems connected to one or more communications networks.

For example various aspects and functions may be distributed among one or more computer systems configured to provide a service to one or more client computers or to perform an overall task as part of a distributed system. Additionally aspects may be performed on a client server or multi tier system that includes components distributed among one or more server systems that perform various functions. Consequently examples are not limited to executing on any particular system or group of systems. Further aspects and functions may be implemented in software hardware or firmware or any combination thereof. Thus aspects and functions may be implemented within methods acts systems system elements and components using a variety of hardware and software configurations and examples are not limited to any particular distributed architecture network or communication protocol.

Referring to there is illustrated a block diagram of a distributed computer system in which various aspects and functions are practiced. As shown the distributed computer system includes one more computer systems that exchange information. More specifically the distributed computer system includes computer systems and . As shown the computer systems and are interconnected by and may exchange data through a communication network . The network may include any communication network through which computer systems may exchange data. To exchange data using the network the computer systems and and the network may use various methods protocols and standards including among others Fibre Channel Token Ring Ethernet Wireless Ethernet Bluetooth IP IPV6 TCP IP UDP DTN HTTP FTP SNMP SMS MMS SS7 JSON SOAP CORBA REST and Web Services. To ensure data transfer is secure the computer systems and may transmit data via the network using a variety of security measures including for example TLS SSL or VPN. While the distributed computer system illustrates three networked computer systems the distributed computer system is not so limited and may include any number of computer systems and computing devices networked using any medium and communication protocol.

As illustrated in the computer system includes a processor a memory a bus an interface and data storage . To implement at least some of the aspects functions and processes disclosed herein the processor performs a series of instructions that result in manipulated data. The processor may be any type of processor multiprocessor or controller. Some exemplary processors include commercially available processors such as an Intel Xeon Itanium Core Celeron or Pentium processor an AMD Opteron processor a Sun UltraSPARC or IBM Power5 processor and an IBM mainframe chip. The processor is connected to other system components including one or more memory devices by the bus .

The memory stores programs and data during operation of the computer system . Thus the memory may be a relatively high performance volatile random access memory such as a dynamic random access memory DRAM or static memory SRAM . However the memory may include any device for storing data such as a disk drive or other non volatile storage device. Various examples may organize the memory into particularized and in some cases unique structures to perform the functions disclosed herein. These data structures may be sized and organized to store values for particular data and types of data.

Components of the computer system are coupled by an interconnection element such as the bus . The bus may include one or more physical busses for example busses between components that are integrated within a same machine but may include any communication coupling between system elements including specialized or standard computing bus technologies such as IDE SCSI PCI and InfiniBand. The bus enables communications such as data and instructions to be exchanged between system components of the computer system .

The computer system also includes one or more interface devices such as input devices output devices and combination input output devices. Interface devices may receive input or provide output. More particularly output devices may render information for external presentation. Input devices may accept information from external sources. Examples of interface devices include keyboards mouse devices trackballs microphones touch screens printing devices display screens speakers network interface cards etc. Interface devices allow the computer system to exchange information and to communicate with external entities such as users and other systems.

The data storage includes a computer readable and writeable nonvolatile or non transitory data storage medium in which instructions are stored that define a program or other object that is executed by the processor . The data storage also may include information that is recorded on or in the medium and that is processed by the processor during execution of the program. More specifically the information may be stored in one or more data structures specifically configured to conserve storage space or increase data exchange performance. The instructions may be persistently stored as encoded signals and the instructions may cause the processor to perform any of the functions described herein. The medium may for example be optical disk magnetic disk or flash memory among others. In operation the processor or some other controller causes data to be read from the nonvolatile recording medium into another memory such as the memory that allows for faster access to the information by the processor than does the storage medium included in the data storage . The memory may be located in the data storage or in the memory however the processor manipulates the data within the memory and then copies the data to the storage medium associated with the data storage after processing is completed. A variety of components may manage data movement between the storage medium and other memory elements and examples are not limited to particular data management components. Further examples are not limited to a particular memory system or data storage system.

Although the computer system is shown by way of example as one type of computer system upon which various aspects and functions may be practiced aspects and functions are not limited to being implemented on the computer system as shown in . Various aspects and functions may be practiced on one or more computers having a different architectures or components than that shown in . For instance the computer system may include specially programmed special purpose hardware such as an application specific integrated circuit ASIC tailored to perform a particular operation disclosed herein. While another example may perform the same function using a grid of several general purpose computing devices running MAC OS System X with Motorola PowerPC processors and several specialized computing devices running proprietary hardware and operating systems.

The computer system may be a computer system including an operating system that manages at least a portion of the hardware elements included in the computer system . In some examples a processor or controller such as the processor executes an operating system. Examples of a particular operating system that may be executed include a Windows based operating system such as Windows NT Windows 2000 Windows ME Windows XP Windows Vista or Windows 7 operating systems available from the Microsoft Corporation a MAC OS System X operating system available from Apple Computer one of many Linux based operating system distributions for example the Enterprise Linux operating system available from Red Hat Inc. a Solaris operating system available from Sun Microsystems or a UNIX operating systems available from various sources. Many other operating systems may be used and examples are not limited to any particular operating system.

The processor and operating system together define a computer platform for which application programs in high level programming languages are written. These component applications may be executable intermediate bytecode or interpreted code which communicates over a communication network for example the Internet using a communication protocol for example TCP IP. Similarly aspects may be implemented using an object oriented programming language such as .Net SmallTalk Java C Ada or C C Sharp . Other object oriented programming languages may also be used. Alternatively functional scripting or logical programming languages may be used. Additionally various aspects and functions may be implemented in a non programmed environment for example documents created in HTML XML or other format that when viewed in a window of a browser program can render aspects of a graphical user interface or perform other functions. Further various examples may be implemented as programmed or non programmed elements or any combination thereof. For example a web page may be implemented using HTML while a data object called from within the web page may be written in C . Thus the examples are not limited to a specific programming language and any suitable programming language could be used. Accordingly the functional components disclosed herein may include a wide variety of elements e.g. specialized hardware executable code data structures or objects that are configured to perform the functions described herein.

In some examples the components disclosed herein may read parameters that affect the functions performed by the components. These parameters may be physically stored in any form of suitable memory including volatile memory such as RAM or nonvolatile memory such as a magnetic hard drive . In addition the parameters may be logically stored in a propriety data structure such as a database or file defined by a user mode application or in a commonly shared data structure such as an application registry that is defined by an operating system . In addition some examples provide for both system and user interfaces that allow external entities to modify the parameters and thereby configure the behavior of the components.

Some embodiments perform processes that add jobs to a transcription job market using a transcription system such as the transcription system described above. One example of such a process is illustrated in . According to this example a process includes acts of receiving a media file creating an ASR transcription receiving job attributes setting job attributes automatically and posting a job.

In act the transcription system receives a media file including content to be transcribed. Next in act the transcription system uses an ASR device to produce an automatic transcription and associated information. After the automatic transcription is created the transcription system optionally delivers the automatic transcription to the customer and determines whether attributes for a job to be associated with the media file will be set manually in act . If so the transcription system receives the manually entered job attributes in act . Otherwise the transcription system executes a process that sets the job attributes automatically in act . This process is described further below with reference to . Once the job attributes have been set the transcription system posts the job in act and the process ends.

Other embodiments perform processes that allow and editor to perform a job listed on the transcription job market using a transcription system such as the transcription system described above. One example of such a process is illustrated in . According to this example a process includes acts of previewing a job claiming a job and completing a job.

In act the transcription system receives a request to provide a preview of a job. In response to this request the transcription system provides a preview of the job. The preview includes a preview of the content included in the media file associated with the job and draft transcription information for an ASR generated transcription that is associated with the media file. The preview may also include job attributes such as pay rate domain duration and difficulty.

Next in act the transcription system receives a request to claim the job. In response to this request the transcription system determines whether to accept the claim using the processes disclosed herein. If the claim is not accepted the process ends. If the claim is accepted the process executes act .

In the act the transcription system receives a request to perform the job. In response to this request the transcription system provides a user interface and tools that enable an editor to perform work. While the editor is performing the work the transcription system monitors progress and periodically saves work in process. Upon receipt of an indication that the editor has completed the job the transcription system saves the completed job and the process ends.

Other embodiments perform processes that monitor jobs to ensure the jobs are completed according to schedule using a transcription system such as the transcription system described above. One example of such a process is illustrated in . According to this example a process includes several acts that are described further below.

In act the transcription system determines whether a job should be assessed for attribute adjustment. The transcription system may make this determination based on a variety of factors including receipt of a request to assess the job from a component of the system or an entity external to the system e.g. a request for immediate delivery of the job s output or expiration of a predetermined period of time since the job was previously assessed i.e. a wait time. If the job should not be assessed the process ends. Otherwise the process executes act .

In the act the transcription system determines whether the job is assigned. If so the transcription system executes act . Otherwise the transcription system determines whether the job is in progress in act . If not the transcription system executes act . Otherwise the transcription system executes the act .

In the acts and the transcription system predicts the completion date and time of the job using one or more of the following factors the current date and time the amount of progress already complete for the job historical productivity of the editor in general or more specifically when editing media files having a characteristic in common with the media file associated with the job the number of jobs currently claimed by the editor the number of jobs the editor has in progress and the due dates and times of the jobs claimed by the editor.

In some embodiments the following equation is used to predict the completion date and time of the job 1 1 2 

In act the transcription system determines whether the predicted completion date and time of the job is before the due date and time of the job. If so the process ends. Otherwise the transcription system executes act .

In act the transcription system determines whether the predicted completion date and time of the job is before the due date and time of the job. If so the process ends. Otherwise the transcription system executes a process that sets the job attributes automatically in act . This process is described further below with reference to . Once the job attributes have been set the process ends.

In act the transcription system determines whether the predicted completion date and time of the job is before the due date and time of the job. If so the process ends. Otherwise the transcription system determines whether to revoke the job in act . If not the process ends. Otherwise the transcription system revokes the job in act .

In act the transcription system determines whether to split the job. If not the process ends. Otherwise the transcription system splits the job in act and the process ends.

As discussed above with reference to some embodiments perform processes that set attributes of jobs using a transcription system such as the transcription system described above. One example of such a process is illustrated in . According to this example a process includes several acts that are described further below.

In act the transcription system determines if the job is available. In not the process ends. Otherwise the transcription system determines a pay rate for the job in act . The transcription system may make this determination based on any of a variety of factors including due date and time difficulty domain and ASR cost.

In act the transcription system predicts a completion date and time for the job for each editor. The transcription system may make this determination based on any of a variety of factors including difficulty domain and historical XRT of previously completed similar jobs.

In act the transcription system determines whether the completion date and time is prior to the due date and time for the job. If so the process ends. Otherwise the transcription system determines whether the number of previews provided for the job transgresses a threshold in act . If not the transcription system executes act . Otherwise the transcription system executes act .

In act the transcription system modifies the pay rate based on the difference between the due date and time to the completion date and time and the process ends. For instance the transcription system may set the modified pay rate equal to the unmodified pay rate plus a date and time increment amount multiplied by the difference between the due date and time and the completion date and time.

In act the transcription system modifies the wait time for reassessment of the job and the process ends. For instance the transcription system may set the modified wait time equal to the unmodified wait time plus an increment amount.

Other embodiments perform processes that synchronize reference content to content derived from the reference content using a transcription system such as the transcription system described above. One example of such a process is illustrated in . According to this example a process includes several acts described further below.

In act a synchronization engine such as the synchronization engine described above with reference to locates reference content and derived content. In one example the located reference content is generated by the overall workflow for producing transcriptions implemented by the transcription system e.g. the process described above with reference to . According to this embodiment media files are uploaded to the system using for example 3Play Media s HTTP API via a customer interface e.g. the customer interface described above with reference to and increasingly accurate transcriptions of the audio portion of the media are produced by automated processing e.g. transcoding automatic speech recognition and natural language processing human editing and potentially depending on configuration human quality assurance review. The completed synchronized transcriptions are stored in a market data storage e.g. the market data storage described above with reference to in association with the original media file for example using a unique identifier such as a media file id as a key in the market data storage. Captions may be constructed according to the system described in the Intelligent Captions application. Also or in isolation the caption positions may be determined according to the system described in the Automated Caption Positioning application.

In some examples of the act the synchronization engine receives transcription request information including an automatic synchronization request that identifies a media file that does not have extant synchronization information. In this example the synchronization engine is configured to in response to receiving the automatic synchronization request transmit a request to a market engine component such as the market engine component to generate synchronization information in association with transcription information.

In another example the reference content located and identified in the act includes one or more media files synchronized transcriptions and caption files uploaded to imported into the system via the customer interface for instance using an API or FTP method. According to this example the reference content is stored in the market data storage as if the transcription and captions had been generated by the process . In this example the automated and manual transcription steps are not executed and the media file is stored in a completed state in the market data storage. In some examples the customer interface converts the format of the reference content from a first format e.g. SRT VTT SCC DFXP to a standard system format prior for performing additional processing. In some embodiments this standard system format encodes within a json file timecodes text and in some examples positions of captions for each caption frame. Captions imported to the transcription system according to this example may have positioning information included. Alternatively in response to a request to determine caption position information e.g. by a parameter supplied to the API the transcription system may determine caption position information according to the transcription system described in the Automated Caption Positioning application. Additionally or in isolation and in response to a request to do so e.g. by a parameter supplied to the API the transcription system may ignore caption frames uploaded with the remainder of the reference content and generate new caption frames. These new caption frames may be based on words and optionally timings in the uploaded transcription or captions and be generated in accordance with the Intelligent Captions application.

In another example the reference content located and identified in the act includes other synchronized data and metadata descriptive of the media file contents such as subtitles annotations semantic tagging advertising and the like that may be associated with the original media file. These data may be generated by normal operation of the transcription system for example as described in the Metadata Media Associator application or may be received separately via the customer interface. In this example these data are stored in the market data storage in association with the media file.

In one example the derived content located and identified in the act is a clip reel uploaded to the system using a method similar to the reference content. In this example the upload process e.g. an HTTP API invocation FTP upload or manual upload from a user interface generates transcription request information. This transcription request information includes a request to automatically synchronize the clip reel with an existing media file and transcription. The existing transcription is indicated by an identifier of an existing media file. For example where the clip reel is comprised of segments from an existing media file with an identifier of 275462 the API call may be 

Other parameters may be provided in the API call as discussed below. The transcription request information may be stored in the database using a unique request identifier as a key. The clip reel may be stored on a file server and then a file pointer to the clip real and the media file id may be stored in the market data storage in association with the request identifier. It is appreciated that the transcription request information described above may be transmitted prior to completion of the reference content e.g. a synchronized transcription . In this case the transcription request information including the synchronization service request would be stored in the market data storage but execution of act would be delayed until the reference transcription is available.

In act the synchronization engine generates a template for the derived content. In some examples a derived content template includes information sufficient to align the derived content with a reference template generated from the one or more media files from which the derived content was derived. The derived content template is robust to minor changes in the derived content such as audio and video filtering added signals or noise. In one example the synchronization engine acquires the derived content template entirely from the audio portion of the derived content. The synchronization engine may construct the derived content template using any number of common features such as total energy envelope band limited energy envelope discrete Fourier transform vector sequence mel frequency cepstral coefficient sequence modulation filter bank outputs etc. Any number of these features may be used with each sampled video frame represented by a concatenated feature vector. For instance in one example a single feature vector may be comprised of one coefficient representing the band limited energy at a given video frame concatenated with the Fourier transform coefficients at that video frame etc. Also in some examples the synchronization engine executes a feature space reduction technique e.g. linear discriminant analysis principal components analysis or vector quantization to reduce the total computational requirements of the synchronization process by reducing the size of the feature vectors.

The sampling period for the derived content template is typically 10 milliseconds msec but this varies between examples according to synchronization requirements. The synchronization engine may construct the derived content template by computing the feature vectors sequentially across the entire audio track corresponding to a video frame clip or clip reel at the desired sampling frequency. The derived content template e.g. sequence of feature vectors may be stored in the market data storage in association with the original media file. Each sample e.g. feature vector may be associated with a time code from the derived content according to the sampling frequency.

In another example the synchronization engine creates the derived content template from both the audio and video tracks of one or more media files. In this example a feature vector may include both audio features and video features. Examples of video features include intensity histograms edge locations jpeg data reduction or any other of numerous features that characterize the attributes of the video. In some examples the synchronization engine constructs a sequence of feature vectors across the entire portion of derived content with a typical sampling frequency of 10 msec and using windowing averaging to merge video frames across the sampling window prior to feature extraction. The derived content template in this example may include the concatenated audio and video feature vectors. In some examples the synchronization engine applies a dimensionality reduction transformation with associated time codes computed from the sampling frequency across the media file and stores the derived content template within the market data storage in association with the video frame clip or clip reel.

In act the synchronization engine generates a template for the reference content. In the act the synchronization engine applies the same feature extraction described above with reference to the derived content to one or more media files serving as the reference content. The reference template may be stored in the market data store in association with the transcription request information specifying synchronization service request. In one example the transcription information request may include an automatic synchronization service request to generate a reference template from a plurality of full length media files. This automatic synchronization request may specify the plurality of full length media files as for example a batch id or project id parameter provided via the API call. In response to receiving this automatic synchronization request the synchronization engine generates a reference template from the plurality of full length media file specified in the API call. In this example the reference template may be stored in association with the relevant e.g. batch level or project level media file grouping and with media file ids appended to the time indexing to facilitate the transcription or caption extraction described in act below.

In act the synchronization engine aligns the derived content template with the reference template. A variety of alignment procedures may be executed within the act . In broad overview these alignment procedures use similarity metrics e.g. correlation coefficients distance measures etc. to identify portions of the derived content template that match portions of the reference content and associate these matched portions into a map of alignment information. The alignment procedures disclosed below include a place and prune procedure a partition and place procedure and a seed and grow procedure. Each of these procedures is described in further detail below.

When executing the place and prune procedure the synchronization engine aligns the derived content template with the reference template by executing a process described by lines 1 117 of the Pseudo Code Listing below. In the Pseudo Code Listing annotations begin with the character. As illustrated in the Pseudo Code Listing the arguments to the ComputeDistance function invoked at lines 32 58 and 88 are a clip template a reference template and an index into the reference template at which the distance computation starts proceeding upward from that index . According to various embodiments the comparison in ComputeDistance may be done with any number of standard distance measures such as the cosine distance the Pearson correlation coefficient the Mahalonibis distance or the Euclidean distance. If the Pearson correlation coefficient were used the ComputeDistance function would subtract the return value from 1.0 so that the comparisons with this measure in the rest of the pseudo code would operate correctly.

In one example the index where method invocation at line 37 returns the first index i.e. leftmost index of the average distance array where the value matches best distance. In another example this method may be modified to return the last index matching the best distance value. In another example the synchronization engine maintains multiple alignment arrays each corresponding to a separate set of matches. Where multiple indices match the best distance value or are within a threshold parameter of this value the synchronization engine selects the alignment array from the multiple alignment arrays that minimizes the total sub clip distance across all sub clips.

Continuing this example the Prune Increment at line 5 specifies a step value for pruning the left and right video frames from the derived content template. This value may be increased to speed up the process at the cost of some precision in creating the alignment. The alignment array constructed by the process described in the Pseudo Code Listing encodes alignment information that describes the alignment between the derived content template and the reference template. That is each element of the alignment array corresponds to an index into the reference template.

In one example of the place and prune procedure the API call supports a Boolean parameter indicating that the derived content e.g. a clip reel while not contiguous is comprised of ordered clips so that all indices in the alignment array will be monotonically increasing. In this example the synchronization engine does not execute left pruning and assumes that all match regions start after a previous match region except for the first match region. In other words in this example the place and prune procedure executed by the synchronization engine does not include lines 52 to 80 from the Pseudo Code Listing includes the following line above line 13 alignment end index 0 and replaces line 25 with the following line reference start index MAX alignment end index 0 . 

In another example of the place and prune procedure the API call supports a Boolean option indicating that the derived content e.g. a clip reel is a contiguous subset of the reference media file. In this example the synchronization engine does execute left or right pruning and therefore does not iterate for left and right subset clips. In other words in this example the process executed by the synchronization engine includes a GOTO FILL IN ALIGNMENTS line after line 40.

In another example of the place and prune procedure the synchronization engine compares the best distance between at least a subset of the derived content template and the reference template to a value of a configurable maximum distance threshold to determine whether any valid match between the derived content template and the reference template exists. In this example where the best distance exceeds the value of the maximum distance threshold the synchronization engine determines that no valid match exists. Stated in view of the Pseudo Code List if the best distance at line 109 were not less than or equal to this maximum threshold value the acts in lines 110 115 would be skipped. In this way the synchronization engine accounts for additional footage being added to a clip reel for example an introductory announcement prior to a highlight reel. In this case the new footage would not have any corresponding transcription or metadata extracted in the act below. In some examples the transcription or metadata for this new footage may be generated by the transcription system using the process .

When executing the partition and place procedure the synchronization engine divides the derived content template produced in the act into template elements referred to as sub clip templates in the Pseudo Code Listing . The template elements may have constant length for example 100 video frames or 1 second in duration at a 10 msec video frame rate or variable length such as by cutting the audio track at silences or at across frequency coherent onsets and offsets . In some examples the length of the template elements is defined by the value of a configurable parameter. The value of this configurable parameter may be selected to balance execution speed with matching accuracy.

In some examples each template element is associated with a match array that includes array elements which indicate a likelihood of a match for the entire template element for a given index into the reference template. In one example the synchronization engine aligns template elements to the reference template by storing in a distinct match array for each template element the likelihoods of a match between that template element and the reference template at given location in the reference template.

In some examples the synchronization engine determines actual match locations by combining these match likelihoods across template elements while favoring consecutive placement of template elements. In one example the synchronization engine generates alignment information by shifting match arrays so that each sample index of any match array refers to a specific time offset into the reference template where a matching template element is likely to be located stacking these match arrays into a matrix and filtering across the matrix of stacked match arrays using a linear low pass filter median filter or any other similar technique. This way match arrays for consecutive template elements that have a high likelihood of matching consecutive portions of the reference template are included in a high filtered output while spurious matches will tend to get attenuated by neighboring template element s match arrays. This process is demonstrated in lines 301 339 of the Pseudo Code Listing below.

When executing the seed and grow procedure the synchronization engine expands one or more template elements referred to as seeds in this example in response to finding a match for the template element in the reference template. In one example the synchronization engine identifies a match for a given seed where the distance between a seed and a subset of the reference template is in a predetermined relationship with a configurable threshold value e.g. distance between seed and subset of reference templatea configurable threshold value etc. . This example takes advantage of the fact that matches will tend to be longer than the initial template elements and saves computing power by not exhaustively searching the reference template to match each template element. This process is demonstrated in lines 401 414 of the Pseudo Code Listing below.

In this example the find matches function line 407 slides the derived content template over the reference template as illustrated in lines 26 35 of the Pseudo Code Listing. Then for each matching template element the expand match forwards and backwards function gradually extends the boundaries of the template element forwards then backwards to form a match region. In one example the expand match forwards and backwards function extends the boundaries of the matching template element forwards by iteratively concatenating additional element templates after the location of the matching template element. In another example the expand match forwards and backwards function extends the boundaries of the matching template element backwards by iteratively concatenating additional element templates before to the location of the matching template element. The expand match forwards and backwards function extends the width of the match region and recomputes the score of each added template element until the score begins to decline. At this point the expand match forward and backwards function can refine the exact boundary of the expanded match by repeating the processes above from the last added template element for each of the forwards and backwards directions but now adding a segment of smaller length e.g. 1 video frame or more up to the number of video frames included in a template element . The find matches function and the expand match forwards and backwards function may use one of the same comparison metrics as used in the ComputeDistance function or find match likelihood function. Using the Seed and Grow procedure a 1 second segment that is part of a larger 30 second clip might be matched to its true location relative to the reference template and this expansion would be responsible for determining that the next 29 seconds yielded a similar match to this 1 second seed rather than beginning the search anew for each of the 29 1 second segments in this clip. At the end of these 30 second segments the synchronization engine generates a new seed and repeats the process until the entire derived content template has been processed. If no match is found for a given template element it is considered unmatched and the algorithm proceeds onto the next template element as a new seed.

At the end of this seed and grow procedure many of the match regions might overlap because the synchronization engine expands backwards as well as forwards. Therefore in at least one example the synchronization engine refines the match regions to correct for some amount of false positive matches in the expansion step. Thus the select best arrangement function detects any such overlaps and assigns them to a single match region. In one example to accomplish this objective the select best arrangement function determine the best possible score of any given arrangement of match regions. In another example the select best arrangement function selects the best scoring and longest match region first delete any overlaps between the selected match region and other match regions and repeats this process until no overlaps between match regions remain.

In another example the ComputeDistance function lines 32 58 88 the detect match likelihood function line 317 the find matches function line 407 and the expand match forwards and backwards function line 409 account for a non 1 1 correspondence between the derived content template indices and the reference template indices. In this example the synchronization engine executes a dynamic time warping process to align the derived content template or templates elements with variable length portions of the reference template while optimizing minimizing a distance metric such as the Levenshtein distance weighted by the feature vector distance e.g. the Euclidean distance . In this example the synchronization engine sets the total distance in the numerator of line 32 and 58 and 88 to this distance metric and sets the normalizer in the denominator of line 32 and 58 and 88 to the number of reference video frames represented in the numerator. The alignment reconstruction acts in lines 109 115 and 326 338 and the higher level matching methods at lines 407 and 409 may be modified to account for this scale factor. In this way the synchronization engine accounts for changes in speed between the reference and clip.

Elements of the alignment procedures described above may be combined to produce other procedures. For example the prune and place procedure may be modified such that the sub clip templates are initialized as in the partition and place procedure line 303 with the Prune Increment at line 5 being set to the length of each sub clip so that no pruning takes place. Alternatively the ComputeDistance function at lines 32 58 and 88 in the prune and place procedure may be patterned after the detect match likelihood function at line 317 of the partition and place procedure. In another example the detect match likelihood function may use a direct distance computation or any of the other distance metrics mentioned for the previous procedures etc.

In the act the synchronization engine generates synchronized derived content. This synchronized derived content may include any transcription product e.g. transcriptions captions etc. . In one example the synchronization engine constructs the synchronized derived content from the alignment information e.g. an alignment array generated in the act and the transcription information for the media file that was the source of the reference template. In examples configured to execute the seed and grow procedure within the act the synchronization engine generates synchronized derived data in the form of caption frames using a procedure illustrated in lines 499 507 in the Pseudo Code Listing.

In some examples the find caption frames function finds caption frames that are located within the time period defined by the begin and end time arguments. Further in these examples the find partial caption frames function finds caption frames that are partially included in the time period. In this example the find caption frames function and the find partial caption frames function may execute the same or different search strategies for finding the corresponding reference caption frame entries based on the begin and end milliseconds in the argument list. For example these functions may return an array of any entries whose time span overlaps the begin and end time arguments. Alternatively these functions may return only those entries that are completely within the time span. In another example these functions may take linguistic features into account in determining which entries are returned. For example the search in these functions may expand backward before the begin time argument to find the latest entry from the original caption frames that begins a sentence. Similarly the search may expand forward after the end time to find the earliest entry that ends a sentence. Similar approaches may be used to ensure that the clip caption frames segment encompasses at least a linguistic phrase or larger units such as a paragraph.

In one example the find partial caption frames function searches for caption frames that are partially overlapped by a match region but are not sufficient to be included in the output. Then add additional match data function adds any additional overlap from other regions. If the sum of overlapped regions transgresses a configurable threshold defined for inclusion of a caption frame the caption frame is included in the output. This functionality is useful for example in the case where a caption frame is cut into two or more parts due to a word or words being edited out of the derived content e.g. clip reel or where a feature abnormality e.g. added noise or extra sounds causes one or more small segments within the caption frame times to have not been successfully matched to the reference template.

In one example where the derived content includes metadata other than caption frames the find caption frames function and the find partial caption frames function may be replaced or supplemented by a find metadata elements function which operates similarly to the find caption frames function and the find partial caption frames function but extracts one or more relevant portions of other synchronized metadata such as subtitles semantic tagging advertising or other events that rely on the time alignment produced in the act .

In another example the synchronization engine may receive a request e.g. by a parameter supplied to the API call that all times in the region.parent times array be offset by a constant value prior to invoking the find caption frames function and the find partial caption frames function. Alternatively the request may indicate that this offset should vary as the times in the region.parent time array increase. This functionality is useful when the transcription or captions for the reference media file are generated outside of the transcription system. Often such externally produced captions or transcriptions will have a time offset characteristic of manual captioning systems particularly when the manual captions were created live as the original television show was being broadcast.

In another example the synchronization engine may generate a synchronized transcription of the derived content using a process illustrated by lines 200 245 of the Pseudo Code Listing.

Note that the scale computed at line 226 will always be one except when the alignment procedure executes dynamic time warping. As such this scaling may be excluded from the implementation when dynamic time warping alignment strategies are not used.

In act the synchronization engine generates the confidence document described above and stores the document and the synchronized derived content in the market data storage. Where the synchronized derived content includes transcription information the synchronization engine may submit the transcription information to other components of the transcription system to generate captions and caption placements as described in the Intelligent Captions application and the Automated Caption Positioning application. Alternatively the automatic synchronization request may include a parameter requesting that the current caption frames be honored in which case the synchronization engine does not reframe the captions. After execution of the act the process ends.

Process in accord with the process generate synchronized derived content is available to customers for download.

Processes through each depict one particular sequence of acts in a particular example. The acts included in these processes may be performed by or using one or more computer systems specially configured as discussed herein. Some acts are optional and as such may be omitted in accord with one or more examples. Additionally the order of acts can be altered or other acts can be added without departing from the scope of the systems and methods discussed herein. Furthermore as discussed above in at least one example the acts are performed on a particular specially configured machine namely a transcription system configured according to the examples and embodiments disclosed herein.

Another example of a synchronization engine e.g. the synchronization engine executing a synchronization process e.g. the synchronization process will now be described with reference to . The illustration of includes a media file content derived from the media file a reference template a derived content template synchronization information alignment information synchronized derived content and a confidence document .

The derived content may be a clip or clip reel as described above. As shown in the media file includes media portions and . The derived content includes copies of the media portions and an additional media portion of content . The reference template includes feature vectors descriptive of the media file . These feature vectors include feature vector sets and which are descriptive of the media portions and . The derived content template includes copies of the feature vector sets and . In addition the derived content template includes feature vector set which includes feature vectors descriptive of the additional portion of content . The synchronization information includes time coded or frame coded transcription information and time coded or frame coded caption frames. The alignment information specifies a mapping between elements of the derived content and elements of the media file .

In this example the synchronization engine first executes the act to identify the location of the media file and the derived content . Next the synchronization engine executes the act to generate a derived content template from the derived content and executes the act to generate a reference template from the media file . Each of the derived content template and the reference template includes a set of feature vectors descriptive of the media it subsumes.

Next the synchronization engine executes the act to align the derived content template with the reference template and generate alignment information . The synchronization engine may be perform the alignment by executing the place and prune procedure the partition and place procedure or the seed and grow procedure.

Where the synchronization engine executes the place and prune procedure the synchronization first aligns the derived content template to the reference template such that the copy of the feature vector set within the derived content template is aligned with the feature vector set within the reference template . Next the synchronization engine prunes the copies of the feature vector sets and from the derived content template . After completing this pruning the synchronization engine aligns the remainder of the derived content template with the reference template such that the copy of the feature vector set within the derived content template is aligned with the feature vector set within the reference template . Next the synchronization engine prunes the copies of the feature vector sets and from the derived content template . After completing this pruning the synchronization engine aligns the remainder of the derived content template with the reference template such that the copy of the feature vector set within the derived content template is aligned with the feature vector set within the reference template . Next the synchronization engine prunes the copy of the feature vector set from the derived content template . After completing this pruning the synchronization engine attempts to align the remainder of the derived content template i.e. the feature vector set with the reference template but is unable to do so because the feature vector set is not located within the reference template. Finally with no additional template elements within the remainder of the derived content to align the synchronization engine terminates the place and prune procedure.

Where the synchronization engine executes the partition and place procedure the synchronization first partitions the derived content template into template elements with a width of 1 second. Next the synchronization engine iteratively attempts to align each template element with the reference template until an attempt to align has been made for all template elements. In this example the synchronization engine fails to align all template elements within the additional feature vector set because in each case a metric that indicates a likelihood of a match fails to exceed a predetermined threshold value.

Where the synchronization engine executes the seed and grow procedure the synchronization engine first partitions the derived content template into template elements with a width of 1 second. Next the synchronization engine attempts to align a first seed e.g. the first template element with the reference template . If successful the synchronization engine grows the first seed backwards and forwards until a metric that indicates the likelihood of a match indicates a decreased likelihood of proper alignment. Next the synchronization engine repeats the align and grow actions described above for the remaining template elements until attempts to align have been made for all template elements. After the synchronization engine has attempted to align all of the template elements it assigns any template element associated with to two or more seeds to a single seed. In this example the synchronization engine fails to align all template elements within the additional feature vector set because in each case a metric that indicates a likelihood of a match fails to exceed a predetermined threshold value.

Next the synchronization engine executes the act to generate synchronized derived content using the alignment synchronization information and the derived content . In this example the media portions and are respectively associated with sets of transcription and caption information from the synchronization information that are in turn respectively associated with media portions and . Finally the synchronization engine executes the act to generate the confidence document using the alignment information . Having thus described several aspects of at least one example it is to be appreciated that various alterations modifications and improvements will readily occur to those skilled in the art. For instance examples disclosed herein may also be used in other contexts. Such alterations modifications and improvements are intended to be part of this disclosure and are intended to be within the scope of the examples discussed herein. Accordingly the foregoing description and drawings are by way of example only.

