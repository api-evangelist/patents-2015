---

title: Generating training data for disambiguation
abstract: A method for generating training data for disambiguation of an entity comprising a word or word string related to a topic to be analyzed includes acquiring sent messages by a user, each including at least one entity in a set of entities; organizing the messages and acquiring sets, each containing messages sent by each user; identifying a set of messages including different entities, greater than or equal to a first threshold value, and identifying a user corresponding to the identified set as a hot user; receiving an instruction indicating an object entity to be disambiguated; determining a likelihood of co-occurrence of each keyword and the object entity in sets of messages sent by hot users; and determining training data for the object entity on the basis of the likelihood of co-occurrence of each keyword and the object entity in the sets of messages sent by the hot users.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09483462&OS=09483462&RS=09483462
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09483462
owner_city: Armonk
owner_country: US
publication_date: 20150807
---
This application claims priority to Japanese Patent Application No. 2014 166695 filed Aug. 19 2014 and all the benefits accruing therefrom under 35 U.S.C. 119 the contents of which in its entirety are herein incorporated by reference.

The present invention relates to a technique for automatically generating training data for disambiguation of a word or word string hereinafter referred to as entity related to a topic to be analyzed.

Analyzing users voices on major spots e.g. sightseeing spots of a city and on an event e.g. motor show is important for the local government and the event organizer in understanding reputations of and needs for the city and the event. To collect users voices for analysis the use of social media has been considered in recent years. A social media tool particularly microblogging has more immediacy than traditional blogging. Therefore what users feel on event sites and sightseeing spots is expected to be more directly reflected in social media messages.

Messages related to a topic e.g. city or event to be analyzed can be collected from social media sites by predefining a set of entities related to the topic and extracting messages including at least one entity contained in the set. However if any of the entities has ambiguity the messages collected by the method described above may include those unrelated to the topic. Therefore it is necessary to disambiguate the entity and eliminate messages unrelated to the topic.

Many of conventional semantic disambiguation algorithms have been based on supervised learning using a tagged corpus see e.g. A. Davis et al. Named Entity Disambiguation in Streaming Data. Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics Long Papers Volume 1. Association for Computational Linguistics 2012 . In the example described above the tagged corpus or training data is a set of messages in which each entity is assigned a binary label indicating whether the entity is related to the topic to be analyzed. However in social media where various topics are created every day it is not realistic to manually generate training data. It is thus necessary to develop a technique for automatically acquiring training data for disambiguation.

The publications D. Spina et al. Discovering Filter Keywords for Company Name Disambiguation in Twitter. Expert Systems with Applications 40.12 2013 4986 5003 and Z. Miklos et al. Entity based classification of twitter messages. International Journal of Computer Science Applications 9. EPFL ARTICLE 174746 2012 88 115 disclose techniques for automatically acquire such training data. Specifically the techniques disclosed in these publications use company websites and Wikipedia to acquire training data for disambiguation of ambiguous company names.

The publication of E. L. Murnane et al. RESLVE leveraging user interest to improve entity disambiguation on short text. Proceedings of the 22nd international conference on World Wide Web companion. International World Wide Web Conferences Steering Committee 2013 discloses a technique in which for users who write articles for Wikipedia an interest model is built to disambiguate entities included in messages sent via social media by the users.

Japanese Patent Application Publication No. 2003 22275 discloses a technique in which upon receipt of a user s search request including a search term and a user s selection of a field that matches a search purpose a document search is performed by referring to a field specific co occurrence term DB and adding one or more co occurrence terms.

Japanese Patent Application Publication No. 2014 002653 discloses a technique in which morphemes acquired within a predetermined period are extracted as co occurrence terms to identify as a co occurrence term a morpheme that occurs in the same document as a search keyword.

Japanese Patent Application Publication No. 2014 032536 discloses a technique that extracts a document including a default topic tag from a plurality of documents calculates a frequency of occurrence of a word in the extracted document and extracts a document related to a topic from documents other than the document including the default topic tag by using the calculated frequency of occurrence.

The techniques disclosed in Spina et al. Miklos et al. and Murnane et al. use external knowledge such as Wikipedia. This means that these techniques are highly dependent on the extensiveness of the external knowledge. However it is true that even Wikipedia which is expected to serve as one of the most extensive knowledge sources cannot fully cover information about entities which are generally unknown and that it is not always easy to deal with the diversity of topics discussed in social media.

The technique disclosed in Japanese Patent Application Publication No. 2003 22275 registers a document that has been used or is determined to be usable and extracts co occurrence terms from the registered document. However to allow the extracted co occurrence terms to effectively function as training data for disambiguation it is essential to register an associated field together with the document. This involves manual work and is costly. Moreover the document that has been used often cannot fully cover information about entities which are generally unknown.

In the technique disclosed in Japanese Patent Application Publication No. 2014 002653 a morpheme that occurs in the same document as a search keyword is identified as a co occurrence term. However the search keyword is not always used in the sense intended in the document. Therefore even if a morpheme occurring in the same document as the search keyword is extracted as a co occurrence term the extracted morpheme may not function as training data for disambiguation of the search keyword.

The technique disclosed in Japanese Patent Application Publication No. 2014 032536 uses the frequency of occurrence of a word in a document which includes a default topic tag indicating a topic to extract a document related to the topic. However for example if the document includes only one default topic tag the document may not necessarily be a document on the topic. This is more so if the only default topic tag included in the document has ambiguity. Therefore a word that frequently occurs in a document including a default topic tag indicating a topic cannot be used as training data for disambiguation.

In one aspect a method for generating training data for disambiguation of an entity comprising a word or word string related to a topic to be analyzed includes acquiring by a processor sent messages each including at least one entity contained in a set of entities organizing the acquired messages by user who is a message sender and acquiring sets of messages the sets each containing messages sent by each user identifying from the acquired sets of messages organized by user a set of messages including different entities contained in the set of entities the different entities being greater than or equal to a first threshold value positive integer greater than one in number and identifying a user corresponding to the identified set of messages as a hot user receiving an instruction indicating an object entity to be disambiguated the object entity being contained in the set of entities determining a likelihood of co occurrence of each keyword and the object entity in sets of messages sent by hot users the keyword being included in messages each including the object entity the messages being acquired and determining training data for the object entity on the basis of the likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users.

In another aspect a nontransitory computer readable storage medium having computer readable instruction stored thereon that when executed by a computer implement method for generating training data for disambiguation of an entity comprising a word or word string related to a topic to be analyzed the method including acquiring by a processor sent messages each including at least one entity contained in a set of entities organizing the acquired messages by user who is a message sender and acquiring sets of messages the sets each containing messages sent by each user identifying from the acquired sets of messages organized by user a set of messages including different entities contained in the set of entities the different entities being greater than or equal to a first threshold value comprising a positive integer greater than one in number and identifying a user corresponding to the identified set of messages as a hot user receiving an instruction indicating an object entity to be disambiguated the object entity being contained in the set of entities determining a likelihood of co occurrence of each keyword and the object entity in sets of messages sent by hot users the keyword being included in messages each including the object entity the messages being acquired and determining training data for the object entity on the basis of the likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users.

In another aspect a system for generating training data for disambiguation of an entity comprising a word or word string related to a topic to be analyzed includes a processing device configured to acquire sent messages each including at least one entity contained in a set of entities organize the acquired messages by user who is a message sender and acquiring sets of messages the sets each containing messages sent by each user identify from the acquired sets of messages organized by user a set of messages including different entities contained in the set of entities the different entities being greater than or equal to a first threshold value comprising a positive integer greater than one in number and identify a user corresponding to the identified set of messages as a hot user receive an instruction indicating an object entity to be disambiguated the object entity being contained in the set of entities determine a likelihood of co occurrence of each keyword and the object entity in sets of messages sent by hot users the keyword being included in messages each including the object entity the messages being acquired and determine training data for the object entity on the basis of the likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users.

Embodiments of the present invention have been made in view of the problems in the conventional techniques described above. An object of the present invention is to provide a method system and program for generating training data for disambiguation of entities. The method system and program to be provided are applicable to messages sent via media such as social media where various topics are created every day and require no external knowledge.

Embodiments of the present invention provide a method having the following features to solve the problems of the conventional techniques described above. The method is for generating training data for disambiguation of an entity. The method for generating training data according to the present invention is performed by a computer and includes a acquiring sent messages each including at least one entity contained in a set of entities b organizing the acquired messages by user who is a message sender and acquiring sets of messages the sets each containing messages sent by each user c identifying from the acquired sets of messages organized by user a set of messages including different entities contained in the set of entities the different entities being greater than or equal to a first threshold value positive integer greater than one in number and identifying a user corresponding to the identified set of messages as a hot user d receiving an instruction indicating an entity to be disambiguated hereinafter referred to as object entity the object entity being contained in the set of entities e determining a likelihood of co occurrence of each keyword and the object entity in sets of messages sent by hot users the keyword being included in messages each including the object entity the messages being acquired in a and f determining training data for the object entity on the basis of the likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users.

Preferably e includes calculating as a score indicating a likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users a value obtained by dividing a ratio of the number of hot users who sent messages including the object entity and the keyword to the total number of users who sent messages including the object entity and the keyword by a ratio of the number of hot users who sent messages including the object entity to the total number of users who sent messages including the object entity. Alternatively e may include calculating as a score indicating a likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users pointwise mutual information about an event where a user who mentioned the object entity also mentioned the keyword and an event where a user who mentioned the object entity is a hot user.

More preferably in f the score calculated for each keyword is compared with a second threshold value to determine whether the keyword is either positive or negative training data for the object entity.

Preferably in f for each message including the object entity acquired in the a if a sum of scores of respective keywords included in the message is greater than a third threshold value the message is determined to be positive training data for the object entity whereas if the sum is smaller than a fourth threshold value the message is determined to be negative training data for the object entity.

More preferably in calculation of the sum a weight is assigned to the score of each keyword in accordance with a frequency of concurrent occurrence of the keyword and the object entity.

Still more preferably as the frequency of concurrent occurrence of the keyword and the object entity the number of users who sent messages including the keyword and the object entity is used.

Preferably b includes further organizing the acquired messages by period and acquiring sets of messages the sets each containing messages sent by each user in each period and c includes identifying from the acquired sets of messages organized by user and period a message including different entities contained in the set of entities the different entities being greater than or equal to a fifth threshold value positive integer greater than one in number and identifying a user who sent the identified message as a hot user in the period in which the message was sent.

More preferably e includes calculating as a score indicating a likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users a value obtained by dividing a ratio of the number of hot users who sent messages including the object entity and the keyword in all periods included in a predetermined period to the total number of users who sent messages including the object entity and the keyword in the predetermined period by a ratio of the number of hot users who sent messages including the object entity in all periods included in the predetermined period to the total number of users who sent messages including the object entity in the predetermined period. Alternatively e may include calculating as a score indicating a likelihood of co occurrence of each keyword and the object entity in the sets of messages sent by the hot users pointwise mutual information about an event where a user who mentioned the object entity in a predetermined period also mentioned the keyword in the predetermined period and an event where a user who mentioned the object entity in the predetermined period is a hot user.

The present invention has been described as a method for generating training data for disambiguation of an object entity. The present invention may also be considered as a training data generating program for causing a computer to execute each operation of the method for generating training data and as a training data generating system implemented by installing the training data generating program on a computer.

In the method configured as described above for generating training data for disambiguation a user who frequently sends messages about a topic to be analyzed is identified as a hot user and a likelihood of co occurrence of each keyword and an object entity in sets of messages sent by hot users is calculated. On the basis of the calculated likelihood of co occurrence training data for disambiguation of the object entity is determined. In the present invention training data is thus generated by using sets of messages sent by hot users. This requires no external knowledge and can cover information about entities which are generally unknown. Other advantageous effects of the present invention can be understood from the description of embodiments.

Embodiments for carrying out the present invention will now be described in detail on the basis of the drawings but the following embodiments do not limit the invention set forth in the scope of claims. Also not all combinations of features described in the embodiments are essential to the solving means of the invention. Throughout the description of the embodiments the same elements are given the same reference numerals.

A display such as a liquid crystal display LCD can be connected via a display controller to the bus . The liquid crystal display may be for example a touch panel display or a floating touch display. The display can be used to display via an appropriate graphical interface information e.g. training data that can be displayed by operation of software e.g. computer program according to the present embodiment running on the computer .

A storage device such as a hard disk drive HDD and a drive such as a CD DVD or BD drive can be optionally connected to the bus for example via an SATA or IDE controller .

A keyboard and a mouse can be optionally connected to the bus via a peripheral controller such as a keyboard mouse controller or a USB bus.

The storage device can store an operating system such as Windows registered trademark OS UNIX registered trademark or Mac OS registered trademark the computer program according to the present embodiment and other programs and data in such a manner that they can be loaded into the main memory .

The storage device may be included in the computer may be connected via a cable to the computer such that the storage device can be accessed by the computer or may be connected via a wired or wireless network to the computer such that the storage device can be accessed by the computer .

The drive can be used to install a computer program such as an operating system or an application from a CD ROM DVD ROM or BD onto the storage device as necessary. The computer program may be compressed or may be divided into a plurality of pieces and stored in a plurality of media.

A communication interface complies with for example the Ethernet registered trademark protocol. The communication interface is connected via a communication controller to the bus and allows wired or wireless connection of the computer to a communication line . The communication interface provides a network interface layer for the TCP IP communication protocol for the communication function of the operating system in the computer . The communication line may be for example a wired LAN environment based on a wired LAN connection standard or a wireless LAN environment based on a wireless LAN connection standard. Examples of the wireless LAN environment include a Wi Fi wireless LAN environment such as IEEE802.11a b g n and a mobile phone network environment e.g. 3G or 4G including LTE environment .

The computer can receive data from other computers via the communication line and store the received data in the storage device .

From the above description it can be easily understood that the computer can be implemented by an information processing apparatus such as a typical personal computer a workstation or a mainframe or by a combination of these devices. Note that components described above are merely examples and not all the components are essential to the present invention. Also it is obvious that the computer for implementing the present invention may include components such as a speaker and others.

The entity set storage unit stores a set of entities which are words or word strings related to a topic to be analyzed. For example if the topic to be analyzed is Tokyo motor show 2013 the names of exhibitors and cars on display may be set as entities in the set of entities by reference to event websites and guide books. If the topic to be analyzed is Kyoto sightseeing spots such as Kiyomizu dera Kinkaku ji and Kamo River may be set as entities in the set of entities by reference to guide books. The set of entities may be manually created or may be created using an existing search query extension method or the like. To simplify the following explanation an entity set for a topic to be analyzed will be indicated by a symbol E and an entity which is an element of the entity set E will be indicated by a symbol e e E .

The message acquiring unit reads an entity set E from the entity set storage unit and acquires messages sent by users and each including at least one of entities e contained in the entity set E. Preferably the message acquiring unit acquires messages sent within a predetermined period by users and each including at least one of entities e contained in the entity set E. Messages acquired by the message acquiring unit are preferably real time messages sent via a social media tool such as microblogging but are not limited thereto. Messages acquired by the message acquiring unit may be other information such as traditional blog articles sent by users.

The message acquiring unit may acquire messages by using an API provided by each service or may acquire messages directly from service providers. The message acquiring unit may acquire authorized messages by using a web crawler. As additional information messages each contain metadata including user information for identifying a message sender and time information indicating the time when the message was sent. If no metadata exists and user information is included in message text in a predetermined format the message acquiring unit may extract the user information from the message text using string matching in accordance with the predetermined format. The message acquiring unit stores the acquired messages in the message storage unit .

The organizing unit reads messages from the message storage unit organizes the read messages by user on the basis of metadata and creates a message set for each user. Preferably the organizing unit further organizes messages in the message set for each user by period on the basis of the metadata. Then the organizing unit performs a morphological analysis of each message and creates a set of entities e included in the message and a set of keywords which are any words or word strings included in the message. To simplify the following explanation a message acquired by the message acquiring unit is indicated by a symbol m u t E W . The meaning of each symbol is as follows 

For a set of messages sent by each user u and stored in the message storage unit the hot user identifying unit determines a set E u D of entities e included in a set of messages sent in a period Dby the user u. Then the hot user identifying unit identifies E u D in which the number of different entities e is greater than or equal to a threshold value is a positive integer greater than one and identifies the user u corresponding to the identified E u D as a hot user. A hot user in the period Dis a user who mentioned or more entities e in the period Dand who frequently sends messages about the topic to be analyzed. In the following description a hot user for a topic to be analyzed in the period Dwill be indicated by a symbol U D which can be expressed as U D u U E u D . Information about the hot user identified by the hot user identifying unit is passed to the score calculating unit described below .

The instruction receiving unit receives an instruction from a user via an input device e.g. the keyboard or the mouse in or by reading it from a storage device e.g. the storage device HDD or the CD ROM DVD ROM or BD in . Of entities e contained in an entity set E an entity to be disambiguated hereinafter referred to as object entity e is indicated by the instruction. The instruction indicating the object entity emay be received from a remote computer via a communication interface e.g. the communication interface in . Information about the object entity ereceived by the instruction receiving unit is passed to the score calculating unit described below .

The score calculating unit calculates a P N score PNscore e w indicating a likelihood of co occurrence of the object entity eand each keyword w in messages sent by hot users. Here the keyword w is any word or word string in messages including the object entity eand acquired by the message acquiring unit . The score calculating unit calculates the P N score for the following reason. That is the object entity eoccurring in messages sent by hot users having a strong interest in the topic to be analyzed is expected to be used in the context of the topic to be analyzed. Therefore a keyword w which is likely to co occur with the object entity ein messages sent by hot users can be used as positive training data for disambiguation of the object entity e. Conversely a keyword w which is unlikely to co occur with the object entity ecan be used as negative training data for disambiguation of the object entity e. In the present invention a P N score for each keyword w is calculated as an index for determining the applicability of the keyword w as positive training data and negative training data for the object entity e. A method for calculating PNscore e w will now be described.

First the score calculating unit calculates in the following manner a user set U D e and a hot user set U D e which are sets of users and hot users who sent messages including the object entity ein the period D 1 2 

The score calculating unit divides the sum of the total numbers of hot users in hot user sets each represented by U D e in equation 2 in all periods included in a message collection period by the sum of the total numbers of users in user sets each represented by U D e in equation 1 in all the periods included in the collection period to calculate the ratio ratio e of the total number of hot users who sent messages including the object entity ein all the periods to the total number of users who sent messages including the object entity ein all the periods ratio 3 

The score calculating unit also calculates in the following manner a user set U D e w and a hot user set U D e w which are sets of users and hot users who sent messages including the object entity eand a keyword w in the period D 4 5 

The score calculating unit divides the sum of the total numbers of hot users in hot user sets each represented by U D e w in equation 5 in all the periods included in the message collection period by the sum of the total numbers of users in user sets each represented by U D e w in equation 4 in all the periods included in the collection period to calculate the ratio ratio e w of the total number of hot users who sent messages including the object entity eand the keyword w in all the periods to the total number of users who sent messages including the object entity eand the keyword w in all the periods ratio 6 

Finally the score calculating unit uses ratio e represented by equation 3 and ratio e w represented by equation 6 to calculate in the following manner a score PNscore e w indicating the likelihood of co occurrence of the object entity eand the keyword w PNscore ratio ratio 7 

The P N score thus calculated is greater than one if the keyword w is more likely to co occur with the object entity ein messages sent by hot users and is smaller than one if the keyword w is less likely to co occur with the object entity ein messages sent by hot users. The P N score for each keyword w calculated by the score calculating unit is passed to the training data determining unit described below .

The P N score may be a score based on pointwise mutual information PMI . When x is an event where a user who mentioned the object entity ealso mentioned the keyword w and y is an event where a user who mentioned the object entity eis a hot user the P N score may be defined by the following equation PNscore log 8 where 9 10 11 

The P N score thus calculated is greater than zero if the keyword w is more likely to co occur with the object entity ein messages sent by hot users and is smaller than zero if the keyword w is less likely to co occur with the object entity ein messages sent by hot users.

The P N score will now be concretely described with reference to . In the example shown in the topic to be analyzed is Tokyo motor show 2013 and the object entity eto be disambiguated is the word Jaguar . The word Jaguar is used in multiple senses. For example the word Jaguar may be used in the context of feline mammals or may be used in the context of car brand names. Since the topic to be analyzed is Tokyo motor show 2013 here the P N score is expected to be higher for a word which is more likely to co occur with the word Jaguar used in the context of car brand names and lower for a word which is less likely to co occur with the word Jaguar used in the context of car brand names.

The training data determining unit determines training data for the object entity eon the basis of the P N score calculated by the score calculating unit . Specifically if the P N score calculated for each keyword w is greater than one in the case of using equation 7 or greater than zero in the case of using equation 8 the training data determining unit can determine the keyword w as positive training data for the object entity e. Also if the P N score calculated for each keyword w is smaller than one in the case of using equation 7 or smaller than zero in the case of using equation 8 the training data determining unit can determine the keyword w as negative training data for the object entity e.

Alternatively the training data determining unit may determine positive and negative training data for each message including the object entity eacquired by the message acquiring unit . Specifically if the sum of P N scores of respective keywords w included in the message is greater than a threshold value p the training data determining unit may determine the message as positive training data for the object entity e. Also if the sum of P N scores described above is smaller than a threshold value n the training data determining unit may determine the message as negative training data for the object entity e.

Additionally when calculating the sum of P N scores of respective keywords w for each message the training data determining unit may assign a weight to the P N score of each keyword w in accordance with the frequency of concurrent occurrence of the keyword w and the object entity eas in the following equation 13 

Information of the training data determined by the training data determining unit is used to disambiguate the object entity e. A framework of existing supervised document classification such as a naive Bayes classifier or a support vector machine may be used to disambiguate the object entity e. These techniques are not described in detail in the present specification as they are known techniques out of the scope of the present invention.

Information of the training data determined by the training data determining unit may itself be used as a result obtained by disambiguating the object entity e. That is positive training data may be used as an entity related to the topic to be analyzed and negative training data may be used as an entity not related to the topic to be analyzed.

A flow of training data generation carried out by the training data generating system according to the present embodiment will now be described with reference to . The process of training data generation starts at operation S. In operation S the message acquiring unit refers to an entity set E stored in the entity set storage unit and containing entities representing a topic to be analyzed acquires messages sent within a predetermine period and each including at least one entity e in the entity set E and stores the messages in the message storage unit .

Next on the basis of metadata acquired with the messages the organizing unit organizes the messages acquired by the message acquiring unit by user u and period D operation S . Next for a set of messages corresponding to each user u and period Dorganized by the organizing unit the hot user identifying unit determines a set E u D of entities included in messages in the set. Then the hot user identifying unit identifies as a hot user in a period D a user u corresponding to a message set in which the number of included entities E u D is greater than or equal to operation S .

Next the instruction receiving unit receives an instruction indicating an object entity efrom a user operation S . Then the score calculating unit calculates a P N score for each keyword w included in messages each including the object entity e operation S . The operation performed by the score calculating unit will be described in detail later on with reference to . Last on the basis of the P N score calculated for each keyword w by the score calculating unit the training data determining unit determines positive and negative training data for the object entity e operation S . Then the process ends.

A flow of score calculation done by the score calculating unit will now be described with reference to . The process of score calculation starts at operation S where the score calculating unit calculates a set U D e of users who sent messages including the object entity ein the period Dand a set U D e of hot users who sent messages including the object entity ein the period D.

Next the score calculating unit calculates a set of users U D e w who sent messages including the object entity eand the keyword w for which the P N score is to be calculated in the period D and also calculates a set of hot users U D e w who sent messages including the object entity eand the keyword w in the period D operation S .

Next the score calculating unit calculates a ratio ratio e of the total number of hot users who sent messages including the object entity ein all periods to the total number of users who sent messages including the object entity ein all the periods operation S . Next the score calculating unit calculates a ratio ratio e w of the total number of hot users who sent messages including the object entity eand the keyword w for which the P N score is to be calculated in all the periods to the total number of users who sent messages including the object entity eand the keyword w in all the periods operation S .

Last the score calculating unit divides the value ratio e w determined in operation S by the value ratio e determined in operation S to obtain the P N score ratio e w ratio e for the keyword w operation S . Then the process ends.

An evaluation experiment for a P N score proposed by the present invention will now be described with reference to . The content of the evaluation experiment to be described with reference to is as follows 

Tweets containing external URLs were eliminated to exclude advertisements. Messages containing URLs for photo sharing services and location based services were not eliminated because they often include descriptions of user experiences. Users who sent exactly the same message more than once in the past were identified as bot users.

The table in shows examples of keywords for the object entity Jaguar and their P N scores calculated by equation 7 . The field on the right side of the table shows meanings of the object entity in actual messages. The table in shows that keywords having P N scores greater than one are used in the context of Tokyo motor show and thus can be used as positive training data for the object entity Jaguar . The table in also shows that keywords having P N scores smaller than one are used in the context of music or animals unrelated to Tokyo motor show and thus can be used as negative training data for the object entity Jaguar .

Although the present invention has been described using the embodiments the technical scope of the present invention is not limited to the scope described in the embodiments. It is apparent to those skilled in the art that various modifications or improvements can be made to the embodiments described above. Therefore it is obvious that such modified or improved embodiments may also be included in the technical scope of the present invention.

It should be noted that the order of execution of processing such as operations procedures steps and stages in the apparatus system program and method described in the scope of claims description and drawings is not specified with such terms as before and prior to and that the processing may be implemented in any order unless the output of previous processing is used in subsequent processing. It should also be noted that even if the output of previous processing is used in subsequent processing it may be possible to add other processing between the previous processing and the subsequent processing or even if other processing is described as being added therebetween it may still be possible to perform the previous processing immediately before the subsequent processing. Even if terms such as first next and subsequently may be used for convenience in the scope of claims description and operation flows in the drawings this does not necessarily mean that it is essential to implement the processing in this order.

