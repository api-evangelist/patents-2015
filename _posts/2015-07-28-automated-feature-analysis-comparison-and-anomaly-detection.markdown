---

title: Automated feature analysis, comparison, and anomaly detection
abstract: Novel methods and systems for automated data analysis are disclosed. Data can be automatically analyzed to determine features in different applications, such as visual field analysis and comparisons. Anomalies between groups of objects may be detected through clustering of objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09424489&OS=09424489&RS=09424489
owner: CALIFORNIA INSTITUTE OF TECHNOLOGY
number: 09424489
owner_city: Pasadena
owner_country: US
publication_date: 20150728
---
The present application is a continuation of U.S. application Ser. No. 14 077 134 which in turn claims priority to U.S. Provisional Patent Application No. 61 724 813 filed on Nov. 9 2012 the entire disclosure all of which is incorporated herein by reference in their entirety.

This invention was made with government support under Grant No. W81XWH 09 1 0266 awarded by the US Army Medical Research and Material Command. The government has certain rights in the invention.

The present disclosure relates to automated data analysis. More particularly it relates to systems devices and methods for automated feature analysis comparison and anomaly detection.

In a first aspect of the disclosure a computer implemented method is described the computer implemented method comprising providing a sensing and analyzing device the sensing and analyzing device comprising at least one sensor configured to detect at least one physical feature describing a plurality of physical objects generating by the sensing and analyzing device a plurality of feature vectors representing the plurality of objects based on the at least one physical feature wherein the plurality of feature vectors comprises a plurality of components describing the at least one physical feature wherein each component of the plurality of components has a numerical range wherein the at least one physical feature is represented by at least one component within each feature vector converting by the sensing and analyzing device the numerical range of each component to a range between 0 and 1 wherein the converting is carried out by formula

In a second aspect of the disclosure a computer implemented method is described the computer implemented method comprising providing a sensing and analyzing device the sensing and analyzing device comprising at least one sensor configured to detect at least one physical feature describing a plurality of physical objects generating by the sensing and analyzing device a plurality of feature vectors representing the plurality of objects based on the at least one physical feature wherein the plurality of feature vectors comprises a plurality of components describing the at least one physical feature wherein each component of the plurality of components has a numerical range wherein the at least one physical feature is represented by at least one component within each feature vector clustering by the sensing and analyzing device the plurality of feature vectors thereby obtaining a plurality of clustered feature vectors applying by the sensing and analyzing device principal component analysis to the plurality of clustered feature vectors thereby obtaining a distance flag value and a first evaluated plurality of feature vectors calculating by the sensing and analyzing device a number flag value by counting each feature vector of the plurality of clustered feature vectors based on a threshold value thereby obtaining a second evaluated plurality of feature vectors analyzing by the sensing and analyzing device the plurality of physical objects based on the first or second evaluated plurality of feature vectors.

In a third aspect of the disclosure a computer implemented method is described the computer implemented method comprising providing a sensing and analyzing device the sensing and analyzing device comprising at least one sensor configured to detect at least one physical feature describing a plurality of physical objects generating by the sensing and analyzing device a plurality of feature vectors representing the plurality of objects based on the at least one physical feature wherein the plurality of feature vectors comprises a plurality of components describing the at least one physical feature wherein each component of the plurality of components has a numerical range wherein the at least one physical feature is represented by at least one component within each feature vector clustering by the sensing and analyzing device the plurality of feature vectors thereby obtaining a plurality of clustered feature vectors applying by the sensing and analyzing device distance calculation based on a threshold value to the plurality of clustered feature vectors thereby obtaining a distance flag value and a first evaluated plurality of feature vectors calculating by the sensing and analyzing device a number flag value by counting each feature vector of the plurality of clustered feature vectors based on a threshold value thereby obtaining a second evaluated plurality of feature vectors analyzing by the sensing and analyzing device the plurality of physical objects based on the first or second evaluated plurality of feature vectors.

In a fourth aspect of the disclosure a computer implemented method is described the computer implemented method comprising providing a sensing and analyzing device the sensing and analyzing device comprising at least one sensor configured to detect at least one physical feature describing a plurality of physical objects generating by the sensing and analyzing device a plurality of feature vectors representing the plurality of objects based on the plurality of physical features wherein the plurality of feature vectors comprises a plurality of components describing the plurality of physical features wherein each component of the plurality of components has a numerical range wherein each physical feature of the at least one physical feature is represented by at least one component within each feature vector converting by the sensing and analyzing device the numerical range of each component to a range between 0 and 1 wherein the converting is carried out by formula

The present disclosure relates to automated data analysis that can apply data aggregation and extraction of features from a wide variety of application fields. A similar technique for the extraction of features from a set of data may be applied to different sets of data. For example a geological survey may collect data about a region of Earth or Mars. Data collected may comprise visual images x ray images mass spectroscopy chemical samples and so on. In the present disclosure methods are described to aggregate such data in a feature space define mathematical entities which describe them extract features from the data and output a resulting analysis. For example certain visual features may indicate the presence of a certain mineral while x ray images or hyperspectral images may give a different chance for the presence of that mineral. In such cases human intervention may normally be necessary to determine the relative importance and reliability of each set of data such as visual vs x ray images. In the present disclosure mathematical entities that is feature vectors are used to express the information contained in different sets of data e.g. visual and x ray images in a format the feature vectors which allows automated comparative analysis. The automated systems devices or methods of the present disclosure may therefore perform an automated analysis of the features of different sets of data. Similar methods may be used for other applications for example medical diagnosis financial systems and military reconnaissance. Therefore such methods devices or systems may be termed automated global feature analyzer AGFA .

For every application AGFA can extract and deliver features that make up a feature vector. Once feature vectors are generated the AGFA framework can then operate. As a result AGFA can cluster the data and can find anomalies based on the feature space. In other words the data is transformed in a feature space and can then be analyzed in that space. Through this transformation automatic analysis of the data is possible regardless of the origin of the data. Furthermore AGFA can also allow for objects to be compared to one another based on their respective feature vectors. In some embodiments a temporal change analysis may also be carried out by analyzing the difference between feature vectors at different times. For example the same feature vector may be compared with itself at time and time .

For example regarding applications for geology mining resource allocation and military reconnaissance the features space will contain feature vectors consisting of specific features. In some embodiments a list of features to be included in a feature vector may comprise Color Albedo brightness Ellipse fit of circumference of segmented object yielding semi major and semi minor axes the ratio of which can be a measure of how circular an object is Extent Angularity Compactness Size Gabor filters for texture assessment Multi spectral data Hyperspectral data Spectroscopic data Biological contaminate concentrations Chemical contaminate concentrations Radioactive contamination.

Some possible outcomes after application of AGFA to the above features may comprise Region of interest demarcation delineation Anomaly detection Autonomous vehicle control Guidance for exploration equipment. In some embodiments the methods of the present disclosure may be applied to asteroid exploitation.

As another example for medical diagnosis possible features may comprise Patient specific data such as age height weight gender Blood examination results Urine stool examination results X ray CT MRI fMRI Ultrasound images results Multi spectral data Hyperspectral data Pulse Heart rate Intraocular pressure Intracranial pressure Blood pressure Lung volume.

Some possible outcomes after application of AGFA to the above features may comprise Medical diagnosis Guidance of surgical equipment e.g. laparoscopic surgeries Region of interest demarcation delineation for tumor treatment Anomaly detection.

As another example for financial markets possible features may comprise Stock values Opening bid Closing bid Bids throughout trading period Gold price Stock indices Dow Jones S P 500 etc. Trading volume e.g. of stocks .

Some possible outcomes after application of AGFA to the above features may comprise Buy Hold Sell decisions Anomaly detection in trends.

Another example for the application of AGFA is visual fields. In certain situations medical diagnosis of visual field defects in a human eye may be done on a mass scale e.g. thousands to millions of people worldwide or it may be only done remotely for example in remote locations on Earth or for the case of astronauts on a space mission to Mars or for human settlement on the Moon.

In such cases an automated system for the detection of visual field defects may be advantageous. In such situations in the absence of clinical experts an integrated auto characterization system can analyze 3D Computerized Threshold Amsler Grid 3D CTAG visual field data and objectively identify and characterize the occurring visual field defects e.g. scotomas as in missing areas of vision in accordance with the following numerical methods 1 visual field data transforms include area and volume of visual field loss lost and preserved area grades and slope distribution and 2 scotoma data transforms include scotoma perimeter scallopedness and scotoma center location. As it is known to the person skilled in the art the Amsler test is a visual field test. The AGFA framework may also be equally applicable to other visual field test data e.g. to Humphrey Visual Field Analyzer.

The raw 3D CTAG data can be systematically assessed first for the number n of distinct contrast sensitivity levels present in the data then for the area denoted A where 0 i 100 represents the percent contrast level in number of square degrees e.g. grid points and percentage of visual field lost 

The Lost Area Grade LAG is calculated by dividing the scotoma area at the highest tested contrast level A by the scotoma area at the lowest tested contrast level A . This area ratio is then multiplied by the contrast sensitivity scaling factor which consists of the scotoma depth 100 h divided by the total depth 100 then squared to eliminate degeneracy 

The number of data points at each level of contrast sensitivity less than 100 is multiplied by the loss in contrast sensitivity at each data point to determine the volume of visual field loss A 100 i . The volume of visual field loss is then divided by total tested visual field volume to determine the percentage of visual field volume lost.

The slope grades are independently determined in for example both the horizontal x and vertical y directions. A slope grade is defined as the loss of contrast sensitivity e.g. 100 i divided by the number of degrees x or y over which the loss occurs 

The x values and y values of all scotoma data points for each tested contrast sensitivity level are averaged to obtain the coordinates for the scotoma center at each tested contrast sensitivity level. The respective centers are plotted in 3D together with the data points of the entire visual field. The centers are subsequently averaged to obtain the mean center. Then the mean distance and standard deviation of distances from each center to the mean center are calculated. All centers and the mean center for each scotoma are then plotted onto a scatterplot.

The scotoma perimeter points at each tested contrast sensitivity level are determined and recorded by scanning the list of points in a scotoma for points that are horizontally and or vertically adjacent to non scotoma points at the respective level i.e. with contrast sensitivity levels greater than that of the current level .

The scallopedness measure assesses the scotoma perimeters at each contrast sensitivity level for the fluctuation of curvature. All points on the perimeter are sequentially numbered. Starting with the first point p 1 the Euclidian distance is calculated between each point along the perimeter p and the point that is a user defined index offset x down the list p x of perimeter points. All Euclidian distances are averaged and subsequently displayed as a histogram. The procedure is performed at each contrast sensitivity level with for example two different user defined index offsets. A sharply peaked histogram i.e. one peak indicates a scotoma with a smooth perimeter not scalloped peaks towards the left end of the histogram indicate more tightly curved perimeters i.e. small radius of curvature while peaks towards the right end of the histogram indicate perimeters with a large radius of curvature.

To also account for the phenomenon of metamorphopsia i.e. distortion or waviness of straight Amsler grid lines instead of missing ones a more general superset of algorithms can be implemented for the automated characterization of both distorted vision i.e. metamorphopsia and visual field defects i.e. scotomas in 3D. The following objective characterization indices that describe visual field defects can be used 

Absolute of Test Locations Not Seen Numerical count of Amsler grid points not seen regardless of contrast.

Relative of Test Locations Not Seen Absolute number of test locations not seen divided by total number of available test locations in percent regardless of contrast.

Area of Visual Field Impaired at XX Contrast number of Amsler grid points marked as not visible at a given Amsler grid contrast 

Relative Area of Visual Field Impaired at XX Contrast number of Amsler grid points marked as not visible at a given Amsler grid contrast divided by the total number of available test locations at that given Amsler grid contrast in percent 

Absolute Hill of Vision Volume Lost Sum of areas of visual field not seen multiplied by respective tested contrast levels in measured in degpercent .

Relative Hill of Vision Volume Lost Absolute Volume Lost divided by overall tested Hill of Vision measured in percent .

Lost Area Grade LAG Existing scotoma area at highest tested contrast level divided by existing scotoma area at lowest tested contrast level multiplied by the actual scotoma depth measured in percent contrast.

Preserved Area Grade PAG Existing preserved visual field area at lowest tested contrast level divided by existing preserved visual field area at highest tested contrast level multiplied by the actual scotoma depth measured in percent contrast.

Inverse Lost Area Grade ILAG existing scotoma area at lowest tested contrast level divided by existing scotoma area at highest tested contrast level multiplied by the actual scotoma depth measured in percent contrast.

Inverse Preserved Area Grade IPAG existing preserved visual field area at highest tested contrast level divided by existing preserved visual field area at lowest tested contrast level multiplied by the actual scotoma depth measured in percent contrast.

The above characterization indices enable the qualitative and quantitative analysis of temporal changes of a subject s visual field. There are modified embodiments of the above listed indices and additional indices known to the person skilled in the art.

In the following different characteristics of AGFA will be described using the example of visual field test. The person skilled in the art will understand that while the AGFA methods are described with a specific example different applications can be envisioned.

In some embodiments AGFA may comprise a step of Flag Computation. The Flag Computation step may comprise Feature Vector Normalization Procedures.

AGFA can be used to analyze objects. An object may be for example a visual field data set a rock in an image etc. Each object may have a feature component vector assigned with all the feature component values. In other words a feature vector may comprise different components each component having a specific value. The feature component values may have different ranges in terms of the maximum and minimum values . Moreover the feature components may have discrete or continuous values. In order to compare the objects in an image it may be necessary to normalize them so as to make the feature component value independent of range and number of components in a feature.

In other words an object can be assigned a feature vector. The feature vector may comprise different components. Each component may have a certain range different from other components. In order to compare feature vectors it may be advantageous to normalize the range of each component to make it possible to compare feature vectors.

For instance it is not possible to compare two objects based on two features such as color R G B components each with integer value range 0 255 and angularity with only one component and real value range 0 1 . In this example the color feature has three times the number of components as compared to the angularity feature. Therefore if a weight would be assigned based on the number of components the color feature would have three times the weight of the angularity feature. Further each color component would have a range 0 255 compared to 0 1 for the angularity feature. Therefore the color components may contribute 255 times more weight than angularity. To overcome this issue a three stage normalization procedure can be implemented in order to normalize each component to a range 0 1 . This normalization procedure also renders the comparison independent of the number of components in a feature.

In some embodiments in the first step of normalization referred to as Min Max normalization the feature component values are converted to within a real value range 0 1 using the formula 

In the second step of normalization which can also be termed feature dimension normalization each feature component value can be divided by the number of components in that feature by the formula 

In the third step of normalization which may also be termed absolute normalization the following formula is applied 

The above three normalization steps ensure that the feature values are in the real value range 0 1 and are independent of the number of components. This ensures that each feature component value contributes equally in analyzing the features of an object for example to determine whether an object is anomalous.

After Feature Vector Normalization Procedures the Flag Computation step may comprise Sequential Clustering.

In some embodiments the feature component vector obtained in the previous step can characterize an object in an image. A next possible step towards determining if an object or objects is or are anomalous is to classify the objects into different groups. In one embodiment a sequential clustering method can be implemented which groups the incoming vectors into a natural number of clusters in real time. A possible advantage of this method over other clustering methods like K means clustering is that the number of clusters the vectors are to be grouped into does not need to be provided. The method not only clusters the vectors but also determines the natural number of clusters.

There are other supervised or unsupervised clustering methods which could be used e.g. Level Set Analysis. Such algorithms determine automatically the natural number of clusters from the data itself and are known to the person skilled in the art.

As known to the person skilled in the art the basic sequential clustering method comprises a single threshold with the vectors having a distance with cluster centers below the threshold being grouped into a particular cluster essentially clustering all vectors in one pass. In some embodiments the sequential clustering method implemented in the present disclosure differs from the basic method in the sense that there are two thresholds and the number of passes to cluster all vectors could be more than one.

In the basic form of sequential clustering the first incoming vector is binned into the first cluster which also becomes its center. The next incoming vector is binned to one of the existing clusters if the distance between the vectors to a particular cluster center is below a pre defined threshold and if not the vector is binned into a new cluster. A possible drawback of this method is that the formation of clusters and cluster members depend on the order in which the vectors arrive since all the vectors are clustered in one pass. Another possible drawback is that the choice of threshold influences the results i.e. changing the threshold value yields a different number of clusters or same number of clusters with different members.

In some embodiments of the present disclosure a different method is implemented which considers the Euclidean distance when calculating the distance between a vector and a cluster center. This constitutes an improved version of the standard sequential clustering method. In the present disclosure this improved method may be referred to as certainty sequential clustering.

In certainty sequential clustering two thresholds tand t t t are selected such that if the Euclidean distance between a vector F3and nearest cluster center C d F3 C is below t the vector belongs to the corresponding cluster. If d F3 C is above t then vector F3 does not belong to cluster C. However if t

In other embodiments K means clustering can also be used however it requires the number of clusters to be provided beforehand unlike sequential clustering.

The clustering of feature component vectors explained in the previous section can give information about any objects being anomalous from other objects detected in an image or data set. The anomaly could be any one of the features or a set or combination of features e.g. fingerprint . However the method may not necessarily be able to determine whether the anomaly is really of interest for further study.

Principal component analysis PCA can be defined as an orthogonal linear transformation that transforms the data to a new coordinate system such that the greatest variance by any projection of the data comes to lie on the first coordinate called the first principal component the second greatest variance on the second principal component and so on. Such method is known to the person skilled in the art and is described for example in Jolliffe I. T. Wiley Online Library 2002 the disclosure of which is incorporated herein by reference in its entirety.

The number of principal components is no higher than the number of variables or vectors. The idea is to determine the first principal component of each cluster which can indicate the greatest variance for the constituting component or components of the feature vectors along direction of that component or these components in the feature vector space.

In the example of objects in the aim is to determine the first principal component of each cluster. The number of feature component values N becomes the dimension of a feature component vector. If F is an M N matrix where M is the number of feature component vectors in a cluster and each vector forms one row of a matrix then a typical method used to evaluate the principal components is to decompose the covariance matrix of F to determine its eigenvalues and eigenvectors. An example of this procedure can be found for example in Press et al. Cambridge University Press 1992 the disclosure of which is incorporated herein by reference in its entirety. The eigenvectors are unit vectors along the principal components and the eigenvalues are their corresponding magnitude. Single value decomposition can be used to determine the eigenvectors and eigenvalues using the formula Cov where CovF is a N N covariance matrix of matrix F U is a N N unitary matrix of eigenvectors of matrix CovF D is a N M rectangular diagonal matrix with the N diagonal values being the eigenvalues and V is a M N unitary matrix.

The largest eigenvalue is the magnitude of the first principal component of a cluster which in other words quantifies the direction with maximum variance of the vectors within that cluster. The eigenvalue is the length of the eigenvector where the eigenvector gives the direction of maximum variance of the principal component of a cluster. For example Table 2 gives the largest eigenvalue for the clusters of Table 1 and .

To determine if two clusters are disjoint a comparison can be made for the Euclidian distance in feature space between the centers of the clusters with that of the sum of the largest eigenvalues of each cluster. If the Euclidian distance is smaller than the sum then the two clusters overlap if not then the two clusters are disjoint in feature space. In another embodiment the corresponding eigenvectors belonging to the respective eigenvalues can be projected onto the respective distance vector between two clusters to get a more accurate distance measurement. If two clusters are disjoint i.e. the Euclidian distance is smaller than the sum of the largest eigenvalues it is likely that the objects belonging to one of the clusters are significantly different from the objects belonging to the other cluster with respect to their features. If the clusters overlap then there is no anomaly. This property can be quantified by a distance flag if the clusters are disjoint the distance flag can be set as red numerically e.g. a value of 1 and if the clusters overlap the distance flag can be set as green numerically e.g. a value of 0 . Continuing with the example of Tables 1 and 2 Table 3 gives the distance flag value for the pairwise relation among the three clusters of Table 2. It can be seen from Table 3 that all clusters are disjoint respectively as their distance flag has a value of 1. The person skilled in the art will understand that different values may be used to indicate that clusters are disjoint. For example in some embodiments the distance flag may be set as 0 to indicate disjoint clusters or in yet another embodiment the distance flag can take on continuous values e.g. between 0 and 1 proportional to the degree of overlap or separation. In some embodiments a different type of distance may be employed instead of an Euclidian distance.

Whether a cluster is anomalous cannot necessarily be determined from the distance flag alone. It can be assumed that the cluster with lesser number of objects is anomalous and this property can be represented by a number flag. For example if the number of objects in a cluster is less than ten percent e.g. user defined threshold of the number of objects in the other cluster the number flag can be set as red numerically e.g. a value of 1 otherwise the number flag can be set as green numerically e.g. a value of 0 . Continuing from the example of Table 3 the result of this step is detailed in Table 4. From Table 4 it can be seen that the number flag for clusters 1 and 2 is 1 the number flag for clusters 1 and 3 is 1 and the number flag for clusters 2 and 3 is 0. In other embodiments a different value for the number flag may be used. In some embodiments a different threshold may be used. For example the threshold may be twenty percent instead of ten percent or even another chosen value different from ten or twenty percent. In another embodiment the number flag can take on continuous values e.g. between 0 and 1 reflecting the ratio of number of cluster members between one cluster and another cluster.

The distance flags can be set based on the distance between each unique pair of clusters and the sum of the largest eigenvalues of corresponding clusters. In other embodiments different flags may be used.

The number flags can be set based on the number of members in the respective clusters. In other embodiments different flags may be used.

After flag computation analysis of the feature vector can be applied to the desired specific application. For example the flag computation can be applied to visual field comparisons and temporal change analysis.

For visual field classification purposes the indices obtained in the methods described above can be taken together to form a feature vector that is characteristic of a particular 3D CTAG examination result i.e. a visual field. As a result visual fields for example assessed with the Web based comprehensive visual field test and diagnosis system can be compared to each other via their respective feature vectors after proper normalization of the feature vectors and anomalies can be detected.

The present disclosure comprises the advantage of allowing the comparison of feature vectors after such vectors have been determined following the methods described above for example comprising the distance flag and number flag indices.

The comparison between visual fields and the anomaly detection among a set of visual fields such as a set of visual fields for a particular patient obtained over time can be performed by an auto classification system based on the Automated Global Feature Analyzer AGFA .

The feature vectors in the case of visual field data classification may comprise the relative characterization indices listed above in the present disclosure relative of test locations not seen volume lost relative to hill of vision LAG ILAG PAG IPAG. The reason for the use of the relative characterization indices for the feature vectors as opposed to the absolute ones is that the resulting feature vectors are largely independent from the respective visual field examination specifications such as the area of visual field tested and contrast levels presented. Otherwise a comparison of different visual fields taken on different test machines with different examination parameter settings can become problematic. In other applications the characterization indices may be different from those listed for visual field comparisons. For example indices for features for financial markets and other applications have been listed above in the present disclosure.

For the case of visual field comparisons the feature vectors may enable both qualitative and quantitative analyses of temporal changes of a subject s visual field. These temporal changes can be assessed by calculating the following comparative quantities amongst different 3D CTAG examination results for each subject 

Overlap Parameter defined as the N dimensional scalar product between two feature vectors ranging from 1 to 1 with 1 representing the case that two visual fields are completely the opposite dissimilar from each other 0 representing the case that two visual fields are orthogonal to each other and with 1 representing the case that two visual fields are the same and of course all continuous variations in between these values. The Overlap Parameter is a measure of similarity between two feature vectors.

Hamming Distance defined as the sum of squared differences between the feature vector components divided by the dimension N of the feature vector. The Hamming Distance is always 0 and is a measure of similarity between two feature vectors.

Euclidian Distance defined as the square root of the sum of squared differences between the feature vector components. The Euclidian Distance is always 0 and is also a measure of similarity between two feature vectors.

Additionally AGFA can perform sequential clustering among other clustering techniques to group visual field exams of a patient or of several patients into clusters of similarity based on the respective feature vectors and can subsequently perform anomaly analyses based on inter cluster comparisons. An anomaly is defined as a particular feature vector or a component of a particular feature vector e.g. relative of test locations not seen volume lost relative to hill of vision LAG ILAG PAG IPAG which is significantly different from the other feature vectors or the same component in the other feature vectors. Together with the Overlap Parameter Hamming Distance and Euclidian distance the clustering and anomaly detection can provide a means for visual field classification and comparison. Moreover this tool set provided by AGFA can allow for the assessment of visual field deterioration or improvement over time i.e. temporal change by analyzing the underlying feature vectors that represent the respective visual fields at a given time.

The feature vectors can also serve as inputs to artificial neural networks such as single or multi layered perceptron systems as well as Hopfield attractor networks for the generation of preliminary diagnoses. In particular the adaptation of Hopfield attractor networks to the respective visual field area and geometry being tested on a given examination station device is straightforward because no spatial arrangement assumption of the neurons of the Hopfield attractor network is made with respect to the actual visual field geometry for a given examination station device.

The methods described in the present disclosure may be computer implemented through a hardware device. Such hardware device can comprise a processor and a memory and a plurality of sensors. The sensors as understood by the person skilled in the art can comprise a wide variety of different sensors. For example camera sensors radioactivity sensors magnetic sensors electrical sensors chemical sensors infrared sensors spectroscopy analyzers mass spectroscopy sensors pressure sensors humidity sensors blood sugar sensors temperature sensors seismic sensors salinity sensors velocity sensors and accelerometers voltmeters magnetometers etc.

In some embodiments the hardware device may be termed a sensing and analyzing device. In some embodiments the device may be a smartphone or a tablet.

The methods and systems described in the present disclosure may be implemented in hardware software firmware or any combination thereof. Features described as blocks modules or components may be implemented together e.g. in a logic device such as an integrated logic device or separately e.g. as separate connected logic devices . The software portion of the methods of the present disclosure may comprise a computer readable medium which comprises instructions that when executed perform at least in part the described methods. The computer readable medium may comprise for example a random access memory RAM and or a read only memory ROM . The instructions may be executed by a processor e.g. a digital signal processor DSP an application specific integrated circuit ASIC a field programmable logic array FPGA a graphic processing unit GPU or a general purpose GPU .

A number of embodiments of the disclosure have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the present disclosure. Accordingly other embodiments are within the scope of the following claims.

The examples set forth above are provided to those of ordinary skill in the art as a complete disclosure and description of how to make and use the embodiments of the disclosure and are not intended to limit the scope of what the inventor inventors regard as their disclosure.

Modifications of the above described modes for carrying out the methods and systems herein disclosed that are obvious to persons of skill in the art are intended to be within the scope of the following claims. All patents and publications mentioned in the specification are indicative of the levels of skill of those skilled in the art to which the disclosure pertains. All references cited in this disclosure are incorporated by reference to the same extent as if each reference had been incorporated by reference in its entirety individually.

It is to be understood that the disclosure is not limited to particular methods or systems which can of course vary. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting. As used in this specification and the appended claims the singular forms a an and the include plural referents unless the content clearly dictates otherwise. The term plurality includes two or more referents unless the content clearly dictates otherwise. Unless defined otherwise all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the disclosure pertains.

